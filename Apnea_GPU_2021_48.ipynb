{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import wfdb\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, lfilter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchvision.models.alexnet import alexnet\n",
    "\n",
    "\n",
    "seed=2020\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a01_100'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reclist=glob(\"./seg/*\")\n",
    "dtlist=glob(\"./seg/*/*.npy*\")\n",
    "reclist.sort()\n",
    "dtlist.sort()\n",
    "lab_list=[seg.split('_')[0][-1] for seg in dtlist]#shuffle by idx\n",
    "(dtlist[0].split('_')[1]+'_'+dtlist[0].split('_')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cheb_bandpass_filter(data, lowcut, highcut, signal_freq, filter_order):    # \n",
    "        \"\"\"\n",
    "        Method responsible for creating and applying Butterworth filter.\n",
    "        :param deque data: raw data\n",
    "        :param float lowcut: filter lowcut frequency value\n",
    "        :param float highcut: filter highcut frequency value\n",
    "        :param int signal_freq: signal frequency in samples per second (Hz)\n",
    "        :param int filter_order: filter order\n",
    "        :return array: filtered data\n",
    "        \"\"\"\n",
    "        nyquist_freq = 0.5 * signal_freq\n",
    "        low = lowcut / nyquist_freq\n",
    "        high = highcut / nyquist_freq\n",
    "        #b, a = butter(filter_order, [low, high], btype=\"band\")\n",
    "        b, a = signal.cheby2(filter_order, 40, [low, high], 'band', analog=False)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects=[['a11'],['a15'],['a17'],['b01'],['c07'],\n",
    "          ['a11','a15','a17','b01','c07'],\n",
    "          ['a14','a19','b05','c01','c07'],\n",
    "          ['a04','a19','b05','c01','c09'],['b02','b03'],['x16','x21']]\n",
    "len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def getTrainTestList(reclist,opt='rec_cv',fold=1):\n",
    "    train_dtlist=[]\n",
    "    test_dtlist=[]\n",
    "    if opt=='rec_cv':#reclist is rec list\n",
    "        kf = KFold(n_splits=10)\n",
    "        kf_idx=kf.split(reclist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_rec,test_rec=list(np.array(reclist)[train_idx]),list(np.array(reclist)[test_idx])\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "    elif opt=='physionet':\n",
    "        train_rec=[rec for rec in reclist if rec[-3]!='x']\n",
    "        test_rec=[rec for rec in reclist if rec[-3]=='x']\n",
    "        print(len(train_rec),len(test_rec))\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "    elif opt=='physionet_train':\n",
    "        train_rec=[rec for rec in reclist if rec[-3]!='x']\n",
    "        #print(len(train_rec),len(test_rec))\n",
    "        kf_idx=kf.split(dtlist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_dtlist,test_dtlist=list(np.array(dtlist)[train_idx]),list(np.array(dtlist)[test_idx])\n",
    "    elif opt=='blind':\n",
    "        subjects=[['a11'],\n",
    "                  ['a15','x27','x28'],\n",
    "                  ['a17','x12'],\n",
    "                  ['b01','x03'],\n",
    "                  ['c07','x34'],\n",
    "                  ['a11','a15','x27','x28','a17','x12','b01','x03','c07','x34'],\n",
    "                  ['a14','a19','x05','x08','x25','b05','x11','c01','x35','c07','x34'],\n",
    "                  ['a04','a19','x05','x08','x25','b05','x11','c01','x35','c09'],\n",
    "                  ['b02','b03','x16','x21']]\n",
    "        train_rec=[rec for rec in reclist if rec.split('/')[-1] not in subjects[fold-1]]\n",
    "        test_rec=[rec for rec in reclist if rec.split('/')[-1] in subjects[fold-1]]\n",
    "        print(len(train_rec),len(test_rec),test_rec)\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "\n",
    "    else:#reclist is npy data list\n",
    "        kf = KFold(n_splits=10)\n",
    "        kf_idx=kf.split(dtlist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_dtlist,test_dtlist=list(np.array(dtlist)[train_idx]),list(np.array(dtlist)[test_idx])\n",
    "         \n",
    "    return train_dtlist,test_dtlist\n",
    "\n",
    "def dtclean(dt_path):\n",
    "    dt=np.load(dt_path)\n",
    "    if dt.std()<0.1:\n",
    "#        print(dt_path)\n",
    "        return 1      \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "#train_dtlist,test_dtlist=getTrainTestList(reclist,opt='kfold',fold=1)#fold 1-10\n",
    "#print('*********')\n",
    "#print(len(train_dtlist),len(test_dtlist))\n",
    "#train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "#np.random.shuffle(train_dtlist)\n",
    "#test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "\n",
    "#print(len(train_dtlist),len(test_dtlist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "ApneaECGDict={'N':0,\n",
    "              'A':1}\n",
    "class ApneaECGDataset(Dataset):\n",
    "    def __init__(self, filelist, istrain=False):\n",
    "        # Get the filelist and img data\n",
    "        self.filelist = filelist\n",
    "        self.istrain = istrain\n",
    "        \n",
    "    def getFeature(self, dt):\n",
    "#         dt=dt.reshape(-1,100)\n",
    "#         if self.istrain:\n",
    "#             shift=np.random.randint(0,5)\n",
    "#             shift=0\n",
    "#         else:\n",
    "#             shift=0\n",
    "#         dt=dt[:,shift::]\n",
    "#         dt_flag=dt[:,20::]*dt[:,0:-20]\n",
    "#         pd_dt=pd.DataFrame(dt)\n",
    "#         pd_dt_flag=pd.DataFrame(dt_flag)\n",
    "#scipy.signal.stft(x,fs=1.0,window='hann',nperseg=256,noverlap=None,nfft=None,detrend=False,return_onesided=True,boundary='zeros',padded=True,axis=-1)\n",
    "        dt=cheb_bandpass_filter(dt, 0.01, 48, 100, 4)\n",
    "    \n",
    "    \n",
    "        f, t, Sxx=signal.spectrogram(dt, fs=100.0, window=('hamming'), nperseg=128, noverlap=64, nfft=128, detrend='constant',\n",
    "        return_onesided=True, scaling='density', axis=-1, mode='psd')\n",
    "        return Sxx[0:33]\n",
    "        \n",
    "#         return np.concatenate((dt_flag.max(axis=1,keepdims=True),\n",
    "#                                dt_flag.min(axis=1,keepdims=True),\n",
    "#                                dt_flag.std(axis=1,keepdims=True),\n",
    "#                                dt.std(axis=1,keepdims=True),\n",
    "#             abs(dt).sum(axis=1,keepdims=True)/100,\n",
    "#             abs(dt_flag).sum(axis=1,keepdims=True)/100,\n",
    "#             (dt.argmax(axis=1)-dt.argmax(axis=1)[0])[:,np.newaxis]/100,\n",
    "#             (dt.argmin(axis=1)-dt.argmin(axis=1)[0])[:,np.newaxis]/100,\n",
    "#             (dt_flag.argmin(axis=1)-dt_flag.argmin(axis=1)[0])[:,np.newaxis]/100,\n",
    "#             (dt_flag.argmax(axis=1)-dt_flag.argmax(axis=1)[0])[:,np.newaxis]/100,\n",
    "#                                dt.mean(axis=1,keepdims=True),#\n",
    "#                                dt.min(axis=1,keepdims=True),\n",
    "#                                dt.max(axis=1,keepdims=True),\n",
    "#                                #pd_dt.skew(axis=1).values[:,np.newaxis],\n",
    "#                                #pd_dt.kurt(axis=1).values[:,np.newaxis],\n",
    "#                                #pd_dt_flag.skew(axis=1).values[:,np.newaxis],\n",
    "#                                #pd_dt_flag.kurt(axis=1).values[:,np.newaxis]\n",
    "#                                ),axis=1)\n",
    "    def __getitem__(self, index):\n",
    "        # return to the data of a Picture\n",
    "        dt_path = self.filelist[index]\n",
    "        label = ApneaECGDict.__getitem__(dt_path.split('_')[0][-1])\n",
    "        data = np.load(dt_path)\n",
    "        seg_id= dt_path.split('_')[1]+'_'+ dt_path.split('_')[-1].split('.')[0]\n",
    "\n",
    "        if self.istrain:\n",
    "            noise = np.random.normal(0, 0.1, data.shape[0])\n",
    "            data = noise+data\n",
    "        data=self.getFeature(data)\n",
    "        return data, label,seg_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "class conv3x3(nn.Module):#ACNet\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, \n",
    "                 padding=1, dilation=1, groups=1, padding_mode='zeros', bias=False, deploy=False):\n",
    "        super(conv3x3, self).__init__()\n",
    "        self.deploy=deploy\n",
    "        if self.deploy:\n",
    "            self.fused_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(kernel_size,kernel_size), stride=stride,\n",
    "                                      padding=padding, dilation=dilation, groups=groups, bias=False, padding_mode=padding_mode)\n",
    "# c=a.square_conv.weight.data.numpy().copy()\n",
    "# c[:,:,1:2,:]=a.square_conv.weight.data[:,:,1:2,:,].numpy().copy()+a.hor_conv.weight.data[:,:,0:1,:,].numpy().copy()\n",
    "# c[:,:,:,1:2]+=a.ver_conv.weight.data[:,:,:,0:1].numpy().copy()\n",
    "# c-a.square_conv.weight.data.numpy()\n",
    "# b.fused_conv.weight.data=torch.FloatTensor(c)    \n",
    "        else:\n",
    "            self.square_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=(kernel_size, kernel_size), stride=stride,\n",
    "                                         padding=padding, dilation=dilation, groups=groups, bias=False,\n",
    "                                         padding_mode=padding_mode)\n",
    "\n",
    "            center_offset_from_origin_border = padding - kernel_size // 2 #1-3//2=0\n",
    "            ver_pad_or_crop = (center_offset_from_origin_border + 1, center_offset_from_origin_border)\n",
    "            hor_pad_or_crop = (center_offset_from_origin_border, center_offset_from_origin_border + 1)\n",
    "            if center_offset_from_origin_border >= 0:\n",
    "                self.ver_conv_crop_layer = nn.Identity()\n",
    "                ver_conv_padding = ver_pad_or_crop\n",
    "                self.hor_conv_crop_layer = nn.Identity()\n",
    "                hor_conv_padding = hor_pad_or_crop\n",
    "\n",
    "            self.ver_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 1),\n",
    "                                      stride=stride,\n",
    "                                      padding=ver_conv_padding, dilation=dilation, groups=groups, bias=False,\n",
    "                                      padding_mode=padding_mode)\n",
    "\n",
    "            self.hor_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1, 3),\n",
    "                                      stride=stride,\n",
    "                                      padding=hor_conv_padding, dilation=dilation, groups=groups, bias=False,\n",
    "                                      padding_mode=padding_mode)\n",
    "\n",
    "    # forward函数\n",
    "    def forward(self, input):\n",
    "        if self.deploy:\n",
    "            #assert self.square_conv\n",
    "            print(\"True\")\n",
    "            return self.fused_conv(input)\n",
    "        square_outputs = self.square_conv(input)\n",
    "        # print(square_outputs.size())\n",
    "        # return square_outputs\n",
    "        vertical_outputs = self.ver_conv(input)\n",
    "        # print(vertical_outputs.size())\n",
    "        #horizontal_outputs = self.hor_conv_crop_layer(input)\n",
    "        horizontal_outputs = self.hor_conv(input)\n",
    "        # print(horizontal_outputs.size())\n",
    "        return square_outputs + vertical_outputs + horizontal_outputs\n",
    "    \n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, class_num,fs):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        #self.bn=nn.BatchNorm1d(60)\n",
    "#         self.conv10=nn.Sequential(nn.Conv1d(1,64,kernel_size=10,stride=10,padding=0, bias=False),\n",
    "#                   nn.Conv1d(64,32,kernel_size=3,stride=2,padding=0, bias=False),\n",
    "#                   nn.MaxPool1d(kernel_size=3,stride=2),\n",
    "#                   nn.Conv1d(32,32,kernel_size=3,stride=2,padding=0, bias=False),\n",
    "#                   nn.MaxPool1d(kernel_size=3,stride=2),\n",
    "#                                nn.ReLU())1200\n",
    "#25 * 65\n",
    "#12* 32\n",
    "#b*64*6*16\n",
    "#b*6*64*16\n",
    "        self.branch1=nn.Sequential(nn.Conv2d(1,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                nn.Conv2d(fs,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                #nn.Conv2d(32,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(3,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                #nn.ReLU(),                               \n",
    "                                nn.LayerNorm([fs,33,92],elementwise_affine=False),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Dropout(p=0.25),\n",
    "                                #nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                #nn.Dropout(p=0.25),\n",
    "                                \n",
    "#                                 nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Dropout(p=0.25),\n",
    "                                nn.LayerNorm([fs,16,46],elementwise_affine=False),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Dropout(p=0.5),\n",
    "                                nn.Conv2d(fs,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(5,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                                          \n",
    "                                nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                #nn.Dropout(p=0.5),\n",
    "                                nn.LayerNorm([fs,8,23],elementwise_affine=False),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.5),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(1,3),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                nn.Conv2d(fs,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False))\n",
    "        \n",
    "#         self.branch2=nn.Sequential(nn.Conv2d(1,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False),\n",
    "#                                 nn.Conv2d(32,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False),\n",
    "#                                 #nn.Conv2d(32,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=(3,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "#                                 #nn.ReLU(),                               \n",
    "#                                 nn.LayerNorm([32,25,92]),\n",
    "#                                 nn.ReLU(), \n",
    "#                                 nn.Dropout(p=0.25),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "#                                 nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#                                 #nn.Dropout(p=0.25),\n",
    "                                \n",
    "# #                                 nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "# #                                 nn.ReLU(),\n",
    "# #                                 nn.Dropout(p=0.25),\n",
    "#                                 nn.LayerNorm([32,12,46]),\n",
    "#                                 nn.ReLU(), \n",
    "#                                 nn.Dropout(p=0.25),\n",
    "#                                 nn.Conv2d(32,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=(5,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                                          \n",
    "#                                 nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#                                 #nn.Dropout(p=0.5),\n",
    "#                                 nn.LayerNorm([32,6,23]),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Dropout(p=0.5),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=(1,3),dilation=1,stride=1,padding=0, bias=False),\n",
    "#                                 nn.Conv2d(32,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False))\n",
    "        \n",
    "        self.avg = nn.Sequential(nn.AdaptiveMaxPool2d((8,8)),nn.LayerNorm([8,8,8],elementwise_affine=False))\n",
    "    \n",
    "        self.lstm = nn.LSTM(64, 8, 2,\n",
    "                            bias=False,\n",
    "                            batch_first=True,\n",
    "                            dropout=0.5,\n",
    "                            bidirectional=True)\n",
    "        #self.conv2=nn.Sequential(nn.Conv1d(64,64,kernel_size=1,stride=1,padding=0, bias=False))\n",
    "        \n",
    "        self.fc=nn.Sequential(nn.Linear(16*2,class_num))\n",
    "    def attention_net(self,lstm_output, final_state):\n",
    "        hidden = final_state.view(-1, 16, 2)   # hidden : [batch_size, n_hidden * num_directions(=2), 1(=n_layer)]\n",
    "        #print('hi',hidden.shape)\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2) # attn_weights : [batch_size, n_step]\n",
    "        #print('att',attn_weights.shape)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        #print('sft',soft_attn_weights.shape)\n",
    "        #print('yimr',torch.bmm(lstm_output.transpose(1, 2),soft_attn_weights).shape)\n",
    "        # [batch_size, n_hidden * num_directions(=2), n_step] * [batch_size, n_step, 1] = [batch_size, n_hidden * num_directions(=2), 1]\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights)\n",
    "        return context#, soft_attn_weights.data.numpy() # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "    def forward(self, x):\n",
    "        x=x.unsqueeze(dim=1)#x.reshape(x.shape[0],1,-1)\n",
    "        #x1=self.conv10(x)\n",
    "        out=self.branch1(x)\n",
    "        #out_1=self.branch1(x)\n",
    "        #out_2=self.branch2(x)\n",
    "        #out=torch.cat((out_1,out_2),1)\n",
    "        #print(out.shape)\n",
    "        out=out.permute(0,2,1,3)\n",
    "        out=self.avg(out)\n",
    "        #print(out.shape)\n",
    "        out=out.view(out.shape[0],out.shape[1],-1)\n",
    "        #print(x2.shape)\n",
    "        #print(x1.shape,x2.shape)\n",
    "        #x=torch.cat((x1,x2),dim=1)\n",
    "        #print(x.shape)\n",
    "        out,(h,c) = self.lstm(out)\n",
    "        out=self.attention_net(out, h)\n",
    "        \n",
    "        #out = self.conv2(out)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out.reshape(out.shape[0],-1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,test_dtlist,criterion,my_device):\n",
    "    test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "    test_loader=DataLoader(test_dataset, batch_size=128, shuffle=False, sampler=None, num_workers=0)\n",
    "    #train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "        #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "    #train_loader=DataLoader(train_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "    sft=nn.Softmax().to(my_device)\n",
    "    all_pred_prob=torch.Tensor([]).to(my_device)\n",
    "    all_label=torch.Tensor([]).long().to(my_device)\n",
    "    all_seg=[]#torch.Tensor([]).to(my_device)\n",
    "    flag=0\n",
    "    with torch.no_grad():\n",
    "        for fe, label,seg_id in test_loader:\n",
    "            fe=fe.float().to(my_device)\n",
    "            #fe=(fe-fe_mean)/fe_std\n",
    "            label=label.long().to(my_device)\n",
    "            pred_prob_no_softmax=model(fe)\n",
    "            all_pred_prob=torch.cat((all_pred_prob,pred_prob_no_softmax),0)\n",
    "            all_label=torch.cat((all_label,label),0)\n",
    "            all_seg+=list(seg_id)\n",
    "            loss=criterion(pred_prob_no_softmax,label)\n",
    "            flag+=1\n",
    "            if flag%8==0:\n",
    "                print('Eval Loss: ',loss.item())\n",
    "            #pos=(sft(pred_prob_no_softmax)[:,1]>0.5)\n",
    "            #print(\"Acc: \", sum(label==pos).detach().numpy()/len(label))\n",
    "    all_pred=sft(all_pred_prob)[:,1].detach().cpu().numpy()\n",
    "    all_pred[all_pred>0.5]=1\n",
    "    all_pred[all_pred<=0.5]=0\n",
    "    all_label=all_label.detach().cpu().numpy()\n",
    "    #all_seg=all_seg.detach().cpu().numpy()\n",
    "    print(confusion_matrix(all_label,all_pred))\n",
    "    print(classification_report(all_label,all_pred))\n",
    "    print(\"acc: \",accuracy_score(all_label,all_pred))\n",
    "    print(\"pre: \",precision_score(all_label,all_pred))\n",
    "    print(\"rec: \",recall_score(all_label,all_pred))\n",
    "    print(\"ma F1: \",f1_score(all_label,all_pred, average='macro'))\n",
    "    print(\"mi F1: \",f1_score(all_label,all_pred, average='micro'))\n",
    "    print(\"we F1: \",f1_score(all_label,all_pred, average='weighted'))\n",
    "    return sft(all_pred_prob)[:,1].detach().cpu().numpy(),all_label, accuracy_score(all_label,all_pred),all_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "kernel: 128\n",
      "  \n",
      "*********\n",
      "29459 3432\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29459 461\n",
      "Loss:  0.16695697605609894\n",
      "Loss:  0.15468408167362213\n",
      "Loss:  0.16555966436862946\n",
      "0 **********\n",
      "Epoch:  94.62798309326172  fold:  1  kers:  128\n",
      "epoch:  1\n",
      "29459 461\n",
      "Loss:  0.13676390051841736\n",
      "Loss:  0.14410196244716644\n",
      "Loss:  0.1303989440202713\n",
      "1 **********\n",
      "Epoch:  174.63306546211243  fold:  1  kers:  128\n",
      "epoch:  2\n",
      "29459 461\n",
      "Loss:  0.101091168820858\n",
      "Loss:  0.12051957100629807\n",
      "Loss:  0.111448273062706\n",
      "2 **********\n",
      "Epoch:  254.8226547241211  fold:  1  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.39044952392578125\n",
      "Eval Loss:  0.5204998254776001\n",
      "Eval Loss:  0.2667495608329773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\install\\envs\\pytorch-gpu\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\anaconda\\install\\envs\\pytorch-gpu\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 837  202]\n",
      " [ 729 1664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.81      0.64      1039\n",
      "           1       0.89      0.70      0.78      2393\n",
      "\n",
      "    accuracy                           0.73      3432\n",
      "   macro avg       0.71      0.75      0.71      3432\n",
      "weighted avg       0.78      0.73      0.74      3432\n",
      "\n",
      "acc:  0.7287296037296037\n",
      "pre:  0.8917470525187567\n",
      "rec:  0.6953614709569578\n",
      "ma F1:  0.7120072250746866\n",
      "mi F1:  0.7287296037296037\n",
      "we F1:  0.7393858232593998\n",
      "update!  Acc:  0.7287296037296037\n",
      "Eval Loss:  0.4191402196884155\n",
      "Eval Loss:  0.5082312226295471\n",
      "Eval Loss:  0.45856478810310364\n",
      "Eval Loss:  0.4532674252986908\n",
      "Eval Loss:  0.4250549376010895\n",
      "Eval Loss:  0.5099753737449646\n",
      "Eval Loss:  0.4253731071949005\n",
      "Eval Loss:  0.42819058895111084\n",
      "Eval Loss:  0.43962523341178894\n",
      "Eval Loss:  0.4229838252067566\n",
      "Eval Loss:  0.3359450399875641\n",
      "Eval Loss:  0.4938490092754364\n",
      "Eval Loss:  0.39705759286880493\n",
      "Eval Loss:  0.4151306748390198\n",
      "Eval Loss:  0.42562153935432434\n",
      "Eval Loss:  0.5321543216705322\n",
      "Eval Loss:  0.4354346692562103\n",
      "Eval Loss:  0.5073819756507874\n",
      "Eval Loss:  0.4297877848148346\n",
      "Eval Loss:  0.4530114531517029\n",
      "Eval Loss:  0.36938509345054626\n",
      "Eval Loss:  0.4678512215614319\n",
      "Eval Loss:  0.40086448192596436\n",
      "Eval Loss:  0.46616026759147644\n",
      "Eval Loss:  0.3743613660335541\n",
      "Eval Loss:  0.4163840115070343\n",
      "Eval Loss:  0.4159209728240967\n",
      "Eval Loss:  0.4989100992679596\n",
      "[[16847  2278]\n",
      " [ 3324  7010]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86     19125\n",
      "           1       0.75      0.68      0.71     10334\n",
      "\n",
      "    accuracy                           0.81     29459\n",
      "   macro avg       0.79      0.78      0.79     29459\n",
      "weighted avg       0.81      0.81      0.81     29459\n",
      "\n",
      "acc:  0.8098374011337791\n",
      "pre:  0.7547372954349698\n",
      "rec:  0.6783433326882137\n",
      "ma F1:  0.7859725444658109\n",
      "mi F1:  0.8098374011337791\n",
      "we F1:  0.8072997738007817\n",
      "29459 461\n",
      "Loss:  0.10659179091453552\n",
      "Loss:  0.08856333792209625\n",
      "Loss:  0.09772185981273651\n",
      "3 **********\n",
      "Epoch:  382.636905670166  fold:  1  kers:  128\n",
      "epoch:  4\n",
      "29459 461\n",
      "Loss:  0.08930333703756332\n",
      "Loss:  0.0641878992319107\n",
      "Loss:  0.11005902290344238\n",
      "4 **********\n",
      "Epoch:  463.1336741447449  fold:  1  kers:  128\n",
      "epoch:  5\n",
      "29459 461\n",
      "Loss:  0.08227374404668808\n",
      "Loss:  0.09763533622026443\n",
      "Loss:  0.08213357627391815\n",
      "5 **********\n",
      "Epoch:  543.6274497509003  fold:  1  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.5431322455406189\n",
      "Eval Loss:  0.6071563363075256\n",
      "Eval Loss:  0.12438469380140305\n",
      "[[ 910  129]\n",
      " [ 830 1563]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.88      0.65      1039\n",
      "           1       0.92      0.65      0.77      2393\n",
      "\n",
      "    accuracy                           0.72      3432\n",
      "   macro avg       0.72      0.76      0.71      3432\n",
      "weighted avg       0.80      0.72      0.73      3432\n",
      "\n",
      "acc:  0.7205710955710956\n",
      "pre:  0.9237588652482269\n",
      "rec:  0.6531550355202674\n",
      "ma F1:  0.7100752584407537\n",
      "mi F1:  0.7205710955710954\n",
      "we F1:  0.7318384490601764\n",
      "Eval Loss:  0.40584036707878113\n",
      "Eval Loss:  0.5041338801383972\n",
      "Eval Loss:  0.5760212540626526\n",
      "Eval Loss:  0.5796449780464172\n",
      "Eval Loss:  0.40689051151275635\n",
      "Eval Loss:  0.5226277112960815\n",
      "Eval Loss:  0.48712867498397827\n",
      "Eval Loss:  0.396886944770813\n",
      "Eval Loss:  0.3777771592140198\n",
      "Eval Loss:  0.4127815365791321\n",
      "Eval Loss:  0.2886582612991333\n",
      "Eval Loss:  0.46708783507347107\n",
      "Eval Loss:  0.4095112085342407\n",
      "Eval Loss:  0.436357319355011\n",
      "Eval Loss:  0.46286237239837646\n",
      "Eval Loss:  0.652269721031189\n",
      "Eval Loss:  0.4950725734233856\n",
      "Eval Loss:  0.6000419855117798\n",
      "Eval Loss:  0.49938809871673584\n",
      "Eval Loss:  0.4477391839027405\n",
      "Eval Loss:  0.366250216960907\n",
      "Eval Loss:  0.4430120587348938\n",
      "Eval Loss:  0.3948599398136139\n",
      "Eval Loss:  0.5391984581947327\n",
      "Eval Loss:  0.4440178871154785\n",
      "Eval Loss:  0.495811402797699\n",
      "Eval Loss:  0.3898075819015503\n",
      "Eval Loss:  0.5305216312408447\n",
      "[[18400   725]\n",
      " [ 4009  6325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89     19125\n",
      "           1       0.90      0.61      0.73     10334\n",
      "\n",
      "    accuracy                           0.84     29459\n",
      "   macro avg       0.86      0.79      0.81     29459\n",
      "weighted avg       0.85      0.84      0.83     29459\n",
      "\n",
      "acc:  0.8393020808581418\n",
      "pre:  0.8971631205673759\n",
      "rec:  0.6120572866266693\n",
      "ma F1:  0.8068508585085488\n",
      "mi F1:  0.8393020808581418\n",
      "we F1:  0.8304764233677846\n",
      "29459 461\n",
      "Loss:  0.07394107431173325\n",
      "Loss:  0.0893343910574913\n",
      "Loss:  0.10908576101064682\n",
      "6 **********\n",
      "Epoch:  671.2721538543701  fold:  1  kers:  128\n",
      "epoch:  7\n",
      "29459 461\n",
      "Loss:  0.06249793618917465\n",
      "Loss:  0.06816654652357101\n",
      "Loss:  0.09063200652599335\n",
      "7 **********\n",
      "Epoch:  751.7739086151123  fold:  1  kers:  128\n",
      "epoch:  8\n",
      "29459 461\n",
      "Loss:  0.08864030987024307\n",
      "Loss:  0.09310699999332428\n",
      "Loss:  0.12689127027988434\n",
      "8 **********\n",
      "Epoch:  832.4920845031738  fold:  1  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.7568989992141724\n",
      "Eval Loss:  0.35204654932022095\n",
      "Eval Loss:  0.06796953082084656\n",
      "[[ 860  179]\n",
      " [ 594 1799]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69      1039\n",
      "           1       0.91      0.75      0.82      2393\n",
      "\n",
      "    accuracy                           0.77      3432\n",
      "   macro avg       0.75      0.79      0.76      3432\n",
      "weighted avg       0.81      0.77      0.78      3432\n",
      "\n",
      "acc:  0.7747668997668997\n",
      "pre:  0.9095045500505561\n",
      "rec:  0.751776013372336\n",
      "ma F1:  0.7565422028625932\n",
      "mi F1:  0.7747668997668997\n",
      "we F1:  0.7828214782709331\n",
      "update!  Acc:  0.7747668997668997\n",
      "Eval Loss:  0.2410120815038681\n",
      "Eval Loss:  0.3722493648529053\n",
      "Eval Loss:  0.48254603147506714\n",
      "Eval Loss:  0.4094318747520447\n",
      "Eval Loss:  0.2947528064250946\n",
      "Eval Loss:  0.37501096725463867\n",
      "Eval Loss:  0.362516313791275\n",
      "Eval Loss:  0.23314210772514343\n",
      "Eval Loss:  0.30296599864959717\n",
      "Eval Loss:  0.27922067046165466\n",
      "Eval Loss:  0.24145106971263885\n",
      "Eval Loss:  0.35525450110435486\n",
      "Eval Loss:  0.33582764863967896\n",
      "Eval Loss:  0.3372509181499481\n",
      "Eval Loss:  0.3181144595146179\n",
      "Eval Loss:  0.4923970699310303\n",
      "Eval Loss:  0.36367684602737427\n",
      "Eval Loss:  0.4531697630882263\n",
      "Eval Loss:  0.38267266750335693\n",
      "Eval Loss:  0.34113115072250366\n",
      "Eval Loss:  0.28301048278808594\n",
      "Eval Loss:  0.2824004292488098\n",
      "Eval Loss:  0.27657198905944824\n",
      "Eval Loss:  0.3968159556388855\n",
      "Eval Loss:  0.3208814859390259\n",
      "Eval Loss:  0.3695562779903412\n",
      "Eval Loss:  0.3360479176044464\n",
      "Eval Loss:  0.3378654420375824\n",
      "[[18368   757]\n",
      " [ 2836  7498]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     19125\n",
      "           1       0.91      0.73      0.81     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.89      0.84      0.86     29459\n",
      "weighted avg       0.88      0.88      0.87     29459\n",
      "\n",
      "acc:  0.8780338775925863\n",
      "pre:  0.908298001211387\n",
      "rec:  0.7255660925101607\n",
      "ma F1:  0.8588107156685645\n",
      "mi F1:  0.8780338775925863\n",
      "we F1:  0.8743572489228492\n",
      "29459 461\n",
      "Loss:  0.06826933473348618\n",
      "Loss:  0.05350344255566597\n",
      "Loss:  0.09811029583215714\n",
      "9 **********\n",
      "Epoch:  960.2115881443024  fold:  1  kers:  128\n",
      "epoch:  10\n",
      "29459 461\n",
      "Loss:  0.09245871752500534\n",
      "Loss:  0.057377900928258896\n",
      "Loss:  0.09862640500068665\n",
      "10 **********\n",
      "Epoch:  1040.72132229805  fold:  1  kers:  128\n",
      "epoch:  11\n",
      "29459 461\n",
      "Loss:  0.05162007734179497\n",
      "Loss:  0.08238409459590912\n",
      "Loss:  0.07841996848583221\n",
      "11 **********\n",
      "Epoch:  1121.2719461917877  fold:  1  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  1.2532204389572144\n",
      "Eval Loss:  0.3543799817562103\n",
      "Eval Loss:  0.06400705873966217\n",
      "[[ 804  235]\n",
      " [ 502 1891]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69      1039\n",
      "           1       0.89      0.79      0.84      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.75      0.78      0.76      3432\n",
      "weighted avg       0.81      0.79      0.79      3432\n",
      "\n",
      "acc:  0.7852564102564102\n",
      "pre:  0.8894637817497648\n",
      "rec:  0.7902214793146678\n",
      "ma F1:  0.7613125533461891\n",
      "mi F1:  0.7852564102564104\n",
      "we F1:  0.7911377440144867\n",
      "update!  Acc:  0.7852564102564102\n",
      "Eval Loss:  0.201814204454422\n",
      "Eval Loss:  0.3267143964767456\n",
      "Eval Loss:  0.3864310085773468\n",
      "Eval Loss:  0.3534916937351227\n",
      "Eval Loss:  0.24847763776779175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3123178482055664\n",
      "Eval Loss:  0.31950345635414124\n",
      "Eval Loss:  0.1718054860830307\n",
      "Eval Loss:  0.2616827189922333\n",
      "Eval Loss:  0.22366821765899658\n",
      "Eval Loss:  0.19180674850940704\n",
      "Eval Loss:  0.2906320095062256\n",
      "Eval Loss:  0.25991204380989075\n",
      "Eval Loss:  0.31927013397216797\n",
      "Eval Loss:  0.2897278368473053\n",
      "Eval Loss:  0.4010683596134186\n",
      "Eval Loss:  0.3044309914112091\n",
      "Eval Loss:  0.3558274805545807\n",
      "Eval Loss:  0.3352116346359253\n",
      "Eval Loss:  0.29819566011428833\n",
      "Eval Loss:  0.20398467779159546\n",
      "Eval Loss:  0.22943802177906036\n",
      "Eval Loss:  0.23539960384368896\n",
      "Eval Loss:  0.3361679017543793\n",
      "Eval Loss:  0.2723080813884735\n",
      "Eval Loss:  0.3486614525318146\n",
      "Eval Loss:  0.30661576986312866\n",
      "Eval Loss:  0.27592578530311584\n",
      "[[18341   784]\n",
      " [ 2388  7946]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     19125\n",
      "           1       0.91      0.77      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.90      0.86      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8923249261685733\n",
      "pre:  0.9101947308132875\n",
      "rec:  0.7689181343139152\n",
      "ma F1:  0.877011293697868\n",
      "mi F1:  0.8923249261685733\n",
      "we F1:  0.8899619568099382\n",
      "29459 461\n",
      "Loss:  0.07690339535474777\n",
      "Loss:  0.09714245796203613\n",
      "Loss:  0.08475124835968018\n",
      "12 **********\n",
      "Epoch:  1249.0273542404175  fold:  1  kers:  128\n",
      "epoch:  13\n",
      "29459 461\n",
      "Loss:  0.06349509954452515\n",
      "Loss:  0.09563933312892914\n",
      "Loss:  0.11596181243658066\n",
      "13 **********\n",
      "Epoch:  1329.5530445575714  fold:  1  kers:  128\n",
      "epoch:  14\n",
      "29459 461\n",
      "Loss:  0.07200096547603607\n",
      "Loss:  0.05889593064785004\n",
      "Loss:  0.08534315228462219\n",
      "14 **********\n",
      "Epoch:  1410.0767407417297  fold:  1  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.8493276238441467\n",
      "Eval Loss:  0.31039202213287354\n",
      "Eval Loss:  0.05854729562997818\n",
      "[[ 767  272]\n",
      " [ 413 1980]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69      1039\n",
      "           1       0.88      0.83      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.78      0.77      3432\n",
      "weighted avg       0.81      0.80      0.80      3432\n",
      "\n",
      "acc:  0.8004079254079254\n",
      "pre:  0.8792184724689165\n",
      "rec:  0.8274132887588801\n",
      "ma F1:  0.771915995092777\n",
      "mi F1:  0.8004079254079254\n",
      "we F1:  0.8037198480579139\n",
      "update!  Acc:  0.8004079254079254\n",
      "Eval Loss:  0.1530206799507141\n",
      "Eval Loss:  0.31049707531929016\n",
      "Eval Loss:  0.37466171383857727\n",
      "Eval Loss:  0.35520291328430176\n",
      "Eval Loss:  0.2229575663805008\n",
      "Eval Loss:  0.29747334122657776\n",
      "Eval Loss:  0.33704280853271484\n",
      "Eval Loss:  0.1812305450439453\n",
      "Eval Loss:  0.2624170780181885\n",
      "Eval Loss:  0.21273934841156006\n",
      "Eval Loss:  0.17687276005744934\n",
      "Eval Loss:  0.29983431100845337\n",
      "Eval Loss:  0.2612760066986084\n",
      "Eval Loss:  0.34831348061561584\n",
      "Eval Loss:  0.25275346636772156\n",
      "Eval Loss:  0.37681281566619873\n",
      "Eval Loss:  0.34872961044311523\n",
      "Eval Loss:  0.3703765571117401\n",
      "Eval Loss:  0.3498656749725342\n",
      "Eval Loss:  0.28152915835380554\n",
      "Eval Loss:  0.2108699381351471\n",
      "Eval Loss:  0.20144815742969513\n",
      "Eval Loss:  0.21600089967250824\n",
      "Eval Loss:  0.30806881189346313\n",
      "Eval Loss:  0.2651478052139282\n",
      "Eval Loss:  0.35686179995536804\n",
      "Eval Loss:  0.2748362123966217\n",
      "Eval Loss:  0.25576308369636536\n",
      "[[18378   747]\n",
      " [ 2244  8090]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     19125\n",
      "           1       0.92      0.78      0.84     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.87      0.88     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.8984690586917411\n",
      "pre:  0.9154690505827769\n",
      "rec:  0.7828527191794078\n",
      "ma F1:  0.8843660685681912\n",
      "mi F1:  0.8984690586917411\n",
      "we F1:  0.8964169420301008\n",
      "29459 461\n",
      "Loss:  0.04539921507239342\n",
      "Loss:  0.07401058077812195\n",
      "Loss:  0.061358384788036346\n",
      "15 **********\n",
      "Epoch:  1537.8341431617737  fold:  1  kers:  128\n",
      "epoch:  16\n",
      "29459 461\n",
      "Loss:  0.039527591317892075\n",
      "Loss:  0.08738484233617783\n",
      "Loss:  0.05380372703075409\n",
      "16 **********\n",
      "Epoch:  1618.6570391654968  fold:  1  kers:  128\n",
      "epoch:  17\n",
      "29459 461\n",
      "Loss:  0.05444643273949623\n",
      "Loss:  0.06793276220560074\n",
      "Loss:  0.05257903039455414\n",
      "17 **********\n",
      "Epoch:  1699.2186336517334  fold:  1  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.6801100969314575\n",
      "Eval Loss:  0.3410545289516449\n",
      "Eval Loss:  0.04292697831988335\n",
      "[[ 806  233]\n",
      " [ 466 1927]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.70      1039\n",
      "           1       0.89      0.81      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.79      0.77      3432\n",
      "weighted avg       0.81      0.80      0.80      3432\n",
      "\n",
      "acc:  0.7963286713286714\n",
      "pre:  0.8921296296296296\n",
      "rec:  0.8052653572921019\n",
      "ma F1:  0.7720041935061099\n",
      "mi F1:  0.7963286713286712\n",
      "we F1:  0.8013845172989271\n",
      "Eval Loss:  0.13734018802642822\n",
      "Eval Loss:  0.29046139121055603\n",
      "Eval Loss:  0.3471440374851227\n",
      "Eval Loss:  0.3155335783958435\n",
      "Eval Loss:  0.2250172644853592\n",
      "Eval Loss:  0.2951992154121399\n",
      "Eval Loss:  0.3143702447414398\n",
      "Eval Loss:  0.18301190435886383\n",
      "Eval Loss:  0.24461574852466583\n",
      "Eval Loss:  0.1804397851228714\n",
      "Eval Loss:  0.15341921150684357\n",
      "Eval Loss:  0.2410060465335846\n",
      "Eval Loss:  0.26231032609939575\n",
      "Eval Loss:  0.3093937039375305\n",
      "Eval Loss:  0.24737800657749176\n",
      "Eval Loss:  0.35561132431030273\n",
      "Eval Loss:  0.3047606348991394\n",
      "Eval Loss:  0.318317711353302\n",
      "Eval Loss:  0.30732253193855286\n",
      "Eval Loss:  0.2635996639728546\n",
      "Eval Loss:  0.1915237456560135\n",
      "Eval Loss:  0.16959168016910553\n",
      "Eval Loss:  0.17926570773124695\n",
      "Eval Loss:  0.28996574878692627\n",
      "Eval Loss:  0.2418111115694046\n",
      "Eval Loss:  0.3301554024219513\n",
      "Eval Loss:  0.2719721794128418\n",
      "Eval Loss:  0.22785651683807373\n",
      "[[18378   747]\n",
      " [ 2045  8289]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     19125\n",
      "           1       0.92      0.80      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.88      0.89     29459\n",
      "weighted avg       0.91      0.91      0.90     29459\n",
      "\n",
      "acc:  0.9052242099188703\n",
      "pre:  0.9173306772908366\n",
      "rec:  0.8021095413199149\n",
      "ma F1:  0.8926309110188286\n",
      "mi F1:  0.9052242099188703\n",
      "we F1:  0.9036040194171105\n",
      "29459 461\n",
      "Loss:  0.044116564095020294\n",
      "Loss:  0.040273647755384445\n",
      "Loss:  0.035800594836473465\n",
      "18 **********\n",
      "Epoch:  1826.9650654792786  fold:  1  kers:  128\n",
      "epoch:  19\n",
      "29459 461\n",
      "Loss:  0.0722888857126236\n",
      "Loss:  0.05121216922998428\n",
      "Loss:  0.0669323280453682\n",
      "19 **********\n",
      "Epoch:  1907.5176846981049  fold:  1  kers:  128\n",
      "epoch:  20\n",
      "29459 461\n",
      "Loss:  0.05168624967336655\n",
      "Loss:  0.07652191817760468\n",
      "Loss:  0.049132950603961945\n",
      "20 **********\n",
      "Epoch:  1988.1351296901703  fold:  1  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.6123719215393066\n",
      "Eval Loss:  0.4036562442779541\n",
      "Eval Loss:  0.14048461616039276\n",
      "[[ 818  221]\n",
      " [ 493 1900]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.70      1039\n",
      "           1       0.90      0.79      0.84      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.76      0.79      0.77      3432\n",
      "weighted avg       0.81      0.79      0.80      3432\n",
      "\n",
      "acc:  0.791958041958042\n",
      "pre:  0.8958038661008958\n",
      "rec:  0.7939824488090264\n",
      "ma F1:  0.7689978223776619\n",
      "mi F1:  0.791958041958042\n",
      "we F1:  0.7977299271020931\n",
      "Eval Loss:  0.15351204574108124\n",
      "Eval Loss:  0.3108116388320923\n",
      "Eval Loss:  0.35803118348121643\n",
      "Eval Loss:  0.36596086621284485\n",
      "Eval Loss:  0.2321455478668213\n",
      "Eval Loss:  0.2647058367729187\n",
      "Eval Loss:  0.3366350829601288\n",
      "Eval Loss:  0.17611365020275116\n",
      "Eval Loss:  0.25442516803741455\n",
      "Eval Loss:  0.19156748056411743\n",
      "Eval Loss:  0.14731399714946747\n",
      "Eval Loss:  0.22766350209712982\n",
      "Eval Loss:  0.25400441884994507\n",
      "Eval Loss:  0.35103467106819153\n",
      "Eval Loss:  0.26012033224105835\n",
      "Eval Loss:  0.3317946493625641\n",
      "Eval Loss:  0.32599836587905884\n",
      "Eval Loss:  0.3238007724285126\n",
      "Eval Loss:  0.3307943046092987\n",
      "Eval Loss:  0.28401827812194824\n",
      "Eval Loss:  0.17836308479309082\n",
      "Eval Loss:  0.1872246414422989\n",
      "Eval Loss:  0.18746140599250793\n",
      "Eval Loss:  0.31592386960983276\n",
      "Eval Loss:  0.2634028494358063\n",
      "Eval Loss:  0.35270658135414124\n",
      "Eval Loss:  0.24890311062335968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24408844113349915\n",
      "[[18504   621]\n",
      " [ 2225  8109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     19125\n",
      "           1       0.93      0.78      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.91      0.88      0.89     29459\n",
      "weighted avg       0.91      0.90      0.90     29459\n",
      "\n",
      "acc:  0.903391153806986\n",
      "pre:  0.9288659793814433\n",
      "rec:  0.7846913102380492\n",
      "ma F1:  0.8896513688096255\n",
      "mi F1:  0.903391153806986\n",
      "we F1:  0.9012710369108083\n",
      "29459 461\n",
      "Loss:  0.07280096411705017\n",
      "Loss:  0.06332357227802277\n",
      "Loss:  0.042421258985996246\n",
      "21 **********\n",
      "Epoch:  2115.9563620090485  fold:  1  kers:  128\n",
      "epoch:  22\n",
      "29459 461\n",
      "Loss:  0.057605259120464325\n",
      "Loss:  0.06232992559671402\n",
      "Loss:  0.0722116157412529\n",
      "22 **********\n",
      "Epoch:  2196.5379028320312  fold:  1  kers:  128\n",
      "epoch:  23\n",
      "29459 461\n",
      "Loss:  0.07494857907295227\n",
      "Loss:  0.06428712606430054\n",
      "Loss:  0.0775349959731102\n",
      "23 **********\n",
      "Epoch:  2277.136399269104  fold:  1  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.9132133722305298\n",
      "Eval Loss:  0.2578028738498688\n",
      "Eval Loss:  0.08551029860973358\n",
      "[[ 742  297]\n",
      " [ 368 2025]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      1039\n",
      "           1       0.87      0.85      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.78      0.77      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8062354312354313\n",
      "pre:  0.872093023255814\n",
      "rec:  0.8462181362306728\n",
      "ma F1:  0.7747572547245087\n",
      "mi F1:  0.8062354312354313\n",
      "we F1:  0.807977403591063\n",
      "update!  Acc:  0.8062354312354313\n",
      "Eval Loss:  0.11192731559276581\n",
      "Eval Loss:  0.2606719434261322\n",
      "Eval Loss:  0.30529704689979553\n",
      "Eval Loss:  0.29328712821006775\n",
      "Eval Loss:  0.20465804636478424\n",
      "Eval Loss:  0.23925863206386566\n",
      "Eval Loss:  0.2980872094631195\n",
      "Eval Loss:  0.16074217855930328\n",
      "Eval Loss:  0.26506277918815613\n",
      "Eval Loss:  0.14320813119411469\n",
      "Eval Loss:  0.10891067981719971\n",
      "Eval Loss:  0.1808498352766037\n",
      "Eval Loss:  0.20047695934772491\n",
      "Eval Loss:  0.2911141812801361\n",
      "Eval Loss:  0.22992002964019775\n",
      "Eval Loss:  0.29246973991394043\n",
      "Eval Loss:  0.26317301392555237\n",
      "Eval Loss:  0.25785014033317566\n",
      "Eval Loss:  0.3141830861568451\n",
      "Eval Loss:  0.24229049682617188\n",
      "Eval Loss:  0.14831572771072388\n",
      "Eval Loss:  0.14656460285186768\n",
      "Eval Loss:  0.14155735075473785\n",
      "Eval Loss:  0.2304891049861908\n",
      "Eval Loss:  0.2352600395679474\n",
      "Eval Loss:  0.31849607825279236\n",
      "Eval Loss:  0.2250063568353653\n",
      "Eval Loss:  0.18807721138000488\n",
      "[[18153   972]\n",
      " [ 1514  8820]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     19125\n",
      "           1       0.90      0.85      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.91      0.90      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9156115278862147\n",
      "pre:  0.9007352941176471\n",
      "rec:  0.8534933230114187\n",
      "ma F1:  0.9061964044953583\n",
      "mi F1:  0.9156115278862147\n",
      "we F1:  0.9150647586932603\n",
      "29459 461\n",
      "Loss:  0.04570547118782997\n",
      "Loss:  0.049332644790410995\n",
      "Loss:  0.029619546607136726\n",
      "24 **********\n",
      "Epoch:  2405.1471242904663  fold:  1  kers:  128\n",
      "epoch:  25\n",
      "29459 461\n",
      "Loss:  0.09932448714971542\n",
      "Loss:  0.07954558730125427\n",
      "Loss:  0.04193171113729477\n",
      "25 **********\n",
      "Epoch:  2485.6877748966217  fold:  1  kers:  128\n",
      "epoch:  26\n",
      "29459 461\n",
      "Loss:  0.06439855694770813\n",
      "Loss:  0.05893909931182861\n",
      "Loss:  0.04253460839390755\n",
      "26 **********\n",
      "Epoch:  2566.2563512325287  fold:  1  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.9015345573425293\n",
      "Eval Loss:  0.30707862973213196\n",
      "Eval Loss:  0.09451676905155182\n",
      "[[ 784  255]\n",
      " [ 403 1990]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70      1039\n",
      "           1       0.89      0.83      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.79      0.78      3432\n",
      "weighted avg       0.82      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8082750582750583\n",
      "pre:  0.8864142538975501\n",
      "rec:  0.8315921437526118\n",
      "ma F1:  0.7812655096943217\n",
      "mi F1:  0.8082750582750583\n",
      "we F1:  0.8115896629101734\n",
      "update!  Acc:  0.8082750582750583\n",
      "Eval Loss:  0.12600664794445038\n",
      "Eval Loss:  0.24039144814014435\n",
      "Eval Loss:  0.31275543570518494\n",
      "Eval Loss:  0.2831652760505676\n",
      "Eval Loss:  0.20568490028381348\n",
      "Eval Loss:  0.2616080641746521\n",
      "Eval Loss:  0.31940925121307373\n",
      "Eval Loss:  0.13715122640132904\n",
      "Eval Loss:  0.2342696189880371\n",
      "Eval Loss:  0.16044683754444122\n",
      "Eval Loss:  0.15035858750343323\n",
      "Eval Loss:  0.18761958181858063\n",
      "Eval Loss:  0.1940336674451828\n",
      "Eval Loss:  0.31316134333610535\n",
      "Eval Loss:  0.2323911339044571\n",
      "Eval Loss:  0.3052853047847748\n",
      "Eval Loss:  0.25852885842323303\n",
      "Eval Loss:  0.2621161639690399\n",
      "Eval Loss:  0.30596187710762024\n",
      "Eval Loss:  0.2304527312517166\n",
      "Eval Loss:  0.15549439191818237\n",
      "Eval Loss:  0.14351886510849\n",
      "Eval Loss:  0.15619485080242157\n",
      "Eval Loss:  0.24726882576942444\n",
      "Eval Loss:  0.21260447800159454\n",
      "Eval Loss:  0.29313337802886963\n",
      "Eval Loss:  0.20808306336402893\n",
      "Eval Loss:  0.18324145674705505\n",
      "[[18369   756]\n",
      " [ 1738  8596]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     19125\n",
      "           1       0.92      0.83      0.87     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.90      0.90     29459\n",
      "weighted avg       0.92      0.92      0.91     29459\n",
      "\n",
      "acc:  0.9153399640177874\n",
      "pre:  0.9191616766467066\n",
      "rec:  0.8318173021095413\n",
      "ma F1:  0.9048702138873959\n",
      "mi F1:  0.9153399640177874\n",
      "we F1:  0.914287953925897\n",
      "29459 461\n",
      "Loss:  0.06196872889995575\n",
      "Loss:  0.06559532880783081\n",
      "Loss:  0.041801851242780685\n",
      "27 **********\n",
      "Epoch:  2694.094537973404  fold:  1  kers:  128\n",
      "epoch:  28\n",
      "29459 461\n",
      "Loss:  0.05965326726436615\n",
      "Loss:  0.04153873026371002\n",
      "Loss:  0.08610863983631134\n",
      "28 **********\n",
      "Epoch:  2774.642170190811  fold:  1  kers:  128\n",
      "epoch:  29\n",
      "29459 461\n",
      "Loss:  0.06579447537660599\n",
      "Loss:  0.06269188225269318\n",
      "Loss:  0.043769288808107376\n",
      "29 **********\n",
      "Epoch:  2855.434148788452  fold:  1  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  1.1126034259796143\n",
      "Eval Loss:  0.3310335874557495\n",
      "Eval Loss:  0.23409448564052582\n",
      "[[ 700  339]\n",
      " [ 292 2101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69      1039\n",
      "           1       0.86      0.88      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.78      0.78      0.78      3432\n",
      "weighted avg       0.81      0.82      0.81      3432\n",
      "\n",
      "acc:  0.8161421911421911\n",
      "pre:  0.8610655737704918\n",
      "rec:  0.8779774341830339\n",
      "ma F1:  0.7793774398743742\n",
      "mi F1:  0.8161421911421912\n",
      "we F1:  0.8149088268955192\n",
      "update!  Acc:  0.8161421911421911\n",
      "Eval Loss:  0.09598758816719055\n",
      "Eval Loss:  0.20710426568984985\n",
      "Eval Loss:  0.29325565695762634\n",
      "Eval Loss:  0.2912085950374603\n",
      "Eval Loss:  0.1859145611524582\n",
      "Eval Loss:  0.24252164363861084\n",
      "Eval Loss:  0.28034940361976624\n",
      "Eval Loss:  0.13968704640865326\n",
      "Eval Loss:  0.20677118003368378\n",
      "Eval Loss:  0.15703429281711578\n",
      "Eval Loss:  0.122274249792099\n",
      "Eval Loss:  0.17159923911094666\n",
      "Eval Loss:  0.15589481592178345\n",
      "Eval Loss:  0.2792080342769623\n",
      "Eval Loss:  0.16654154658317566\n",
      "Eval Loss:  0.2547737658023834\n",
      "Eval Loss:  0.25222671031951904\n",
      "Eval Loss:  0.2528657615184784\n",
      "Eval Loss:  0.3099977374076843\n",
      "Eval Loss:  0.24847568571567535\n",
      "Eval Loss:  0.1410766988992691\n",
      "Eval Loss:  0.13196933269500732\n",
      "Eval Loss:  0.129603773355484\n",
      "Eval Loss:  0.19673587381839752\n",
      "Eval Loss:  0.19458530843257904\n",
      "Eval Loss:  0.28517958521842957\n",
      "Eval Loss:  0.197564959526062\n",
      "Eval Loss:  0.16022996604442596\n",
      "[[18163   962]\n",
      " [ 1311  9023]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.90      0.87      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9228419158830917\n",
      "pre:  0.9036554832248372\n",
      "rec:  0.8731372169537449\n",
      "ma F1:  0.9146233613145951\n",
      "mi F1:  0.9228419158830918\n",
      "we F1:  0.9225281001780147\n",
      "29459 461\n",
      "Loss:  0.03178649768233299\n",
      "Loss:  0.04016805812716484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04140746220946312\n",
      "30 **********\n",
      "Epoch:  2983.3222019672394  fold:  1  kers:  128\n",
      "epoch:  31\n",
      "29459 461\n",
      "Loss:  0.06836845725774765\n",
      "Loss:  0.04014214128255844\n",
      "Loss:  0.06523282080888748\n",
      "31 **********\n",
      "Epoch:  3063.786057472229  fold:  1  kers:  128\n",
      "epoch:  32\n",
      "29459 461\n",
      "Loss:  0.06243825703859329\n",
      "Loss:  0.0744786337018013\n",
      "Loss:  0.045501694083213806\n",
      "32 **********\n",
      "Epoch:  3144.2688636779785  fold:  1  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.6918940544128418\n",
      "Eval Loss:  0.3181721270084381\n",
      "Eval Loss:  0.09505125135183334\n",
      "[[ 802  237]\n",
      " [ 427 1966]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.71      1039\n",
      "           1       0.89      0.82      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.80      0.78      3432\n",
      "weighted avg       0.82      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8065268065268065\n",
      "pre:  0.8924194280526555\n",
      "rec:  0.8215628917676556\n",
      "ma F1:  0.7813787926929789\n",
      "mi F1:  0.8065268065268065\n",
      "we F1:  0.8106317228742526\n",
      "Eval Loss:  0.1280154585838318\n",
      "Eval Loss:  0.21428634226322174\n",
      "Eval Loss:  0.2908259630203247\n",
      "Eval Loss:  0.3184751272201538\n",
      "Eval Loss:  0.20784147083759308\n",
      "Eval Loss:  0.2631337344646454\n",
      "Eval Loss:  0.28311270475387573\n",
      "Eval Loss:  0.1515684723854065\n",
      "Eval Loss:  0.19776059687137604\n",
      "Eval Loss:  0.1456424742937088\n",
      "Eval Loss:  0.14092771708965302\n",
      "Eval Loss:  0.16773629188537598\n",
      "Eval Loss:  0.1832486242055893\n",
      "Eval Loss:  0.3113735318183899\n",
      "Eval Loss:  0.19892853498458862\n",
      "Eval Loss:  0.2736400365829468\n",
      "Eval Loss:  0.24726060032844543\n",
      "Eval Loss:  0.24049797654151917\n",
      "Eval Loss:  0.27881941199302673\n",
      "Eval Loss:  0.2338934987783432\n",
      "Eval Loss:  0.15356256067752838\n",
      "Eval Loss:  0.12231389433145523\n",
      "Eval Loss:  0.1644396334886551\n",
      "Eval Loss:  0.22564442455768585\n",
      "Eval Loss:  0.18878231942653656\n",
      "Eval Loss:  0.30222392082214355\n",
      "Eval Loss:  0.2021588385105133\n",
      "Eval Loss:  0.20160610973834991\n",
      "[[18468   657]\n",
      " [ 1747  8587]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     19125\n",
      "           1       0.93      0.83      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.90      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9183950575375947\n",
      "pre:  0.9289268714842059\n",
      "rec:  0.8309463905554481\n",
      "ma F1:  0.9080504127689053\n",
      "mi F1:  0.9183950575375947\n",
      "we F1:  0.9172539116214047\n",
      "29459 461\n",
      "Loss:  0.04575450345873833\n",
      "Loss:  0.07894451171159744\n",
      "Loss:  0.0643918365240097\n",
      "33 **********\n",
      "Epoch:  3272.223737716675  fold:  1  kers:  128\n",
      "epoch:  34\n",
      "29459 461\n",
      "Loss:  0.055535878986120224\n",
      "Loss:  0.03137785196304321\n",
      "Loss:  0.053066398948431015\n",
      "34 **********\n",
      "Epoch:  3356.6330444812775  fold:  1  kers:  128\n",
      "epoch:  35\n",
      "29459 461\n",
      "Loss:  0.0829087346792221\n",
      "Loss:  0.03191979229450226\n",
      "Loss:  0.06995837390422821\n",
      "35 **********\n",
      "Epoch:  3437.1198391914368  fold:  1  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.6951742172241211\n",
      "Eval Loss:  0.3001454472541809\n",
      "Eval Loss:  0.0914299264550209\n",
      "[[ 756  283]\n",
      " [ 384 2009]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.73      0.69      1039\n",
      "           1       0.88      0.84      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.78      0.78      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8056526806526807\n",
      "pre:  0.8765270506108203\n",
      "rec:  0.8395319682407021\n",
      "ma F1:  0.7757635095456141\n",
      "mi F1:  0.8056526806526807\n",
      "we F1:  0.8080619434474242\n",
      "Eval Loss:  0.09948965907096863\n",
      "Eval Loss:  0.21202866733074188\n",
      "Eval Loss:  0.2789931297302246\n",
      "Eval Loss:  0.33984917402267456\n",
      "Eval Loss:  0.23110567033290863\n",
      "Eval Loss:  0.24459215998649597\n",
      "Eval Loss:  0.3138595521450043\n",
      "Eval Loss:  0.14394862949848175\n",
      "Eval Loss:  0.25630342960357666\n",
      "Eval Loss:  0.1534484177827835\n",
      "Eval Loss:  0.12829838693141937\n",
      "Eval Loss:  0.1325012892484665\n",
      "Eval Loss:  0.168537437915802\n",
      "Eval Loss:  0.3065328896045685\n",
      "Eval Loss:  0.19986461102962494\n",
      "Eval Loss:  0.2941698729991913\n",
      "Eval Loss:  0.2329351007938385\n",
      "Eval Loss:  0.24629494547843933\n",
      "Eval Loss:  0.29159584641456604\n",
      "Eval Loss:  0.23501911759376526\n",
      "Eval Loss:  0.15195496380329132\n",
      "Eval Loss:  0.109565868973732\n",
      "Eval Loss:  0.1471490114927292\n",
      "Eval Loss:  0.262483686208725\n",
      "Eval Loss:  0.17210239171981812\n",
      "Eval Loss:  0.3271210491657257\n",
      "Eval Loss:  0.19798493385314941\n",
      "Eval Loss:  0.18128344416618347\n",
      "[[18260   865]\n",
      " [ 1474  8860]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.91      0.86      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9206015139685665\n",
      "pre:  0.9110539845758355\n",
      "rec:  0.857364041029611\n",
      "ma F1:  0.9116010058086949\n",
      "mi F1:  0.9206015139685665\n",
      "we F1:  0.9200183959399109\n",
      "29459 461\n",
      "Loss:  0.05332963913679123\n",
      "Loss:  0.04458054155111313\n",
      "Loss:  0.06254678219556808\n",
      "36 **********\n",
      "Epoch:  3565.0886764526367  fold:  1  kers:  128\n",
      "epoch:  37\n",
      "29459 461\n",
      "Loss:  0.034714266657829285\n",
      "Loss:  0.03238118067383766\n",
      "Loss:  0.06778695434331894\n",
      "37 **********\n",
      "Epoch:  3645.5256044864655  fold:  1  kers:  128\n",
      "epoch:  38\n",
      "29459 461\n",
      "Loss:  0.048337869346141815\n",
      "Loss:  0.051456429064273834\n",
      "Loss:  0.05463605746626854\n",
      "38 **********\n",
      "Epoch:  3726.0293538570404  fold:  1  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.8409450054168701\n",
      "Eval Loss:  0.3763465881347656\n",
      "Eval Loss:  0.13825322687625885\n",
      "[[ 747  292]\n",
      " [ 318 2075]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      1039\n",
      "           1       0.88      0.87      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.79      0.79      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8222610722610723\n",
      "pre:  0.8766370933671314\n",
      "rec:  0.8671124111993314\n",
      "ma F1:  0.7909623925615874\n",
      "mi F1:  0.8222610722610723\n",
      "we F1:  0.8228738476166345\n",
      "update!  Acc:  0.8222610722610723\n",
      "Eval Loss:  0.09872991591691971\n",
      "Eval Loss:  0.1782926768064499\n",
      "Eval Loss:  0.2685690224170685\n",
      "Eval Loss:  0.28591644763946533\n",
      "Eval Loss:  0.1969880908727646\n",
      "Eval Loss:  0.23842982947826385\n",
      "Eval Loss:  0.26830682158470154\n",
      "Eval Loss:  0.1331932544708252\n",
      "Eval Loss:  0.22223106026649475\n",
      "Eval Loss:  0.14575481414794922\n",
      "Eval Loss:  0.1424420028924942\n",
      "Eval Loss:  0.13619817793369293\n",
      "Eval Loss:  0.15437941253185272\n",
      "Eval Loss:  0.2749616503715515\n",
      "Eval Loss:  0.1871485710144043\n",
      "Eval Loss:  0.2405044585466385\n",
      "Eval Loss:  0.208853080868721\n",
      "Eval Loss:  0.21499302983283997\n",
      "Eval Loss:  0.283108115196228\n",
      "Eval Loss:  0.20991310477256775\n",
      "Eval Loss:  0.14220091700553894\n",
      "Eval Loss:  0.11415152996778488\n",
      "Eval Loss:  0.12569625675678253\n",
      "Eval Loss:  0.2188095897436142\n",
      "Eval Loss:  0.1466810256242752\n",
      "Eval Loss:  0.2654644846916199\n",
      "Eval Loss:  0.1894283890724182\n",
      "Eval Loss:  0.17718788981437683\n",
      "[[18248   877]\n",
      " [ 1323  9011]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.91      0.87      0.89     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.92      0.91      0.92     29459\n",
      "weighted avg       0.93      0.93      0.92     29459\n",
      "\n",
      "acc:  0.9253199361824909\n",
      "pre:  0.9113066343042071\n",
      "rec:  0.8719760015482872\n",
      "ma F1:  0.9171770870727931\n",
      "mi F1:  0.9253199361824909\n",
      "we F1:  0.9249267662460476\n",
      "29459 461\n",
      "Loss:  0.05275915935635567\n",
      "Loss:  0.09448802471160889\n",
      "Loss:  0.05765397846698761\n",
      "39 **********\n",
      "Epoch:  3853.9054396152496  fold:  1  kers:  128\n",
      "epoch:  40\n",
      "29459 461\n",
      "Loss:  0.08995040506124496\n",
      "Loss:  0.04550843685865402\n",
      "Loss:  0.03618454933166504\n",
      "40 **********\n",
      "Epoch:  3934.4191620349884  fold:  1  kers:  128\n",
      "epoch:  41\n",
      "29459 461\n",
      "Loss:  0.036785535514354706\n",
      "Loss:  0.06758928298950195\n",
      "Loss:  0.022001167759299278\n",
      "41 **********\n",
      "Epoch:  4014.9737751483917  fold:  1  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.7000781297683716\n",
      "Eval Loss:  0.23809242248535156\n",
      "Eval Loss:  0.25351327657699585\n",
      "[[ 667  372]\n",
      " [ 249 2144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68      1039\n",
      "           1       0.85      0.90      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.77      0.78      3432\n",
      "weighted avg       0.81      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8190559440559441\n",
      "pre:  0.8521462639109698\n",
      "rec:  0.8959465106560802\n",
      "ma F1:  0.7779252992702479\n",
      "mi F1:  0.8190559440559441\n",
      "we F1:  0.8156307109424432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.10364394634962082\n",
      "Eval Loss:  0.19800354540348053\n",
      "Eval Loss:  0.287258505821228\n",
      "Eval Loss:  0.27451133728027344\n",
      "Eval Loss:  0.17570292949676514\n",
      "Eval Loss:  0.19666491448879242\n",
      "Eval Loss:  0.27749770879745483\n",
      "Eval Loss:  0.12768109142780304\n",
      "Eval Loss:  0.2120671421289444\n",
      "Eval Loss:  0.15676157176494598\n",
      "Eval Loss:  0.09815186262130737\n",
      "Eval Loss:  0.14264531433582306\n",
      "Eval Loss:  0.15878142416477203\n",
      "Eval Loss:  0.25903016328811646\n",
      "Eval Loss:  0.1518741101026535\n",
      "Eval Loss:  0.23427864909172058\n",
      "Eval Loss:  0.23788784444332123\n",
      "Eval Loss:  0.2122642546892166\n",
      "Eval Loss:  0.2530866265296936\n",
      "Eval Loss:  0.2091258466243744\n",
      "Eval Loss:  0.1437123715877533\n",
      "Eval Loss:  0.11879346519708633\n",
      "Eval Loss:  0.127419576048851\n",
      "Eval Loss:  0.21178491413593292\n",
      "Eval Loss:  0.1704753339290619\n",
      "Eval Loss:  0.2854281961917877\n",
      "Eval Loss:  0.2257024645805359\n",
      "Eval Loss:  0.17587131261825562\n",
      "[[18314   811]\n",
      " [ 1332  9002]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     19125\n",
      "           1       0.92      0.87      0.89     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.92      0.91      0.92     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9272548287450355\n",
      "pre:  0.9173545297054927\n",
      "rec:  0.8711050899941939\n",
      "ma F1:  0.9191792674824025\n",
      "mi F1:  0.9272548287450355\n",
      "we F1:  0.926803006642605\n",
      "29459 461\n",
      "Loss:  0.05115235596895218\n",
      "Loss:  0.04574940726161003\n",
      "Loss:  0.027409162372350693\n",
      "42 **********\n",
      "Epoch:  4142.871802330017  fold:  1  kers:  128\n",
      "epoch:  43\n",
      "29459 461\n",
      "Loss:  0.03756733611226082\n",
      "Loss:  0.05327599495649338\n",
      "Loss:  0.05668874457478523\n",
      "43 **********\n",
      "Epoch:  4223.415444135666  fold:  1  kers:  128\n",
      "epoch:  44\n",
      "29459 461\n",
      "Loss:  0.057873912155628204\n",
      "Loss:  0.058464229106903076\n",
      "Loss:  0.05983227491378784\n",
      "44 **********\n",
      "Epoch:  4303.990004062653  fold:  1  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  1.0568121671676636\n",
      "Eval Loss:  0.24166589975357056\n",
      "Eval Loss:  0.1099187359213829\n",
      "[[ 698  341]\n",
      " [ 272 2121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69      1039\n",
      "           1       0.86      0.89      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.78      0.78      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8213869463869464\n",
      "pre:  0.8614947197400488\n",
      "rec:  0.8863351441704973\n",
      "ma F1:  0.7843057425929352\n",
      "mi F1:  0.8213869463869464\n",
      "we F1:  0.8195889119092326\n",
      "Eval Loss:  0.09211204946041107\n",
      "Eval Loss:  0.1996847242116928\n",
      "Eval Loss:  0.28851619362831116\n",
      "Eval Loss:  0.26751473546028137\n",
      "Eval Loss:  0.14544937014579773\n",
      "Eval Loss:  0.201693594455719\n",
      "Eval Loss:  0.2383180856704712\n",
      "Eval Loss:  0.12770304083824158\n",
      "Eval Loss:  0.19835977256298065\n",
      "Eval Loss:  0.1823701411485672\n",
      "Eval Loss:  0.09791713953018188\n",
      "Eval Loss:  0.14214080572128296\n",
      "Eval Loss:  0.15029621124267578\n",
      "Eval Loss:  0.2695031762123108\n",
      "Eval Loss:  0.1408490687608719\n",
      "Eval Loss:  0.1984991878271103\n",
      "Eval Loss:  0.20626690983772278\n",
      "Eval Loss:  0.19694392383098602\n",
      "Eval Loss:  0.25571584701538086\n",
      "Eval Loss:  0.20018009841442108\n",
      "Eval Loss:  0.13728120923042297\n",
      "Eval Loss:  0.10273244231939316\n",
      "Eval Loss:  0.10928821563720703\n",
      "Eval Loss:  0.19896113872528076\n",
      "Eval Loss:  0.1729924976825714\n",
      "Eval Loss:  0.24740912020206451\n",
      "Eval Loss:  0.19316032528877258\n",
      "Eval Loss:  0.1412508487701416\n",
      "[[18204   921]\n",
      " [ 1068  9266]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     19125\n",
      "           1       0.91      0.90      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.93      0.92      0.93     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9324824332122611\n",
      "pre:  0.9095906547560616\n",
      "rec:  0.8966518289142636\n",
      "ma F1:  0.9256369884685214\n",
      "mi F1:  0.9324824332122611\n",
      "we F1:  0.9323698486992459\n",
      "29459 461\n",
      "Loss:  0.0389472097158432\n",
      "Loss:  0.022942230105400085\n",
      "Loss:  0.03568115085363388\n",
      "45 **********\n",
      "Epoch:  4431.874068021774  fold:  1  kers:  128\n",
      "epoch:  46\n",
      "29459 461\n",
      "Loss:  0.05396224930882454\n",
      "Loss:  0.035036828368902206\n",
      "Loss:  0.044490568339824677\n",
      "46 **********\n",
      "Epoch:  4512.374826192856  fold:  1  kers:  128\n",
      "epoch:  47\n",
      "29459 461\n",
      "Loss:  0.06276687979698181\n",
      "Loss:  0.03869649022817612\n",
      "Loss:  0.032054603099823\n",
      "47 **********\n",
      "Epoch:  4592.857630968094  fold:  1  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  1.0258331298828125\n",
      "Eval Loss:  0.27990400791168213\n",
      "Eval Loss:  0.12967520952224731\n",
      "[[ 692  347]\n",
      " [ 307 2086]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68      1039\n",
      "           1       0.86      0.87      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.77      0.77      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8094405594405595\n",
      "pre:  0.8573777229757501\n",
      "rec:  0.8717091516924362\n",
      "ma F1:  0.7717905994150916\n",
      "mi F1:  0.8094405594405595\n",
      "we F1:  0.8083602162547496\n",
      "Eval Loss:  0.08996783196926117\n",
      "Eval Loss:  0.1674470603466034\n",
      "Eval Loss:  0.2661491632461548\n",
      "Eval Loss:  0.278036504983902\n",
      "Eval Loss:  0.18232521414756775\n",
      "Eval Loss:  0.20415477454662323\n",
      "Eval Loss:  0.23319083452224731\n",
      "Eval Loss:  0.12465707212686539\n",
      "Eval Loss:  0.20847481489181519\n",
      "Eval Loss:  0.16566233336925507\n",
      "Eval Loss:  0.11053434014320374\n",
      "Eval Loss:  0.13069269061088562\n",
      "Eval Loss:  0.14962805807590485\n",
      "Eval Loss:  0.23834288120269775\n",
      "Eval Loss:  0.16147133708000183\n",
      "Eval Loss:  0.21833926439285278\n",
      "Eval Loss:  0.18243415653705597\n",
      "Eval Loss:  0.18587428331375122\n",
      "Eval Loss:  0.2524186968803406\n",
      "Eval Loss:  0.21475833654403687\n",
      "Eval Loss:  0.133024662733078\n",
      "Eval Loss:  0.09922023117542267\n",
      "Eval Loss:  0.1029738262295723\n",
      "Eval Loss:  0.18117466568946838\n",
      "Eval Loss:  0.14963577687740326\n",
      "Eval Loss:  0.25108957290649414\n",
      "Eval Loss:  0.18146562576293945\n",
      "Eval Loss:  0.13287359476089478\n",
      "[[18090  1035]\n",
      " [  954  9380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     19125\n",
      "           1       0.90      0.91      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.93      0.93      0.93     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9324824332122611\n",
      "pre:  0.9006240998559769\n",
      "rec:  0.9076833752661119\n",
      "ma F1:  0.9260148036099931\n",
      "mi F1:  0.9324824332122611\n",
      "we F1:  0.9325425799399055\n",
      "29459 461\n",
      "Loss:  0.04361548647284508\n",
      "Loss:  0.0778139978647232\n",
      "Loss:  0.052042849361896515\n",
      "48 **********\n",
      "Epoch:  4720.693823099136  fold:  1  kers:  128\n",
      "epoch:  49\n",
      "29459 461\n",
      "Loss:  0.07469945400953293\n",
      "Loss:  0.042603857815265656\n",
      "Loss:  0.05232744663953781\n",
      "49 **********\n",
      "Epoch:  4801.198569774628  fold:  1  kers:  128\n",
      "epoch:  50\n",
      "29459 461\n",
      "Loss:  0.04808325693011284\n",
      "Loss:  0.03762480616569519\n",
      "Loss:  0.03556331619620323\n",
      "50 **********\n",
      "Epoch:  4881.688356161118  fold:  1  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  1.2807941436767578\n",
      "Eval Loss:  0.19644388556480408\n",
      "Eval Loss:  0.09897592663764954\n",
      "[[ 728  311]\n",
      " [ 314 2079]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70      1039\n",
      "           1       0.87      0.87      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.78      0.78      0.78      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8178904428904429\n",
      "pre:  0.8698744769874477\n",
      "rec:  0.8687839531968241\n",
      "ma F1:  0.7844962481751252\n",
      "mi F1:  0.8178904428904429\n",
      "we F1:  0.8179645972828529\n",
      "Eval Loss:  0.09874185919761658\n",
      "Eval Loss:  0.16563007235527039\n",
      "Eval Loss:  0.27003416419029236\n",
      "Eval Loss:  0.2505147457122803\n",
      "Eval Loss:  0.15198341012001038\n",
      "Eval Loss:  0.1912831962108612\n",
      "Eval Loss:  0.21816423535346985\n",
      "Eval Loss:  0.11934218555688858\n",
      "Eval Loss:  0.17212645709514618\n",
      "Eval Loss:  0.1613142192363739\n",
      "Eval Loss:  0.10170245915651321\n",
      "Eval Loss:  0.14161574840545654\n",
      "Eval Loss:  0.1470700204372406\n",
      "Eval Loss:  0.23019465804100037\n",
      "Eval Loss:  0.16332866251468658\n",
      "Eval Loss:  0.20401911437511444\n",
      "Eval Loss:  0.2066924124956131\n",
      "Eval Loss:  0.19562339782714844\n",
      "Eval Loss:  0.23882192373275757\n",
      "Eval Loss:  0.2072073072195053\n",
      "Eval Loss:  0.1278696358203888\n",
      "Eval Loss:  0.11136431992053986\n",
      "Eval Loss:  0.10051126033067703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20273669064044952\n",
      "Eval Loss:  0.160739004611969\n",
      "Eval Loss:  0.21838882565498352\n",
      "Eval Loss:  0.16867004334926605\n",
      "Eval Loss:  0.14839991927146912\n",
      "[[18312   813]\n",
      " [ 1115  9219]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     19125\n",
      "           1       0.92      0.89      0.91     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.93      0.92      0.93     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9345531077090193\n",
      "pre:  0.9189593301435407\n",
      "rec:  0.8921037352428876\n",
      "ma F1:  0.9276610205882283\n",
      "mi F1:  0.9345531077090193\n",
      "we F1:  0.9343242052224386\n",
      "29459 461\n",
      "Loss:  0.0810430571436882\n",
      "Loss:  0.045384716242551804\n",
      "Loss:  0.08505845814943314\n",
      "51 **********\n",
      "Epoch:  5009.614308595657  fold:  1  kers:  128\n",
      "epoch:  52\n",
      "29459 461\n",
      "Loss:  0.04238288849592209\n",
      "Loss:  0.05511123687028885\n",
      "Loss:  0.06470561772584915\n",
      "52 **********\n",
      "Epoch:  5090.111076116562  fold:  1  kers:  128\n",
      "epoch:  53\n",
      "29459 461\n",
      "Loss:  0.05473323166370392\n",
      "Loss:  0.043134476989507675\n",
      "Loss:  0.04544997215270996\n",
      "53 **********\n",
      "Epoch:  5170.629786014557  fold:  1  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.7173414826393127\n",
      "Eval Loss:  0.2921384274959564\n",
      "Eval Loss:  0.06834208965301514\n",
      "[[ 775  264]\n",
      " [ 291 2102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      1039\n",
      "           1       0.89      0.88      0.88      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.81      0.81      0.81      3432\n",
      "weighted avg       0.84      0.84      0.84      3432\n",
      "\n",
      "acc:  0.8382867132867133\n",
      "pre:  0.8884192730346576\n",
      "rec:  0.878395319682407\n",
      "ma F1:  0.8098604519303093\n",
      "mi F1:  0.8382867132867133\n",
      "we F1:  0.8388650923798731\n",
      "update!  Acc:  0.8382867132867133\n",
      "Eval Loss:  0.09450604021549225\n",
      "Eval Loss:  0.17409254610538483\n",
      "Eval Loss:  0.27697792649269104\n",
      "Eval Loss:  0.28972378373146057\n",
      "Eval Loss:  0.16301140189170837\n",
      "Eval Loss:  0.20691528916358948\n",
      "Eval Loss:  0.21763072907924652\n",
      "Eval Loss:  0.1274789273738861\n",
      "Eval Loss:  0.17966429889202118\n",
      "Eval Loss:  0.15243306756019592\n",
      "Eval Loss:  0.11182956397533417\n",
      "Eval Loss:  0.13548675179481506\n",
      "Eval Loss:  0.16767913103103638\n",
      "Eval Loss:  0.26636040210723877\n",
      "Eval Loss:  0.16435134410858154\n",
      "Eval Loss:  0.2361973524093628\n",
      "Eval Loss:  0.21374192833900452\n",
      "Eval Loss:  0.2090441733598709\n",
      "Eval Loss:  0.21365556120872498\n",
      "Eval Loss:  0.20996952056884766\n",
      "Eval Loss:  0.1428728997707367\n",
      "Eval Loss:  0.10174766927957535\n",
      "Eval Loss:  0.13031703233718872\n",
      "Eval Loss:  0.19808238744735718\n",
      "Eval Loss:  0.16182459890842438\n",
      "Eval Loss:  0.26460424065589905\n",
      "Eval Loss:  0.16441749036312103\n",
      "Eval Loss:  0.18468248844146729\n",
      "[[18325   800]\n",
      " [ 1204  9130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     19125\n",
      "           1       0.92      0.88      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.93      0.92      0.92     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9319732509589599\n",
      "pre:  0.919436052366566\n",
      "rec:  0.8834913876524095\n",
      "ma F1:  0.9246304194167696\n",
      "mi F1:  0.9319732509589599\n",
      "we F1:  0.9316506295404667\n",
      "29459 461\n",
      "Loss:  0.062337927520275116\n",
      "Loss:  0.035818129777908325\n",
      "Loss:  0.046716563403606415\n",
      "54 **********\n",
      "Epoch:  5298.583663225174  fold:  1  kers:  128\n",
      "epoch:  55\n",
      "29459 461\n",
      "Loss:  0.06071540713310242\n",
      "Loss:  0.018824871629476547\n",
      "Loss:  0.041319455951452255\n",
      "55 **********\n",
      "Epoch:  5379.077439069748  fold:  1  kers:  128\n",
      "epoch:  56\n",
      "29459 461\n",
      "Loss:  0.029893334954977036\n",
      "Loss:  0.05346544086933136\n",
      "Loss:  0.052200790494680405\n",
      "56 **********\n",
      "Epoch:  5459.574206829071  fold:  1  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.8704073429107666\n",
      "Eval Loss:  0.3510797619819641\n",
      "Eval Loss:  0.10319237411022186\n",
      "[[ 760  279]\n",
      " [ 350 2043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.71      1039\n",
      "           1       0.88      0.85      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.78      0.79      0.79      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8167249417249417\n",
      "pre:  0.8798449612403101\n",
      "rec:  0.8537400752193899\n",
      "ma F1:  0.7869508469499489\n",
      "mi F1:  0.8167249417249417\n",
      "we F1:  0.8183726118177121\n",
      "Eval Loss:  0.07354281097650528\n",
      "Eval Loss:  0.1752651184797287\n",
      "Eval Loss:  0.2387273758649826\n",
      "Eval Loss:  0.2917063236236572\n",
      "Eval Loss:  0.15332739055156708\n",
      "Eval Loss:  0.19900047779083252\n",
      "Eval Loss:  0.24722130596637726\n",
      "Eval Loss:  0.10470059514045715\n",
      "Eval Loss:  0.16797968745231628\n",
      "Eval Loss:  0.14579708874225616\n",
      "Eval Loss:  0.10272243618965149\n",
      "Eval Loss:  0.12247426807880402\n",
      "Eval Loss:  0.13889339566230774\n",
      "Eval Loss:  0.21492668986320496\n",
      "Eval Loss:  0.1633385568857193\n",
      "Eval Loss:  0.23081286251544952\n",
      "Eval Loss:  0.1968727856874466\n",
      "Eval Loss:  0.2083110809326172\n",
      "Eval Loss:  0.2199915647506714\n",
      "Eval Loss:  0.20719324052333832\n",
      "Eval Loss:  0.1174539104104042\n",
      "Eval Loss:  0.10718636959791183\n",
      "Eval Loss:  0.11716810613870621\n",
      "Eval Loss:  0.18924927711486816\n",
      "Eval Loss:  0.1385483741760254\n",
      "Eval Loss:  0.22926127910614014\n",
      "Eval Loss:  0.16647252440452576\n",
      "Eval Loss:  0.16829364001750946\n",
      "[[18481   644]\n",
      " [ 1245  9089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     19125\n",
      "           1       0.93      0.88      0.91     10334\n",
      "\n",
      "    accuracy                           0.94     29459\n",
      "   macro avg       0.94      0.92      0.93     29459\n",
      "weighted avg       0.94      0.94      0.94     29459\n",
      "\n",
      "acc:  0.9358769815676025\n",
      "pre:  0.9338333504572074\n",
      "rec:  0.8795239016837624\n",
      "ma F1:  0.9286218469868496\n",
      "mi F1:  0.9358769815676025\n",
      "we F1:  0.935412720932697\n",
      "29459 461\n",
      "Loss:  0.03837957978248596\n",
      "Loss:  0.07264362275600433\n",
      "Loss:  0.04008067771792412\n",
      "57 **********\n",
      "Epoch:  5587.4024205207825  fold:  1  kers:  128\n",
      "epoch:  58\n",
      "29459 461\n",
      "Loss:  0.033528897911310196\n",
      "Loss:  0.024623509496450424\n",
      "Loss:  0.05763556435704231\n",
      "58 **********\n",
      "Epoch:  5667.815412521362  fold:  1  kers:  128\n",
      "epoch:  59\n",
      "29459 461\n",
      "Loss:  0.05883246660232544\n",
      "Loss:  0.05505911260843277\n",
      "Loss:  0.026624087244272232\n",
      "59 **********\n",
      "Epoch:  5748.207460403442  fold:  1  kers:  128\n",
      "Eval Loss:  0.8682688474655151\n",
      "Eval Loss:  0.24967743456363678\n",
      "Eval Loss:  0.09731923788785934\n",
      "[[ 709  330]\n",
      " [ 310 2083]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      1039\n",
      "           1       0.86      0.87      0.87      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.78      0.78      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8135198135198135\n",
      "pre:  0.8632407791131371\n",
      "rec:  0.8704554951943168\n",
      "ma F1:  0.7779257948943801\n",
      "mi F1:  0.8135198135198135\n",
      "we F1:  0.8130017055339994\n",
      "update!  Acc:  0.8382867132867133\n",
      "Epoch:  5752.7602870464325  fold:  1  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29797 3094\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29797 466\n",
      "Loss:  0.16859936714172363\n",
      "Loss:  0.16605214774608612\n",
      "Loss:  0.1684606373310089\n",
      "0 **********\n",
      "Epoch:  93.51296401023865  fold:  2  kers:  128\n",
      "epoch:  1\n",
      "29797 466\n",
      "Loss:  0.16074761748313904\n",
      "Loss:  0.1298806071281433\n",
      "Loss:  0.11473619937896729\n",
      "1 **********\n",
      "Epoch:  174.7736895084381  fold:  2  kers:  128\n",
      "epoch:  2\n",
      "29797 466\n",
      "Loss:  0.11317426711320877\n",
      "Loss:  0.09766839444637299\n",
      "Loss:  0.09591823071241379\n",
      "2 **********\n",
      "Epoch:  256.06433510780334  fold:  2  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.7821573615074158\n",
      "Eval Loss:  0.24106813967227936\n",
      "Eval Loss:  0.542591392993927\n",
      "[[1145  285]\n",
      " [ 532 1132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74      1430\n",
      "           1       0.80      0.68      0.73      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.74      0.74      0.74      3094\n",
      "weighted avg       0.75      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7359405300581772\n",
      "pre:  0.7988708539167255\n",
      "rec:  0.6802884615384616\n",
      "ma F1:  0.7359358682381828\n",
      "mi F1:  0.7359405300581772\n",
      "we F1:  0.735851955478284\n",
      "update!  Acc:  0.7359405300581772\n",
      "Eval Loss:  0.3723111152648926\n",
      "Eval Loss:  0.4340142607688904\n",
      "Eval Loss:  0.345350980758667\n",
      "Eval Loss:  0.3746970295906067\n",
      "Eval Loss:  0.3803912103176117\n",
      "Eval Loss:  0.4373287260532379\n",
      "Eval Loss:  0.392558753490448\n",
      "Eval Loss:  0.38508689403533936\n",
      "Eval Loss:  0.32347995042800903\n",
      "Eval Loss:  0.42594701051712036\n",
      "Eval Loss:  0.3831409811973572\n",
      "Eval Loss:  0.3472804129123688\n",
      "Eval Loss:  0.4028099775314331\n",
      "Eval Loss:  0.3160627782344818\n",
      "Eval Loss:  0.32215777039527893\n",
      "Eval Loss:  0.35914868116378784\n",
      "Eval Loss:  0.32229292392730713\n",
      "Eval Loss:  0.3228885233402252\n",
      "Eval Loss:  0.38954469561576843\n",
      "Eval Loss:  0.36822497844696045\n",
      "Eval Loss:  0.30503055453300476\n",
      "Eval Loss:  0.3678227961063385\n",
      "Eval Loss:  0.34922948479652405\n",
      "Eval Loss:  0.5327337384223938\n",
      "Eval Loss:  0.35190463066101074\n",
      "Eval Loss:  0.29828009009361267\n",
      "Eval Loss:  0.3599061071872711\n",
      "Eval Loss:  0.30723026394844055\n",
      "Eval Loss:  0.3065185248851776\n",
      "[[15931  2803]\n",
      " [ 1980  9083]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87     18734\n",
      "           1       0.76      0.82      0.79     11063\n",
      "\n",
      "    accuracy                           0.84     29797\n",
      "   macro avg       0.83      0.84      0.83     29797\n",
      "weighted avg       0.84      0.84      0.84     29797\n",
      "\n",
      "acc:  0.8394804846125449\n",
      "pre:  0.7641763419148578\n",
      "rec:  0.8210250384163428\n",
      "ma F1:  0.8305293754972444\n",
      "mi F1:  0.8394804846125449\n",
      "we F1:  0.8405562385263727\n",
      "29797 466\n",
      "Loss:  0.09805846214294434\n",
      "Loss:  0.09434454143047333\n",
      "Loss:  0.10957727581262589\n",
      "3 **********\n",
      "Epoch:  380.4557378292084  fold:  2  kers:  128\n",
      "epoch:  4\n",
      "29797 466\n",
      "Loss:  0.07120261341333389\n",
      "Loss:  0.11286967992782593\n",
      "Loss:  0.05931065231561661\n",
      "4 **********\n",
      "Epoch:  461.7084846496582  fold:  2  kers:  128\n",
      "epoch:  5\n",
      "29797 466\n",
      "Loss:  0.08566798269748688\n",
      "Loss:  0.09194961935281754\n",
      "Loss:  0.0604109913110733\n",
      "5 **********\n",
      "Epoch:  542.978185415268  fold:  2  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.8715622425079346\n",
      "Eval Loss:  0.12367783486843109\n",
      "Eval Loss:  0.664612352848053\n",
      "[[1312  118]\n",
      " [ 775  889]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.92      0.75      1430\n",
      "           1       0.88      0.53      0.67      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.76      0.73      0.71      3094\n",
      "weighted avg       0.77      0.71      0.70      3094\n",
      "\n",
      "acc:  0.711376858435682\n",
      "pre:  0.8828202581926514\n",
      "rec:  0.5342548076923077\n",
      "ma F1:  0.7058793535000932\n",
      "mi F1:  0.711376858435682\n",
      "we F1:  0.7028381805570015\n",
      "Eval Loss:  0.34098517894744873\n",
      "Eval Loss:  0.3563408851623535\n",
      "Eval Loss:  0.30775895714759827\n",
      "Eval Loss:  0.31890779733657837\n",
      "Eval Loss:  0.27440083026885986\n",
      "Eval Loss:  0.4474317729473114\n",
      "Eval Loss:  0.3475858271121979\n",
      "Eval Loss:  0.343036413192749\n",
      "Eval Loss:  0.3007052540779114\n",
      "Eval Loss:  0.4734804928302765\n",
      "Eval Loss:  0.339584082365036\n",
      "Eval Loss:  0.28816932439804077\n",
      "Eval Loss:  0.31874915957450867\n",
      "Eval Loss:  0.32454243302345276\n",
      "Eval Loss:  0.2747552990913391\n",
      "Eval Loss:  0.3459625840187073\n",
      "Eval Loss:  0.32888421416282654\n",
      "Eval Loss:  0.2846509516239166\n",
      "Eval Loss:  0.3795680105686188\n",
      "Eval Loss:  0.21744227409362793\n",
      "Eval Loss:  0.2978198826313019\n",
      "Eval Loss:  0.28988802433013916\n",
      "Eval Loss:  0.2784239649772644\n",
      "Eval Loss:  0.6130028963088989\n",
      "Eval Loss:  0.33256515860557556\n",
      "Eval Loss:  0.2501029968261719\n",
      "Eval Loss:  0.351639986038208\n",
      "Eval Loss:  0.3277207911014557\n",
      "Eval Loss:  0.2339659333229065\n",
      "[[17756   978]\n",
      " [ 2766  8297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.90     18734\n",
      "           1       0.89      0.75      0.82     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.88      0.85      0.86     29797\n",
      "weighted avg       0.88      0.87      0.87     29797\n",
      "\n",
      "acc:  0.8743497667550425\n",
      "pre:  0.89455525606469\n",
      "rec:  0.7499774021513151\n",
      "ma F1:  0.8602685733981388\n",
      "mi F1:  0.8743497667550425\n",
      "we F1:  0.8716880505353424\n",
      "29797 466\n",
      "Loss:  0.10170779377222061\n",
      "Loss:  0.057878732681274414\n",
      "Loss:  0.08312401175498962\n",
      "6 **********\n",
      "Epoch:  667.3456518650055  fold:  2  kers:  128\n",
      "epoch:  7\n",
      "29797 466\n",
      "Loss:  0.07666458189487457\n",
      "Loss:  0.050095539540052414\n",
      "Loss:  0.0658540427684784\n",
      "7 **********\n",
      "Epoch:  748.6123616695404  fold:  2  kers:  128\n",
      "epoch:  8\n",
      "29797 466\n",
      "Loss:  0.0670982301235199\n",
      "Loss:  0.06848093867301941\n",
      "Loss:  0.05306904390454292\n",
      "8 **********\n",
      "Epoch:  829.921956539154  fold:  2  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.6218252778053284\n",
      "Eval Loss:  0.23780882358551025\n",
      "Eval Loss:  0.7606224417686462\n",
      "[[1319  111]\n",
      " [ 783  881]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.92      0.75      1430\n",
      "           1       0.89      0.53      0.66      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.76      0.73      0.71      3094\n",
      "weighted avg       0.77      0.71      0.70      3094\n",
      "\n",
      "acc:  0.7110536522301228\n",
      "pre:  0.8881048387096774\n",
      "rec:  0.5294471153846154\n",
      "ma F1:  0.7051446158359371\n",
      "mi F1:  0.7110536522301227\n",
      "we F1:  0.7019877333787696\n",
      "Eval Loss:  0.3262432813644409\n",
      "Eval Loss:  0.30776873230934143\n",
      "Eval Loss:  0.30575698614120483\n",
      "Eval Loss:  0.2773576080799103\n",
      "Eval Loss:  0.23982253670692444\n",
      "Eval Loss:  0.37682121992111206\n",
      "Eval Loss:  0.2984559237957001\n",
      "Eval Loss:  0.2885575294494629\n",
      "Eval Loss:  0.24292589724063873\n",
      "Eval Loss:  0.4275955855846405\n",
      "Eval Loss:  0.2925914525985718\n",
      "Eval Loss:  0.24371705949306488\n",
      "Eval Loss:  0.3449324667453766\n",
      "Eval Loss:  0.2853713631629944\n",
      "Eval Loss:  0.2535834014415741\n",
      "Eval Loss:  0.3056221902370453\n",
      "Eval Loss:  0.31273823976516724\n",
      "Eval Loss:  0.2545626163482666\n",
      "Eval Loss:  0.3514648675918579\n",
      "Eval Loss:  0.17573487758636475\n",
      "Eval Loss:  0.2766309678554535\n",
      "Eval Loss:  0.25372809171676636\n",
      "Eval Loss:  0.2796819508075714\n",
      "Eval Loss:  0.5194677710533142\n",
      "Eval Loss:  0.33701658248901367\n",
      "Eval Loss:  0.229631245136261\n",
      "Eval Loss:  0.34825143218040466\n",
      "Eval Loss:  0.29744237661361694\n",
      "Eval Loss:  0.23310193419456482\n",
      "[[18004   730]\n",
      " [ 2762  8301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     18734\n",
      "           1       0.92      0.75      0.83     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.89      0.86      0.87     29797\n",
      "weighted avg       0.89      0.88      0.88     29797\n",
      "\n",
      "acc:  0.8828069939926838\n",
      "pre:  0.9191673125899679\n",
      "rec:  0.7503389677302721\n",
      "ma F1:  0.8689058589187779\n",
      "mi F1:  0.8828069939926839\n",
      "we F1:  0.8798958215233263\n",
      "29797 466\n",
      "Loss:  0.05701817199587822\n",
      "Loss:  0.08413727581501007\n",
      "Loss:  0.08429650962352753\n",
      "9 **********\n",
      "Epoch:  954.2724680900574  fold:  2  kers:  128\n",
      "epoch:  10\n",
      "29797 466\n",
      "Loss:  0.09263407438993454\n",
      "Loss:  0.06933501362800598\n",
      "Loss:  0.10114928334951401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 **********\n",
      "Epoch:  1035.5481534004211  fold:  2  kers:  128\n",
      "epoch:  11\n",
      "29797 466\n",
      "Loss:  0.04997975006699562\n",
      "Loss:  0.04126826673746109\n",
      "Loss:  0.0717473179101944\n",
      "11 **********\n",
      "Epoch:  1116.8118705749512  fold:  2  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.5193103551864624\n",
      "Eval Loss:  0.26303592324256897\n",
      "Eval Loss:  0.3976641893386841\n",
      "[[1289  141]\n",
      " [ 616 1048]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77      1430\n",
      "           1       0.88      0.63      0.73      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.78      0.77      0.75      3094\n",
      "weighted avg       0.79      0.76      0.75      3094\n",
      "\n",
      "acc:  0.7553329023917259\n",
      "pre:  0.8814129520605551\n",
      "rec:  0.6298076923076923\n",
      "ma F1:  0.753839378943546\n",
      "mi F1:  0.7553329023917259\n",
      "we F1:  0.7523892358444834\n",
      "update!  Acc:  0.7553329023917259\n",
      "Eval Loss:  0.2802567780017853\n",
      "Eval Loss:  0.28527510166168213\n",
      "Eval Loss:  0.2727385461330414\n",
      "Eval Loss:  0.24508772790431976\n",
      "Eval Loss:  0.20337286591529846\n",
      "Eval Loss:  0.28055939078330994\n",
      "Eval Loss:  0.23949408531188965\n",
      "Eval Loss:  0.26553621888160706\n",
      "Eval Loss:  0.1973591148853302\n",
      "Eval Loss:  0.2898542881011963\n",
      "Eval Loss:  0.25106287002563477\n",
      "Eval Loss:  0.19082553684711456\n",
      "Eval Loss:  0.26313334703445435\n",
      "Eval Loss:  0.20370793342590332\n",
      "Eval Loss:  0.20729054510593414\n",
      "Eval Loss:  0.22900694608688354\n",
      "Eval Loss:  0.20471933484077454\n",
      "Eval Loss:  0.22210583090782166\n",
      "Eval Loss:  0.27557024359703064\n",
      "Eval Loss:  0.16577620804309845\n",
      "Eval Loss:  0.21288201212882996\n",
      "Eval Loss:  0.19791308045387268\n",
      "Eval Loss:  0.2570984363555908\n",
      "Eval Loss:  0.44541630148887634\n",
      "Eval Loss:  0.27207767963409424\n",
      "Eval Loss:  0.2073209583759308\n",
      "Eval Loss:  0.32196927070617676\n",
      "Eval Loss:  0.1773848831653595\n",
      "Eval Loss:  0.16838760673999786\n",
      "[[17718  1016]\n",
      " [ 1828  9235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18734\n",
      "           1       0.90      0.83      0.87     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.89      0.90     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9045541497466187\n",
      "pre:  0.9008877182713881\n",
      "rec:  0.8347645304167043\n",
      "ma F1:  0.8961359525565342\n",
      "mi F1:  0.9045541497466187\n",
      "we F1:  0.9037483527268911\n",
      "29797 466\n",
      "Loss:  0.03945497050881386\n",
      "Loss:  0.06515388190746307\n",
      "Loss:  0.06938376277685165\n",
      "12 **********\n",
      "Epoch:  1241.2302017211914  fold:  2  kers:  128\n",
      "epoch:  13\n",
      "29797 466\n",
      "Loss:  0.05709855258464813\n",
      "Loss:  0.09611573815345764\n",
      "Loss:  0.047422926872968674\n",
      "13 **********\n",
      "Epoch:  1322.5028944015503  fold:  2  kers:  128\n",
      "epoch:  14\n",
      "29797 466\n",
      "Loss:  0.04511789605021477\n",
      "Loss:  0.04666818305850029\n",
      "Loss:  0.0556010976433754\n",
      "14 **********\n",
      "Epoch:  1404.0209321975708  fold:  2  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.5156704783439636\n",
      "Eval Loss:  0.15419656038284302\n",
      "Eval Loss:  0.7393348217010498\n",
      "[[1344   86]\n",
      " [ 750  914]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.94      0.76      1430\n",
      "           1       0.91      0.55      0.69      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.78      0.74      0.72      3094\n",
      "weighted avg       0.79      0.73      0.72      3094\n",
      "\n",
      "acc:  0.7297996121525533\n",
      "pre:  0.914\n",
      "rec:  0.5492788461538461\n",
      "ma F1:  0.7244778831044438\n",
      "mi F1:  0.7297996121525533\n",
      "we F1:  0.721581872413147\n",
      "Eval Loss:  0.26997238397598267\n",
      "Eval Loss:  0.27972427010536194\n",
      "Eval Loss:  0.3233031630516052\n",
      "Eval Loss:  0.2471369504928589\n",
      "Eval Loss:  0.22247935831546783\n",
      "Eval Loss:  0.24888566136360168\n",
      "Eval Loss:  0.2681502103805542\n",
      "Eval Loss:  0.25919899344444275\n",
      "Eval Loss:  0.2180260568857193\n",
      "Eval Loss:  0.32091230154037476\n",
      "Eval Loss:  0.2770872116088867\n",
      "Eval Loss:  0.17018061876296997\n",
      "Eval Loss:  0.31041139364242554\n",
      "Eval Loss:  0.23121260106563568\n",
      "Eval Loss:  0.1916305422782898\n",
      "Eval Loss:  0.25221800804138184\n",
      "Eval Loss:  0.24325205385684967\n",
      "Eval Loss:  0.2785448431968689\n",
      "Eval Loss:  0.2964562475681305\n",
      "Eval Loss:  0.13309501111507416\n",
      "Eval Loss:  0.23342600464820862\n",
      "Eval Loss:  0.19867271184921265\n",
      "Eval Loss:  0.2777969241142273\n",
      "Eval Loss:  0.5056374073028564\n",
      "Eval Loss:  0.30427345633506775\n",
      "Eval Loss:  0.18756169080734253\n",
      "Eval Loss:  0.29175031185150146\n",
      "Eval Loss:  0.24462682008743286\n",
      "Eval Loss:  0.1791296899318695\n",
      "[[18144   590]\n",
      " [ 2418  8645]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18734\n",
      "           1       0.94      0.78      0.85     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.87      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.8990502399570427\n",
      "pre:  0.9361126150514347\n",
      "rec:  0.781433607520564\n",
      "ma F1:  0.8876304143185109\n",
      "mi F1:  0.8990502399570427\n",
      "we F1:  0.8968525937556281\n",
      "29797 466\n",
      "Loss:  0.06752005964517593\n",
      "Loss:  0.04271708428859711\n",
      "Loss:  0.05887589603662491\n",
      "15 **********\n",
      "Epoch:  1528.3614709377289  fold:  2  kers:  128\n",
      "epoch:  16\n",
      "29797 466\n",
      "Loss:  0.04144609719514847\n",
      "Loss:  0.04083546623587608\n",
      "Loss:  0.06399302184581757\n",
      "16 **********\n",
      "Epoch:  1609.637156009674  fold:  2  kers:  128\n",
      "epoch:  17\n",
      "29797 466\n",
      "Loss:  0.0651526004076004\n",
      "Loss:  0.062090203166007996\n",
      "Loss:  0.05462949723005295\n",
      "17 **********\n",
      "Epoch:  1690.9068579673767  fold:  2  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.44565480947494507\n",
      "Eval Loss:  0.4056619703769684\n",
      "Eval Loss:  0.5678296685218811\n",
      "[[1235  195]\n",
      " [ 541 1123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77      1430\n",
      "           1       0.85      0.67      0.75      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.77      0.76      3094\n",
      "weighted avg       0.78      0.76      0.76      3094\n",
      "\n",
      "acc:  0.762120232708468\n",
      "pre:  0.8520485584218513\n",
      "rec:  0.6748798076923077\n",
      "ma F1:  0.7618081121371607\n",
      "mi F1:  0.762120232708468\n",
      "we F1:  0.7611560030863935\n",
      "update!  Acc:  0.762120232708468\n",
      "Eval Loss:  0.25280261039733887\n",
      "Eval Loss:  0.20540094375610352\n",
      "Eval Loss:  0.25227952003479004\n",
      "Eval Loss:  0.26443514227867126\n",
      "Eval Loss:  0.19759000837802887\n",
      "Eval Loss:  0.20378251373767853\n",
      "Eval Loss:  0.24926969408988953\n",
      "Eval Loss:  0.2262042760848999\n",
      "Eval Loss:  0.14933641254901886\n",
      "Eval Loss:  0.2083403468132019\n",
      "Eval Loss:  0.20461244881153107\n",
      "Eval Loss:  0.13493624329566956\n",
      "Eval Loss:  0.2664000391960144\n",
      "Eval Loss:  0.2272181510925293\n",
      "Eval Loss:  0.19531454145908356\n",
      "Eval Loss:  0.2151278853416443\n",
      "Eval Loss:  0.16995157301425934\n",
      "Eval Loss:  0.17842447757720947\n",
      "Eval Loss:  0.2324945479631424\n",
      "Eval Loss:  0.14314453303813934\n",
      "Eval Loss:  0.2216375321149826\n",
      "Eval Loss:  0.19880858063697815\n",
      "Eval Loss:  0.29905420541763306\n",
      "Eval Loss:  0.31196510791778564\n",
      "Eval Loss:  0.2632119953632355\n",
      "Eval Loss:  0.16156238317489624\n",
      "Eval Loss:  0.3098614811897278\n",
      "Eval Loss:  0.20664319396018982\n",
      "Eval Loss:  0.17997947335243225\n",
      "[[17779   955]\n",
      " [ 1645  9418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18734\n",
      "           1       0.91      0.85      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9127428935798906\n",
      "pre:  0.90793405957775\n",
      "rec:  0.8513061556539817\n",
      "ma F1:  0.9052854856220383\n",
      "mi F1:  0.9127428935798906\n",
      "we F1:  0.912127463429081\n",
      "29797 466\n",
      "Loss:  0.0513799786567688\n",
      "Loss:  0.08335671573877335\n",
      "Loss:  0.08135422319173813\n",
      "18 **********\n",
      "Epoch:  1815.2703347206116  fold:  2  kers:  128\n",
      "epoch:  19\n",
      "29797 466\n",
      "Loss:  0.05513172224164009\n",
      "Loss:  0.05137299746274948\n",
      "Loss:  0.04848772659897804\n",
      "19 **********\n",
      "Epoch:  1896.573945760727  fold:  2  kers:  128\n",
      "epoch:  20\n",
      "29797 466\n",
      "Loss:  0.05092240497469902\n",
      "Loss:  0.05738333240151405\n",
      "Loss:  0.04818736016750336\n",
      "20 **********\n",
      "Epoch:  1977.860601425171  fold:  2  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.44154560565948486\n",
      "Eval Loss:  0.17637020349502563\n",
      "Eval Loss:  0.8318938612937927\n",
      "[[1285  145]\n",
      " [ 662 1002]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      1430\n",
      "           1       0.87      0.60      0.71      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.77      0.75      0.74      3094\n",
      "weighted avg       0.77      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7391725921137686\n",
      "pre:  0.8735832606800349\n",
      "rec:  0.6021634615384616\n",
      "ma F1:  0.736972027169796\n",
      "mi F1:  0.7391725921137686\n",
      "we F1:  0.7351524787708928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24615946412086487\n",
      "Eval Loss:  0.24135169386863708\n",
      "Eval Loss:  0.25450268387794495\n",
      "Eval Loss:  0.22142940759658813\n",
      "Eval Loss:  0.2238798886537552\n",
      "Eval Loss:  0.22941425442695618\n",
      "Eval Loss:  0.2787727415561676\n",
      "Eval Loss:  0.23317323625087738\n",
      "Eval Loss:  0.1977364867925644\n",
      "Eval Loss:  0.23659946024417877\n",
      "Eval Loss:  0.19097338616847992\n",
      "Eval Loss:  0.1357707977294922\n",
      "Eval Loss:  0.23087608814239502\n",
      "Eval Loss:  0.23955106735229492\n",
      "Eval Loss:  0.19391322135925293\n",
      "Eval Loss:  0.2181728184223175\n",
      "Eval Loss:  0.16321802139282227\n",
      "Eval Loss:  0.2105819284915924\n",
      "Eval Loss:  0.2481754720211029\n",
      "Eval Loss:  0.13058781623840332\n",
      "Eval Loss:  0.20048339664936066\n",
      "Eval Loss:  0.2151118963956833\n",
      "Eval Loss:  0.3060021698474884\n",
      "Eval Loss:  0.34771639108657837\n",
      "Eval Loss:  0.2660592794418335\n",
      "Eval Loss:  0.169427290558815\n",
      "Eval Loss:  0.2734764814376831\n",
      "Eval Loss:  0.19361832737922668\n",
      "Eval Loss:  0.16707921028137207\n",
      "[[18010   724]\n",
      " [ 1927  9136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18734\n",
      "           1       0.93      0.83      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.89      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9110313118770346\n",
      "pre:  0.9265720081135903\n",
      "rec:  0.8258157823375215\n",
      "ma F1:  0.9023723330486757\n",
      "mi F1:  0.9110313118770346\n",
      "we F1:  0.90985746112985\n",
      "29797 466\n",
      "Loss:  0.060425836592912674\n",
      "Loss:  0.0632382482290268\n",
      "Loss:  0.05666959658265114\n",
      "21 **********\n",
      "Epoch:  2102.277935028076  fold:  2  kers:  128\n",
      "epoch:  22\n",
      "29797 466\n",
      "Loss:  0.049615278840065\n",
      "Loss:  0.08080030977725983\n",
      "Loss:  0.07612395286560059\n",
      "22 **********\n",
      "Epoch:  2183.592516183853  fold:  2  kers:  128\n",
      "epoch:  23\n",
      "29797 466\n",
      "Loss:  0.03390457481145859\n",
      "Loss:  0.058351706713438034\n",
      "Loss:  0.05052900314331055\n",
      "23 **********\n",
      "Epoch:  2264.9250497817993  fold:  2  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.5410585403442383\n",
      "Eval Loss:  0.4089602530002594\n",
      "Eval Loss:  0.6929296255111694\n",
      "[[1216  214]\n",
      " [ 531 1133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1430\n",
      "           1       0.84      0.68      0.75      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.77      0.76      3094\n",
      "weighted avg       0.77      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7592113768584356\n",
      "pre:  0.8411284335560505\n",
      "rec:  0.6808894230769231\n",
      "ma F1:  0.7590379708355064\n",
      "mi F1:  0.7592113768584355\n",
      "we F1:  0.7585490912045973\n",
      "Eval Loss:  0.23029087483882904\n",
      "Eval Loss:  0.20489902794361115\n",
      "Eval Loss:  0.23688122630119324\n",
      "Eval Loss:  0.25417858362197876\n",
      "Eval Loss:  0.22586588561534882\n",
      "Eval Loss:  0.24347859621047974\n",
      "Eval Loss:  0.2893926501274109\n",
      "Eval Loss:  0.2848060131072998\n",
      "Eval Loss:  0.217115581035614\n",
      "Eval Loss:  0.24672487378120422\n",
      "Eval Loss:  0.21464131772518158\n",
      "Eval Loss:  0.12869149446487427\n",
      "Eval Loss:  0.21181648969650269\n",
      "Eval Loss:  0.2919887900352478\n",
      "Eval Loss:  0.22084516286849976\n",
      "Eval Loss:  0.2309948205947876\n",
      "Eval Loss:  0.1656164675951004\n",
      "Eval Loss:  0.18872757256031036\n",
      "Eval Loss:  0.21958038210868835\n",
      "Eval Loss:  0.1451568454504013\n",
      "Eval Loss:  0.22168585658073425\n",
      "Eval Loss:  0.20863676071166992\n",
      "Eval Loss:  0.3477814495563507\n",
      "Eval Loss:  0.31410473585128784\n",
      "Eval Loss:  0.26760396361351013\n",
      "Eval Loss:  0.17188675701618195\n",
      "Eval Loss:  0.29533398151397705\n",
      "Eval Loss:  0.25258439779281616\n",
      "Eval Loss:  0.19084732234477997\n",
      "[[17839   895]\n",
      " [ 1878  9185]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     18734\n",
      "           1       0.91      0.83      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.89      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9069369399603987\n",
      "pre:  0.9112103174603174\n",
      "rec:  0.8302449606797433\n",
      "ma F1:  0.8983638602537327\n",
      "mi F1:  0.9069369399603987\n",
      "we F1:  0.9059631316230226\n",
      "29797 466\n",
      "Loss:  0.05195186659693718\n",
      "Loss:  0.03394390642642975\n",
      "Loss:  0.04527668282389641\n",
      "24 **********\n",
      "Epoch:  2389.37629199028  fold:  2  kers:  128\n",
      "epoch:  25\n",
      "29797 466\n",
      "Loss:  0.051509562879800797\n",
      "Loss:  0.05535620078444481\n",
      "Loss:  0.057288557291030884\n",
      "25 **********\n",
      "Epoch:  2470.6809000968933  fold:  2  kers:  128\n",
      "epoch:  26\n",
      "29797 466\n",
      "Loss:  0.07501164823770523\n",
      "Loss:  0.05985618755221367\n",
      "Loss:  0.06650814414024353\n",
      "26 **********\n",
      "Epoch:  2551.994483947754  fold:  2  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.5489298105239868\n",
      "Eval Loss:  0.5283143520355225\n",
      "Eval Loss:  0.49597176909446716\n",
      "[[1125  305]\n",
      " [ 413 1251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1430\n",
      "           1       0.80      0.75      0.78      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.77      0.77      0.77      3094\n",
      "weighted avg       0.77      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7679379444085327\n",
      "pre:  0.8039845758354756\n",
      "rec:  0.7518028846153846\n",
      "ma F1:  0.7675524434548224\n",
      "mi F1:  0.7679379444085327\n",
      "we F1:  0.768268373797427\n",
      "update!  Acc:  0.7679379444085327\n",
      "Eval Loss:  0.21997451782226562\n",
      "Eval Loss:  0.17583657801151276\n",
      "Eval Loss:  0.219523087143898\n",
      "Eval Loss:  0.2559128403663635\n",
      "Eval Loss:  0.2122115045785904\n",
      "Eval Loss:  0.2092001736164093\n",
      "Eval Loss:  0.2513243556022644\n",
      "Eval Loss:  0.2521034777164459\n",
      "Eval Loss:  0.17379960417747498\n",
      "Eval Loss:  0.20682644844055176\n",
      "Eval Loss:  0.19164596498012543\n",
      "Eval Loss:  0.11244259774684906\n",
      "Eval Loss:  0.20058351755142212\n",
      "Eval Loss:  0.26868101954460144\n",
      "Eval Loss:  0.21232563257217407\n",
      "Eval Loss:  0.2010858654975891\n",
      "Eval Loss:  0.13418370485305786\n",
      "Eval Loss:  0.16801205277442932\n",
      "Eval Loss:  0.2301541268825531\n",
      "Eval Loss:  0.15913449227809906\n",
      "Eval Loss:  0.20070986449718475\n",
      "Eval Loss:  0.21281641721725464\n",
      "Eval Loss:  0.3445657193660736\n",
      "Eval Loss:  0.26425299048423767\n",
      "Eval Loss:  0.24019426107406616\n",
      "Eval Loss:  0.17834974825382233\n",
      "Eval Loss:  0.2934434711933136\n",
      "Eval Loss:  0.20074792206287384\n",
      "Eval Loss:  0.19753411412239075\n",
      "[[17510  1224]\n",
      " [ 1388  9675]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18734\n",
      "           1       0.89      0.87      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9123401684733362\n",
      "pre:  0.8876961189099918\n",
      "rec:  0.8745367441019615\n",
      "ma F1:  0.9058291422274218\n",
      "mi F1:  0.9123401684733362\n",
      "we F1:  0.9122038815168169\n",
      "29797 466\n",
      "Loss:  0.07085467129945755\n",
      "Loss:  0.0878312811255455\n",
      "Loss:  0.051313214004039764\n",
      "27 **********\n",
      "Epoch:  2676.4038393497467  fold:  2  kers:  128\n",
      "epoch:  28\n",
      "29797 466\n",
      "Loss:  0.055893510580062866\n",
      "Loss:  0.047579605132341385\n",
      "Loss:  0.02960110642015934\n",
      "28 **********\n",
      "Epoch:  2757.6934864521027  fold:  2  kers:  128\n",
      "epoch:  29\n",
      "29797 466\n",
      "Loss:  0.016713686287403107\n",
      "Loss:  0.07107019424438477\n",
      "Loss:  0.0540621317923069\n",
      "29 **********\n",
      "Epoch:  2838.991113424301  fold:  2  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.47590604424476624\n",
      "Eval Loss:  0.2911933362483978\n",
      "Eval Loss:  0.8776299953460693\n",
      "[[1184  246]\n",
      " [ 526 1138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75      1430\n",
      "           1       0.82      0.68      0.75      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.76      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7504848093083387\n",
      "pre:  0.8222543352601156\n",
      "rec:  0.6838942307692307\n",
      "ma F1:  0.750429643746761\n",
      "mi F1:  0.7504848093083387\n",
      "we F1:  0.7501490189335175\n",
      "Eval Loss:  0.18933254480361938\n",
      "Eval Loss:  0.20824697613716125\n",
      "Eval Loss:  0.19999518990516663\n",
      "Eval Loss:  0.1942683607339859\n",
      "Eval Loss:  0.1688879430294037\n",
      "Eval Loss:  0.17803221940994263\n",
      "Eval Loss:  0.20212571322917938\n",
      "Eval Loss:  0.15315207839012146\n",
      "Eval Loss:  0.1389409452676773\n",
      "Eval Loss:  0.1892758309841156\n",
      "Eval Loss:  0.16073811054229736\n",
      "Eval Loss:  0.12894928455352783\n",
      "Eval Loss:  0.18818655610084534\n",
      "Eval Loss:  0.20269429683685303\n",
      "Eval Loss:  0.1599309742450714\n",
      "Eval Loss:  0.14085645973682404\n",
      "Eval Loss:  0.1022222489118576\n",
      "Eval Loss:  0.180137038230896\n",
      "Eval Loss:  0.204197958111763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.13214470446109772\n",
      "Eval Loss:  0.15635357797145844\n",
      "Eval Loss:  0.17935071885585785\n",
      "Eval Loss:  0.28922128677368164\n",
      "Eval Loss:  0.23164066672325134\n",
      "Eval Loss:  0.21812686324119568\n",
      "Eval Loss:  0.1260584443807602\n",
      "Eval Loss:  0.2571616470813751\n",
      "Eval Loss:  0.1333158314228058\n",
      "Eval Loss:  0.13942579925060272\n",
      "[[17854   880]\n",
      " [ 1288  9775]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18734\n",
      "           1       0.92      0.88      0.90     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.92      0.92     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9272409974158472\n",
      "pre:  0.9174096668230878\n",
      "rec:  0.8835758835758836\n",
      "ma F1:  0.9214677786250627\n",
      "mi F1:  0.9272409974158472\n",
      "we F1:  0.9269494423636576\n",
      "29797 466\n",
      "Loss:  0.050029508769512177\n",
      "Loss:  0.033225201070308685\n",
      "Loss:  0.03609642758965492\n",
      "30 **********\n",
      "Epoch:  2963.3406281471252  fold:  2  kers:  128\n",
      "epoch:  31\n",
      "29797 466\n",
      "Loss:  0.06517455726861954\n",
      "Loss:  0.07797849923372269\n",
      "Loss:  0.05370480567216873\n",
      "31 **********\n",
      "Epoch:  3044.630275964737  fold:  2  kers:  128\n",
      "epoch:  32\n",
      "29797 466\n",
      "Loss:  0.029905229806900024\n",
      "Loss:  0.08459115028381348\n",
      "Loss:  0.05590832978487015\n",
      "32 **********\n",
      "Epoch:  3125.9428627490997  fold:  2  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.736262321472168\n",
      "Eval Loss:  0.4273570775985718\n",
      "Eval Loss:  1.0953176021575928\n",
      "[[1155  275]\n",
      " [ 560 1104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73      1430\n",
      "           1       0.80      0.66      0.73      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.74      0.74      0.73      3094\n",
      "weighted avg       0.74      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7301228183581124\n",
      "pre:  0.8005801305293692\n",
      "rec:  0.6634615384615384\n",
      "ma F1:  0.7300494710944925\n",
      "mi F1:  0.7301228183581123\n",
      "we F1:  0.7297129365908241\n",
      "Eval Loss:  0.20449002087116241\n",
      "Eval Loss:  0.16464559733867645\n",
      "Eval Loss:  0.20073768496513367\n",
      "Eval Loss:  0.22357076406478882\n",
      "Eval Loss:  0.1728239506483078\n",
      "Eval Loss:  0.18559278547763824\n",
      "Eval Loss:  0.20945531129837036\n",
      "Eval Loss:  0.18800866603851318\n",
      "Eval Loss:  0.14544516801834106\n",
      "Eval Loss:  0.1905672550201416\n",
      "Eval Loss:  0.18558631837368011\n",
      "Eval Loss:  0.10738392174243927\n",
      "Eval Loss:  0.1709541529417038\n",
      "Eval Loss:  0.24899603426456451\n",
      "Eval Loss:  0.19084779918193817\n",
      "Eval Loss:  0.17413946986198425\n",
      "Eval Loss:  0.09334879368543625\n",
      "Eval Loss:  0.1618034541606903\n",
      "Eval Loss:  0.1916837841272354\n",
      "Eval Loss:  0.13937892019748688\n",
      "Eval Loss:  0.19835177063941956\n",
      "Eval Loss:  0.18924623727798462\n",
      "Eval Loss:  0.336706280708313\n",
      "Eval Loss:  0.2479197233915329\n",
      "Eval Loss:  0.21931473910808563\n",
      "Eval Loss:  0.14199867844581604\n",
      "Eval Loss:  0.2678198218345642\n",
      "Eval Loss:  0.1766747534275055\n",
      "Eval Loss:  0.14581678807735443\n",
      "[[17813   921]\n",
      " [ 1386  9677]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18734\n",
      "           1       0.91      0.87      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.91      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.922576098264926\n",
      "pre:  0.9130968107190036\n",
      "rec:  0.8747175268914399\n",
      "ma F1:  0.9163387321009802\n",
      "mi F1:  0.922576098264926\n",
      "we F1:  0.9222196116294497\n",
      "29797 466\n",
      "Loss:  0.04632050544023514\n",
      "Loss:  0.06638172268867493\n",
      "Loss:  0.1076495498418808\n",
      "33 **********\n",
      "Epoch:  3250.399092435837  fold:  2  kers:  128\n",
      "epoch:  34\n",
      "29797 466\n",
      "Loss:  0.06497115641832352\n",
      "Loss:  0.031258877366781235\n",
      "Loss:  0.024899082258343697\n",
      "34 **********\n",
      "Epoch:  3331.743593454361  fold:  2  kers:  128\n",
      "epoch:  35\n",
      "29797 466\n",
      "Loss:  0.06347818672657013\n",
      "Loss:  0.037698760628700256\n",
      "Loss:  0.03637047857046127\n",
      "35 **********\n",
      "Epoch:  3413.0302493572235  fold:  2  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.5932164192199707\n",
      "Eval Loss:  0.25572243332862854\n",
      "Eval Loss:  0.7664285898208618\n",
      "[[1223  207]\n",
      " [ 561 1103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.76      1430\n",
      "           1       0.84      0.66      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.77      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7517776341305753\n",
      "pre:  0.8419847328244274\n",
      "rec:  0.6628605769230769\n",
      "ma F1:  0.751403681522793\n",
      "mi F1:  0.7517776341305753\n",
      "we F1:  0.7506744739376177\n",
      "Eval Loss:  0.19556039571762085\n",
      "Eval Loss:  0.2109847068786621\n",
      "Eval Loss:  0.22401906549930573\n",
      "Eval Loss:  0.20617353916168213\n",
      "Eval Loss:  0.2020806074142456\n",
      "Eval Loss:  0.2131197154521942\n",
      "Eval Loss:  0.21560370922088623\n",
      "Eval Loss:  0.22398686408996582\n",
      "Eval Loss:  0.19568008184432983\n",
      "Eval Loss:  0.24076604843139648\n",
      "Eval Loss:  0.18084284663200378\n",
      "Eval Loss:  0.1150052472949028\n",
      "Eval Loss:  0.16540676355361938\n",
      "Eval Loss:  0.24155080318450928\n",
      "Eval Loss:  0.16997990012168884\n",
      "Eval Loss:  0.19020739197731018\n",
      "Eval Loss:  0.09802563488483429\n",
      "Eval Loss:  0.1920556277036667\n",
      "Eval Loss:  0.21158082783222198\n",
      "Eval Loss:  0.11855539679527283\n",
      "Eval Loss:  0.18279962241649628\n",
      "Eval Loss:  0.15908636152744293\n",
      "Eval Loss:  0.3361789584159851\n",
      "Eval Loss:  0.30569541454315186\n",
      "Eval Loss:  0.22547239065170288\n",
      "Eval Loss:  0.1443670243024826\n",
      "Eval Loss:  0.2570001780986786\n",
      "Eval Loss:  0.16852232813835144\n",
      "Eval Loss:  0.14284269511699677\n",
      "[[17998   736]\n",
      " [ 1623  9440]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18734\n",
      "           1       0.93      0.85      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.91      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9208309561365238\n",
      "pre:  0.9276729559748428\n",
      "rec:  0.8532947663382446\n",
      "ma F1:  0.9137131867609074\n",
      "mi F1:  0.9208309561365238\n",
      "we F1:  0.9200932298644776\n",
      "29797 466\n",
      "Loss:  0.06827393174171448\n",
      "Loss:  0.042810842394828796\n",
      "Loss:  0.05776704475283623\n",
      "36 **********\n",
      "Epoch:  3537.5154016017914  fold:  2  kers:  128\n",
      "epoch:  37\n",
      "29797 466\n",
      "Loss:  0.09255799651145935\n",
      "Loss:  0.04756471514701843\n",
      "Loss:  0.044372156262397766\n",
      "37 **********\n",
      "Epoch:  3618.8309803009033  fold:  2  kers:  128\n",
      "epoch:  38\n",
      "29797 466\n",
      "Loss:  0.06458090245723724\n",
      "Loss:  0.04315798357129097\n",
      "Loss:  0.050672031939029694\n",
      "38 **********\n",
      "Epoch:  3700.183459997177  fold:  2  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.5386875867843628\n",
      "Eval Loss:  0.3416583836078644\n",
      "Eval Loss:  0.6170632243156433\n",
      "[[1152  278]\n",
      " [ 504 1160]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      1430\n",
      "           1       0.81      0.70      0.75      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.75      0.75      0.75      3094\n",
      "weighted avg       0.76      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7472527472527473\n",
      "pre:  0.8066759388038943\n",
      "rec:  0.6971153846153846\n",
      "ma F1:  0.7472510574784399\n",
      "mi F1:  0.7472527472527473\n",
      "we F1:  0.7473004833769301\n",
      "Eval Loss:  0.16800230741500854\n",
      "Eval Loss:  0.18648117780685425\n",
      "Eval Loss:  0.17842839658260345\n",
      "Eval Loss:  0.17482084035873413\n",
      "Eval Loss:  0.1699267029762268\n",
      "Eval Loss:  0.18180249631404877\n",
      "Eval Loss:  0.17901334166526794\n",
      "Eval Loss:  0.15975210070610046\n",
      "Eval Loss:  0.15115642547607422\n",
      "Eval Loss:  0.22151412069797516\n",
      "Eval Loss:  0.16445909440517426\n",
      "Eval Loss:  0.11341002583503723\n",
      "Eval Loss:  0.14680130779743195\n",
      "Eval Loss:  0.19477081298828125\n",
      "Eval Loss:  0.14102528989315033\n",
      "Eval Loss:  0.14748378098011017\n",
      "Eval Loss:  0.06560506671667099\n",
      "Eval Loss:  0.18562643229961395\n",
      "Eval Loss:  0.19117799401283264\n",
      "Eval Loss:  0.12762562930583954\n",
      "Eval Loss:  0.17218992114067078\n",
      "Eval Loss:  0.154994934797287\n",
      "Eval Loss:  0.2720057964324951\n",
      "Eval Loss:  0.2470521777868271\n",
      "Eval Loss:  0.21021300554275513\n",
      "Eval Loss:  0.12791526317596436\n",
      "Eval Loss:  0.21712622046470642\n",
      "Eval Loss:  0.12147244065999985\n",
      "Eval Loss:  0.128550723195076\n",
      "[[17924   810]\n",
      " [ 1231  9832]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     18734\n",
      "           1       0.92      0.89      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.92      0.93     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9315031714602141\n",
      "pre:  0.9238864875023491\n",
      "rec:  0.8887281930760191\n",
      "ma F1:  0.9260492449880986\n",
      "mi F1:  0.9315031714602141\n",
      "we F1:  0.9312194217018404\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.044581372290849686\n",
      "Loss:  0.044240038841962814\n",
      "Loss:  0.03421976417303085\n",
      "39 **********\n",
      "Epoch:  3824.6297166347504  fold:  2  kers:  128\n",
      "epoch:  40\n",
      "29797 466\n",
      "Loss:  0.04361756518483162\n",
      "Loss:  0.03587530925869942\n",
      "Loss:  0.05832263454794884\n",
      "40 **********\n",
      "Epoch:  3905.9203612804413  fold:  2  kers:  128\n",
      "epoch:  41\n",
      "29797 466\n",
      "Loss:  0.06780555844306946\n",
      "Loss:  0.06003081798553467\n",
      "Loss:  0.04486431926488876\n",
      "41 **********\n",
      "Epoch:  3987.2568838596344  fold:  2  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.5841667056083679\n",
      "Eval Loss:  0.20106273889541626\n",
      "Eval Loss:  1.10689115524292\n",
      "[[1170  260]\n",
      " [ 585 1079]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.73      1430\n",
      "           1       0.81      0.65      0.72      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.74      0.73      0.73      3094\n",
      "weighted avg       0.74      0.73      0.73      3094\n",
      "\n",
      "acc:  0.726890756302521\n",
      "pre:  0.8058252427184466\n",
      "rec:  0.6484375\n",
      "ma F1:  0.7266542980828694\n",
      "mi F1:  0.7268907563025211\n",
      "we F1:  0.7260462626609084\n",
      "Eval Loss:  0.17473843693733215\n",
      "Eval Loss:  0.17696700990200043\n",
      "Eval Loss:  0.18514034152030945\n",
      "Eval Loss:  0.172587588429451\n",
      "Eval Loss:  0.1508992463350296\n",
      "Eval Loss:  0.1774037629365921\n",
      "Eval Loss:  0.19892776012420654\n",
      "Eval Loss:  0.1572326421737671\n",
      "Eval Loss:  0.16524732112884521\n",
      "Eval Loss:  0.2021629512310028\n",
      "Eval Loss:  0.18489359319210052\n",
      "Eval Loss:  0.10982467979192734\n",
      "Eval Loss:  0.1664019376039505\n",
      "Eval Loss:  0.182743102312088\n",
      "Eval Loss:  0.171142578125\n",
      "Eval Loss:  0.13541676104068756\n",
      "Eval Loss:  0.08461311459541321\n",
      "Eval Loss:  0.17141564190387726\n",
      "Eval Loss:  0.20029714703559875\n",
      "Eval Loss:  0.1180330216884613\n",
      "Eval Loss:  0.15377061069011688\n",
      "Eval Loss:  0.14920204877853394\n",
      "Eval Loss:  0.26422762870788574\n",
      "Eval Loss:  0.22356373071670532\n",
      "Eval Loss:  0.21491268277168274\n",
      "Eval Loss:  0.11066246777772903\n",
      "Eval Loss:  0.2252616286277771\n",
      "Eval Loss:  0.11886462569236755\n",
      "Eval Loss:  0.12108273059129715\n",
      "[[17902   832]\n",
      " [ 1278  9785]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     18734\n",
      "           1       0.92      0.88      0.90     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.92      0.92     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9291875020975267\n",
      "pre:  0.9216351134972215\n",
      "rec:  0.8844797975232758\n",
      "ma F1:  0.9235115055494597\n",
      "mi F1:  0.9291875020975267\n",
      "we F1:  0.9288756264710097\n",
      "29797 466\n",
      "Loss:  0.042371176183223724\n",
      "Loss:  0.042515456676483154\n",
      "Loss:  0.037265948951244354\n",
      "42 **********\n",
      "Epoch:  4111.665241241455  fold:  2  kers:  128\n",
      "epoch:  43\n",
      "29797 466\n",
      "Loss:  0.05550464615225792\n",
      "Loss:  0.03944207727909088\n",
      "Loss:  0.07238668203353882\n",
      "43 **********\n",
      "Epoch:  4192.975833415985  fold:  2  kers:  128\n",
      "epoch:  44\n",
      "29797 466\n",
      "Loss:  0.06196306273341179\n",
      "Loss:  0.03151526302099228\n",
      "Loss:  0.027839113026857376\n",
      "44 **********\n",
      "Epoch:  4274.277449607849  fold:  2  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.7006337642669678\n",
      "Eval Loss:  0.5432592034339905\n",
      "Eval Loss:  0.3899087905883789\n",
      "[[ 866  564]\n",
      " [ 331 1333]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.61      0.66      1430\n",
      "           1       0.70      0.80      0.75      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.71      0.70      0.70      3094\n",
      "weighted avg       0.71      0.71      0.71      3094\n",
      "\n",
      "acc:  0.7107304460245637\n",
      "pre:  0.7026884554559831\n",
      "rec:  0.8010817307692307\n",
      "ma F1:  0.70398664977257\n",
      "mi F1:  0.7107304460245636\n",
      "we F1:  0.7073657682371663\n",
      "Eval Loss:  0.20994627475738525\n",
      "Eval Loss:  0.1895323246717453\n",
      "Eval Loss:  0.22660763561725616\n",
      "Eval Loss:  0.27659815549850464\n",
      "Eval Loss:  0.23095805943012238\n",
      "Eval Loss:  0.19028306007385254\n",
      "Eval Loss:  0.2520376443862915\n",
      "Eval Loss:  0.2544269263744354\n",
      "Eval Loss:  0.18488363921642303\n",
      "Eval Loss:  0.20058231055736542\n",
      "Eval Loss:  0.20685479044914246\n",
      "Eval Loss:  0.09473510086536407\n",
      "Eval Loss:  0.1503905951976776\n",
      "Eval Loss:  0.24975433945655823\n",
      "Eval Loss:  0.21472792327404022\n",
      "Eval Loss:  0.20882514119148254\n",
      "Eval Loss:  0.09405327588319778\n",
      "Eval Loss:  0.14200736582279205\n",
      "Eval Loss:  0.2405710369348526\n",
      "Eval Loss:  0.164884552359581\n",
      "Eval Loss:  0.23043744266033173\n",
      "Eval Loss:  0.21696193516254425\n",
      "Eval Loss:  0.3261170983314514\n",
      "Eval Loss:  0.3166922628879547\n",
      "Eval Loss:  0.2362150251865387\n",
      "Eval Loss:  0.17240023612976074\n",
      "Eval Loss:  0.2771565914154053\n",
      "Eval Loss:  0.16615727543830872\n",
      "Eval Loss:  0.15695704519748688\n",
      "[[17540  1194]\n",
      " [ 1249  9814]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18734\n",
      "           1       0.89      0.89      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.91      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9180118803906434\n",
      "pre:  0.8915334302325582\n",
      "rec:  0.8871011479707132\n",
      "ma F1:  0.912102516017684\n",
      "mi F1:  0.9180118803906434\n",
      "we F1:  0.9179698126918971\n",
      "29797 466\n",
      "Loss:  0.06623886525630951\n",
      "Loss:  0.05420015752315521\n",
      "Loss:  0.07312889397144318\n",
      "45 **********\n",
      "Epoch:  4398.885273933411  fold:  2  kers:  128\n",
      "epoch:  46\n",
      "29797 466\n",
      "Loss:  0.025974459946155548\n",
      "Loss:  0.06827913224697113\n",
      "Loss:  0.05019073188304901\n",
      "46 **********\n",
      "Epoch:  4480.171929597855  fold:  2  kers:  128\n",
      "epoch:  47\n",
      "29797 466\n",
      "Loss:  0.06020226329565048\n",
      "Loss:  0.024605799466371536\n",
      "Loss:  0.06392184644937515\n",
      "47 **********\n",
      "Epoch:  4561.494489908218  fold:  2  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.5686526894569397\n",
      "Eval Loss:  0.16616711020469666\n",
      "Eval Loss:  0.8161332607269287\n",
      "[[1192  238]\n",
      " [ 603 1061]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.83      0.74      1430\n",
      "           1       0.82      0.64      0.72      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.74      0.74      0.73      3094\n",
      "weighted avg       0.75      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7281835811247576\n",
      "pre:  0.8167821401077752\n",
      "rec:  0.6376201923076923\n",
      "ma F1:  0.7276954270629756\n",
      "mi F1:  0.7281835811247577\n",
      "we F1:  0.726823457212159\n",
      "Eval Loss:  0.17552079260349274\n",
      "Eval Loss:  0.18724191188812256\n",
      "Eval Loss:  0.1771072894334793\n",
      "Eval Loss:  0.15319539606571198\n",
      "Eval Loss:  0.14411661028862\n",
      "Eval Loss:  0.16009056568145752\n",
      "Eval Loss:  0.17723670601844788\n",
      "Eval Loss:  0.137969970703125\n",
      "Eval Loss:  0.13451345264911652\n",
      "Eval Loss:  0.18710462749004364\n",
      "Eval Loss:  0.16599485278129578\n",
      "Eval Loss:  0.1145138218998909\n",
      "Eval Loss:  0.1617545634508133\n",
      "Eval Loss:  0.20488813519477844\n",
      "Eval Loss:  0.12414869666099548\n",
      "Eval Loss:  0.14774103462696075\n",
      "Eval Loss:  0.06193982809782028\n",
      "Eval Loss:  0.18734247982501984\n",
      "Eval Loss:  0.16971293091773987\n",
      "Eval Loss:  0.11323907971382141\n",
      "Eval Loss:  0.1629297137260437\n",
      "Eval Loss:  0.10441294312477112\n",
      "Eval Loss:  0.2189246565103531\n",
      "Eval Loss:  0.2656623423099518\n",
      "Eval Loss:  0.20493075251579285\n",
      "Eval Loss:  0.1160559356212616\n",
      "Eval Loss:  0.21200047433376312\n",
      "Eval Loss:  0.1391759216785431\n",
      "Eval Loss:  0.10465787351131439\n",
      "[[18164   570]\n",
      " [ 1294  9769]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     18734\n",
      "           1       0.94      0.88      0.91     11063\n",
      "\n",
      "    accuracy                           0.94     29797\n",
      "   macro avg       0.94      0.93      0.93     29797\n",
      "weighted avg       0.94      0.94      0.94     29797\n",
      "\n",
      "acc:  0.9374433667818908\n",
      "pre:  0.9448689428377987\n",
      "rec:  0.8830335352074482\n",
      "ma F1:  0.9320496516364554\n",
      "mi F1:  0.9374433667818908\n",
      "we F1:  0.9369782030218794\n",
      "29797 466\n",
      "Loss:  0.03830358386039734\n",
      "Loss:  0.04631130397319794\n",
      "Loss:  0.05800027400255203\n",
      "48 **********\n",
      "Epoch:  4685.949721574783  fold:  2  kers:  128\n",
      "epoch:  49\n",
      "29797 466\n",
      "Loss:  0.08743002265691757\n",
      "Loss:  0.043163400143384933\n",
      "Loss:  0.051883865147829056\n",
      "49 **********\n",
      "Epoch:  4767.272282123566  fold:  2  kers:  128\n",
      "epoch:  50\n",
      "29797 466\n",
      "Loss:  0.04745718091726303\n",
      "Loss:  0.04320714622735977\n",
      "Loss:  0.020514341071248055\n",
      "50 **********\n",
      "Epoch:  4851.942889451981  fold:  2  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.6352880001068115\n",
      "Eval Loss:  0.48841220140457153\n",
      "Eval Loss:  0.43492379784584045\n",
      "[[1004  426]\n",
      " [ 379 1285]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71      1430\n",
      "           1       0.75      0.77      0.76      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.74      0.74      0.74      3094\n",
      "weighted avg       0.74      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7398190045248869\n",
      "pre:  0.7510227936879018\n",
      "rec:  0.7722355769230769\n",
      "ma F1:  0.7376550670827244\n",
      "mi F1:  0.7398190045248869\n",
      "we F1:  0.7394570648103616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.15365058183670044\n",
      "Eval Loss:  0.1888321191072464\n",
      "Eval Loss:  0.17389409244060516\n",
      "Eval Loss:  0.20240522921085358\n",
      "Eval Loss:  0.16944751143455505\n",
      "Eval Loss:  0.1751176416873932\n",
      "Eval Loss:  0.1963769644498825\n",
      "Eval Loss:  0.18191573023796082\n",
      "Eval Loss:  0.16088591516017914\n",
      "Eval Loss:  0.14987899363040924\n",
      "Eval Loss:  0.1680888533592224\n",
      "Eval Loss:  0.10448187589645386\n",
      "Eval Loss:  0.16274283826351166\n",
      "Eval Loss:  0.23691153526306152\n",
      "Eval Loss:  0.1651666909456253\n",
      "Eval Loss:  0.15438786149024963\n",
      "Eval Loss:  0.06247236579656601\n",
      "Eval Loss:  0.17306676506996155\n",
      "Eval Loss:  0.18491598963737488\n",
      "Eval Loss:  0.16222698986530304\n",
      "Eval Loss:  0.17697858810424805\n",
      "Eval Loss:  0.13623499870300293\n",
      "Eval Loss:  0.2778320908546448\n",
      "Eval Loss:  0.2590807378292084\n",
      "Eval Loss:  0.1808289885520935\n",
      "Eval Loss:  0.12434211373329163\n",
      "Eval Loss:  0.22152473032474518\n",
      "Eval Loss:  0.1391650289297104\n",
      "Eval Loss:  0.12495237588882446\n",
      "[[17787   947]\n",
      " [ 1048 10015]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18734\n",
      "           1       0.91      0.91      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.93      0.93     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9330469510353391\n",
      "pre:  0.9136106549899653\n",
      "rec:  0.9052698183132966\n",
      "ma F1:  0.9281594102945925\n",
      "mi F1:  0.9330469510353391\n",
      "we F1:  0.9329834356448585\n",
      "29797 466\n",
      "Loss:  0.0664805918931961\n",
      "Loss:  0.04642637073993683\n",
      "Loss:  0.05832416191697121\n",
      "51 **********\n",
      "Epoch:  4978.879487037659  fold:  2  kers:  128\n",
      "epoch:  52\n",
      "29797 466\n",
      "Loss:  0.0360746793448925\n",
      "Loss:  0.031971290707588196\n",
      "Loss:  0.06190287694334984\n",
      "52 **********\n",
      "Epoch:  5060.178110837936  fold:  2  kers:  128\n",
      "epoch:  53\n",
      "29797 466\n",
      "Loss:  0.04666432738304138\n",
      "Loss:  0.011812230572104454\n",
      "Loss:  0.028999166563153267\n",
      "53 **********\n",
      "Epoch:  5141.574473619461  fold:  2  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.754389226436615\n",
      "Eval Loss:  0.2686430811882019\n",
      "Eval Loss:  1.1356122493743896\n",
      "[[1198  232]\n",
      " [ 591 1073]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.74      1430\n",
      "           1       0.82      0.64      0.72      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.75      0.74      0.73      3094\n",
      "weighted avg       0.75      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7340012928248222\n",
      "pre:  0.8222222222222222\n",
      "rec:  0.6448317307692307\n",
      "ma F1:  0.7335664138837157\n",
      "mi F1:  0.7340012928248222\n",
      "we F1:  0.7327523205059641\n",
      "Eval Loss:  0.15569700300693512\n",
      "Eval Loss:  0.1635892242193222\n",
      "Eval Loss:  0.14854054152965546\n",
      "Eval Loss:  0.1434970200061798\n",
      "Eval Loss:  0.14032156765460968\n",
      "Eval Loss:  0.13888059556484222\n",
      "Eval Loss:  0.16049933433532715\n",
      "Eval Loss:  0.1396760493516922\n",
      "Eval Loss:  0.13900135457515717\n",
      "Eval Loss:  0.14836837351322174\n",
      "Eval Loss:  0.16747555136680603\n",
      "Eval Loss:  0.09309868514537811\n",
      "Eval Loss:  0.1406012624502182\n",
      "Eval Loss:  0.20059765875339508\n",
      "Eval Loss:  0.13919194042682648\n",
      "Eval Loss:  0.15207983553409576\n",
      "Eval Loss:  0.05032646656036377\n",
      "Eval Loss:  0.15370962023735046\n",
      "Eval Loss:  0.1736808866262436\n",
      "Eval Loss:  0.1257956326007843\n",
      "Eval Loss:  0.15675699710845947\n",
      "Eval Loss:  0.08665630221366882\n",
      "Eval Loss:  0.21862202882766724\n",
      "Eval Loss:  0.2123357206583023\n",
      "Eval Loss:  0.18666993081569672\n",
      "Eval Loss:  0.10712700337171555\n",
      "Eval Loss:  0.16492724418640137\n",
      "Eval Loss:  0.10799653083086014\n",
      "Eval Loss:  0.11080362647771835\n",
      "[[17974   760]\n",
      " [  974 10089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     18734\n",
      "           1       0.93      0.91      0.92     11063\n",
      "\n",
      "    accuracy                           0.94     29797\n",
      "   macro avg       0.94      0.94      0.94     29797\n",
      "weighted avg       0.94      0.94      0.94     29797\n",
      "\n",
      "acc:  0.9418062221028962\n",
      "pre:  0.9299474605954466\n",
      "rec:  0.9119587815239989\n",
      "ma F1:  0.9374243067584715\n",
      "mi F1:  0.9418062221028962\n",
      "we F1:  0.9416872963091476\n",
      "29797 466\n",
      "Loss:  0.055382341146469116\n",
      "Loss:  0.03808286041021347\n",
      "Loss:  0.04292159900069237\n",
      "54 **********\n",
      "Epoch:  5266.214212179184  fold:  2  kers:  128\n",
      "epoch:  55\n",
      "29797 466\n",
      "Loss:  0.052531104534864426\n",
      "Loss:  0.07172182947397232\n",
      "Loss:  0.0500708669424057\n",
      "55 **********\n",
      "Epoch:  5347.564697504044  fold:  2  kers:  128\n",
      "epoch:  56\n",
      "29797 466\n",
      "Loss:  0.031915098428726196\n",
      "Loss:  0.06764880567789078\n",
      "Loss:  0.02212863601744175\n",
      "56 **********\n",
      "Epoch:  5428.942110776901  fold:  2  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.5470473170280457\n",
      "Eval Loss:  0.6484888195991516\n",
      "Eval Loss:  0.6495665311813354\n",
      "[[1033  397]\n",
      " [ 418 1246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72      1430\n",
      "           1       0.76      0.75      0.75      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.74      0.74      0.74      3094\n",
      "weighted avg       0.74      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7365869424692955\n",
      "pre:  0.7583688374923919\n",
      "rec:  0.7487980769230769\n",
      "ma F1:  0.7353325915482047\n",
      "mi F1:  0.7365869424692955\n",
      "we F1:  0.7367106108699663\n",
      "Eval Loss:  0.1767844259738922\n",
      "Eval Loss:  0.1578679382801056\n",
      "Eval Loss:  0.15800073742866516\n",
      "Eval Loss:  0.1551397144794464\n",
      "Eval Loss:  0.20655512809753418\n",
      "Eval Loss:  0.15892165899276733\n",
      "Eval Loss:  0.19286634027957916\n",
      "Eval Loss:  0.18586871027946472\n",
      "Eval Loss:  0.15725712478160858\n",
      "Eval Loss:  0.15984223783016205\n",
      "Eval Loss:  0.19232571125030518\n",
      "Eval Loss:  0.08594869822263718\n",
      "Eval Loss:  0.1500312089920044\n",
      "Eval Loss:  0.1756032556295395\n",
      "Eval Loss:  0.15536293387413025\n",
      "Eval Loss:  0.16252179443836212\n",
      "Eval Loss:  0.061234183609485626\n",
      "Eval Loss:  0.13774734735488892\n",
      "Eval Loss:  0.2037740796804428\n",
      "Eval Loss:  0.14065206050872803\n",
      "Eval Loss:  0.17689068615436554\n",
      "Eval Loss:  0.1590716540813446\n",
      "Eval Loss:  0.25118735432624817\n",
      "Eval Loss:  0.22156426310539246\n",
      "Eval Loss:  0.1882229447364807\n",
      "Eval Loss:  0.1250194013118744\n",
      "Eval Loss:  0.1544233113527298\n",
      "Eval Loss:  0.12335770577192307\n",
      "Eval Loss:  0.14245055615901947\n",
      "[[17624  1110]\n",
      " [  860 10203]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     18734\n",
      "           1       0.90      0.92      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.93      0.93     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9338859616739941\n",
      "pre:  0.901882789710952\n",
      "rec:  0.9222634005242701\n",
      "ma F1:  0.929513932377245\n",
      "mi F1:  0.9338859616739941\n",
      "we F1:  0.9340332473934639\n",
      "29797 466\n",
      "Loss:  0.04789121076464653\n",
      "Loss:  0.027149805799126625\n",
      "Loss:  0.039633769541978836\n",
      "57 **********\n",
      "Epoch:  5553.487102985382  fold:  2  kers:  128\n",
      "epoch:  58\n",
      "29797 466\n",
      "Loss:  0.048942241817712784\n",
      "Loss:  0.03481883928179741\n",
      "Loss:  0.03675370663404465\n",
      "58 **********\n",
      "Epoch:  5634.812655448914  fold:  2  kers:  128\n",
      "epoch:  59\n",
      "29797 466\n",
      "Loss:  0.03607296198606491\n",
      "Loss:  0.036233969032764435\n",
      "Loss:  0.0623297281563282\n",
      "59 **********\n",
      "Epoch:  5716.147182941437  fold:  2  kers:  128\n",
      "Eval Loss:  0.5862850546836853\n",
      "Eval Loss:  0.4859784245491028\n",
      "Eval Loss:  0.5304344296455383\n",
      "[[1072  358]\n",
      " [ 437 1227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      1430\n",
      "           1       0.77      0.74      0.76      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.74      0.74      0.74      3094\n",
      "weighted avg       0.74      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7430510665804784\n",
      "pre:  0.7741324921135647\n",
      "rec:  0.7373798076923077\n",
      "ma F1:  0.7424045779102759\n",
      "mi F1:  0.7430510665804783\n",
      "we F1:  0.7433805672575493\n",
      "update!  Acc:  0.7679379444085327\n",
      "Epoch:  5720.266169786453  fold:  2  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.16643813252449036\n",
      "Loss:  0.16021163761615753\n",
      "Loss:  0.15985365211963654\n",
      "0 **********\n",
      "Epoch:  92.6781964302063  fold:  3  kers:  128\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.16062341630458832\n",
      "Loss:  0.13318073749542236\n",
      "Loss:  0.11960294842720032\n",
      "1 **********\n",
      "Epoch:  173.0961754322052  fold:  3  kers:  128\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.11657000333070755\n",
      "Loss:  0.10351170599460602\n",
      "Loss:  0.09982345998287201\n",
      "2 **********\n",
      "Epoch:  253.49121499061584  fold:  3  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.9954921007156372\n",
      "Eval Loss:  0.9504536986351013\n",
      "Eval Loss:  0.42429792881011963\n",
      "[[1365  171]\n",
      " [ 738 1157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75      1536\n",
      "           1       0.87      0.61      0.72      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.76      0.75      0.73      3431\n",
      "weighted avg       0.77      0.74      0.73      3431\n",
      "\n",
      "acc:  0.7350626639463713\n",
      "pre:  0.8712349397590361\n",
      "rec:  0.6105540897097625\n",
      "ma F1:  0.7340853649022547\n",
      "mi F1:  0.7350626639463712\n",
      "we F1:  0.7323985843405344\n",
      "update!  Acc:  0.7350626639463713\n",
      "Eval Loss:  0.4238453209400177\n",
      "Eval Loss:  0.6074813604354858\n",
      "Eval Loss:  0.3203088343143463\n",
      "Eval Loss:  0.3633998930454254\n",
      "Eval Loss:  0.4429774284362793\n",
      "Eval Loss:  0.37377500534057617\n",
      "Eval Loss:  0.5224868059158325\n",
      "Eval Loss:  0.4356827735900879\n",
      "Eval Loss:  0.36973491311073303\n",
      "Eval Loss:  0.43189331889152527\n",
      "Eval Loss:  0.4130800664424896\n",
      "Eval Loss:  0.4764915108680725\n",
      "Eval Loss:  0.49358507990837097\n",
      "Eval Loss:  0.3463178873062134\n",
      "Eval Loss:  0.3564906120300293\n",
      "Eval Loss:  0.37145546078681946\n",
      "Eval Loss:  0.36764952540397644\n",
      "Eval Loss:  0.398285835981369\n",
      "Eval Loss:  0.41771289706230164\n",
      "Eval Loss:  0.4490599036216736\n",
      "Eval Loss:  0.38627660274505615\n",
      "Eval Loss:  0.4417744576931\n",
      "Eval Loss:  0.44765904545783997\n",
      "Eval Loss:  0.34384477138519287\n",
      "Eval Loss:  0.36419281363487244\n",
      "Eval Loss:  0.3998486399650574\n",
      "Eval Loss:  0.45782873034477234\n",
      "Eval Loss:  0.4515593349933624\n",
      "[[16817  1811]\n",
      " [ 3268  7564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87     18628\n",
      "           1       0.81      0.70      0.75     10832\n",
      "\n",
      "    accuracy                           0.83     29460\n",
      "   macro avg       0.82      0.80      0.81     29460\n",
      "weighted avg       0.83      0.83      0.82     29460\n",
      "\n",
      "acc:  0.8275967413441955\n",
      "pre:  0.8068266666666667\n",
      "rec:  0.698301329394387\n",
      "ma F1:  0.8087276092131301\n",
      "mi F1:  0.8275967413441955\n",
      "we F1:  0.8246255616711206\n",
      "29460 461\n",
      "Loss:  0.10400693863630295\n",
      "Loss:  0.11416789144277573\n",
      "Loss:  0.13678309321403503\n",
      "3 **********\n",
      "Epoch:  377.07078886032104  fold:  3  kers:  128\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.09402210265398026\n",
      "Loss:  0.0820997953414917\n",
      "Loss:  0.0799005776643753\n",
      "4 **********\n",
      "Epoch:  457.4538605213165  fold:  3  kers:  128\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.07355241477489471\n",
      "Loss:  0.08359384536743164\n",
      "Loss:  0.11168152093887329\n",
      "5 **********\n",
      "Epoch:  537.8409221172333  fold:  3  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  1.2659358978271484\n",
      "Eval Loss:  1.001315951347351\n",
      "Eval Loss:  0.7166963815689087\n",
      "[[1464   72]\n",
      " [ 932  963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.95      0.74      1536\n",
      "           1       0.93      0.51      0.66      1895\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.77      0.73      0.70      3431\n",
      "weighted avg       0.79      0.71      0.70      3431\n",
      "\n",
      "acc:  0.7073739434567181\n",
      "pre:  0.9304347826086956\n",
      "rec:  0.508179419525066\n",
      "ma F1:  0.7009985452348629\n",
      "mi F1:  0.7073739434567181\n",
      "we F1:  0.6964301461098209\n",
      "Eval Loss:  0.5507211089134216\n",
      "Eval Loss:  0.8221490383148193\n",
      "Eval Loss:  0.25185734033584595\n",
      "Eval Loss:  0.41223591566085815\n",
      "Eval Loss:  0.45659390091896057\n",
      "Eval Loss:  0.4172411561012268\n",
      "Eval Loss:  0.6142787933349609\n",
      "Eval Loss:  0.49174386262893677\n",
      "Eval Loss:  0.36916467547416687\n",
      "Eval Loss:  0.5240568518638611\n",
      "Eval Loss:  0.42584335803985596\n",
      "Eval Loss:  0.5612507462501526\n",
      "Eval Loss:  0.5406533479690552\n",
      "Eval Loss:  0.35431742668151855\n",
      "Eval Loss:  0.4391726851463318\n",
      "Eval Loss:  0.3970659673213959\n",
      "Eval Loss:  0.40799322724342346\n",
      "Eval Loss:  0.4219033420085907\n",
      "Eval Loss:  0.5560047030448914\n",
      "Eval Loss:  0.5832019448280334\n",
      "Eval Loss:  0.4461265802383423\n",
      "Eval Loss:  0.5274916291236877\n",
      "Eval Loss:  0.60592120885849\n",
      "Eval Loss:  0.37114930152893066\n",
      "Eval Loss:  0.47827085852622986\n",
      "Eval Loss:  0.47500839829444885\n",
      "Eval Loss:  0.546739399433136\n",
      "Eval Loss:  0.5509350895881653\n",
      "[[18196   432]\n",
      " [ 4888  5944]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87     18628\n",
      "           1       0.93      0.55      0.69     10832\n",
      "\n",
      "    accuracy                           0.82     29460\n",
      "   macro avg       0.86      0.76      0.78     29460\n",
      "weighted avg       0.84      0.82      0.81     29460\n",
      "\n",
      "acc:  0.8194161575016972\n",
      "pre:  0.9322459222082811\n",
      "rec:  0.5487444608567208\n",
      "ma F1:  0.7816501169739876\n",
      "mi F1:  0.8194161575016972\n",
      "we F1:  0.8056808100815638\n",
      "29460 461\n",
      "Loss:  0.09791190177202225\n",
      "Loss:  0.07724785059690475\n",
      "Loss:  0.09297266602516174\n",
      "6 **********\n",
      "Epoch:  661.4185004234314  fold:  3  kers:  128\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.08310850709676743\n",
      "Loss:  0.07341941446065903\n",
      "Loss:  0.07765328139066696\n",
      "7 **********\n",
      "Epoch:  741.8314924240112  fold:  3  kers:  128\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.057413652539253235\n",
      "Loss:  0.06803667545318604\n",
      "Loss:  0.08330755680799484\n",
      "8 **********\n",
      "Epoch:  822.2305219173431  fold:  3  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.8256965279579163\n",
      "Eval Loss:  0.3169884979724884\n",
      "Eval Loss:  0.7388226985931396\n",
      "[[1327  209]\n",
      " [ 624 1271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76      1536\n",
      "           1       0.86      0.67      0.75      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7572136403380938\n",
      "pre:  0.8587837837837838\n",
      "rec:  0.670712401055409\n",
      "ma F1:  0.7571489447577777\n",
      "mi F1:  0.7572136403380937\n",
      "we F1:  0.7567341998768216\n",
      "update!  Acc:  0.7572136403380938\n",
      "Eval Loss:  0.3941633403301239\n",
      "Eval Loss:  0.5099962949752808\n",
      "Eval Loss:  0.20140913128852844\n",
      "Eval Loss:  0.28895846009254456\n",
      "Eval Loss:  0.32591408491134644\n",
      "Eval Loss:  0.2651294469833374\n",
      "Eval Loss:  0.40729662775993347\n",
      "Eval Loss:  0.36487072706222534\n",
      "Eval Loss:  0.269456684589386\n",
      "Eval Loss:  0.3533526062965393\n",
      "Eval Loss:  0.3376551866531372\n",
      "Eval Loss:  0.366049200296402\n",
      "Eval Loss:  0.46395933628082275\n",
      "Eval Loss:  0.24426054954528809\n",
      "Eval Loss:  0.29978182911872864\n",
      "Eval Loss:  0.2810416519641876\n",
      "Eval Loss:  0.3154534697532654\n",
      "Eval Loss:  0.28052815794944763\n",
      "Eval Loss:  0.3657509684562683\n",
      "Eval Loss:  0.39103102684020996\n",
      "Eval Loss:  0.29849523305892944\n",
      "Eval Loss:  0.4043423533439636\n",
      "Eval Loss:  0.4718187749385834\n",
      "Eval Loss:  0.2896028757095337\n",
      "Eval Loss:  0.3710820972919464\n",
      "Eval Loss:  0.3587985932826996\n",
      "Eval Loss:  0.43403902649879456\n",
      "Eval Loss:  0.34955066442489624\n",
      "[[17891   737]\n",
      " [ 3197  7635]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     18628\n",
      "           1       0.91      0.70      0.80     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.83      0.85     29460\n",
      "weighted avg       0.87      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8664630006788866\n",
      "pre:  0.9119684663162924\n",
      "rec:  0.7048559822747416\n",
      "ma F1:  0.8480467830658286\n",
      "mi F1:  0.8664630006788866\n",
      "we F1:  0.8620456941921351\n",
      "29460 461\n",
      "Loss:  0.06642036139965057\n",
      "Loss:  0.06962867826223373\n",
      "Loss:  0.061050672084093094\n",
      "9 **********\n",
      "Epoch:  945.7123565673828  fold:  3  kers:  128\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.049431394785642624\n",
      "Loss:  0.07339748740196228\n",
      "Loss:  0.09133034944534302\n",
      "10 **********\n",
      "Epoch:  1026.1253480911255  fold:  3  kers:  128\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08461037278175354\n",
      "Loss:  0.06000235304236412\n",
      "Loss:  0.0716092512011528\n",
      "11 **********\n",
      "Epoch:  1106.5662655830383  fold:  3  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.837809145450592\n",
      "Eval Loss:  0.259242981672287\n",
      "Eval Loss:  0.8251778483390808\n",
      "[[1329  207]\n",
      " [ 643 1252]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76      1536\n",
      "           1       0.86      0.66      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.76      0.75      3431\n",
      "weighted avg       0.78      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7522588166715244\n",
      "pre:  0.858122001370802\n",
      "rec:  0.6606860158311345\n",
      "ma F1:  0.7521339757358425\n",
      "mi F1:  0.7522588166715244\n",
      "we F1:  0.751551925139612\n",
      "Eval Loss:  0.40752220153808594\n",
      "Eval Loss:  0.5009411573410034\n",
      "Eval Loss:  0.1735677719116211\n",
      "Eval Loss:  0.23088960349559784\n",
      "Eval Loss:  0.2640034556388855\n",
      "Eval Loss:  0.2552604675292969\n",
      "Eval Loss:  0.37510764598846436\n",
      "Eval Loss:  0.3143538534641266\n",
      "Eval Loss:  0.24686084687709808\n",
      "Eval Loss:  0.3597618341445923\n",
      "Eval Loss:  0.3373352289199829\n",
      "Eval Loss:  0.36306440830230713\n",
      "Eval Loss:  0.4320017099380493\n",
      "Eval Loss:  0.2263326793909073\n",
      "Eval Loss:  0.28311601281166077\n",
      "Eval Loss:  0.265874445438385\n",
      "Eval Loss:  0.32317617535591125\n",
      "Eval Loss:  0.23661547899246216\n",
      "Eval Loss:  0.3219412863254547\n",
      "Eval Loss:  0.36232790350914\n",
      "Eval Loss:  0.27291250228881836\n",
      "Eval Loss:  0.3745042085647583\n",
      "Eval Loss:  0.45491230487823486\n",
      "Eval Loss:  0.26459556818008423\n",
      "Eval Loss:  0.30507412552833557\n",
      "Eval Loss:  0.260156512260437\n",
      "Eval Loss:  0.3705330193042755\n",
      "Eval Loss:  0.3551989793777466\n",
      "[[18005   623]\n",
      " [ 2925  7907]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     18628\n",
      "           1       0.93      0.73      0.82     10832\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.85      0.86     29460\n",
      "weighted avg       0.88      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8795655125594026\n",
      "pre:  0.9269636576787808\n",
      "rec:  0.729966765140325\n",
      "ma F1:  0.8635316905038982\n",
      "mi F1:  0.8795655125594025\n",
      "we F1:  0.8759103473413622\n",
      "29460 461\n",
      "Loss:  0.07211656868457794\n",
      "Loss:  0.0937526747584343\n",
      "Loss:  0.04980688914656639\n",
      "12 **********\n",
      "Epoch:  1230.0411186218262  fold:  3  kers:  128\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.0641767755150795\n",
      "Loss:  0.06436169892549515\n",
      "Loss:  0.09840141981840134\n",
      "13 **********\n",
      "Epoch:  1310.4561059474945  fold:  3  kers:  128\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.09282036125659943\n",
      "Loss:  0.05795394629240036\n",
      "Loss:  0.07230200618505478\n",
      "14 **********\n",
      "Epoch:  1390.8950283527374  fold:  3  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.7072590589523315\n",
      "Eval Loss:  0.24920977652072906\n",
      "Eval Loss:  0.8844585418701172\n",
      "[[1292  244]\n",
      " [ 609 1286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.84      0.75      1536\n",
      "           1       0.84      0.68      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.77      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7513844360244827\n",
      "pre:  0.8405228758169935\n",
      "rec:  0.6786279683377309\n",
      "ma F1:  0.7513836757144767\n",
      "mi F1:  0.7513844360244826\n",
      "we F1:  0.7513381838324626\n",
      "Eval Loss:  0.35292527079582214\n",
      "Eval Loss:  0.44748595356941223\n",
      "Eval Loss:  0.162371426820755\n",
      "Eval Loss:  0.19839414954185486\n",
      "Eval Loss:  0.2619592845439911\n",
      "Eval Loss:  0.22190892696380615\n",
      "Eval Loss:  0.3245278298854828\n",
      "Eval Loss:  0.29582202434539795\n",
      "Eval Loss:  0.2095724493265152\n",
      "Eval Loss:  0.3372785449028015\n",
      "Eval Loss:  0.2769676446914673\n",
      "Eval Loss:  0.3380330801010132\n",
      "Eval Loss:  0.37667009234428406\n",
      "Eval Loss:  0.22142820060253143\n",
      "Eval Loss:  0.26223859190940857\n",
      "Eval Loss:  0.24017535150051117\n",
      "Eval Loss:  0.2788659632205963\n",
      "Eval Loss:  0.21693362295627594\n",
      "Eval Loss:  0.2784600257873535\n",
      "Eval Loss:  0.32501858472824097\n",
      "Eval Loss:  0.24162745475769043\n",
      "Eval Loss:  0.3571757972240448\n",
      "Eval Loss:  0.39912354946136475\n",
      "Eval Loss:  0.23439458012580872\n",
      "Eval Loss:  0.2850545048713684\n",
      "Eval Loss:  0.22710776329040527\n",
      "Eval Loss:  0.3321918845176697\n",
      "Eval Loss:  0.33417603373527527\n",
      "[[17936   692]\n",
      " [ 2441  8391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18628\n",
      "           1       0.92      0.77      0.84     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.87      0.88     29460\n",
      "weighted avg       0.90      0.89      0.89     29460\n",
      "\n",
      "acc:  0.893652410047522\n",
      "pre:  0.9238137179346031\n",
      "rec:  0.774649187592319\n",
      "ma F1:  0.881179180212223\n",
      "mi F1:  0.893652410047522\n",
      "we F1:  0.8913668491274657\n",
      "29460 461\n",
      "Loss:  0.06403689086437225\n",
      "Loss:  0.038017865270376205\n",
      "Loss:  0.08771505951881409\n",
      "15 **********\n",
      "Epoch:  1514.4446818828583  fold:  3  kers:  128\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.08190175890922546\n",
      "Loss:  0.08387590944766998\n",
      "Loss:  0.052864089608192444\n",
      "16 **********\n",
      "Epoch:  1594.889588356018  fold:  3  kers:  128\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.05192078277468681\n",
      "Loss:  0.057380832731723785\n",
      "Loss:  0.06859874725341797\n",
      "17 **********\n",
      "Epoch:  1675.3075671195984  fold:  3  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.4194088578224182\n",
      "Eval Loss:  0.1604478806257248\n",
      "Eval Loss:  0.946415364742279\n",
      "[[1219  317]\n",
      " [ 525 1370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74      1536\n",
      "           1       0.81      0.72      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.76      3431\n",
      "\n",
      "acc:  0.7545904983969688\n",
      "pre:  0.8120924718435092\n",
      "rec:  0.7229551451187335\n",
      "ma F1:  0.7541142364941238\n",
      "mi F1:  0.7545904983969688\n",
      "we F1:  0.7552465412830071\n",
      "Eval Loss:  0.24810154736042023\n",
      "Eval Loss:  0.3166864812374115\n",
      "Eval Loss:  0.18127842247486115\n",
      "Eval Loss:  0.16786666214466095\n",
      "Eval Loss:  0.2433558851480484\n",
      "Eval Loss:  0.16824373602867126\n",
      "Eval Loss:  0.21613502502441406\n",
      "Eval Loss:  0.2773273289203644\n",
      "Eval Loss:  0.22986963391304016\n",
      "Eval Loss:  0.22173982858657837\n",
      "Eval Loss:  0.2770991325378418\n",
      "Eval Loss:  0.24446932971477509\n",
      "Eval Loss:  0.31485190987586975\n",
      "Eval Loss:  0.16666769981384277\n",
      "Eval Loss:  0.22655661404132843\n",
      "Eval Loss:  0.186662957072258\n",
      "Eval Loss:  0.22932548820972443\n",
      "Eval Loss:  0.1901065856218338\n",
      "Eval Loss:  0.18851704895496368\n",
      "Eval Loss:  0.23605577647686005\n",
      "Eval Loss:  0.19649040699005127\n",
      "Eval Loss:  0.3005635440349579\n",
      "Eval Loss:  0.2958522140979767\n",
      "Eval Loss:  0.17988842725753784\n",
      "Eval Loss:  0.2589476704597473\n",
      "Eval Loss:  0.24054723978042603\n",
      "Eval Loss:  0.26206064224243164\n",
      "Eval Loss:  0.2289992868900299\n",
      "[[17350  1278]\n",
      " [ 1358  9474]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18628\n",
      "           1       0.88      0.87      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9105227427019688\n",
      "pre:  0.8811383928571429\n",
      "rec:  0.8746307237813885\n",
      "ma F1:  0.9036351991483824\n",
      "mi F1:  0.9105227427019688\n",
      "we F1:  0.9104527828893371\n",
      "29460 461\n",
      "Loss:  0.07939457893371582\n",
      "Loss:  0.04839314520359039\n",
      "Loss:  0.05195969343185425\n",
      "18 **********\n",
      "Epoch:  1798.8542284965515  fold:  3  kers:  128\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.05869252607226372\n",
      "Loss:  0.09081833809614182\n",
      "Loss:  0.060436856001615524\n",
      "19 **********\n",
      "Epoch:  1879.251263141632  fold:  3  kers:  128\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.06860005110502243\n",
      "Loss:  0.059093259274959564\n",
      "Loss:  0.052911847829818726\n",
      "20 **********\n",
      "Epoch:  1959.6692419052124  fold:  3  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.535207986831665\n",
      "Eval Loss:  0.22931556403636932\n",
      "Eval Loss:  1.2582157850265503\n",
      "[[1257  279]\n",
      " [ 626 1269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.74      1536\n",
      "           1       0.82      0.67      0.74      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.74      0.74      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7362285048090935\n",
      "pre:  0.8197674418604651\n",
      "rec:  0.6696569920844327\n",
      "ma F1:  0.7362252781414822\n",
      "mi F1:  0.7362285048090936\n",
      "we F1:  0.736321809280856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3128416836261749\n",
      "Eval Loss:  0.35948318243026733\n",
      "Eval Loss:  0.15773971378803253\n",
      "Eval Loss:  0.18707513809204102\n",
      "Eval Loss:  0.23187591135501862\n",
      "Eval Loss:  0.17659533023834229\n",
      "Eval Loss:  0.24146457016468048\n",
      "Eval Loss:  0.28194373846054077\n",
      "Eval Loss:  0.22416488826274872\n",
      "Eval Loss:  0.24867555499076843\n",
      "Eval Loss:  0.23977676033973694\n",
      "Eval Loss:  0.27678343653678894\n",
      "Eval Loss:  0.3424960970878601\n",
      "Eval Loss:  0.17524942755699158\n",
      "Eval Loss:  0.2638069689273834\n",
      "Eval Loss:  0.19617830216884613\n",
      "Eval Loss:  0.2311852127313614\n",
      "Eval Loss:  0.2075284868478775\n",
      "Eval Loss:  0.22684696316719055\n",
      "Eval Loss:  0.26193785667419434\n",
      "Eval Loss:  0.20052962005138397\n",
      "Eval Loss:  0.3242790997028351\n",
      "Eval Loss:  0.31577590107917786\n",
      "Eval Loss:  0.19785483181476593\n",
      "Eval Loss:  0.2581351399421692\n",
      "Eval Loss:  0.25819817185401917\n",
      "Eval Loss:  0.3176843523979187\n",
      "Eval Loss:  0.2330528199672699\n",
      "[[17813   815]\n",
      " [ 1811  9021]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18628\n",
      "           1       0.92      0.83      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9108621860149355\n",
      "pre:  0.9171411142740952\n",
      "rec:  0.8328101920236337\n",
      "ma F1:  0.9021468379121753\n",
      "mi F1:  0.9108621860149355\n",
      "we F1:  0.9098748695101188\n",
      "29460 461\n",
      "Loss:  0.06601320207118988\n",
      "Loss:  0.09776418656110764\n",
      "Loss:  0.08822234719991684\n",
      "21 **********\n",
      "Epoch:  2083.3465535640717  fold:  3  kers:  128\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.04633096605539322\n",
      "Loss:  0.0403464175760746\n",
      "Loss:  0.07938180863857269\n",
      "22 **********\n",
      "Epoch:  2163.7824845314026  fold:  3  kers:  128\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.061162736266851425\n",
      "Loss:  0.0643739402294159\n",
      "Loss:  0.051315877586603165\n",
      "23 **********\n",
      "Epoch:  2244.246340274811  fold:  3  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.48373013734817505\n",
      "Eval Loss:  0.17101933062076569\n",
      "Eval Loss:  1.2712053060531616\n",
      "[[1244  292]\n",
      " [ 590 1305]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74      1536\n",
      "           1       0.82      0.69      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7429320897697465\n",
      "pre:  0.8171571696931748\n",
      "rec:  0.6886543535620053\n",
      "ma F1:  0.7428508060815566\n",
      "mi F1:  0.7429320897697465\n",
      "we F1:  0.7433291805743466\n",
      "Eval Loss:  0.2631914019584656\n",
      "Eval Loss:  0.2715024948120117\n",
      "Eval Loss:  0.15558545291423798\n",
      "Eval Loss:  0.1810784488916397\n",
      "Eval Loss:  0.24402576684951782\n",
      "Eval Loss:  0.14488759636878967\n",
      "Eval Loss:  0.22070428729057312\n",
      "Eval Loss:  0.2802821099758148\n",
      "Eval Loss:  0.21375325322151184\n",
      "Eval Loss:  0.2089620679616928\n",
      "Eval Loss:  0.24226243793964386\n",
      "Eval Loss:  0.2300805151462555\n",
      "Eval Loss:  0.3099042475223541\n",
      "Eval Loss:  0.13838641345500946\n",
      "Eval Loss:  0.23730768263339996\n",
      "Eval Loss:  0.17083565890789032\n",
      "Eval Loss:  0.2055099904537201\n",
      "Eval Loss:  0.1706392616033554\n",
      "Eval Loss:  0.20620037615299225\n",
      "Eval Loss:  0.23810788989067078\n",
      "Eval Loss:  0.17652744054794312\n",
      "Eval Loss:  0.3122667372226715\n",
      "Eval Loss:  0.3209960460662842\n",
      "Eval Loss:  0.15508317947387695\n",
      "Eval Loss:  0.2384614497423172\n",
      "Eval Loss:  0.22481974959373474\n",
      "Eval Loss:  0.2783801257610321\n",
      "Eval Loss:  0.19161076843738556\n",
      "[[17581  1047]\n",
      " [ 1320  9512]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18628\n",
      "           1       0.90      0.88      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9196537678207739\n",
      "pre:  0.9008428828487546\n",
      "rec:  0.878138847858198\n",
      "ma F1:  0.9131373808552476\n",
      "mi F1:  0.9196537678207739\n",
      "we F1:  0.9194332976706204\n",
      "29460 461\n",
      "Loss:  0.05806766450405121\n",
      "Loss:  0.06450589746236801\n",
      "Loss:  0.05295732989907265\n",
      "24 **********\n",
      "Epoch:  2367.800980091095  fold:  3  kers:  128\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.07135009765625\n",
      "Loss:  0.04659344628453255\n",
      "Loss:  0.05168991908431053\n",
      "25 **********\n",
      "Epoch:  2448.244889497757  fold:  3  kers:  128\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.04334282502532005\n",
      "Loss:  0.025784697383642197\n",
      "Loss:  0.03888741135597229\n",
      "26 **********\n",
      "Epoch:  2528.6907935142517  fold:  3  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.5413088798522949\n",
      "Eval Loss:  0.19225797057151794\n",
      "Eval Loss:  1.1584646701812744\n",
      "[[1241  295]\n",
      " [ 609 1286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73      1536\n",
      "           1       0.81      0.68      0.74      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.74      0.74      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7365199650247741\n",
      "pre:  0.8134092346616065\n",
      "rec:  0.6786279683377309\n",
      "ma F1:  0.7364746329059548\n",
      "mi F1:  0.736519965024774\n",
      "we F1:  0.7368362824760918\n",
      "Eval Loss:  0.2516270577907562\n",
      "Eval Loss:  0.28785401582717896\n",
      "Eval Loss:  0.14319297671318054\n",
      "Eval Loss:  0.1670839488506317\n",
      "Eval Loss:  0.24668245017528534\n",
      "Eval Loss:  0.14085906744003296\n",
      "Eval Loss:  0.22051818668842316\n",
      "Eval Loss:  0.2647607624530792\n",
      "Eval Loss:  0.2247033715248108\n",
      "Eval Loss:  0.18107861280441284\n",
      "Eval Loss:  0.2322562336921692\n",
      "Eval Loss:  0.2504429519176483\n",
      "Eval Loss:  0.3328576982021332\n",
      "Eval Loss:  0.1288062334060669\n",
      "Eval Loss:  0.2331102341413498\n",
      "Eval Loss:  0.15282101929187775\n",
      "Eval Loss:  0.21863946318626404\n",
      "Eval Loss:  0.17892305552959442\n",
      "Eval Loss:  0.21182502806186676\n",
      "Eval Loss:  0.24137860536575317\n",
      "Eval Loss:  0.17372463643550873\n",
      "Eval Loss:  0.315583199262619\n",
      "Eval Loss:  0.297053724527359\n",
      "Eval Loss:  0.1416763961315155\n",
      "Eval Loss:  0.25098517537117004\n",
      "Eval Loss:  0.2321457862854004\n",
      "Eval Loss:  0.2910485863685608\n",
      "Eval Loss:  0.21378688514232635\n",
      "[[17766   862]\n",
      " [ 1490  9342]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18628\n",
      "           1       0.92      0.86      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.920162932790224\n",
      "pre:  0.9155233241865935\n",
      "rec:  0.8624446085672083\n",
      "ma F1:  0.9130537071071069\n",
      "mi F1:  0.920162932790224\n",
      "we F1:  0.9196329477796592\n",
      "29460 461\n",
      "Loss:  0.040880996733903885\n",
      "Loss:  0.057777516543865204\n",
      "Loss:  0.06717649102210999\n",
      "27 **********\n",
      "Epoch:  2652.1437060832977  fold:  3  kers:  128\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.06874852627515793\n",
      "Loss:  0.03211706504225731\n",
      "Loss:  0.058798711746931076\n",
      "28 **********\n",
      "Epoch:  2732.585620164871  fold:  3  kers:  128\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.046576619148254395\n",
      "Loss:  0.023085517808794975\n",
      "Loss:  0.046127088367938995\n",
      "29 **********\n",
      "Epoch:  2813.284847021103  fold:  3  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.5845155119895935\n",
      "Eval Loss:  0.13644209504127502\n",
      "Eval Loss:  1.2431010007858276\n",
      "[[1242  294]\n",
      " [ 639 1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73      1536\n",
      "           1       0.81      0.66      0.73      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.74      0.74      0.73      3431\n",
      "weighted avg       0.74      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7280676187700379\n",
      "pre:  0.8103225806451613\n",
      "rec:  0.6627968337730871\n",
      "ma F1:  0.7280630910163601\n",
      "mi F1:  0.7280676187700379\n",
      "we F1:  0.7281791955570956\n",
      "Eval Loss:  0.25916561484336853\n",
      "Eval Loss:  0.2765136957168579\n",
      "Eval Loss:  0.1656150370836258\n",
      "Eval Loss:  0.14802679419517517\n",
      "Eval Loss:  0.25509002804756165\n",
      "Eval Loss:  0.14840877056121826\n",
      "Eval Loss:  0.2153371423482895\n",
      "Eval Loss:  0.2461702525615692\n",
      "Eval Loss:  0.2541811466217041\n",
      "Eval Loss:  0.18506371974945068\n",
      "Eval Loss:  0.2336474061012268\n",
      "Eval Loss:  0.23606348037719727\n",
      "Eval Loss:  0.2748696208000183\n",
      "Eval Loss:  0.10550239682197571\n",
      "Eval Loss:  0.23704463243484497\n",
      "Eval Loss:  0.16568748652935028\n",
      "Eval Loss:  0.19454246759414673\n",
      "Eval Loss:  0.15569734573364258\n",
      "Eval Loss:  0.21050216257572174\n",
      "Eval Loss:  0.25296398997306824\n",
      "Eval Loss:  0.17439040541648865\n",
      "Eval Loss:  0.2991103231906891\n",
      "Eval Loss:  0.32541942596435547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.15507689118385315\n",
      "Eval Loss:  0.24179981648921967\n",
      "Eval Loss:  0.23906324803829193\n",
      "Eval Loss:  0.26763415336608887\n",
      "Eval Loss:  0.17420007288455963\n",
      "[[17699   929]\n",
      " [ 1362  9470]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.91      0.87      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9222335369993211\n",
      "pre:  0.910664486969901\n",
      "rec:  0.8742614475627769\n",
      "ma F1:  0.9156523928031612\n",
      "mi F1:  0.9222335369993211\n",
      "we F1:  0.921887245173226\n",
      "29460 461\n",
      "Loss:  0.07249555736780167\n",
      "Loss:  0.07735613733530045\n",
      "Loss:  0.040511634200811386\n",
      "30 **********\n",
      "Epoch:  2936.9222660064697  fold:  3  kers:  128\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.04971969127655029\n",
      "Loss:  0.045710667967796326\n",
      "Loss:  0.044711675494909286\n",
      "31 **********\n",
      "Epoch:  3017.3771455287933  fold:  3  kers:  128\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.05325055122375488\n",
      "Loss:  0.04204341024160385\n",
      "Loss:  0.02978813834488392\n",
      "32 **********\n",
      "Epoch:  3097.7921330928802  fold:  3  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.4990643262863159\n",
      "Eval Loss:  0.17687883973121643\n",
      "Eval Loss:  1.3616291284561157\n",
      "[[1246  290]\n",
      " [ 641 1254]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73      1536\n",
      "           1       0.81      0.66      0.73      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.74      0.74      0.73      3431\n",
      "weighted avg       0.74      0.73      0.73      3431\n",
      "\n",
      "acc:  0.728650539201399\n",
      "pre:  0.8121761658031088\n",
      "rec:  0.6617414248021108\n",
      "ma F1:  0.7286490639370009\n",
      "mi F1:  0.728650539201399\n",
      "we F1:  0.7287152664268725\n",
      "Eval Loss:  0.29703855514526367\n",
      "Eval Loss:  0.2632668614387512\n",
      "Eval Loss:  0.16052192449569702\n",
      "Eval Loss:  0.13631831109523773\n",
      "Eval Loss:  0.23399363458156586\n",
      "Eval Loss:  0.11980769038200378\n",
      "Eval Loss:  0.20373225212097168\n",
      "Eval Loss:  0.22511395812034607\n",
      "Eval Loss:  0.2160813957452774\n",
      "Eval Loss:  0.17957670986652374\n",
      "Eval Loss:  0.23068828880786896\n",
      "Eval Loss:  0.24458764493465424\n",
      "Eval Loss:  0.27501004934310913\n",
      "Eval Loss:  0.14014197885990143\n",
      "Eval Loss:  0.23114193975925446\n",
      "Eval Loss:  0.17423242330551147\n",
      "Eval Loss:  0.20146417617797852\n",
      "Eval Loss:  0.14029419422149658\n",
      "Eval Loss:  0.21215224266052246\n",
      "Eval Loss:  0.24837777018547058\n",
      "Eval Loss:  0.18131783604621887\n",
      "Eval Loss:  0.3036903142929077\n",
      "Eval Loss:  0.2758104205131531\n",
      "Eval Loss:  0.14416617155075073\n",
      "Eval Loss:  0.22076396644115448\n",
      "Eval Loss:  0.20629841089248657\n",
      "Eval Loss:  0.24976634979248047\n",
      "Eval Loss:  0.1882522702217102\n",
      "[[17848   780]\n",
      " [ 1466  9366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18628\n",
      "           1       0.92      0.86      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9237610319076714\n",
      "pre:  0.9231224127735068\n",
      "rec:  0.8646602658788775\n",
      "ma F1:  0.9168699209167217\n",
      "mi F1:  0.9237610319076714\n",
      "we F1:  0.9232036984792594\n",
      "29460 461\n",
      "Loss:  0.049614403396844864\n",
      "Loss:  0.06643294543027878\n",
      "Loss:  0.05231744050979614\n",
      "33 **********\n",
      "Epoch:  3221.3377969264984  fold:  3  kers:  128\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.05466025322675705\n",
      "Loss:  0.05670426785945892\n",
      "Loss:  0.04418649151921272\n",
      "34 **********\n",
      "Epoch:  3301.7507886886597  fold:  3  kers:  128\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.07272965461015701\n",
      "Loss:  0.042445603758096695\n",
      "Loss:  0.04254637658596039\n",
      "35 **********\n",
      "Epoch:  3382.154804468155  fold:  3  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.510193943977356\n",
      "Eval Loss:  0.14191710948944092\n",
      "Eval Loss:  1.2030969858169556\n",
      "[[1243  293]\n",
      " [ 633 1262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73      1536\n",
      "           1       0.81      0.67      0.73      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.74      0.74      0.73      3431\n",
      "weighted avg       0.74      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7301078402798018\n",
      "pre:  0.8115755627009646\n",
      "rec:  0.6659630606860159\n",
      "ma F1:  0.7300995633484548\n",
      "mi F1:  0.7301078402798017\n",
      "we F1:  0.7302559537881179\n",
      "Eval Loss:  0.2653917968273163\n",
      "Eval Loss:  0.25466302037239075\n",
      "Eval Loss:  0.15744411945343018\n",
      "Eval Loss:  0.1584683358669281\n",
      "Eval Loss:  0.26297226548194885\n",
      "Eval Loss:  0.12865357100963593\n",
      "Eval Loss:  0.2067718654870987\n",
      "Eval Loss:  0.234796404838562\n",
      "Eval Loss:  0.21501052379608154\n",
      "Eval Loss:  0.13471192121505737\n",
      "Eval Loss:  0.24445849657058716\n",
      "Eval Loss:  0.22254155576229095\n",
      "Eval Loss:  0.2724640667438507\n",
      "Eval Loss:  0.11850026994943619\n",
      "Eval Loss:  0.24495330452919006\n",
      "Eval Loss:  0.1640888750553131\n",
      "Eval Loss:  0.21631138026714325\n",
      "Eval Loss:  0.1454828530550003\n",
      "Eval Loss:  0.19149433076381683\n",
      "Eval Loss:  0.25631022453308105\n",
      "Eval Loss:  0.19549040496349335\n",
      "Eval Loss:  0.31313514709472656\n",
      "Eval Loss:  0.26094159483909607\n",
      "Eval Loss:  0.12935924530029297\n",
      "Eval Loss:  0.24325576424598694\n",
      "Eval Loss:  0.19884933531284332\n",
      "Eval Loss:  0.255258709192276\n",
      "Eval Loss:  0.1815502643585205\n",
      "[[17661   967]\n",
      " [ 1264  9568]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.91      0.88      0.90     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9242701968771215\n",
      "pre:  0.9082107261509255\n",
      "rec:  0.8833087149187593\n",
      "ma F1:  0.9180886421106107\n",
      "mi F1:  0.9242701968771215\n",
      "we F1:  0.9240433438231671\n",
      "29460 461\n",
      "Loss:  0.08189224451780319\n",
      "Loss:  0.06251241266727448\n",
      "Loss:  0.09335052222013474\n",
      "36 **********\n",
      "Epoch:  3505.6306550502777  fold:  3  kers:  128\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.05469056963920593\n",
      "Loss:  0.09235195070505142\n",
      "Loss:  0.044293954968452454\n",
      "37 **********\n",
      "Epoch:  3586.048633813858  fold:  3  kers:  128\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.03524651750922203\n",
      "Loss:  0.04154907912015915\n",
      "Loss:  0.0314495749771595\n",
      "38 **********\n",
      "Epoch:  3666.4686074256897  fold:  3  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.3814069628715515\n",
      "Eval Loss:  0.11387699842453003\n",
      "Eval Loss:  1.1616389751434326\n",
      "[[1226  310]\n",
      " [ 601 1294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73      1536\n",
      "           1       0.81      0.68      0.74      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.74      0.74      0.73      3431\n",
      "weighted avg       0.75      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7344797435150102\n",
      "pre:  0.8067331670822943\n",
      "rec:  0.6828496042216359\n",
      "ma F1:  0.734375404994435\n",
      "mi F1:  0.7344797435150102\n",
      "we F1:  0.7349262510074722\n",
      "Eval Loss:  0.2424580454826355\n",
      "Eval Loss:  0.2478712648153305\n",
      "Eval Loss:  0.14135192334651947\n",
      "Eval Loss:  0.12247049808502197\n",
      "Eval Loss:  0.21718831360340118\n",
      "Eval Loss:  0.12249905616044998\n",
      "Eval Loss:  0.19793103635311127\n",
      "Eval Loss:  0.19856753945350647\n",
      "Eval Loss:  0.18934664130210876\n",
      "Eval Loss:  0.19776389002799988\n",
      "Eval Loss:  0.22067929804325104\n",
      "Eval Loss:  0.24654299020767212\n",
      "Eval Loss:  0.22487130761146545\n",
      "Eval Loss:  0.12434030324220657\n",
      "Eval Loss:  0.19672715663909912\n",
      "Eval Loss:  0.1580134630203247\n",
      "Eval Loss:  0.17677022516727448\n",
      "Eval Loss:  0.11294173449277878\n",
      "Eval Loss:  0.19317394495010376\n",
      "Eval Loss:  0.23046544194221497\n",
      "Eval Loss:  0.18093585968017578\n",
      "Eval Loss:  0.2808804512023926\n",
      "Eval Loss:  0.26834896206855774\n",
      "Eval Loss:  0.1224856749176979\n",
      "Eval Loss:  0.20255951583385468\n",
      "Eval Loss:  0.17902766168117523\n",
      "Eval Loss:  0.23184892535209656\n",
      "Eval Loss:  0.15320931375026703\n",
      "[[17887   741]\n",
      " [ 1291  9541]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95     18628\n",
      "           1       0.93      0.88      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9310251188051596\n",
      "pre:  0.9279323088893211\n",
      "rec:  0.8808161004431314\n",
      "ma F1:  0.9250062278583306\n",
      "mi F1:  0.9310251188051596\n",
      "we F1:  0.9306284749014024\n",
      "29460 461\n",
      "Loss:  0.04084949940443039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.068003810942173\n",
      "Loss:  0.06900754570960999\n",
      "39 **********\n",
      "Epoch:  3790.1159987449646  fold:  3  kers:  128\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.049800559878349304\n",
      "Loss:  0.056340593844652176\n",
      "Loss:  0.052283257246017456\n",
      "40 **********\n",
      "Epoch:  3870.5349752902985  fold:  3  kers:  128\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.03408895805478096\n",
      "Loss:  0.04932676628232002\n",
      "Loss:  0.07981260865926743\n",
      "41 **********\n",
      "Epoch:  3950.952954053879  fold:  3  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.2855663001537323\n",
      "Eval Loss:  0.08189985901117325\n",
      "Eval Loss:  1.1057993173599243\n",
      "[[1155  381]\n",
      " [ 538 1357]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.72      1536\n",
      "           1       0.78      0.72      0.75      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.73      0.73      0.73      3431\n",
      "weighted avg       0.74      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7321480617895657\n",
      "pre:  0.7807825086306099\n",
      "rec:  0.7160949868073878\n",
      "ma F1:  0.7312163875462163\n",
      "mi F1:  0.7321480617895657\n",
      "we F1:  0.7328721848400896\n",
      "Eval Loss:  0.2544841170310974\n",
      "Eval Loss:  0.2118348330259323\n",
      "Eval Loss:  0.165595144033432\n",
      "Eval Loss:  0.15740357339382172\n",
      "Eval Loss:  0.2868095636367798\n",
      "Eval Loss:  0.11501909792423248\n",
      "Eval Loss:  0.17287826538085938\n",
      "Eval Loss:  0.250705361366272\n",
      "Eval Loss:  0.21954455971717834\n",
      "Eval Loss:  0.1329018771648407\n",
      "Eval Loss:  0.22541122138500214\n",
      "Eval Loss:  0.19087150692939758\n",
      "Eval Loss:  0.25910595059394836\n",
      "Eval Loss:  0.10607195645570755\n",
      "Eval Loss:  0.2025359869003296\n",
      "Eval Loss:  0.1591547727584839\n",
      "Eval Loss:  0.19561365246772766\n",
      "Eval Loss:  0.14733725786209106\n",
      "Eval Loss:  0.17980748414993286\n",
      "Eval Loss:  0.20958258211612701\n",
      "Eval Loss:  0.20877289772033691\n",
      "Eval Loss:  0.2548341751098633\n",
      "Eval Loss:  0.26656612753868103\n",
      "Eval Loss:  0.15012773871421814\n",
      "Eval Loss:  0.24652980268001556\n",
      "Eval Loss:  0.19549036026000977\n",
      "Eval Loss:  0.260630339384079\n",
      "Eval Loss:  0.15995916724205017\n",
      "[[17388  1240]\n",
      " [  935  9897]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18628\n",
      "           1       0.89      0.91      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9261710794297352\n",
      "pre:  0.8886594235431444\n",
      "rec:  0.9136816838995568\n",
      "ma F1:  0.921067561699207\n",
      "mi F1:  0.9261710794297352\n",
      "we F1:  0.9263788718349963\n",
      "29460 461\n",
      "Loss:  0.03925567865371704\n",
      "Loss:  0.05274398252367973\n",
      "Loss:  0.053597308695316315\n",
      "42 **********\n",
      "Epoch:  4074.607326745987  fold:  3  kers:  128\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.0585937537252903\n",
      "Loss:  0.03176916390657425\n",
      "Loss:  0.06694988906383514\n",
      "43 **********\n",
      "Epoch:  4155.068191051483  fold:  3  kers:  128\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.09230750799179077\n",
      "Loss:  0.04456579312682152\n",
      "Loss:  0.06975487619638443\n",
      "44 **********\n",
      "Epoch:  4235.518084049225  fold:  3  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.3470589816570282\n",
      "Eval Loss:  0.08375050872564316\n",
      "Eval Loss:  1.2018284797668457\n",
      "[[1176  360]\n",
      " [ 594 1301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71      1536\n",
      "           1       0.78      0.69      0.73      1895\n",
      "\n",
      "    accuracy                           0.72      3431\n",
      "   macro avg       0.72      0.73      0.72      3431\n",
      "weighted avg       0.73      0.72      0.72      3431\n",
      "\n",
      "acc:  0.7219469542407462\n",
      "pre:  0.7832630945213727\n",
      "rec:  0.6865435356200528\n",
      "ma F1:  0.7215773958382244\n",
      "mi F1:  0.7219469542407462\n",
      "we F1:  0.722638767570267\n",
      "Eval Loss:  0.22292156517505646\n",
      "Eval Loss:  0.20190349221229553\n",
      "Eval Loss:  0.1525396704673767\n",
      "Eval Loss:  0.14989714324474335\n",
      "Eval Loss:  0.2618773579597473\n",
      "Eval Loss:  0.10709076374769211\n",
      "Eval Loss:  0.1618863046169281\n",
      "Eval Loss:  0.2305387705564499\n",
      "Eval Loss:  0.21220393478870392\n",
      "Eval Loss:  0.1237918809056282\n",
      "Eval Loss:  0.23309700191020966\n",
      "Eval Loss:  0.19952033460140228\n",
      "Eval Loss:  0.23569738864898682\n",
      "Eval Loss:  0.10077732801437378\n",
      "Eval Loss:  0.2101719230413437\n",
      "Eval Loss:  0.16460460424423218\n",
      "Eval Loss:  0.2044852077960968\n",
      "Eval Loss:  0.1374325454235077\n",
      "Eval Loss:  0.1814856380224228\n",
      "Eval Loss:  0.21386761963367462\n",
      "Eval Loss:  0.18913814425468445\n",
      "Eval Loss:  0.2591981291770935\n",
      "Eval Loss:  0.2510712742805481\n",
      "Eval Loss:  0.13939620554447174\n",
      "Eval Loss:  0.21695251762866974\n",
      "Eval Loss:  0.18509052693843842\n",
      "Eval Loss:  0.26194798946380615\n",
      "Eval Loss:  0.16267479956150055\n",
      "[[17542  1086]\n",
      " [  972  9860]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     18628\n",
      "           1       0.90      0.91      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.930142566191446\n",
      "pre:  0.9007856751324684\n",
      "rec:  0.9102658788774003\n",
      "ma F1:  0.9250459966498108\n",
      "mi F1:  0.930142566191446\n",
      "we F1:  0.9302181986996141\n",
      "29460 461\n",
      "Loss:  0.07199349254369736\n",
      "Loss:  0.035952482372522354\n",
      "Loss:  0.04212488606572151\n",
      "45 **********\n",
      "Epoch:  4358.95304441452  fold:  3  kers:  128\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.04207926243543625\n",
      "Loss:  0.033193543553352356\n",
      "Loss:  0.07101105153560638\n",
      "46 **********\n",
      "Epoch:  4439.35307097435  fold:  3  kers:  128\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.04195704683661461\n",
      "Loss:  0.047819387167692184\n",
      "Loss:  0.05424060299992561\n",
      "47 **********\n",
      "Epoch:  4519.804959058762  fold:  3  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.24937212467193604\n",
      "Eval Loss:  0.09617595374584198\n",
      "Eval Loss:  1.1326589584350586\n",
      "[[1147  389]\n",
      " [ 530 1365]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71      1536\n",
      "           1       0.78      0.72      0.75      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.73      0.73      0.73      3431\n",
      "weighted avg       0.74      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7321480617895657\n",
      "pre:  0.7782212086659065\n",
      "rec:  0.7203166226912929\n",
      "ma F1:  0.731062328405678\n",
      "mi F1:  0.7321480617895657\n",
      "we F1:  0.7328503021892364\n",
      "Eval Loss:  0.2029174268245697\n",
      "Eval Loss:  0.22470970451831818\n",
      "Eval Loss:  0.14791469275951385\n",
      "Eval Loss:  0.17369860410690308\n",
      "Eval Loss:  0.24698559939861298\n",
      "Eval Loss:  0.1115981936454773\n",
      "Eval Loss:  0.16458016633987427\n",
      "Eval Loss:  0.21071285009384155\n",
      "Eval Loss:  0.21931393444538116\n",
      "Eval Loss:  0.12744930386543274\n",
      "Eval Loss:  0.24845832586288452\n",
      "Eval Loss:  0.1851644068956375\n",
      "Eval Loss:  0.23127132654190063\n",
      "Eval Loss:  0.10094457864761353\n",
      "Eval Loss:  0.19976553320884705\n",
      "Eval Loss:  0.13165128231048584\n",
      "Eval Loss:  0.17392022907733917\n",
      "Eval Loss:  0.14755184948444366\n",
      "Eval Loss:  0.1860046088695526\n",
      "Eval Loss:  0.2012709528207779\n",
      "Eval Loss:  0.20144031941890717\n",
      "Eval Loss:  0.23938138782978058\n",
      "Eval Loss:  0.23917043209075928\n",
      "Eval Loss:  0.1484115868806839\n",
      "Eval Loss:  0.21111294627189636\n",
      "Eval Loss:  0.17578265070915222\n",
      "Eval Loss:  0.24153152108192444\n",
      "Eval Loss:  0.1537373811006546\n",
      "[[17425  1203]\n",
      " [  849  9983]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     18628\n",
      "           1       0.89      0.92      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9303462321792261\n",
      "pre:  0.8924548542821383\n",
      "rec:  0.9216211225997046\n",
      "ma F1:  0.9255983911035703\n",
      "mi F1:  0.9303462321792261\n",
      "we F1:  0.9305720768098069\n",
      "29460 461\n",
      "Loss:  0.07235745340585709\n",
      "Loss:  0.029179148375988007\n",
      "Loss:  0.04253622889518738\n",
      "48 **********\n",
      "Epoch:  4643.411460638046  fold:  3  kers:  128\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.041667379438877106\n",
      "Loss:  0.053973738104104996\n",
      "Loss:  0.05025295540690422\n",
      "49 **********\n",
      "Epoch:  4723.827444553375  fold:  3  kers:  128\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.05560833215713501\n",
      "Loss:  0.034943677484989166\n",
      "Loss:  0.04037521034479141\n",
      "50 **********\n",
      "Epoch:  4804.270356178284  fold:  3  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.40170520544052124\n",
      "Eval Loss:  0.10716544091701508\n",
      "Eval Loss:  1.23447585105896\n",
      "[[1194  342]\n",
      " [ 616 1279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.78      0.71      1536\n",
      "           1       0.79      0.67      0.73      1895\n",
      "\n",
      "    accuracy                           0.72      3431\n",
      "   macro avg       0.72      0.73      0.72      3431\n",
      "weighted avg       0.73      0.72      0.72      3431\n",
      "\n",
      "acc:  0.7207811133780239\n",
      "pre:  0.7890191239975324\n",
      "rec:  0.674934036939314\n",
      "ma F1:  0.7206096356031382\n",
      "mi F1:  0.7207811133780239\n",
      "we F1:  0.7213338770288322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.231377512216568\n",
      "Eval Loss:  0.22515635192394257\n",
      "Eval Loss:  0.1653565615415573\n",
      "Eval Loss:  0.1330944299697876\n",
      "Eval Loss:  0.23865917325019836\n",
      "Eval Loss:  0.10509415715932846\n",
      "Eval Loss:  0.1780899167060852\n",
      "Eval Loss:  0.17534102499485016\n",
      "Eval Loss:  0.2028641700744629\n",
      "Eval Loss:  0.12359140813350677\n",
      "Eval Loss:  0.215143084526062\n",
      "Eval Loss:  0.17966975271701813\n",
      "Eval Loss:  0.20883440971374512\n",
      "Eval Loss:  0.08611557632684708\n",
      "Eval Loss:  0.19038720428943634\n",
      "Eval Loss:  0.14201584458351135\n",
      "Eval Loss:  0.16423441469669342\n",
      "Eval Loss:  0.13978056609630585\n",
      "Eval Loss:  0.1798391491174698\n",
      "Eval Loss:  0.22448132932186127\n",
      "Eval Loss:  0.1845734864473343\n",
      "Eval Loss:  0.23516570031642914\n",
      "Eval Loss:  0.2341524213552475\n",
      "Eval Loss:  0.15069293975830078\n",
      "Eval Loss:  0.20014937222003937\n",
      "Eval Loss:  0.1625373661518097\n",
      "Eval Loss:  0.24449649453163147\n",
      "Eval Loss:  0.13773393630981445\n",
      "[[17690   938]\n",
      " [  987  9845]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     18628\n",
      "           1       0.91      0.91      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9346571622539036\n",
      "pre:  0.9130112213669666\n",
      "rec:  0.9088810930576071\n",
      "ma F1:  0.9296699069256827\n",
      "mi F1:  0.9346571622539036\n",
      "we F1:  0.9346260117744793\n",
      "29460 461\n",
      "Loss:  0.05103905126452446\n",
      "Loss:  0.061533261090517044\n",
      "Loss:  0.0506618395447731\n",
      "51 **********\n",
      "Epoch:  4927.827988386154  fold:  3  kers:  128\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.028186481446027756\n",
      "Loss:  0.03703736141324043\n",
      "Loss:  0.05489541217684746\n",
      "52 **********\n",
      "Epoch:  5008.2369911670685  fold:  3  kers:  128\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.01904340833425522\n",
      "Loss:  0.04875964671373367\n",
      "Loss:  0.03345037251710892\n",
      "53 **********\n",
      "Epoch:  5088.671924352646  fold:  3  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.5805864930152893\n",
      "Eval Loss:  0.13810743391513824\n",
      "Eval Loss:  1.2548388242721558\n",
      "[[1275  261]\n",
      " [ 719 1176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.83      0.72      1536\n",
      "           1       0.82      0.62      0.71      1895\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.73      0.73      0.71      3431\n",
      "weighted avg       0.74      0.71      0.71      3431\n",
      "\n",
      "acc:  0.7143689886330515\n",
      "pre:  0.8183716075156576\n",
      "rec:  0.6205804749340369\n",
      "ma F1:  0.7141309781703049\n",
      "mi F1:  0.7143689886330515\n",
      "we F1:  0.7132678897245872\n",
      "Eval Loss:  0.24261130392551422\n",
      "Eval Loss:  0.28867584466934204\n",
      "Eval Loss:  0.13374574482440948\n",
      "Eval Loss:  0.13550429046154022\n",
      "Eval Loss:  0.21621011197566986\n",
      "Eval Loss:  0.11324713379144669\n",
      "Eval Loss:  0.220394104719162\n",
      "Eval Loss:  0.211155965924263\n",
      "Eval Loss:  0.20772984623908997\n",
      "Eval Loss:  0.17869675159454346\n",
      "Eval Loss:  0.17485389113426208\n",
      "Eval Loss:  0.23698750138282776\n",
      "Eval Loss:  0.22814185917377472\n",
      "Eval Loss:  0.11811056733131409\n",
      "Eval Loss:  0.2351367473602295\n",
      "Eval Loss:  0.16681288182735443\n",
      "Eval Loss:  0.19690175354480743\n",
      "Eval Loss:  0.15294110774993896\n",
      "Eval Loss:  0.217282235622406\n",
      "Eval Loss:  0.2693620026111603\n",
      "Eval Loss:  0.20204168558120728\n",
      "Eval Loss:  0.268170565366745\n",
      "Eval Loss:  0.23207148909568787\n",
      "Eval Loss:  0.15502619743347168\n",
      "Eval Loss:  0.1996007263660431\n",
      "Eval Loss:  0.1912979781627655\n",
      "Eval Loss:  0.24459825456142426\n",
      "Eval Loss:  0.18088503181934357\n",
      "[[18032   596]\n",
      " [ 1560  9272]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     18628\n",
      "           1       0.94      0.86      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.91      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.926816021724372\n",
      "pre:  0.9396027563842724\n",
      "rec:  0.8559822747415067\n",
      "ma F1:  0.9197175771088815\n",
      "mi F1:  0.9268160217243719\n",
      "we F1:  0.9260348686867771\n",
      "29460 461\n",
      "Loss:  0.026708140969276428\n",
      "Loss:  0.07928570359945297\n",
      "Loss:  0.06545049697160721\n",
      "54 **********\n",
      "Epoch:  5212.232547998428  fold:  3  kers:  128\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.058551378548145294\n",
      "Loss:  0.039863813668489456\n",
      "Loss:  0.03156932070851326\n",
      "55 **********\n",
      "Epoch:  5292.630580186844  fold:  3  kers:  128\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.044160716235637665\n",
      "Loss:  0.06275928765535355\n",
      "Loss:  0.031461987644433975\n",
      "56 **********\n",
      "Epoch:  5373.055540800095  fold:  3  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.4094091057777405\n",
      "Eval Loss:  0.04832059144973755\n",
      "Eval Loss:  1.2239497900009155\n",
      "[[1211  325]\n",
      " [ 605 1290]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72      1536\n",
      "           1       0.80      0.68      0.74      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.73      0.73      0.73      3431\n",
      "weighted avg       0.74      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7289419994170796\n",
      "pre:  0.7987616099071208\n",
      "rec:  0.6807387862796834\n",
      "ma F1:  0.7287982171633723\n",
      "mi F1:  0.7289419994170796\n",
      "we F1:  0.7294516074049028\n",
      "Eval Loss:  0.21042890846729279\n",
      "Eval Loss:  0.22885321080684662\n",
      "Eval Loss:  0.13759100437164307\n",
      "Eval Loss:  0.12372712790966034\n",
      "Eval Loss:  0.22305159270763397\n",
      "Eval Loss:  0.09948340058326721\n",
      "Eval Loss:  0.15975870192050934\n",
      "Eval Loss:  0.18124599754810333\n",
      "Eval Loss:  0.1748221069574356\n",
      "Eval Loss:  0.13744443655014038\n",
      "Eval Loss:  0.23186054825782776\n",
      "Eval Loss:  0.16761551797389984\n",
      "Eval Loss:  0.23810866475105286\n",
      "Eval Loss:  0.0967484638094902\n",
      "Eval Loss:  0.17421725392341614\n",
      "Eval Loss:  0.13657253980636597\n",
      "Eval Loss:  0.16301752626895905\n",
      "Eval Loss:  0.11965745687484741\n",
      "Eval Loss:  0.15300126373767853\n",
      "Eval Loss:  0.20092584192752838\n",
      "Eval Loss:  0.17508308589458466\n",
      "Eval Loss:  0.24166297912597656\n",
      "Eval Loss:  0.24669185280799866\n",
      "Eval Loss:  0.11499444395303726\n",
      "Eval Loss:  0.15913502871990204\n",
      "Eval Loss:  0.16257800161838531\n",
      "Eval Loss:  0.2060510516166687\n",
      "Eval Loss:  0.12578092515468597\n",
      "[[17733   895]\n",
      " [  981  9851]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     18628\n",
      "           1       0.92      0.91      0.91     10832\n",
      "\n",
      "    accuracy                           0.94     29460\n",
      "   macro avg       0.93      0.93      0.93     29460\n",
      "weighted avg       0.94      0.94      0.94     29460\n",
      "\n",
      "acc:  0.9363204344874406\n",
      "pre:  0.916713195607668\n",
      "rec:  0.9094350073855244\n",
      "ma F1:  0.9314106301048246\n",
      "mi F1:  0.9363204344874406\n",
      "we F1:  0.9362668639245244\n",
      "29460 461\n",
      "Loss:  0.03671013563871384\n",
      "Loss:  0.0656709298491478\n",
      "Loss:  0.03962360695004463\n",
      "57 **********\n",
      "Epoch:  5496.670020341873  fold:  3  kers:  128\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.04329656437039375\n",
      "Loss:  0.07166723906993866\n",
      "Loss:  0.01564059779047966\n",
      "58 **********\n",
      "Epoch:  5577.083012342453  fold:  3  kers:  128\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.02849859744310379\n",
      "Loss:  0.04435362666845322\n",
      "Loss:  0.04965978115797043\n",
      "59 **********\n",
      "Epoch:  5657.510964393616  fold:  3  kers:  128\n",
      "Eval Loss:  0.23365440964698792\n",
      "Eval Loss:  0.051698461174964905\n",
      "Eval Loss:  1.1819087266921997\n",
      "[[1170  366]\n",
      " [ 522 1373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72      1536\n",
      "           1       0.79      0.72      0.76      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.74      0.74      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.741183328475663\n",
      "pre:  0.78953421506613\n",
      "rec:  0.7245382585751979\n",
      "ma F1:  0.7402741149777095\n",
      "mi F1:  0.7411833284756629\n",
      "we F1:  0.7418820344149771\n",
      "update!  Acc:  0.7572136403380938\n",
      "Epoch:  5662.063791275024  fold:  3  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29520 3371\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29520 462\n",
      "Loss:  0.182927206158638\n",
      "Loss:  0.16380320489406586\n",
      "Loss:  0.1609133929014206\n",
      "0 **********\n",
      "Epoch:  92.80782651901245  fold:  4  kers:  128\n",
      "epoch:  1\n",
      "29520 462\n",
      "Loss:  0.15878072381019592\n",
      "Loss:  0.13342463970184326\n",
      "Loss:  0.12591002881526947\n",
      "1 **********\n",
      "Epoch:  173.37640261650085  fold:  4  kers:  128\n",
      "epoch:  2\n",
      "29520 462\n",
      "Loss:  0.1357264518737793\n",
      "Loss:  0.10298377275466919\n",
      "Loss:  0.11027728766202927\n",
      "2 **********\n",
      "Epoch:  253.94797110557556  fold:  4  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.1663484126329422\n",
      "Eval Loss:  0.19369511306285858\n",
      "Eval Loss:  0.08353040367364883\n",
      "[[3033  104]\n",
      " [ 217   17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3137\n",
      "           1       0.14      0.07      0.10       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.54      0.52      0.52      3371\n",
      "weighted avg       0.88      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9047760308513794\n",
      "pre:  0.14049586776859505\n",
      "rec:  0.07264957264957266\n",
      "ma F1:  0.522758155319895\n",
      "mi F1:  0.9047760308513794\n",
      "we F1:  0.8904630268941324\n",
      "update!  Acc:  0.9047760308513794\n",
      "Eval Loss:  0.5539959073066711\n",
      "Eval Loss:  0.5518230199813843\n",
      "Eval Loss:  0.38275763392448425\n",
      "Eval Loss:  0.4835786819458008\n",
      "Eval Loss:  0.4336996376514435\n",
      "Eval Loss:  0.45378825068473816\n",
      "Eval Loss:  0.5252328515052795\n",
      "Eval Loss:  0.42317765951156616\n",
      "Eval Loss:  0.5392500758171082\n",
      "Eval Loss:  0.48991549015045166\n",
      "Eval Loss:  0.4927864968776703\n",
      "Eval Loss:  0.46512702107429504\n",
      "Eval Loss:  0.556115984916687\n",
      "Eval Loss:  0.494141161441803\n",
      "Eval Loss:  0.5371689200401306\n",
      "Eval Loss:  0.43997061252593994\n",
      "Eval Loss:  0.4732990860939026\n",
      "Eval Loss:  0.5567337274551392\n",
      "Eval Loss:  0.5496805906295776\n",
      "Eval Loss:  0.5711809396743774\n",
      "Eval Loss:  0.4142477810382843\n",
      "Eval Loss:  0.5221388339996338\n",
      "Eval Loss:  0.5772454738616943\n",
      "Eval Loss:  0.5736557245254517\n",
      "Eval Loss:  0.45145919919013977\n",
      "Eval Loss:  0.38580912351608276\n",
      "Eval Loss:  0.5503891110420227\n",
      "Eval Loss:  0.4193928837776184\n",
      "[[15966  1061]\n",
      " [ 5270  7223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83     17027\n",
      "           1       0.87      0.58      0.70     12493\n",
      "\n",
      "    accuracy                           0.79     29520\n",
      "   macro avg       0.81      0.76      0.76     29520\n",
      "weighted avg       0.80      0.79      0.78     29520\n",
      "\n",
      "acc:  0.7855352303523035\n",
      "pre:  0.8719217769193627\n",
      "rec:  0.5781637717121588\n",
      "ma F1:  0.7649139769244822\n",
      "mi F1:  0.7855352303523035\n",
      "we F1:  0.7756078763916836\n",
      "29520 462\n",
      "Loss:  0.0967535525560379\n",
      "Loss:  0.0918569564819336\n",
      "Loss:  0.10154591500759125\n",
      "3 **********\n",
      "Epoch:  377.90254163742065  fold:  4  kers:  128\n",
      "epoch:  4\n",
      "29520 462\n",
      "Loss:  0.11152832210063934\n",
      "Loss:  0.08117669820785522\n",
      "Loss:  0.0836864709854126\n",
      "4 **********\n",
      "Epoch:  458.46214151382446  fold:  4  kers:  128\n",
      "epoch:  5\n",
      "29520 462\n",
      "Loss:  0.12013117969036102\n",
      "Loss:  0.08440440893173218\n",
      "Loss:  0.13830193877220154\n",
      "5 **********\n",
      "Epoch:  539.0406906604767  fold:  4  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.11743936687707901\n",
      "Eval Loss:  0.13162961602210999\n",
      "Eval Loss:  0.03339884430170059\n",
      "[[3114   23]\n",
      " [ 231    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.12      0.01      0.02       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.52      0.50      0.49      3371\n",
      "weighted avg       0.87      0.92      0.90      3371\n",
      "\n",
      "acc:  0.924651438742213\n",
      "pre:  0.11538461538461539\n",
      "rec:  0.01282051282051282\n",
      "ma F1:  0.49194574324163953\n",
      "mi F1:  0.924651438742213\n",
      "we F1:  0.8957209390108984\n",
      "update!  Acc:  0.924651438742213\n",
      "Eval Loss:  0.5413388013839722\n",
      "Eval Loss:  0.5642894506454468\n",
      "Eval Loss:  0.3974604606628418\n",
      "Eval Loss:  0.5609238743782043\n",
      "Eval Loss:  0.5067094564437866\n",
      "Eval Loss:  0.4749256372451782\n",
      "Eval Loss:  0.6317398548126221\n",
      "Eval Loss:  0.43437859416007996\n",
      "Eval Loss:  0.6102702617645264\n",
      "Eval Loss:  0.49615710973739624\n",
      "Eval Loss:  0.5770200490951538\n",
      "Eval Loss:  0.5010872483253479\n",
      "Eval Loss:  0.5758569836616516\n",
      "Eval Loss:  0.5050484538078308\n",
      "Eval Loss:  0.5739018321037292\n",
      "Eval Loss:  0.5181287527084351\n",
      "Eval Loss:  0.5156815052032471\n",
      "Eval Loss:  0.6388615369796753\n",
      "Eval Loss:  0.6330750584602356\n",
      "Eval Loss:  0.617522656917572\n",
      "Eval Loss:  0.4389230012893677\n",
      "Eval Loss:  0.539976954460144\n",
      "Eval Loss:  0.5943904519081116\n",
      "Eval Loss:  0.5585446357727051\n",
      "Eval Loss:  0.46840041875839233\n",
      "Eval Loss:  0.4223974943161011\n",
      "Eval Loss:  0.6250686645507812\n",
      "Eval Loss:  0.46949076652526855\n",
      "[[16662   365]\n",
      " [ 6021  6472]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.84     17027\n",
      "           1       0.95      0.52      0.67     12493\n",
      "\n",
      "    accuracy                           0.78     29520\n",
      "   macro avg       0.84      0.75      0.75     29520\n",
      "weighted avg       0.82      0.78      0.77     29520\n",
      "\n",
      "acc:  0.7836720867208672\n",
      "pre:  0.9466140119935644\n",
      "rec:  0.5180501080605139\n",
      "ma F1:  0.7544083899528697\n",
      "mi F1:  0.7836720867208672\n",
      "we F1:  0.7674291555216726\n",
      "29520 462\n",
      "Loss:  0.05056460574269295\n",
      "Loss:  0.05976325646042824\n",
      "Loss:  0.08740291744470596\n",
      "6 **********\n",
      "Epoch:  663.0421361923218  fold:  4  kers:  128\n",
      "epoch:  7\n",
      "29520 462\n",
      "Loss:  0.07411917299032211\n",
      "Loss:  0.08123718202114105\n",
      "Loss:  0.07232178747653961\n",
      "7 **********\n",
      "Epoch:  746.0282485485077  fold:  4  kers:  128\n",
      "epoch:  8\n",
      "29520 462\n",
      "Loss:  0.05632258579134941\n",
      "Loss:  0.06796054542064667\n",
      "Loss:  0.09992426633834839\n",
      "8 **********\n",
      "Epoch:  826.801276922226  fold:  4  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.09320779144763947\n",
      "Eval Loss:  0.12279391288757324\n",
      "Eval Loss:  0.029345238581299782\n",
      "[[3086   51]\n",
      " [ 224   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.16      0.04      0.07       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.55      0.51      0.51      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.918421833283892\n",
      "pre:  0.16393442622950818\n",
      "rec:  0.042735042735042736\n",
      "ma F1:  0.512570555743967\n",
      "mi F1:  0.918421833283892\n",
      "we F1:  0.8955959974534605\n",
      "Eval Loss:  0.39507654309272766\n",
      "Eval Loss:  0.40455666184425354\n",
      "Eval Loss:  0.29216140508651733\n",
      "Eval Loss:  0.4257369935512543\n",
      "Eval Loss:  0.3635461926460266\n",
      "Eval Loss:  0.38700029253959656\n",
      "Eval Loss:  0.45925000309944153\n",
      "Eval Loss:  0.342242568731308\n",
      "Eval Loss:  0.44439148902893066\n",
      "Eval Loss:  0.3538167178630829\n",
      "Eval Loss:  0.4509369134902954\n",
      "Eval Loss:  0.3306199610233307\n",
      "Eval Loss:  0.4713478684425354\n",
      "Eval Loss:  0.3551972210407257\n",
      "Eval Loss:  0.4199109673500061\n",
      "Eval Loss:  0.3866063356399536\n",
      "Eval Loss:  0.37816041707992554\n",
      "Eval Loss:  0.36644142866134644\n",
      "Eval Loss:  0.533727765083313\n",
      "Eval Loss:  0.44487595558166504\n",
      "Eval Loss:  0.30715376138687134\n",
      "Eval Loss:  0.388050377368927\n",
      "Eval Loss:  0.4504818320274353\n",
      "Eval Loss:  0.40328988432884216\n",
      "Eval Loss:  0.3269307613372803\n",
      "Eval Loss:  0.3129522502422333\n",
      "Eval Loss:  0.38692620396614075\n",
      "Eval Loss:  0.3025949001312256\n",
      "[[16362   665]\n",
      " [ 4118  8375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87     17027\n",
      "           1       0.93      0.67      0.78     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.86      0.82      0.83     29520\n",
      "weighted avg       0.85      0.84      0.83     29520\n",
      "\n",
      "acc:  0.8379742547425474\n",
      "pre:  0.9264380530973452\n",
      "rec:  0.6703754102297287\n",
      "ma F1:  0.8251764780560519\n",
      "mi F1:  0.8379742547425474\n",
      "we F1:  0.8324414235295177\n",
      "29520 462\n",
      "Loss:  0.08897755295038223\n",
      "Loss:  0.061819303780794144\n",
      "Loss:  0.07809709757566452\n",
      "9 **********\n",
      "Epoch:  950.976259469986  fold:  4  kers:  128\n",
      "epoch:  10\n",
      "29520 462\n",
      "Loss:  0.07337988168001175\n",
      "Loss:  0.1057252287864685\n",
      "Loss:  0.060336146503686905\n",
      "10 **********\n",
      "Epoch:  1031.5747549533844  fold:  4  kers:  128\n",
      "epoch:  11\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.10793281346559525\n",
      "Loss:  0.08048812299966812\n",
      "Loss:  0.06601753830909729\n",
      "11 **********\n",
      "Epoch:  1112.1961889266968  fold:  4  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.09650599956512451\n",
      "Eval Loss:  0.13270042836666107\n",
      "Eval Loss:  0.052922897040843964\n",
      "[[3075   62]\n",
      " [ 204   30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.33      0.13      0.18       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.63      0.55      0.57      3371\n",
      "weighted avg       0.90      0.92      0.90      3371\n",
      "\n",
      "acc:  0.921091664194601\n",
      "pre:  0.32608695652173914\n",
      "rec:  0.1282051282051282\n",
      "ma F1:  0.5712951134433853\n",
      "mi F1:  0.921091664194601\n",
      "we F1:  0.9047793127309974\n",
      "Eval Loss:  0.2363501638174057\n",
      "Eval Loss:  0.36790353059768677\n",
      "Eval Loss:  0.24414683878421783\n",
      "Eval Loss:  0.3179593086242676\n",
      "Eval Loss:  0.2763146758079529\n",
      "Eval Loss:  0.31956639885902405\n",
      "Eval Loss:  0.38077235221862793\n",
      "Eval Loss:  0.27815598249435425\n",
      "Eval Loss:  0.34334778785705566\n",
      "Eval Loss:  0.2994534969329834\n",
      "Eval Loss:  0.4038086235523224\n",
      "Eval Loss:  0.30084511637687683\n",
      "Eval Loss:  0.35181719064712524\n",
      "Eval Loss:  0.3232504725456238\n",
      "Eval Loss:  0.3044886291027069\n",
      "Eval Loss:  0.27877023816108704\n",
      "Eval Loss:  0.3104749619960785\n",
      "Eval Loss:  0.28011277318000793\n",
      "Eval Loss:  0.4031854271888733\n",
      "Eval Loss:  0.36834585666656494\n",
      "Eval Loss:  0.26307442784309387\n",
      "Eval Loss:  0.34782326221466064\n",
      "Eval Loss:  0.3342357873916626\n",
      "Eval Loss:  0.36429929733276367\n",
      "Eval Loss:  0.26492586731910706\n",
      "Eval Loss:  0.2435317486524582\n",
      "Eval Loss:  0.30233943462371826\n",
      "Eval Loss:  0.24057425558567047\n",
      "[[16303   724]\n",
      " [ 3224  9269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     17027\n",
      "           1       0.93      0.74      0.82     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.88      0.85      0.86     29520\n",
      "weighted avg       0.87      0.87      0.86     29520\n",
      "\n",
      "acc:  0.866260162601626\n",
      "pre:  0.9275492844991494\n",
      "rec:  0.7419354838709677\n",
      "ma F1:  0.8582097450788819\n",
      "mi F1:  0.8662601626016261\n",
      "we F1:  0.863398910994168\n",
      "29520 462\n",
      "Loss:  0.06392375379800797\n",
      "Loss:  0.09043031185865402\n",
      "Loss:  0.09049791097640991\n",
      "12 **********\n",
      "Epoch:  1236.324295759201  fold:  4  kers:  128\n",
      "epoch:  13\n",
      "29520 462\n",
      "Loss:  0.0765678659081459\n",
      "Loss:  0.11333017796278\n",
      "Loss:  0.057539865374565125\n",
      "13 **********\n",
      "Epoch:  1316.9118211269379  fold:  4  kers:  128\n",
      "epoch:  14\n",
      "29520 462\n",
      "Loss:  0.055398259311914444\n",
      "Loss:  0.06466565281152725\n",
      "Loss:  0.0892382487654686\n",
      "14 **********\n",
      "Epoch:  1397.553202867508  fold:  4  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.0921408087015152\n",
      "Eval Loss:  0.14828506112098694\n",
      "Eval Loss:  0.022813374176621437\n",
      "[[3074   63]\n",
      " [ 198   36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.36      0.15      0.22       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.65      0.57      0.59      3371\n",
      "weighted avg       0.90      0.92      0.91      3371\n",
      "\n",
      "acc:  0.9225749035894394\n",
      "pre:  0.36363636363636365\n",
      "rec:  0.15384615384615385\n",
      "ma F1:  0.5877461171578819\n",
      "mi F1:  0.9225749035894394\n",
      "we F1:  0.9076960733826388\n",
      "Eval Loss:  0.2606219947338104\n",
      "Eval Loss:  0.325899600982666\n",
      "Eval Loss:  0.23157238960266113\n",
      "Eval Loss:  0.32722967863082886\n",
      "Eval Loss:  0.2715607285499573\n",
      "Eval Loss:  0.2863791882991791\n",
      "Eval Loss:  0.3716517686843872\n",
      "Eval Loss:  0.2584609389305115\n",
      "Eval Loss:  0.3528372049331665\n",
      "Eval Loss:  0.2706558108329773\n",
      "Eval Loss:  0.37307974696159363\n",
      "Eval Loss:  0.27170899510383606\n",
      "Eval Loss:  0.3846682906150818\n",
      "Eval Loss:  0.3048034608364105\n",
      "Eval Loss:  0.2896752655506134\n",
      "Eval Loss:  0.2862772047519684\n",
      "Eval Loss:  0.2816084623336792\n",
      "Eval Loss:  0.2748258411884308\n",
      "Eval Loss:  0.37609410285949707\n",
      "Eval Loss:  0.35176172852516174\n",
      "Eval Loss:  0.21072633564472198\n",
      "Eval Loss:  0.33107370138168335\n",
      "Eval Loss:  0.3174106776714325\n",
      "Eval Loss:  0.2866280972957611\n",
      "Eval Loss:  0.24170148372650146\n",
      "Eval Loss:  0.21205855906009674\n",
      "Eval Loss:  0.2942921221256256\n",
      "Eval Loss:  0.23478034138679504\n",
      "[[16403   624]\n",
      " [ 3119  9374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     17027\n",
      "           1       0.94      0.75      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.89      0.86      0.87     29520\n",
      "weighted avg       0.88      0.87      0.87     29520\n",
      "\n",
      "acc:  0.8732046070460705\n",
      "pre:  0.9375875175035007\n",
      "rec:  0.7503401905066838\n",
      "ma F1:  0.8655837064640626\n",
      "mi F1:  0.8732046070460705\n",
      "we F1:  0.8704995071809247\n",
      "29520 462\n",
      "Loss:  0.07411111146211624\n",
      "Loss:  0.06369009613990784\n",
      "Loss:  0.0516442209482193\n",
      "15 **********\n",
      "Epoch:  1521.3641574382782  fold:  4  kers:  128\n",
      "epoch:  16\n",
      "29520 462\n",
      "Loss:  0.07602429389953613\n",
      "Loss:  0.10123572498559952\n",
      "Loss:  0.050439294427633286\n",
      "16 **********\n",
      "Epoch:  1601.9706318378448  fold:  4  kers:  128\n",
      "epoch:  17\n",
      "29520 462\n",
      "Loss:  0.07510215789079666\n",
      "Loss:  0.11650190502405167\n",
      "Loss:  0.04995793476700783\n",
      "17 **********\n",
      "Epoch:  1682.587080001831  fold:  4  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.1279454082250595\n",
      "Eval Loss:  0.19949539005756378\n",
      "Eval Loss:  0.018835654482245445\n",
      "[[3041   96]\n",
      " [ 216   18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3137\n",
      "           1       0.16      0.08      0.10       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.55      0.52      0.53      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9074458617620884\n",
      "pre:  0.15789473684210525\n",
      "rec:  0.07692307692307693\n",
      "ma F1:  0.5273262649250914\n",
      "mi F1:  0.9074458617620884\n",
      "we F1:  0.8923567609944933\n",
      "Eval Loss:  0.2850525379180908\n",
      "Eval Loss:  0.3099260926246643\n",
      "Eval Loss:  0.21360106766223907\n",
      "Eval Loss:  0.3296988606452942\n",
      "Eval Loss:  0.2535015642642975\n",
      "Eval Loss:  0.2917327880859375\n",
      "Eval Loss:  0.3173374831676483\n",
      "Eval Loss:  0.2650974690914154\n",
      "Eval Loss:  0.318646103143692\n",
      "Eval Loss:  0.257203608751297\n",
      "Eval Loss:  0.4051710069179535\n",
      "Eval Loss:  0.24632470309734344\n",
      "Eval Loss:  0.35028189420700073\n",
      "Eval Loss:  0.2850867211818695\n",
      "Eval Loss:  0.27124813199043274\n",
      "Eval Loss:  0.2783503830432892\n",
      "Eval Loss:  0.3115836977958679\n",
      "Eval Loss:  0.24604439735412598\n",
      "Eval Loss:  0.35804063081741333\n",
      "Eval Loss:  0.308665007352829\n",
      "Eval Loss:  0.220846027135849\n",
      "Eval Loss:  0.373577356338501\n",
      "Eval Loss:  0.28040191531181335\n",
      "Eval Loss:  0.3007315695285797\n",
      "Eval Loss:  0.25394195318222046\n",
      "Eval Loss:  0.21169322729110718\n",
      "Eval Loss:  0.2783663272857666\n",
      "Eval Loss:  0.2300184965133667\n",
      "[[16282   745]\n",
      " [ 2933  9560]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     17027\n",
      "           1       0.93      0.77      0.84     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.89      0.86      0.87     29520\n",
      "weighted avg       0.88      0.88      0.87     29520\n",
      "\n",
      "acc:  0.8754065040650406\n",
      "pre:  0.9277049975739932\n",
      "rec:  0.7652285279756664\n",
      "ma F1:  0.8685927966199318\n",
      "mi F1:  0.8754065040650406\n",
      "we F1:  0.8731886534417295\n",
      "29520 462\n",
      "Loss:  0.08081430196762085\n",
      "Loss:  0.05711361765861511\n",
      "Loss:  0.0920233204960823\n",
      "18 **********\n",
      "Epoch:  1806.246440410614  fold:  4  kers:  128\n",
      "epoch:  19\n",
      "29520 462\n",
      "Loss:  0.04825311154127121\n",
      "Loss:  0.07798942178487778\n",
      "Loss:  0.05658222362399101\n",
      "19 **********\n",
      "Epoch:  1886.862888097763  fold:  4  kers:  128\n",
      "epoch:  20\n",
      "29520 462\n",
      "Loss:  0.04564831405878067\n",
      "Loss:  0.05105786398053169\n",
      "Loss:  0.06828868389129639\n",
      "20 **********\n",
      "Epoch:  1967.500280380249  fold:  4  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.04306689277291298\n",
      "Eval Loss:  0.18115593492984772\n",
      "Eval Loss:  0.021400412544608116\n",
      "[[3019  118]\n",
      " [ 216   18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      3137\n",
      "           1       0.13      0.08      0.10       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.53      0.52      0.52      3371\n",
      "weighted avg       0.88      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9009196084247998\n",
      "pre:  0.1323529411764706\n",
      "rec:  0.07692307692307693\n",
      "ma F1:  0.5224402368470165\n",
      "mi F1:  0.9009196084247998\n",
      "we F1:  0.8885600687998007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.29231566190719604\n",
      "Eval Loss:  0.2547319233417511\n",
      "Eval Loss:  0.2131815105676651\n",
      "Eval Loss:  0.27892231941223145\n",
      "Eval Loss:  0.253777414560318\n",
      "Eval Loss:  0.290758341550827\n",
      "Eval Loss:  0.2673432528972626\n",
      "Eval Loss:  0.2552054524421692\n",
      "Eval Loss:  0.2923186421394348\n",
      "Eval Loss:  0.2532094717025757\n",
      "Eval Loss:  0.3707955479621887\n",
      "Eval Loss:  0.22216780483722687\n",
      "Eval Loss:  0.382978230714798\n",
      "Eval Loss:  0.2550787031650543\n",
      "Eval Loss:  0.2586747407913208\n",
      "Eval Loss:  0.2280023694038391\n",
      "Eval Loss:  0.2569045126438141\n",
      "Eval Loss:  0.21440526843070984\n",
      "Eval Loss:  0.3195939362049103\n",
      "Eval Loss:  0.31016889214515686\n",
      "Eval Loss:  0.1959255337715149\n",
      "Eval Loss:  0.3232854902744293\n",
      "Eval Loss:  0.24907410144805908\n",
      "Eval Loss:  0.28053992986679077\n",
      "Eval Loss:  0.25239986181259155\n",
      "Eval Loss:  0.165745347738266\n",
      "Eval Loss:  0.24402613937854767\n",
      "Eval Loss:  0.19312234222888947\n",
      "[[16235   792]\n",
      " [ 2507  9986]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17027\n",
      "           1       0.93      0.80      0.86     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.90      0.88      0.88     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8882452574525745\n",
      "pre:  0.9265169790313602\n",
      "rec:  0.7993276234691428\n",
      "ma F1:  0.8830024348038499\n",
      "mi F1:  0.8882452574525745\n",
      "we F1:  0.8868063967000441\n",
      "29520 462\n",
      "Loss:  0.06265745311975479\n",
      "Loss:  0.04241887107491493\n",
      "Loss:  0.05545077100396156\n",
      "21 **********\n",
      "Epoch:  2091.13969373703  fold:  4  kers:  128\n",
      "epoch:  22\n",
      "29520 462\n",
      "Loss:  0.08799087256193161\n",
      "Loss:  0.08215777575969696\n",
      "Loss:  0.09566424041986465\n",
      "22 **********\n",
      "Epoch:  2171.7332031726837  fold:  4  kers:  128\n",
      "epoch:  23\n",
      "29520 462\n",
      "Loss:  0.08708349615335464\n",
      "Loss:  0.0855536162853241\n",
      "Loss:  0.0388883501291275\n",
      "23 **********\n",
      "Epoch:  2252.3257145881653  fold:  4  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.041467320173978806\n",
      "Eval Loss:  0.19433417916297913\n",
      "Eval Loss:  0.014800254255533218\n",
      "[[3026  111]\n",
      " [ 209   25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.18      0.11      0.14       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.56      0.54      0.54      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.905072678730347\n",
      "pre:  0.18382352941176472\n",
      "rec:  0.10683760683760683\n",
      "ma F1:  0.5424577119492374\n",
      "mi F1:  0.905072678730347\n",
      "we F1:  0.8932312036405275\n",
      "Eval Loss:  0.2851656377315521\n",
      "Eval Loss:  0.2680417001247406\n",
      "Eval Loss:  0.20814819633960724\n",
      "Eval Loss:  0.28110063076019287\n",
      "Eval Loss:  0.26968643069267273\n",
      "Eval Loss:  0.30170613527297974\n",
      "Eval Loss:  0.2504783868789673\n",
      "Eval Loss:  0.25467172265052795\n",
      "Eval Loss:  0.30981436371803284\n",
      "Eval Loss:  0.2416120022535324\n",
      "Eval Loss:  0.38364264369010925\n",
      "Eval Loss:  0.2284892201423645\n",
      "Eval Loss:  0.3400869369506836\n",
      "Eval Loss:  0.25271129608154297\n",
      "Eval Loss:  0.2660749852657318\n",
      "Eval Loss:  0.2564776837825775\n",
      "Eval Loss:  0.26072391867637634\n",
      "Eval Loss:  0.2438153624534607\n",
      "Eval Loss:  0.3117654323577881\n",
      "Eval Loss:  0.2958936095237732\n",
      "Eval Loss:  0.1714375913143158\n",
      "Eval Loss:  0.32524657249450684\n",
      "Eval Loss:  0.21492061018943787\n",
      "Eval Loss:  0.30357080698013306\n",
      "Eval Loss:  0.2891550064086914\n",
      "Eval Loss:  0.1753275990486145\n",
      "Eval Loss:  0.24697111546993256\n",
      "Eval Loss:  0.20395253598690033\n",
      "[[16227   800]\n",
      " [ 2478 10015]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17027\n",
      "           1       0.93      0.80      0.86     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.90      0.88      0.88     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8889566395663957\n",
      "pre:  0.9260286638927415\n",
      "rec:  0.8016489233971024\n",
      "ma F1:  0.8838115474405491\n",
      "mi F1:  0.8889566395663957\n",
      "we F1:  0.8875668352220346\n",
      "29520 462\n",
      "Loss:  0.0673668310046196\n",
      "Loss:  0.050106994807720184\n",
      "Loss:  0.05122668668627739\n",
      "24 **********\n",
      "Epoch:  2375.9551541805267  fold:  4  kers:  128\n",
      "epoch:  25\n",
      "29520 462\n",
      "Loss:  0.06437289714813232\n",
      "Loss:  0.09353941679000854\n",
      "Loss:  0.06641223281621933\n",
      "25 **********\n",
      "Epoch:  2456.5307116508484  fold:  4  kers:  128\n",
      "epoch:  26\n",
      "29520 462\n",
      "Loss:  0.05211005359888077\n",
      "Loss:  0.05225497856736183\n",
      "Loss:  0.04989809915423393\n",
      "26 **********\n",
      "Epoch:  2537.142173051834  fold:  4  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.03918248414993286\n",
      "Eval Loss:  0.37228307127952576\n",
      "Eval Loss:  0.015270374715328217\n",
      "[[2884  253]\n",
      " [ 213   21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      3137\n",
      "           1       0.08      0.09      0.08       234\n",
      "\n",
      "    accuracy                           0.86      3371\n",
      "   macro avg       0.50      0.50      0.50      3371\n",
      "weighted avg       0.87      0.86      0.87      3371\n",
      "\n",
      "acc:  0.8617620884010679\n",
      "pre:  0.07664233576642336\n",
      "rec:  0.08974358974358974\n",
      "ma F1:  0.5039629009318974\n",
      "mi F1:  0.861762088401068\n",
      "we F1:  0.8667610291970046\n",
      "Eval Loss:  0.2705439031124115\n",
      "Eval Loss:  0.25616079568862915\n",
      "Eval Loss:  0.20479008555412292\n",
      "Eval Loss:  0.2890790104866028\n",
      "Eval Loss:  0.27065154910087585\n",
      "Eval Loss:  0.2900997996330261\n",
      "Eval Loss:  0.24672289192676544\n",
      "Eval Loss:  0.25867271423339844\n",
      "Eval Loss:  0.28937864303588867\n",
      "Eval Loss:  0.22089345753192902\n",
      "Eval Loss:  0.347027063369751\n",
      "Eval Loss:  0.21861188113689423\n",
      "Eval Loss:  0.31876033544540405\n",
      "Eval Loss:  0.26110973954200745\n",
      "Eval Loss:  0.23806267976760864\n",
      "Eval Loss:  0.2011231929063797\n",
      "Eval Loss:  0.24894623458385468\n",
      "Eval Loss:  0.25746503472328186\n",
      "Eval Loss:  0.29759472608566284\n",
      "Eval Loss:  0.2822120189666748\n",
      "Eval Loss:  0.17637546360492706\n",
      "Eval Loss:  0.3279394805431366\n",
      "Eval Loss:  0.21089120209217072\n",
      "Eval Loss:  0.25994259119033813\n",
      "Eval Loss:  0.2617839276790619\n",
      "Eval Loss:  0.18416982889175415\n",
      "Eval Loss:  0.24876558780670166\n",
      "Eval Loss:  0.1914074420928955\n",
      "[[16259   768]\n",
      " [ 2379 10114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17027\n",
      "           1       0.93      0.81      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.90      0.88      0.89     29520\n",
      "weighted avg       0.90      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8933943089430895\n",
      "pre:  0.929424738099614\n",
      "rec:  0.809573361082206\n",
      "ma F1:  0.8885656079186068\n",
      "mi F1:  0.8933943089430895\n",
      "we F1:  0.8921283956232454\n",
      "29520 462\n",
      "Loss:  0.0449175126850605\n",
      "Loss:  0.06576457619667053\n",
      "Loss:  0.04492108151316643\n",
      "27 **********\n",
      "Epoch:  2660.7696192264557  fold:  4  kers:  128\n",
      "epoch:  28\n",
      "29520 462\n",
      "Loss:  0.05206306651234627\n",
      "Loss:  0.05416157841682434\n",
      "Loss:  0.05162808299064636\n",
      "28 **********\n",
      "Epoch:  2741.3731033802032  fold:  4  kers:  128\n",
      "epoch:  29\n",
      "29520 462\n",
      "Loss:  0.05136622488498688\n",
      "Loss:  0.06491545587778091\n",
      "Loss:  0.08013734221458435\n",
      "29 **********\n",
      "Epoch:  2821.980573654175  fold:  4  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.017470911145210266\n",
      "Eval Loss:  0.15993376076221466\n",
      "Eval Loss:  0.009360249154269695\n",
      "[[3009  128]\n",
      " [ 199   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.21      0.15      0.18       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.58      0.55      0.56      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9029961435775734\n",
      "pre:  0.2147239263803681\n",
      "rec:  0.14957264957264957\n",
      "ma F1:  0.5623928875550077\n",
      "mi F1:  0.9029961435775734\n",
      "we F1:  0.8948647275797247\n",
      "Eval Loss:  0.25287750363349915\n",
      "Eval Loss:  0.22598454356193542\n",
      "Eval Loss:  0.1919289380311966\n",
      "Eval Loss:  0.2651112675666809\n",
      "Eval Loss:  0.22548842430114746\n",
      "Eval Loss:  0.27465033531188965\n",
      "Eval Loss:  0.23352275788784027\n",
      "Eval Loss:  0.22483572363853455\n",
      "Eval Loss:  0.27162083983421326\n",
      "Eval Loss:  0.2330787628889084\n",
      "Eval Loss:  0.3759671151638031\n",
      "Eval Loss:  0.2009071707725525\n",
      "Eval Loss:  0.2904936671257019\n",
      "Eval Loss:  0.24670083820819855\n",
      "Eval Loss:  0.20157669484615326\n",
      "Eval Loss:  0.21073661744594574\n",
      "Eval Loss:  0.26139459013938904\n",
      "Eval Loss:  0.20847727358341217\n",
      "Eval Loss:  0.28469228744506836\n",
      "Eval Loss:  0.28351834416389465\n",
      "Eval Loss:  0.1711827516555786\n",
      "Eval Loss:  0.32472777366638184\n",
      "Eval Loss:  0.20788681507110596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2690260112285614\n",
      "Eval Loss:  0.2533119320869446\n",
      "Eval Loss:  0.1850043684244156\n",
      "Eval Loss:  0.23370103538036346\n",
      "Eval Loss:  0.2081657350063324\n",
      "[[16226   801]\n",
      " [ 2150 10343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     17027\n",
      "           1       0.93      0.83      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.91      0.89      0.90     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9000338753387533\n",
      "pre:  0.9281227566403446\n",
      "rec:  0.8279036260305771\n",
      "ma F1:  0.895899421638478\n",
      "mi F1:  0.9000338753387533\n",
      "we F1:  0.8990858253571671\n",
      "29520 462\n",
      "Loss:  0.05986190587282181\n",
      "Loss:  0.07981976866722107\n",
      "Loss:  0.07448914647102356\n",
      "30 **********\n",
      "Epoch:  2945.6668615341187  fold:  4  kers:  128\n",
      "epoch:  31\n",
      "29520 462\n",
      "Loss:  0.058463700115680695\n",
      "Loss:  0.03800911456346512\n",
      "Loss:  0.056632764637470245\n",
      "31 **********\n",
      "Epoch:  3026.2843070030212  fold:  4  kers:  128\n",
      "epoch:  32\n",
      "29520 462\n",
      "Loss:  0.07656941562891006\n",
      "Loss:  0.056987229734659195\n",
      "Loss:  0.07967162132263184\n",
      "32 **********\n",
      "Epoch:  3106.8838007450104  fold:  4  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.04728153720498085\n",
      "Eval Loss:  0.2734107971191406\n",
      "Eval Loss:  0.009955697692930698\n",
      "[[2947  190]\n",
      " [ 200   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.15      0.15      0.15       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.54      0.54      0.54      3371\n",
      "weighted avg       0.88      0.88      0.88      3371\n",
      "\n",
      "acc:  0.8843073272026105\n",
      "pre:  0.15178571428571427\n",
      "rec:  0.1452991452991453\n",
      "ma F1:  0.543204617535628\n",
      "mi F1:  0.8843073272026106\n",
      "we F1:  0.8831363601251407\n",
      "Eval Loss:  0.29102200269699097\n",
      "Eval Loss:  0.24448932707309723\n",
      "Eval Loss:  0.19725576043128967\n",
      "Eval Loss:  0.3002137243747711\n",
      "Eval Loss:  0.23530243337154388\n",
      "Eval Loss:  0.28080928325653076\n",
      "Eval Loss:  0.23576298356056213\n",
      "Eval Loss:  0.2282426953315735\n",
      "Eval Loss:  0.29617002606391907\n",
      "Eval Loss:  0.22125646471977234\n",
      "Eval Loss:  0.37078356742858887\n",
      "Eval Loss:  0.21405532956123352\n",
      "Eval Loss:  0.3204377293586731\n",
      "Eval Loss:  0.2236599177122116\n",
      "Eval Loss:  0.22875559329986572\n",
      "Eval Loss:  0.26479461789131165\n",
      "Eval Loss:  0.27155667543411255\n",
      "Eval Loss:  0.22336357831954956\n",
      "Eval Loss:  0.2966451644897461\n",
      "Eval Loss:  0.2686498165130615\n",
      "Eval Loss:  0.1558702141046524\n",
      "Eval Loss:  0.34905949234962463\n",
      "Eval Loss:  0.22630105912685394\n",
      "Eval Loss:  0.2722424864768982\n",
      "Eval Loss:  0.2414165884256363\n",
      "Eval Loss:  0.18137915432453156\n",
      "Eval Loss:  0.233622208237648\n",
      "Eval Loss:  0.1987672746181488\n",
      "[[16343   684]\n",
      " [ 2379 10114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17027\n",
      "           1       0.94      0.81      0.87     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.88      0.89     29520\n",
      "weighted avg       0.90      0.90      0.89     29520\n",
      "\n",
      "acc:  0.896239837398374\n",
      "pre:  0.9366549360992776\n",
      "rec:  0.809573361082206\n",
      "ma F1:  0.8914046281632775\n",
      "mi F1:  0.896239837398374\n",
      "we F1:  0.8949241078023733\n",
      "29520 462\n",
      "Loss:  0.07171481847763062\n",
      "Loss:  0.05126700550317764\n",
      "Loss:  0.07461686432361603\n",
      "33 **********\n",
      "Epoch:  3230.582056045532  fold:  4  kers:  128\n",
      "epoch:  34\n",
      "29520 462\n",
      "Loss:  0.11293850094079971\n",
      "Loss:  0.05699308216571808\n",
      "Loss:  0.05485215783119202\n",
      "34 **********\n",
      "Epoch:  3311.2094745635986  fold:  4  kers:  128\n",
      "epoch:  35\n",
      "29520 462\n",
      "Loss:  0.04785984382033348\n",
      "Loss:  0.10450710356235504\n",
      "Loss:  0.06811657547950745\n",
      "35 **********\n",
      "Epoch:  3391.856840133667  fold:  4  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.030595198273658752\n",
      "Eval Loss:  0.16901391744613647\n",
      "Eval Loss:  0.017156004905700684\n",
      "[[2953  184]\n",
      " [ 190   44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.19      0.19      0.19       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.57      0.56      0.57      3371\n",
      "weighted avg       0.89      0.89      0.89      3371\n",
      "\n",
      "acc:  0.8890536932660932\n",
      "pre:  0.19298245614035087\n",
      "rec:  0.18803418803418803\n",
      "ma F1:  0.565461025174401\n",
      "mi F1:  0.8890536932660932\n",
      "we F1:  0.8883862625309435\n",
      "Eval Loss:  0.21284352242946625\n",
      "Eval Loss:  0.20082445442676544\n",
      "Eval Loss:  0.2107553482055664\n",
      "Eval Loss:  0.2782401740550995\n",
      "Eval Loss:  0.20606866478919983\n",
      "Eval Loss:  0.22560569643974304\n",
      "Eval Loss:  0.203185573220253\n",
      "Eval Loss:  0.2227802872657776\n",
      "Eval Loss:  0.22599594295024872\n",
      "Eval Loss:  0.22960592806339264\n",
      "Eval Loss:  0.31328076124191284\n",
      "Eval Loss:  0.1720159351825714\n",
      "Eval Loss:  0.2565848231315613\n",
      "Eval Loss:  0.23019923269748688\n",
      "Eval Loss:  0.19362038373947144\n",
      "Eval Loss:  0.21578939259052277\n",
      "Eval Loss:  0.21479614078998566\n",
      "Eval Loss:  0.18251393735408783\n",
      "Eval Loss:  0.23656383156776428\n",
      "Eval Loss:  0.2626546621322632\n",
      "Eval Loss:  0.14601194858551025\n",
      "Eval Loss:  0.3121774196624756\n",
      "Eval Loss:  0.214427649974823\n",
      "Eval Loss:  0.21831844747066498\n",
      "Eval Loss:  0.2436290830373764\n",
      "Eval Loss:  0.1664116531610489\n",
      "Eval Loss:  0.20545002818107605\n",
      "Eval Loss:  0.1840723305940628\n",
      "[[16025  1002]\n",
      " [ 1676 10817]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     17027\n",
      "           1       0.92      0.87      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9092818428184282\n",
      "pre:  0.9152212539131906\n",
      "rec:  0.8658448731289522\n",
      "ma F1:  0.9063675330584913\n",
      "mi F1:  0.9092818428184282\n",
      "we F1:  0.9089046836828297\n",
      "29520 462\n",
      "Loss:  0.04812850058078766\n",
      "Loss:  0.04842348396778107\n",
      "Loss:  0.06927242875099182\n",
      "36 **********\n",
      "Epoch:  3515.6937251091003  fold:  4  kers:  128\n",
      "epoch:  37\n",
      "29520 462\n",
      "Loss:  0.05829218775033951\n",
      "Loss:  0.06225140020251274\n",
      "Loss:  0.0771634578704834\n",
      "37 **********\n",
      "Epoch:  3596.297208070755  fold:  4  kers:  128\n",
      "epoch:  38\n",
      "29520 462\n",
      "Loss:  0.0596795529127121\n",
      "Loss:  0.03319641947746277\n",
      "Loss:  0.10275553166866302\n",
      "38 **********\n",
      "Epoch:  3676.9355974197388  fold:  4  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.2268555462360382\n",
      "Eval Loss:  0.12424790114164352\n",
      "Eval Loss:  0.010166946798563004\n",
      "[[2988  149]\n",
      " [ 225    9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3137\n",
      "           1       0.06      0.04      0.05       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.49      0.50      0.49      3371\n",
      "weighted avg       0.87      0.89      0.88      3371\n",
      "\n",
      "acc:  0.8890536932660932\n",
      "pre:  0.056962025316455694\n",
      "rec:  0.038461538461538464\n",
      "ma F1:  0.4935103647758316\n",
      "mi F1:  0.8890536932660932\n",
      "we F1:  0.8789626247983994\n",
      "Eval Loss:  0.2006767988204956\n",
      "Eval Loss:  0.2624143660068512\n",
      "Eval Loss:  0.2176227867603302\n",
      "Eval Loss:  0.27206453680992126\n",
      "Eval Loss:  0.20366270840168\n",
      "Eval Loss:  0.2483765333890915\n",
      "Eval Loss:  0.2580861449241638\n",
      "Eval Loss:  0.21177257597446442\n",
      "Eval Loss:  0.2541733682155609\n",
      "Eval Loss:  0.18251203000545502\n",
      "Eval Loss:  0.3462575078010559\n",
      "Eval Loss:  0.20935136079788208\n",
      "Eval Loss:  0.28158038854599\n",
      "Eval Loss:  0.2415822148323059\n",
      "Eval Loss:  0.17892490327358246\n",
      "Eval Loss:  0.22017772495746613\n",
      "Eval Loss:  0.2407425194978714\n",
      "Eval Loss:  0.19854700565338135\n",
      "Eval Loss:  0.288436621427536\n",
      "Eval Loss:  0.2525416612625122\n",
      "Eval Loss:  0.16687823832035065\n",
      "Eval Loss:  0.34137699007987976\n",
      "Eval Loss:  0.21979683637619019\n",
      "Eval Loss:  0.24343177676200867\n",
      "Eval Loss:  0.17692843079566956\n",
      "Eval Loss:  0.18926933407783508\n",
      "Eval Loss:  0.20683936774730682\n",
      "Eval Loss:  0.205678328871727\n",
      "[[16412   615]\n",
      " [ 2282 10211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17027\n",
      "           1       0.94      0.82      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.91      0.89      0.90     29520\n",
      "weighted avg       0.91      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9018631436314363\n",
      "pre:  0.9431923147977093\n",
      "rec:  0.8173377091171056\n",
      "ma F1:  0.8973328946230668\n",
      "mi F1:  0.9018631436314363\n",
      "we F1:  0.9006452876248322\n",
      "29520 462\n",
      "Loss:  0.03750617057085037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.061988383531570435\n",
      "Loss:  0.040445081889629364\n",
      "39 **********\n",
      "Epoch:  3800.749544620514  fold:  4  kers:  128\n",
      "epoch:  40\n",
      "29520 462\n",
      "Loss:  0.059974219650030136\n",
      "Loss:  0.0568602979183197\n",
      "Loss:  0.07334723323583603\n",
      "40 **********\n",
      "Epoch:  3881.456749677658  fold:  4  kers:  128\n",
      "epoch:  41\n",
      "29520 462\n",
      "Loss:  0.031221073120832443\n",
      "Loss:  0.06026016175746918\n",
      "Loss:  0.040298447012901306\n",
      "41 **********\n",
      "Epoch:  3962.1509890556335  fold:  4  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.26601341366767883\n",
      "Eval Loss:  0.09248021245002747\n",
      "Eval Loss:  0.006846134550869465\n",
      "[[2983  154]\n",
      " [ 180   54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      3137\n",
      "           1       0.26      0.23      0.24       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.60      0.59      0.60      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.9009196084247998\n",
      "pre:  0.25961538461538464\n",
      "rec:  0.23076923076923078\n",
      "ma F1:  0.595664009193421\n",
      "mi F1:  0.9009196084247998\n",
      "we F1:  0.8982099308624863\n",
      "Eval Loss:  0.21100661158561707\n",
      "Eval Loss:  0.21971377730369568\n",
      "Eval Loss:  0.17090962827205658\n",
      "Eval Loss:  0.26500165462493896\n",
      "Eval Loss:  0.15474814176559448\n",
      "Eval Loss:  0.19632290303707123\n",
      "Eval Loss:  0.20242011547088623\n",
      "Eval Loss:  0.2102869749069214\n",
      "Eval Loss:  0.20281030237674713\n",
      "Eval Loss:  0.17924021184444427\n",
      "Eval Loss:  0.3054468035697937\n",
      "Eval Loss:  0.12509754300117493\n",
      "Eval Loss:  0.2752530574798584\n",
      "Eval Loss:  0.19756381213665009\n",
      "Eval Loss:  0.1432112455368042\n",
      "Eval Loss:  0.19559447467327118\n",
      "Eval Loss:  0.22715003788471222\n",
      "Eval Loss:  0.15707121789455414\n",
      "Eval Loss:  0.2250482589006424\n",
      "Eval Loss:  0.2661389112472534\n",
      "Eval Loss:  0.15136317908763885\n",
      "Eval Loss:  0.3312687873840332\n",
      "Eval Loss:  0.1935073733329773\n",
      "Eval Loss:  0.22635281085968018\n",
      "Eval Loss:  0.18230733275413513\n",
      "Eval Loss:  0.16352489590644836\n",
      "Eval Loss:  0.1743864268064499\n",
      "Eval Loss:  0.13759569823741913\n",
      "[[16294   733]\n",
      " [ 1744 10749]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     17027\n",
      "           1       0.94      0.86      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9160907859078591\n",
      "pre:  0.9361609475701097\n",
      "rec:  0.8604018250220123\n",
      "ma F1:  0.9130219031630071\n",
      "mi F1:  0.9160907859078592\n",
      "we F1:  0.9155312475029816\n",
      "29520 462\n",
      "Loss:  0.044529467821121216\n",
      "Loss:  0.06526783108711243\n",
      "Loss:  0.048388343304395676\n",
      "42 **********\n",
      "Epoch:  4085.910082578659  fold:  4  kers:  128\n",
      "epoch:  43\n",
      "29520 462\n",
      "Loss:  0.058688823133707047\n",
      "Loss:  0.07497090846300125\n",
      "Loss:  0.04021059349179268\n",
      "43 **********\n",
      "Epoch:  4166.600333690643  fold:  4  kers:  128\n",
      "epoch:  44\n",
      "29520 462\n",
      "Loss:  0.054006051272153854\n",
      "Loss:  0.05197291076183319\n",
      "Loss:  0.05085264518857002\n",
      "44 **********\n",
      "Epoch:  4247.316514968872  fold:  4  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.034505121409893036\n",
      "Eval Loss:  0.08293625712394714\n",
      "Eval Loss:  0.003927065525203943\n",
      "[[3025  112]\n",
      " [ 218   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      3137\n",
      "           1       0.12      0.07      0.09       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.53      0.52      0.52      3371\n",
      "weighted avg       0.88      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9021061999406704\n",
      "pre:  0.125\n",
      "rec:  0.06837606837606838\n",
      "ma F1:  0.5183368260621071\n",
      "mi F1:  0.9021061999406704\n",
      "we F1:  0.8885869066102856\n",
      "Eval Loss:  0.1977463960647583\n",
      "Eval Loss:  0.2471146285533905\n",
      "Eval Loss:  0.20883029699325562\n",
      "Eval Loss:  0.2670119106769562\n",
      "Eval Loss:  0.17817635834217072\n",
      "Eval Loss:  0.23673343658447266\n",
      "Eval Loss:  0.2511593997478485\n",
      "Eval Loss:  0.23885378241539001\n",
      "Eval Loss:  0.23393166065216064\n",
      "Eval Loss:  0.2174205183982849\n",
      "Eval Loss:  0.3517095446586609\n",
      "Eval Loss:  0.15780051052570343\n",
      "Eval Loss:  0.272344708442688\n",
      "Eval Loss:  0.23183973133563995\n",
      "Eval Loss:  0.18311338126659393\n",
      "Eval Loss:  0.2115689367055893\n",
      "Eval Loss:  0.25893598794937134\n",
      "Eval Loss:  0.1987515091896057\n",
      "Eval Loss:  0.22984318435192108\n",
      "Eval Loss:  0.24700549244880676\n",
      "Eval Loss:  0.1513615846633911\n",
      "Eval Loss:  0.35409224033355713\n",
      "Eval Loss:  0.19288577139377594\n",
      "Eval Loss:  0.2432287633419037\n",
      "Eval Loss:  0.16446787118911743\n",
      "Eval Loss:  0.1655333936214447\n",
      "Eval Loss:  0.1857452690601349\n",
      "Eval Loss:  0.1644819676876068\n",
      "[[16348   679]\n",
      " [ 1961 10532]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     17027\n",
      "           1       0.94      0.84      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.92      0.90      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9105691056910569\n",
      "pre:  0.9394344839889395\n",
      "rec:  0.8430320979748659\n",
      "ma F1:  0.9069575248149561\n",
      "mi F1:  0.9105691056910569\n",
      "we F1:  0.909773017884461\n",
      "29520 462\n",
      "Loss:  0.05462449789047241\n",
      "Loss:  0.0799964889883995\n",
      "Loss:  0.09097137302160263\n",
      "45 **********\n",
      "Epoch:  4370.89409327507  fold:  4  kers:  128\n",
      "epoch:  46\n",
      "29520 462\n",
      "Loss:  0.055956512689590454\n",
      "Loss:  0.048017702996730804\n",
      "Loss:  0.041451387107372284\n",
      "46 **********\n",
      "Epoch:  4455.927730798721  fold:  4  kers:  128\n",
      "epoch:  47\n",
      "29520 462\n",
      "Loss:  0.03422907739877701\n",
      "Loss:  0.10409892350435257\n",
      "Loss:  0.0455394946038723\n",
      "47 **********\n",
      "Epoch:  4536.522237300873  fold:  4  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.09132043272256851\n",
      "Eval Loss:  0.11495448648929596\n",
      "Eval Loss:  0.0076801711693406105\n",
      "[[2986  151]\n",
      " [ 204   30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      3137\n",
      "           1       0.17      0.13      0.14       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.55      0.54      0.54      3371\n",
      "weighted avg       0.88      0.89      0.89      3371\n",
      "\n",
      "acc:  0.8946900029664788\n",
      "pre:  0.16574585635359115\n",
      "rec:  0.1282051282051282\n",
      "ma F1:  0.5442347864668727\n",
      "mi F1:  0.8946900029664789\n",
      "we F1:  0.8884064689764656\n",
      "Eval Loss:  0.20649197697639465\n",
      "Eval Loss:  0.23476271331310272\n",
      "Eval Loss:  0.15828461945056915\n",
      "Eval Loss:  0.24496108293533325\n",
      "Eval Loss:  0.15363642573356628\n",
      "Eval Loss:  0.18213950097560883\n",
      "Eval Loss:  0.18512918055057526\n",
      "Eval Loss:  0.18406932055950165\n",
      "Eval Loss:  0.20564372837543488\n",
      "Eval Loss:  0.18012402951717377\n",
      "Eval Loss:  0.29282376170158386\n",
      "Eval Loss:  0.14368151128292084\n",
      "Eval Loss:  0.2110511064529419\n",
      "Eval Loss:  0.20170579850673676\n",
      "Eval Loss:  0.10519979894161224\n",
      "Eval Loss:  0.20246799290180206\n",
      "Eval Loss:  0.22661596536636353\n",
      "Eval Loss:  0.154275044798851\n",
      "Eval Loss:  0.26357075572013855\n",
      "Eval Loss:  0.2573510408401489\n",
      "Eval Loss:  0.12470994144678116\n",
      "Eval Loss:  0.30669543147087097\n",
      "Eval Loss:  0.1881949007511139\n",
      "Eval Loss:  0.23309968411922455\n",
      "Eval Loss:  0.152612566947937\n",
      "Eval Loss:  0.1512673795223236\n",
      "Eval Loss:  0.17947912216186523\n",
      "Eval Loss:  0.15989339351654053\n",
      "[[16399   628]\n",
      " [ 1792 10701]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     17027\n",
      "           1       0.94      0.86      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9180216802168022\n",
      "pre:  0.9445670403389531\n",
      "rec:  0.8565596734171136\n",
      "ma F1:  0.914849184874136\n",
      "mi F1:  0.9180216802168022\n",
      "we F1:  0.9173735958751272\n",
      "29520 462\n",
      "Loss:  0.0441688671708107\n",
      "Loss:  0.03157048672437668\n",
      "Loss:  0.07344277948141098\n",
      "48 **********\n",
      "Epoch:  4660.3591232299805  fold:  4  kers:  128\n",
      "epoch:  49\n",
      "29520 462\n",
      "Loss:  0.04698820412158966\n",
      "Loss:  0.05454297363758087\n",
      "Loss:  0.05278238281607628\n",
      "49 **********\n",
      "Epoch:  4740.969586849213  fold:  4  kers:  128\n",
      "epoch:  50\n",
      "29520 462\n",
      "Loss:  0.09268579632043839\n",
      "Loss:  0.042285554111003876\n",
      "Loss:  0.036372821778059006\n",
      "50 **********\n",
      "Epoch:  4821.6249306201935  fold:  4  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.027065318077802658\n",
      "Eval Loss:  0.11190474033355713\n",
      "Eval Loss:  0.006180105730891228\n",
      "[[2962  175]\n",
      " [ 183   51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.23      0.22      0.22       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.58      0.58      0.58      3371\n",
      "weighted avg       0.89      0.89      0.89      3371\n",
      "\n",
      "acc:  0.8938000593295758\n",
      "pre:  0.22566371681415928\n",
      "rec:  0.21794871794871795\n",
      "ma F1:  0.58237545506139\n",
      "mi F1:  0.8938000593295758\n",
      "we F1:  0.8929442033233423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17339466512203217\n",
      "Eval Loss:  0.21719525754451752\n",
      "Eval Loss:  0.17978689074516296\n",
      "Eval Loss:  0.2532237470149994\n",
      "Eval Loss:  0.16160157322883606\n",
      "Eval Loss:  0.1897123008966446\n",
      "Eval Loss:  0.19181008636951447\n",
      "Eval Loss:  0.20717130601406097\n",
      "Eval Loss:  0.17951714992523193\n",
      "Eval Loss:  0.18618452548980713\n",
      "Eval Loss:  0.2674853503704071\n",
      "Eval Loss:  0.11977362632751465\n",
      "Eval Loss:  0.2142326533794403\n",
      "Eval Loss:  0.19107317924499512\n",
      "Eval Loss:  0.127370223402977\n",
      "Eval Loss:  0.15964363515377045\n",
      "Eval Loss:  0.1650390326976776\n",
      "Eval Loss:  0.17013545334339142\n",
      "Eval Loss:  0.18777614831924438\n",
      "Eval Loss:  0.26154276728630066\n",
      "Eval Loss:  0.11585912108421326\n",
      "Eval Loss:  0.26663738489151\n",
      "Eval Loss:  0.14238093793392181\n",
      "Eval Loss:  0.21167799830436707\n",
      "Eval Loss:  0.17111660540103912\n",
      "Eval Loss:  0.16546949744224548\n",
      "Eval Loss:  0.1526070237159729\n",
      "Eval Loss:  0.1498538702726364\n",
      "[[16231   796]\n",
      " [ 1473 11020]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     17027\n",
      "           1       0.93      0.88      0.91     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.92      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9231368563685637\n",
      "pre:  0.9326337169939065\n",
      "rec:  0.8820939726246698\n",
      "ma F1:  0.9206647001696467\n",
      "mi F1:  0.9231368563685637\n",
      "we F1:  0.9228156800594739\n",
      "29520 462\n",
      "Loss:  0.04784031957387924\n",
      "Loss:  0.044556476175785065\n",
      "Loss:  0.03696741536259651\n",
      "51 **********\n",
      "Epoch:  4945.310221195221  fold:  4  kers:  128\n",
      "epoch:  52\n",
      "29520 462\n",
      "Loss:  0.061625465750694275\n",
      "Loss:  0.03516723960638046\n",
      "Loss:  0.043794404715299606\n",
      "52 **********\n",
      "Epoch:  5025.919687747955  fold:  4  kers:  128\n",
      "epoch:  53\n",
      "29520 462\n",
      "Loss:  0.04839843139052391\n",
      "Loss:  0.051732324063777924\n",
      "Loss:  0.0460493266582489\n",
      "53 **********\n",
      "Epoch:  5106.552093029022  fold:  4  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.0575270839035511\n",
      "Eval Loss:  0.07718563824892044\n",
      "Eval Loss:  0.006063966080546379\n",
      "[[2980  157]\n",
      " [ 187   47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      3137\n",
      "           1       0.23      0.20      0.21       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.59      0.58      0.58      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.8979531296351231\n",
      "pre:  0.23039215686274508\n",
      "rec:  0.20085470085470086\n",
      "ma F1:  0.5800216721136685\n",
      "mi F1:  0.8979531296351231\n",
      "we F1:  0.8947011883716919\n",
      "Eval Loss:  0.1913413256406784\n",
      "Eval Loss:  0.16434724628925323\n",
      "Eval Loss:  0.15293267369270325\n",
      "Eval Loss:  0.2617824971675873\n",
      "Eval Loss:  0.15034833550453186\n",
      "Eval Loss:  0.17348356544971466\n",
      "Eval Loss:  0.17578306794166565\n",
      "Eval Loss:  0.18140463531017303\n",
      "Eval Loss:  0.16978436708450317\n",
      "Eval Loss:  0.1680513620376587\n",
      "Eval Loss:  0.2675943672657013\n",
      "Eval Loss:  0.13720381259918213\n",
      "Eval Loss:  0.203558087348938\n",
      "Eval Loss:  0.19491350650787354\n",
      "Eval Loss:  0.14327017962932587\n",
      "Eval Loss:  0.20204727351665497\n",
      "Eval Loss:  0.1493908017873764\n",
      "Eval Loss:  0.1608886569738388\n",
      "Eval Loss:  0.18994641304016113\n",
      "Eval Loss:  0.24470975995063782\n",
      "Eval Loss:  0.10781961679458618\n",
      "Eval Loss:  0.29083698987960815\n",
      "Eval Loss:  0.14591585099697113\n",
      "Eval Loss:  0.20800234377384186\n",
      "Eval Loss:  0.16288571059703827\n",
      "Eval Loss:  0.16095168888568878\n",
      "Eval Loss:  0.1758379191160202\n",
      "Eval Loss:  0.14033953845500946\n",
      "[[16224   803]\n",
      " [ 1447 11046]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     17027\n",
      "           1       0.93      0.88      0.91     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.93      0.92      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9237804878048781\n",
      "pre:  0.9322305679804203\n",
      "rec:  0.8841751380773233\n",
      "ma F1:  0.9213609659106821\n",
      "mi F1:  0.9237804878048781\n",
      "we F1:  0.9234795661942441\n",
      "29520 462\n",
      "Loss:  0.04069701209664345\n",
      "Loss:  0.08684033155441284\n",
      "Loss:  0.03568533807992935\n",
      "54 **********\n",
      "Epoch:  5230.240376234055  fold:  4  kers:  128\n",
      "epoch:  55\n",
      "29520 462\n",
      "Loss:  0.03727898746728897\n",
      "Loss:  0.04901121184229851\n",
      "Loss:  0.08156944811344147\n",
      "55 **********\n",
      "Epoch:  5310.888738870621  fold:  4  kers:  128\n",
      "epoch:  56\n",
      "29520 462\n",
      "Loss:  0.02986101061105728\n",
      "Loss:  0.04249768331646919\n",
      "Loss:  0.044662218540906906\n",
      "56 **********\n",
      "Epoch:  5391.533111810684  fold:  4  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.06772781908512115\n",
      "Eval Loss:  0.0960383266210556\n",
      "Eval Loss:  0.008833479136228561\n",
      "[[3016  121]\n",
      " [ 186   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.28      0.21      0.24       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.61      0.58      0.59      3371\n",
      "weighted avg       0.90      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9089291011569267\n",
      "pre:  0.28402366863905326\n",
      "rec:  0.20512820512820512\n",
      "ma F1:  0.5948915238566095\n",
      "mi F1:  0.9089291011569267\n",
      "we F1:  0.9020515935678026\n",
      "Eval Loss:  0.1726347804069519\n",
      "Eval Loss:  0.1962754875421524\n",
      "Eval Loss:  0.13477762043476105\n",
      "Eval Loss:  0.23257841169834137\n",
      "Eval Loss:  0.14675527811050415\n",
      "Eval Loss:  0.16948731243610382\n",
      "Eval Loss:  0.1788162738084793\n",
      "Eval Loss:  0.1804570108652115\n",
      "Eval Loss:  0.17072422802448273\n",
      "Eval Loss:  0.1948600709438324\n",
      "Eval Loss:  0.255283921957016\n",
      "Eval Loss:  0.12330947816371918\n",
      "Eval Loss:  0.18239469826221466\n",
      "Eval Loss:  0.19525399804115295\n",
      "Eval Loss:  0.11820219457149506\n",
      "Eval Loss:  0.17219074070453644\n",
      "Eval Loss:  0.1701478213071823\n",
      "Eval Loss:  0.13102295994758606\n",
      "Eval Loss:  0.1777118593454361\n",
      "Eval Loss:  0.22503875195980072\n",
      "Eval Loss:  0.10766585171222687\n",
      "Eval Loss:  0.2729322016239166\n",
      "Eval Loss:  0.1526326984167099\n",
      "Eval Loss:  0.21839639544487\n",
      "Eval Loss:  0.14322300255298615\n",
      "Eval Loss:  0.14466603100299835\n",
      "Eval Loss:  0.16068629920482635\n",
      "Eval Loss:  0.17112335562705994\n",
      "[[16273   754]\n",
      " [ 1346 11147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     17027\n",
      "           1       0.94      0.89      0.91     12493\n",
      "\n",
      "    accuracy                           0.93     29520\n",
      "   macro avg       0.93      0.92      0.93     29520\n",
      "weighted avg       0.93      0.93      0.93     29520\n",
      "\n",
      "acc:  0.9288617886178862\n",
      "pre:  0.9366439794975212\n",
      "rec:  0.892259665412631\n",
      "ma F1:  0.9266500997869591\n",
      "mi F1:  0.9288617886178862\n",
      "we F1:  0.9286063614255512\n",
      "29520 462\n",
      "Loss:  0.06204047054052353\n",
      "Loss:  0.046564746648073196\n",
      "Loss:  0.02574097365140915\n",
      "57 **********\n",
      "Epoch:  5515.190477132797  fold:  4  kers:  128\n",
      "epoch:  58\n",
      "29520 462\n",
      "Loss:  0.034465573728084564\n",
      "Loss:  0.07470347732305527\n",
      "Loss:  0.06076802313327789\n",
      "58 **********\n",
      "Epoch:  5595.816898584366  fold:  4  kers:  128\n",
      "epoch:  59\n",
      "29520 462\n",
      "Loss:  0.022878699004650116\n",
      "Loss:  0.0668645054101944\n",
      "Loss:  0.046538397669792175\n",
      "59 **********\n",
      "Epoch:  5676.477229595184  fold:  4  kers:  128\n",
      "Eval Loss:  0.13438093662261963\n",
      "Eval Loss:  0.137162983417511\n",
      "Eval Loss:  0.008615856990218163\n",
      "[[2920  217]\n",
      " [ 172   62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3137\n",
      "           1       0.22      0.26      0.24       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.58      0.60      0.59      3371\n",
      "weighted avg       0.89      0.88      0.89      3371\n",
      "\n",
      "acc:  0.8846039750815782\n",
      "pre:  0.2222222222222222\n",
      "rec:  0.26495726495726496\n",
      "ma F1:  0.5896327840882598\n",
      "mi F1:  0.8846039750815782\n",
      "we F1:  0.8892483780188418\n",
      "update!  Acc:  0.924651438742213\n",
      "Epoch:  5681.014099121094  fold:  4  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA16ElEQVR4nO3deXwU9fkH8M+ThCQQwh3uI0HOIIgQAQWxICBHFbFoUat4VKAFkao/f/Gopa0HFRVrRRAVC/2piFdFiXJ7cBPuMxAgQCCEhBsCOZ/fHztJZiezuzO7szu72ef9euWV3ZnvzHwnm51n5nsSM0MIIUT4ibA7A0IIIewhAUAIIcKUBAAhhAhTEgCEECJMSQAQQogwFWV3Bsxo1KgRJyYm2p0NIYQIKZs3b85n5gTt8pAKAImJiUhPT7c7G0IIEVKI6IjecikCEkKIMCUBQAghwpQEACGECFMSAIQQIkxJABBCiDAlAUAIIcKUBAAhhAhTYRMArhSV4svN2ZDhr4UQwiGkOoL54pW0vfjP+iNoUicW/do3sjs7Qghhu7B5AvjPekdHuEuFxdhy9CwuFZbYnCMhhLBX2ASAcheulOCud9fiD/+32e6sCCGErcIuAPxzxQEAwM7j523OiRBC2CvsAsDxc1cAAFIXLIQId2EXAMqdv1KMvTkX7M6GEELYJiwCwAnlrl9r2D9/CXBOhBAieIRFAPh663G7syCEEEEnLALA9CUZdmdBCCGCjqEAQERDiSiDiDKJKFVnfSciWkdEhUT0tGp5RyLapvq5QERTlHVTiei4at1wy85KCCGERx57AhNRJICZAAYDyAawiYgWMfMeVbIzACYDuFO9LTNnAOiu2s9xAF+rksxg5td9yL8QQggvGXkC6AUgk5kPMXMRgAUARqoTMPMpZt4EoNjNfm4FcJCZdeemtEv+pUK7syCEELYwEgBaADimep+tLDNrDIBPNcsmEdEOIppLRPX1NiKicUSUTkTpeXl5XhzWvZSXlqOwpNTy/QohRLAzEgBIZ5mpblREFA3gDgCfqxbPAnANHEVEOQDe0NuWmecwcwozpyQkJJg5rGFvLt3vl/0KIUQwMxIAsgG0Ur1vCeCEyeMMA7CFmXPLFzBzLjOXMnMZgPfhKGqyxamLUgwkhAg/RgLAJgDtiShJuZMfA2CRyePcC03xDxE1U70dBWCXyX1aRuYIEEKEI4+tgJi5hIgmAVgCIBLAXGbeTUQTlPWziagpgHQAdQCUKU09k5n5AhHVgqMF0XjNrl8jou5wFCdl6awPGLn8CyHCkaEJYZg5DUCaZtls1euTcBQN6W1bAKChzvIHTOVUCCGEpcKiJ7AQQoiqJAC4IE1DhRDVnQQAVJ0bYM+JC+j4wg/4fmeOPRkSQogAkAAAYNF251at27PPAQD+8PEWG3IjhBCBIQFAkZi6GFuPnrU7G0IIETASAFTu/2CD3VkQQoiAkQCgojfmhRBCVFcSAFSIJAQIIcJHWASApnViDaWTy78QIpyERQBoVs9YAJAIYJ70lxAidIVFAJg++jpD6UjzW7i3MP0YOr7wA46eLrA7K0IIL4RFAGjXuLahdFbVAQyZ8RP+5/PtluwrmJV3lMvMu2hzToQQ3giLAOCLsjLzY4Xuz72Ezzdnu02TmLoYL323x20aIYTwJwkAKleLS/Hh6sNQX/PfWu6YLeyHXTkoKCqx9HgfrD5s6f6EEMIMCQAqhSVl+Pt3e7Bk98mKZf/ddgK7jp/HhP/bghf+a9ucNUFJ5lEQIrSFTQDo0MRYPQAAXCmubNly9EwBftrvmIz++NkrluerOiCpNhciJIVNAPDlIjV9SYaFOal+WJ4FhAhJ4RMAlOt/52Z17M2IScyMBRuPBmV7e7nvFyK0GQoARDSUiDKIKJOIUnXWdyKidURUSERPa9ZlEdFOItpGROmq5Q2IaBkRHVB+1/f9dDz7bYruzJXOXNzQumslerVY/wL9yYaj6PPKCgM50/f9rpNI/WonZiw74PU+/EXu+4UIbR4DABFFApgJYBiAZAD3ElGyJtkZAJMBvO5iNwOYuTszp6iWpQJYwcztAaxQ3vvNkOQmAIDGBoaFMFuk8cOuHHT68w/YfeJ8lXXPfb0TJy9cNbU/tYtXiwEAZy4Xer0Pf5M6ACFCk5EngF4AMpn5EDMXAVgAYKQ6ATOfYuZNAIpNHHskgHnK63kA7jSxrWlTBnXAlj8Pxq2dG3tMuynL/bwAh/Iu4b2fDuJKkeOuf+W+UwCAXcerBgAhhAhWUQbStABwTPU+G0BvE8dgAEuJiAG8x8xzlOVNmDkHAJg5h4h0r8xENA7AOABo3bq1icM6i4ggNIiL9np7tYFv/ATA0eHrjXuMDTPhK+20lUII4SsjTwB6z/dmLkd9mbkHHEVIE4mov4ltwcxzmDmFmVMSEhLMbGo5bVFH1unLAT+mEEJYxUgAyAbQSvW+JYATLtJWwcwnlN+nAHwNR5ESAOQSUTMAUH6fMrpPX83+XQ9L9lNSxih1M1TE459uteQ4QgjhD0YCwCYA7YkoiYiiAYwBsMjIzokojojiy18DGAKgvDvtIgBjlddjAXxjJuO+GHptM0v2s/3YOQye8ZPL9d9u9xwnr//bUkz7fp8l+RFC+E9JaVlQNsf2hccAwMwlACYBWAJgL4CFzLybiCYQ0QQAIKKmRJQN4EkALxBRNhHVAdAEwGoi2g5gI4DFzPyDsutpAAYT0QEAg5X3AdOlufn+AHrNQA/lGSsGWnfwNIpKyqosP1tQjNk/HfS4vVQBCGGvX/9rNTq+8IPnhCHESCUwmDkNQJpm2WzV65NwFA1pXQCgW0vKzKcB3Go4pxaLjzV06pa59/31eLhvIv5yexdzGypB5+iZAhzOv4ykRnHWZ04I4dG+k9Vv2POw6Qms9dZvrze9zcG8S0h6drHL9WcL3LeCzTx1yfQxy208fAYDXv/R6+39QVomCRHawjYANK1rcJpIldwLhW4vekbL8hemH/OcSAgh/CxsA4Cd/r0my3BabxuB9n5lOaYu2u3l1sZYNIGaEMImEgAssPHwGbuzUEXuhUL8e22W3dkwRa+SXAjhPxIALHD+ipkRMKpPix4r6wCW7j6JDi98rzuekhDCPyQABNDxc1dcTit59HQBth07V2W5p4nqj50pQFa+/3sku6VkkZnBXkaF8vGUdmRLABAiUCQAWMBo0cWhvMtIfnGJ7kWy//RVuHPmGtPHvvm1VfhVkLQOSno2Db/7cIPd2RBCGCQBwAKXiwLXO5CZK0YhNau4tAxvLtvvcXL77LMF+FmZBtNYpipfrsk87VXehLDaxxuOIDF1scu5OoQEgJAzb20WOr/4A3LOm5+feGH6Mby94gDeXpFZsez4uStYezDfKd2QGT/jwbkbfc6rEHZ6Z6Xj//zM5SKbcxK8JAAEOW0NwOKdOQCAY2fMB4DCYkdRlfqOaMDrP+K+952LbQoMPmFsOXpWP5MWuVRYgpEz12B/bvXrgSlEMJAAEOSsaGjTdeoSPDY/XXedL00vL151X5Tkq7WZ+dh+7Bxe+yHDp/0cyL2IFXtzLcqVEMasP3QaZ4P86UMCgMWu++tSj2kCPYTCxaslWLYnNC6A/vjbDJ7xMx6dpx8AhfCHsjLGmDnrcf8Hwd0oIqwDQI/W9Szfp9k+AZ5oS1e2K80kvW1uCQDz12VVWXYw7xISUxdXqQ8IFOlVLKxm51hV5Yfed/KCfZkwIKwDQON48+MB2c2K3rJlDORddJ5kfv0hR+udb7fnVCz7/bx0Qy0o5NotgpncXLgW1gEgwqazZ5v6AquPauQJYvneXPyYkYfle3Ldpg/Fns2bj5xBYupibNfpfCdEuAjrADD1DpNj84cF58v5nJ8P4vfz07FktzV1CHfOXIMFG49asi9frNjr6Hm8OtOaIq/i0jKUuZkeVIQXX4poAymsA0AoFAG5enz15t/L3ZOwq8nns886mpvmXyrUXW/WtmPnkPrVTkNpQ+Mr5ND++e/xwje7PCcEcKWoFEnPLsZ3OwxPrS1ClKehXOwW1gEAACIjAv8BWXFz8NxXO53uMraWt8nXcDn3gMHTNpLV4P4Xt97MVZl49qsdVZZ/ssHYk03O+StgBt5Yut/qrAkVu4paQ4mhAEBEQ4kog4gyiShVZ30nIlpHRIVE9LRqeSsiWkVEe4loNxE9oVo3lYiOE9E25We4NadkzpDkJnYc1qX/bj2OZ77Yjjk/u58n+FD+ZZy8cLXi/ah31+qme+aLqhcqd6wITr50vVd/aYM1sExfkoFPN/o+qc/h/MtITF2ME+fMd+oTxrl6uhUGAgARRQKYCWAYgGQA9xJRsibZGQCTAbyuWV4C4Clm7gygD4CJmm1nMHN35ScNNri/d5uAH/OAm6khp3y2DQvTs/FKmmN2MSufIN1d210WNXkREP6z7oj5jQL8JQ2me8MtLp7eROgKpv8vd4w8AfQCkMnMh5i5CMACACPVCZj5FDNvAlCsWZ7DzFuU1xcB7AXQwpKcWyQuJtLuLHhNe3Ge9aP7pwZfXS0uxZOfbUNiatV5kS9crfzoy1xEjUN5nudEfuG/xsrR7bLruAxXLaqPKANpWgBQP+9mA+ht9kBElAjgegDqrnGTiOhBAOlwPCnIrZAP5q/LQrO6sZjy2TaPabccOas7iX3Va3flgkFv/lRRKax124yfPR5z5irPASrYG09YMftbsFcMCt+FyidsJADonYuprykR1QbwJYApzFzeNW4WgL8r+/o7gDcAPKKz7TgA4wCgdevWZg5bLbgrvyzVNDssKnEM92zEhP/bojmOvkKl4xkRXF78ASDn/FWX655auB2FJaWIiQqepy1/B5ri0jKcLSgKiZZm1VUw9AQOdkaKgLIBtFK9bwnAcPs1IqoBx8X/Y2b+qnw5M+cycykzlwF4H46ipiqYeQ4zpzBzSkJCgtHDGtatZT3L9xkoqzJOOb0/7WHgqaOnzc8cZsWAb19uycZ3O3I8J9QIxJeo/GZ8bWY+/vbtHsv2+9xXO9Hr5RUGe1L7fr+YmLrY5YB/vjpXUIT73l+P3Auug3ww8+aBa1PWGUuGRQn2JwEjAWATgPZElERE0QDGAFhkZOfkeNb9EMBeZn5Ts66Z6u0oALYU/trRDNQqenc4R88UuEw/z03lbKmFt0tW7GntwfyKC04gSkzu+2AD5q45bNn+luw+CaByCO4HPtyAuasd+/fX6fhrwL8vNmdj7cHTeO+nQ37ZfzC6e/a6KsOkV0cei4CYuYSIJgFYAiASwFxm3k1EE5T1s4moKRzl+HUAlBHRFDhaDHUD8ACAnUS0Tdnlc0qLn9eIqDsc14ssAOMtPK9q4czlIkPl+VaYv9YRHLxpO220l7B63yWlZWj3/Pf428guePDGxCpp1V8+fzzKGz3PsjJGUWkZYmv4Vnz1y4F8/HIgH4/0S5KxaWySc/4KSkoZrRrUsjsrQcNIHQCUC3aaZtls1euTcBQNaa2GixseZn7AeDbDU4+/L3O73sr246cumnu8V8+y9KkXQztcVeoW/vH9Pjx4Y6IlF8WrxaWmL9Seil+mL83ArB8PYu/fhqJmdGS1vngXlZQhPesMbmrXSHf93DWHcVePFri2Rd0A58w72hB/46srAQBZ00b4/9ghUgkQ9j2BQ9l7P9v3SO4pOPnDpE+26DZBBYBvt59Apz//YPnwu58rPakvFZqrCzHz/Q+WoPKPH/bhvg82uB0g788Gh7vwxpWiUsxclYmSUt9HvFXz1593bWa+x9nqguWzdUUCgDDEiorK/Eu+zY7kriJ55T5HhfieE9YFgP+sP1Ilz3p3dm4H/tL5swVrz9RMpYPimQLncw5Us9W3Vx7A9CUZ+GJztqntZq7KROapwE8bet8HGzDEQPPnYCYBQFjO1eXi5/15Fa99GS3xh13uWxS9veIAuk1d4vX+y/3Zik5pIVIUEAwKlKcsM0OJXCkqxfQlGfjNrHX+ypZPgr0oSAIAgL7tGtqdBdvpdQrzlvp//oDHR2TCsTMFhgdSAxx9GLLyXTdpfXPZflxw0Xw15/wVp0yuzsxzWaykxmBknrrkNP5SuV8OVDYXzDjpOF8z98y6HW2Y8er3ez3+/aqLkTPXuG2l5kp5Zb4VEyVZKVQGopMAAOC10dfZnYWgUVCkf/dlthRg7cF8LNl9EoMNPCKP/Wij2/V6x75a4sjnlaJSTF20W7e/QkFRidPQDd/tOIEbX12JtZn5FV/PNZmnPeav3KA3f8IcnXqXV9L2Vry+7S3H+Zbv/2xBEe6erT9QXzm988u7WIj3fjqE333ofVPE05cKDQ2/4UkgCoBc1TtcvFqMqYt26z4V5F64isFvuv7/Coa775IyRlcLnkb9xVAroOquRb2admchaFj1nTHThvqyyQpWtdGz12K3qtxf3Trp8U+2YsW+ys5yW46cAwDMXZOFtglxpo6z1E1TV+2FZpXqmF9uycamLOcRTswEU1/mmOn3j1W4UlzqstVLcWkZ5q3NwtibElEj0vW9oJ3X0X+tzMS/12ahTcNaeLhvktO6z9OP4biRlnA2V7n40pmSmf1aByNPAMLJYhcVre6KXLzh7qKi7dCkX/Hq+L1bU+l7/kplUdZmzSib5Y/ly/fmOhXbGGFmkLo8N5Pn/HP5AUP78PaiW1bGFUOEXPFQlj5vbRZeWrwXH5noAOePu2r1Z6ZVrLQICpfJ1t5avr/iO5iVfxlJz6Zh0Xb/TRwkAUAYYnWT0y1HHBdnveaVvgxp4O4CpV53KkDDGuzUjB46Y7m5SWDyLpqbie32d1bjmueMjaxe/re/VOg+UPj7BjrlJecmxV7NdhdkDau8DZRvLT+AiZ9swfI9uRUzxqV5MYyKUVIEJGyxI9u3YZXXHTyNDk3iqyz/eIOxikRX38+MkxfRtG4s6tasYTgv7i4+P2bkuV6puFJciuyzBWhZv7KHqrcXEO0Tkb9dLS5FGTNqRXt/KSkudX2ywVCOf/ZyEZbuORnQY/7eT+M6ackTgLCckS+tetRSI+3id2oCxt++24O3dO6mfW3NdNtbP2P0LPeVtp54OhttwPjTZ9vR7x+rAADnC4pxrsC3/hKuMLPbTl7ljp52PZ6U1g0vL0fyi/6v5NT+TTcePmOg5Y/7f8Sd2efxxIKtVUbV1Xris2343y+NzWMdaiQAiJBw+zurqyz718pMt9uccxMMzrgZOdXdjG1GeIp/7kbVvO5vS9H9b8sMNyM8V1BkuE/FV1uOY+TMNUjbmYPCklKX9Tp/WbTb6b06YGl7WvtSwZl/qRAzV7n/DPUcyL2Ie95bh7c9fP7l9G4wDudfxu3vrMY3207oNu1VM1sMF0qkCEhYzury2OV7/TPKpV2s6rSUc/5Kxfg2RmQqTUIP51/GM1/swDfbzFcuXi22rr39Uwu346f9novItHx9ytufe9FUD15fOi26s/7QaWSfvYLRPfWGUQsMeQIQtgtUBZ6/vsj6B/NxcwPbnzjnfUX2mszKVlB21Z+aaf6r/h/RK/oxcw5WDqLoizFz1uPpz7ejoKgEbyzNcFmk5c/vhzwBCMud9TAxTXXnj+9retYZtG5QC43ryAxjep3jtPHyzOWiinGcfO2V6+/7hndWZuLdHw8iIT7GvwfSIU8AwnJmvy++dAQzIwgalBimzuvWo2cxevY6DP3nLxXLXk3bi9/4WFltN28+j2NuJjxS23XceCszdwF7xrL9yPDzcBzlxWqungC+33WycggTi0kAEJYzW9Tiatweq5WP02MVV+fJgM+PAfmqisdR7zou9OUV12sy8y3tlxHMgVH7N3558V4XKV3TVgK/9kNGlTSLd+TgwtWqdQv/XGGs456W1U8Nf9DM4W0VCQDCcp46FtnF6gvdv9dm6S5/5osdXrWOKVM1Rxw5c43LdPd/4NtUhdOXZOgOzf3zAf0KWVexTN188seMU15V6BrFbKx56uIdOfhuxwm3n/WeHOeWTAfzLmHiJ1vw9MLthvMT6HqEKy7G6PKVBABFnVipDrHKQmUSlaBjcQTYcvQcMk9dxD6LnizaGuzBa4TZQeBOXyo0fdc6/j+VnZUe+mgTxs51HtTvfEEx3lq+3ymwGfHXb/dg38kL+OfyA0jb5eiANfung+g/fRX2uxj3vzxITfxkCyZ9stVp3dqD+fjWzXAK5QMgnjBRzKJXxGT2PM3w1+iiEgAUK576ld1ZEH62MeuM5fsc5GY0Sjtph6Bwh+B53CA9y/eecrv+L4t24a3lB9D2uTS8+M0unL5U6DR4m7uiwqFv/YIZy/dXtME/pfw+ftbYRVq97ycWbMPjn251mdaKSvu9ORfQ9rk0rFCaLGsv2As3HasoYioqKQtsizQ3DAUAIhpKRBlElElEqTrrOxHROiIqJKKnjWxLRA2IaBkRHVB+1/f9dLxnRw18deWpZ2V14e6u0l+GzPjJUDq94ZPL3Fx0Rr7jusjJ7GiUmaccHbVOq1qDzV93BD1fWo6+04z3W9Bj9D8r0P+BW5SBBz/dqP/0+8yXO/C/X+xA/qVCdHjhe3y4unIAPiN39/6KFx4DABFFApgJYBiAZAD3ElGyJtkZAJMBvG5i21QAK5i5PYAVynshgsJUTW/YYLE/11jRjnrogm5Tl+D0Jcf8Aq6c1mm6e/zcFWSfNT4sRLlX0/Zh4+EzWHvQ+FwLRgXbxC9a7jot5l8qrKg70OuEV2jDuRl5AugFIJOZDzFzEYAFAEaqEzDzKWbeBEBbje5u25EA5imv5wG407tTEMJ6rip4Q9GFqyVYd8jcxfjHjFPoO21lxRhFZmwzMN5QMPFm6A9fx+hXF9F9tCYLgD3BzUgAaAFA/VyTrSwzwt22TZg5BwCU3431dkBE44gonYjS8/L818pACFHpoY82ebVd7oWrFU8TnooCrSzVuFykGdvIxM6nL3E0CzUyKKFRropsvC3K8VeRlpEAoDtlqcH9+7KtIzHzHGZOYeaUhIQEM5ua9vmEG/26fyFCUfmkLEboze+gt7+pi3Yj383EOd741es/Vrz255y8e05cQEFRYPqu+JuRto/ZAFqp3rcEYLT2y922uUTUjJlziKgZAPdNCgLghsQGdmdBCL/wZf6FtJ3WTkiyat+pkC5iG/72L54ThQgjTwCbALQnoiQiigYwBsAig/t3t+0iAGOV12MBfGM820IIM/QmszfKzXwtVRgp4giTRmKm2TGrmccnAGYuIaJJAJYAiAQwl5l3E9EEZf1sImoKIB1AHQBlRDQFQDIzX9DbVtn1NAALiehRAEcB3G3xuQkhDCjyUMRj/XXJ/xHA7mb2rg4fbLHPUPdXZk4DkKZZNlv1+iQcxTuGtlWWnwZwq5nMBsL1reth69FzdmdDiIBRt0n3VbDMzfvxhqOmt/El70YCji+VzP7qOCY9gTWub2VrfzQhAi7QzQ8L/DSujdrKfd5VKR7IvYiHP9roOaEXNmadweYjZ/2yb2/JADhCCLfM3Bkb6QX+pIlB1wLt+f/uwsbD1g8ZUu7v3+3xajs7m4EKIcKYdiL5/249jvNX9KdlNNIMNBwEy1g/nsgTgIY/2w8LEYq0N/VTPtvmMu2yPSE+f7OXX38r6j7c1REUWjgXs5o8AQghLDPrx4N2Z8FrBO9GjP14wxFcUs3/cLW4FE8s2Gb++G6CyHE/zT8gTwBCCAFgu5ed5Z7/epfT+zeX7feqEtqOUiN5AhBCCAudK6g6smqwkgAghBBB4N9rreuPYZQEACGEsJC3RTlnC/RbVvmTBAAhhLDQ55uz7c6CYRIAhBAiTEkAEEKIMCUBQCNEOvAJIYTPJAC48Gi/JLuzIIQQfiUBwIUW9WranQUhhPArCQBCCBGmJABo3NWjBQBgQKfG+OWZATbnRggh/EfGAtLo1rIesqaNAAAUlvh/4gohhLCLoScAIhpKRBlElElEqTrriYjeVtbvIKIeyvKORLRN9XNBmS8YRDSViI6r1g239MyEEEK45fEJgIgiAcwEMBhANoBNRLSImdVT2wwD0F756Q1gFoDezJwBoLtqP8cBfK3abgYzv27BeQghhDDJyBNALwCZzHyImYsALAAwUpNmJID57LAeQD0iaqZJcyuAg8x8xOdcCyGE8JmRANACwDHV+2xlmdk0YwB8qlk2SSkymktEurOxE9E4IkonovS8vDwD2RVCCGGEkQCgN0+Ntr+s2zREFA3gDgCfq9bPAnANHEVEOQDe0Ds4M89h5hRmTklISDCQXSGEEEYYCQDZAFqp3rcEcMJkmmEAtjBzxYShzJzLzKXMXAbgfTiKmoQQQugo007ObAEjAWATgPZElKTcyY8BsEiTZhGAB5XWQH0AnGfmHNX6e6Ep/tHUEYwC4DyvmhBCiAprD562fJ8eWwExcwkRTQKwBEAkgLnMvJuIJijrZwNIAzAcQCaAAgAPl29PRLXgaEE0XrPr14ioOxxFRVk664UQQihKysos36ehjmDMnAbHRV69bLbqNQOY6GLbAgANdZY/YCqnNnu0XxI+XB34KduEEAKoWvFqBRkKwqBOTePtzoIQQlhKAoAB0ZERiI+VUTOEEPYpKbWnEjhsRZKjdWvvtg1szokQItydvHDV8n3Kba0bUZERWDKlP1rWr4lfDuTbnR0hRDjzw3SFEgA86Chl/0KIICCVwEHghkTdESuEEMKv/DFfuQQAk+rXirY7C0KIMMR+iAASAEzSfgRN68Takg8hRHiRIiAbkd5wdwBiasifUAjhf34YCkgCgFnap7CYKPkTCiH8b9uxc5bvU65eBrl4AEBcjDSkEkL439pM65uiSwAwzfkR4M7u2nlvhBDCemVSCWwfclEJEEHA0j/1x9yHUgKcIyFEOJFK4CDEADo0icfATk3w/oMSBIQQ/mHXhDDCoMHJTezOghCimpIngBD30E2JdmdBCBGqpBmo/bT1MJERznUDURGu2gsJIYT3pBLYRnqX9fG3tMXdPVs5Lfv+iZtd7sMfXbmFEOHBtiIgIhpKRBlElElEqTrriYjeVtbvIKIeqnVZRLSTiLYRUbpqeQMiWkZEB5TfITfK2rPDOiPa4o5g0ZESk4UQVdnyBEBEkQBmAhgGIBnAvUSUrEk2DEB75WccgFma9QOYuTszq5vJpAJYwcztAaxQ3gc9f9/Db31xsJ+PIIQIRXYNBdELQCYzH2LmIgALAIzUpBkJYD47rAdQj4iaedjvSADzlNfzANxpPNuB52osIE/p5jzQ0/rMCCHCjl3NQFsAOKZ6n60sM5qGASwlos1ENE6Vpgkz5wCA8ruxmYzbxWw5vpmmoeP6t0UNKQISQujwR+mDkYFs9O59tXlxl6YvM58gosYAlhHRPmb+2WgGlaAxDgBat25tdDPLqe/s338wBbEmRgGdensypn67x2O6B29sY3mdghCierBrPoBsAOqmLi0BnDCahpnLf58C8DUcRUoAkFteTKT8PqV3cGaew8wpzJySkJBgILv+Nzi5CW5ubzwvv+nZEoM6N8HEge18Ou5jNyehfePaPu1DCBGa7GoFtAlAeyJKIqJoAGMALNKkWQTgQaU1UB8A55k5h4jiiCgeAIgoDsAQALtU24xVXo8F8I2P5+JX3Vs5Gik91r+tofRtE+Jw+NXhICLEx9bAB2NT0Djet8ljGtWOwf29K5+CHu6b6NP+hBChw5YpIZm5BMAkAEsA7AWwkJl3E9EEIpqgJEsDcAhAJoD3AfxRWd4EwGoi2g5gI4DFzPyDsm4agMFEdADAYOV90GoQF42saSNw0zWNPKSsLCtyNYAcALw2upvpPPyqY2Onu4CuLeqa3ocQIjTVio60fJ+GBrNn5jQ4LvLqZbNVrxnARJ3tDgG4zsU+TwO41Uxmq5N7UlrhnpRWSExdbCh91rQRAIA1qjHBZS4CIcJHzzbWd5WSGscAe2pwB9R2ceGOidKP8B+oRhm1oy+xmQpvIYR/2FIEJMxpUa8moiIITw3uqLv+8VvbY9dfb6uyfN4jvZAQH6O7zSBVU9J2NlQCN69bM+DHFEI480dPYClDsFjN6EhkvjLc9Ha3dDDWqqhR7WgAQOdmdUwfQwgh1CQABLHvHu+HEk3vv6Z1HC2JRl3f3OU8xUKI6keKgMLMtS3qonurek7LGtaOQcZLQ/HYzZ6bo7ZpWMuSfDwxqL0l+xFCeI/9UAMoAcBmsTUi0Lyuuf4BMVGRbpuYlhcTNartXKfwx19dYzp/WdNGYKRMfC9EtSRFQDbb/dehlu6vf4cE7DlxHgDwuz6tsfnIWQDA8if7o13jeLz740FLjyeECAx/jAYqAcBm2hnFvDGwU2M8PaQjkps7KoZTXloGAOjXLgHbXhyMpXty0a5xPADgzXuuw5MLt/t8TCFEYDWp49tIAnqkCKgaiCCquPhr1asVjXtSKodpGnpt0yppnhmq32RVCBE8bu1k/YDJ8gQgUCe2RpVlX/7hJrRtFGdDboQQgSIBQCAl0bmL+fYXh6BuLeeg0Dg+BqcuFgYyW0IIFWkFJJykJDZAjUjC+Fucm4QO6Oh4VKypM3hU+ZzD429pW/E6qVFcxVhDAKpc/AHgu8n98MWEG13m5ekhHdzmtW1CHMYbHElVq0U96YkshD/6AcgTQAhrEBeNAy9X7XX88qiumOJizKGoyAgcemU4iIDh1zbD11uPG5qIvnF8rNvhrCcOaIcPVh/GuYJi3fUfjr0BSY3i8N7PhzweS+uxm5MMTajTqWk89p28aHr/QoQCu+YEFjaoEel966DoqAi3d80REQQiwnWt6mHqHV3c9inwpEW9mph2V1cQEb6d1M9luqQA1CcMu9bTNNRCCDUJAEFo8wuDkP7C4IAf96GbEnH7dc09pqtbs7KIaE3qQIzp5ZikplWDWph2V1d0ahrvctuDrwzHgnF9nJb9z22+tUK6v3drJMTH4K4e5jqs3XRNQ1Ppeyc1MJVeCCv5Y7pYCQBBqGHtGKeLbKBMvaML/nXv9W7TbHp+EH753wHo0rwORl1f9YI7pldrzH+0l86WDpERhD5tGyJt8s2G8mSk/P/lUV2x6flBpttJa8tUNz7venqKJwd3wEM3JRre9106fxshfFGrhvUTwkgAEKYkxMegTmwNLJ58M2b8trtuGiNTX2r7Lbw2upvuxX5N6sAqy5b+qb/uPqOjIrA2dSA+eugGfPz73h7zoBXhpijMbCFZH5NPF0J4YtecwEL43T0praoUDZVr07Cy/qBFvZro0MR1EVPzejUxoFNj9G3naepOICnBuV6CADx4YxvdtL3MFv+ovq2/PDPA3LZwDN0RTCbfKgMCVkcSAETQ+u5xR6XyAFUPSO0TgbuKZy3toHsv/joZ/374BjSIi65YFhWh/5Xo3bbyjn5ol6ZVpuezupK7sR+6/fviupYy/7Td2A/tQA0FACIaSkQZRJRJRKk664mI3lbW7yCiHsryVkS0ioj2EtFuInpCtc1UIjpORNuUH/OzqIhqIcZF5da1qknv42P1Wyx3dXNh+uihG5zefzb+RuycOqTifWyNSPyqo3P3+imDK+903ZX5f/qY89PKZ+Mr37dpWAvXNK4MCDE6U2p2aFJ1Zrdk1SQ/3n7XP3nMfNGXJ3ZUft+QaP38t6IqjwGAiCIBzAQwDEAygHuJKFmTbBiA9srPOACzlOUlAJ5i5s4A+gCYqNl2BjN3V36cJp0X4eMBF8Uuaosm9cM/ftPV1H4HdGqM1g0q50SIiiTE6wx7MXlgOwBA7dgo1ImtgYkDHMNma8dN6pXUALE1IjDulrZVWmQ0jo9FR6VoauZ9PdCzTQOndR+OTXFq7aRXYZ32xM0uA51R7Ru7Lh5z58DLw3BIZya7JnVi8Nn4G+FDS2GvaOfBEPbVAfQCkMnMh5i5CMACACM1aUYCmM8O6wHUI6JmzJzDzFsAgJkvAtgLQJpHhIHx/dvivQd6GkobE+W5dUNSozj89obWpvMxRWcym/t7t8b00d0q3j/UNwlZ00ZU5GPKoA6Y/0gv9GnbEHMe6FlRFNWwdgz2/X0YerR2f3eqN8LrrZ2b4A+3XIP7e+ufg15ldzlXzf/+8Zuuhuomtv9liMc0NSIjEOHjyLRmmtW+epe5YO6Le3uZ/78xo03DWnhlVODOx0pGAkALAMdU77NR9SLuMQ0RJQK4HsAG1eJJSpHRXCLS/VYR0TgiSiei9Ly8PAPZFcHg2eGdcVuXqiOPGjWimzWduu7q0RKP9E0CgIqe0S+P6oq7VSOkatWIjEB/ZY7mIV2aOhVFuaO9S176p/6Y+1BKxfuICMLg5CZKWufEVVpAqW73lv/pFt1mpb+9oTV+3y/JaZneE4QVTYr7tPV8ca+lM/SIKzUM9D63yq8t+l9y5d8P96r4XP1JW+9kBSOfgt5tgfZpxG0aIqoN4EsAU5j5grJ4FoBrAHQHkAPgDb2DM/McZk5h5pSEBGMTp4vg0qqBflv+6aO74fsnqvYHSIiPwdtj3PdHMOP5EZ2x5c+DdYt/fLEmdSC2vzikYhylQZ0dF4GGyoxsHZrEY2An1xcGvVZPel+k1g1rubzADFRVkB9+dThiXbQVV4/15M2YTLWio7D+2Vvx3PBOLtN4qrdYPLkf/nJ7MmJrRKB/e/ettBrExbhdX+7d+3vghRGd3aZR1634Q1KjOCTEG8uvtx7tl1Rlhj8rGAkA2QDUt0stAZwwmoaIasBx8f+Ymb8qT8DMucxcysxlAN6Ho6hJVDNpk2/Goon6LXXuTmmFzjpfzpioCEMT5Vzfup6hPERGkFNLH6u0qFfTaeC8Jwd3QPoLgwz1gwAcd9XzHumF9x+sfEqIU43ftGhS34rml+WV3doK2ajICNM9oEcp6fXGilo82XWrqqZ1YzGu/zVe3+12aV4XD/dNwr6/D/PYyknvrn3eI5WXiNE9W2L66G4Y3rUZfn9zW6d8v/dATzw/vDIo1Nd89vektDSU30c1T1cAKoZI1yta9KSpgZZdroLzQD/MBQAYCwCbALQnoiQiigYwBsAiTZpFAB5UWgP1AXCemXPI8Zz7IYC9zPymegMiUn/CowDs8vosRNBKbl6nyhfQlfKL6R0GhqPY9uLgKi1x7BYRQR7v0rQ3ybd0SHC6oH76WB88N7wT6taqgW4t6+HJwY5RVlvWr4WsaSPw2fiqI7K+9ptu2P6XIVWKlZY/2V/3Caum8pSgFxS7NPdc3OVNC6Uv/3CTy3V6TUyjIskpMGo1jIt2Ksbr0rxuxd+qR+v6GOuiBVfTOrF4bfR1+FVH96UJjw9sV/H3UdfBfPt4P8y8rwemDHI/+q1WQnyMoe/BfUod0ULN52ykX4s3PAYAZi4BMAnAEjgqcRcy824imkBEE5RkaQAOAciE427+j8ryvgAeADBQp7nna0S0k4h2ABgA4E+WnZUISXVia2DXX2/D00M8jw1Ur1a0y+KOUODq+SaxURzG9b/G1L6iIiN0y/nbNY7XfcKyyl/v6IIXf61tEOjM3VNa1rQR2Pj8rfjqj30x6/4eFctfHnUtmtWticHJTSqKyYz0Q5h8a3tkTRuBhPgYlxXny5QOdrN/1xN1XLS4+n2/JDw1pGNFAHhG1XorLibKVP3UpAHt8OHYFKxLHVjRjt/dU1abho6h2a9rFZh+F4banClNNNM0y2arXjOAiTrbrYaL/3VmfsBUTkVY0CuWEObd0sGa+jK9jnHtm9TG8r25uLZFXac+HD3a1MeKfadc7En/saG8uGxY18qL6v29qzYLjomKRGLDyia93jaJLK8Hiq0RiWZ1a+LC1YuYPLAd3l6ZCQCY/0gv9FPutn+b0gpREYRR17fAS4v3enW8p3UGOiQQZt7XAxM/2eJyu5ioSHz9x5sw6t21fq1glm+bENXM/peGGapD8WTywHa4U6f10ZODO6B/+4SKVimHXhmOrNOXkdgwDtOXZDilNZOL3X+9rcqyKOU8akZHok3DOEwccA1mrjpoYq+eDe/WDL9k5mPr0XOIi4mqaA4bEUEVxUwz7+uB/bnm5pp4edS1LtcNU/UxGdG1GRbvzKmS5vrW9ZH58jC3Y1T5SgKAEAHUWGkt0qW5/4pmzAwb3LNNfWw+clZ33ZMuiuJqREbgRlWb/4gIQtsER8/mZ4d1QvqRszicfxkjujbDLweMN92O03n669mmPv40qENF2bje/NXeMjPF4ohuzTAC7ot+Rl3fAuevFGOl8hSk9yRTflx1n4vhLgIA4Cje8ycJAEIEUJfmdfHtpH7o3My7HrtWaFInFhHkKJ4Y1LkxzmpmcRvZvbnTHaoZ42+5BuNV7yMjCFuOnjM9VHc5IsITXrS4AYDhXZvi+Nkrno8Bwl09WmLr0XMumywbUT46bmLqYkPpeyU1wMbDZ1Cnpn2XYQkAQgSYu/GLAiG2RiQOvVrZL6BWtPNl4J8W9sGYNKAdxtzQypbB7d6931hPdAD4Xe/WuK9Xa1NFZ9893g95FwtN54uUgjH1rH+P3ZyE9385bHpfvpIAIESIeeimRPxsomjFThERZOnF/64eLfHfbSdcNvN0ZeVTt+DM5SKX64kIZmdhNdpD3BMC4fkRyXh+hPsWVf4gAUCIEDP1ji5ebde/QwJqWFA5bKeE+Bjdvg2etE2ojbaahlF+GF055EgAECJMzH9EOtvrCdRIp0mN4rDv5MUqYyaZqYy2mgQAIYQIgOl3X4e7U1oiURlOgkxPNGo9mRFMCBGWOjZ1tMQyM4qpL2rHRLkdHNAO8gQghAhLr43uht/1aYOW9Wt5TlxNyROAECIs1YqOMjTPgb8M6+roa5HY0Nr5pM2QJwAhhLDBfb1a4zc9Wto6qKE8AQghhA2IyPYRbSUACCFEmJIAIIQQYUoCgBBCWMiKobgDRSqBhRDCQmmTbzY1DLadJAAIIYSFOjaNr+hkFuwMFQER0VAiyiCiTCJK1VlPRPS2sn4HEfXwtC0RNSCiZUR0QPld35pTEkIIYYTHAEBEkQBmAhgGIBnAvUSkHbd0GID2ys84ALMMbJsKYAUztwewQnkvhBAiQIw8AfQCkMnMh5i5CMACACM1aUYCmM8O6wHUI6JmHrYdCWCe8noegDt9OxUhhBBmGAkALQAcU73PVpYZSeNu2ybMnAMAyu/GegcnonFElE5E6Xl5oVGxIoQQocBIANBr06QdwNpVGiPbusXMc5g5hZlTEhISPG8ghBDCECMBIBtAK9X7lgBOGEzjbttcpZgIyu9TxrMthBDCV0YCwCYA7YkoiYiiAYwBsEiTZhGAB5XWQH0AnFeKddxtuwjAWOX1WADf+HguQgghTPDYD4CZS4hoEoAlACIBzGXm3UQ0QVk/G0AagOEAMgEUAHjY3bbKrqcBWEhEjwI4CuBuS89MCCGEW8QhNDMyEeUBOOLl5o0A5FuYnWAi5xaa5NxCUyieWxtmrlKJGlIBwBdElM7MKXbnwx/k3EKTnFtoqk7nJoPBCSFEmJIAIIQQYSqcAsAcuzPgR3JuoUnOLTRVm3MLmzoAIYQQzsLpCUAIIYSKBAAhhAhTYREAPM1nEIyIKIuIdhLRNiJKV5a5nEOBiJ5Vzi+DiG5TLe+p7CdTmbMh4PPVEdFcIjpFRLtUyyw7FyKKIaLPlOUbiCjR5nObSkTHlc9uGxEND9Fza0VEq4hoLxHtJqInlOUh/dm5Oa9q8bmZwszV+geOHsgHAbQFEA1gO4Bku/NlIN9ZABpplr0GIFV5nQrgH8rrZOW8YgAkKecbqazbCOBGOAbm+x7AMBvOpT+AHgB2+eNcAPwRwGzl9RgAn9l8blMBPK2TNtTOrRmAHsrreAD7lXMI6c/OzXlVi8/NzE84PAEYmc8gVLiaQ2EkgAXMXMjMh+EYkqMXOQbZq8PM69jxnzgfNsy7wMw/AzijWWzluaj39QWAWwP1pOPi3FwJtXPLYeYtyuuLAPbCMZx7SH92bs7LlZA4L2+EQwAwMp9BMGIAS4loMxGNU5a5mkPB3XwM2TrLg4GV51KxDTOXADgPoKHfcm7MJHJMjzpXVUQSsuemFGFcD2ADqtFnpzkvoJp9bp6EQwDweU4Cm/Rl5h5wTKc5kYj6u0nrt/kYbODNuQTbec4CcA2A7gByALyhLA/JcyOi2gC+BDCFmS+4S6qzLGjPT+e8qtXnZkQ4BAAj8xkEHWY+ofw+BeBrOIqyXM2h4G4+hpY6y4OBledSsQ0RRQGoC+PFMpZj5lxmLmXmMgDvw/HZASF4bkRUA46L5MfM/JWyOOQ/O73zqk6fm1HhEACMzGcQVIgojojiy18DGAJgF1zPobAIwBil5UESgPYANiqP5xeJqI9S/vgggmfeBSvPRb2v0QBWKmWytii/OCpGwfHZASF2bkpePgSwl5nfVK0K6c/O1XlVl8/NFLtroQPxA8dcBfvhqL1/3u78GMhvWzhaHWwHsLs8z3CUIa4AcED53UC1zfPK+WVA1dIHQAoc/8gHAbwDpfd3gM/nUzgeqYvhuDN61MpzARAL4HM4Kuc2Amhr87n9B8BOADvguBA0C9Fz6wdHscUOANuUn+Gh/tm5Oa9q8bmZ+ZGhIIQQIkyFQxGQEEIIHRIAhBAiTEkAEEKIMCUBQAghwpQEACGECFMSAIQQIkxJABBCiDD1/3sWUm1bdUx+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29673 3218\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29673 464\n",
      "Loss:  0.17278572916984558\n",
      "Loss:  0.17154090106487274\n",
      "Loss:  0.16378499567508698\n",
      "0 **********\n",
      "Epoch:  93.25166296958923  fold:  5  kers:  128\n",
      "epoch:  1\n",
      "29673 464\n",
      "Loss:  0.15103036165237427\n",
      "Loss:  0.14586256444454193\n",
      "Loss:  0.13221615552902222\n",
      "1 **********\n",
      "Epoch:  174.25008964538574  fold:  5  kers:  128\n",
      "epoch:  2\n",
      "29673 464\n",
      "Loss:  0.12583766877651215\n",
      "Loss:  0.11693669855594635\n",
      "Loss:  0.09845234453678131\n",
      "2 **********\n",
      "Epoch:  255.23455357551575  fold:  5  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.17897041141986847\n",
      "Eval Loss:  0.38631680607795715\n",
      "Eval Loss:  0.264109343290329\n",
      "[[2761  336]\n",
      " [  34   87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      3097\n",
      "           1       0.21      0.72      0.32       121\n",
      "\n",
      "    accuracy                           0.89      3218\n",
      "   macro avg       0.60      0.81      0.63      3218\n",
      "weighted avg       0.96      0.89      0.91      3218\n",
      "\n",
      "acc:  0.8850217526413922\n",
      "pre:  0.20567375886524822\n",
      "rec:  0.71900826446281\n",
      "ma F1:  0.6285279641388124\n",
      "mi F1:  0.8850217526413923\n",
      "we F1:  0.9139900114775102\n",
      "update!  Acc:  0.8850217526413922\n",
      "Eval Loss:  0.3978174328804016\n",
      "Eval Loss:  0.36027583479881287\n",
      "Eval Loss:  0.41033875942230225\n",
      "Eval Loss:  0.3518686592578888\n",
      "Eval Loss:  0.3957223892211914\n",
      "Eval Loss:  0.4000486731529236\n",
      "Eval Loss:  0.3886154890060425\n",
      "Eval Loss:  0.472925066947937\n",
      "Eval Loss:  0.4305175244808197\n",
      "Eval Loss:  0.4258926510810852\n",
      "Eval Loss:  0.3901333212852478\n",
      "Eval Loss:  0.5702636241912842\n",
      "Eval Loss:  0.3715166747570038\n",
      "Eval Loss:  0.4494393467903137\n",
      "Eval Loss:  0.32994765043258667\n",
      "Eval Loss:  0.44007667899131775\n",
      "Eval Loss:  0.4036337733268738\n",
      "Eval Loss:  0.49073541164398193\n",
      "Eval Loss:  0.4730081558227539\n",
      "Eval Loss:  0.43446171283721924\n",
      "Eval Loss:  0.397644966840744\n",
      "Eval Loss:  0.42017099261283875\n",
      "Eval Loss:  0.45260339975357056\n",
      "Eval Loss:  0.33568260073661804\n",
      "Eval Loss:  0.40438276529312134\n",
      "Eval Loss:  0.4045145809650421\n",
      "Eval Loss:  0.43939536809921265\n",
      "Eval Loss:  0.4142742455005646\n",
      "Eval Loss:  0.34396442770957947\n",
      "[[14560  2507]\n",
      " [ 2806  9800]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85     17067\n",
      "           1       0.80      0.78      0.79     12606\n",
      "\n",
      "    accuracy                           0.82     29673\n",
      "   macro avg       0.82      0.82      0.82     29673\n",
      "weighted avg       0.82      0.82      0.82     29673\n",
      "\n",
      "acc:  0.8209483368719037\n",
      "pre:  0.7962947915820265\n",
      "rec:  0.7774075836903062\n",
      "ma F1:  0.8162190966543648\n",
      "mi F1:  0.8209483368719037\n",
      "we F1:  0.8206512690515162\n",
      "29673 464\n",
      "Loss:  0.1033969447016716\n",
      "Loss:  0.09404347091913223\n",
      "Loss:  0.08805278688669205\n",
      "3 **********\n",
      "Epoch:  379.4584045410156  fold:  5  kers:  128\n",
      "epoch:  4\n",
      "29673 464\n",
      "Loss:  0.09664277732372284\n",
      "Loss:  0.11316743493080139\n",
      "Loss:  0.09860365837812424\n",
      "4 **********\n",
      "Epoch:  460.43090057373047  fold:  5  kers:  128\n",
      "epoch:  5\n",
      "29673 464\n",
      "Loss:  0.08534561842679977\n",
      "Loss:  0.10442101955413818\n",
      "Loss:  0.09240666031837463\n",
      "5 **********\n",
      "Epoch:  541.4402980804443  fold:  5  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.1101299375295639\n",
      "Eval Loss:  0.2122243046760559\n",
      "Eval Loss:  0.10890296846628189\n",
      "[[3007   90]\n",
      " [  46   75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      3097\n",
      "           1       0.45      0.62      0.52       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.72      0.80      0.75      3218\n",
      "weighted avg       0.96      0.96      0.96      3218\n",
      "\n",
      "acc:  0.9577377252952144\n",
      "pre:  0.45454545454545453\n",
      "rec:  0.6198347107438017\n",
      "ma F1:  0.7511808516686566\n",
      "mi F1:  0.9577377252952144\n",
      "we F1:  0.9608374873823797\n",
      "update!  Acc:  0.9577377252952144\n",
      "Eval Loss:  0.4357790946960449\n",
      "Eval Loss:  0.3927324712276459\n",
      "Eval Loss:  0.4418400824069977\n",
      "Eval Loss:  0.3198513686656952\n",
      "Eval Loss:  0.4203183948993683\n",
      "Eval Loss:  0.39355650544166565\n",
      "Eval Loss:  0.47903531789779663\n",
      "Eval Loss:  0.4131762385368347\n",
      "Eval Loss:  0.42307543754577637\n",
      "Eval Loss:  0.40046006441116333\n",
      "Eval Loss:  0.45289647579193115\n",
      "Eval Loss:  0.6174008846282959\n",
      "Eval Loss:  0.36219286918640137\n",
      "Eval Loss:  0.4854695498943329\n",
      "Eval Loss:  0.30572113394737244\n",
      "Eval Loss:  0.44520944356918335\n",
      "Eval Loss:  0.4049493372440338\n",
      "Eval Loss:  0.4754485487937927\n",
      "Eval Loss:  0.5236803889274597\n",
      "Eval Loss:  0.47831711173057556\n",
      "Eval Loss:  0.36889714002609253\n",
      "Eval Loss:  0.5622819662094116\n",
      "Eval Loss:  0.5480971336364746\n",
      "Eval Loss:  0.31493982672691345\n",
      "Eval Loss:  0.4234909117221832\n",
      "Eval Loss:  0.4536173939704895\n",
      "Eval Loss:  0.5057705640792847\n",
      "Eval Loss:  0.5812022686004639\n",
      "Eval Loss:  0.386393666267395\n",
      "[[16157   910]\n",
      " [ 4234  8372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86     17067\n",
      "           1       0.90      0.66      0.76     12606\n",
      "\n",
      "    accuracy                           0.83     29673\n",
      "   macro avg       0.85      0.81      0.81     29673\n",
      "weighted avg       0.84      0.83      0.82     29673\n",
      "\n",
      "acc:  0.8266437502106292\n",
      "pre:  0.9019607843137255\n",
      "rec:  0.6641281929240045\n",
      "ma F1:  0.8138291201935641\n",
      "mi F1:  0.8266437502106292\n",
      "we F1:  0.8211722241763679\n",
      "29673 464\n",
      "Loss:  0.10258068144321442\n",
      "Loss:  0.08775583654642105\n",
      "Loss:  0.12410920858383179\n",
      "6 **********\n",
      "Epoch:  665.674122095108  fold:  5  kers:  128\n",
      "epoch:  7\n",
      "29673 464\n",
      "Loss:  0.14215940237045288\n",
      "Loss:  0.11435175687074661\n",
      "Loss:  0.08717228472232819\n",
      "7 **********\n",
      "Epoch:  746.6286661624908  fold:  5  kers:  128\n",
      "epoch:  8\n",
      "29673 464\n",
      "Loss:  0.10368887335062027\n",
      "Loss:  0.07415689527988434\n",
      "Loss:  0.07440562546253204\n",
      "8 **********\n",
      "Epoch:  827.625097990036  fold:  5  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.0955272763967514\n",
      "Eval Loss:  0.17377173900604248\n",
      "Eval Loss:  0.08117347210645676\n",
      "[[3038   59]\n",
      " [  49   72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3097\n",
      "           1       0.55      0.60      0.57       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.79      0.78      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.966438781852082\n",
      "pre:  0.549618320610687\n",
      "rec:  0.5950413223140496\n",
      "ma F1:  0.7769820735538717\n",
      "mi F1:  0.9664387818520821\n",
      "we F1:  0.9670775435118872\n",
      "update!  Acc:  0.966438781852082\n",
      "Eval Loss:  0.44128063321113586\n",
      "Eval Loss:  0.36119508743286133\n",
      "Eval Loss:  0.42249372601509094\n",
      "Eval Loss:  0.29956114292144775\n",
      "Eval Loss:  0.4304880201816559\n",
      "Eval Loss:  0.345402330160141\n",
      "Eval Loss:  0.42764702439308167\n",
      "Eval Loss:  0.3542138636112213\n",
      "Eval Loss:  0.40477240085601807\n",
      "Eval Loss:  0.4052206575870514\n",
      "Eval Loss:  0.4304167330265045\n",
      "Eval Loss:  0.5486574769020081\n",
      "Eval Loss:  0.35402897000312805\n",
      "Eval Loss:  0.41570401191711426\n",
      "Eval Loss:  0.2569005489349365\n",
      "Eval Loss:  0.40409719944000244\n",
      "Eval Loss:  0.3978714644908905\n",
      "Eval Loss:  0.4007863402366638\n",
      "Eval Loss:  0.44471293687820435\n",
      "Eval Loss:  0.43316030502319336\n",
      "Eval Loss:  0.32662907242774963\n",
      "Eval Loss:  0.5136040449142456\n",
      "Eval Loss:  0.5205511450767517\n",
      "Eval Loss:  0.28745588660240173\n",
      "Eval Loss:  0.35241952538490295\n",
      "Eval Loss:  0.4141539931297302\n",
      "Eval Loss:  0.45922064781188965\n",
      "Eval Loss:  0.5549838542938232\n",
      "Eval Loss:  0.34372127056121826\n",
      "[[16337   730]\n",
      " [ 4086  8520]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87     17067\n",
      "           1       0.92      0.68      0.78     12606\n",
      "\n",
      "    accuracy                           0.84     29673\n",
      "   macro avg       0.86      0.82      0.83     29673\n",
      "weighted avg       0.85      0.84      0.83     29673\n",
      "\n",
      "acc:  0.8376975701816466\n",
      "pre:  0.9210810810810811\n",
      "rec:  0.6758686339838172\n",
      "ma F1:  0.825593843082411\n",
      "mi F1:  0.8376975701816466\n",
      "we F1:  0.8325011894543811\n",
      "29673 464\n",
      "Loss:  0.0896650180220604\n",
      "Loss:  0.09923407435417175\n",
      "Loss:  0.09642255306243896\n",
      "9 **********\n",
      "Epoch:  952.1301965713501  fold:  5  kers:  128\n",
      "epoch:  10\n",
      "29673 464\n",
      "Loss:  0.08336703479290009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08525136858224869\n",
      "Loss:  0.08534663170576096\n",
      "10 **********\n",
      "Epoch:  1033.1306183338165  fold:  5  kers:  128\n",
      "epoch:  11\n",
      "29673 464\n",
      "Loss:  0.06900008767843246\n",
      "Loss:  0.09332498162984848\n",
      "Loss:  0.08876027166843414\n",
      "11 **********\n",
      "Epoch:  1114.1190712451935  fold:  5  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.0802634209394455\n",
      "Eval Loss:  0.13053688406944275\n",
      "Eval Loss:  0.05494336038827896\n",
      "[[3053   44]\n",
      " [  41   80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.65      0.66      0.65       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.82      0.82      0.82      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.973586078309509\n",
      "pre:  0.6451612903225806\n",
      "rec:  0.6611570247933884\n",
      "ma F1:  0.8196658084975228\n",
      "mi F1:  0.973586078309509\n",
      "we F1:  0.9737413964425182\n",
      "update!  Acc:  0.973586078309509\n",
      "Eval Loss:  0.39345404505729675\n",
      "Eval Loss:  0.3087741732597351\n",
      "Eval Loss:  0.34200426936149597\n",
      "Eval Loss:  0.2529572546482086\n",
      "Eval Loss:  0.4099501669406891\n",
      "Eval Loss:  0.26488471031188965\n",
      "Eval Loss:  0.3714042901992798\n",
      "Eval Loss:  0.2672264575958252\n",
      "Eval Loss:  0.4009399116039276\n",
      "Eval Loss:  0.3479042649269104\n",
      "Eval Loss:  0.3735281527042389\n",
      "Eval Loss:  0.4374271035194397\n",
      "Eval Loss:  0.27489832043647766\n",
      "Eval Loss:  0.3872966468334198\n",
      "Eval Loss:  0.20375360548496246\n",
      "Eval Loss:  0.3615497350692749\n",
      "Eval Loss:  0.35957327485084534\n",
      "Eval Loss:  0.3650922477245331\n",
      "Eval Loss:  0.3727341592311859\n",
      "Eval Loss:  0.38045740127563477\n",
      "Eval Loss:  0.2559964656829834\n",
      "Eval Loss:  0.40753981471061707\n",
      "Eval Loss:  0.3963354825973511\n",
      "Eval Loss:  0.25207406282424927\n",
      "Eval Loss:  0.30486366152763367\n",
      "Eval Loss:  0.3299672305583954\n",
      "Eval Loss:  0.42587143182754517\n",
      "Eval Loss:  0.5214956402778625\n",
      "Eval Loss:  0.3285123109817505\n",
      "[[16130   937]\n",
      " [ 3272  9334]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88     17067\n",
      "           1       0.91      0.74      0.82     12606\n",
      "\n",
      "    accuracy                           0.86     29673\n",
      "   macro avg       0.87      0.84      0.85     29673\n",
      "weighted avg       0.86      0.86      0.86     29673\n",
      "\n",
      "acc:  0.8581538772621575\n",
      "pre:  0.9087722714438711\n",
      "rec:  0.7404410598127875\n",
      "ma F1:  0.8503014977275962\n",
      "mi F1:  0.8581538772621574\n",
      "we F1:  0.8554559216686907\n",
      "29673 464\n",
      "Loss:  0.05704887956380844\n",
      "Loss:  0.08300384879112244\n",
      "Loss:  0.07242440432310104\n",
      "12 **********\n",
      "Epoch:  1238.3429219722748  fold:  5  kers:  128\n",
      "epoch:  13\n",
      "29673 464\n",
      "Loss:  0.10895483940839767\n",
      "Loss:  0.059111338108778\n",
      "Loss:  0.07180552184581757\n",
      "13 **********\n",
      "Epoch:  1319.3413481712341  fold:  5  kers:  128\n",
      "epoch:  14\n",
      "29673 464\n",
      "Loss:  0.09445928037166595\n",
      "Loss:  0.10459482669830322\n",
      "Loss:  0.06625673919916153\n",
      "14 **********\n",
      "Epoch:  1400.349748134613  fold:  5  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.08495982736349106\n",
      "Eval Loss:  0.1676066815853119\n",
      "Eval Loss:  0.08708848804235458\n",
      "[[3035   62]\n",
      " [  42   79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.56      0.65      0.60       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.82      0.79      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9676817899316346\n",
      "pre:  0.5602836879432624\n",
      "rec:  0.6528925619834711\n",
      "ma F1:  0.7931043009715699\n",
      "mi F1:  0.9676817899316346\n",
      "we F1:  0.9688629637405659\n",
      "Eval Loss:  0.3225749731063843\n",
      "Eval Loss:  0.2524067163467407\n",
      "Eval Loss:  0.33266764879226685\n",
      "Eval Loss:  0.21502244472503662\n",
      "Eval Loss:  0.33092010021209717\n",
      "Eval Loss:  0.25350430607795715\n",
      "Eval Loss:  0.3208358585834503\n",
      "Eval Loss:  0.22737233340740204\n",
      "Eval Loss:  0.3268510103225708\n",
      "Eval Loss:  0.35108694434165955\n",
      "Eval Loss:  0.33223146200180054\n",
      "Eval Loss:  0.345988929271698\n",
      "Eval Loss:  0.2304668426513672\n",
      "Eval Loss:  0.3366538882255554\n",
      "Eval Loss:  0.16691173613071442\n",
      "Eval Loss:  0.28989046812057495\n",
      "Eval Loss:  0.3038172721862793\n",
      "Eval Loss:  0.31615471839904785\n",
      "Eval Loss:  0.26872894167900085\n",
      "Eval Loss:  0.2991081178188324\n",
      "Eval Loss:  0.22393132746219635\n",
      "Eval Loss:  0.31806594133377075\n",
      "Eval Loss:  0.32660186290740967\n",
      "Eval Loss:  0.2313488870859146\n",
      "Eval Loss:  0.2762407660484314\n",
      "Eval Loss:  0.2722555994987488\n",
      "Eval Loss:  0.3594517111778259\n",
      "Eval Loss:  0.3998434543609619\n",
      "Eval Loss:  0.29271623492240906\n",
      "[[15922  1145]\n",
      " [ 2418 10188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     17067\n",
      "           1       0.90      0.81      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.88      0.87      0.88     29673\n",
      "weighted avg       0.88      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8799245104977589\n",
      "pre:  0.8989676166946087\n",
      "rec:  0.8081865778200856\n",
      "ma F1:  0.8752667773060749\n",
      "mi F1:  0.8799245104977589\n",
      "we F1:  0.8788904514895598\n",
      "29673 464\n",
      "Loss:  0.09015044569969177\n",
      "Loss:  0.1008227989077568\n",
      "Loss:  0.059591468423604965\n",
      "15 **********\n",
      "Epoch:  1524.4539189338684  fold:  5  kers:  128\n",
      "epoch:  16\n",
      "29673 464\n",
      "Loss:  0.09406173974275589\n",
      "Loss:  0.093576580286026\n",
      "Loss:  0.08691507577896118\n",
      "16 **********\n",
      "Epoch:  1605.452345609665  fold:  5  kers:  128\n",
      "epoch:  17\n",
      "29673 464\n",
      "Loss:  0.09886578470468521\n",
      "Loss:  0.051548391580581665\n",
      "Loss:  0.06971804052591324\n",
      "17 **********\n",
      "Epoch:  1686.4816896915436  fold:  5  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.07964064925909042\n",
      "Eval Loss:  0.1257178634405136\n",
      "Eval Loss:  0.05286039784550667\n",
      "[[3048   49]\n",
      " [  30   91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.65      0.75      0.70       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.82      0.87      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9754505904288377\n",
      "pre:  0.65\n",
      "rec:  0.7520661157024794\n",
      "ma F1:  0.8422622426978144\n",
      "mi F1:  0.9754505904288377\n",
      "we F1:  0.9763063829911947\n",
      "update!  Acc:  0.9754505904288377\n",
      "Eval Loss:  0.26700472831726074\n",
      "Eval Loss:  0.22213856875896454\n",
      "Eval Loss:  0.28972312808036804\n",
      "Eval Loss:  0.17699803411960602\n",
      "Eval Loss:  0.32625913619995117\n",
      "Eval Loss:  0.23580782115459442\n",
      "Eval Loss:  0.3333926498889923\n",
      "Eval Loss:  0.17682193219661713\n",
      "Eval Loss:  0.3119373023509979\n",
      "Eval Loss:  0.3228144645690918\n",
      "Eval Loss:  0.3107318878173828\n",
      "Eval Loss:  0.27059751749038696\n",
      "Eval Loss:  0.2404841035604477\n",
      "Eval Loss:  0.322214812040329\n",
      "Eval Loss:  0.13657666742801666\n",
      "Eval Loss:  0.263937383890152\n",
      "Eval Loss:  0.2770773768424988\n",
      "Eval Loss:  0.28139105439186096\n",
      "Eval Loss:  0.2547796666622162\n",
      "Eval Loss:  0.2822912931442261\n",
      "Eval Loss:  0.20278984308242798\n",
      "Eval Loss:  0.23115544021129608\n",
      "Eval Loss:  0.26788854598999023\n",
      "Eval Loss:  0.23920869827270508\n",
      "Eval Loss:  0.30475133657455444\n",
      "Eval Loss:  0.21648621559143066\n",
      "Eval Loss:  0.323414146900177\n",
      "Eval Loss:  0.3951786756515503\n",
      "Eval Loss:  0.3020400106906891\n",
      "[[15736  1331]\n",
      " [ 1863 10743]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91     17067\n",
      "           1       0.89      0.85      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8923600579651535\n",
      "pre:  0.8897631273811496\n",
      "rec:  0.8522132317943836\n",
      "ma F1:  0.889223540578623\n",
      "mi F1:  0.8923600579651535\n",
      "we F1:  0.892025864644578\n",
      "29673 464\n",
      "Loss:  0.053457122296094894\n",
      "Loss:  0.06874343752861023\n",
      "Loss:  0.0609307698905468\n",
      "18 **********\n",
      "Epoch:  1810.8451669216156  fold:  5  kers:  128\n",
      "epoch:  19\n",
      "29673 464\n",
      "Loss:  0.0614762082695961\n",
      "Loss:  0.06526611745357513\n",
      "Loss:  0.06627853959798813\n",
      "19 **********\n",
      "Epoch:  1891.8435938358307  fold:  5  kers:  128\n",
      "epoch:  20\n",
      "29673 464\n",
      "Loss:  0.07997065782546997\n",
      "Loss:  0.051233626902103424\n",
      "Loss:  0.06944059580564499\n",
      "20 **********\n",
      "Epoch:  1972.8569803237915  fold:  5  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.07588258385658264\n",
      "Eval Loss:  0.07735435664653778\n",
      "Eval Loss:  0.039029043167829514\n",
      "[[3053   44]\n",
      " [  31   90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.67      0.74      0.71       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.83      0.86      0.85      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9766935985083903\n",
      "pre:  0.6716417910447762\n",
      "rec:  0.743801652892562\n",
      "ma F1:  0.8468741970174253\n",
      "mi F1:  0.9766935985083903\n",
      "we F1:  0.9772631740127381\n",
      "update!  Acc:  0.9766935985083903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2561785876750946\n",
      "Eval Loss:  0.20633360743522644\n",
      "Eval Loss:  0.272591769695282\n",
      "Eval Loss:  0.17422711849212646\n",
      "Eval Loss:  0.3127487003803253\n",
      "Eval Loss:  0.22807615995407104\n",
      "Eval Loss:  0.3172016143798828\n",
      "Eval Loss:  0.1604577898979187\n",
      "Eval Loss:  0.33070066571235657\n",
      "Eval Loss:  0.31470635533332825\n",
      "Eval Loss:  0.3059386610984802\n",
      "Eval Loss:  0.2676738202571869\n",
      "Eval Loss:  0.23447653651237488\n",
      "Eval Loss:  0.30399003624916077\n",
      "Eval Loss:  0.13575176894664764\n",
      "Eval Loss:  0.2678675055503845\n",
      "Eval Loss:  0.2396726757287979\n",
      "Eval Loss:  0.2572251558303833\n",
      "Eval Loss:  0.24561811983585358\n",
      "Eval Loss:  0.23709052801132202\n",
      "Eval Loss:  0.19373053312301636\n",
      "Eval Loss:  0.22588172554969788\n",
      "Eval Loss:  0.25538724660873413\n",
      "Eval Loss:  0.1858801543712616\n",
      "Eval Loss:  0.2822754681110382\n",
      "Eval Loss:  0.16912677884101868\n",
      "Eval Loss:  0.31140580773353577\n",
      "Eval Loss:  0.38723108172416687\n",
      "Eval Loss:  0.28805527091026306\n",
      "[[15831  1236]\n",
      " [ 1776 10830]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     17067\n",
      "           1       0.90      0.86      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.8984935800222424\n",
      "pre:  0.8975634012928891\n",
      "rec:  0.8591147072822466\n",
      "ma F1:  0.8955260240519309\n",
      "mi F1:  0.8984935800222424\n",
      "we F1:  0.8981731480638405\n",
      "29673 464\n",
      "Loss:  0.04250871390104294\n",
      "Loss:  0.059972360730171204\n",
      "Loss:  0.06819277256727219\n",
      "21 **********\n",
      "Epoch:  2097.0529062747955  fold:  5  kers:  128\n",
      "epoch:  22\n",
      "29673 464\n",
      "Loss:  0.08223499357700348\n",
      "Loss:  0.05394572764635086\n",
      "Loss:  0.09652002155780792\n",
      "22 **********\n",
      "Epoch:  2178.0503351688385  fold:  5  kers:  128\n",
      "epoch:  23\n",
      "29673 464\n",
      "Loss:  0.06604883819818497\n",
      "Loss:  0.05953173711895943\n",
      "Loss:  0.05910651385784149\n",
      "23 **********\n",
      "Epoch:  2259.0816736221313  fold:  5  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.07547331601381302\n",
      "Eval Loss:  0.10381387919187546\n",
      "Eval Loss:  0.04117200896143913\n",
      "[[3056   41]\n",
      " [  35   86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.68      0.71      0.69       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.83      0.85      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9763828464885022\n",
      "pre:  0.6771653543307087\n",
      "rec:  0.7107438016528925\n",
      "ma F1:  0.8406332756427634\n",
      "mi F1:  0.9763828464885022\n",
      "we F1:  0.9766570880457663\n",
      "Eval Loss:  0.23528853058815002\n",
      "Eval Loss:  0.20681408047676086\n",
      "Eval Loss:  0.2689262926578522\n",
      "Eval Loss:  0.18197527527809143\n",
      "Eval Loss:  0.2736615538597107\n",
      "Eval Loss:  0.21564975380897522\n",
      "Eval Loss:  0.2933412790298462\n",
      "Eval Loss:  0.14866408705711365\n",
      "Eval Loss:  0.31326714158058167\n",
      "Eval Loss:  0.28542667627334595\n",
      "Eval Loss:  0.28507596254348755\n",
      "Eval Loss:  0.2591259777545929\n",
      "Eval Loss:  0.2130197435617447\n",
      "Eval Loss:  0.30952298641204834\n",
      "Eval Loss:  0.13727593421936035\n",
      "Eval Loss:  0.25068071484565735\n",
      "Eval Loss:  0.24164387583732605\n",
      "Eval Loss:  0.2339840978384018\n",
      "Eval Loss:  0.25192373991012573\n",
      "Eval Loss:  0.21763846278190613\n",
      "Eval Loss:  0.17391300201416016\n",
      "Eval Loss:  0.1954127550125122\n",
      "Eval Loss:  0.21977534890174866\n",
      "Eval Loss:  0.1904606819152832\n",
      "Eval Loss:  0.2856086194515228\n",
      "Eval Loss:  0.15880487859249115\n",
      "Eval Loss:  0.2940013110637665\n",
      "Eval Loss:  0.34516996145248413\n",
      "Eval Loss:  0.2702363431453705\n",
      "[[15917  1150]\n",
      " [ 1700 10906]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     17067\n",
      "           1       0.90      0.87      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.90      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9039530886664645\n",
      "pre:  0.9046118115461181\n",
      "rec:  0.8651435824210694\n",
      "ma F1:  0.901133571533541\n",
      "mi F1:  0.9039530886664645\n",
      "we F1:  0.9036436226071732\n",
      "29673 464\n",
      "Loss:  0.06917031854391098\n",
      "Loss:  0.09260474890470505\n",
      "Loss:  0.04843117296695709\n",
      "24 **********\n",
      "Epoch:  2387.517263174057  fold:  5  kers:  128\n",
      "epoch:  25\n",
      "29673 464\n",
      "Loss:  0.08749325573444366\n",
      "Loss:  0.06224004551768303\n",
      "Loss:  0.08069232106208801\n",
      "25 **********\n",
      "Epoch:  2468.5186817646027  fold:  5  kers:  128\n",
      "epoch:  26\n",
      "29673 464\n",
      "Loss:  0.05363856256008148\n",
      "Loss:  0.06329552829265594\n",
      "Loss:  0.10931053012609482\n",
      "26 **********\n",
      "Epoch:  2552.5490016937256  fold:  5  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.07077060639858246\n",
      "Eval Loss:  0.09263218939304352\n",
      "Eval Loss:  0.04656890779733658\n",
      "[[3053   44]\n",
      " [  42   79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.64      0.65      0.65       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.81      0.82      0.82      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9732753262896209\n",
      "pre:  0.6422764227642277\n",
      "rec:  0.6528925619834711\n",
      "ma F1:  0.8168260473588342\n",
      "mi F1:  0.9732753262896209\n",
      "we F1:  0.9733805376406166\n",
      "Eval Loss:  0.23017890751361847\n",
      "Eval Loss:  0.19412855803966522\n",
      "Eval Loss:  0.266409695148468\n",
      "Eval Loss:  0.19571076333522797\n",
      "Eval Loss:  0.26541945338249207\n",
      "Eval Loss:  0.22307929396629333\n",
      "Eval Loss:  0.2618679702281952\n",
      "Eval Loss:  0.16130641102790833\n",
      "Eval Loss:  0.27945780754089355\n",
      "Eval Loss:  0.28435301780700684\n",
      "Eval Loss:  0.27025890350341797\n",
      "Eval Loss:  0.26606521010398865\n",
      "Eval Loss:  0.1966211497783661\n",
      "Eval Loss:  0.2805154025554657\n",
      "Eval Loss:  0.12904149293899536\n",
      "Eval Loss:  0.2395431101322174\n",
      "Eval Loss:  0.20109142363071442\n",
      "Eval Loss:  0.2046414017677307\n",
      "Eval Loss:  0.23430557548999786\n",
      "Eval Loss:  0.21339744329452515\n",
      "Eval Loss:  0.18321584165096283\n",
      "Eval Loss:  0.21464860439300537\n",
      "Eval Loss:  0.22726649045944214\n",
      "Eval Loss:  0.18790684640407562\n",
      "Eval Loss:  0.2717393636703491\n",
      "Eval Loss:  0.1546037793159485\n",
      "Eval Loss:  0.3028084933757782\n",
      "Eval Loss:  0.3138672113418579\n",
      "Eval Loss:  0.2509360909461975\n",
      "[[15874  1193]\n",
      " [ 1547 11059]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     17067\n",
      "           1       0.90      0.88      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9076601624372325\n",
      "pre:  0.902628142344107\n",
      "rec:  0.8772806600031731\n",
      "ma F1:  0.9051629959632088\n",
      "mi F1:  0.9076601624372325\n",
      "we F1:  0.9074765701357156\n",
      "29673 464\n",
      "Loss:  0.05721604824066162\n",
      "Loss:  0.09016399085521698\n",
      "Loss:  0.05647324025630951\n",
      "27 **********\n",
      "Epoch:  2676.916468143463  fold:  5  kers:  128\n",
      "epoch:  28\n",
      "29673 464\n",
      "Loss:  0.04136944189667702\n",
      "Loss:  0.08541661500930786\n",
      "Loss:  0.06407839059829712\n",
      "28 **********\n",
      "Epoch:  2757.997674226761  fold:  5  kers:  128\n",
      "epoch:  29\n",
      "29673 464\n",
      "Loss:  0.04822542145848274\n",
      "Loss:  0.05300472676753998\n",
      "Loss:  0.06537436693906784\n",
      "29 **********\n",
      "Epoch:  2839.0679087638855  fold:  5  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.07321473956108093\n",
      "Eval Loss:  0.060903940349817276\n",
      "Eval Loss:  0.036958903074264526\n",
      "[[3066   31]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.74      0.74      0.74       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.86      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9804226227470478\n",
      "pre:  0.7416666666666667\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.8642098600464168\n",
      "mi F1:  0.9804226227470478\n",
      "we F1:  0.9803835858768092\n",
      "update!  Acc:  0.9804226227470478\n",
      "Eval Loss:  0.25810477137565613\n",
      "Eval Loss:  0.1761857271194458\n",
      "Eval Loss:  0.2431720644235611\n",
      "Eval Loss:  0.18170039355754852\n",
      "Eval Loss:  0.27618104219436646\n",
      "Eval Loss:  0.19784466922283173\n",
      "Eval Loss:  0.26850706338882446\n",
      "Eval Loss:  0.1480070948600769\n",
      "Eval Loss:  0.2975366413593292\n",
      "Eval Loss:  0.2779656648635864\n",
      "Eval Loss:  0.2668856084346771\n",
      "Eval Loss:  0.27207717299461365\n",
      "Eval Loss:  0.204433411359787\n",
      "Eval Loss:  0.342133104801178\n",
      "Eval Loss:  0.15610921382904053\n",
      "Eval Loss:  0.2529401481151581\n",
      "Eval Loss:  0.2050943821668625\n",
      "Eval Loss:  0.20217815041542053\n",
      "Eval Loss:  0.2497607171535492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21144217252731323\n",
      "Eval Loss:  0.15603959560394287\n",
      "Eval Loss:  0.2045578807592392\n",
      "Eval Loss:  0.18760836124420166\n",
      "Eval Loss:  0.174274280667305\n",
      "Eval Loss:  0.2792792320251465\n",
      "Eval Loss:  0.1509884148836136\n",
      "Eval Loss:  0.32505765557289124\n",
      "Eval Loss:  0.3277644217014313\n",
      "Eval Loss:  0.2663005292415619\n",
      "[[16100   967]\n",
      " [ 1787 10819]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17067\n",
      "           1       0.92      0.86      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.90     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9071883530482256\n",
      "pre:  0.917953504157475\n",
      "rec:  0.8582421069332065\n",
      "ma F1:  0.9041524316651901\n",
      "mi F1:  0.9071883530482256\n",
      "we F1:  0.9067169545376994\n",
      "29673 464\n",
      "Loss:  0.06828150153160095\n",
      "Loss:  0.07590429484844208\n",
      "Loss:  0.08055783063173294\n",
      "30 **********\n",
      "Epoch:  2963.371545791626  fold:  5  kers:  128\n",
      "epoch:  31\n",
      "29673 464\n",
      "Loss:  0.09466046094894409\n",
      "Loss:  0.06422595679759979\n",
      "Loss:  0.06171880662441254\n",
      "31 **********\n",
      "Epoch:  3044.3769540786743  fold:  5  kers:  128\n",
      "epoch:  32\n",
      "29673 464\n",
      "Loss:  0.04907742887735367\n",
      "Loss:  0.07424885034561157\n",
      "Loss:  0.06047769635915756\n",
      "32 **********\n",
      "Epoch:  3125.4252469539642  fold:  5  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.06743953377008438\n",
      "Eval Loss:  0.05945006012916565\n",
      "Eval Loss:  0.025759391486644745\n",
      "[[3073   24]\n",
      " [  36   85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.78      0.70      0.74       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.85      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9813548788067122\n",
      "pre:  0.7798165137614679\n",
      "rec:  0.7024793388429752\n",
      "ma F1:  0.8647311858089646\n",
      "mi F1:  0.9813548788067122\n",
      "we F1:  0.9808865105617413\n",
      "update!  Acc:  0.9813548788067122\n",
      "Eval Loss:  0.2454521209001541\n",
      "Eval Loss:  0.17729534208774567\n",
      "Eval Loss:  0.24695739150047302\n",
      "Eval Loss:  0.1828932911157608\n",
      "Eval Loss:  0.2730458378791809\n",
      "Eval Loss:  0.18349890410900116\n",
      "Eval Loss:  0.2650999128818512\n",
      "Eval Loss:  0.14727313816547394\n",
      "Eval Loss:  0.2940642237663269\n",
      "Eval Loss:  0.2613702714443207\n",
      "Eval Loss:  0.24838624894618988\n",
      "Eval Loss:  0.2559022605419159\n",
      "Eval Loss:  0.19417038559913635\n",
      "Eval Loss:  0.3005804717540741\n",
      "Eval Loss:  0.13602063059806824\n",
      "Eval Loss:  0.25005602836608887\n",
      "Eval Loss:  0.22080180048942566\n",
      "Eval Loss:  0.19205288589000702\n",
      "Eval Loss:  0.2519333064556122\n",
      "Eval Loss:  0.20464788377285004\n",
      "Eval Loss:  0.17758901417255402\n",
      "Eval Loss:  0.2067907601594925\n",
      "Eval Loss:  0.206263467669487\n",
      "Eval Loss:  0.1650245487689972\n",
      "Eval Loss:  0.246048241853714\n",
      "Eval Loss:  0.15834347903728485\n",
      "Eval Loss:  0.32540664076805115\n",
      "Eval Loss:  0.3326258659362793\n",
      "Eval Loss:  0.2726604640483856\n",
      "[[16109   958]\n",
      " [ 1762 10844]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17067\n",
      "           1       0.92      0.86      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9083341758500995\n",
      "pre:  0.9188273174038298\n",
      "rec:  0.8602252895446613\n",
      "ma F1:  0.9053544660908805\n",
      "mi F1:  0.9083341758500995\n",
      "we F1:  0.9078791546447029\n",
      "29673 464\n",
      "Loss:  0.06915014982223511\n",
      "Loss:  0.05161811038851738\n",
      "Loss:  0.06678793579339981\n",
      "33 **********\n",
      "Epoch:  3249.5304148197174  fold:  5  kers:  128\n",
      "epoch:  34\n",
      "29673 464\n",
      "Loss:  0.07425183057785034\n",
      "Loss:  0.062369152903556824\n",
      "Loss:  0.06465629488229752\n",
      "34 **********\n",
      "Epoch:  3330.4999191761017  fold:  5  kers:  128\n",
      "epoch:  35\n",
      "29673 464\n",
      "Loss:  0.09309017658233643\n",
      "Loss:  0.07174993306398392\n",
      "Loss:  0.029481127858161926\n",
      "35 **********\n",
      "Epoch:  3411.5043296813965  fold:  5  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.09511786699295044\n",
      "Eval Loss:  0.15100301802158356\n",
      "Eval Loss:  0.06209138035774231\n",
      "[[3033   64]\n",
      " [  20  101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.61      0.83      0.71       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.80      0.91      0.85      3218\n",
      "weighted avg       0.98      0.97      0.98      3218\n",
      "\n",
      "acc:  0.9738968303293971\n",
      "pre:  0.6121212121212121\n",
      "rec:  0.8347107438016529\n",
      "ma F1:  0.8463175848541702\n",
      "mi F1:  0.9738968303293971\n",
      "we F1:  0.9758113892655874\n",
      "Eval Loss:  0.21569031476974487\n",
      "Eval Loss:  0.19275090098381042\n",
      "Eval Loss:  0.2589781880378723\n",
      "Eval Loss:  0.19224128127098083\n",
      "Eval Loss:  0.25845223665237427\n",
      "Eval Loss:  0.19977261126041412\n",
      "Eval Loss:  0.2316761612892151\n",
      "Eval Loss:  0.16731058061122894\n",
      "Eval Loss:  0.2564486861228943\n",
      "Eval Loss:  0.25906291604042053\n",
      "Eval Loss:  0.2669662535190582\n",
      "Eval Loss:  0.2705326974391937\n",
      "Eval Loss:  0.1901349574327469\n",
      "Eval Loss:  0.28140079975128174\n",
      "Eval Loss:  0.13482441008090973\n",
      "Eval Loss:  0.24491293728351593\n",
      "Eval Loss:  0.18446007370948792\n",
      "Eval Loss:  0.2131444215774536\n",
      "Eval Loss:  0.22419561445713043\n",
      "Eval Loss:  0.22011469304561615\n",
      "Eval Loss:  0.19736450910568237\n",
      "Eval Loss:  0.20832720398902893\n",
      "Eval Loss:  0.20798036456108093\n",
      "Eval Loss:  0.18726412951946259\n",
      "Eval Loss:  0.26014530658721924\n",
      "Eval Loss:  0.15330667793750763\n",
      "Eval Loss:  0.2601941227912903\n",
      "Eval Loss:  0.26992374658584595\n",
      "Eval Loss:  0.2842826843261719\n",
      "[[15515  1552]\n",
      " [ 1104 11502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     17067\n",
      "           1       0.88      0.91      0.90     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.91      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9104910187712736\n",
      "pre:  0.8811092385475716\n",
      "rec:  0.9124226558781533\n",
      "ma F1:  0.9088233920815358\n",
      "mi F1:  0.9104910187712736\n",
      "we F1:  0.9106771879108208\n",
      "29673 464\n",
      "Loss:  0.07396101951599121\n",
      "Loss:  0.08587464690208435\n",
      "Loss:  0.04206584021449089\n",
      "36 **********\n",
      "Epoch:  3535.591546058655  fold:  5  kers:  128\n",
      "epoch:  37\n",
      "29673 464\n",
      "Loss:  0.0314205177128315\n",
      "Loss:  0.08657548576593399\n",
      "Loss:  0.08420251309871674\n",
      "37 **********\n",
      "Epoch:  3616.5969541072845  fold:  5  kers:  128\n",
      "epoch:  38\n",
      "29673 464\n",
      "Loss:  0.0477728471159935\n",
      "Loss:  0.05070923641324043\n",
      "Loss:  0.06444034725427628\n",
      "38 **********\n",
      "Epoch:  3697.6023621559143  fold:  5  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.07077370584011078\n",
      "Eval Loss:  0.07138308137655258\n",
      "Eval Loss:  0.03902369365096092\n",
      "[[3062   35]\n",
      " [  26   95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.73      0.79      0.76       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.89      0.87      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9810441267868241\n",
      "pre:  0.7307692307692307\n",
      "rec:  0.7851239669421488\n",
      "ma F1:  0.873554770409067\n",
      "mi F1:  0.981044126786824\n",
      "we F1:  0.9813701814573329\n",
      "Eval Loss:  0.20967908203601837\n",
      "Eval Loss:  0.1551017016172409\n",
      "Eval Loss:  0.23729106783866882\n",
      "Eval Loss:  0.18090388178825378\n",
      "Eval Loss:  0.25267690420150757\n",
      "Eval Loss:  0.1827888935804367\n",
      "Eval Loss:  0.22483959794044495\n",
      "Eval Loss:  0.14092621207237244\n",
      "Eval Loss:  0.2629331052303314\n",
      "Eval Loss:  0.22726230323314667\n",
      "Eval Loss:  0.2716538608074188\n",
      "Eval Loss:  0.26428431272506714\n",
      "Eval Loss:  0.16081126034259796\n",
      "Eval Loss:  0.27548784017562866\n",
      "Eval Loss:  0.12616464495658875\n",
      "Eval Loss:  0.23926420509815216\n",
      "Eval Loss:  0.18518681824207306\n",
      "Eval Loss:  0.18887531757354736\n",
      "Eval Loss:  0.2112007886171341\n",
      "Eval Loss:  0.19840608537197113\n",
      "Eval Loss:  0.19489242136478424\n",
      "Eval Loss:  0.17525146901607513\n",
      "Eval Loss:  0.19478361308574677\n",
      "Eval Loss:  0.16809339821338654\n",
      "Eval Loss:  0.24948926270008087\n",
      "Eval Loss:  0.133916437625885\n",
      "Eval Loss:  0.28892219066619873\n",
      "Eval Loss:  0.3258468508720398\n",
      "Eval Loss:  0.2502860426902771\n",
      "[[15817  1250]\n",
      " [ 1303 11303]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     17067\n",
      "           1       0.90      0.90      0.90     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.91      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9139621878475381\n",
      "pre:  0.9004222098303194\n",
      "rec:  0.8966365222909726\n",
      "ma F1:  0.9119239347987536\n",
      "mi F1:  0.9139621878475381\n",
      "we F1:  0.9139382562100582\n",
      "29673 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.031080279499292374\n",
      "Loss:  0.04054396599531174\n",
      "Loss:  0.046515513211488724\n",
      "39 **********\n",
      "Epoch:  3821.8830609321594  fold:  5  kers:  128\n",
      "epoch:  40\n",
      "29673 464\n",
      "Loss:  0.04566550254821777\n",
      "Loss:  0.06675875931978226\n",
      "Loss:  0.04360206052660942\n",
      "40 **********\n",
      "Epoch:  3902.8755025863647  fold:  5  kers:  128\n",
      "epoch:  41\n",
      "29673 464\n",
      "Loss:  0.06461435556411743\n",
      "Loss:  0.06316602230072021\n",
      "Loss:  0.10262756049633026\n",
      "41 **********\n",
      "Epoch:  3983.8799142837524  fold:  5  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.07360763102769852\n",
      "Eval Loss:  0.08588004112243652\n",
      "Eval Loss:  0.03153248131275177\n",
      "[[3054   43]\n",
      " [  16  105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.71      0.87      0.78       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.85      0.93      0.89      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9816656308266004\n",
      "pre:  0.7094594594594594\n",
      "rec:  0.8677685950413223\n",
      "ma F1:  0.885551047275853\n",
      "mi F1:  0.9816656308266004\n",
      "we F1:  0.9825456219272685\n",
      "update!  Acc:  0.9816656308266004\n",
      "Eval Loss:  0.21064284443855286\n",
      "Eval Loss:  0.16487693786621094\n",
      "Eval Loss:  0.23093342781066895\n",
      "Eval Loss:  0.18670997023582458\n",
      "Eval Loss:  0.26883482933044434\n",
      "Eval Loss:  0.17453928291797638\n",
      "Eval Loss:  0.2428034245967865\n",
      "Eval Loss:  0.16268375515937805\n",
      "Eval Loss:  0.2678714096546173\n",
      "Eval Loss:  0.27223461866378784\n",
      "Eval Loss:  0.2829601466655731\n",
      "Eval Loss:  0.25091537833213806\n",
      "Eval Loss:  0.1502821296453476\n",
      "Eval Loss:  0.2805804908275604\n",
      "Eval Loss:  0.12208154797554016\n",
      "Eval Loss:  0.24996721744537354\n",
      "Eval Loss:  0.18096022307872772\n",
      "Eval Loss:  0.17658497393131256\n",
      "Eval Loss:  0.21682491898536682\n",
      "Eval Loss:  0.21192555129528046\n",
      "Eval Loss:  0.2056436836719513\n",
      "Eval Loss:  0.20262478291988373\n",
      "Eval Loss:  0.17667736113071442\n",
      "Eval Loss:  0.1913045197725296\n",
      "Eval Loss:  0.2560476064682007\n",
      "Eval Loss:  0.1253686547279358\n",
      "Eval Loss:  0.25358569622039795\n",
      "Eval Loss:  0.2928979992866516\n",
      "Eval Loss:  0.2835220694541931\n",
      "[[15640  1427]\n",
      " [ 1139 11467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     17067\n",
      "           1       0.89      0.91      0.90     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.91      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9135240791291747\n",
      "pre:  0.8893283697843959\n",
      "rec:  0.9096462002221165\n",
      "ma F1:  0.9117792840234835\n",
      "mi F1:  0.9135240791291747\n",
      "we F1:  0.9136444963327307\n",
      "29673 464\n",
      "Loss:  0.06099869683384895\n",
      "Loss:  0.04815016686916351\n",
      "Loss:  0.07755924016237259\n",
      "42 **********\n",
      "Epoch:  4108.189534902573  fold:  5  kers:  128\n",
      "epoch:  43\n",
      "29673 464\n",
      "Loss:  0.05294772610068321\n",
      "Loss:  0.042118314653635025\n",
      "Loss:  0.04555562138557434\n",
      "43 **********\n",
      "Epoch:  4189.170009851456  fold:  5  kers:  128\n",
      "epoch:  44\n",
      "29673 464\n",
      "Loss:  0.09142801910638809\n",
      "Loss:  0.06927578151226044\n",
      "Loss:  0.06756002455949783\n",
      "44 **********\n",
      "Epoch:  4270.150484323502  fold:  5  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.06832503527402878\n",
      "Eval Loss:  0.08457404375076294\n",
      "Eval Loss:  0.04991260915994644\n",
      "[[3052   45]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.66      0.73      0.69       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.83      0.86      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9757613424487259\n",
      "pre:  0.6616541353383458\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.8401480549321501\n",
      "mi F1:  0.9757613424487259\n",
      "we F1:  0.9763103840985906\n",
      "Eval Loss:  0.22524787485599518\n",
      "Eval Loss:  0.14883533120155334\n",
      "Eval Loss:  0.2393849492073059\n",
      "Eval Loss:  0.17703880369663239\n",
      "Eval Loss:  0.229499951004982\n",
      "Eval Loss:  0.17810600996017456\n",
      "Eval Loss:  0.22685857117176056\n",
      "Eval Loss:  0.14658552408218384\n",
      "Eval Loss:  0.2468886524438858\n",
      "Eval Loss:  0.2308511584997177\n",
      "Eval Loss:  0.2648080587387085\n",
      "Eval Loss:  0.2233096808195114\n",
      "Eval Loss:  0.15909221768379211\n",
      "Eval Loss:  0.25897812843322754\n",
      "Eval Loss:  0.1357060819864273\n",
      "Eval Loss:  0.2328081727027893\n",
      "Eval Loss:  0.16302673518657684\n",
      "Eval Loss:  0.18209101259708405\n",
      "Eval Loss:  0.21155555546283722\n",
      "Eval Loss:  0.17001083493232727\n",
      "Eval Loss:  0.1833418309688568\n",
      "Eval Loss:  0.15848641097545624\n",
      "Eval Loss:  0.19213752448558807\n",
      "Eval Loss:  0.16895192861557007\n",
      "Eval Loss:  0.2656710743904114\n",
      "Eval Loss:  0.11855272203683853\n",
      "Eval Loss:  0.22645710408687592\n",
      "Eval Loss:  0.24241121113300323\n",
      "Eval Loss:  0.2657860219478607\n",
      "[[15812  1255]\n",
      " [ 1125 11481]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17067\n",
      "           1       0.90      0.91      0.91     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.92      0.92     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.919792403868837\n",
      "pre:  0.9014604271356784\n",
      "rec:  0.9107567824845312\n",
      "ma F1:  0.9180464974010263\n",
      "mi F1:  0.919792403868837\n",
      "we F1:  0.9198448092811702\n",
      "29673 464\n",
      "Loss:  0.06280427426099777\n",
      "Loss:  0.05743712931871414\n",
      "Loss:  0.06003418192267418\n",
      "45 **********\n",
      "Epoch:  4394.187833547592  fold:  5  kers:  128\n",
      "epoch:  46\n",
      "29673 464\n",
      "Loss:  0.06594345718622208\n",
      "Loss:  0.046846989542245865\n",
      "Loss:  0.04781412333250046\n",
      "46 **********\n",
      "Epoch:  4475.153348445892  fold:  5  kers:  128\n",
      "epoch:  47\n",
      "29673 464\n",
      "Loss:  0.052775200456380844\n",
      "Loss:  0.03527333214879036\n",
      "Loss:  0.056753918528556824\n",
      "47 **********\n",
      "Epoch:  4556.189673423767  fold:  5  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.05961949750781059\n",
      "Eval Loss:  0.04847478121519089\n",
      "Eval Loss:  0.027707651257514954\n",
      "[[3083   14]\n",
      " [  20  101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3097\n",
      "           1       0.88      0.83      0.86       121\n",
      "\n",
      "    accuracy                           0.99      3218\n",
      "   macro avg       0.94      0.92      0.93      3218\n",
      "weighted avg       0.99      0.99      0.99      3218\n",
      "\n",
      "acc:  0.9894344313238036\n",
      "pre:  0.8782608695652174\n",
      "rec:  0.8347107438016529\n",
      "ma F1:  0.9252241662110443\n",
      "mi F1:  0.9894344313238036\n",
      "we F1:  0.9893052356193512\n",
      "update!  Acc:  0.9894344313238036\n",
      "Eval Loss:  0.25744330883026123\n",
      "Eval Loss:  0.15238656103610992\n",
      "Eval Loss:  0.24129806458950043\n",
      "Eval Loss:  0.18845894932746887\n",
      "Eval Loss:  0.2648211121559143\n",
      "Eval Loss:  0.1580790877342224\n",
      "Eval Loss:  0.24557815492153168\n",
      "Eval Loss:  0.13056185841560364\n",
      "Eval Loss:  0.2933399975299835\n",
      "Eval Loss:  0.24198228120803833\n",
      "Eval Loss:  0.27746716141700745\n",
      "Eval Loss:  0.2540653944015503\n",
      "Eval Loss:  0.17192378640174866\n",
      "Eval Loss:  0.3241695761680603\n",
      "Eval Loss:  0.16607145965099335\n",
      "Eval Loss:  0.22199171781539917\n",
      "Eval Loss:  0.2060459405183792\n",
      "Eval Loss:  0.18574588000774384\n",
      "Eval Loss:  0.2617901563644409\n",
      "Eval Loss:  0.20835839211940765\n",
      "Eval Loss:  0.17401911318302155\n",
      "Eval Loss:  0.21322038769721985\n",
      "Eval Loss:  0.166789248585701\n",
      "Eval Loss:  0.17581294476985931\n",
      "Eval Loss:  0.23727978765964508\n",
      "Eval Loss:  0.11988013237714767\n",
      "Eval Loss:  0.3047265112400055\n",
      "Eval Loss:  0.33845654129981995\n",
      "Eval Loss:  0.27124717831611633\n",
      "[[16254   813]\n",
      " [ 1745 10861]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     17067\n",
      "           1       0.93      0.86      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.92      0.91      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9137936844943214\n",
      "pre:  0.930358060647593\n",
      "rec:  0.8615738537204506\n",
      "ma F1:  0.910848822051822\n",
      "mi F1:  0.9137936844943214\n",
      "we F1:  0.9132847633379318\n",
      "29673 464\n",
      "Loss:  0.08311488479375839\n",
      "Loss:  0.07775310426950455\n",
      "Loss:  0.056888397783041\n",
      "48 **********\n",
      "Epoch:  4680.246969938278  fold:  5  kers:  128\n",
      "epoch:  49\n",
      "29673 464\n",
      "Loss:  0.05627596750855446\n",
      "Loss:  0.06112087145447731\n",
      "Loss:  0.02311107888817787\n",
      "49 **********\n",
      "Epoch:  4761.235423088074  fold:  5  kers:  128\n",
      "epoch:  50\n",
      "29673 464\n",
      "Loss:  0.06894370913505554\n",
      "Loss:  0.08185795694589615\n",
      "Loss:  0.07900582998991013\n",
      "50 **********\n",
      "Epoch:  4842.230857849121  fold:  5  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.0637018084526062\n",
      "Eval Loss:  0.07253140956163406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.03650735318660736\n",
      "[[3067   30]\n",
      " [  25   96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.76      0.79      0.78       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.89      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9829086389061529\n",
      "pre:  0.7619047619047619\n",
      "rec:  0.7933884297520661\n",
      "ma F1:  0.8842206003468345\n",
      "mi F1:  0.9829086389061529\n",
      "we F1:  0.9830747244641457\n",
      "Eval Loss:  0.23449404537677765\n",
      "Eval Loss:  0.1209939569234848\n",
      "Eval Loss:  0.20519202947616577\n",
      "Eval Loss:  0.1716674119234085\n",
      "Eval Loss:  0.2354268580675125\n",
      "Eval Loss:  0.1740664392709732\n",
      "Eval Loss:  0.2233538180589676\n",
      "Eval Loss:  0.13460318744182587\n",
      "Eval Loss:  0.2689928412437439\n",
      "Eval Loss:  0.2461830973625183\n",
      "Eval Loss:  0.2526094615459442\n",
      "Eval Loss:  0.22337627410888672\n",
      "Eval Loss:  0.13573478162288666\n",
      "Eval Loss:  0.29252758622169495\n",
      "Eval Loss:  0.1579601913690567\n",
      "Eval Loss:  0.24339696764945984\n",
      "Eval Loss:  0.16304360330104828\n",
      "Eval Loss:  0.17577452957630157\n",
      "Eval Loss:  0.23297268152236938\n",
      "Eval Loss:  0.1936299055814743\n",
      "Eval Loss:  0.19388604164123535\n",
      "Eval Loss:  0.18031515181064606\n",
      "Eval Loss:  0.14629149436950684\n",
      "Eval Loss:  0.18058256804943085\n",
      "Eval Loss:  0.2648952901363373\n",
      "Eval Loss:  0.12403520196676254\n",
      "Eval Loss:  0.22946064174175262\n",
      "Eval Loss:  0.25842010974884033\n",
      "Eval Loss:  0.2833690345287323\n",
      "[[15999  1068]\n",
      " [ 1337 11269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17067\n",
      "           1       0.91      0.89      0.90     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.92      0.92     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9189498871027534\n",
      "pre:  0.9134311420928913\n",
      "rec:  0.8939393939393939\n",
      "ma F1:  0.9168367342937356\n",
      "mi F1:  0.9189498871027534\n",
      "we F1:  0.9188297099134033\n",
      "29673 464\n",
      "Loss:  0.04782431572675705\n",
      "Loss:  0.09204867482185364\n",
      "Loss:  0.0668797492980957\n",
      "51 **********\n",
      "Epoch:  4966.290148496628  fold:  5  kers:  128\n",
      "epoch:  52\n",
      "29673 464\n",
      "Loss:  0.06293327361345291\n",
      "Loss:  0.064878910779953\n",
      "Loss:  0.057160086929798126\n",
      "52 **********\n",
      "Epoch:  5047.3055300712585  fold:  5  kers:  128\n",
      "epoch:  53\n",
      "29673 464\n",
      "Loss:  0.057022105902433395\n",
      "Loss:  0.05678129941225052\n",
      "Loss:  0.031875256448984146\n",
      "53 **********\n",
      "Epoch:  5128.3498339653015  fold:  5  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.06183098256587982\n",
      "Eval Loss:  0.07129870355129242\n",
      "Eval Loss:  0.030389493331313133\n",
      "[[3069   28]\n",
      " [  22   99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.78      0.82      0.80       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.89      0.90      0.90      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9844623990055935\n",
      "pre:  0.7795275590551181\n",
      "rec:  0.8181818181818182\n",
      "ma F1:  0.8951534708176074\n",
      "mi F1:  0.9844623990055935\n",
      "we F1:  0.9846428210827409\n",
      "Eval Loss:  0.2062353491783142\n",
      "Eval Loss:  0.13624002039432526\n",
      "Eval Loss:  0.1995120644569397\n",
      "Eval Loss:  0.18633106350898743\n",
      "Eval Loss:  0.22750966250896454\n",
      "Eval Loss:  0.16764414310455322\n",
      "Eval Loss:  0.20916487276554108\n",
      "Eval Loss:  0.13879020512104034\n",
      "Eval Loss:  0.19350789487361908\n",
      "Eval Loss:  0.25349900126457214\n",
      "Eval Loss:  0.2442072480916977\n",
      "Eval Loss:  0.22685033082962036\n",
      "Eval Loss:  0.15948307514190674\n",
      "Eval Loss:  0.26928985118865967\n",
      "Eval Loss:  0.15624192357063293\n",
      "Eval Loss:  0.2309364676475525\n",
      "Eval Loss:  0.15259960293769836\n",
      "Eval Loss:  0.157305508852005\n",
      "Eval Loss:  0.18647588789463043\n",
      "Eval Loss:  0.18242530524730682\n",
      "Eval Loss:  0.16847726702690125\n",
      "Eval Loss:  0.17086128890514374\n",
      "Eval Loss:  0.14727433025836945\n",
      "Eval Loss:  0.17839179933071136\n",
      "Eval Loss:  0.23455098271369934\n",
      "Eval Loss:  0.10998846590518951\n",
      "Eval Loss:  0.22763465344905853\n",
      "Eval Loss:  0.2448439747095108\n",
      "Eval Loss:  0.25457894802093506\n",
      "[[16022  1045]\n",
      " [ 1299 11307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     17067\n",
      "           1       0.92      0.90      0.91     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.92      0.92     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9210056280119975\n",
      "pre:  0.9153983160621761\n",
      "rec:  0.8969538315088054\n",
      "ma F1:  0.9189594526714616\n",
      "mi F1:  0.9210056280119975\n",
      "we F1:  0.920895399266187\n",
      "29673 464\n",
      "Loss:  0.01900019869208336\n",
      "Loss:  0.06151667237281799\n",
      "Loss:  0.04889104515314102\n",
      "54 **********\n",
      "Epoch:  5252.51384472847  fold:  5  kers:  128\n",
      "epoch:  55\n",
      "29673 464\n",
      "Loss:  0.0406135655939579\n",
      "Loss:  0.04645408317446709\n",
      "Loss:  0.059782251715660095\n",
      "55 **********\n",
      "Epoch:  5333.540196180344  fold:  5  kers:  128\n",
      "epoch:  56\n",
      "29673 464\n",
      "Loss:  0.06355452537536621\n",
      "Loss:  0.042083989828825\n",
      "Loss:  0.10853461921215057\n",
      "56 **********\n",
      "Epoch:  5414.577518939972  fold:  5  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.06636898219585419\n",
      "Eval Loss:  0.0502907820045948\n",
      "Eval Loss:  0.031382571905851364\n",
      "[[3069   28]\n",
      " [  21  100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.78      0.83      0.80       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.89      0.91      0.90      3218\n",
      "weighted avg       0.99      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9847731510254817\n",
      "pre:  0.78125\n",
      "rec:  0.8264462809917356\n",
      "ma F1:  0.897646509750007\n",
      "mi F1:  0.9847731510254817\n",
      "we F1:  0.9849785691760132\n",
      "Eval Loss:  0.2180902659893036\n",
      "Eval Loss:  0.1275673508644104\n",
      "Eval Loss:  0.2379920482635498\n",
      "Eval Loss:  0.16745740175247192\n",
      "Eval Loss:  0.2307133823633194\n",
      "Eval Loss:  0.14882536232471466\n",
      "Eval Loss:  0.22817856073379517\n",
      "Eval Loss:  0.14553675055503845\n",
      "Eval Loss:  0.22886674106121063\n",
      "Eval Loss:  0.2278556078672409\n",
      "Eval Loss:  0.22699174284934998\n",
      "Eval Loss:  0.23094770312309265\n",
      "Eval Loss:  0.13797947764396667\n",
      "Eval Loss:  0.27025023102760315\n",
      "Eval Loss:  0.11935839056968689\n",
      "Eval Loss:  0.20707999169826508\n",
      "Eval Loss:  0.1545231193304062\n",
      "Eval Loss:  0.15197192132472992\n",
      "Eval Loss:  0.2021273672580719\n",
      "Eval Loss:  0.18402650952339172\n",
      "Eval Loss:  0.17478632926940918\n",
      "Eval Loss:  0.18284371495246887\n",
      "Eval Loss:  0.13882364332675934\n",
      "Eval Loss:  0.15729643404483795\n",
      "Eval Loss:  0.22845716774463654\n",
      "Eval Loss:  0.10068577527999878\n",
      "Eval Loss:  0.22154486179351807\n",
      "Eval Loss:  0.23014937341213226\n",
      "Eval Loss:  0.21446320414543152\n",
      "[[16042  1025]\n",
      " [ 1177 11429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     17067\n",
      "           1       0.92      0.91      0.91     12606\n",
      "\n",
      "    accuracy                           0.93     29673\n",
      "   macro avg       0.92      0.92      0.92     29673\n",
      "weighted avg       0.93      0.93      0.93     29673\n",
      "\n",
      "acc:  0.9257911232433526\n",
      "pre:  0.9176971254215514\n",
      "rec:  0.9066317626527051\n",
      "ma F1:  0.9239532105388879\n",
      "mi F1:  0.9257911232433526\n",
      "we F1:  0.925730563362347\n",
      "29673 464\n",
      "Loss:  0.05787720903754234\n",
      "Loss:  0.06068389490246773\n",
      "Loss:  0.0381024107336998\n",
      "57 **********\n",
      "Epoch:  5538.838271141052  fold:  5  kers:  128\n",
      "epoch:  58\n",
      "29673 464\n",
      "Loss:  0.03214496746659279\n",
      "Loss:  0.06931716203689575\n",
      "Loss:  0.04118987172842026\n",
      "58 **********\n",
      "Epoch:  5619.884569883347  fold:  5  kers:  128\n",
      "epoch:  59\n",
      "29673 464\n",
      "Loss:  0.03551170229911804\n",
      "Loss:  0.1131521463394165\n",
      "Loss:  0.057448048144578934\n",
      "59 **********\n",
      "Epoch:  5700.908927440643  fold:  5  kers:  128\n",
      "Eval Loss:  0.09397869557142258\n",
      "Eval Loss:  0.10004317760467529\n",
      "Eval Loss:  0.03367104381322861\n",
      "[[3041   56]\n",
      " [  15  106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3097\n",
      "           1       0.65      0.88      0.75       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.82      0.93      0.87      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9779366065879428\n",
      "pre:  0.654320987654321\n",
      "rec:  0.8760330578512396\n",
      "ma F1:  0.8687887605747204\n",
      "mi F1:  0.9779366065879428\n",
      "we F1:  0.9794613294794394\n",
      "update!  Acc:  0.9894344313238036\n",
      "Epoch:  5705.2453327178955  fold:  5  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29479 3412\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29479 461\n",
      "Loss:  0.17505232989788055\n",
      "Loss:  0.16959407925605774\n",
      "Loss:  0.1709911823272705\n",
      "0 **********\n",
      "Epoch:  92.69714593887329  fold:  6  kers:  128\n",
      "epoch:  1\n",
      "29479 461\n",
      "Loss:  0.15280504524707794\n",
      "Loss:  0.13698358833789825\n",
      "Loss:  0.12911668419837952\n",
      "1 **********\n",
      "Epoch:  173.13507103919983  fold:  6  kers:  128\n",
      "epoch:  2\n",
      "29479 461\n",
      "Loss:  0.11580425500869751\n",
      "Loss:  0.09795187413692474\n",
      "Loss:  0.10418373346328735\n",
      "2 **********\n",
      "Epoch:  253.6039137840271  fold:  6  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.1437145471572876\n",
      "Eval Loss:  0.3148066997528076\n",
      "Eval Loss:  0.5374559164047241\n",
      "[[1871  361]\n",
      " [ 139 1041]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88      2232\n",
      "           1       0.74      0.88      0.81      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.84      0.86      0.84      3412\n",
      "weighted avg       0.87      0.85      0.86      3412\n",
      "\n",
      "acc:  0.8534583821805393\n",
      "pre:  0.7425106990014265\n",
      "rec:  0.8822033898305085\n",
      "ma F1:  0.8442413678127799\n",
      "mi F1:  0.8534583821805394\n",
      "we F1:  0.8559236559030001\n",
      "update!  Acc:  0.8534583821805393\n",
      "Eval Loss:  0.3574586808681488\n",
      "Eval Loss:  0.4318898916244507\n",
      "Eval Loss:  0.4139396846294403\n",
      "Eval Loss:  0.34186214208602905\n",
      "Eval Loss:  0.37948668003082275\n",
      "Eval Loss:  0.44052571058273315\n",
      "Eval Loss:  0.4296502470970154\n",
      "Eval Loss:  0.3960812985897064\n",
      "Eval Loss:  0.44185271859169006\n",
      "Eval Loss:  0.4171811640262604\n",
      "Eval Loss:  0.5011391639709473\n",
      "Eval Loss:  0.3438188135623932\n",
      "Eval Loss:  0.44973859190940857\n",
      "Eval Loss:  0.3849044442176819\n",
      "Eval Loss:  0.43666040897369385\n",
      "Eval Loss:  0.3979482352733612\n",
      "Eval Loss:  0.4732395112514496\n",
      "Eval Loss:  0.453857958316803\n",
      "Eval Loss:  0.35063260793685913\n",
      "Eval Loss:  0.5154134631156921\n",
      "Eval Loss:  0.4274435341358185\n",
      "Eval Loss:  0.4263792634010315\n",
      "Eval Loss:  0.41612061858177185\n",
      "Eval Loss:  0.3910718560218811\n",
      "Eval Loss:  0.4266027808189392\n",
      "Eval Loss:  0.46517810225486755\n",
      "Eval Loss:  0.37500301003456116\n",
      "Eval Loss:  0.4126901626586914\n",
      "[[16041  1891]\n",
      " [ 3234  8313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86     17932\n",
      "           1       0.81      0.72      0.76     11547\n",
      "\n",
      "    accuracy                           0.83     29479\n",
      "   macro avg       0.82      0.81      0.81     29479\n",
      "weighted avg       0.83      0.83      0.82     29479\n",
      "\n",
      "acc:  0.8261474269819193\n",
      "pre:  0.8146805174441396\n",
      "rec:  0.7199272538321642\n",
      "ma F1:  0.8133178757078507\n",
      "mi F1:  0.8261474269819193\n",
      "we F1:  0.823917860812008\n",
      "29479 461\n",
      "Loss:  0.09730630367994308\n",
      "Loss:  0.08956067264080048\n",
      "Loss:  0.09067893028259277\n",
      "3 **********\n",
      "Epoch:  381.9547302722931  fold:  6  kers:  128\n",
      "epoch:  4\n",
      "29479 461\n",
      "Loss:  0.11733139306306839\n",
      "Loss:  0.07953491061925888\n",
      "Loss:  0.09315765649080276\n",
      "4 **********\n",
      "Epoch:  462.40063428878784  fold:  6  kers:  128\n",
      "epoch:  5\n",
      "29479 461\n",
      "Loss:  0.08216458559036255\n",
      "Loss:  0.14012594521045685\n",
      "Loss:  0.06377319991588593\n",
      "5 **********\n",
      "Epoch:  542.8704736232758  fold:  6  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.056392330676317215\n",
      "Eval Loss:  0.2749669551849365\n",
      "Eval Loss:  0.48854199051856995\n",
      "[[1993  239]\n",
      " [ 173 1007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      2232\n",
      "           1       0.81      0.85      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.86      0.87      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8792497069167644\n",
      "pre:  0.8081861958266453\n",
      "rec:  0.8533898305084746\n",
      "ma F1:  0.86824708975488\n",
      "mi F1:  0.8792497069167644\n",
      "we F1:  0.8799861904184726\n",
      "update!  Acc:  0.8792497069167644\n",
      "Eval Loss:  0.27412381768226624\n",
      "Eval Loss:  0.3616757392883301\n",
      "Eval Loss:  0.40336862206459045\n",
      "Eval Loss:  0.2739982008934021\n",
      "Eval Loss:  0.36824309825897217\n",
      "Eval Loss:  0.3952956795692444\n",
      "Eval Loss:  0.38703233003616333\n",
      "Eval Loss:  0.36267250776290894\n",
      "Eval Loss:  0.4298509359359741\n",
      "Eval Loss:  0.3860057592391968\n",
      "Eval Loss:  0.46078845858573914\n",
      "Eval Loss:  0.3449949622154236\n",
      "Eval Loss:  0.42470410466194153\n",
      "Eval Loss:  0.4005913734436035\n",
      "Eval Loss:  0.4171420633792877\n",
      "Eval Loss:  0.3222830891609192\n",
      "Eval Loss:  0.4975045919418335\n",
      "Eval Loss:  0.3934459984302521\n",
      "Eval Loss:  0.3107185959815979\n",
      "Eval Loss:  0.5241001844406128\n",
      "Eval Loss:  0.38823646306991577\n",
      "Eval Loss:  0.4024866819381714\n",
      "Eval Loss:  0.4324372708797455\n",
      "Eval Loss:  0.32151421904563904\n",
      "Eval Loss:  0.3793007433414459\n",
      "Eval Loss:  0.47026312351226807\n",
      "Eval Loss:  0.3533473312854767\n",
      "Eval Loss:  0.4150318503379822\n",
      "[[16890  1042]\n",
      " [ 3351  8196]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88     17932\n",
      "           1       0.89      0.71      0.79     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.86      0.83      0.84     29479\n",
      "weighted avg       0.86      0.85      0.85     29479\n",
      "\n",
      "acc:  0.850978662776892\n",
      "pre:  0.8872050227321931\n",
      "rec:  0.7097947518836061\n",
      "ma F1:  0.8367821588560508\n",
      "mi F1:  0.850978662776892\n",
      "we F1:  0.8472082777351135\n",
      "29479 461\n",
      "Loss:  0.08346107602119446\n",
      "Loss:  0.05936938896775246\n",
      "Loss:  0.08512968569993973\n",
      "6 **********\n",
      "Epoch:  666.7412683963776  fold:  6  kers:  128\n",
      "epoch:  7\n",
      "29479 461\n",
      "Loss:  0.10272204130887985\n",
      "Loss:  0.09726571291685104\n",
      "Loss:  0.08364615589380264\n",
      "7 **********\n",
      "Epoch:  747.2041275501251  fold:  6  kers:  128\n",
      "epoch:  8\n",
      "29479 461\n",
      "Loss:  0.08856873214244843\n",
      "Loss:  0.10460713505744934\n",
      "Loss:  0.08454006165266037\n",
      "8 **********\n",
      "Epoch:  827.6719727516174  fold:  6  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.026987174525856972\n",
      "Eval Loss:  0.31017935276031494\n",
      "Eval Loss:  0.39815831184387207\n",
      "[[2082  150]\n",
      " [ 202  978]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      2232\n",
      "           1       0.87      0.83      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.88      0.88      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8968347010550997\n",
      "pre:  0.8670212765957447\n",
      "rec:  0.8288135593220339\n",
      "ma F1:  0.8847709587939204\n",
      "mi F1:  0.8968347010550995\n",
      "we F1:  0.8962664813109136\n",
      "update!  Acc:  0.8968347010550997\n",
      "Eval Loss:  0.2707595229148865\n",
      "Eval Loss:  0.35916271805763245\n",
      "Eval Loss:  0.3890313506126404\n",
      "Eval Loss:  0.3159565329551697\n",
      "Eval Loss:  0.3483245074748993\n",
      "Eval Loss:  0.3865453898906708\n",
      "Eval Loss:  0.4122403860092163\n",
      "Eval Loss:  0.4016079008579254\n",
      "Eval Loss:  0.38248851895332336\n",
      "Eval Loss:  0.39258307218551636\n",
      "Eval Loss:  0.4967251420021057\n",
      "Eval Loss:  0.32547348737716675\n",
      "Eval Loss:  0.409474641084671\n",
      "Eval Loss:  0.3599129915237427\n",
      "Eval Loss:  0.4558981955051422\n",
      "Eval Loss:  0.34005263447761536\n",
      "Eval Loss:  0.5194813013076782\n",
      "Eval Loss:  0.4014105796813965\n",
      "Eval Loss:  0.33061492443084717\n",
      "Eval Loss:  0.5414996147155762\n",
      "Eval Loss:  0.35127919912338257\n",
      "Eval Loss:  0.3647712767124176\n",
      "Eval Loss:  0.3866086006164551\n",
      "Eval Loss:  0.3418503701686859\n",
      "Eval Loss:  0.40058645606040955\n",
      "Eval Loss:  0.4834195375442505\n",
      "Eval Loss:  0.3686598539352417\n",
      "Eval Loss:  0.41811859607696533\n",
      "[[17226   706]\n",
      " [ 3717  7830]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89     17932\n",
      "           1       0.92      0.68      0.78     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.87      0.82      0.83     29479\n",
      "weighted avg       0.86      0.85      0.84     29479\n",
      "\n",
      "acc:  0.8499609891787374\n",
      "pre:  0.9172914714151827\n",
      "rec:  0.6780982073265783\n",
      "ma F1:  0.8329945299354944\n",
      "mi F1:  0.8499609891787374\n",
      "we F1:  0.8445239937784176\n",
      "29479 461\n",
      "Loss:  0.0880487784743309\n",
      "Loss:  0.0516173429787159\n",
      "Loss:  0.06936918199062347\n",
      "9 **********\n",
      "Epoch:  951.5557324886322  fold:  6  kers:  128\n",
      "epoch:  10\n",
      "29479 461\n",
      "Loss:  0.0940709263086319\n",
      "Loss:  0.09087258577346802\n",
      "Loss:  0.07337680459022522\n",
      "10 **********\n",
      "Epoch:  1032.0165965557098  fold:  6  kers:  128\n",
      "epoch:  11\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09099502116441727\n",
      "Loss:  0.08784174919128418\n",
      "Loss:  0.09806309640407562\n",
      "11 **********\n",
      "Epoch:  1112.5113697052002  fold:  6  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.03700289875268936\n",
      "Eval Loss:  0.2797640562057495\n",
      "Eval Loss:  0.35912245512008667\n",
      "[[2055  177]\n",
      " [ 184  996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2232\n",
      "           1       0.85      0.84      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8941969519343493\n",
      "pre:  0.8491048593350383\n",
      "rec:  0.8440677966101695\n",
      "ma F1:  0.882918136172071\n",
      "mi F1:  0.8941969519343493\n",
      "we F1:  0.8941223988556564\n",
      "Eval Loss:  0.22082078456878662\n",
      "Eval Loss:  0.3034074306488037\n",
      "Eval Loss:  0.3072279393672943\n",
      "Eval Loss:  0.24948252737522125\n",
      "Eval Loss:  0.2946973145008087\n",
      "Eval Loss:  0.30566710233688354\n",
      "Eval Loss:  0.3551095426082611\n",
      "Eval Loss:  0.3111177086830139\n",
      "Eval Loss:  0.30728933215141296\n",
      "Eval Loss:  0.319909930229187\n",
      "Eval Loss:  0.3474169075489044\n",
      "Eval Loss:  0.2658022344112396\n",
      "Eval Loss:  0.3420802354812622\n",
      "Eval Loss:  0.2843804955482483\n",
      "Eval Loss:  0.3478001356124878\n",
      "Eval Loss:  0.22771453857421875\n",
      "Eval Loss:  0.4143822491168976\n",
      "Eval Loss:  0.3057585060596466\n",
      "Eval Loss:  0.27960193157196045\n",
      "Eval Loss:  0.4090057909488678\n",
      "Eval Loss:  0.27652794122695923\n",
      "Eval Loss:  0.3075745105743408\n",
      "Eval Loss:  0.34702450037002563\n",
      "Eval Loss:  0.2951642870903015\n",
      "Eval Loss:  0.33985474705696106\n",
      "Eval Loss:  0.35858234763145447\n",
      "Eval Loss:  0.320376455783844\n",
      "Eval Loss:  0.2823844850063324\n",
      "[[17000   932]\n",
      " [ 2677  8870]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     17932\n",
      "           1       0.90      0.77      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.88      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8775738661419994\n",
      "pre:  0.9049173638033055\n",
      "rec:  0.7681648913137612\n",
      "ma F1:  0.8674955981398773\n",
      "mi F1:  0.8775738661419994\n",
      "we F1:  0.8754106954576572\n",
      "29479 461\n",
      "Loss:  0.09235577285289764\n",
      "Loss:  0.07424290478229523\n",
      "Loss:  0.07879424840211868\n",
      "12 **********\n",
      "Epoch:  1236.2096264362335  fold:  6  kers:  128\n",
      "epoch:  13\n",
      "29479 461\n",
      "Loss:  0.11346887052059174\n",
      "Loss:  0.07690389454364777\n",
      "Loss:  0.045634157955646515\n",
      "13 **********\n",
      "Epoch:  1316.6575245857239  fold:  6  kers:  128\n",
      "epoch:  14\n",
      "29479 461\n",
      "Loss:  0.06615252792835236\n",
      "Loss:  0.07325299829244614\n",
      "Loss:  0.06712345033884048\n",
      "14 **********\n",
      "Epoch:  1397.1143991947174  fold:  6  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.01620408706367016\n",
      "Eval Loss:  0.17637932300567627\n",
      "Eval Loss:  0.41122737526893616\n",
      "[[2056  176]\n",
      " [ 212  968]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      2232\n",
      "           1       0.85      0.82      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.87      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8862837045720985\n",
      "pre:  0.8461538461538461\n",
      "rec:  0.8203389830508474\n",
      "ma F1:  0.873412124689233\n",
      "mi F1:  0.8862837045720985\n",
      "we F1:  0.8858578067083273\n",
      "Eval Loss:  0.1742394119501114\n",
      "Eval Loss:  0.3067614734172821\n",
      "Eval Loss:  0.2956356108188629\n",
      "Eval Loss:  0.21009638905525208\n",
      "Eval Loss:  0.28771883249282837\n",
      "Eval Loss:  0.26520198583602905\n",
      "Eval Loss:  0.3707044720649719\n",
      "Eval Loss:  0.25337639451026917\n",
      "Eval Loss:  0.26347121596336365\n",
      "Eval Loss:  0.2610461115837097\n",
      "Eval Loss:  0.2592567205429077\n",
      "Eval Loss:  0.20919540524482727\n",
      "Eval Loss:  0.26468902826309204\n",
      "Eval Loss:  0.2449108362197876\n",
      "Eval Loss:  0.2899639308452606\n",
      "Eval Loss:  0.17265689373016357\n",
      "Eval Loss:  0.3234677016735077\n",
      "Eval Loss:  0.2686306834220886\n",
      "Eval Loss:  0.22694170475006104\n",
      "Eval Loss:  0.3442372679710388\n",
      "Eval Loss:  0.18197762966156006\n",
      "Eval Loss:  0.271575927734375\n",
      "Eval Loss:  0.31203535199165344\n",
      "Eval Loss:  0.2910327911376953\n",
      "Eval Loss:  0.29381221532821655\n",
      "Eval Loss:  0.29551011323928833\n",
      "Eval Loss:  0.2725785970687866\n",
      "Eval Loss:  0.23673544824123383\n",
      "[[16539  1393]\n",
      " [ 1829  9718]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17932\n",
      "           1       0.87      0.84      0.86     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.89      0.88      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8907018555581939\n",
      "pre:  0.8746287462874629\n",
      "rec:  0.8416038797956179\n",
      "ma F1:  0.884519119731487\n",
      "mi F1:  0.8907018555581939\n",
      "we F1:  0.8903066535613543\n",
      "29479 461\n",
      "Loss:  0.08817644417285919\n",
      "Loss:  0.08380233496427536\n",
      "Loss:  0.09136680513620377\n",
      "15 **********\n",
      "Epoch:  1520.9742233753204  fold:  6  kers:  128\n",
      "epoch:  16\n",
      "29479 461\n",
      "Loss:  0.04940112680196762\n",
      "Loss:  0.07303906232118607\n",
      "Loss:  0.05828077718615532\n",
      "16 **********\n",
      "Epoch:  1601.426111459732  fold:  6  kers:  128\n",
      "epoch:  17\n",
      "29479 461\n",
      "Loss:  0.03423690423369408\n",
      "Loss:  0.05579093098640442\n",
      "Loss:  0.05292690172791481\n",
      "17 **********\n",
      "Epoch:  1681.9029324054718  fold:  6  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.014531920664012432\n",
      "Eval Loss:  0.14190061390399933\n",
      "Eval Loss:  0.2879217863082886\n",
      "[[2074  158]\n",
      " [ 221  959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      2232\n",
      "           1       0.86      0.81      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.87      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8889214536928488\n",
      "pre:  0.8585496866606983\n",
      "rec:  0.8127118644067797\n",
      "ma F1:  0.8756411369734478\n",
      "mi F1:  0.8889214536928488\n",
      "we F1:  0.8881710860217077\n",
      "Eval Loss:  0.17391540110111237\n",
      "Eval Loss:  0.27714669704437256\n",
      "Eval Loss:  0.2705236077308655\n",
      "Eval Loss:  0.19736778736114502\n",
      "Eval Loss:  0.25848278403282166\n",
      "Eval Loss:  0.24330532550811768\n",
      "Eval Loss:  0.35446399450302124\n",
      "Eval Loss:  0.2792988717556\n",
      "Eval Loss:  0.24660204350948334\n",
      "Eval Loss:  0.27906933426856995\n",
      "Eval Loss:  0.264420747756958\n",
      "Eval Loss:  0.1794193685054779\n",
      "Eval Loss:  0.2520082890987396\n",
      "Eval Loss:  0.25150543451309204\n",
      "Eval Loss:  0.2921862006187439\n",
      "Eval Loss:  0.14735141396522522\n",
      "Eval Loss:  0.2722768187522888\n",
      "Eval Loss:  0.21527165174484253\n",
      "Eval Loss:  0.196916863322258\n",
      "Eval Loss:  0.3278982937335968\n",
      "Eval Loss:  0.17969930171966553\n",
      "Eval Loss:  0.2578229308128357\n",
      "Eval Loss:  0.26203304529190063\n",
      "Eval Loss:  0.2241395115852356\n",
      "Eval Loss:  0.2763916850090027\n",
      "Eval Loss:  0.2721109688282013\n",
      "Eval Loss:  0.2672100067138672\n",
      "Eval Loss:  0.18853408098220825\n",
      "[[16832  1100]\n",
      " [ 1840  9707]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17932\n",
      "           1       0.90      0.84      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.89      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9002679873808473\n",
      "pre:  0.8982141204774683\n",
      "rec:  0.8406512514072919\n",
      "ma F1:  0.894080411649792\n",
      "mi F1:  0.9002679873808472\n",
      "we F1:  0.8996253479364992\n",
      "29479 461\n",
      "Loss:  0.07492685317993164\n",
      "Loss:  0.09109333157539368\n",
      "Loss:  0.07102027535438538\n",
      "18 **********\n",
      "Epoch:  1805.5812423229218  fold:  6  kers:  128\n",
      "epoch:  19\n",
      "29479 461\n",
      "Loss:  0.06134963035583496\n",
      "Loss:  0.07577523589134216\n",
      "Loss:  0.08830637484788895\n",
      "19 **********\n",
      "Epoch:  1886.049087524414  fold:  6  kers:  128\n",
      "epoch:  20\n",
      "29479 461\n",
      "Loss:  0.0638759508728981\n",
      "Loss:  0.10383661091327667\n",
      "Loss:  0.07793071866035461\n",
      "20 **********\n",
      "Epoch:  1966.5548312664032  fold:  6  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.010500947944819927\n",
      "Eval Loss:  0.14528590440750122\n",
      "Eval Loss:  0.34979766607284546\n",
      "[[2072  160]\n",
      " [ 264  916]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      2232\n",
      "           1       0.85      0.78      0.81      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.85      0.86      3412\n",
      "weighted avg       0.87      0.88      0.87      3412\n",
      "\n",
      "acc:  0.8757327080890973\n",
      "pre:  0.8513011152416357\n",
      "rec:  0.7762711864406779\n",
      "ma F1:  0.8596185614388097\n",
      "mi F1:  0.8757327080890973\n",
      "we F1:  0.8742829924735005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.16408109664916992\n",
      "Eval Loss:  0.2943916320800781\n",
      "Eval Loss:  0.2629680931568146\n",
      "Eval Loss:  0.2060687094926834\n",
      "Eval Loss:  0.25493329763412476\n",
      "Eval Loss:  0.2209678292274475\n",
      "Eval Loss:  0.340487539768219\n",
      "Eval Loss:  0.25665104389190674\n",
      "Eval Loss:  0.2533952593803406\n",
      "Eval Loss:  0.24308522045612335\n",
      "Eval Loss:  0.25576621294021606\n",
      "Eval Loss:  0.167574942111969\n",
      "Eval Loss:  0.25576892495155334\n",
      "Eval Loss:  0.25658002495765686\n",
      "Eval Loss:  0.28370487689971924\n",
      "Eval Loss:  0.18381832540035248\n",
      "Eval Loss:  0.25673428177833557\n",
      "Eval Loss:  0.23688125610351562\n",
      "Eval Loss:  0.2126547396183014\n",
      "Eval Loss:  0.35630306601524353\n",
      "Eval Loss:  0.17218607664108276\n",
      "Eval Loss:  0.24292191863059998\n",
      "Eval Loss:  0.26346278190612793\n",
      "Eval Loss:  0.2592853903770447\n",
      "Eval Loss:  0.29296818375587463\n",
      "Eval Loss:  0.28869178891181946\n",
      "Eval Loss:  0.2586840093135834\n",
      "Eval Loss:  0.19432571530342102\n",
      "[[16672  1260]\n",
      " [ 1665  9882]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     17932\n",
      "           1       0.89      0.86      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.89      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9007768241799247\n",
      "pre:  0.8869143780290791\n",
      "rec:  0.8558067030397506\n",
      "ma F1:  0.8952177593953436\n",
      "mi F1:  0.9007768241799247\n",
      "we F1:  0.900445245205292\n",
      "29479 461\n",
      "Loss:  0.09368442744016647\n",
      "Loss:  0.05462750047445297\n",
      "Loss:  0.06686647981405258\n",
      "21 **********\n",
      "Epoch:  2090.214191198349  fold:  6  kers:  128\n",
      "epoch:  22\n",
      "29479 461\n",
      "Loss:  0.055437345057725906\n",
      "Loss:  0.06605778634548187\n",
      "Loss:  0.05854164808988571\n",
      "22 **********\n",
      "Epoch:  2170.7209327220917  fold:  6  kers:  128\n",
      "epoch:  23\n",
      "29479 461\n",
      "Loss:  0.06845135986804962\n",
      "Loss:  0.07091398537158966\n",
      "Loss:  0.06402905285358429\n",
      "23 **********\n",
      "Epoch:  2251.201743364334  fold:  6  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.009866348467767239\n",
      "Eval Loss:  0.20024830102920532\n",
      "Eval Loss:  0.34524229168891907\n",
      "[[2035  197]\n",
      " [ 253  927]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      2232\n",
      "           1       0.82      0.79      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.85      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8681125439624854\n",
      "pre:  0.8247330960854092\n",
      "rec:  0.785593220338983\n",
      "ma F1:  0.8525649889380531\n",
      "mi F1:  0.8681125439624854\n",
      "we F1:  0.8673267469576403\n",
      "Eval Loss:  0.19781383872032166\n",
      "Eval Loss:  0.2754923701286316\n",
      "Eval Loss:  0.22214560210704803\n",
      "Eval Loss:  0.20194374024868011\n",
      "Eval Loss:  0.26559945940971375\n",
      "Eval Loss:  0.2640514373779297\n",
      "Eval Loss:  0.297251433134079\n",
      "Eval Loss:  0.2603268623352051\n",
      "Eval Loss:  0.2596425712108612\n",
      "Eval Loss:  0.2358076274394989\n",
      "Eval Loss:  0.2714429497718811\n",
      "Eval Loss:  0.17282147705554962\n",
      "Eval Loss:  0.27140870690345764\n",
      "Eval Loss:  0.24555151164531708\n",
      "Eval Loss:  0.2997263967990875\n",
      "Eval Loss:  0.16347931325435638\n",
      "Eval Loss:  0.27718961238861084\n",
      "Eval Loss:  0.2475620061159134\n",
      "Eval Loss:  0.2182919681072235\n",
      "Eval Loss:  0.26928040385246277\n",
      "Eval Loss:  0.1476566046476364\n",
      "Eval Loss:  0.2158876657485962\n",
      "Eval Loss:  0.25610074400901794\n",
      "Eval Loss:  0.24050520360469818\n",
      "Eval Loss:  0.3234293758869171\n",
      "Eval Loss:  0.28065022826194763\n",
      "Eval Loss:  0.2591738700866699\n",
      "Eval Loss:  0.21128752827644348\n",
      "[[16590  1342]\n",
      " [ 1541 10006]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     17932\n",
      "           1       0.88      0.87      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9022015672173411\n",
      "pre:  0.8817412759957702\n",
      "rec:  0.866545423053607\n",
      "ma F1:  0.8970669385647259\n",
      "mi F1:  0.9022015672173411\n",
      "we F1:  0.9020463741581264\n",
      "29479 461\n",
      "Loss:  0.0629061684012413\n",
      "Loss:  0.06593247503042221\n",
      "Loss:  0.05149798095226288\n",
      "24 **********\n",
      "Epoch:  2374.825199365616  fold:  6  kers:  128\n",
      "epoch:  25\n",
      "29479 461\n",
      "Loss:  0.04546579718589783\n",
      "Loss:  0.12159816920757294\n",
      "Loss:  0.06020359694957733\n",
      "25 **********\n",
      "Epoch:  2455.321967601776  fold:  6  kers:  128\n",
      "epoch:  26\n",
      "29479 461\n",
      "Loss:  0.06199466809630394\n",
      "Loss:  0.04380330070853233\n",
      "Loss:  0.03691311925649643\n",
      "26 **********\n",
      "Epoch:  2535.8356895446777  fold:  6  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.007675636559724808\n",
      "Eval Loss:  0.2683890461921692\n",
      "Eval Loss:  0.3299955129623413\n",
      "[[2092  140]\n",
      " [ 345  835]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      2232\n",
      "           1       0.86      0.71      0.77      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.82      0.84      3412\n",
      "weighted avg       0.86      0.86      0.85      3412\n",
      "\n",
      "acc:  0.8578546307151231\n",
      "pre:  0.8564102564102564\n",
      "rec:  0.7076271186440678\n",
      "ma F1:  0.8355326811238066\n",
      "mi F1:  0.8578546307151231\n",
      "we F1:  0.8542142172972872\n",
      "Eval Loss:  0.20547738671302795\n",
      "Eval Loss:  0.27023956179618835\n",
      "Eval Loss:  0.2115340232849121\n",
      "Eval Loss:  0.18889953196048737\n",
      "Eval Loss:  0.2317715883255005\n",
      "Eval Loss:  0.2225329875946045\n",
      "Eval Loss:  0.3425155282020569\n",
      "Eval Loss:  0.2469145655632019\n",
      "Eval Loss:  0.22510501742362976\n",
      "Eval Loss:  0.22026671469211578\n",
      "Eval Loss:  0.2579273581504822\n",
      "Eval Loss:  0.16272911429405212\n",
      "Eval Loss:  0.23962979018688202\n",
      "Eval Loss:  0.23401083052158356\n",
      "Eval Loss:  0.26000314950942993\n",
      "Eval Loss:  0.16056060791015625\n",
      "Eval Loss:  0.25128358602523804\n",
      "Eval Loss:  0.2541733682155609\n",
      "Eval Loss:  0.19049197435379028\n",
      "Eval Loss:  0.2875901162624359\n",
      "Eval Loss:  0.17107927799224854\n",
      "Eval Loss:  0.2157229632139206\n",
      "Eval Loss:  0.21677008271217346\n",
      "Eval Loss:  0.190669447183609\n",
      "Eval Loss:  0.2775498330593109\n",
      "Eval Loss:  0.278260737657547\n",
      "Eval Loss:  0.2375529706478119\n",
      "Eval Loss:  0.18741998076438904\n",
      "[[16888  1044]\n",
      " [ 1661  9886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     17932\n",
      "           1       0.90      0.86      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9082397638997253\n",
      "pre:  0.9044830741079597\n",
      "rec:  0.8561531133627782\n",
      "ma F1:  0.9027532857349654\n",
      "mi F1:  0.9082397638997253\n",
      "we F1:  0.9077563081688402\n",
      "29479 461\n",
      "Loss:  0.07578477263450623\n",
      "Loss:  0.066046342253685\n",
      "Loss:  0.04452992603182793\n",
      "27 **********\n",
      "Epoch:  2659.3175246715546  fold:  6  kers:  128\n",
      "epoch:  28\n",
      "29479 461\n",
      "Loss:  0.04723381996154785\n",
      "Loss:  0.047647036612033844\n",
      "Loss:  0.07385148853063583\n",
      "28 **********\n",
      "Epoch:  2739.756446838379  fold:  6  kers:  128\n",
      "epoch:  29\n",
      "29479 461\n",
      "Loss:  0.08097418397665024\n",
      "Loss:  0.037825290113687515\n",
      "Loss:  0.09026281535625458\n",
      "29 **********\n",
      "Epoch:  2820.2372584342957  fold:  6  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.010225498117506504\n",
      "Eval Loss:  0.18993499875068665\n",
      "Eval Loss:  0.3130931854248047\n",
      "[[2060  172]\n",
      " [ 298  882]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90      2232\n",
      "           1       0.84      0.75      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.84      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8622508792497069\n",
      "pre:  0.8368121442125237\n",
      "rec:  0.747457627118644\n",
      "ma F1:  0.8436092630626308\n",
      "mi F1:  0.8622508792497069\n",
      "we F1:  0.8602569542585597\n",
      "Eval Loss:  0.19780753552913666\n",
      "Eval Loss:  0.2429904341697693\n",
      "Eval Loss:  0.20343324542045593\n",
      "Eval Loss:  0.18589431047439575\n",
      "Eval Loss:  0.20627282559871674\n",
      "Eval Loss:  0.20197099447250366\n",
      "Eval Loss:  0.30904093384742737\n",
      "Eval Loss:  0.24378840625286102\n",
      "Eval Loss:  0.22770704329013824\n",
      "Eval Loss:  0.25073882937431335\n",
      "Eval Loss:  0.25634661316871643\n",
      "Eval Loss:  0.1557110846042633\n",
      "Eval Loss:  0.24597333371639252\n",
      "Eval Loss:  0.21871709823608398\n",
      "Eval Loss:  0.26595795154571533\n",
      "Eval Loss:  0.15517663955688477\n",
      "Eval Loss:  0.2578815519809723\n",
      "Eval Loss:  0.24542978405952454\n",
      "Eval Loss:  0.19015105068683624\n",
      "Eval Loss:  0.2697991132736206\n",
      "Eval Loss:  0.129990354180336\n",
      "Eval Loss:  0.18897248804569244\n",
      "Eval Loss:  0.20111757516860962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1918904036283493\n",
      "Eval Loss:  0.2760683298110962\n",
      "Eval Loss:  0.25480136275291443\n",
      "Eval Loss:  0.21090221405029297\n",
      "Eval Loss:  0.17081192135810852\n",
      "[[16859  1073]\n",
      " [ 1488 10059]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17932\n",
      "           1       0.90      0.87      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9131245971708674\n",
      "pre:  0.9036112109234639\n",
      "rec:  0.871135359833723\n",
      "ma F1:  0.9082421736609596\n",
      "mi F1:  0.9131245971708674\n",
      "we F1:  0.9128266257360715\n",
      "29479 461\n",
      "Loss:  0.044898878782987595\n",
      "Loss:  0.08595598489046097\n",
      "Loss:  0.05518234521150589\n",
      "30 **********\n",
      "Epoch:  2943.7599833011627  fold:  6  kers:  128\n",
      "epoch:  31\n",
      "29479 461\n",
      "Loss:  0.04289572685956955\n",
      "Loss:  0.08975768834352493\n",
      "Loss:  0.08955822139978409\n",
      "31 **********\n",
      "Epoch:  3024.233812570572  fold:  6  kers:  128\n",
      "epoch:  32\n",
      "29479 461\n",
      "Loss:  0.05771868675947189\n",
      "Loss:  0.046303920447826385\n",
      "Loss:  0.05969400331377983\n",
      "32 **********\n",
      "Epoch:  3104.7255942821503  fold:  6  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.011749010533094406\n",
      "Eval Loss:  0.13551075756549835\n",
      "Eval Loss:  0.3279467821121216\n",
      "[[2048  184]\n",
      " [ 242  938]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91      2232\n",
      "           1       0.84      0.79      0.81      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.86      3412\n",
      "weighted avg       0.87      0.88      0.87      3412\n",
      "\n",
      "acc:  0.8751465416178195\n",
      "pre:  0.8360071301247772\n",
      "rec:  0.7949152542372881\n",
      "ma F1:  0.8603687119367387\n",
      "mi F1:  0.8751465416178195\n",
      "we F1:  0.8743743667335828\n",
      "Eval Loss:  0.1796361356973648\n",
      "Eval Loss:  0.23738740384578705\n",
      "Eval Loss:  0.21357184648513794\n",
      "Eval Loss:  0.196616068482399\n",
      "Eval Loss:  0.1980568915605545\n",
      "Eval Loss:  0.19603662192821503\n",
      "Eval Loss:  0.3021625280380249\n",
      "Eval Loss:  0.24356742203235626\n",
      "Eval Loss:  0.20095093548297882\n",
      "Eval Loss:  0.256137490272522\n",
      "Eval Loss:  0.2722442150115967\n",
      "Eval Loss:  0.15874570608139038\n",
      "Eval Loss:  0.2471744269132614\n",
      "Eval Loss:  0.2041434645652771\n",
      "Eval Loss:  0.2670416235923767\n",
      "Eval Loss:  0.1483345627784729\n",
      "Eval Loss:  0.23900540173053741\n",
      "Eval Loss:  0.24058158695697784\n",
      "Eval Loss:  0.17246013879776\n",
      "Eval Loss:  0.2764431834220886\n",
      "Eval Loss:  0.15370649099349976\n",
      "Eval Loss:  0.19031120836734772\n",
      "Eval Loss:  0.20636805891990662\n",
      "Eval Loss:  0.1691821962594986\n",
      "Eval Loss:  0.2725105881690979\n",
      "Eval Loss:  0.25107964873313904\n",
      "Eval Loss:  0.19804419577121735\n",
      "Eval Loss:  0.17192403972148895\n",
      "[[16923  1009]\n",
      " [ 1474 10073]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17932\n",
      "           1       0.91      0.87      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9157705485260694\n",
      "pre:  0.9089514528063526\n",
      "rec:  0.8723477959643198\n",
      "ma F1:  0.9109629708545125\n",
      "mi F1:  0.9157705485260694\n",
      "we F1:  0.9154441947133288\n",
      "29479 461\n",
      "Loss:  0.04627556726336479\n",
      "Loss:  0.05553986132144928\n",
      "Loss:  0.048356153070926666\n",
      "33 **********\n",
      "Epoch:  3228.3310983181  fold:  6  kers:  128\n",
      "epoch:  34\n",
      "29479 461\n",
      "Loss:  0.0402713380753994\n",
      "Loss:  0.04421396180987358\n",
      "Loss:  0.05812728404998779\n",
      "34 **********\n",
      "Epoch:  3308.810911178589  fold:  6  kers:  128\n",
      "epoch:  35\n",
      "29479 461\n",
      "Loss:  0.052473705261945724\n",
      "Loss:  0.04475904628634453\n",
      "Loss:  0.017278237268328667\n",
      "35 **********\n",
      "Epoch:  3389.326628923416  fold:  6  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.01624348573386669\n",
      "Eval Loss:  0.26666581630706787\n",
      "Eval Loss:  0.3493785560131073\n",
      "[[2060  172]\n",
      " [ 287  893]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      2232\n",
      "           1       0.84      0.76      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.84      0.85      3412\n",
      "weighted avg       0.86      0.87      0.86      3412\n",
      "\n",
      "acc:  0.8654747948417351\n",
      "pre:  0.8384976525821596\n",
      "rec:  0.7567796610169492\n",
      "ma F1:  0.8476527149458821\n",
      "mi F1:  0.8654747948417351\n",
      "we F1:  0.8637185487508842\n",
      "Eval Loss:  0.2021181285381317\n",
      "Eval Loss:  0.25935378670692444\n",
      "Eval Loss:  0.20738539099693298\n",
      "Eval Loss:  0.21539930999279022\n",
      "Eval Loss:  0.20049239695072174\n",
      "Eval Loss:  0.19217894971370697\n",
      "Eval Loss:  0.29951488971710205\n",
      "Eval Loss:  0.21525880694389343\n",
      "Eval Loss:  0.23842871189117432\n",
      "Eval Loss:  0.23335659503936768\n",
      "Eval Loss:  0.2385076880455017\n",
      "Eval Loss:  0.18700261414051056\n",
      "Eval Loss:  0.20696908235549927\n",
      "Eval Loss:  0.20423363149166107\n",
      "Eval Loss:  0.2424210160970688\n",
      "Eval Loss:  0.1603829264640808\n",
      "Eval Loss:  0.2419365495443344\n",
      "Eval Loss:  0.24294690787792206\n",
      "Eval Loss:  0.19472765922546387\n",
      "Eval Loss:  0.25088703632354736\n",
      "Eval Loss:  0.1505172848701477\n",
      "Eval Loss:  0.19591477513313293\n",
      "Eval Loss:  0.22575487196445465\n",
      "Eval Loss:  0.1895488053560257\n",
      "Eval Loss:  0.2745271921157837\n",
      "Eval Loss:  0.24864526093006134\n",
      "Eval Loss:  0.1928069293498993\n",
      "Eval Loss:  0.15708065032958984\n",
      "[[16718  1214]\n",
      " [ 1248 10299]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17932\n",
      "           1       0.89      0.89      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9164829200447776\n",
      "pre:  0.8945539824546165\n",
      "rec:  0.8919199792153806\n",
      "ma F1:  0.9123259155252303\n",
      "mi F1:  0.9164829200447776\n",
      "we F1:  0.916460901326338\n",
      "29479 461\n",
      "Loss:  0.03615425154566765\n",
      "Loss:  0.06777779757976532\n",
      "Loss:  0.05385784059762955\n",
      "36 **********\n",
      "Epoch:  3512.818436861038  fold:  6  kers:  128\n",
      "epoch:  37\n",
      "29479 461\n",
      "Loss:  0.0503452830016613\n",
      "Loss:  0.07938128709793091\n",
      "Loss:  0.04164893925189972\n",
      "37 **********\n",
      "Epoch:  3593.295257806778  fold:  6  kers:  128\n",
      "epoch:  38\n",
      "29479 461\n",
      "Loss:  0.031099772080779076\n",
      "Loss:  0.05233257636427879\n",
      "Loss:  0.025680074468255043\n",
      "38 **********\n",
      "Epoch:  3673.787039041519  fold:  6  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.016614403575658798\n",
      "Eval Loss:  0.38935619592666626\n",
      "Eval Loss:  0.35022687911987305\n",
      "[[2122  110]\n",
      " [ 387  793]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      2232\n",
      "           1       0.88      0.67      0.76      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.86      0.81      0.83      3412\n",
      "weighted avg       0.86      0.85      0.85      3412\n",
      "\n",
      "acc:  0.854337631887456\n",
      "pre:  0.8781838316722038\n",
      "rec:  0.6720338983050848\n",
      "ma F1:  0.8282858098468504\n",
      "mi F1:  0.854337631887456\n",
      "we F1:  0.8489077186404677\n",
      "Eval Loss:  0.2005191147327423\n",
      "Eval Loss:  0.23518985509872437\n",
      "Eval Loss:  0.186351478099823\n",
      "Eval Loss:  0.18494948744773865\n",
      "Eval Loss:  0.20020730793476105\n",
      "Eval Loss:  0.19880744814872742\n",
      "Eval Loss:  0.31807100772857666\n",
      "Eval Loss:  0.24023307859897614\n",
      "Eval Loss:  0.2640773355960846\n",
      "Eval Loss:  0.2418968677520752\n",
      "Eval Loss:  0.2646246552467346\n",
      "Eval Loss:  0.16863465309143066\n",
      "Eval Loss:  0.21671898663043976\n",
      "Eval Loss:  0.19744518399238586\n",
      "Eval Loss:  0.25204721093177795\n",
      "Eval Loss:  0.15077447891235352\n",
      "Eval Loss:  0.2474578619003296\n",
      "Eval Loss:  0.2446361482143402\n",
      "Eval Loss:  0.1912376433610916\n",
      "Eval Loss:  0.26194900274276733\n",
      "Eval Loss:  0.1472378820180893\n",
      "Eval Loss:  0.1820177584886551\n",
      "Eval Loss:  0.2147281914949417\n",
      "Eval Loss:  0.18925723433494568\n",
      "Eval Loss:  0.269185334444046\n",
      "Eval Loss:  0.2511520981788635\n",
      "Eval Loss:  0.20559293031692505\n",
      "Eval Loss:  0.18755967915058136\n",
      "[[17069   863]\n",
      " [ 1597  9950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     17932\n",
      "           1       0.92      0.86      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9165507649513213\n",
      "pre:  0.9201886617959864\n",
      "rec:  0.8616956785312202\n",
      "ma F1:  0.9113826615548657\n",
      "mi F1:  0.9165507649513213\n",
      "we F1:  0.9160179109138162\n",
      "29479 461\n",
      "Loss:  0.05100955814123154\n",
      "Loss:  0.05375569313764572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06727743148803711\n",
      "39 **********\n",
      "Epoch:  3797.605972766876  fold:  6  kers:  128\n",
      "epoch:  40\n",
      "29479 461\n",
      "Loss:  0.08180887252092361\n",
      "Loss:  0.026715058833360672\n",
      "Loss:  0.05674764886498451\n",
      "40 **********\n",
      "Epoch:  3882.497988462448  fold:  6  kers:  128\n",
      "epoch:  41\n",
      "29479 461\n",
      "Loss:  0.06247955188155174\n",
      "Loss:  0.05360022187232971\n",
      "Loss:  0.08814474195241928\n",
      "41 **********\n",
      "Epoch:  3962.948879003525  fold:  6  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.013761298730969429\n",
      "Eval Loss:  0.31853702664375305\n",
      "Eval Loss:  0.34880173206329346\n",
      "[[2041  191]\n",
      " [ 290  890]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      2232\n",
      "           1       0.82      0.75      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.85      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8590269636576788\n",
      "pre:  0.8233117483811286\n",
      "rec:  0.7542372881355932\n",
      "ma F1:  0.8409245839586397\n",
      "mi F1:  0.8590269636576788\n",
      "we F1:  0.8574699388182306\n",
      "Eval Loss:  0.2045646458864212\n",
      "Eval Loss:  0.2836795747280121\n",
      "Eval Loss:  0.21728360652923584\n",
      "Eval Loss:  0.2142922729253769\n",
      "Eval Loss:  0.2307802140712738\n",
      "Eval Loss:  0.21015137434005737\n",
      "Eval Loss:  0.3018026649951935\n",
      "Eval Loss:  0.2329830676317215\n",
      "Eval Loss:  0.2716061472892761\n",
      "Eval Loss:  0.26747584342956543\n",
      "Eval Loss:  0.2847067713737488\n",
      "Eval Loss:  0.1782895028591156\n",
      "Eval Loss:  0.22029061615467072\n",
      "Eval Loss:  0.2036363035440445\n",
      "Eval Loss:  0.3072945177555084\n",
      "Eval Loss:  0.17615503072738647\n",
      "Eval Loss:  0.26189178228378296\n",
      "Eval Loss:  0.20958559215068817\n",
      "Eval Loss:  0.23129674792289734\n",
      "Eval Loss:  0.277499794960022\n",
      "Eval Loss:  0.1722901314496994\n",
      "Eval Loss:  0.2608456611633301\n",
      "Eval Loss:  0.2063968926668167\n",
      "Eval Loss:  0.2172047346830368\n",
      "Eval Loss:  0.35514238476753235\n",
      "Eval Loss:  0.2752852439880371\n",
      "Eval Loss:  0.20352080464363098\n",
      "Eval Loss:  0.18324582278728485\n",
      "[[16505  1427]\n",
      " [ 1312 10235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     17932\n",
      "           1       0.88      0.89      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9070864004884833\n",
      "pre:  0.8776367689933116\n",
      "rec:  0.8863774140469386\n",
      "ma F1:  0.9026839544605153\n",
      "mi F1:  0.9070864004884833\n",
      "we F1:  0.9071671471062213\n",
      "29479 461\n",
      "Loss:  0.046255212277173996\n",
      "Loss:  0.05292562022805214\n",
      "Loss:  0.030635422095656395\n",
      "42 **********\n",
      "Epoch:  4086.509503364563  fold:  6  kers:  128\n",
      "epoch:  43\n",
      "29479 461\n",
      "Loss:  0.0326765701174736\n",
      "Loss:  0.052749380469322205\n",
      "Loss:  0.050243277102708817\n",
      "43 **********\n",
      "Epoch:  4167.02322602272  fold:  6  kers:  128\n",
      "epoch:  44\n",
      "29479 461\n",
      "Loss:  0.058603037148714066\n",
      "Loss:  0.05700059235095978\n",
      "Loss:  0.058444660156965256\n",
      "44 **********\n",
      "Epoch:  4247.582826137543  fold:  6  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.03503010421991348\n",
      "Eval Loss:  0.11659865826368332\n",
      "Eval Loss:  0.3557896614074707\n",
      "[[2017  215]\n",
      " [ 244  936]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      2232\n",
      "           1       0.81      0.79      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.85      0.85      0.85      3412\n",
      "weighted avg       0.86      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8654747948417351\n",
      "pre:  0.8132059079061685\n",
      "rec:  0.7932203389830509\n",
      "ma F1:  0.8504649446113947\n",
      "mi F1:  0.8654747948417351\n",
      "we F1:  0.8650721254090988\n",
      "Eval Loss:  0.17940790951251984\n",
      "Eval Loss:  0.2423744648694992\n",
      "Eval Loss:  0.19160401821136475\n",
      "Eval Loss:  0.19312810897827148\n",
      "Eval Loss:  0.19037486612796783\n",
      "Eval Loss:  0.1815837323665619\n",
      "Eval Loss:  0.28281569480895996\n",
      "Eval Loss:  0.2398790866136551\n",
      "Eval Loss:  0.20971989631652832\n",
      "Eval Loss:  0.23568981885910034\n",
      "Eval Loss:  0.24393115937709808\n",
      "Eval Loss:  0.13735249638557434\n",
      "Eval Loss:  0.2093629240989685\n",
      "Eval Loss:  0.21347838640213013\n",
      "Eval Loss:  0.2728508412837982\n",
      "Eval Loss:  0.13576827943325043\n",
      "Eval Loss:  0.24470412731170654\n",
      "Eval Loss:  0.23657581210136414\n",
      "Eval Loss:  0.16573254764080048\n",
      "Eval Loss:  0.22535282373428345\n",
      "Eval Loss:  0.14500762522220612\n",
      "Eval Loss:  0.15782827138900757\n",
      "Eval Loss:  0.2333565205335617\n",
      "Eval Loss:  0.15177159011363983\n",
      "Eval Loss:  0.2680608332157135\n",
      "Eval Loss:  0.24628028273582458\n",
      "Eval Loss:  0.17146100103855133\n",
      "Eval Loss:  0.15481345355510712\n",
      "[[16733  1199]\n",
      " [ 1136 10411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     17932\n",
      "           1       0.90      0.90      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.92      0.92     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9207910716102988\n",
      "pre:  0.8967269595176572\n",
      "rec:  0.9016194682601542\n",
      "ma F1:  0.9169724584271853\n",
      "mi F1:  0.9207910716102988\n",
      "we F1:  0.9208291248577739\n",
      "29479 461\n",
      "Loss:  0.05894428864121437\n",
      "Loss:  0.04458051919937134\n",
      "Loss:  0.05369461327791214\n",
      "45 **********\n",
      "Epoch:  4371.241188764572  fold:  6  kers:  128\n",
      "epoch:  46\n",
      "29479 461\n",
      "Loss:  0.04425225406885147\n",
      "Loss:  0.05586933344602585\n",
      "Loss:  0.04746164381504059\n",
      "46 **********\n",
      "Epoch:  4451.783833742142  fold:  6  kers:  128\n",
      "epoch:  47\n",
      "29479 461\n",
      "Loss:  0.05051719769835472\n",
      "Loss:  0.03870217874646187\n",
      "Loss:  0.06269209086894989\n",
      "47 **********\n",
      "Epoch:  4532.301546096802  fold:  6  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.01514405757188797\n",
      "Eval Loss:  0.24694396555423737\n",
      "Eval Loss:  0.29338714480400085\n",
      "[[2061  171]\n",
      " [ 301  879]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90      2232\n",
      "           1       0.84      0.74      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.85      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.861664712778429\n",
      "pre:  0.8371428571428572\n",
      "rec:  0.7449152542372881\n",
      "ma F1:  0.8427990496475223\n",
      "mi F1:  0.861664712778429\n",
      "we F1:  0.8595898090499875\n",
      "Eval Loss:  0.17358161509037018\n",
      "Eval Loss:  0.256693035364151\n",
      "Eval Loss:  0.18694546818733215\n",
      "Eval Loss:  0.1965666562318802\n",
      "Eval Loss:  0.20152592658996582\n",
      "Eval Loss:  0.1749311238527298\n",
      "Eval Loss:  0.3072763681411743\n",
      "Eval Loss:  0.2048415094614029\n",
      "Eval Loss:  0.18931737542152405\n",
      "Eval Loss:  0.22860932350158691\n",
      "Eval Loss:  0.22150234878063202\n",
      "Eval Loss:  0.15737180411815643\n",
      "Eval Loss:  0.19077323377132416\n",
      "Eval Loss:  0.21240657567977905\n",
      "Eval Loss:  0.27638790011405945\n",
      "Eval Loss:  0.13879050314426422\n",
      "Eval Loss:  0.2125568985939026\n",
      "Eval Loss:  0.21530020236968994\n",
      "Eval Loss:  0.1833271086215973\n",
      "Eval Loss:  0.2191380113363266\n",
      "Eval Loss:  0.1272798329591751\n",
      "Eval Loss:  0.18642498552799225\n",
      "Eval Loss:  0.2043718695640564\n",
      "Eval Loss:  0.1397426575422287\n",
      "Eval Loss:  0.28097981214523315\n",
      "Eval Loss:  0.24669073522090912\n",
      "Eval Loss:  0.17043450474739075\n",
      "Eval Loss:  0.16071514785289764\n",
      "[[16751  1181]\n",
      " [ 1075 10472]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     17932\n",
      "           1       0.90      0.91      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.92      0.92     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9234709454187727\n",
      "pre:  0.8986527074573071\n",
      "rec:  0.9069022256863255\n",
      "ma F1:  0.9198339219002838\n",
      "mi F1:  0.9234709454187727\n",
      "we F1:  0.9235323444461591\n",
      "29479 461\n",
      "Loss:  0.07966773211956024\n",
      "Loss:  0.044972680509090424\n",
      "Loss:  0.04936081916093826\n",
      "48 **********\n",
      "Epoch:  4655.91303396225  fold:  6  kers:  128\n",
      "epoch:  49\n",
      "29479 461\n",
      "Loss:  0.02689506486058235\n",
      "Loss:  0.021646365523338318\n",
      "Loss:  0.0628676638007164\n",
      "49 **********\n",
      "Epoch:  4736.409801721573  fold:  6  kers:  128\n",
      "epoch:  50\n",
      "29479 461\n",
      "Loss:  0.06498852372169495\n",
      "Loss:  0.052830688655376434\n",
      "Loss:  0.0571293979883194\n",
      "50 **********\n",
      "Epoch:  4816.8736577034  fold:  6  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.027308518067002296\n",
      "Eval Loss:  0.20195762813091278\n",
      "Eval Loss:  0.3757987320423126\n",
      "[[2043  189]\n",
      " [ 252  928]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90      2232\n",
      "           1       0.83      0.79      0.81      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.85      0.86      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8707502930832356\n",
      "pre:  0.8307967770814683\n",
      "rec:  0.7864406779661017\n",
      "ma F1:  0.8552974707263601\n",
      "mi F1:  0.8707502930832356\n",
      "we F1:  0.8698771739724884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1673574447631836\n",
      "Eval Loss:  0.24042680859565735\n",
      "Eval Loss:  0.16506430506706238\n",
      "Eval Loss:  0.17260584235191345\n",
      "Eval Loss:  0.1631755232810974\n",
      "Eval Loss:  0.1589004397392273\n",
      "Eval Loss:  0.2885318100452423\n",
      "Eval Loss:  0.207298144698143\n",
      "Eval Loss:  0.17526254057884216\n",
      "Eval Loss:  0.2144317328929901\n",
      "Eval Loss:  0.19845598936080933\n",
      "Eval Loss:  0.14253593981266022\n",
      "Eval Loss:  0.18622371554374695\n",
      "Eval Loss:  0.1708347648382187\n",
      "Eval Loss:  0.2182764708995819\n",
      "Eval Loss:  0.12353182584047318\n",
      "Eval Loss:  0.19484862685203552\n",
      "Eval Loss:  0.18919844925403595\n",
      "Eval Loss:  0.16178442537784576\n",
      "Eval Loss:  0.20365993678569794\n",
      "Eval Loss:  0.15298934280872345\n",
      "Eval Loss:  0.15350216627120972\n",
      "Eval Loss:  0.19469000399112701\n",
      "Eval Loss:  0.1168910339474678\n",
      "Eval Loss:  0.25842103362083435\n",
      "Eval Loss:  0.22541260719299316\n",
      "Eval Loss:  0.17706157267093658\n",
      "Eval Loss:  0.14732730388641357\n",
      "[[16716  1216]\n",
      " [  899 10648]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     17932\n",
      "           1       0.90      0.92      0.91     11547\n",
      "\n",
      "    accuracy                           0.93     29479\n",
      "   macro avg       0.92      0.93      0.93     29479\n",
      "weighted avg       0.93      0.93      0.93     29479\n",
      "\n",
      "acc:  0.9282540113300994\n",
      "pre:  0.8975050573162509\n",
      "rec:  0.922144279899541\n",
      "ma F1:  0.9250795806366126\n",
      "mi F1:  0.9282540113300994\n",
      "we F1:  0.9284198476072641\n",
      "29479 461\n",
      "Loss:  0.036128848791122437\n",
      "Loss:  0.062217600643634796\n",
      "Loss:  0.042302072048187256\n",
      "51 **********\n",
      "Epoch:  4940.593854904175  fold:  6  kers:  128\n",
      "epoch:  52\n",
      "29479 461\n",
      "Loss:  0.03866412490606308\n",
      "Loss:  0.03900102525949478\n",
      "Loss:  0.05302141606807709\n",
      "52 **********\n",
      "Epoch:  5021.148468732834  fold:  6  kers:  128\n",
      "epoch:  53\n",
      "29479 461\n",
      "Loss:  0.03240140527486801\n",
      "Loss:  0.043751589953899384\n",
      "Loss:  0.05966697260737419\n",
      "53 **********\n",
      "Epoch:  5101.682138442993  fold:  6  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.009682144038379192\n",
      "Eval Loss:  0.2252144068479538\n",
      "Eval Loss:  0.3402620255947113\n",
      "[[2057  175]\n",
      " [ 284  896]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      2232\n",
      "           1       0.84      0.76      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.84      0.85      3412\n",
      "weighted avg       0.86      0.87      0.86      3412\n",
      "\n",
      "acc:  0.8654747948417351\n",
      "pre:  0.8366013071895425\n",
      "rec:  0.7593220338983051\n",
      "ma F1:  0.847859439588188\n",
      "mi F1:  0.8654747948417351\n",
      "we F1:  0.8638209845724528\n",
      "Eval Loss:  0.12581981718540192\n",
      "Eval Loss:  0.24175170063972473\n",
      "Eval Loss:  0.16206739842891693\n",
      "Eval Loss:  0.172160342335701\n",
      "Eval Loss:  0.16343189775943756\n",
      "Eval Loss:  0.15260042250156403\n",
      "Eval Loss:  0.24051207304000854\n",
      "Eval Loss:  0.240589901804924\n",
      "Eval Loss:  0.19965162873268127\n",
      "Eval Loss:  0.2390764057636261\n",
      "Eval Loss:  0.20375074446201324\n",
      "Eval Loss:  0.13421544432640076\n",
      "Eval Loss:  0.17442446947097778\n",
      "Eval Loss:  0.17403900623321533\n",
      "Eval Loss:  0.2136881947517395\n",
      "Eval Loss:  0.09323087334632874\n",
      "Eval Loss:  0.1835879385471344\n",
      "Eval Loss:  0.16541627049446106\n",
      "Eval Loss:  0.1324368566274643\n",
      "Eval Loss:  0.18097154796123505\n",
      "Eval Loss:  0.1474076807498932\n",
      "Eval Loss:  0.14358533918857574\n",
      "Eval Loss:  0.22299033403396606\n",
      "Eval Loss:  0.11943675577640533\n",
      "Eval Loss:  0.25369739532470703\n",
      "Eval Loss:  0.1974884420633316\n",
      "Eval Loss:  0.19257067143917084\n",
      "Eval Loss:  0.1373310536146164\n",
      "[[16916  1016]\n",
      " [ 1011 10536]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     17932\n",
      "           1       0.91      0.91      0.91     11547\n",
      "\n",
      "    accuracy                           0.93     29479\n",
      "   macro avg       0.93      0.93      0.93     29479\n",
      "weighted avg       0.93      0.93      0.93     29479\n",
      "\n",
      "acc:  0.9312391872180196\n",
      "pre:  0.9120498614958449\n",
      "rec:  0.9124447908547675\n",
      "ma F1:  0.9278601653224386\n",
      "mi F1:  0.9312391872180196\n",
      "we F1:  0.9312418353543013\n",
      "29479 461\n",
      "Loss:  0.03267515078186989\n",
      "Loss:  0.055949896574020386\n",
      "Loss:  0.05296678841114044\n",
      "54 **********\n",
      "Epoch:  5225.437242031097  fold:  6  kers:  128\n",
      "epoch:  55\n",
      "29479 461\n",
      "Loss:  0.06259637326002121\n",
      "Loss:  0.04457163065671921\n",
      "Loss:  0.03482741117477417\n",
      "55 **********\n",
      "Epoch:  5305.924036979675  fold:  6  kers:  128\n",
      "epoch:  56\n",
      "29479 461\n",
      "Loss:  0.06512212753295898\n",
      "Loss:  0.05267254635691643\n",
      "Loss:  0.05703943595290184\n",
      "56 **********\n",
      "Epoch:  5386.4148206710815  fold:  6  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.007246648892760277\n",
      "Eval Loss:  0.26691821217536926\n",
      "Eval Loss:  0.2930147647857666\n",
      "[[2085  147]\n",
      " [ 322  858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      2232\n",
      "           1       0.85      0.73      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8625439624853458\n",
      "pre:  0.8537313432835821\n",
      "rec:  0.7271186440677966\n",
      "ma F1:  0.8421276581051211\n",
      "mi F1:  0.8625439624853458\n",
      "we F1:  0.8596321016324207\n",
      "Eval Loss:  0.15873216092586517\n",
      "Eval Loss:  0.22079989314079285\n",
      "Eval Loss:  0.15817901492118835\n",
      "Eval Loss:  0.17087799310684204\n",
      "Eval Loss:  0.15171460807323456\n",
      "Eval Loss:  0.1673421710729599\n",
      "Eval Loss:  0.2724543511867523\n",
      "Eval Loss:  0.20793579518795013\n",
      "Eval Loss:  0.15816988050937653\n",
      "Eval Loss:  0.2294428050518036\n",
      "Eval Loss:  0.23849204182624817\n",
      "Eval Loss:  0.1371016651391983\n",
      "Eval Loss:  0.18093030154705048\n",
      "Eval Loss:  0.18250548839569092\n",
      "Eval Loss:  0.21455352008342743\n",
      "Eval Loss:  0.13177073001861572\n",
      "Eval Loss:  0.20714469254016876\n",
      "Eval Loss:  0.23429782688617706\n",
      "Eval Loss:  0.13740913569927216\n",
      "Eval Loss:  0.17041908204555511\n",
      "Eval Loss:  0.143090158700943\n",
      "Eval Loss:  0.13719049096107483\n",
      "Eval Loss:  0.1684822142124176\n",
      "Eval Loss:  0.1388614922761917\n",
      "Eval Loss:  0.2269625961780548\n",
      "Eval Loss:  0.22591416537761688\n",
      "Eval Loss:  0.16679750382900238\n",
      "Eval Loss:  0.1844824105501175\n",
      "[[17061   871]\n",
      " [ 1150 10397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     17932\n",
      "           1       0.92      0.90      0.91     11547\n",
      "\n",
      "    accuracy                           0.93     29479\n",
      "   macro avg       0.93      0.93      0.93     29479\n",
      "weighted avg       0.93      0.93      0.93     29479\n",
      "\n",
      "acc:  0.9314427219376505\n",
      "pre:  0.9227014554490592\n",
      "rec:  0.9004070321295574\n",
      "ma F1:  0.9277505758850162\n",
      "mi F1:  0.9314427219376505\n",
      "we F1:  0.9312881437940903\n",
      "29479 461\n",
      "Loss:  0.04423341155052185\n",
      "Loss:  0.038886044174432755\n",
      "Loss:  0.05290883406996727\n",
      "57 **********\n",
      "Epoch:  5509.9894070625305  fold:  6  kers:  128\n",
      "epoch:  58\n",
      "29479 461\n",
      "Loss:  0.05947989225387573\n",
      "Loss:  0.062239162623882294\n",
      "Loss:  0.06004071235656738\n",
      "58 **********\n",
      "Epoch:  5590.457252979279  fold:  6  kers:  128\n",
      "epoch:  59\n",
      "29479 461\n",
      "Loss:  0.06590132415294647\n",
      "Loss:  0.06322968006134033\n",
      "Loss:  0.034449249505996704\n",
      "59 **********\n",
      "Epoch:  5670.9639937877655  fold:  6  kers:  128\n",
      "Eval Loss:  0.01644621603190899\n",
      "Eval Loss:  0.2598060071468353\n",
      "Eval Loss:  0.3015945851802826\n",
      "[[2074  158]\n",
      " [ 324  856]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90      2232\n",
      "           1       0.84      0.73      0.78      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.85      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8587338804220399\n",
      "pre:  0.8441814595660749\n",
      "rec:  0.7254237288135593\n",
      "ma F1:  0.8381031322416722\n",
      "mi F1:  0.8587338804220398\n",
      "we F1:  0.8559221364171621\n",
      "update!  Acc:  0.8968347010550997\n",
      "Epoch:  5675.513828992844  fold:  6  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.1600031554698944\n",
      "Loss:  0.16649921238422394\n",
      "Loss:  0.14359164237976074\n",
      "0 **********\n",
      "Epoch:  92.67919301986694  fold:  7  kers:  128\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.11202424019575119\n",
      "Loss:  0.12336113303899765\n",
      "Loss:  0.09249255806207657\n",
      "1 **********\n",
      "Epoch:  173.09019017219543  fold:  7  kers:  128\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.11289823055267334\n",
      "Loss:  0.10637495666742325\n",
      "Loss:  0.11117910593748093\n",
      "2 **********\n",
      "Epoch:  253.51814246177673  fold:  7  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.7863808870315552\n",
      "Eval Loss:  0.11821632832288742\n",
      "Eval Loss:  2.319395065307617\n",
      "[[1778  349]\n",
      " [ 727  577]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      2127\n",
      "           1       0.62      0.44      0.52      1304\n",
      "\n",
      "    accuracy                           0.69      3431\n",
      "   macro avg       0.67      0.64      0.64      3431\n",
      "weighted avg       0.68      0.69      0.67      3431\n",
      "\n",
      "acc:  0.6863888079277178\n",
      "pre:  0.6231101511879049\n",
      "rec:  0.4424846625766871\n",
      "ma F1:  0.6425958626671933\n",
      "mi F1:  0.6863888079277178\n",
      "we F1:  0.6726055162470532\n",
      "update!  Acc:  0.6863888079277178\n",
      "Eval Loss:  0.3169267177581787\n",
      "Eval Loss:  0.3270610272884369\n",
      "Eval Loss:  0.46521806716918945\n",
      "Eval Loss:  0.4225039780139923\n",
      "Eval Loss:  0.44566190242767334\n",
      "Eval Loss:  0.48240843415260315\n",
      "Eval Loss:  0.4654504060745239\n",
      "Eval Loss:  0.34239041805267334\n",
      "Eval Loss:  0.41792628169059753\n",
      "Eval Loss:  0.4865057170391083\n",
      "Eval Loss:  0.4170037806034088\n",
      "Eval Loss:  0.3403562009334564\n",
      "Eval Loss:  0.33092695474624634\n",
      "Eval Loss:  0.45108309388160706\n",
      "Eval Loss:  0.29965853691101074\n",
      "Eval Loss:  0.42771729826927185\n",
      "Eval Loss:  0.431332528591156\n",
      "Eval Loss:  0.42277008295059204\n",
      "Eval Loss:  0.49313443899154663\n",
      "Eval Loss:  0.35606247186660767\n",
      "Eval Loss:  0.38089004158973694\n",
      "Eval Loss:  0.33942151069641113\n",
      "Eval Loss:  0.4070133566856384\n",
      "Eval Loss:  0.4230650067329407\n",
      "Eval Loss:  0.45910608768463135\n",
      "Eval Loss:  0.4207596778869629\n",
      "Eval Loss:  0.45805397629737854\n",
      "Eval Loss:  0.33185747265815735\n",
      "[[16006  2031]\n",
      " [ 2994  8429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86     18037\n",
      "           1       0.81      0.74      0.77     11423\n",
      "\n",
      "    accuracy                           0.83     29460\n",
      "   macro avg       0.82      0.81      0.82     29460\n",
      "weighted avg       0.83      0.83      0.83     29460\n",
      "\n",
      "acc:  0.8294297352342159\n",
      "pre:  0.805831739961759\n",
      "rec:  0.7378972248971374\n",
      "ma F1:  0.8173472788470733\n",
      "mi F1:  0.8294297352342158\n",
      "we F1:  0.827894113550064\n",
      "29460 461\n",
      "Loss:  0.07763254642486572\n",
      "Loss:  0.09246065467596054\n",
      "Loss:  0.10722728073596954\n",
      "3 **********\n",
      "Epoch:  377.3280997276306  fold:  7  kers:  128\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.09196597337722778\n",
      "Loss:  0.10236076265573502\n",
      "Loss:  0.07217580080032349\n",
      "4 **********\n",
      "Epoch:  457.7281265258789  fold:  7  kers:  128\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.11401325464248657\n",
      "Loss:  0.06585115194320679\n",
      "Loss:  0.08106604218482971\n",
      "5 **********\n",
      "Epoch:  538.1560778617859  fold:  7  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.7622917890548706\n",
      "Eval Loss:  0.085560142993927\n",
      "Eval Loss:  2.85300612449646\n",
      "[[1957  170]\n",
      " [ 839  465]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.80      2127\n",
      "           1       0.73      0.36      0.48      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.72      0.64      0.64      3431\n",
      "weighted avg       0.71      0.71      0.68      3431\n",
      "\n",
      "acc:  0.7059166423783153\n",
      "pre:  0.7322834645669292\n",
      "rec:  0.3565950920245399\n",
      "ma F1:  0.6373361735659534\n",
      "mi F1:  0.7059166423783153\n",
      "we F1:  0.6751657485207617\n",
      "update!  Acc:  0.7059166423783153\n",
      "Eval Loss:  0.29703718423843384\n",
      "Eval Loss:  0.2826882302761078\n",
      "Eval Loss:  0.4492526650428772\n",
      "Eval Loss:  0.4001796841621399\n",
      "Eval Loss:  0.4529263973236084\n",
      "Eval Loss:  0.4240659475326538\n",
      "Eval Loss:  0.42581260204315186\n",
      "Eval Loss:  0.36199480295181274\n",
      "Eval Loss:  0.3956663906574249\n",
      "Eval Loss:  0.4672054946422577\n",
      "Eval Loss:  0.40541595220565796\n",
      "Eval Loss:  0.27093321084976196\n",
      "Eval Loss:  0.27497154474258423\n",
      "Eval Loss:  0.4065200686454773\n",
      "Eval Loss:  0.25082454085350037\n",
      "Eval Loss:  0.4247359037399292\n",
      "Eval Loss:  0.3578850030899048\n",
      "Eval Loss:  0.38953956961631775\n",
      "Eval Loss:  0.4886244535446167\n",
      "Eval Loss:  0.29143550992012024\n",
      "Eval Loss:  0.3664850890636444\n",
      "Eval Loss:  0.31415635347366333\n",
      "Eval Loss:  0.3466629981994629\n",
      "Eval Loss:  0.380719929933548\n",
      "Eval Loss:  0.4278770983219147\n",
      "Eval Loss:  0.3926870822906494\n",
      "Eval Loss:  0.4058254659175873\n",
      "Eval Loss:  0.3390195071697235\n",
      "[[16911  1126]\n",
      " [ 3258  8165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     18037\n",
      "           1       0.88      0.71      0.79     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.86      0.83      0.84     29460\n",
      "weighted avg       0.85      0.85      0.85     29460\n",
      "\n",
      "acc:  0.8511880515953836\n",
      "pre:  0.8788074480680228\n",
      "rec:  0.7147859581546003\n",
      "ma F1:  0.8368046632715083\n",
      "mi F1:  0.8511880515953836\n",
      "we F1:  0.8476818334492022\n",
      "29460 461\n",
      "Loss:  0.05950290709733963\n",
      "Loss:  0.07377160340547562\n",
      "Loss:  0.05522763356566429\n",
      "6 **********\n",
      "Epoch:  661.9002113342285  fold:  7  kers:  128\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.09520392119884491\n",
      "Loss:  0.07737811654806137\n",
      "Loss:  0.05345834791660309\n",
      "7 **********\n",
      "Epoch:  742.3311557769775  fold:  7  kers:  128\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.11386298388242722\n",
      "Loss:  0.10334570705890656\n",
      "Loss:  0.0769452452659607\n",
      "8 **********\n",
      "Epoch:  822.7750647068024  fold:  7  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.99738609790802\n",
      "Eval Loss:  0.08343619853258133\n",
      "Eval Loss:  3.1806459426879883\n",
      "[[2071   56]\n",
      " [ 938  366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81      2127\n",
      "           1       0.87      0.28      0.42      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.78      0.63      0.62      3431\n",
      "weighted avg       0.76      0.71      0.66      3431\n",
      "\n",
      "acc:  0.7102885456135237\n",
      "pre:  0.8672985781990521\n",
      "rec:  0.28067484662576686\n",
      "ma F1:  0.6152830721636832\n",
      "mi F1:  0.7102885456135237\n",
      "we F1:  0.6611420191720226\n",
      "update!  Acc:  0.7102885456135237\n",
      "Eval Loss:  0.2564280927181244\n",
      "Eval Loss:  0.2964300513267517\n",
      "Eval Loss:  0.4392785429954529\n",
      "Eval Loss:  0.39833617210388184\n",
      "Eval Loss:  0.4748780131340027\n",
      "Eval Loss:  0.393911749124527\n",
      "Eval Loss:  0.3702719807624817\n",
      "Eval Loss:  0.36012303829193115\n",
      "Eval Loss:  0.37555962800979614\n",
      "Eval Loss:  0.4797719120979309\n",
      "Eval Loss:  0.37963733077049255\n",
      "Eval Loss:  0.2663288414478302\n",
      "Eval Loss:  0.29939866065979004\n",
      "Eval Loss:  0.4222874343395233\n",
      "Eval Loss:  0.2373652160167694\n",
      "Eval Loss:  0.38836780190467834\n",
      "Eval Loss:  0.35962778329849243\n",
      "Eval Loss:  0.38603174686431885\n",
      "Eval Loss:  0.502421498298645\n",
      "Eval Loss:  0.28214019536972046\n",
      "Eval Loss:  0.3575577139854431\n",
      "Eval Loss:  0.31015801429748535\n",
      "Eval Loss:  0.3262816369533539\n",
      "Eval Loss:  0.3757697641849518\n",
      "Eval Loss:  0.4646885395050049\n",
      "Eval Loss:  0.38303840160369873\n",
      "Eval Loss:  0.3949415385723114\n",
      "Eval Loss:  0.35069170594215393\n",
      "[[17383   654]\n",
      " [ 3815  7608]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89     18037\n",
      "           1       0.92      0.67      0.77     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.87      0.81      0.83     29460\n",
      "weighted avg       0.86      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8483027834351663\n",
      "pre:  0.9208424110384895\n",
      "rec:  0.6660246870349296\n",
      "ma F1:  0.8295354716872299\n",
      "mi F1:  0.8483027834351663\n",
      "we F1:  0.8422338859993376\n",
      "29460 461\n",
      "Loss:  0.07793422043323517\n",
      "Loss:  0.05048513412475586\n",
      "Loss:  0.07846393436193466\n",
      "9 **********\n",
      "Epoch:  946.3745846748352  fold:  7  kers:  128\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.07735215872526169\n",
      "Loss:  0.08203970640897751\n",
      "Loss:  0.06904369592666626\n",
      "10 **********\n",
      "Epoch:  1026.8234803676605  fold:  7  kers:  128\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.1213972195982933\n",
      "Loss:  0.11085271090269089\n",
      "Loss:  0.0720832571387291\n",
      "11 **********\n",
      "Epoch:  1107.283347606659  fold:  7  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  1.050131916999817\n",
      "Eval Loss:  0.08542522042989731\n",
      "Eval Loss:  2.9511752128601074\n",
      "[[2041   86]\n",
      " [ 843  461]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.81      2127\n",
      "           1       0.84      0.35      0.50      1304\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.78      0.66      0.66      3431\n",
      "weighted avg       0.76      0.73      0.69      3431\n",
      "\n",
      "acc:  0.7292334596327601\n",
      "pre:  0.8427787934186471\n",
      "rec:  0.3535276073619632\n",
      "ma F1:  0.6563584964509738\n",
      "mi F1:  0.7292334596327601\n",
      "we F1:  0.6943180500576891\n",
      "update!  Acc:  0.7292334596327601\n",
      "Eval Loss:  0.21915900707244873\n",
      "Eval Loss:  0.2627101540565491\n",
      "Eval Loss:  0.35804712772369385\n",
      "Eval Loss:  0.35432004928588867\n",
      "Eval Loss:  0.3728368580341339\n",
      "Eval Loss:  0.3318079710006714\n",
      "Eval Loss:  0.3048967123031616\n",
      "Eval Loss:  0.3024199306964874\n",
      "Eval Loss:  0.3262690603733063\n",
      "Eval Loss:  0.40118834376335144\n",
      "Eval Loss:  0.3320891559123993\n",
      "Eval Loss:  0.20542223751544952\n",
      "Eval Loss:  0.2526888847351074\n",
      "Eval Loss:  0.3255962133407593\n",
      "Eval Loss:  0.18790173530578613\n",
      "Eval Loss:  0.3223140835762024\n",
      "Eval Loss:  0.30923715233802795\n",
      "Eval Loss:  0.3402951657772064\n",
      "Eval Loss:  0.3955442011356354\n",
      "Eval Loss:  0.2572883367538452\n",
      "Eval Loss:  0.31125783920288086\n",
      "Eval Loss:  0.29813152551651\n",
      "Eval Loss:  0.29889726638793945\n",
      "Eval Loss:  0.29109275341033936\n",
      "Eval Loss:  0.38379138708114624\n",
      "Eval Loss:  0.315477192401886\n",
      "Eval Loss:  0.3399544358253479\n",
      "Eval Loss:  0.28643375635147095\n",
      "[[17233   804]\n",
      " [ 2964  8459]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     18037\n",
      "           1       0.91      0.74      0.82     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.85      0.86     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8720977596741344\n",
      "pre:  0.9132030659613516\n",
      "rec:  0.7405235052087893\n",
      "ma F1:  0.8596483959502755\n",
      "mi F1:  0.8720977596741345\n",
      "we F1:  0.8690329516454661\n",
      "29460 461\n",
      "Loss:  0.0630766972899437\n",
      "Loss:  0.05777797847986221\n",
      "Loss:  0.11304815858602524\n",
      "12 **********\n",
      "Epoch:  1230.9486916065216  fold:  7  kers:  128\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.06327161192893982\n",
      "Loss:  0.08384011685848236\n",
      "Loss:  0.057372625917196274\n",
      "13 **********\n",
      "Epoch:  1311.3806328773499  fold:  7  kers:  128\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.09459332376718521\n",
      "Loss:  0.10341955721378326\n",
      "Loss:  0.061815761029720306\n",
      "14 **********\n",
      "Epoch:  1391.8534648418427  fold:  7  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.9006819725036621\n",
      "Eval Loss:  0.07007691264152527\n",
      "Eval Loss:  2.4151222705841064\n",
      "[[2044   83]\n",
      " [ 776  528]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.83      2127\n",
      "           1       0.86      0.40      0.55      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.79      0.68      0.69      3431\n",
      "weighted avg       0.78      0.75      0.72      3431\n",
      "\n",
      "acc:  0.7496356747303993\n",
      "pre:  0.8641571194762684\n",
      "rec:  0.4049079754601227\n",
      "ma F1:  0.6888977205374357\n",
      "mi F1:  0.7496356747303993\n",
      "we F1:  0.7218708975168611\n",
      "update!  Acc:  0.7496356747303993\n",
      "Eval Loss:  0.193213552236557\n",
      "Eval Loss:  0.2517140805721283\n",
      "Eval Loss:  0.37380897998809814\n",
      "Eval Loss:  0.3420907258987427\n",
      "Eval Loss:  0.34733811020851135\n",
      "Eval Loss:  0.33454152941703796\n",
      "Eval Loss:  0.30237096548080444\n",
      "Eval Loss:  0.2958751916885376\n",
      "Eval Loss:  0.3210274875164032\n",
      "Eval Loss:  0.3778097331523895\n",
      "Eval Loss:  0.32144632935523987\n",
      "Eval Loss:  0.19043508172035217\n",
      "Eval Loss:  0.2574937641620636\n",
      "Eval Loss:  0.3194364607334137\n",
      "Eval Loss:  0.1878073364496231\n",
      "Eval Loss:  0.3298499584197998\n",
      "Eval Loss:  0.30668333172798157\n",
      "Eval Loss:  0.3183881938457489\n",
      "Eval Loss:  0.3790300190448761\n",
      "Eval Loss:  0.24405239522457123\n",
      "Eval Loss:  0.265335351228714\n",
      "Eval Loss:  0.2673088014125824\n",
      "Eval Loss:  0.28418055176734924\n",
      "Eval Loss:  0.2904227674007416\n",
      "Eval Loss:  0.364818274974823\n",
      "Eval Loss:  0.33599597215652466\n",
      "Eval Loss:  0.2647220492362976\n",
      "Eval Loss:  0.2845124900341034\n",
      "[[17338   699]\n",
      " [ 2898  8525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18037\n",
      "           1       0.92      0.75      0.83     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.85      0.87     29460\n",
      "weighted avg       0.88      0.88      0.87     29460\n",
      "\n",
      "acc:  0.8779022403258656\n",
      "pre:  0.9242194275802255\n",
      "rec:  0.7463013218944236\n",
      "ma F1:  0.8659015626192563\n",
      "mi F1:  0.8779022403258657\n",
      "we F1:  0.8749078581317394\n",
      "29460 461\n",
      "Loss:  0.0698193833231926\n",
      "Loss:  0.04654008522629738\n",
      "Loss:  0.0617702454328537\n",
      "15 **********\n",
      "Epoch:  1515.4749262332916  fold:  7  kers:  128\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.06049000844359398\n",
      "Loss:  0.07393885403871536\n",
      "Loss:  0.0651618167757988\n",
      "16 **********\n",
      "Epoch:  1595.9158437252045  fold:  7  kers:  128\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.10828991234302521\n",
      "Loss:  0.07604557275772095\n",
      "Loss:  0.06432624906301498\n",
      "17 **********\n",
      "Epoch:  1676.3906705379486  fold:  7  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.701839029788971\n",
      "Eval Loss:  0.13466320931911469\n",
      "Eval Loss:  1.7565456628799438\n",
      "[[1929  198]\n",
      " [ 576  728]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83      2127\n",
      "           1       0.79      0.56      0.65      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.73      0.74      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7744097930632469\n",
      "pre:  0.7861771058315334\n",
      "rec:  0.558282208588957\n",
      "ma F1:  0.7429081763052116\n",
      "mi F1:  0.7744097930632469\n",
      "we F1:  0.7644950460736238\n",
      "update!  Acc:  0.7744097930632469\n",
      "Eval Loss:  0.1842191070318222\n",
      "Eval Loss:  0.22094717621803284\n",
      "Eval Loss:  0.24304427206516266\n",
      "Eval Loss:  0.291755348443985\n",
      "Eval Loss:  0.25691524147987366\n",
      "Eval Loss:  0.2260768562555313\n",
      "Eval Loss:  0.24866776168346405\n",
      "Eval Loss:  0.24008193612098694\n",
      "Eval Loss:  0.26321104168891907\n",
      "Eval Loss:  0.3002951443195343\n",
      "Eval Loss:  0.3056126534938812\n",
      "Eval Loss:  0.15261487662792206\n",
      "Eval Loss:  0.2146901786327362\n",
      "Eval Loss:  0.23682901263237\n",
      "Eval Loss:  0.16961488127708435\n",
      "Eval Loss:  0.3052618205547333\n",
      "Eval Loss:  0.259199321269989\n",
      "Eval Loss:  0.3118605613708496\n",
      "Eval Loss:  0.27668583393096924\n",
      "Eval Loss:  0.20922867953777313\n",
      "Eval Loss:  0.25852251052856445\n",
      "Eval Loss:  0.2615545988082886\n",
      "Eval Loss:  0.25405198335647583\n",
      "Eval Loss:  0.25725027918815613\n",
      "Eval Loss:  0.27478212118148804\n",
      "Eval Loss:  0.28331777453422546\n",
      "Eval Loss:  0.24194884300231934\n",
      "Eval Loss:  0.21584196388721466\n",
      "[[16586  1451]\n",
      " [ 1452  9971]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     18037\n",
      "           1       0.87      0.87      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9014596062457569\n",
      "pre:  0.8729644545613728\n",
      "rec:  0.8728880329160466\n",
      "ma F1:  0.8962275007974285\n",
      "mi F1:  0.9014596062457569\n",
      "we F1:  0.9014588153001108\n",
      "29460 461\n",
      "Loss:  0.05759962275624275\n",
      "Loss:  0.07590346038341522\n",
      "Loss:  0.04587359353899956\n",
      "18 **********\n",
      "Epoch:  1800.0131289958954  fold:  7  kers:  128\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.08530852943658829\n",
      "Loss:  0.05393916368484497\n",
      "Loss:  0.05396166816353798\n",
      "19 **********\n",
      "Epoch:  1883.0600786209106  fold:  7  kers:  128\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.08357113599777222\n",
      "Loss:  0.06494766473770142\n",
      "Loss:  0.0610884465277195\n",
      "20 **********\n",
      "Epoch:  1963.5548512935638  fold:  7  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.9025442600250244\n",
      "Eval Loss:  0.05337037146091461\n",
      "Eval Loss:  2.49377179145813\n",
      "[[2047   80]\n",
      " [ 810  494]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      2127\n",
      "           1       0.86      0.38      0.53      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.79      0.67      0.67      3431\n",
      "weighted avg       0.77      0.74      0.71      3431\n",
      "\n",
      "acc:  0.7406004080443019\n",
      "pre:  0.8606271777003485\n",
      "rec:  0.37883435582822084\n",
      "ma F1:  0.6737600791115168\n",
      "mi F1:  0.7406004080443019\n",
      "we F1:  0.7091815798917371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.15971161425113678\n",
      "Eval Loss:  0.23145242035388947\n",
      "Eval Loss:  0.28101012110710144\n",
      "Eval Loss:  0.3443702161312103\n",
      "Eval Loss:  0.29869207739830017\n",
      "Eval Loss:  0.24524059891700745\n",
      "Eval Loss:  0.2541818618774414\n",
      "Eval Loss:  0.2555256485939026\n",
      "Eval Loss:  0.2712549865245819\n",
      "Eval Loss:  0.3178274631500244\n",
      "Eval Loss:  0.2820485532283783\n",
      "Eval Loss:  0.19244544208049774\n",
      "Eval Loss:  0.23455727100372314\n",
      "Eval Loss:  0.22661273181438446\n",
      "Eval Loss:  0.1691933274269104\n",
      "Eval Loss:  0.2679519057273865\n",
      "Eval Loss:  0.2640575170516968\n",
      "Eval Loss:  0.2878912687301636\n",
      "Eval Loss:  0.33044153451919556\n",
      "Eval Loss:  0.2413550168275833\n",
      "Eval Loss:  0.2516495883464813\n",
      "Eval Loss:  0.23142579197883606\n",
      "Eval Loss:  0.2391689121723175\n",
      "Eval Loss:  0.26375454664230347\n",
      "Eval Loss:  0.3126119077205658\n",
      "Eval Loss:  0.343242883682251\n",
      "Eval Loss:  0.25987595319747925\n",
      "Eval Loss:  0.2575782239437103\n",
      "[[17276   761]\n",
      " [ 2340  9083]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18037\n",
      "           1       0.92      0.80      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8947386286490157\n",
      "pre:  0.9226940268183665\n",
      "rec:  0.7951501356911495\n",
      "ma F1:  0.8859149614791944\n",
      "mi F1:  0.8947386286490157\n",
      "we F1:  0.8930380830050333\n",
      "29460 461\n",
      "Loss:  0.05545646324753761\n",
      "Loss:  0.09068344533443451\n",
      "Loss:  0.05689267814159393\n",
      "21 **********\n",
      "Epoch:  2087.2062332630157  fold:  7  kers:  128\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.06951521337032318\n",
      "Loss:  0.040372904390096664\n",
      "Loss:  0.06227830424904823\n",
      "22 **********\n",
      "Epoch:  2167.7159667015076  fold:  7  kers:  128\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.049693651497364044\n",
      "Loss:  0.056860920041799545\n",
      "Loss:  0.05147528648376465\n",
      "23 **********\n",
      "Epoch:  2248.2456464767456  fold:  7  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.8682026863098145\n",
      "Eval Loss:  0.06733088940382004\n",
      "Eval Loss:  2.4791817665100098\n",
      "[[2061   66]\n",
      " [ 793  511]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.83      2127\n",
      "           1       0.89      0.39      0.54      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.80      0.68      0.69      3431\n",
      "weighted avg       0.78      0.75      0.72      3431\n",
      "\n",
      "acc:  0.7496356747303993\n",
      "pre:  0.8856152512998267\n",
      "rec:  0.3918711656441718\n",
      "ma F1:  0.6854363433786294\n",
      "mi F1:  0.7496356747303993\n",
      "we F1:  0.7195241173802466\n",
      "Eval Loss:  0.16192786395549774\n",
      "Eval Loss:  0.22820395231246948\n",
      "Eval Loss:  0.2406265139579773\n",
      "Eval Loss:  0.3114749491214752\n",
      "Eval Loss:  0.30631086230278015\n",
      "Eval Loss:  0.24516117572784424\n",
      "Eval Loss:  0.2425551414489746\n",
      "Eval Loss:  0.24125774204730988\n",
      "Eval Loss:  0.2388150542974472\n",
      "Eval Loss:  0.30622246861457825\n",
      "Eval Loss:  0.285726934671402\n",
      "Eval Loss:  0.15904481709003448\n",
      "Eval Loss:  0.23621027171611786\n",
      "Eval Loss:  0.2318863570690155\n",
      "Eval Loss:  0.1490040421485901\n",
      "Eval Loss:  0.25307533144950867\n",
      "Eval Loss:  0.2717161774635315\n",
      "Eval Loss:  0.2896995544433594\n",
      "Eval Loss:  0.3118854761123657\n",
      "Eval Loss:  0.2063302993774414\n",
      "Eval Loss:  0.2521980404853821\n",
      "Eval Loss:  0.20413534343242645\n",
      "Eval Loss:  0.2181626409292221\n",
      "Eval Loss:  0.23762038350105286\n",
      "Eval Loss:  0.3151795566082001\n",
      "Eval Loss:  0.2545529305934906\n",
      "Eval Loss:  0.2576446533203125\n",
      "Eval Loss:  0.22603052854537964\n",
      "[[17219   818]\n",
      " [ 2098  9325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18037\n",
      "           1       0.92      0.82      0.86     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.91      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9010183299389002\n",
      "pre:  0.9193532485457951\n",
      "rec:  0.816335463538475\n",
      "ma F1:  0.8933616180427062\n",
      "mi F1:  0.9010183299389002\n",
      "we F1:  0.899776805841215\n",
      "29460 461\n",
      "Loss:  0.07081419229507446\n",
      "Loss:  0.0833185538649559\n",
      "Loss:  0.057699959725141525\n",
      "24 **********\n",
      "Epoch:  2371.7982914447784  fold:  7  kers:  128\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.054559625685214996\n",
      "Loss:  0.07019435614347458\n",
      "Loss:  0.05624457076191902\n",
      "25 **********\n",
      "Epoch:  2452.255166053772  fold:  7  kers:  128\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.04204173758625984\n",
      "Loss:  0.06604467332363129\n",
      "Loss:  0.07452330738306046\n",
      "26 **********\n",
      "Epoch:  2532.718024969101  fold:  7  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.6408654451370239\n",
      "Eval Loss:  0.06351334601640701\n",
      "Eval Loss:  1.762596607208252\n",
      "[[1988  139]\n",
      " [ 608  696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84      2127\n",
      "           1       0.83      0.53      0.65      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.80      0.73      0.75      3431\n",
      "weighted avg       0.79      0.78      0.77      3431\n",
      "\n",
      "acc:  0.782279218886622\n",
      "pre:  0.8335329341317366\n",
      "rec:  0.5337423312883436\n",
      "ma F1:  0.7463046017237125\n",
      "mi F1:  0.782279218886622\n",
      "we F1:  0.7692203214799621\n",
      "update!  Acc:  0.782279218886622\n",
      "Eval Loss:  0.17866647243499756\n",
      "Eval Loss:  0.20040172338485718\n",
      "Eval Loss:  0.19777117669582367\n",
      "Eval Loss:  0.273388147354126\n",
      "Eval Loss:  0.2427183985710144\n",
      "Eval Loss:  0.21563389897346497\n",
      "Eval Loss:  0.25414490699768066\n",
      "Eval Loss:  0.24033775925636292\n",
      "Eval Loss:  0.2402537316083908\n",
      "Eval Loss:  0.2718406319618225\n",
      "Eval Loss:  0.26539522409439087\n",
      "Eval Loss:  0.15662655234336853\n",
      "Eval Loss:  0.20792889595031738\n",
      "Eval Loss:  0.21270021796226501\n",
      "Eval Loss:  0.1516118049621582\n",
      "Eval Loss:  0.27845656871795654\n",
      "Eval Loss:  0.235458642244339\n",
      "Eval Loss:  0.2990072965621948\n",
      "Eval Loss:  0.28367918729782104\n",
      "Eval Loss:  0.18523941934108734\n",
      "Eval Loss:  0.25328871607780457\n",
      "Eval Loss:  0.21842019259929657\n",
      "Eval Loss:  0.2098761945962906\n",
      "Eval Loss:  0.23391053080558777\n",
      "Eval Loss:  0.2935010492801666\n",
      "Eval Loss:  0.27854835987091064\n",
      "Eval Loss:  0.23025882244110107\n",
      "Eval Loss:  0.23248866200447083\n",
      "[[16861  1176]\n",
      " [ 1467  9956]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18037\n",
      "           1       0.89      0.87      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9102851323828921\n",
      "pre:  0.8943586058210564\n",
      "rec:  0.8715748927602206\n",
      "ma F1:  0.9050699996888001\n",
      "mi F1:  0.9102851323828921\n",
      "we F1:  0.9100653490933944\n",
      "29460 461\n",
      "Loss:  0.08313995599746704\n",
      "Loss:  0.040789999067783356\n",
      "Loss:  0.04876052215695381\n",
      "27 **********\n",
      "Epoch:  2656.373395204544  fold:  7  kers:  128\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.06503801047801971\n",
      "Loss:  0.03402078151702881\n",
      "Loss:  0.0796743631362915\n",
      "28 **********\n",
      "Epoch:  2736.850216627121  fold:  7  kers:  128\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.05308343470096588\n",
      "Loss:  0.0522678941488266\n",
      "Loss:  0.06290408223867416\n",
      "29 **********\n",
      "Epoch:  2817.3400037288666  fold:  7  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.7142219543457031\n",
      "Eval Loss:  0.04646563157439232\n",
      "Eval Loss:  2.2112386226654053\n",
      "[[2017  110]\n",
      " [ 702  602]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83      2127\n",
      "           1       0.85      0.46      0.60      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.79      0.70      0.71      3431\n",
      "weighted avg       0.78      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7633343048673856\n",
      "pre:  0.8455056179775281\n",
      "rec:  0.4616564417177914\n",
      "ma F1:  0.7148306736369054\n",
      "mi F1:  0.7633343048673855\n",
      "we F1:  0.7430416195751988\n",
      "Eval Loss:  0.16522668302059174\n",
      "Eval Loss:  0.19318144023418427\n",
      "Eval Loss:  0.19895979762077332\n",
      "Eval Loss:  0.2875522971153259\n",
      "Eval Loss:  0.2317868024110794\n",
      "Eval Loss:  0.2074703872203827\n",
      "Eval Loss:  0.2574526071548462\n",
      "Eval Loss:  0.21030066907405853\n",
      "Eval Loss:  0.24415232241153717\n",
      "Eval Loss:  0.28574419021606445\n",
      "Eval Loss:  0.26503121852874756\n",
      "Eval Loss:  0.14424967765808105\n",
      "Eval Loss:  0.2166784405708313\n",
      "Eval Loss:  0.19734297692775726\n",
      "Eval Loss:  0.1438460499048233\n",
      "Eval Loss:  0.2578955590724945\n",
      "Eval Loss:  0.23233748972415924\n",
      "Eval Loss:  0.23456750810146332\n",
      "Eval Loss:  0.2862418293952942\n",
      "Eval Loss:  0.1714702993631363\n",
      "Eval Loss:  0.23343157768249512\n",
      "Eval Loss:  0.19903044402599335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19461016356945038\n",
      "Eval Loss:  0.22997881472110748\n",
      "Eval Loss:  0.2732164263725281\n",
      "Eval Loss:  0.2643114924430847\n",
      "Eval Loss:  0.22233211994171143\n",
      "Eval Loss:  0.22681252658367157\n",
      "[[17174   863]\n",
      " [ 1684  9739]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18037\n",
      "           1       0.92      0.85      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9135437881873727\n",
      "pre:  0.918600264101113\n",
      "rec:  0.8525781318392717\n",
      "ma F1:  0.9076624694523019\n",
      "mi F1:  0.9135437881873727\n",
      "we F1:  0.912894351377488\n",
      "29460 461\n",
      "Loss:  0.057420212775468826\n",
      "Loss:  0.07079222798347473\n",
      "Loss:  0.06017174571752548\n",
      "30 **********\n",
      "Epoch:  2941.072168827057  fold:  7  kers:  128\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.06856755912303925\n",
      "Loss:  0.037045273929834366\n",
      "Loss:  0.04297707974910736\n",
      "31 **********\n",
      "Epoch:  3021.5440039634705  fold:  7  kers:  128\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.03670024871826172\n",
      "Loss:  0.0568353496491909\n",
      "Loss:  0.05107160285115242\n",
      "32 **********\n",
      "Epoch:  3102.012845993042  fold:  7  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.5876776576042175\n",
      "Eval Loss:  0.13783584535121918\n",
      "Eval Loss:  1.5005083084106445\n",
      "[[1954  173]\n",
      " [ 525  779]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85      2127\n",
      "           1       0.82      0.60      0.69      1304\n",
      "\n",
      "    accuracy                           0.80      3431\n",
      "   macro avg       0.80      0.76      0.77      3431\n",
      "weighted avg       0.80      0.80      0.79      3431\n",
      "\n",
      "acc:  0.7965607694549693\n",
      "pre:  0.8182773109243697\n",
      "rec:  0.5973926380368099\n",
      "ma F1:  0.7695306846142713\n",
      "mi F1:  0.7965607694549693\n",
      "we F1:  0.788463246166522\n",
      "update!  Acc:  0.7965607694549693\n",
      "Eval Loss:  0.1730126142501831\n",
      "Eval Loss:  0.18310168385505676\n",
      "Eval Loss:  0.19413679838180542\n",
      "Eval Loss:  0.24831528961658478\n",
      "Eval Loss:  0.23364248871803284\n",
      "Eval Loss:  0.19950804114341736\n",
      "Eval Loss:  0.22418011724948883\n",
      "Eval Loss:  0.2025928795337677\n",
      "Eval Loss:  0.2340594381093979\n",
      "Eval Loss:  0.25170499086380005\n",
      "Eval Loss:  0.2614937126636505\n",
      "Eval Loss:  0.12159901857376099\n",
      "Eval Loss:  0.20554044842720032\n",
      "Eval Loss:  0.20385923981666565\n",
      "Eval Loss:  0.15091213583946228\n",
      "Eval Loss:  0.24249517917633057\n",
      "Eval Loss:  0.2370971143245697\n",
      "Eval Loss:  0.26393771171569824\n",
      "Eval Loss:  0.23778559267520905\n",
      "Eval Loss:  0.17623892426490784\n",
      "Eval Loss:  0.23570206761360168\n",
      "Eval Loss:  0.19510044157505035\n",
      "Eval Loss:  0.16899527609348297\n",
      "Eval Loss:  0.2691948711872101\n",
      "Eval Loss:  0.27161866426467896\n",
      "Eval Loss:  0.24213513731956482\n",
      "Eval Loss:  0.21495066583156586\n",
      "Eval Loss:  0.19631871581077576\n",
      "[[16818  1219]\n",
      " [ 1233 10190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18037\n",
      "           1       0.89      0.89      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9167684996605567\n",
      "pre:  0.8931545271277062\n",
      "rec:  0.8920598791911056\n",
      "ma F1:  0.9123309221389371\n",
      "mi F1:  0.9167684996605567\n",
      "we F1:  0.9167591263827499\n",
      "29460 461\n",
      "Loss:  0.07341334223747253\n",
      "Loss:  0.0760834813117981\n",
      "Loss:  0.05567631497979164\n",
      "33 **********\n",
      "Epoch:  3225.7629635334015  fold:  7  kers:  128\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.0726795345544815\n",
      "Loss:  0.025875240564346313\n",
      "Loss:  0.03273095563054085\n",
      "34 **********\n",
      "Epoch:  3306.226819753647  fold:  7  kers:  128\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.06246977671980858\n",
      "Loss:  0.041517842561006546\n",
      "Loss:  0.07122581452131271\n",
      "35 **********\n",
      "Epoch:  3386.718601465225  fold:  7  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.5450199246406555\n",
      "Eval Loss:  0.1605626940727234\n",
      "Eval Loss:  1.7675442695617676\n",
      "[[1896  231]\n",
      " [ 534  770]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      2127\n",
      "           1       0.77      0.59      0.67      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.77      0.74      0.75      3431\n",
      "weighted avg       0.78      0.78      0.77      3431\n",
      "\n",
      "acc:  0.7770329350043719\n",
      "pre:  0.7692307692307693\n",
      "rec:  0.5904907975460123\n",
      "ma F1:  0.7501195986056588\n",
      "mi F1:  0.7770329350043719\n",
      "we F1:  0.7697907139308282\n",
      "Eval Loss:  0.18723201751708984\n",
      "Eval Loss:  0.1815551519393921\n",
      "Eval Loss:  0.20775210857391357\n",
      "Eval Loss:  0.26451829075813293\n",
      "Eval Loss:  0.18894325196743011\n",
      "Eval Loss:  0.1799640655517578\n",
      "Eval Loss:  0.24980556964874268\n",
      "Eval Loss:  0.1933659464120865\n",
      "Eval Loss:  0.23950369656085968\n",
      "Eval Loss:  0.2626855969429016\n",
      "Eval Loss:  0.28446656465530396\n",
      "Eval Loss:  0.12716415524482727\n",
      "Eval Loss:  0.17595389485359192\n",
      "Eval Loss:  0.19342565536499023\n",
      "Eval Loss:  0.16718600690364838\n",
      "Eval Loss:  0.27727392315864563\n",
      "Eval Loss:  0.21809475123882294\n",
      "Eval Loss:  0.24963019788265228\n",
      "Eval Loss:  0.23339128494262695\n",
      "Eval Loss:  0.16396203637123108\n",
      "Eval Loss:  0.2499508261680603\n",
      "Eval Loss:  0.21346542239189148\n",
      "Eval Loss:  0.185862198472023\n",
      "Eval Loss:  0.2279464155435562\n",
      "Eval Loss:  0.2474265843629837\n",
      "Eval Loss:  0.26396098732948303\n",
      "Eval Loss:  0.2062389850616455\n",
      "Eval Loss:  0.2025633454322815\n",
      "[[16617  1420]\n",
      " [  990 10433]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     18037\n",
      "           1       0.88      0.91      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.92      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.918194161575017\n",
      "pre:  0.8801991057116342\n",
      "rec:  0.9133327497154863\n",
      "ma F1:  0.9144234051616846\n",
      "mi F1:  0.918194161575017\n",
      "we F1:  0.9184563584148832\n",
      "29460 461\n",
      "Loss:  0.04061770811676979\n",
      "Loss:  0.06386043131351471\n",
      "Loss:  0.08125399798154831\n",
      "36 **********\n",
      "Epoch:  3511.219710111618  fold:  7  kers:  128\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.08614923059940338\n",
      "Loss:  0.043533992022275925\n",
      "Loss:  0.05781644210219383\n",
      "37 **********\n",
      "Epoch:  3591.8461315631866  fold:  7  kers:  128\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.06349910795688629\n",
      "Loss:  0.03443067520856857\n",
      "Loss:  0.053411781787872314\n",
      "38 **********\n",
      "Epoch:  3672.4516088962555  fold:  7  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.5095248818397522\n",
      "Eval Loss:  0.06162741035223007\n",
      "Eval Loss:  1.9092228412628174\n",
      "[[1942  185]\n",
      " [ 591  713]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83      2127\n",
      "           1       0.79      0.55      0.65      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.73      0.74      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7738268726318858\n",
      "pre:  0.7939866369710468\n",
      "rec:  0.5467791411042945\n",
      "ma F1:  0.7405347460170817\n",
      "mi F1:  0.7738268726318857\n",
      "we F1:  0.7628288226680041\n",
      "Eval Loss:  0.16780783236026764\n",
      "Eval Loss:  0.15610940754413605\n",
      "Eval Loss:  0.22865034639835358\n",
      "Eval Loss:  0.2881005108356476\n",
      "Eval Loss:  0.18148505687713623\n",
      "Eval Loss:  0.19616559147834778\n",
      "Eval Loss:  0.24233737587928772\n",
      "Eval Loss:  0.20225876569747925\n",
      "Eval Loss:  0.2064928114414215\n",
      "Eval Loss:  0.2517717480659485\n",
      "Eval Loss:  0.292000412940979\n",
      "Eval Loss:  0.11619014292955399\n",
      "Eval Loss:  0.17720818519592285\n",
      "Eval Loss:  0.1997852325439453\n",
      "Eval Loss:  0.15173618495464325\n",
      "Eval Loss:  0.24894560873508453\n",
      "Eval Loss:  0.20364482700824738\n",
      "Eval Loss:  0.23548905551433563\n",
      "Eval Loss:  0.25619032979011536\n",
      "Eval Loss:  0.14810803532600403\n",
      "Eval Loss:  0.23167985677719116\n",
      "Eval Loss:  0.17555998265743256\n",
      "Eval Loss:  0.16117039322853088\n",
      "Eval Loss:  0.2294449508190155\n",
      "Eval Loss:  0.2838076055049896\n",
      "Eval Loss:  0.2633030116558075\n",
      "Eval Loss:  0.20379874110221863\n",
      "Eval Loss:  0.22481323778629303\n",
      "[[16919  1118]\n",
      " [ 1203 10220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18037\n",
      "           1       0.90      0.89      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9212152070604209\n",
      "pre:  0.9013935438348916\n",
      "rec:  0.8946861595027576\n",
      "ma F1:  0.916919302706414\n",
      "mi F1:  0.9212152070604209\n",
      "we F1:  0.9211606986457186\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06811293214559555\n",
      "Loss:  0.05587013438344002\n",
      "Loss:  0.07917426526546478\n",
      "39 **********\n",
      "Epoch:  3796.304451942444  fold:  7  kers:  128\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.03212179243564606\n",
      "Loss:  0.029123486950993538\n",
      "Loss:  0.045352354645729065\n",
      "40 **********\n",
      "Epoch:  3876.9218966960907  fold:  7  kers:  128\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.048214759677648544\n",
      "Loss:  0.04967249929904938\n",
      "Loss:  0.05263711139559746\n",
      "41 **********\n",
      "Epoch:  3957.559288740158  fold:  7  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.4263208210468292\n",
      "Eval Loss:  0.09713062644004822\n",
      "Eval Loss:  1.7105286121368408\n",
      "[[1938  189]\n",
      " [ 524  780]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.84      2127\n",
      "           1       0.80      0.60      0.69      1304\n",
      "\n",
      "    accuracy                           0.79      3431\n",
      "   macro avg       0.80      0.75      0.77      3431\n",
      "weighted avg       0.79      0.79      0.78      3431\n",
      "\n",
      "acc:  0.792188866219761\n",
      "pre:  0.804953560371517\n",
      "rec:  0.598159509202454\n",
      "ma F1:  0.7654730506211558\n",
      "mi F1:  0.792188866219761\n",
      "we F1:  0.7844601976312181\n",
      "Eval Loss:  0.16119594871997833\n",
      "Eval Loss:  0.17028303444385529\n",
      "Eval Loss:  0.19113856554031372\n",
      "Eval Loss:  0.26407933235168457\n",
      "Eval Loss:  0.1950555145740509\n",
      "Eval Loss:  0.1923738718032837\n",
      "Eval Loss:  0.22168810665607452\n",
      "Eval Loss:  0.18683676421642303\n",
      "Eval Loss:  0.199632465839386\n",
      "Eval Loss:  0.25448352098464966\n",
      "Eval Loss:  0.24875901639461517\n",
      "Eval Loss:  0.11631382256746292\n",
      "Eval Loss:  0.15926535427570343\n",
      "Eval Loss:  0.20479576289653778\n",
      "Eval Loss:  0.1420697271823883\n",
      "Eval Loss:  0.2655414640903473\n",
      "Eval Loss:  0.20417408645153046\n",
      "Eval Loss:  0.19882014393806458\n",
      "Eval Loss:  0.2406613975763321\n",
      "Eval Loss:  0.15269586443901062\n",
      "Eval Loss:  0.1877778321504593\n",
      "Eval Loss:  0.1978798359632492\n",
      "Eval Loss:  0.16199564933776855\n",
      "Eval Loss:  0.22814512252807617\n",
      "Eval Loss:  0.2786523699760437\n",
      "Eval Loss:  0.2493388056755066\n",
      "Eval Loss:  0.20504285395145416\n",
      "Eval Loss:  0.2183552235364914\n",
      "[[16886  1151]\n",
      " [ 1144 10279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18037\n",
      "           1       0.90      0.90      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9220977596741344\n",
      "pre:  0.8993000874890639\n",
      "rec:  0.8998511774490064\n",
      "ma F1:  0.9179719867492682\n",
      "mi F1:  0.9220977596741344\n",
      "we F1:  0.9221021308577995\n",
      "29460 461\n",
      "Loss:  0.06148601323366165\n",
      "Loss:  0.030273456126451492\n",
      "Loss:  0.03982308879494667\n",
      "42 **********\n",
      "Epoch:  4081.367251634598  fold:  7  kers:  128\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.05686664208769798\n",
      "Loss:  0.04968081787228584\n",
      "Loss:  0.06603033095598221\n",
      "43 **********\n",
      "Epoch:  4161.985694408417  fold:  7  kers:  128\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.05009246617555618\n",
      "Loss:  0.03975215554237366\n",
      "Loss:  0.04602525010704994\n",
      "44 **********\n",
      "Epoch:  4242.601144552231  fold:  7  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.48824968934059143\n",
      "Eval Loss:  0.21358631551265717\n",
      "Eval Loss:  1.7221556901931763\n",
      "[[1892  235]\n",
      " [ 545  759]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      2127\n",
      "           1       0.76      0.58      0.66      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.74      0.74      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7726610317691636\n",
      "pre:  0.7635814889336016\n",
      "rec:  0.5820552147239264\n",
      "ma F1:  0.7448358478088251\n",
      "mi F1:  0.7726610317691636\n",
      "we F1:  0.7650477863784265\n",
      "Eval Loss:  0.15322233736515045\n",
      "Eval Loss:  0.16647443175315857\n",
      "Eval Loss:  0.2525981068611145\n",
      "Eval Loss:  0.27933359146118164\n",
      "Eval Loss:  0.18676568567752838\n",
      "Eval Loss:  0.18333446979522705\n",
      "Eval Loss:  0.21368560194969177\n",
      "Eval Loss:  0.17807923257350922\n",
      "Eval Loss:  0.19605033099651337\n",
      "Eval Loss:  0.22120216488838196\n",
      "Eval Loss:  0.2528465688228607\n",
      "Eval Loss:  0.11022713780403137\n",
      "Eval Loss:  0.16961771249771118\n",
      "Eval Loss:  0.22672517597675323\n",
      "Eval Loss:  0.1491376906633377\n",
      "Eval Loss:  0.23796997964382172\n",
      "Eval Loss:  0.22140656411647797\n",
      "Eval Loss:  0.24518929421901703\n",
      "Eval Loss:  0.2207513004541397\n",
      "Eval Loss:  0.19538915157318115\n",
      "Eval Loss:  0.2243811935186386\n",
      "Eval Loss:  0.17427875101566315\n",
      "Eval Loss:  0.14425723254680634\n",
      "Eval Loss:  0.21978147327899933\n",
      "Eval Loss:  0.2805541753768921\n",
      "Eval Loss:  0.2843095064163208\n",
      "Eval Loss:  0.2175421118736267\n",
      "Eval Loss:  0.22221001982688904\n",
      "[[16891  1146]\n",
      " [ 1199 10224]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18037\n",
      "           1       0.90      0.90      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9204005431093008\n",
      "pre:  0.8992084432717679\n",
      "rec:  0.8950363302109778\n",
      "ma F1:  0.9161038174518494\n",
      "mi F1:  0.9204005431093008\n",
      "we F1:  0.920366385848187\n",
      "29460 461\n",
      "Loss:  0.05836544185876846\n",
      "Loss:  0.05695227161049843\n",
      "Loss:  0.0674506425857544\n",
      "45 **********\n",
      "Epoch:  4366.252525568008  fold:  7  kers:  128\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.06903251260519028\n",
      "Loss:  0.06490688025951385\n",
      "Loss:  0.033934563398361206\n",
      "46 **********\n",
      "Epoch:  4446.88293671608  fold:  7  kers:  128\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.030197585001587868\n",
      "Loss:  0.1076902374625206\n",
      "Loss:  0.04570678621530533\n",
      "47 **********\n",
      "Epoch:  4527.535288572311  fold:  7  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.46814221143722534\n",
      "Eval Loss:  0.21078181266784668\n",
      "Eval Loss:  1.230739951133728\n",
      "[[1731  396]\n",
      " [ 431  873]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      2127\n",
      "           1       0.69      0.67      0.68      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.74      0.74      0.74      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7589624016321772\n",
      "pre:  0.6879432624113475\n",
      "rec:  0.6694785276073619\n",
      "ma F1:  0.7428832350438312\n",
      "mi F1:  0.7589624016321772\n",
      "we F1:  0.7583064915732121\n",
      "Eval Loss:  0.19266073405742645\n",
      "Eval Loss:  0.21267014741897583\n",
      "Eval Loss:  0.19754600524902344\n",
      "Eval Loss:  0.3030264377593994\n",
      "Eval Loss:  0.19284552335739136\n",
      "Eval Loss:  0.18475428223609924\n",
      "Eval Loss:  0.24198190867900848\n",
      "Eval Loss:  0.2069842517375946\n",
      "Eval Loss:  0.22957490384578705\n",
      "Eval Loss:  0.21755105257034302\n",
      "Eval Loss:  0.30060622096061707\n",
      "Eval Loss:  0.13879118859767914\n",
      "Eval Loss:  0.1601286232471466\n",
      "Eval Loss:  0.2059047371149063\n",
      "Eval Loss:  0.20949871838092804\n",
      "Eval Loss:  0.33116614818573\n",
      "Eval Loss:  0.22580216825008392\n",
      "Eval Loss:  0.2784889340400696\n",
      "Eval Loss:  0.19590772688388824\n",
      "Eval Loss:  0.18464821577072144\n",
      "Eval Loss:  0.2356327474117279\n",
      "Eval Loss:  0.23957791924476624\n",
      "Eval Loss:  0.16338568925857544\n",
      "Eval Loss:  0.24310573935508728\n",
      "Eval Loss:  0.3053258955478668\n",
      "Eval Loss:  0.2905789911746979\n",
      "Eval Loss:  0.2444656491279602\n",
      "Eval Loss:  0.23370948433876038\n",
      "[[16164  1873]\n",
      " [  703 10720]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93     18037\n",
      "           1       0.85      0.94      0.89     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.92      0.91     29460\n",
      "weighted avg       0.92      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9125594025797692\n",
      "pre:  0.8512665766695784\n",
      "rec:  0.9384574980302898\n",
      "ma F1:  0.9094678725146641\n",
      "mi F1:  0.9125594025797692\n",
      "we F1:  0.9132238203196982\n",
      "29460 461\n",
      "Loss:  0.03202728182077408\n",
      "Loss:  0.06904879212379456\n",
      "Loss:  0.05260447412729263\n",
      "48 **********\n",
      "Epoch:  4651.163731813431  fold:  7  kers:  128\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.08371984958648682\n",
      "Loss:  0.05588964745402336\n",
      "Loss:  0.04908520728349686\n",
      "49 **********\n",
      "Epoch:  4731.768211364746  fold:  7  kers:  128\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.053921692073345184\n",
      "Loss:  0.05531288683414459\n",
      "Loss:  0.05275970697402954\n",
      "50 **********\n",
      "Epoch:  4812.372691631317  fold:  7  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.4119260609149933\n",
      "Eval Loss:  0.23946833610534668\n",
      "Eval Loss:  1.698686957359314\n",
      "[[1786  341]\n",
      " [ 448  856]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      2127\n",
      "           1       0.72      0.66      0.68      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.76      0.75      0.75      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7700378898280384\n",
      "pre:  0.7151211361737677\n",
      "rec:  0.656441717791411\n",
      "ma F1:  0.7518021912995866\n",
      "mi F1:  0.7700378898280384\n",
      "we F1:  0.7679398040833672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.16562408208847046\n",
      "Eval Loss:  0.15777206420898438\n",
      "Eval Loss:  0.1738259345293045\n",
      "Eval Loss:  0.25447237491607666\n",
      "Eval Loss:  0.18169274926185608\n",
      "Eval Loss:  0.1880839765071869\n",
      "Eval Loss:  0.19380411505699158\n",
      "Eval Loss:  0.16968104243278503\n",
      "Eval Loss:  0.20896732807159424\n",
      "Eval Loss:  0.2123114913702011\n",
      "Eval Loss:  0.2553422152996063\n",
      "Eval Loss:  0.10837088525295258\n",
      "Eval Loss:  0.17003658413887024\n",
      "Eval Loss:  0.20916229486465454\n",
      "Eval Loss:  0.148309588432312\n",
      "Eval Loss:  0.27209439873695374\n",
      "Eval Loss:  0.2169252187013626\n",
      "Eval Loss:  0.232471764087677\n",
      "Eval Loss:  0.19682762026786804\n",
      "Eval Loss:  0.16495177149772644\n",
      "Eval Loss:  0.20689746737480164\n",
      "Eval Loss:  0.1939961016178131\n",
      "Eval Loss:  0.13789333403110504\n",
      "Eval Loss:  0.21287664771080017\n",
      "Eval Loss:  0.28006231784820557\n",
      "Eval Loss:  0.2540293037891388\n",
      "Eval Loss:  0.18845568597316742\n",
      "Eval Loss:  0.22827690839767456\n",
      "[[16628  1409]\n",
      " [  822 10601]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     18037\n",
      "           1       0.88      0.93      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.93      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9242701968771215\n",
      "pre:  0.8826810990840965\n",
      "rec:  0.9280399194607372\n",
      "ma F1:  0.9209621471320013\n",
      "mi F1:  0.9242701968771215\n",
      "we F1:  0.9245923845659195\n",
      "29460 461\n",
      "Loss:  0.048428118228912354\n",
      "Loss:  0.03693799674510956\n",
      "Loss:  0.04580291733145714\n",
      "51 **********\n",
      "Epoch:  4936.0250697135925  fold:  7  kers:  128\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.06084650009870529\n",
      "Loss:  0.0620119571685791\n",
      "Loss:  0.05173123627901077\n",
      "52 **********\n",
      "Epoch:  5016.642515897751  fold:  7  kers:  128\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.0470818467438221\n",
      "Loss:  0.05125697702169418\n",
      "Loss:  0.05892103165388107\n",
      "53 **********\n",
      "Epoch:  5097.288884162903  fold:  7  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.42849263548851013\n",
      "Eval Loss:  0.090750552713871\n",
      "Eval Loss:  1.8389787673950195\n",
      "[[1951  176]\n",
      " [ 606  698]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83      2127\n",
      "           1       0.80      0.54      0.64      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.73      0.74      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7720781113378024\n",
      "pre:  0.7986270022883295\n",
      "rec:  0.5352760736196319\n",
      "ma F1:  0.7370018404681862\n",
      "mi F1:  0.7720781113378024\n",
      "we F1:  0.7600407637927624\n",
      "Eval Loss:  0.16886098682880402\n",
      "Eval Loss:  0.16654719412326813\n",
      "Eval Loss:  0.22129018604755402\n",
      "Eval Loss:  0.2451990693807602\n",
      "Eval Loss:  0.22410309314727783\n",
      "Eval Loss:  0.18252655863761902\n",
      "Eval Loss:  0.18076327443122864\n",
      "Eval Loss:  0.17913830280303955\n",
      "Eval Loss:  0.16958332061767578\n",
      "Eval Loss:  0.2123458981513977\n",
      "Eval Loss:  0.2735532820224762\n",
      "Eval Loss:  0.10026046633720398\n",
      "Eval Loss:  0.14940033853054047\n",
      "Eval Loss:  0.2021058350801468\n",
      "Eval Loss:  0.14909587800502777\n",
      "Eval Loss:  0.2259543091058731\n",
      "Eval Loss:  0.20895680785179138\n",
      "Eval Loss:  0.22023038566112518\n",
      "Eval Loss:  0.23180703818798065\n",
      "Eval Loss:  0.14056521654129028\n",
      "Eval Loss:  0.18693748116493225\n",
      "Eval Loss:  0.14938999712467194\n",
      "Eval Loss:  0.14264890551567078\n",
      "Eval Loss:  0.20148511230945587\n",
      "Eval Loss:  0.3240513801574707\n",
      "Eval Loss:  0.24164354801177979\n",
      "Eval Loss:  0.199544757604599\n",
      "Eval Loss:  0.21684187650680542\n",
      "[[17143   894]\n",
      " [ 1437  9986]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18037\n",
      "           1       0.92      0.87      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9208757637474542\n",
      "pre:  0.9178308823529412\n",
      "rec:  0.8742011730718725\n",
      "ma F1:  0.9159129780605557\n",
      "mi F1:  0.9208757637474542\n",
      "we F1:  0.9204992382999223\n",
      "29460 461\n",
      "Loss:  0.061586812138557434\n",
      "Loss:  0.058919601142406464\n",
      "Loss:  0.08866069465875626\n",
      "54 **********\n",
      "Epoch:  5220.982152938843  fold:  7  kers:  128\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.07098366320133209\n",
      "Loss:  0.041836030781269073\n",
      "Loss:  0.026621036231517792\n",
      "55 **********\n",
      "Epoch:  5301.579651117325  fold:  7  kers:  128\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.04781153425574303\n",
      "Loss:  0.03387531265616417\n",
      "Loss:  0.026275230571627617\n",
      "56 **********\n",
      "Epoch:  5382.170168399811  fold:  7  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.5963214039802551\n",
      "Eval Loss:  0.12430676817893982\n",
      "Eval Loss:  0.7740123867988586\n",
      "[[1928  199]\n",
      " [ 467  837]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.85      2127\n",
      "           1       0.81      0.64      0.72      1304\n",
      "\n",
      "    accuracy                           0.81      3431\n",
      "   macro avg       0.81      0.77      0.78      3431\n",
      "weighted avg       0.81      0.81      0.80      3431\n",
      "\n",
      "acc:  0.8058874963567473\n",
      "pre:  0.8079150579150579\n",
      "rec:  0.6418711656441718\n",
      "ma F1:  0.7840523253835947\n",
      "mi F1:  0.8058874963567473\n",
      "we F1:  0.8005237696649005\n",
      "update!  Acc:  0.8058874963567473\n",
      "Eval Loss:  0.1457153707742691\n",
      "Eval Loss:  0.14840446412563324\n",
      "Eval Loss:  0.16837894916534424\n",
      "Eval Loss:  0.2733214199542999\n",
      "Eval Loss:  0.17974568903446198\n",
      "Eval Loss:  0.16703130304813385\n",
      "Eval Loss:  0.19253915548324585\n",
      "Eval Loss:  0.1552630364894867\n",
      "Eval Loss:  0.17761480808258057\n",
      "Eval Loss:  0.20777803659439087\n",
      "Eval Loss:  0.22160454094409943\n",
      "Eval Loss:  0.1117718294262886\n",
      "Eval Loss:  0.1763158142566681\n",
      "Eval Loss:  0.1673024594783783\n",
      "Eval Loss:  0.14045971632003784\n",
      "Eval Loss:  0.211923286318779\n",
      "Eval Loss:  0.21538767218589783\n",
      "Eval Loss:  0.18696613609790802\n",
      "Eval Loss:  0.185993492603302\n",
      "Eval Loss:  0.13371340930461884\n",
      "Eval Loss:  0.1804865300655365\n",
      "Eval Loss:  0.15509183704853058\n",
      "Eval Loss:  0.12175116688013077\n",
      "Eval Loss:  0.19621124863624573\n",
      "Eval Loss:  0.26400554180145264\n",
      "Eval Loss:  0.24025489389896393\n",
      "Eval Loss:  0.20179668068885803\n",
      "Eval Loss:  0.1959695965051651\n",
      "[[17188   849]\n",
      " [ 1252 10171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18037\n",
      "           1       0.92      0.89      0.91     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9286829599456891\n",
      "pre:  0.9229582577132487\n",
      "rec:  0.8903965683270595\n",
      "ma F1:  0.924393562979189\n",
      "mi F1:  0.9286829599456891\n",
      "we F1:  0.9284366115093916\n",
      "29460 461\n",
      "Loss:  0.060643166303634644\n",
      "Loss:  0.047228164970874786\n",
      "Loss:  0.03663419559597969\n",
      "57 **********\n",
      "Epoch:  5505.84947514534  fold:  7  kers:  128\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.02977798320353031\n",
      "Loss:  0.058027565479278564\n",
      "Loss:  0.03483644127845764\n",
      "58 **********\n",
      "Epoch:  5588.244168996811  fold:  7  kers:  128\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.051956530660390854\n",
      "Loss:  0.056209418922662735\n",
      "Loss:  0.03820349648594856\n",
      "59 **********\n",
      "Epoch:  5671.8336679935455  fold:  7  kers:  128\n",
      "Eval Loss:  0.507721483707428\n",
      "Eval Loss:  0.26120418310165405\n",
      "Eval Loss:  0.7293914556503296\n",
      "[[1759  368]\n",
      " [ 343  961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      2127\n",
      "           1       0.72      0.74      0.73      1304\n",
      "\n",
      "    accuracy                           0.79      3431\n",
      "   macro avg       0.78      0.78      0.78      3431\n",
      "weighted avg       0.79      0.79      0.79      3431\n",
      "\n",
      "acc:  0.7927717866511221\n",
      "pre:  0.7231000752445448\n",
      "rec:  0.7369631901840491\n",
      "ma F1:  0.7809204831235541\n",
      "mi F1:  0.7927717866511221\n",
      "we F1:  0.7931430680899558\n",
      "update!  Acc:  0.8058874963567473\n",
      "Epoch:  5676.465283632278  fold:  7  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29817 3074\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29817 466\n",
      "Loss:  0.1741122305393219\n",
      "Loss:  0.17074370384216309\n",
      "Loss:  0.16241194307804108\n",
      "0 **********\n",
      "Epoch:  93.84008955955505  fold:  8  kers:  128\n",
      "epoch:  1\n",
      "29817 466\n",
      "Loss:  0.1350448727607727\n",
      "Loss:  0.13808482885360718\n",
      "Loss:  0.11291100084781647\n",
      "1 **********\n",
      "Epoch:  175.40101265907288  fold:  8  kers:  128\n",
      "epoch:  2\n",
      "29817 466\n",
      "Loss:  0.13644374907016754\n",
      "Loss:  0.13634833693504333\n",
      "Loss:  0.09779975563287735\n",
      "2 **********\n",
      "Epoch:  256.97589778900146  fold:  8  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.28073543310165405\n",
      "Eval Loss:  1.3332431316375732\n",
      "Eval Loss:  0.18413344025611877\n",
      "[[1931  142]\n",
      " [ 472  529]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      2073\n",
      "           1       0.79      0.53      0.63      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.80      0.73      0.75      3074\n",
      "weighted avg       0.80      0.80      0.79      3074\n",
      "\n",
      "acc:  0.8002602472348731\n",
      "pre:  0.7883755588673621\n",
      "rec:  0.5284715284715285\n",
      "ma F1:  0.747799534786271\n",
      "mi F1:  0.8002602472348731\n",
      "we F1:  0.7879121480137329\n",
      "update!  Acc:  0.8002602472348731\n",
      "Eval Loss:  0.4801584482192993\n",
      "Eval Loss:  0.4687441289424896\n",
      "Eval Loss:  0.4168332517147064\n",
      "Eval Loss:  0.5403825640678406\n",
      "Eval Loss:  0.4102775454521179\n",
      "Eval Loss:  0.324832946062088\n",
      "Eval Loss:  0.6416633725166321\n",
      "Eval Loss:  0.43871936202049255\n",
      "Eval Loss:  0.4244656264781952\n",
      "Eval Loss:  0.30404016375541687\n",
      "Eval Loss:  0.4753997325897217\n",
      "Eval Loss:  0.33942580223083496\n",
      "Eval Loss:  0.4320153295993805\n",
      "Eval Loss:  0.3416643738746643\n",
      "Eval Loss:  0.4074767827987671\n",
      "Eval Loss:  0.4036616086959839\n",
      "Eval Loss:  0.4363400340080261\n",
      "Eval Loss:  0.44571852684020996\n",
      "Eval Loss:  0.4901845455169678\n",
      "Eval Loss:  0.47298628091812134\n",
      "Eval Loss:  0.5199177861213684\n",
      "Eval Loss:  0.45595961809158325\n",
      "Eval Loss:  0.42213407158851624\n",
      "Eval Loss:  0.4009859561920166\n",
      "Eval Loss:  0.4354865252971649\n",
      "Eval Loss:  0.5208805203437805\n",
      "Eval Loss:  0.26479703187942505\n",
      "Eval Loss:  0.4047478139400482\n",
      "Eval Loss:  0.5109143257141113\n",
      "[[16334  1757]\n",
      " [ 3697  8029]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86     18091\n",
      "           1       0.82      0.68      0.75     11726\n",
      "\n",
      "    accuracy                           0.82     29817\n",
      "   macro avg       0.82      0.79      0.80     29817\n",
      "weighted avg       0.82      0.82      0.81     29817\n",
      "\n",
      "acc:  0.817084213703592\n",
      "pre:  0.8204577968526466\n",
      "rec:  0.6847177213030872\n",
      "ma F1:  0.8017000463505737\n",
      "mi F1:  0.8170842137035921\n",
      "we F1:  0.8134905611250423\n",
      "29817 466\n",
      "Loss:  0.0887235626578331\n",
      "Loss:  0.09776744246482849\n",
      "Loss:  0.11206649243831635\n",
      "3 **********\n",
      "Epoch:  384.66248989105225  fold:  8  kers:  128\n",
      "epoch:  4\n",
      "29817 466\n",
      "Loss:  0.09125138819217682\n",
      "Loss:  0.09502992779016495\n",
      "Loss:  0.10287566483020782\n",
      "4 **********\n",
      "Epoch:  466.22241497039795  fold:  8  kers:  128\n",
      "epoch:  5\n",
      "29817 466\n",
      "Loss:  0.09052296727895737\n",
      "Loss:  0.090427465736866\n",
      "Loss:  0.07006754726171494\n",
      "5 **********\n",
      "Epoch:  547.8371939659119  fold:  8  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.2619889974594116\n",
      "Eval Loss:  1.9560250043869019\n",
      "Eval Loss:  0.11827950179576874\n",
      "[[1983   90]\n",
      " [ 508  493]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87      2073\n",
      "           1       0.85      0.49      0.62      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.82      0.72      0.75      3074\n",
      "weighted avg       0.81      0.81      0.79      3074\n",
      "\n",
      "acc:  0.8054651919323357\n",
      "pre:  0.8456260720411664\n",
      "rec:  0.4925074925074925\n",
      "ma F1:  0.7457246655866288\n",
      "mi F1:  0.8054651919323357\n",
      "we F1:  0.788705769105151\n",
      "update!  Acc:  0.8054651919323357\n",
      "Eval Loss:  0.43151432275772095\n",
      "Eval Loss:  0.36681967973709106\n",
      "Eval Loss:  0.30842962861061096\n",
      "Eval Loss:  0.46771055459976196\n",
      "Eval Loss:  0.30140623450279236\n",
      "Eval Loss:  0.26101136207580566\n",
      "Eval Loss:  0.6015782952308655\n",
      "Eval Loss:  0.419667512178421\n",
      "Eval Loss:  0.4155721068382263\n",
      "Eval Loss:  0.24845293164253235\n",
      "Eval Loss:  0.4107147753238678\n",
      "Eval Loss:  0.24761882424354553\n",
      "Eval Loss:  0.37482139468193054\n",
      "Eval Loss:  0.31599441170692444\n",
      "Eval Loss:  0.40370211005210876\n",
      "Eval Loss:  0.38505518436431885\n",
      "Eval Loss:  0.3735344111919403\n",
      "Eval Loss:  0.4638335704803467\n",
      "Eval Loss:  0.4615267515182495\n",
      "Eval Loss:  0.3342494070529938\n",
      "Eval Loss:  0.40591129660606384\n",
      "Eval Loss:  0.31107449531555176\n",
      "Eval Loss:  0.36126604676246643\n",
      "Eval Loss:  0.41373223066329956\n",
      "Eval Loss:  0.4048406779766083\n",
      "Eval Loss:  0.48599231243133545\n",
      "Eval Loss:  0.25723958015441895\n",
      "Eval Loss:  0.37972891330718994\n",
      "Eval Loss:  0.43974801898002625\n",
      "[[17235   856]\n",
      " [ 3561  8165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     18091\n",
      "           1       0.91      0.70      0.79     11726\n",
      "\n",
      "    accuracy                           0.85     29817\n",
      "   macro avg       0.87      0.82      0.84     29817\n",
      "weighted avg       0.86      0.85      0.85     29817\n",
      "\n",
      "acc:  0.8518630311567227\n",
      "pre:  0.905110298193105\n",
      "rec:  0.6963158792427085\n",
      "ma F1:  0.8367581163198627\n",
      "mi F1:  0.8518630311567227\n",
      "we F1:  0.8473582026414298\n",
      "29817 466\n",
      "Loss:  0.06570125371217728\n",
      "Loss:  0.10077903419733047\n",
      "Loss:  0.12028777599334717\n",
      "6 **********\n",
      "Epoch:  672.4898979663849  fold:  8  kers:  128\n",
      "epoch:  7\n",
      "29817 466\n",
      "Loss:  0.0924944132566452\n",
      "Loss:  0.05434088036417961\n",
      "Loss:  0.06568694114685059\n",
      "7 **********\n",
      "Epoch:  753.9650497436523  fold:  8  kers:  128\n",
      "epoch:  8\n",
      "29817 466\n",
      "Loss:  0.09809025377035141\n",
      "Loss:  0.06829676032066345\n",
      "Loss:  0.09398744255304337\n",
      "8 **********\n",
      "Epoch:  835.4491782188416  fold:  8  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.2338947206735611\n",
      "Eval Loss:  1.873893141746521\n",
      "Eval Loss:  0.10368242859840393\n",
      "[[1965  108]\n",
      " [ 447  554]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88      2073\n",
      "           1       0.84      0.55      0.67      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.83      0.75      0.77      3074\n",
      "weighted avg       0.82      0.82      0.81      3074\n",
      "\n",
      "acc:  0.8194534808067664\n",
      "pre:  0.8368580060422961\n",
      "rec:  0.5534465534465535\n",
      "ma F1:  0.7712599826642024\n",
      "mi F1:  0.8194534808067664\n",
      "we F1:  0.80787474525019\n",
      "update!  Acc:  0.8194534808067664\n",
      "Eval Loss:  0.34974220395088196\n",
      "Eval Loss:  0.29794660210609436\n",
      "Eval Loss:  0.2485359013080597\n",
      "Eval Loss:  0.3996606171131134\n",
      "Eval Loss:  0.24571716785430908\n",
      "Eval Loss:  0.23571717739105225\n",
      "Eval Loss:  0.5027486681938171\n",
      "Eval Loss:  0.3645213842391968\n",
      "Eval Loss:  0.3472835421562195\n",
      "Eval Loss:  0.21099740266799927\n",
      "Eval Loss:  0.33165839314460754\n",
      "Eval Loss:  0.16786493360996246\n",
      "Eval Loss:  0.2951262593269348\n",
      "Eval Loss:  0.2675494849681854\n",
      "Eval Loss:  0.3415914475917816\n",
      "Eval Loss:  0.3648427426815033\n",
      "Eval Loss:  0.33369767665863037\n",
      "Eval Loss:  0.36254361271858215\n",
      "Eval Loss:  0.38709554076194763\n",
      "Eval Loss:  0.24389947950839996\n",
      "Eval Loss:  0.2894120216369629\n",
      "Eval Loss:  0.2323666512966156\n",
      "Eval Loss:  0.3078148365020752\n",
      "Eval Loss:  0.34847593307495117\n",
      "Eval Loss:  0.3511478304862976\n",
      "Eval Loss:  0.4361797571182251\n",
      "Eval Loss:  0.24246977269649506\n",
      "Eval Loss:  0.3061090111732483\n",
      "Eval Loss:  0.35558345913887024\n",
      "[[17247   844]\n",
      " [ 2906  8820]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18091\n",
      "           1       0.91      0.75      0.82     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.88      0.85      0.86     29817\n",
      "weighted avg       0.88      0.87      0.87     29817\n",
      "\n",
      "acc:  0.8742328202032398\n",
      "pre:  0.9126655629139073\n",
      "rec:  0.752174654613679\n",
      "ma F1:  0.8633149175890309\n",
      "mi F1:  0.8742328202032398\n",
      "we F1:  0.87156132201996\n",
      "29817 466\n",
      "Loss:  0.07105744630098343\n",
      "Loss:  0.07912883907556534\n",
      "Loss:  0.07316932827234268\n",
      "9 **********\n",
      "Epoch:  960.0250871181488  fold:  8  kers:  128\n",
      "epoch:  10\n",
      "29817 466\n",
      "Loss:  0.10195077210664749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04559154435992241\n",
      "Loss:  0.09343650192022324\n",
      "10 **********\n",
      "Epoch:  1041.430425643921  fold:  8  kers:  128\n",
      "epoch:  11\n",
      "29817 466\n",
      "Loss:  0.07640328258275986\n",
      "Loss:  0.06870459765195847\n",
      "Loss:  0.072486512362957\n",
      "11 **********\n",
      "Epoch:  1122.847732782364  fold:  8  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.4965209364891052\n",
      "Eval Loss:  1.3965144157409668\n",
      "Eval Loss:  0.15475177764892578\n",
      "[[1863  210]\n",
      " [ 308  693]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      2073\n",
      "           1       0.77      0.69      0.73      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.80      0.80      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8314899154196487\n",
      "pre:  0.7674418604651163\n",
      "rec:  0.6923076923076923\n",
      "ma F1:  0.8029432555302989\n",
      "mi F1:  0.8314899154196488\n",
      "we F1:  0.8290988276682331\n",
      "update!  Acc:  0.8314899154196487\n",
      "Eval Loss:  0.2879045307636261\n",
      "Eval Loss:  0.2618424892425537\n",
      "Eval Loss:  0.18591971695423126\n",
      "Eval Loss:  0.2737390697002411\n",
      "Eval Loss:  0.188262477517128\n",
      "Eval Loss:  0.20613162219524384\n",
      "Eval Loss:  0.3829028606414795\n",
      "Eval Loss:  0.2951045334339142\n",
      "Eval Loss:  0.25168800354003906\n",
      "Eval Loss:  0.1622503101825714\n",
      "Eval Loss:  0.23100562393665314\n",
      "Eval Loss:  0.15947000682353973\n",
      "Eval Loss:  0.2336401492357254\n",
      "Eval Loss:  0.24174171686172485\n",
      "Eval Loss:  0.2941511869430542\n",
      "Eval Loss:  0.31477171182632446\n",
      "Eval Loss:  0.2713935673236847\n",
      "Eval Loss:  0.2677229642868042\n",
      "Eval Loss:  0.2779272794723511\n",
      "Eval Loss:  0.2276272028684616\n",
      "Eval Loss:  0.2539953589439392\n",
      "Eval Loss:  0.17777712643146515\n",
      "Eval Loss:  0.2744903266429901\n",
      "Eval Loss:  0.309709370136261\n",
      "Eval Loss:  0.3004409372806549\n",
      "Eval Loss:  0.37990573048591614\n",
      "Eval Loss:  0.2147340476512909\n",
      "Eval Loss:  0.24851760268211365\n",
      "Eval Loss:  0.2693226933479309\n",
      "[[16919  1172]\n",
      " [ 1972  9754]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.91     18091\n",
      "           1       0.89      0.83      0.86     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.89      0.88      0.89     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8945567964583963\n",
      "pre:  0.8927329306241991\n",
      "rec:  0.8318267098754903\n",
      "ma F1:  0.8880949886870049\n",
      "mi F1:  0.8945567964583963\n",
      "we F1:  0.8938353105941795\n",
      "29817 466\n",
      "Loss:  0.05781595781445503\n",
      "Loss:  0.09262774139642715\n",
      "Loss:  0.09341398626565933\n",
      "12 **********\n",
      "Epoch:  1248.0330123901367  fold:  8  kers:  128\n",
      "epoch:  13\n",
      "29817 466\n",
      "Loss:  0.07994742691516876\n",
      "Loss:  0.047008492052555084\n",
      "Loss:  0.04466019198298454\n",
      "13 **********\n",
      "Epoch:  1329.8791725635529  fold:  8  kers:  128\n",
      "epoch:  14\n",
      "29817 466\n",
      "Loss:  0.08099643141031265\n",
      "Loss:  0.034310903400182724\n",
      "Loss:  0.07132089883089066\n",
      "14 **********\n",
      "Epoch:  1411.484974861145  fold:  8  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.5690769553184509\n",
      "Eval Loss:  1.1599061489105225\n",
      "Eval Loss:  0.15882889926433563\n",
      "[[1836  237]\n",
      " [ 249  752]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      2073\n",
      "           1       0.76      0.75      0.76      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.82      0.82      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8418998048145738\n",
      "pre:  0.7603640040444893\n",
      "rec:  0.7512487512487512\n",
      "ma F1:  0.8194478887946224\n",
      "mi F1:  0.8418998048145738\n",
      "we F1:  0.8416512596187808\n",
      "update!  Acc:  0.8418998048145738\n",
      "Eval Loss:  0.28723806142807007\n",
      "Eval Loss:  0.2433631867170334\n",
      "Eval Loss:  0.1582462340593338\n",
      "Eval Loss:  0.2613990902900696\n",
      "Eval Loss:  0.1839222013950348\n",
      "Eval Loss:  0.21449002623558044\n",
      "Eval Loss:  0.3875882625579834\n",
      "Eval Loss:  0.2935049831867218\n",
      "Eval Loss:  0.2580473721027374\n",
      "Eval Loss:  0.1303100883960724\n",
      "Eval Loss:  0.18194681406021118\n",
      "Eval Loss:  0.16225238144397736\n",
      "Eval Loss:  0.2248309701681137\n",
      "Eval Loss:  0.24419111013412476\n",
      "Eval Loss:  0.27198871970176697\n",
      "Eval Loss:  0.3327939212322235\n",
      "Eval Loss:  0.24438470602035522\n",
      "Eval Loss:  0.20195643603801727\n",
      "Eval Loss:  0.2434912919998169\n",
      "Eval Loss:  0.2208753079175949\n",
      "Eval Loss:  0.23061306774616241\n",
      "Eval Loss:  0.16690385341644287\n",
      "Eval Loss:  0.2626890242099762\n",
      "Eval Loss:  0.28875935077667236\n",
      "Eval Loss:  0.3315163850784302\n",
      "Eval Loss:  0.3441407084465027\n",
      "Eval Loss:  0.19038152694702148\n",
      "Eval Loss:  0.21767500042915344\n",
      "Eval Loss:  0.2473156452178955\n",
      "[[16699  1392]\n",
      " [ 1622 10104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     18091\n",
      "           1       0.88      0.86      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8989167253580173\n",
      "pre:  0.8789144050104384\n",
      "rec:  0.8616749104553982\n",
      "ma F1:  0.8937171874644171\n",
      "mi F1:  0.8989167253580173\n",
      "we F1:  0.8987353919667318\n",
      "29817 466\n",
      "Loss:  0.07410173863172531\n",
      "Loss:  0.04121595621109009\n",
      "Loss:  0.08014537394046783\n",
      "15 **********\n",
      "Epoch:  1536.173582792282  fold:  8  kers:  128\n",
      "epoch:  16\n",
      "29817 466\n",
      "Loss:  0.04089678078889847\n",
      "Loss:  0.07469549775123596\n",
      "Loss:  0.08012242615222931\n",
      "16 **********\n",
      "Epoch:  1617.7594389915466  fold:  8  kers:  128\n",
      "epoch:  17\n",
      "29817 466\n",
      "Loss:  0.04898228868842125\n",
      "Loss:  0.045067377388477325\n",
      "Loss:  0.05143412947654724\n",
      "17 **********\n",
      "Epoch:  1699.3083934783936  fold:  8  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.3972778618335724\n",
      "Eval Loss:  1.3962997198104858\n",
      "Eval Loss:  0.15044207870960236\n",
      "[[1918  155]\n",
      " [ 367  634]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      2073\n",
      "           1       0.80      0.63      0.71      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.82      0.78      0.79      3074\n",
      "weighted avg       0.83      0.83      0.82      3074\n",
      "\n",
      "acc:  0.8301886792452831\n",
      "pre:  0.8035487959442332\n",
      "rec:  0.6333666333666333\n",
      "ma F1:  0.7943000864011732\n",
      "mi F1:  0.8301886792452831\n",
      "we F1:  0.8242631483395576\n",
      "Eval Loss:  0.27425000071525574\n",
      "Eval Loss:  0.2811072766780853\n",
      "Eval Loss:  0.2170960158109665\n",
      "Eval Loss:  0.331662118434906\n",
      "Eval Loss:  0.25009578466415405\n",
      "Eval Loss:  0.2166287899017334\n",
      "Eval Loss:  0.4437689185142517\n",
      "Eval Loss:  0.2873961925506592\n",
      "Eval Loss:  0.2672930061817169\n",
      "Eval Loss:  0.18033374845981598\n",
      "Eval Loss:  0.25661501288414\n",
      "Eval Loss:  0.15811312198638916\n",
      "Eval Loss:  0.22945721447467804\n",
      "Eval Loss:  0.2534705698490143\n",
      "Eval Loss:  0.3187360465526581\n",
      "Eval Loss:  0.3173600137233734\n",
      "Eval Loss:  0.3179051876068115\n",
      "Eval Loss:  0.2540622353553772\n",
      "Eval Loss:  0.34082865715026855\n",
      "Eval Loss:  0.24841605126857758\n",
      "Eval Loss:  0.2774777114391327\n",
      "Eval Loss:  0.17614823579788208\n",
      "Eval Loss:  0.3036557137966156\n",
      "Eval Loss:  0.38296714425086975\n",
      "Eval Loss:  0.3456081748008728\n",
      "Eval Loss:  0.35303184390068054\n",
      "Eval Loss:  0.2253565639257431\n",
      "Eval Loss:  0.2811104953289032\n",
      "Eval Loss:  0.24977555871009827\n",
      "[[17333   758]\n",
      " [ 2468  9258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91     18091\n",
      "           1       0.92      0.79      0.85     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.87      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8918066874601738\n",
      "pre:  0.9243210862619808\n",
      "rec:  0.7895275456251066\n",
      "ma F1:  0.8832434406845777\n",
      "mi F1:  0.8918066874601738\n",
      "we F1:  0.8899932940253416\n",
      "29817 466\n",
      "Loss:  0.07247626036405563\n",
      "Loss:  0.10211382061243057\n",
      "Loss:  0.046364858746528625\n",
      "18 **********\n",
      "Epoch:  1824.0029854774475  fold:  8  kers:  128\n",
      "epoch:  19\n",
      "29817 466\n",
      "Loss:  0.058872371912002563\n",
      "Loss:  0.04764674976468086\n",
      "Loss:  0.0591139979660511\n",
      "19 **********\n",
      "Epoch:  1905.5848524570465  fold:  8  kers:  128\n",
      "epoch:  20\n",
      "29817 466\n",
      "Loss:  0.04520559310913086\n",
      "Loss:  0.1041996031999588\n",
      "Loss:  0.04822538420557976\n",
      "20 **********\n",
      "Epoch:  1987.1717054843903  fold:  8  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.5357578992843628\n",
      "Eval Loss:  1.2988914251327515\n",
      "Eval Loss:  0.1548536866903305\n",
      "[[1850  223]\n",
      " [ 311  690]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      2073\n",
      "           1       0.76      0.69      0.72      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.79      0.80      3074\n",
      "weighted avg       0.82      0.83      0.82      3074\n",
      "\n",
      "acc:  0.8262849707221861\n",
      "pre:  0.755750273822563\n",
      "rec:  0.6893106893106893\n",
      "ma F1:  0.7974406321123374\n",
      "mi F1:  0.8262849707221861\n",
      "we F1:  0.824096779517301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.26184970140457153\n",
      "Eval Loss:  0.2692282199859619\n",
      "Eval Loss:  0.1818016618490219\n",
      "Eval Loss:  0.28746628761291504\n",
      "Eval Loss:  0.20222744345664978\n",
      "Eval Loss:  0.20838291943073273\n",
      "Eval Loss:  0.42062458395957947\n",
      "Eval Loss:  0.2513425648212433\n",
      "Eval Loss:  0.2458026260137558\n",
      "Eval Loss:  0.1721109300851822\n",
      "Eval Loss:  0.19524769484996796\n",
      "Eval Loss:  0.1368822455406189\n",
      "Eval Loss:  0.22216796875\n",
      "Eval Loss:  0.25368696451187134\n",
      "Eval Loss:  0.2844700515270233\n",
      "Eval Loss:  0.3017754852771759\n",
      "Eval Loss:  0.29775843024253845\n",
      "Eval Loss:  0.2170846313238144\n",
      "Eval Loss:  0.26796138286590576\n",
      "Eval Loss:  0.24260163307189941\n",
      "Eval Loss:  0.2592897415161133\n",
      "Eval Loss:  0.1665097177028656\n",
      "Eval Loss:  0.2509799897670746\n",
      "Eval Loss:  0.3337245583534241\n",
      "Eval Loss:  0.28048914670944214\n",
      "Eval Loss:  0.32042720913887024\n",
      "Eval Loss:  0.19736063480377197\n",
      "Eval Loss:  0.25470322370529175\n",
      "Eval Loss:  0.23860672116279602\n",
      "[[17287   804]\n",
      " [ 2129  9597]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18091\n",
      "           1       0.92      0.82      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.91      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.9016332964416273\n",
      "pre:  0.922699740409576\n",
      "rec:  0.8184376599010745\n",
      "ma F1:  0.8946241371019158\n",
      "mi F1:  0.9016332964416273\n",
      "we F1:  0.9004256064383609\n",
      "29817 466\n",
      "Loss:  0.045352570712566376\n",
      "Loss:  0.04195058345794678\n",
      "Loss:  0.04529206454753876\n",
      "21 **********\n",
      "Epoch:  2111.8762712478638  fold:  8  kers:  128\n",
      "epoch:  22\n",
      "29817 466\n",
      "Loss:  0.05605613440275192\n",
      "Loss:  0.06680789589881897\n",
      "Loss:  0.08141525834798813\n",
      "22 **********\n",
      "Epoch:  2193.446169614792  fold:  8  kers:  128\n",
      "epoch:  23\n",
      "29817 466\n",
      "Loss:  0.09131435304880142\n",
      "Loss:  0.06620491296052933\n",
      "Loss:  0.04285344481468201\n",
      "23 **********\n",
      "Epoch:  2275.042996406555  fold:  8  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.8200681209564209\n",
      "Eval Loss:  0.9100439548492432\n",
      "Eval Loss:  0.2496435046195984\n",
      "[[1663  410]\n",
      " [ 211  790]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84      2073\n",
      "           1       0.66      0.79      0.72      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.77      0.80      0.78      3074\n",
      "weighted avg       0.81      0.80      0.80      3074\n",
      "\n",
      "acc:  0.7979830839297333\n",
      "pre:  0.6583333333333333\n",
      "rec:  0.7892107892107892\n",
      "ma F1:  0.7802604178237613\n",
      "mi F1:  0.7979830839297333\n",
      "we F1:  0.8020229585632823\n",
      "Eval Loss:  0.24066975712776184\n",
      "Eval Loss:  0.23734328150749207\n",
      "Eval Loss:  0.16331803798675537\n",
      "Eval Loss:  0.2281741350889206\n",
      "Eval Loss:  0.14655491709709167\n",
      "Eval Loss:  0.16982075572013855\n",
      "Eval Loss:  0.3662166893482208\n",
      "Eval Loss:  0.2183283418416977\n",
      "Eval Loss:  0.22083641588687897\n",
      "Eval Loss:  0.12375316023826599\n",
      "Eval Loss:  0.1476527899503708\n",
      "Eval Loss:  0.1553962230682373\n",
      "Eval Loss:  0.21563319861888885\n",
      "Eval Loss:  0.22571256756782532\n",
      "Eval Loss:  0.27609753608703613\n",
      "Eval Loss:  0.27482667565345764\n",
      "Eval Loss:  0.2524375021457672\n",
      "Eval Loss:  0.19252771139144897\n",
      "Eval Loss:  0.223580002784729\n",
      "Eval Loss:  0.20234355330467224\n",
      "Eval Loss:  0.22576996684074402\n",
      "Eval Loss:  0.17442668974399567\n",
      "Eval Loss:  0.25303375720977783\n",
      "Eval Loss:  0.3106344938278198\n",
      "Eval Loss:  0.30972787737846375\n",
      "Eval Loss:  0.32619932293891907\n",
      "Eval Loss:  0.16900719702243805\n",
      "Eval Loss:  0.2113453596830368\n",
      "Eval Loss:  0.19597524404525757\n",
      "[[16837  1254]\n",
      " [ 1384 10342]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18091\n",
      "           1       0.89      0.88      0.89     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9115269812523057\n",
      "pre:  0.8918592618144188\n",
      "rec:  0.8819716868497356\n",
      "ma F1:  0.9071198783002503\n",
      "mi F1:  0.9115269812523057\n",
      "we F1:  0.9114387713394855\n",
      "29817 466\n",
      "Loss:  0.08131998032331467\n",
      "Loss:  0.04502543807029724\n",
      "Loss:  0.0747089833021164\n",
      "24 **********\n",
      "Epoch:  2399.877215385437  fold:  8  kers:  128\n",
      "epoch:  25\n",
      "29817 466\n",
      "Loss:  0.040592778474092484\n",
      "Loss:  0.062375277280807495\n",
      "Loss:  0.06656014919281006\n",
      "25 **********\n",
      "Epoch:  2481.453097820282  fold:  8  kers:  128\n",
      "epoch:  26\n",
      "29817 466\n",
      "Loss:  0.07303107529878616\n",
      "Loss:  0.0601782463490963\n",
      "Loss:  0.06268610805273056\n",
      "26 **********\n",
      "Epoch:  2563.0598978996277  fold:  8  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.405143141746521\n",
      "Eval Loss:  1.4836000204086304\n",
      "Eval Loss:  0.16338972747325897\n",
      "[[1890  183]\n",
      " [ 329  672]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      2073\n",
      "           1       0.79      0.67      0.72      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.82      0.79      0.80      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8334417696811971\n",
      "pre:  0.7859649122807018\n",
      "rec:  0.6713286713286714\n",
      "ma F1:  0.8024231127679403\n",
      "mi F1:  0.8334417696811971\n",
      "we F1:  0.8297236055520218\n",
      "Eval Loss:  0.24280358850955963\n",
      "Eval Loss:  0.2308633029460907\n",
      "Eval Loss:  0.14822445809841156\n",
      "Eval Loss:  0.24284528195858002\n",
      "Eval Loss:  0.23042500019073486\n",
      "Eval Loss:  0.1658957153558731\n",
      "Eval Loss:  0.36579734086990356\n",
      "Eval Loss:  0.24530521035194397\n",
      "Eval Loss:  0.22884130477905273\n",
      "Eval Loss:  0.1213170737028122\n",
      "Eval Loss:  0.19286908209323883\n",
      "Eval Loss:  0.11804844439029694\n",
      "Eval Loss:  0.20014452934265137\n",
      "Eval Loss:  0.2116163969039917\n",
      "Eval Loss:  0.26807141304016113\n",
      "Eval Loss:  0.26948538422584534\n",
      "Eval Loss:  0.2512514293193817\n",
      "Eval Loss:  0.1987745612859726\n",
      "Eval Loss:  0.2545967102050781\n",
      "Eval Loss:  0.24292665719985962\n",
      "Eval Loss:  0.21684476733207703\n",
      "Eval Loss:  0.15525008738040924\n",
      "Eval Loss:  0.260547399520874\n",
      "Eval Loss:  0.2992804944515228\n",
      "Eval Loss:  0.2918206453323364\n",
      "Eval Loss:  0.33977389335632324\n",
      "Eval Loss:  0.16089791059494019\n",
      "Eval Loss:  0.21356722712516785\n",
      "Eval Loss:  0.21026653051376343\n",
      "[[17295   796]\n",
      " [ 1800  9926]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18091\n",
      "           1       0.93      0.85      0.88     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.92      0.90      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9129355736660294\n",
      "pre:  0.9257601193807126\n",
      "rec:  0.846494968446188\n",
      "ma F1:  0.907271867197317\n",
      "mi F1:  0.9129355736660294\n",
      "we F1:  0.9121639138350365\n",
      "29817 466\n",
      "Loss:  0.06843075156211853\n",
      "Loss:  0.056877318769693375\n",
      "Loss:  0.06530991941690445\n",
      "27 **********\n",
      "Epoch:  2687.700633764267  fold:  8  kers:  128\n",
      "epoch:  28\n",
      "29817 466\n",
      "Loss:  0.08598896861076355\n",
      "Loss:  0.05590290576219559\n",
      "Loss:  0.040366318076848984\n",
      "28 **********\n",
      "Epoch:  2769.2555730342865  fold:  8  kers:  128\n",
      "epoch:  29\n",
      "29817 466\n",
      "Loss:  0.03104410693049431\n",
      "Loss:  0.08061780035495758\n",
      "Loss:  0.02256666123867035\n",
      "29 **********\n",
      "Epoch:  2850.822479248047  fold:  8  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.4784865081310272\n",
      "Eval Loss:  1.1003729104995728\n",
      "Eval Loss:  0.17486520111560822\n",
      "[[1787  286]\n",
      " [ 239  762]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      2073\n",
      "           1       0.73      0.76      0.74      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.80      0.81      0.81      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8292127521145087\n",
      "pre:  0.7270992366412213\n",
      "rec:  0.7612387612387612\n",
      "ma F1:  0.8078487164494286\n",
      "mi F1:  0.8292127521145087\n",
      "we F1:  0.8301923713108588\n",
      "Eval Loss:  0.22955183684825897\n",
      "Eval Loss:  0.23317985236644745\n",
      "Eval Loss:  0.14128896594047546\n",
      "Eval Loss:  0.1943027377128601\n",
      "Eval Loss:  0.1996658891439438\n",
      "Eval Loss:  0.17156696319580078\n",
      "Eval Loss:  0.2985471189022064\n",
      "Eval Loss:  0.1851896494626999\n",
      "Eval Loss:  0.23529545962810516\n",
      "Eval Loss:  0.1029248833656311\n",
      "Eval Loss:  0.1344013810157776\n",
      "Eval Loss:  0.12374959886074066\n",
      "Eval Loss:  0.20157510042190552\n",
      "Eval Loss:  0.19687426090240479\n",
      "Eval Loss:  0.2687060236930847\n",
      "Eval Loss:  0.2691337764263153\n",
      "Eval Loss:  0.22773949801921844\n",
      "Eval Loss:  0.17236560583114624\n",
      "Eval Loss:  0.21485701203346252\n",
      "Eval Loss:  0.20893169939517975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20323118567466736\n",
      "Eval Loss:  0.20176845788955688\n",
      "Eval Loss:  0.2382996678352356\n",
      "Eval Loss:  0.27709075808525085\n",
      "Eval Loss:  0.3159697353839874\n",
      "Eval Loss:  0.31663286685943604\n",
      "Eval Loss:  0.17556101083755493\n",
      "Eval Loss:  0.193054661154747\n",
      "Eval Loss:  0.1811397820711136\n",
      "[[16946  1145]\n",
      " [ 1303 10423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18091\n",
      "           1       0.90      0.89      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.917899185028675\n",
      "pre:  0.9010200553250346\n",
      "rec:  0.8888794132696571\n",
      "ma F1:  0.9137723868415217\n",
      "mi F1:  0.917899185028675\n",
      "we F1:  0.917799225790047\n",
      "29817 466\n",
      "Loss:  0.07089446485042572\n",
      "Loss:  0.0643811821937561\n",
      "Loss:  0.05772535130381584\n",
      "30 **********\n",
      "Epoch:  2975.5689327716827  fold:  8  kers:  128\n",
      "epoch:  31\n",
      "29817 466\n",
      "Loss:  0.03471484035253525\n",
      "Loss:  0.050201475620269775\n",
      "Loss:  0.06088889017701149\n",
      "31 **********\n",
      "Epoch:  3057.15678358078  fold:  8  kers:  128\n",
      "epoch:  32\n",
      "29817 466\n",
      "Loss:  0.050828270614147186\n",
      "Loss:  0.07641495019197464\n",
      "Loss:  0.04780519753694534\n",
      "32 **********\n",
      "Epoch:  3138.709727525711  fold:  8  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.7252038717269897\n",
      "Eval Loss:  0.9471191167831421\n",
      "Eval Loss:  0.13590802252292633\n",
      "[[1888  185]\n",
      " [ 285  716]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      2073\n",
      "           1       0.79      0.72      0.75      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.83      0.81      0.82      3074\n",
      "weighted avg       0.84      0.85      0.84      3074\n",
      "\n",
      "acc:  0.8471047495120364\n",
      "pre:  0.7946725860155383\n",
      "rec:  0.7152847152847153\n",
      "ma F1:  0.8210996382814431\n",
      "mi F1:  0.8471047495120364\n",
      "we F1:  0.8448858833660814\n",
      "update!  Acc:  0.8471047495120364\n",
      "Eval Loss:  0.25912168622016907\n",
      "Eval Loss:  0.21856287121772766\n",
      "Eval Loss:  0.1281880885362625\n",
      "Eval Loss:  0.21358798444271088\n",
      "Eval Loss:  0.17736731469631195\n",
      "Eval Loss:  0.1488337367773056\n",
      "Eval Loss:  0.31859663128852844\n",
      "Eval Loss:  0.23831002414226532\n",
      "Eval Loss:  0.21553996205329895\n",
      "Eval Loss:  0.13722681999206543\n",
      "Eval Loss:  0.14498335123062134\n",
      "Eval Loss:  0.1579740196466446\n",
      "Eval Loss:  0.21171218156814575\n",
      "Eval Loss:  0.21107326447963715\n",
      "Eval Loss:  0.23768562078475952\n",
      "Eval Loss:  0.26210933923721313\n",
      "Eval Loss:  0.21133433282375336\n",
      "Eval Loss:  0.18403710424900055\n",
      "Eval Loss:  0.21044006943702698\n",
      "Eval Loss:  0.2199975699186325\n",
      "Eval Loss:  0.21369895339012146\n",
      "Eval Loss:  0.14718255400657654\n",
      "Eval Loss:  0.2522171437740326\n",
      "Eval Loss:  0.28115636110305786\n",
      "Eval Loss:  0.2724517583847046\n",
      "Eval Loss:  0.31301048398017883\n",
      "Eval Loss:  0.13686788082122803\n",
      "Eval Loss:  0.19840581715106964\n",
      "Eval Loss:  0.19836999475955963\n",
      "[[17321   770]\n",
      " [ 1706 10020]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18091\n",
      "           1       0.93      0.85      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9169601234195258\n",
      "pre:  0.9286376274328082\n",
      "rec:  0.8545113423162204\n",
      "ma F1:  0.9116637867426034\n",
      "mi F1:  0.9169601234195258\n",
      "we F1:  0.9162811244975152\n",
      "29817 466\n",
      "Loss:  0.04782508686184883\n",
      "Loss:  0.07764085382223129\n",
      "Loss:  0.057307206094264984\n",
      "33 **********\n",
      "Epoch:  3263.4791190624237  fold:  8  kers:  128\n",
      "epoch:  34\n",
      "29817 466\n",
      "Loss:  0.054766420274972916\n",
      "Loss:  0.05886734649538994\n",
      "Loss:  0.05595728009939194\n",
      "34 **********\n",
      "Epoch:  3345.0679671764374  fold:  8  kers:  128\n",
      "epoch:  35\n",
      "29817 466\n",
      "Loss:  0.06317455321550369\n",
      "Loss:  0.058914851397275925\n",
      "Loss:  0.029668617993593216\n",
      "35 **********\n",
      "Epoch:  3426.66180229187  fold:  8  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.8711540102958679\n",
      "Eval Loss:  1.1402537822723389\n",
      "Eval Loss:  0.23692621290683746\n",
      "[[1784  289]\n",
      " [ 223  778]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87      2073\n",
      "           1       0.73      0.78      0.75      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.82      0.81      3074\n",
      "weighted avg       0.84      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8334417696811971\n",
      "pre:  0.7291471415182755\n",
      "rec:  0.7772227772227772\n",
      "ma F1:  0.8134637994462774\n",
      "mi F1:  0.8334417696811971\n",
      "we F1:  0.8347524516250386\n",
      "Eval Loss:  0.24996821582317352\n",
      "Eval Loss:  0.20141497254371643\n",
      "Eval Loss:  0.16827760636806488\n",
      "Eval Loss:  0.18640996515750885\n",
      "Eval Loss:  0.18173155188560486\n",
      "Eval Loss:  0.1541922241449356\n",
      "Eval Loss:  0.30845388770103455\n",
      "Eval Loss:  0.22509446740150452\n",
      "Eval Loss:  0.20788046717643738\n",
      "Eval Loss:  0.11269210278987885\n",
      "Eval Loss:  0.15053817629814148\n",
      "Eval Loss:  0.15465302765369415\n",
      "Eval Loss:  0.17833656072616577\n",
      "Eval Loss:  0.19657763838768005\n",
      "Eval Loss:  0.23597590625286102\n",
      "Eval Loss:  0.26916101574897766\n",
      "Eval Loss:  0.19579117000102997\n",
      "Eval Loss:  0.1590847671031952\n",
      "Eval Loss:  0.2078208327293396\n",
      "Eval Loss:  0.2163604348897934\n",
      "Eval Loss:  0.212750643491745\n",
      "Eval Loss:  0.17009922862052917\n",
      "Eval Loss:  0.22239752113819122\n",
      "Eval Loss:  0.31157082319259644\n",
      "Eval Loss:  0.29628852009773254\n",
      "Eval Loss:  0.2743733823299408\n",
      "Eval Loss:  0.1348087042570114\n",
      "Eval Loss:  0.194472998380661\n",
      "Eval Loss:  0.18906593322753906\n",
      "[[17115   976]\n",
      " [ 1472 10254]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18091\n",
      "           1       0.91      0.87      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.917899185028675\n",
      "pre:  0.9130899376669634\n",
      "rec:  0.8744669964182159\n",
      "ma F1:  0.9133091030239087\n",
      "mi F1:  0.917899185028675\n",
      "we F1:  0.9175673557509655\n",
      "29817 466\n",
      "Loss:  0.03604546934366226\n",
      "Loss:  0.03325151652097702\n",
      "Loss:  0.09123261272907257\n",
      "36 **********\n",
      "Epoch:  3554.5149483680725  fold:  8  kers:  128\n",
      "epoch:  37\n",
      "29817 466\n",
      "Loss:  0.03910015523433685\n",
      "Loss:  0.05323033407330513\n",
      "Loss:  0.07290744036436081\n",
      "37 **********\n",
      "Epoch:  3636.095818042755  fold:  8  kers:  128\n",
      "epoch:  38\n",
      "29817 466\n",
      "Loss:  0.0960933119058609\n",
      "Loss:  0.0809401124715805\n",
      "Loss:  0.045301761478185654\n",
      "38 **********\n",
      "Epoch:  3717.792377948761  fold:  8  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.6925099492073059\n",
      "Eval Loss:  1.2188488245010376\n",
      "Eval Loss:  0.20155777037143707\n",
      "[[1834  239]\n",
      " [ 251  750]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      2073\n",
      "           1       0.76      0.75      0.75      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.82      0.82      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8405985686402082\n",
      "pre:  0.7583417593528817\n",
      "rec:  0.7492507492507493\n",
      "ma F1:  0.8179618631879939\n",
      "mi F1:  0.8405985686402082\n",
      "we F1:  0.8403479778049439\n",
      "Eval Loss:  0.2624092102050781\n",
      "Eval Loss:  0.22039766609668732\n",
      "Eval Loss:  0.15026603639125824\n",
      "Eval Loss:  0.1802886724472046\n",
      "Eval Loss:  0.14373835921287537\n",
      "Eval Loss:  0.14949573576450348\n",
      "Eval Loss:  0.31240496039390564\n",
      "Eval Loss:  0.2274678647518158\n",
      "Eval Loss:  0.21197228133678436\n",
      "Eval Loss:  0.10373885929584503\n",
      "Eval Loss:  0.16648417711257935\n",
      "Eval Loss:  0.14829474687576294\n",
      "Eval Loss:  0.17350153625011444\n",
      "Eval Loss:  0.19585177302360535\n",
      "Eval Loss:  0.24095067381858826\n",
      "Eval Loss:  0.29174166917800903\n",
      "Eval Loss:  0.2028394341468811\n",
      "Eval Loss:  0.18507808446884155\n",
      "Eval Loss:  0.17440955340862274\n",
      "Eval Loss:  0.24505376815795898\n",
      "Eval Loss:  0.22845374047756195\n",
      "Eval Loss:  0.16498467326164246\n",
      "Eval Loss:  0.2194405347108841\n",
      "Eval Loss:  0.317557692527771\n",
      "Eval Loss:  0.2931229770183563\n",
      "Eval Loss:  0.3060135543346405\n",
      "Eval Loss:  0.12616153061389923\n",
      "Eval Loss:  0.20701684057712555\n",
      "Eval Loss:  0.2045629769563675\n",
      "[[17179   912]\n",
      " [ 1558 10168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18091\n",
      "           1       0.92      0.87      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9171613509072006\n",
      "pre:  0.9176895306859206\n",
      "rec:  0.8671328671328671\n",
      "ma F1:  0.9123133165638957\n",
      "mi F1:  0.9171613509072006\n",
      "we F1:  0.916714648555785\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04246164485812187\n",
      "Loss:  0.044525016099214554\n",
      "Loss:  0.035026535391807556\n",
      "39 **********\n",
      "Epoch:  3842.404191017151  fold:  8  kers:  128\n",
      "epoch:  40\n",
      "29817 466\n",
      "Loss:  0.07193975150585175\n",
      "Loss:  0.07169690728187561\n",
      "Loss:  0.049860335886478424\n",
      "40 **********\n",
      "Epoch:  3924.0129854679108  fold:  8  kers:  128\n",
      "epoch:  41\n",
      "29817 466\n",
      "Loss:  0.0441405326128006\n",
      "Loss:  0.04820273444056511\n",
      "Loss:  0.06006009504199028\n",
      "41 **********\n",
      "Epoch:  4005.6387350559235  fold:  8  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.3462352454662323\n",
      "Eval Loss:  1.075713872909546\n",
      "Eval Loss:  0.13635188341140747\n",
      "[[1884  189]\n",
      " [ 278  723]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      2073\n",
      "           1       0.79      0.72      0.76      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.83      0.82      0.82      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8480806766428106\n",
      "pre:  0.7927631578947368\n",
      "rec:  0.7222777222777222\n",
      "ma F1:  0.8228046344189479\n",
      "mi F1:  0.8480806766428105\n",
      "we F1:  0.8461430644482166\n",
      "update!  Acc:  0.8480806766428106\n",
      "Eval Loss:  0.23040471971035004\n",
      "Eval Loss:  0.20434537529945374\n",
      "Eval Loss:  0.12975259125232697\n",
      "Eval Loss:  0.19224902987480164\n",
      "Eval Loss:  0.2139386534690857\n",
      "Eval Loss:  0.13992372155189514\n",
      "Eval Loss:  0.2853460907936096\n",
      "Eval Loss:  0.18347227573394775\n",
      "Eval Loss:  0.19963476061820984\n",
      "Eval Loss:  0.11196950823068619\n",
      "Eval Loss:  0.15340326726436615\n",
      "Eval Loss:  0.14411252737045288\n",
      "Eval Loss:  0.1849011331796646\n",
      "Eval Loss:  0.17926837503910065\n",
      "Eval Loss:  0.2108241766691208\n",
      "Eval Loss:  0.24630211293697357\n",
      "Eval Loss:  0.21526750922203064\n",
      "Eval Loss:  0.16274861991405487\n",
      "Eval Loss:  0.18412797152996063\n",
      "Eval Loss:  0.21427935361862183\n",
      "Eval Loss:  0.21294961869716644\n",
      "Eval Loss:  0.14807413518428802\n",
      "Eval Loss:  0.22226911783218384\n",
      "Eval Loss:  0.2827773690223694\n",
      "Eval Loss:  0.260118693113327\n",
      "Eval Loss:  0.2744378447532654\n",
      "Eval Loss:  0.13942590355873108\n",
      "Eval Loss:  0.19265085458755493\n",
      "Eval Loss:  0.1844354122877121\n",
      "[[17437   654]\n",
      " [ 1593 10133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18091\n",
      "           1       0.94      0.86      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.93      0.91      0.92     29817\n",
      "weighted avg       0.93      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9246403058657813\n",
      "pre:  0.9393714656531009\n",
      "rec:  0.8641480470748764\n",
      "ma F1:  0.9198296131439183\n",
      "mi F1:  0.9246403058657813\n",
      "we F1:  0.9240218446848079\n",
      "29817 466\n",
      "Loss:  0.02960093505680561\n",
      "Loss:  0.050216350704431534\n",
      "Loss:  0.03070778213441372\n",
      "42 **********\n",
      "Epoch:  4130.334324598312  fold:  8  kers:  128\n",
      "epoch:  43\n",
      "29817 466\n",
      "Loss:  0.04622456431388855\n",
      "Loss:  0.03224557638168335\n",
      "Loss:  0.026402046903967857\n",
      "43 **********\n",
      "Epoch:  4211.754623413086  fold:  8  kers:  128\n",
      "epoch:  44\n",
      "29817 466\n",
      "Loss:  0.04343187063932419\n",
      "Loss:  0.05364210903644562\n",
      "Loss:  0.03668292611837387\n",
      "44 **********\n",
      "Epoch:  4293.219801664352  fold:  8  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.5814826488494873\n",
      "Eval Loss:  1.1144027709960938\n",
      "Eval Loss:  0.13365717232227325\n",
      "[[1925  148]\n",
      " [ 323  678]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      2073\n",
      "           1       0.82      0.68      0.74      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.80      0.82      3074\n",
      "weighted avg       0.84      0.85      0.84      3074\n",
      "\n",
      "acc:  0.846779440468445\n",
      "pre:  0.8208232445520581\n",
      "rec:  0.6773226773226774\n",
      "ma F1:  0.8165988913501063\n",
      "mi F1:  0.846779440468445\n",
      "we F1:  0.8425439985312284\n",
      "Eval Loss:  0.2550278306007385\n",
      "Eval Loss:  0.245580792427063\n",
      "Eval Loss:  0.1343107968568802\n",
      "Eval Loss:  0.20283105969429016\n",
      "Eval Loss:  0.23307150602340698\n",
      "Eval Loss:  0.14251163601875305\n",
      "Eval Loss:  0.31070148944854736\n",
      "Eval Loss:  0.18443390727043152\n",
      "Eval Loss:  0.19293977320194244\n",
      "Eval Loss:  0.11940398067235947\n",
      "Eval Loss:  0.14864078164100647\n",
      "Eval Loss:  0.15526671707630157\n",
      "Eval Loss:  0.18896786868572235\n",
      "Eval Loss:  0.16920022666454315\n",
      "Eval Loss:  0.20877033472061157\n",
      "Eval Loss:  0.21168939769268036\n",
      "Eval Loss:  0.23938749730587006\n",
      "Eval Loss:  0.16240721940994263\n",
      "Eval Loss:  0.19791603088378906\n",
      "Eval Loss:  0.22837437689304352\n",
      "Eval Loss:  0.19759072363376617\n",
      "Eval Loss:  0.1803579479455948\n",
      "Eval Loss:  0.22102898359298706\n",
      "Eval Loss:  0.24142220616340637\n",
      "Eval Loss:  0.2371675968170166\n",
      "Eval Loss:  0.27260828018188477\n",
      "Eval Loss:  0.11863226443529129\n",
      "Eval Loss:  0.21125376224517822\n",
      "Eval Loss:  0.19368261098861694\n",
      "[[17504   587]\n",
      " [ 1632 10094]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     18091\n",
      "           1       0.95      0.86      0.90     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.91      0.92     29817\n",
      "weighted avg       0.93      0.93      0.92     29817\n",
      "\n",
      "acc:  0.9255793674749304\n",
      "pre:  0.9450425990075836\n",
      "rec:  0.8608221047245438\n",
      "ma F1:  0.9206805865350172\n",
      "mi F1:  0.9255793674749304\n",
      "we F1:  0.9248885137526349\n",
      "29817 466\n",
      "Loss:  0.04225101321935654\n",
      "Loss:  0.04193076118826866\n",
      "Loss:  0.06502102315425873\n",
      "45 **********\n",
      "Epoch:  4417.991188526154  fold:  8  kers:  128\n",
      "epoch:  46\n",
      "29817 466\n",
      "Loss:  0.03335031867027283\n",
      "Loss:  0.08956301212310791\n",
      "Loss:  0.02404511347413063\n",
      "46 **********\n",
      "Epoch:  4499.452377796173  fold:  8  kers:  128\n",
      "epoch:  47\n",
      "29817 466\n",
      "Loss:  0.038328204303979874\n",
      "Loss:  0.016739709302783012\n",
      "Loss:  0.05962992459535599\n",
      "47 **********\n",
      "Epoch:  4580.92254281044  fold:  8  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.7400913238525391\n",
      "Eval Loss:  1.0292396545410156\n",
      "Eval Loss:  0.122303307056427\n",
      "[[1809  264]\n",
      " [ 252  749]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      2073\n",
      "           1       0.74      0.75      0.74      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.81      0.81      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8321405335068315\n",
      "pre:  0.7393879565646594\n",
      "rec:  0.7482517482517482\n",
      "ma F1:  0.8094874341150409\n",
      "mi F1:  0.8321405335068315\n",
      "we F1:  0.8323969836886254\n",
      "Eval Loss:  0.22258327901363373\n",
      "Eval Loss:  0.18354108929634094\n",
      "Eval Loss:  0.09178042411804199\n",
      "Eval Loss:  0.16090455651283264\n",
      "Eval Loss:  0.16213072836399078\n",
      "Eval Loss:  0.13411779701709747\n",
      "Eval Loss:  0.24740749597549438\n",
      "Eval Loss:  0.18050606548786163\n",
      "Eval Loss:  0.20855960249900818\n",
      "Eval Loss:  0.10160712897777557\n",
      "Eval Loss:  0.16223880648612976\n",
      "Eval Loss:  0.15572567284107208\n",
      "Eval Loss:  0.20455050468444824\n",
      "Eval Loss:  0.1580408215522766\n",
      "Eval Loss:  0.19357605278491974\n",
      "Eval Loss:  0.21929045021533966\n",
      "Eval Loss:  0.18522413074970245\n",
      "Eval Loss:  0.1635894477367401\n",
      "Eval Loss:  0.16407574713230133\n",
      "Eval Loss:  0.21370713412761688\n",
      "Eval Loss:  0.19675011932849884\n",
      "Eval Loss:  0.16919437050819397\n",
      "Eval Loss:  0.22363069653511047\n",
      "Eval Loss:  0.2582988440990448\n",
      "Eval Loss:  0.240610733628273\n",
      "Eval Loss:  0.25015953183174133\n",
      "Eval Loss:  0.10597220063209534\n",
      "Eval Loss:  0.18502730131149292\n",
      "Eval Loss:  0.1575648933649063\n",
      "[[17234   857]\n",
      " [ 1221 10505]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18091\n",
      "           1       0.92      0.90      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.92      0.93     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9303082134352886\n",
      "pre:  0.9245731385319486\n",
      "rec:  0.8958724202626641\n",
      "ma F1:  0.9265683435667837\n",
      "mi F1:  0.9303082134352887\n",
      "we F1:  0.9301059080953962\n",
      "29817 466\n",
      "Loss:  0.05909111350774765\n",
      "Loss:  0.08009348809719086\n",
      "Loss:  0.023321660235524178\n",
      "48 **********\n",
      "Epoch:  4705.596190929413  fold:  8  kers:  128\n",
      "epoch:  49\n",
      "29817 466\n",
      "Loss:  0.038368407636880875\n",
      "Loss:  0.0697212964296341\n",
      "Loss:  0.03539875149726868\n",
      "49 **********\n",
      "Epoch:  4787.034441947937  fold:  8  kers:  128\n",
      "epoch:  50\n",
      "29817 466\n",
      "Loss:  0.02900616265833378\n",
      "Loss:  0.0444832444190979\n",
      "Loss:  0.07035265117883682\n",
      "50 **********\n",
      "Epoch:  4868.520564317703  fold:  8  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.6146228313446045\n",
      "Eval Loss:  1.081239938735962\n",
      "Eval Loss:  0.13869409263134003\n",
      "[[1875  198]\n",
      " [ 272  729]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89      2073\n",
      "           1       0.79      0.73      0.76      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.83      0.82      0.82      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8471047495120364\n",
      "pre:  0.7864077669902912\n",
      "rec:  0.7282717282717283\n",
      "ma F1:  0.8224248294035514\n",
      "mi F1:  0.8471047495120364\n",
      "we F1:  0.8455111072013664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20937088131904602\n",
      "Eval Loss:  0.178659126162529\n",
      "Eval Loss:  0.11999092251062393\n",
      "Eval Loss:  0.15442728996276855\n",
      "Eval Loss:  0.15545476973056793\n",
      "Eval Loss:  0.13061964511871338\n",
      "Eval Loss:  0.2579045593738556\n",
      "Eval Loss:  0.19405312836170197\n",
      "Eval Loss:  0.18197348713874817\n",
      "Eval Loss:  0.0829935073852539\n",
      "Eval Loss:  0.14475779235363007\n",
      "Eval Loss:  0.14281748235225677\n",
      "Eval Loss:  0.16899541020393372\n",
      "Eval Loss:  0.16947634518146515\n",
      "Eval Loss:  0.20799216628074646\n",
      "Eval Loss:  0.2548322081565857\n",
      "Eval Loss:  0.1756182610988617\n",
      "Eval Loss:  0.15311473608016968\n",
      "Eval Loss:  0.15971432626247406\n",
      "Eval Loss:  0.1900215446949005\n",
      "Eval Loss:  0.18594807386398315\n",
      "Eval Loss:  0.14038614928722382\n",
      "Eval Loss:  0.20281481742858887\n",
      "Eval Loss:  0.2332005500793457\n",
      "Eval Loss:  0.2245924025774002\n",
      "Eval Loss:  0.24637877941131592\n",
      "Eval Loss:  0.11283241212368011\n",
      "Eval Loss:  0.17890676856040955\n",
      "Eval Loss:  0.16264772415161133\n",
      "[[17376   715]\n",
      " [ 1359 10367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     18091\n",
      "           1       0.94      0.88      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.92      0.93     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9304423650937385\n",
      "pre:  0.9354809601155026\n",
      "rec:  0.8841037011768719\n",
      "ma F1:  0.9263740444578992\n",
      "mi F1:  0.9304423650937385\n",
      "we F1:  0.9300685602015312\n",
      "29817 466\n",
      "Loss:  0.053719136863946915\n",
      "Loss:  0.09122771769762039\n",
      "Loss:  0.04698313772678375\n",
      "51 **********\n",
      "Epoch:  4993.105449914932  fold:  8  kers:  128\n",
      "epoch:  52\n",
      "29817 466\n",
      "Loss:  0.030295636504888535\n",
      "Loss:  0.04955068975687027\n",
      "Loss:  0.04664134234189987\n",
      "52 **********\n",
      "Epoch:  5074.5317323207855  fold:  8  kers:  128\n",
      "epoch:  53\n",
      "29817 466\n",
      "Loss:  0.028323443606495857\n",
      "Loss:  0.06320595741271973\n",
      "Loss:  0.0226577315479517\n",
      "53 **********\n",
      "Epoch:  5155.966990947723  fold:  8  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.7574827075004578\n",
      "Eval Loss:  1.1409612894058228\n",
      "Eval Loss:  0.21324902772903442\n",
      "[[1794  279]\n",
      " [ 209  792]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      2073\n",
      "           1       0.74      0.79      0.76      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.82      0.83      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.841249186727391\n",
      "pre:  0.7394957983193278\n",
      "rec:  0.7912087912087912\n",
      "ma F1:  0.822376771837027\n",
      "mi F1:  0.841249186727391\n",
      "we F1:  0.8425676189053606\n",
      "Eval Loss:  0.22393105924129486\n",
      "Eval Loss:  0.1984805166721344\n",
      "Eval Loss:  0.12054488062858582\n",
      "Eval Loss:  0.15873795747756958\n",
      "Eval Loss:  0.14009498059749603\n",
      "Eval Loss:  0.14008359611034393\n",
      "Eval Loss:  0.2386893928050995\n",
      "Eval Loss:  0.17081019282341003\n",
      "Eval Loss:  0.1770978569984436\n",
      "Eval Loss:  0.09641868621110916\n",
      "Eval Loss:  0.12047331035137177\n",
      "Eval Loss:  0.1238994300365448\n",
      "Eval Loss:  0.1586124449968338\n",
      "Eval Loss:  0.1775568723678589\n",
      "Eval Loss:  0.20892414450645447\n",
      "Eval Loss:  0.22937847673892975\n",
      "Eval Loss:  0.1929250955581665\n",
      "Eval Loss:  0.17363794147968292\n",
      "Eval Loss:  0.15252889692783356\n",
      "Eval Loss:  0.186076357960701\n",
      "Eval Loss:  0.1955735683441162\n",
      "Eval Loss:  0.1849871426820755\n",
      "Eval Loss:  0.20454545319080353\n",
      "Eval Loss:  0.2507549524307251\n",
      "Eval Loss:  0.2718288004398346\n",
      "Eval Loss:  0.2388993352651596\n",
      "Eval Loss:  0.14489389955997467\n",
      "Eval Loss:  0.16181433200836182\n",
      "Eval Loss:  0.1843164712190628\n",
      "[[17143   948]\n",
      " [ 1072 10654]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18091\n",
      "           1       0.92      0.91      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.93      0.93     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9322534124828118\n",
      "pre:  0.9182899500086192\n",
      "rec:  0.9085792256523963\n",
      "ma F1:  0.9288852963119384\n",
      "mi F1:  0.9322534124828118\n",
      "we F1:  0.9321890502690365\n",
      "29817 466\n",
      "Loss:  0.06687712669372559\n",
      "Loss:  0.04594248905777931\n",
      "Loss:  0.05117950960993767\n",
      "54 **********\n",
      "Epoch:  5280.546889781952  fold:  8  kers:  128\n",
      "epoch:  55\n",
      "29817 466\n",
      "Loss:  0.04279742017388344\n",
      "Loss:  0.03289792686700821\n",
      "Loss:  0.04967053234577179\n",
      "55 **********\n",
      "Epoch:  5361.978159427643  fold:  8  kers:  128\n",
      "epoch:  56\n",
      "29817 466\n",
      "Loss:  0.04108384624123573\n",
      "Loss:  0.04555181413888931\n",
      "Loss:  0.07496684044599533\n",
      "56 **********\n",
      "Epoch:  5443.437353849411  fold:  8  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.4071701765060425\n",
      "Eval Loss:  1.2383923530578613\n",
      "Eval Loss:  0.16053453087806702\n",
      "[[1864  209]\n",
      " [ 246  755]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      2073\n",
      "           1       0.78      0.75      0.77      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.83      0.83      0.83      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8519843851659076\n",
      "pre:  0.783195020746888\n",
      "rec:  0.7542457542457542\n",
      "ma F1:  0.8298371148456827\n",
      "mi F1:  0.8519843851659075\n",
      "we F1:  0.8512454771389929\n",
      "update!  Acc:  0.8519843851659076\n",
      "Eval Loss:  0.2167876809835434\n",
      "Eval Loss:  0.19638629257678986\n",
      "Eval Loss:  0.12969188392162323\n",
      "Eval Loss:  0.1369960606098175\n",
      "Eval Loss:  0.17803901433944702\n",
      "Eval Loss:  0.17612245678901672\n",
      "Eval Loss:  0.24836619198322296\n",
      "Eval Loss:  0.17994371056556702\n",
      "Eval Loss:  0.18611745536327362\n",
      "Eval Loss:  0.07958804070949554\n",
      "Eval Loss:  0.13412269949913025\n",
      "Eval Loss:  0.11751134693622589\n",
      "Eval Loss:  0.16241684556007385\n",
      "Eval Loss:  0.17659488320350647\n",
      "Eval Loss:  0.20763608813285828\n",
      "Eval Loss:  0.24238933622837067\n",
      "Eval Loss:  0.20066110789775848\n",
      "Eval Loss:  0.13219857215881348\n",
      "Eval Loss:  0.17721043527126312\n",
      "Eval Loss:  0.18803222477436066\n",
      "Eval Loss:  0.1962377429008484\n",
      "Eval Loss:  0.1806984692811966\n",
      "Eval Loss:  0.1906963437795639\n",
      "Eval Loss:  0.25966423749923706\n",
      "Eval Loss:  0.29852166771888733\n",
      "Eval Loss:  0.2381516695022583\n",
      "Eval Loss:  0.1314641833305359\n",
      "Eval Loss:  0.16001421213150024\n",
      "Eval Loss:  0.16243819892406464\n",
      "[[17175   916]\n",
      " [ 1162 10564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18091\n",
      "           1       0.92      0.90      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.93      0.93     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9303082134352886\n",
      "pre:  0.9202090592334494\n",
      "rec:  0.9009039740747058\n",
      "ma F1:  0.9267050804089516\n",
      "mi F1:  0.9303082134352887\n",
      "we F1:  0.9301741382992306\n",
      "29817 466\n",
      "Loss:  0.041172415018081665\n",
      "Loss:  0.025348730385303497\n",
      "Loss:  0.046388134360313416\n",
      "57 **********\n",
      "Epoch:  5567.949434041977  fold:  8  kers:  128\n",
      "epoch:  58\n",
      "29817 466\n",
      "Loss:  0.05312434211373329\n",
      "Loss:  0.036306772381067276\n",
      "Loss:  0.07815926522016525\n",
      "58 **********\n",
      "Epoch:  5649.394665956497  fold:  8  kers:  128\n",
      "epoch:  59\n",
      "29817 466\n",
      "Loss:  0.0362962931394577\n",
      "Loss:  0.030364125967025757\n",
      "Loss:  0.04332038387656212\n",
      "59 **********\n",
      "Epoch:  5730.8548579216  fold:  8  kers:  128\n",
      "Eval Loss:  0.9571300148963928\n",
      "Eval Loss:  1.0510995388031006\n",
      "Eval Loss:  0.27879083156585693\n",
      "[[1761  312]\n",
      " [ 182  819]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88      2073\n",
      "           1       0.72      0.82      0.77      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.82      0.83      0.82      3074\n",
      "weighted avg       0.85      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8392973324658426\n",
      "pre:  0.7241379310344828\n",
      "rec:  0.8181818181818182\n",
      "ma F1:  0.8226423573996697\n",
      "mi F1:  0.8392973324658426\n",
      "we F1:  0.841595789746737\n",
      "update!  Acc:  0.8519843851659076\n",
      "Epoch:  5734.888073682785  fold:  8  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29483 3408\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29483 461\n",
      "Loss:  0.1704016774892807\n",
      "Loss:  0.16662093997001648\n",
      "Loss:  0.16670210659503937\n",
      "0 **********\n",
      "Epoch:  92.74402046203613  fold:  9  kers:  128\n",
      "epoch:  1\n",
      "29483 461\n",
      "Loss:  0.14816612005233765\n",
      "Loss:  0.1404891312122345\n",
      "Loss:  0.12133706361055374\n",
      "1 **********\n",
      "Epoch:  173.21086812019348  fold:  9  kers:  128\n",
      "epoch:  2\n",
      "29483 461\n",
      "Loss:  0.13037191331386566\n",
      "Loss:  0.0915689468383789\n",
      "Loss:  0.09280355274677277\n",
      "2 **********\n",
      "Epoch:  253.7445375919342  fold:  9  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.2270161211490631\n",
      "Eval Loss:  1.0638326406478882\n",
      "Eval Loss:  0.3546285033226013\n",
      "[[1568  174]\n",
      " [ 463 1203]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83      1742\n",
      "           1       0.87      0.72      0.79      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.82      0.81      0.81      3408\n",
      "weighted avg       0.82      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8130868544600939\n",
      "pre:  0.8736383442265795\n",
      "rec:  0.7220888355342137\n",
      "ma F1:  0.8109179679997951\n",
      "mi F1:  0.8130868544600938\n",
      "we F1:  0.8113695717559123\n",
      "update!  Acc:  0.8130868544600939\n",
      "Eval Loss:  0.37421470880508423\n",
      "Eval Loss:  0.4200754165649414\n",
      "Eval Loss:  0.4427753686904907\n",
      "Eval Loss:  0.45271560549736023\n",
      "Eval Loss:  0.43891340494155884\n",
      "Eval Loss:  0.4884489178657532\n",
      "Eval Loss:  0.5369462966918945\n",
      "Eval Loss:  0.4962913393974304\n",
      "Eval Loss:  0.41361260414123535\n",
      "Eval Loss:  0.36882832646369934\n",
      "Eval Loss:  0.4987115263938904\n",
      "Eval Loss:  0.4063595235347748\n",
      "Eval Loss:  0.4088851511478424\n",
      "Eval Loss:  0.4807572066783905\n",
      "Eval Loss:  0.4420805275440216\n",
      "Eval Loss:  0.43223264813423157\n",
      "Eval Loss:  0.4331987500190735\n",
      "Eval Loss:  0.37487325072288513\n",
      "Eval Loss:  0.3890712261199951\n",
      "Eval Loss:  0.4498812258243561\n",
      "Eval Loss:  0.4465084969997406\n",
      "Eval Loss:  0.38446199893951416\n",
      "Eval Loss:  0.3577708601951599\n",
      "Eval Loss:  0.49221372604370117\n",
      "Eval Loss:  0.401501327753067\n",
      "Eval Loss:  0.4205288887023926\n",
      "Eval Loss:  0.40807175636291504\n",
      "Eval Loss:  0.37258365750312805\n",
      "[[16347  2075]\n",
      " [ 3685  7376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85     18422\n",
      "           1       0.78      0.67      0.72     11061\n",
      "\n",
      "    accuracy                           0.80     29483\n",
      "   macro avg       0.80      0.78      0.78     29483\n",
      "weighted avg       0.80      0.80      0.80     29483\n",
      "\n",
      "acc:  0.8046331784418139\n",
      "pre:  0.7804465135964448\n",
      "rec:  0.6668474821444715\n",
      "ma F1:  0.784699704418197\n",
      "mi F1:  0.8046331784418139\n",
      "we F1:  0.8010557742306867\n",
      "29483 461\n",
      "Loss:  0.14513923227787018\n",
      "Loss:  0.11396962404251099\n",
      "Loss:  0.10606174916028976\n",
      "3 **********\n",
      "Epoch:  377.52956199645996  fold:  9  kers:  128\n",
      "epoch:  4\n",
      "29483 461\n",
      "Loss:  0.08072645962238312\n",
      "Loss:  0.07400691509246826\n",
      "Loss:  0.07319643348455429\n",
      "4 **********\n",
      "Epoch:  458.03829741477966  fold:  9  kers:  128\n",
      "epoch:  5\n",
      "29483 461\n",
      "Loss:  0.10034829378128052\n",
      "Loss:  0.12370166927576065\n",
      "Loss:  0.07484494149684906\n",
      "5 **********\n",
      "Epoch:  538.530079126358  fold:  9  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.0762350931763649\n",
      "Eval Loss:  1.9219136238098145\n",
      "Eval Loss:  0.33318039774894714\n",
      "[[1676   66]\n",
      " [ 659 1007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      1742\n",
      "           1       0.94      0.60      0.74      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.83      0.78      0.78      3408\n",
      "weighted avg       0.83      0.79      0.78      3408\n",
      "\n",
      "acc:  0.7872652582159625\n",
      "pre:  0.9384902143522833\n",
      "rec:  0.6044417767106842\n",
      "ma F1:  0.7787390111654056\n",
      "mi F1:  0.7872652582159625\n",
      "we F1:  0.7797076132219711\n",
      "Eval Loss:  0.3682743012905121\n",
      "Eval Loss:  0.3429756462574005\n",
      "Eval Loss:  0.3731110692024231\n",
      "Eval Loss:  0.40436750650405884\n",
      "Eval Loss:  0.4612874686717987\n",
      "Eval Loss:  0.420463889837265\n",
      "Eval Loss:  0.49193593859672546\n",
      "Eval Loss:  0.5293944478034973\n",
      "Eval Loss:  0.38705289363861084\n",
      "Eval Loss:  0.30505311489105225\n",
      "Eval Loss:  0.5006390810012817\n",
      "Eval Loss:  0.40003639459609985\n",
      "Eval Loss:  0.37393617630004883\n",
      "Eval Loss:  0.44549426436424255\n",
      "Eval Loss:  0.423505961894989\n",
      "Eval Loss:  0.43048515915870667\n",
      "Eval Loss:  0.39629337191581726\n",
      "Eval Loss:  0.3375788927078247\n",
      "Eval Loss:  0.3589209020137787\n",
      "Eval Loss:  0.4663887619972229\n",
      "Eval Loss:  0.3880385458469391\n",
      "Eval Loss:  0.34781932830810547\n",
      "Eval Loss:  0.31110870838165283\n",
      "Eval Loss:  0.47290343046188354\n",
      "Eval Loss:  0.379207044839859\n",
      "Eval Loss:  0.36793819069862366\n",
      "Eval Loss:  0.3791685104370117\n",
      "Eval Loss:  0.31945207715034485\n",
      "[[17750   672]\n",
      " [ 4167  6894]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88     18422\n",
      "           1       0.91      0.62      0.74     11061\n",
      "\n",
      "    accuracy                           0.84     29483\n",
      "   macro avg       0.86      0.79      0.81     29483\n",
      "weighted avg       0.85      0.84      0.83     29483\n",
      "\n",
      "acc:  0.8358715191805447\n",
      "pre:  0.9111816019032514\n",
      "rec:  0.6232709519934907\n",
      "ma F1:  0.8101287313963268\n",
      "mi F1:  0.8358715191805447\n",
      "we F1:  0.8275838401730059\n",
      "29483 461\n",
      "Loss:  0.06426118314266205\n",
      "Loss:  0.08533231914043427\n",
      "Loss:  0.08672970533370972\n",
      "6 **********\n",
      "Epoch:  662.2432949542999  fold:  9  kers:  128\n",
      "epoch:  7\n",
      "29483 461\n",
      "Loss:  0.09627468883991241\n",
      "Loss:  0.09783891588449478\n",
      "Loss:  0.06781298667192459\n",
      "7 **********\n",
      "Epoch:  742.7071511745453  fold:  9  kers:  128\n",
      "epoch:  8\n",
      "29483 461\n",
      "Loss:  0.056162506341934204\n",
      "Loss:  0.04072662070393562\n",
      "Loss:  0.05595020204782486\n",
      "8 **********\n",
      "Epoch:  823.2089054584503  fold:  9  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.07291332632303238\n",
      "Eval Loss:  1.2023919820785522\n",
      "Eval Loss:  0.2180081158876419\n",
      "[[1625  117]\n",
      " [ 432 1234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86      1742\n",
      "           1       0.91      0.74      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8389084507042254\n",
      "pre:  0.9133974833456698\n",
      "rec:  0.7406962785114045\n",
      "ma F1:  0.836759721584706\n",
      "mi F1:  0.8389084507042254\n",
      "we F1:  0.8371773773726433\n",
      "update!  Acc:  0.8389084507042254\n",
      "Eval Loss:  0.27416887879371643\n",
      "Eval Loss:  0.26756665110588074\n",
      "Eval Loss:  0.2780075967311859\n",
      "Eval Loss:  0.2635379731655121\n",
      "Eval Loss:  0.26078158617019653\n",
      "Eval Loss:  0.24809828400611877\n",
      "Eval Loss:  0.3486182391643524\n",
      "Eval Loss:  0.3260098099708557\n",
      "Eval Loss:  0.25132888555526733\n",
      "Eval Loss:  0.26152244210243225\n",
      "Eval Loss:  0.2918165326118469\n",
      "Eval Loss:  0.2949163615703583\n",
      "Eval Loss:  0.2567993402481079\n",
      "Eval Loss:  0.3276607394218445\n",
      "Eval Loss:  0.28687015175819397\n",
      "Eval Loss:  0.2766053080558777\n",
      "Eval Loss:  0.3081704080104828\n",
      "Eval Loss:  0.24733991920948029\n",
      "Eval Loss:  0.2859956920146942\n",
      "Eval Loss:  0.34927263855934143\n",
      "Eval Loss:  0.25180232524871826\n",
      "Eval Loss:  0.30650565028190613\n",
      "Eval Loss:  0.21339739859104156\n",
      "Eval Loss:  0.3422641158103943\n",
      "Eval Loss:  0.2698991298675537\n",
      "Eval Loss:  0.2914735674858093\n",
      "Eval Loss:  0.25639042258262634\n",
      "Eval Loss:  0.22636860609054565\n",
      "[[17083  1339]\n",
      " [ 2007  9054]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18422\n",
      "           1       0.87      0.82      0.84     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.88      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8865108706712342\n",
      "pre:  0.8711632829789281\n",
      "rec:  0.8185516680227828\n",
      "ma F1:  0.8774201422444541\n",
      "mi F1:  0.8865108706712342\n",
      "we F1:  0.8857545365587558\n",
      "29483 461\n",
      "Loss:  0.06246354430913925\n",
      "Loss:  0.06860002130270004\n",
      "Loss:  0.11381393671035767\n",
      "9 **********\n",
      "Epoch:  947.1564955711365  fold:  9  kers:  128\n",
      "epoch:  10\n",
      "29483 461\n",
      "Loss:  0.10595758259296417\n",
      "Loss:  0.09039812535047531\n",
      "Loss:  0.06969968974590302\n",
      "10 **********\n",
      "Epoch:  1027.7131028175354  fold:  9  kers:  128\n",
      "epoch:  11\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07352501899003983\n",
      "Loss:  0.04796047881245613\n",
      "Loss:  0.07754673808813095\n",
      "11 **********\n",
      "Epoch:  1108.30162525177  fold:  9  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.03409457206726074\n",
      "Eval Loss:  1.7626274824142456\n",
      "Eval Loss:  0.21196983754634857\n",
      "[[1681   61]\n",
      " [ 592 1074]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.84      1742\n",
      "           1       0.95      0.64      0.77      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.80      0.80      3408\n",
      "weighted avg       0.84      0.81      0.80      3408\n",
      "\n",
      "acc:  0.8083920187793427\n",
      "pre:  0.9462555066079296\n",
      "rec:  0.6446578631452581\n",
      "ma F1:  0.8021144378697698\n",
      "mi F1:  0.8083920187793426\n",
      "we F1:  0.8029004282307708\n",
      "Eval Loss:  0.24664098024368286\n",
      "Eval Loss:  0.29680103063583374\n",
      "Eval Loss:  0.25252771377563477\n",
      "Eval Loss:  0.24525569379329681\n",
      "Eval Loss:  0.30482548475265503\n",
      "Eval Loss:  0.25453701615333557\n",
      "Eval Loss:  0.36478161811828613\n",
      "Eval Loss:  0.33404454588890076\n",
      "Eval Loss:  0.22804361581802368\n",
      "Eval Loss:  0.2201823741197586\n",
      "Eval Loss:  0.28037092089653015\n",
      "Eval Loss:  0.27340516448020935\n",
      "Eval Loss:  0.22940640151500702\n",
      "Eval Loss:  0.31814733147621155\n",
      "Eval Loss:  0.2797273099422455\n",
      "Eval Loss:  0.3098115026950836\n",
      "Eval Loss:  0.2986929714679718\n",
      "Eval Loss:  0.2085411548614502\n",
      "Eval Loss:  0.3053405284881592\n",
      "Eval Loss:  0.3481920659542084\n",
      "Eval Loss:  0.24023504555225372\n",
      "Eval Loss:  0.2986737787723541\n",
      "Eval Loss:  0.209051251411438\n",
      "Eval Loss:  0.35726398229599\n",
      "Eval Loss:  0.26948070526123047\n",
      "Eval Loss:  0.2404833436012268\n",
      "Eval Loss:  0.2812213897705078\n",
      "Eval Loss:  0.2528564929962158\n",
      "[[17504   918]\n",
      " [ 2291  8770]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     18422\n",
      "           1       0.91      0.79      0.85     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8911576162534341\n",
      "pre:  0.9052436003303055\n",
      "rec:  0.7928758701744869\n",
      "ma F1:  0.8806870382436133\n",
      "mi F1:  0.8911576162534341\n",
      "we F1:  0.8895116231680799\n",
      "29483 461\n",
      "Loss:  0.07436083257198334\n",
      "Loss:  0.035669609904289246\n",
      "Loss:  0.08003805577754974\n",
      "12 **********\n",
      "Epoch:  1232.1863827705383  fold:  9  kers:  128\n",
      "epoch:  13\n",
      "29483 461\n",
      "Loss:  0.05588197335600853\n",
      "Loss:  0.06829661130905151\n",
      "Loss:  0.06025812402367592\n",
      "13 **********\n",
      "Epoch:  1312.6801590919495  fold:  9  kers:  128\n",
      "epoch:  14\n",
      "29483 461\n",
      "Loss:  0.06368350237607956\n",
      "Loss:  0.06334397941827774\n",
      "Loss:  0.049880653619766235\n",
      "14 **********\n",
      "Epoch:  1393.2158226966858  fold:  9  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.03855393826961517\n",
      "Eval Loss:  1.5031602382659912\n",
      "Eval Loss:  0.20313943922519684\n",
      "[[1682   60]\n",
      " [ 531 1135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85      1742\n",
      "           1       0.95      0.68      0.79      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.82      0.82      3408\n",
      "weighted avg       0.85      0.83      0.82      3408\n",
      "\n",
      "acc:  0.8265845070422535\n",
      "pre:  0.9497907949790795\n",
      "rec:  0.6812725090036015\n",
      "ma F1:  0.8219988855752699\n",
      "mi F1:  0.8265845070422535\n",
      "we F1:  0.8226360103129129\n",
      "Eval Loss:  0.24180151522159576\n",
      "Eval Loss:  0.22640936076641083\n",
      "Eval Loss:  0.22547116875648499\n",
      "Eval Loss:  0.2527337372303009\n",
      "Eval Loss:  0.2395939826965332\n",
      "Eval Loss:  0.25931110978126526\n",
      "Eval Loss:  0.31488338112831116\n",
      "Eval Loss:  0.2800928056240082\n",
      "Eval Loss:  0.20025916397571564\n",
      "Eval Loss:  0.2135278582572937\n",
      "Eval Loss:  0.27998316287994385\n",
      "Eval Loss:  0.2573494613170624\n",
      "Eval Loss:  0.22521129250526428\n",
      "Eval Loss:  0.3006940484046936\n",
      "Eval Loss:  0.290012389421463\n",
      "Eval Loss:  0.27816686034202576\n",
      "Eval Loss:  0.26279881596565247\n",
      "Eval Loss:  0.2007226198911667\n",
      "Eval Loss:  0.27164819836616516\n",
      "Eval Loss:  0.3099939227104187\n",
      "Eval Loss:  0.1887853890657425\n",
      "Eval Loss:  0.2769210636615753\n",
      "Eval Loss:  0.20672589540481567\n",
      "Eval Loss:  0.3156467378139496\n",
      "Eval Loss:  0.2450554370880127\n",
      "Eval Loss:  0.17847397923469543\n",
      "Eval Loss:  0.2570543885231018\n",
      "Eval Loss:  0.23161107301712036\n",
      "[[17512   910]\n",
      " [ 2006  9055]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18422\n",
      "           1       0.91      0.82      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9010955465861683\n",
      "pre:  0.9086803813346713\n",
      "rec:  0.8186420757616852\n",
      "ma F1:  0.8922281828843481\n",
      "mi F1:  0.9010955465861684\n",
      "we F1:  0.899946364770253\n",
      "29483 461\n",
      "Loss:  0.06457696855068207\n",
      "Loss:  0.06281634420156479\n",
      "Loss:  0.05092261731624603\n",
      "15 **********\n",
      "Epoch:  1519.0473747253418  fold:  9  kers:  128\n",
      "epoch:  16\n",
      "29483 461\n",
      "Loss:  0.07243303209543228\n",
      "Loss:  0.0403021015226841\n",
      "Loss:  0.07447285950183868\n",
      "16 **********\n",
      "Epoch:  1599.5301802158356  fold:  9  kers:  128\n",
      "epoch:  17\n",
      "29483 461\n",
      "Loss:  0.04920180141925812\n",
      "Loss:  0.08588950335979462\n",
      "Loss:  0.05991547182202339\n",
      "17 **********\n",
      "Epoch:  1680.038916349411  fold:  9  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.0371253527700901\n",
      "Eval Loss:  1.2051419019699097\n",
      "Eval Loss:  0.1490461826324463\n",
      "[[1654   88]\n",
      " [ 505 1161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85      1742\n",
      "           1       0.93      0.70      0.80      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.82      0.82      3408\n",
      "weighted avg       0.85      0.83      0.82      3408\n",
      "\n",
      "acc:  0.8259976525821596\n",
      "pre:  0.9295436349079264\n",
      "rec:  0.6968787515006002\n",
      "ma F1:  0.8222785818651417\n",
      "mi F1:  0.8259976525821596\n",
      "we F1:  0.8228519071683738\n",
      "Eval Loss:  0.2256871610879898\n",
      "Eval Loss:  0.22897891700267792\n",
      "Eval Loss:  0.2249133288860321\n",
      "Eval Loss:  0.23753255605697632\n",
      "Eval Loss:  0.19666993618011475\n",
      "Eval Loss:  0.22371037304401398\n",
      "Eval Loss:  0.32757264375686646\n",
      "Eval Loss:  0.26729458570480347\n",
      "Eval Loss:  0.1646004021167755\n",
      "Eval Loss:  0.22147122025489807\n",
      "Eval Loss:  0.2539661228656769\n",
      "Eval Loss:  0.21933220326900482\n",
      "Eval Loss:  0.23014913499355316\n",
      "Eval Loss:  0.2738368511199951\n",
      "Eval Loss:  0.2577112019062042\n",
      "Eval Loss:  0.27433472871780396\n",
      "Eval Loss:  0.25291550159454346\n",
      "Eval Loss:  0.2100927233695984\n",
      "Eval Loss:  0.27131637930870056\n",
      "Eval Loss:  0.2936728596687317\n",
      "Eval Loss:  0.1888914853334427\n",
      "Eval Loss:  0.2884320616722107\n",
      "Eval Loss:  0.17784647643566132\n",
      "Eval Loss:  0.2794897258281708\n",
      "Eval Loss:  0.2447596788406372\n",
      "Eval Loss:  0.21012268960475922\n",
      "Eval Loss:  0.24166889488697052\n",
      "Eval Loss:  0.22481566667556763\n",
      "[[17214  1208]\n",
      " [ 1558  9503]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18422\n",
      "           1       0.89      0.86      0.87     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.90      0.90      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9061832242309127\n",
      "pre:  0.8872187470824386\n",
      "rec:  0.8591447427899829\n",
      "ma F1:  0.8992946285155545\n",
      "mi F1:  0.9061832242309127\n",
      "we F1:  0.9058705529171562\n",
      "29483 461\n",
      "Loss:  0.05266742780804634\n",
      "Loss:  0.03708347678184509\n",
      "Loss:  0.04547658935189247\n",
      "18 **********\n",
      "Epoch:  1803.843887090683  fold:  9  kers:  128\n",
      "epoch:  19\n",
      "29483 461\n",
      "Loss:  0.09234170615673065\n",
      "Loss:  0.05017370358109474\n",
      "Loss:  0.06238388270139694\n",
      "19 **********\n",
      "Epoch:  1884.369577884674  fold:  9  kers:  128\n",
      "epoch:  20\n",
      "29483 461\n",
      "Loss:  0.05935784801840782\n",
      "Loss:  0.06678362190723419\n",
      "Loss:  0.06471958756446838\n",
      "20 **********\n",
      "Epoch:  1964.8583674430847  fold:  9  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.03164042532444\n",
      "Eval Loss:  1.8593183755874634\n",
      "Eval Loss:  0.20586414635181427\n",
      "[[1697   45]\n",
      " [ 678  988]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82      1742\n",
      "           1       0.96      0.59      0.73      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.84      0.78      0.78      3408\n",
      "weighted avg       0.83      0.79      0.78      3408\n",
      "\n",
      "acc:  0.7878521126760564\n",
      "pre:  0.9564375605033882\n",
      "rec:  0.5930372148859544\n",
      "ma F1:  0.7782548489292853\n",
      "mi F1:  0.7878521126760564\n",
      "we F1:  0.779283610628516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2274477183818817\n",
      "Eval Loss:  0.2330373078584671\n",
      "Eval Loss:  0.2278803139925003\n",
      "Eval Loss:  0.25123319029808044\n",
      "Eval Loss:  0.24212566018104553\n",
      "Eval Loss:  0.22884827852249146\n",
      "Eval Loss:  0.32896825671195984\n",
      "Eval Loss:  0.3029995560646057\n",
      "Eval Loss:  0.21383248269557953\n",
      "Eval Loss:  0.1997765451669693\n",
      "Eval Loss:  0.2864729166030884\n",
      "Eval Loss:  0.22929349541664124\n",
      "Eval Loss:  0.21856394410133362\n",
      "Eval Loss:  0.29517054557800293\n",
      "Eval Loss:  0.2848891019821167\n",
      "Eval Loss:  0.2999359965324402\n",
      "Eval Loss:  0.24331925809383392\n",
      "Eval Loss:  0.16731184720993042\n",
      "Eval Loss:  0.24134573340415955\n",
      "Eval Loss:  0.3289164900779724\n",
      "Eval Loss:  0.18218322098255157\n",
      "Eval Loss:  0.28693318367004395\n",
      "Eval Loss:  0.2321026623249054\n",
      "Eval Loss:  0.3269818127155304\n",
      "Eval Loss:  0.2483878880739212\n",
      "Eval Loss:  0.1628817319869995\n",
      "Eval Loss:  0.236826092004776\n",
      "Eval Loss:  0.24839508533477783\n",
      "[[17638   784]\n",
      " [ 2097  8964]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18422\n",
      "           1       0.92      0.81      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.902282671369942\n",
      "pre:  0.919573245794009\n",
      "rec:  0.8104149715215623\n",
      "ma F1:  0.8930232256696058\n",
      "mi F1:  0.902282671369942\n",
      "we F1:  0.9008810513325266\n",
      "29483 461\n",
      "Loss:  0.12175565958023071\n",
      "Loss:  0.05230587720870972\n",
      "Loss:  0.04147641360759735\n",
      "21 **********\n",
      "Epoch:  2088.613471508026  fold:  9  kers:  128\n",
      "epoch:  22\n",
      "29483 461\n",
      "Loss:  0.04913501814007759\n",
      "Loss:  0.048207540065050125\n",
      "Loss:  0.06773318350315094\n",
      "22 **********\n",
      "Epoch:  2169.100265979767  fold:  9  kers:  128\n",
      "epoch:  23\n",
      "29483 461\n",
      "Loss:  0.05538959056138992\n",
      "Loss:  0.05530006065964699\n",
      "Loss:  0.06249319389462471\n",
      "23 **********\n",
      "Epoch:  2249.610996246338  fold:  9  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.03364494442939758\n",
      "Eval Loss:  1.217016577720642\n",
      "Eval Loss:  0.1688820719718933\n",
      "[[1681   61]\n",
      " [ 472 1194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86      1742\n",
      "           1       0.95      0.72      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.87      0.84      0.84      3408\n",
      "weighted avg       0.86      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8436032863849765\n",
      "pre:  0.951394422310757\n",
      "rec:  0.7166866746698679\n",
      "ma F1:  0.8403430692444909\n",
      "mi F1:  0.8436032863849765\n",
      "we F1:  0.840851850564156\n",
      "update!  Acc:  0.8436032863849765\n",
      "Eval Loss:  0.21008829772472382\n",
      "Eval Loss:  0.2577728033065796\n",
      "Eval Loss:  0.22262874245643616\n",
      "Eval Loss:  0.2504236102104187\n",
      "Eval Loss:  0.20710980892181396\n",
      "Eval Loss:  0.2392507940530777\n",
      "Eval Loss:  0.2632961869239807\n",
      "Eval Loss:  0.28941360116004944\n",
      "Eval Loss:  0.20879991352558136\n",
      "Eval Loss:  0.1963503509759903\n",
      "Eval Loss:  0.23180444538593292\n",
      "Eval Loss:  0.2148560881614685\n",
      "Eval Loss:  0.21825657784938812\n",
      "Eval Loss:  0.2805125415325165\n",
      "Eval Loss:  0.270309716463089\n",
      "Eval Loss:  0.24379299581050873\n",
      "Eval Loss:  0.2481449693441391\n",
      "Eval Loss:  0.18403325974941254\n",
      "Eval Loss:  0.23879586160182953\n",
      "Eval Loss:  0.2913070619106293\n",
      "Eval Loss:  0.16705627739429474\n",
      "Eval Loss:  0.25841793417930603\n",
      "Eval Loss:  0.21613691747188568\n",
      "Eval Loss:  0.30981308221817017\n",
      "Eval Loss:  0.24279242753982544\n",
      "Eval Loss:  0.13413970172405243\n",
      "Eval Loss:  0.21907171607017517\n",
      "Eval Loss:  0.2542775571346283\n",
      "[[17689   733]\n",
      " [ 1937  9124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18422\n",
      "           1       0.93      0.82      0.87     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.89      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9094393379235491\n",
      "pre:  0.9256366034290352\n",
      "rec:  0.8248802097459542\n",
      "ma F1:  0.9010921088521313\n",
      "mi F1:  0.9094393379235491\n",
      "we F1:  0.9082659504393708\n",
      "29483 461\n",
      "Loss:  0.08016988635063171\n",
      "Loss:  0.051525287330150604\n",
      "Loss:  0.02426118589937687\n",
      "24 **********\n",
      "Epoch:  2373.4698235988617  fold:  9  kers:  128\n",
      "epoch:  25\n",
      "29483 461\n",
      "Loss:  0.06542138755321503\n",
      "Loss:  0.09650283306837082\n",
      "Loss:  0.08234833180904388\n",
      "25 **********\n",
      "Epoch:  2453.961604833603  fold:  9  kers:  128\n",
      "epoch:  26\n",
      "29483 461\n",
      "Loss:  0.08130929619073868\n",
      "Loss:  0.1072024405002594\n",
      "Loss:  0.06222589686512947\n",
      "26 **********\n",
      "Epoch:  2534.4882922172546  fold:  9  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.03437609225511551\n",
      "Eval Loss:  1.7870224714279175\n",
      "Eval Loss:  0.28181496262550354\n",
      "[[1699   43]\n",
      " [ 795  871]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80      1742\n",
      "           1       0.95      0.52      0.68      1666\n",
      "\n",
      "    accuracy                           0.75      3408\n",
      "   macro avg       0.82      0.75      0.74      3408\n",
      "weighted avg       0.81      0.75      0.74      3408\n",
      "\n",
      "acc:  0.7541079812206573\n",
      "pre:  0.9529540481400438\n",
      "rec:  0.5228091236494598\n",
      "ma F1:  0.7386828293475636\n",
      "mi F1:  0.7541079812206573\n",
      "we F1:  0.7400986645436447\n",
      "Eval Loss:  0.23555177450180054\n",
      "Eval Loss:  0.28820836544036865\n",
      "Eval Loss:  0.24399709701538086\n",
      "Eval Loss:  0.2544313371181488\n",
      "Eval Loss:  0.24529913067817688\n",
      "Eval Loss:  0.26493340730667114\n",
      "Eval Loss:  0.35106712579727173\n",
      "Eval Loss:  0.32679155468940735\n",
      "Eval Loss:  0.253513902425766\n",
      "Eval Loss:  0.17650620639324188\n",
      "Eval Loss:  0.2873944640159607\n",
      "Eval Loss:  0.21673385798931122\n",
      "Eval Loss:  0.23936709761619568\n",
      "Eval Loss:  0.3093714714050293\n",
      "Eval Loss:  0.3111753463745117\n",
      "Eval Loss:  0.30935388803482056\n",
      "Eval Loss:  0.2654806077480316\n",
      "Eval Loss:  0.18842484056949615\n",
      "Eval Loss:  0.26737213134765625\n",
      "Eval Loss:  0.3354402780532837\n",
      "Eval Loss:  0.2050691694021225\n",
      "Eval Loss:  0.27843761444091797\n",
      "Eval Loss:  0.2549003064632416\n",
      "Eval Loss:  0.35155826807022095\n",
      "Eval Loss:  0.25465622544288635\n",
      "Eval Loss:  0.18233713507652283\n",
      "Eval Loss:  0.24515484273433685\n",
      "Eval Loss:  0.2821574807167053\n",
      "[[17913   509]\n",
      " [ 2539  8522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18422\n",
      "           1       0.94      0.77      0.85     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.87      0.88     29483\n",
      "weighted avg       0.90      0.90      0.89     29483\n",
      "\n",
      "acc:  0.8966183902587932\n",
      "pre:  0.9436385782305392\n",
      "rec:  0.7704547509266794\n",
      "ma F1:  0.8849453341915352\n",
      "mi F1:  0.8966183902587932\n",
      "we F1:  0.8940950909491846\n",
      "29483 461\n",
      "Loss:  0.04042273014783859\n",
      "Loss:  0.05107574164867401\n",
      "Loss:  0.06260878592729568\n",
      "27 **********\n",
      "Epoch:  2658.2154712677  fold:  9  kers:  128\n",
      "epoch:  28\n",
      "29483 461\n",
      "Loss:  0.06588733941316605\n",
      "Loss:  0.053343385457992554\n",
      "Loss:  0.04462335631251335\n",
      "28 **********\n",
      "Epoch:  2738.7052578926086  fold:  9  kers:  128\n",
      "epoch:  29\n",
      "29483 461\n",
      "Loss:  0.02747490629553795\n",
      "Loss:  0.0440591461956501\n",
      "Loss:  0.05351793020963669\n",
      "29 **********\n",
      "Epoch:  2819.2020258903503  fold:  9  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.03497767075896263\n",
      "Eval Loss:  1.775307297706604\n",
      "Eval Loss:  0.14523576200008392\n",
      "[[1645   97]\n",
      " [ 481 1185]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85      1742\n",
      "           1       0.92      0.71      0.80      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8303990610328639\n",
      "pre:  0.9243369734789392\n",
      "rec:  0.7112845138055222\n",
      "ma F1:  0.8272518202444579\n",
      "mi F1:  0.8303990610328639\n",
      "we F1:  0.827771799157325\n",
      "Eval Loss:  0.21745826303958893\n",
      "Eval Loss:  0.20381687581539154\n",
      "Eval Loss:  0.19654712080955505\n",
      "Eval Loss:  0.24234801530838013\n",
      "Eval Loss:  0.18718299269676208\n",
      "Eval Loss:  0.17883072793483734\n",
      "Eval Loss:  0.25783491134643555\n",
      "Eval Loss:  0.2573704123497009\n",
      "Eval Loss:  0.16581955552101135\n",
      "Eval Loss:  0.16496199369430542\n",
      "Eval Loss:  0.23047684133052826\n",
      "Eval Loss:  0.18790428340435028\n",
      "Eval Loss:  0.17847654223442078\n",
      "Eval Loss:  0.21529284119606018\n",
      "Eval Loss:  0.25337788462638855\n",
      "Eval Loss:  0.2327950894832611\n",
      "Eval Loss:  0.2640047073364258\n",
      "Eval Loss:  0.19420593976974487\n",
      "Eval Loss:  0.21996183693408966\n",
      "Eval Loss:  0.26368820667266846\n",
      "Eval Loss:  0.1719484180212021\n",
      "Eval Loss:  0.21524512767791748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18631097674369812\n",
      "Eval Loss:  0.25835350155830383\n",
      "Eval Loss:  0.26189756393432617\n",
      "Eval Loss:  0.13977740705013275\n",
      "Eval Loss:  0.20153778791427612\n",
      "Eval Loss:  0.24821962416172028\n",
      "[[17625   797]\n",
      " [ 1670  9391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18422\n",
      "           1       0.92      0.85      0.88     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.90      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9163246616694366\n",
      "pre:  0.9217707106399686\n",
      "rec:  0.8490190760329084\n",
      "ma F1:  0.9092461237308173\n",
      "mi F1:  0.9163246616694366\n",
      "we F1:  0.9155741681522621\n",
      "29483 461\n",
      "Loss:  0.06661061197519302\n",
      "Loss:  0.03234465792775154\n",
      "Loss:  0.04136454686522484\n",
      "30 **********\n",
      "Epoch:  2943.0269434452057  fold:  9  kers:  128\n",
      "epoch:  31\n",
      "29483 461\n",
      "Loss:  0.04982779920101166\n",
      "Loss:  0.055493973195552826\n",
      "Loss:  0.05092327669262886\n",
      "31 **********\n",
      "Epoch:  3023.516729593277  fold:  9  kers:  128\n",
      "epoch:  32\n",
      "29483 461\n",
      "Loss:  0.07390664517879486\n",
      "Loss:  0.06519454717636108\n",
      "Loss:  0.05026824399828911\n",
      "32 **********\n",
      "Epoch:  3104.0025272369385  fold:  9  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.030456408858299255\n",
      "Eval Loss:  1.5335794687271118\n",
      "Eval Loss:  0.11393125355243683\n",
      "[[1618  124]\n",
      " [ 410 1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      1742\n",
      "           1       0.91      0.75      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8433098591549296\n",
      "pre:  0.9101449275362319\n",
      "rec:  0.7539015606242497\n",
      "ma F1:  0.8415217766135872\n",
      "mi F1:  0.8433098591549296\n",
      "we F1:  0.8418971751581783\n",
      "Eval Loss:  0.19659100472927094\n",
      "Eval Loss:  0.20715026557445526\n",
      "Eval Loss:  0.16871525347232819\n",
      "Eval Loss:  0.1982114166021347\n",
      "Eval Loss:  0.1520150750875473\n",
      "Eval Loss:  0.15946340560913086\n",
      "Eval Loss:  0.2739991247653961\n",
      "Eval Loss:  0.26469945907592773\n",
      "Eval Loss:  0.15355511009693146\n",
      "Eval Loss:  0.1623029261827469\n",
      "Eval Loss:  0.22833740711212158\n",
      "Eval Loss:  0.20491540431976318\n",
      "Eval Loss:  0.18889281153678894\n",
      "Eval Loss:  0.20623338222503662\n",
      "Eval Loss:  0.2271362543106079\n",
      "Eval Loss:  0.24710310995578766\n",
      "Eval Loss:  0.2514759600162506\n",
      "Eval Loss:  0.14665627479553223\n",
      "Eval Loss:  0.23254357278347015\n",
      "Eval Loss:  0.24203750491142273\n",
      "Eval Loss:  0.12781555950641632\n",
      "Eval Loss:  0.23784339427947998\n",
      "Eval Loss:  0.154777392745018\n",
      "Eval Loss:  0.2445603609085083\n",
      "Eval Loss:  0.25791555643081665\n",
      "Eval Loss:  0.18555530905723572\n",
      "Eval Loss:  0.185201495885849\n",
      "Eval Loss:  0.22036582231521606\n",
      "[[17259  1163]\n",
      " [ 1125  9936]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18422\n",
      "           1       0.90      0.90      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9223959569921649\n",
      "pre:  0.8952157852058744\n",
      "rec:  0.8982912937347437\n",
      "ma F1:  0.9172935624410634\n",
      "mi F1:  0.9223959569921649\n",
      "we F1:  0.9224224339815056\n",
      "29483 461\n",
      "Loss:  0.0648973286151886\n",
      "Loss:  0.06665176898241043\n",
      "Loss:  0.04812784492969513\n",
      "33 **********\n",
      "Epoch:  3227.656900882721  fold:  9  kers:  128\n",
      "epoch:  34\n",
      "29483 461\n",
      "Loss:  0.030580120161175728\n",
      "Loss:  0.05295632407069206\n",
      "Loss:  0.03165500983595848\n",
      "34 **********\n",
      "Epoch:  3308.398015022278  fold:  9  kers:  128\n",
      "epoch:  35\n",
      "29483 461\n",
      "Loss:  0.07710886746644974\n",
      "Loss:  0.06983483582735062\n",
      "Loss:  0.061738889664411545\n",
      "35 **********\n",
      "Epoch:  3389.0952475070953  fold:  9  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.036604590713977814\n",
      "Eval Loss:  1.566174864768982\n",
      "Eval Loss:  0.14900705218315125\n",
      "[[1648   94]\n",
      " [ 459 1207]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86      1742\n",
      "           1       0.93      0.72      0.81      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.83      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8377347417840375\n",
      "pre:  0.9277478862413528\n",
      "rec:  0.7244897959183674\n",
      "ma F1:  0.8349713830572252\n",
      "mi F1:  0.8377347417840375\n",
      "we F1:  0.835447608143932\n",
      "Eval Loss:  0.18453660607337952\n",
      "Eval Loss:  0.24058498442173004\n",
      "Eval Loss:  0.1629532277584076\n",
      "Eval Loss:  0.18422472476959229\n",
      "Eval Loss:  0.1619979590177536\n",
      "Eval Loss:  0.17696385085582733\n",
      "Eval Loss:  0.25084608793258667\n",
      "Eval Loss:  0.24724315106868744\n",
      "Eval Loss:  0.18029990792274475\n",
      "Eval Loss:  0.13732793927192688\n",
      "Eval Loss:  0.2098052203655243\n",
      "Eval Loss:  0.20083148777484894\n",
      "Eval Loss:  0.19859464466571808\n",
      "Eval Loss:  0.19908763468265533\n",
      "Eval Loss:  0.21371546387672424\n",
      "Eval Loss:  0.27579790353775024\n",
      "Eval Loss:  0.2590683698654175\n",
      "Eval Loss:  0.1479462832212448\n",
      "Eval Loss:  0.20327642560005188\n",
      "Eval Loss:  0.24970310926437378\n",
      "Eval Loss:  0.15129908919334412\n",
      "Eval Loss:  0.2030533403158188\n",
      "Eval Loss:  0.20705553889274597\n",
      "Eval Loss:  0.2866251766681671\n",
      "Eval Loss:  0.2201484888792038\n",
      "Eval Loss:  0.1492675542831421\n",
      "Eval Loss:  0.1815980076789856\n",
      "Eval Loss:  0.22342455387115479\n",
      "[[17586   836]\n",
      " [ 1502  9559]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18422\n",
      "           1       0.92      0.86      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9207000644439168\n",
      "pre:  0.9195767195767196\n",
      "rec:  0.8642075761685201\n",
      "ma F1:  0.9143513830067885\n",
      "mi F1:  0.9207000644439169\n",
      "we F1:  0.9201733144953523\n",
      "29483 461\n",
      "Loss:  0.0433344729244709\n",
      "Loss:  0.05723349750041962\n",
      "Loss:  0.03996327519416809\n",
      "36 **********\n",
      "Epoch:  3513.0966930389404  fold:  9  kers:  128\n",
      "epoch:  37\n",
      "29483 461\n",
      "Loss:  0.05285543203353882\n",
      "Loss:  0.03190776705741882\n",
      "Loss:  0.04705407842993736\n",
      "37 **********\n",
      "Epoch:  3593.740068435669  fold:  9  kers:  128\n",
      "epoch:  38\n",
      "29483 461\n",
      "Loss:  0.04746945947408676\n",
      "Loss:  0.05874275043606758\n",
      "Loss:  0.05251745134592056\n",
      "38 **********\n",
      "Epoch:  3674.389428138733  fold:  9  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.0363507941365242\n",
      "Eval Loss:  2.040915012359619\n",
      "Eval Loss:  0.17711016535758972\n",
      "[[1669   73]\n",
      " [ 565 1101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84      1742\n",
      "           1       0.94      0.66      0.78      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.81      0.81      3408\n",
      "weighted avg       0.84      0.81      0.81      3408\n",
      "\n",
      "acc:  0.812793427230047\n",
      "pre:  0.9378194207836457\n",
      "rec:  0.6608643457382953\n",
      "ma F1:  0.8074446680080483\n",
      "mi F1:  0.8127934272300471\n",
      "we F1:  0.8081603470588792\n",
      "Eval Loss:  0.17279356718063354\n",
      "Eval Loss:  0.24673976004123688\n",
      "Eval Loss:  0.16967765986919403\n",
      "Eval Loss:  0.18252475559711456\n",
      "Eval Loss:  0.18195906281471252\n",
      "Eval Loss:  0.18695038557052612\n",
      "Eval Loss:  0.2666004002094269\n",
      "Eval Loss:  0.2641574740409851\n",
      "Eval Loss:  0.17694108188152313\n",
      "Eval Loss:  0.16025607287883759\n",
      "Eval Loss:  0.22707444429397583\n",
      "Eval Loss:  0.22561070322990417\n",
      "Eval Loss:  0.15816771984100342\n",
      "Eval Loss:  0.2457306832075119\n",
      "Eval Loss:  0.22345070540905\n",
      "Eval Loss:  0.24077236652374268\n",
      "Eval Loss:  0.26443442702293396\n",
      "Eval Loss:  0.13264435529708862\n",
      "Eval Loss:  0.21864236891269684\n",
      "Eval Loss:  0.2559613287448883\n",
      "Eval Loss:  0.1352161020040512\n",
      "Eval Loss:  0.19286827743053436\n",
      "Eval Loss:  0.20518061518669128\n",
      "Eval Loss:  0.23063576221466064\n",
      "Eval Loss:  0.21325019001960754\n",
      "Eval Loss:  0.15377819538116455\n",
      "Eval Loss:  0.19993293285369873\n",
      "Eval Loss:  0.2365531176328659\n",
      "[[17660   762]\n",
      " [ 1537  9524]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18422\n",
      "           1       0.93      0.86      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9220228606315504\n",
      "pre:  0.9259187244798756\n",
      "rec:  0.8610433053069343\n",
      "ma F1:  0.9155953162845173\n",
      "mi F1:  0.9220228606315504\n",
      "we F1:  0.9214106006919055\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04031790420413017\n",
      "Loss:  0.06494660675525665\n",
      "Loss:  0.06389306485652924\n",
      "39 **********\n",
      "Epoch:  3798.281167268753  fold:  9  kers:  128\n",
      "epoch:  40\n",
      "29483 461\n",
      "Loss:  0.04609661176800728\n",
      "Loss:  0.04464622586965561\n",
      "Loss:  0.05491861328482628\n",
      "40 **********\n",
      "Epoch:  3878.916563987732  fold:  9  kers:  128\n",
      "epoch:  41\n",
      "29483 461\n",
      "Loss:  0.05555133894085884\n",
      "Loss:  0.09366802871227264\n",
      "Loss:  0.061220306903123856\n",
      "41 **********\n",
      "Epoch:  3959.5549540519714  fold:  9  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.029639018699526787\n",
      "Eval Loss:  0.9690027236938477\n",
      "Eval Loss:  0.1940675675868988\n",
      "[[1674   68]\n",
      " [ 480 1186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86      1742\n",
      "           1       0.95      0.71      0.81      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.86      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8392018779342723\n",
      "pre:  0.9457735247208932\n",
      "rec:  0.7118847539015606\n",
      "ma F1:  0.835835841467188\n",
      "mi F1:  0.8392018779342723\n",
      "we F1:  0.8363600602612421\n",
      "Eval Loss:  0.14248105883598328\n",
      "Eval Loss:  0.24390436708927155\n",
      "Eval Loss:  0.15384574234485626\n",
      "Eval Loss:  0.1848435252904892\n",
      "Eval Loss:  0.1492927372455597\n",
      "Eval Loss:  0.16142408549785614\n",
      "Eval Loss:  0.23449495434761047\n",
      "Eval Loss:  0.24877122044563293\n",
      "Eval Loss:  0.16780251264572144\n",
      "Eval Loss:  0.15707769989967346\n",
      "Eval Loss:  0.2229660302400589\n",
      "Eval Loss:  0.21416717767715454\n",
      "Eval Loss:  0.16035355627536774\n",
      "Eval Loss:  0.2309112250804901\n",
      "Eval Loss:  0.21352992951869965\n",
      "Eval Loss:  0.21334348618984222\n",
      "Eval Loss:  0.22496670484542847\n",
      "Eval Loss:  0.1413552314043045\n",
      "Eval Loss:  0.21771623194217682\n",
      "Eval Loss:  0.23950134217739105\n",
      "Eval Loss:  0.1317962110042572\n",
      "Eval Loss:  0.18839135766029358\n",
      "Eval Loss:  0.16345280408859253\n",
      "Eval Loss:  0.23317508399486542\n",
      "Eval Loss:  0.22159616649150848\n",
      "Eval Loss:  0.15559124946594238\n",
      "Eval Loss:  0.1757538914680481\n",
      "Eval Loss:  0.21973176300525665\n",
      "[[17681   741]\n",
      " [ 1508  9553]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18422\n",
      "           1       0.93      0.86      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9237187531797986\n",
      "pre:  0.9280163201865164\n",
      "rec:  0.8636651297351053\n",
      "ma F1:  0.9174443746409169\n",
      "mi F1:  0.9237187531797986\n",
      "we F1:  0.9231266704608858\n",
      "29483 461\n",
      "Loss:  0.03485830873250961\n",
      "Loss:  0.06070476025342941\n",
      "Loss:  0.049535129219293594\n",
      "42 **********\n",
      "Epoch:  4083.452676296234  fold:  9  kers:  128\n",
      "epoch:  43\n",
      "29483 461\n",
      "Loss:  0.06853155046701431\n",
      "Loss:  0.06419810652732849\n",
      "Loss:  0.05749726668000221\n",
      "43 **********\n",
      "Epoch:  4164.092063188553  fold:  9  kers:  128\n",
      "epoch:  44\n",
      "29483 461\n",
      "Loss:  0.05432885140180588\n",
      "Loss:  0.04666740074753761\n",
      "Loss:  0.06709949672222137\n",
      "44 **********\n",
      "Epoch:  4244.711503267288  fold:  9  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.03075569123029709\n",
      "Eval Loss:  2.5685036182403564\n",
      "Eval Loss:  0.16027213633060455\n",
      "[[1671   71]\n",
      " [ 663 1003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      1742\n",
      "           1       0.93      0.60      0.73      1666\n",
      "\n",
      "    accuracy                           0.78      3408\n",
      "   macro avg       0.82      0.78      0.78      3408\n",
      "weighted avg       0.82      0.78      0.78      3408\n",
      "\n",
      "acc:  0.7846244131455399\n",
      "pre:  0.9338919925512105\n",
      "rec:  0.6020408163265306\n",
      "ma F1:  0.7760191399898284\n",
      "mi F1:  0.7846244131455399\n",
      "we F1:  0.7769981830434722\n",
      "Eval Loss:  0.16385427117347717\n",
      "Eval Loss:  0.2634475827217102\n",
      "Eval Loss:  0.18458135426044464\n",
      "Eval Loss:  0.2160625159740448\n",
      "Eval Loss:  0.20414790511131287\n",
      "Eval Loss:  0.19402530789375305\n",
      "Eval Loss:  0.2782798111438751\n",
      "Eval Loss:  0.2648886442184448\n",
      "Eval Loss:  0.2157406210899353\n",
      "Eval Loss:  0.14378546178340912\n",
      "Eval Loss:  0.22544287145137787\n",
      "Eval Loss:  0.20861506462097168\n",
      "Eval Loss:  0.20125266909599304\n",
      "Eval Loss:  0.2635919153690338\n",
      "Eval Loss:  0.20114654302597046\n",
      "Eval Loss:  0.2830280661582947\n",
      "Eval Loss:  0.24526852369308472\n",
      "Eval Loss:  0.12150178104639053\n",
      "Eval Loss:  0.21817578375339508\n",
      "Eval Loss:  0.29127368330955505\n",
      "Eval Loss:  0.15274062752723694\n",
      "Eval Loss:  0.22496555745601654\n",
      "Eval Loss:  0.23255348205566406\n",
      "Eval Loss:  0.2364133894443512\n",
      "Eval Loss:  0.27098846435546875\n",
      "Eval Loss:  0.1530267745256424\n",
      "Eval Loss:  0.18430954217910767\n",
      "Eval Loss:  0.24059335887432098\n",
      "[[17679   743]\n",
      " [ 1737  9324]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18422\n",
      "           1       0.93      0.84      0.88     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.90      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9158837296068921\n",
      "pre:  0.9261944968709646\n",
      "rec:  0.8429617575264443\n",
      "ma F1:  0.9085388216838404\n",
      "mi F1:  0.9158837296068921\n",
      "we F1:  0.9150099009443532\n",
      "29483 461\n",
      "Loss:  0.05912192910909653\n",
      "Loss:  0.0377148874104023\n",
      "Loss:  0.0873364731669426\n",
      "45 **********\n",
      "Epoch:  4368.5723242759705  fold:  9  kers:  128\n",
      "epoch:  46\n",
      "29483 461\n",
      "Loss:  0.03197679668664932\n",
      "Loss:  0.047018252313137054\n",
      "Loss:  0.0496736504137516\n",
      "46 **********\n",
      "Epoch:  4449.221684217453  fold:  9  kers:  128\n",
      "epoch:  47\n",
      "29483 461\n",
      "Loss:  0.06124631315469742\n",
      "Loss:  0.058645036071538925\n",
      "Loss:  0.02323920652270317\n",
      "47 **********\n",
      "Epoch:  4529.883012294769  fold:  9  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.03611711412668228\n",
      "Eval Loss:  1.9568910598754883\n",
      "Eval Loss:  0.12939712405204773\n",
      "[[1685   57]\n",
      " [ 563 1103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.97      0.84      1742\n",
      "           1       0.95      0.66      0.78      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.85      0.81      0.81      3408\n",
      "weighted avg       0.85      0.82      0.81      3408\n",
      "\n",
      "acc:  0.818075117370892\n",
      "pre:  0.9508620689655173\n",
      "rec:  0.6620648259303722\n",
      "ma F1:  0.812610081466937\n",
      "mi F1:  0.8180751173708921\n",
      "we F1:  0.8133237287671099\n",
      "Eval Loss:  0.14621642231941223\n",
      "Eval Loss:  0.2774060368537903\n",
      "Eval Loss:  0.14212875068187714\n",
      "Eval Loss:  0.20772185921669006\n",
      "Eval Loss:  0.1604638546705246\n",
      "Eval Loss:  0.15177716314792633\n",
      "Eval Loss:  0.22242121398448944\n",
      "Eval Loss:  0.26498880982398987\n",
      "Eval Loss:  0.1792224496603012\n",
      "Eval Loss:  0.144255131483078\n",
      "Eval Loss:  0.19504685699939728\n",
      "Eval Loss:  0.21200428903102875\n",
      "Eval Loss:  0.19915038347244263\n",
      "Eval Loss:  0.22247983515262604\n",
      "Eval Loss:  0.18915748596191406\n",
      "Eval Loss:  0.22131164371967316\n",
      "Eval Loss:  0.22948695719242096\n",
      "Eval Loss:  0.11752132326364517\n",
      "Eval Loss:  0.2258516550064087\n",
      "Eval Loss:  0.26644864678382874\n",
      "Eval Loss:  0.1461259126663208\n",
      "Eval Loss:  0.19745339453220367\n",
      "Eval Loss:  0.18376654386520386\n",
      "Eval Loss:  0.20643757283687592\n",
      "Eval Loss:  0.18249213695526123\n",
      "Eval Loss:  0.1311550885438919\n",
      "Eval Loss:  0.1621088832616806\n",
      "Eval Loss:  0.22225981950759888\n",
      "[[17636   786]\n",
      " [ 1465  9596]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18422\n",
      "           1       0.92      0.87      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9236509174778686\n",
      "pre:  0.924292043922173\n",
      "rec:  0.8675526625079106\n",
      "ma F1:  0.9175170721419048\n",
      "mi F1:  0.9236509174778688\n",
      "we F1:  0.9231328974550926\n",
      "29483 461\n",
      "Loss:  0.06960933655500412\n",
      "Loss:  0.016426853835582733\n",
      "Loss:  0.04632967710494995\n",
      "48 **********\n",
      "Epoch:  4653.738847255707  fold:  9  kers:  128\n",
      "epoch:  49\n",
      "29483 461\n",
      "Loss:  0.05292392894625664\n",
      "Loss:  0.04465578868985176\n",
      "Loss:  0.051800716668367386\n",
      "49 **********\n",
      "Epoch:  4734.345321655273  fold:  9  kers:  128\n",
      "epoch:  50\n",
      "29483 461\n",
      "Loss:  0.046431176364421844\n",
      "Loss:  0.04135359823703766\n",
      "Loss:  0.10103379189968109\n",
      "50 **********\n",
      "Epoch:  4814.993684768677  fold:  9  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.038599513471126556\n",
      "Eval Loss:  1.825946569442749\n",
      "Eval Loss:  0.13078394532203674\n",
      "[[1616  126]\n",
      " [ 458 1208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85      1742\n",
      "           1       0.91      0.73      0.81      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.84      0.83      0.83      3408\n",
      "weighted avg       0.84      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8286384976525821\n",
      "pre:  0.9055472263868066\n",
      "rec:  0.7250900360144058\n",
      "ma F1:  0.826146750524109\n",
      "mi F1:  0.8286384976525821\n",
      "we F1:  0.8266108994990207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1553936004638672\n",
      "Eval Loss:  0.22907748818397522\n",
      "Eval Loss:  0.1332520842552185\n",
      "Eval Loss:  0.19172793626785278\n",
      "Eval Loss:  0.16935627162456512\n",
      "Eval Loss:  0.1128203421831131\n",
      "Eval Loss:  0.24366158246994019\n",
      "Eval Loss:  0.2599848806858063\n",
      "Eval Loss:  0.15971647202968597\n",
      "Eval Loss:  0.15543848276138306\n",
      "Eval Loss:  0.17770668864250183\n",
      "Eval Loss:  0.20603156089782715\n",
      "Eval Loss:  0.15577249228954315\n",
      "Eval Loss:  0.20329490303993225\n",
      "Eval Loss:  0.17409998178482056\n",
      "Eval Loss:  0.21915748715400696\n",
      "Eval Loss:  0.23644223809242249\n",
      "Eval Loss:  0.14928843080997467\n",
      "Eval Loss:  0.1835361123085022\n",
      "Eval Loss:  0.2398136556148529\n",
      "Eval Loss:  0.12016303837299347\n",
      "Eval Loss:  0.18314029276371002\n",
      "Eval Loss:  0.16704542934894562\n",
      "Eval Loss:  0.2160405069589615\n",
      "Eval Loss:  0.2215804159641266\n",
      "Eval Loss:  0.1272796094417572\n",
      "Eval Loss:  0.1583573818206787\n",
      "Eval Loss:  0.19986306130886078\n",
      "[[17454   968]\n",
      " [ 1147  9914]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18422\n",
      "           1       0.91      0.90      0.90     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9282637452091036\n",
      "pre:  0.9110457636463886\n",
      "rec:  0.8963023234788898\n",
      "ma F1:  0.9232436288814427\n",
      "mi F1:  0.9282637452091036\n",
      "we F1:  0.9281445673811657\n",
      "29483 461\n",
      "Loss:  0.06932394206523895\n",
      "Loss:  0.0595688559114933\n",
      "Loss:  0.07338051497936249\n",
      "51 **********\n",
      "Epoch:  4938.85450553894  fold:  9  kers:  128\n",
      "epoch:  52\n",
      "29483 461\n",
      "Loss:  0.055638767778873444\n",
      "Loss:  0.03785572201013565\n",
      "Loss:  0.03878210857510567\n",
      "52 **********\n",
      "Epoch:  5019.51683139801  fold:  9  kers:  128\n",
      "epoch:  53\n",
      "29483 461\n",
      "Loss:  0.04153487831354141\n",
      "Loss:  0.02917609177529812\n",
      "Loss:  0.04211633279919624\n",
      "53 **********\n",
      "Epoch:  5101.867641687393  fold:  9  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.03311583027243614\n",
      "Eval Loss:  1.5601763725280762\n",
      "Eval Loss:  0.17622323334217072\n",
      "[[1701   41]\n",
      " [ 684  982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82      1742\n",
      "           1       0.96      0.59      0.73      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.84      0.78      0.78      3408\n",
      "weighted avg       0.83      0.79      0.78      3408\n",
      "\n",
      "acc:  0.7872652582159625\n",
      "pre:  0.9599217986314761\n",
      "rec:  0.5894357743097239\n",
      "ma F1:  0.7773553203815309\n",
      "mi F1:  0.7872652582159625\n",
      "we F1:  0.7784028242416375\n",
      "Eval Loss:  0.13061636686325073\n",
      "Eval Loss:  0.2670822739601135\n",
      "Eval Loss:  0.14104248583316803\n",
      "Eval Loss:  0.17296157777309418\n",
      "Eval Loss:  0.13729014992713928\n",
      "Eval Loss:  0.1439126580953598\n",
      "Eval Loss:  0.23246534168720245\n",
      "Eval Loss:  0.2778436243534088\n",
      "Eval Loss:  0.15401999652385712\n",
      "Eval Loss:  0.15338920056819916\n",
      "Eval Loss:  0.17679618299007416\n",
      "Eval Loss:  0.20236968994140625\n",
      "Eval Loss:  0.13856622576713562\n",
      "Eval Loss:  0.21072879433631897\n",
      "Eval Loss:  0.19190794229507446\n",
      "Eval Loss:  0.20382234454154968\n",
      "Eval Loss:  0.2174205482006073\n",
      "Eval Loss:  0.15722578763961792\n",
      "Eval Loss:  0.2536086142063141\n",
      "Eval Loss:  0.23589707911014557\n",
      "Eval Loss:  0.14645758271217346\n",
      "Eval Loss:  0.18736577033996582\n",
      "Eval Loss:  0.18308992683887482\n",
      "Eval Loss:  0.20528008043766022\n",
      "Eval Loss:  0.21725794672966003\n",
      "Eval Loss:  0.12784405052661896\n",
      "Eval Loss:  0.19054670631885529\n",
      "Eval Loss:  0.21980924904346466\n",
      "[[17830   592]\n",
      " [ 1578  9483]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     18422\n",
      "           1       0.94      0.86      0.90     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.93      0.91      0.92     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9263982634060306\n",
      "pre:  0.9412406947890819\n",
      "rec:  0.8573365880119338\n",
      "ma F1:  0.9199848424452755\n",
      "mi F1:  0.9263982634060306\n",
      "we F1:  0.9256406698913181\n",
      "29483 461\n",
      "Loss:  0.05105016753077507\n",
      "Loss:  0.061112817376852036\n",
      "Loss:  0.0977851152420044\n",
      "54 **********\n",
      "Epoch:  5225.955854892731  fold:  9  kers:  128\n",
      "epoch:  55\n",
      "29483 461\n",
      "Loss:  0.04303336888551712\n",
      "Loss:  0.03888082876801491\n",
      "Loss:  0.05701574683189392\n",
      "55 **********\n",
      "Epoch:  5311.659700393677  fold:  9  kers:  128\n",
      "epoch:  56\n",
      "29483 461\n",
      "Loss:  0.03308046609163284\n",
      "Loss:  0.0557742565870285\n",
      "Loss:  0.014820131473243237\n",
      "56 **********\n",
      "Epoch:  5392.250217914581  fold:  9  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.03267186880111694\n",
      "Eval Loss:  1.6990270614624023\n",
      "Eval Loss:  0.17533157765865326\n",
      "[[1689   53]\n",
      " [ 606 1060]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84      1742\n",
      "           1       0.95      0.64      0.76      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.80      0.80      3408\n",
      "weighted avg       0.84      0.81      0.80      3408\n",
      "\n",
      "acc:  0.806631455399061\n",
      "pre:  0.9523809523809523\n",
      "rec:  0.6362545018007203\n",
      "ma F1:  0.7998121549827464\n",
      "mi F1:  0.8066314553990611\n",
      "we F1:  0.8006361086101548\n",
      "Eval Loss:  0.15767718851566315\n",
      "Eval Loss:  0.22744062542915344\n",
      "Eval Loss:  0.13101129233837128\n",
      "Eval Loss:  0.1939307451248169\n",
      "Eval Loss:  0.12816819548606873\n",
      "Eval Loss:  0.130343496799469\n",
      "Eval Loss:  0.23505115509033203\n",
      "Eval Loss:  0.2573031485080719\n",
      "Eval Loss:  0.18576852977275848\n",
      "Eval Loss:  0.13824167847633362\n",
      "Eval Loss:  0.18402642011642456\n",
      "Eval Loss:  0.19881032407283783\n",
      "Eval Loss:  0.17499998211860657\n",
      "Eval Loss:  0.18463528156280518\n",
      "Eval Loss:  0.1957009881734848\n",
      "Eval Loss:  0.22268298268318176\n",
      "Eval Loss:  0.2324412316083908\n",
      "Eval Loss:  0.15114235877990723\n",
      "Eval Loss:  0.22496956586837769\n",
      "Eval Loss:  0.26013311743736267\n",
      "Eval Loss:  0.1373157501220703\n",
      "Eval Loss:  0.1774093061685562\n",
      "Eval Loss:  0.18629801273345947\n",
      "Eval Loss:  0.2108154147863388\n",
      "Eval Loss:  0.2193499654531479\n",
      "Eval Loss:  0.12065206468105316\n",
      "Eval Loss:  0.17168231308460236\n",
      "Eval Loss:  0.2016332447528839\n",
      "[[17808   614]\n",
      " [ 1547  9514]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     18422\n",
      "           1       0.94      0.86      0.90     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.93      0.91      0.92     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9267035240647152\n",
      "pre:  0.9393759873617693\n",
      "rec:  0.8601392279179098\n",
      "ma F1:  0.9204045005533859\n",
      "mi F1:  0.9267035240647152\n",
      "we F1:  0.9259949408797538\n",
      "29483 461\n",
      "Loss:  0.07058471441268921\n",
      "Loss:  0.04050580784678459\n",
      "Loss:  0.041793953627347946\n",
      "57 **********\n",
      "Epoch:  5516.087103366852  fold:  9  kers:  128\n",
      "epoch:  58\n",
      "29483 461\n",
      "Loss:  0.05825885012745857\n",
      "Loss:  0.0498628132045269\n",
      "Loss:  0.049182020127773285\n",
      "58 **********\n",
      "Epoch:  5596.732473611832  fold:  9  kers:  128\n",
      "epoch:  59\n",
      "29483 461\n",
      "Loss:  0.04220246151089668\n",
      "Loss:  0.0506015345454216\n",
      "Loss:  0.022136911749839783\n",
      "59 **********\n",
      "Epoch:  5677.370862960815  fold:  9  kers:  128\n",
      "Eval Loss:  0.0380677729845047\n",
      "Eval Loss:  1.5753319263458252\n",
      "Eval Loss:  0.1784767210483551\n",
      "[[1704   38]\n",
      " [ 548 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.85      1742\n",
      "           1       0.97      0.67      0.79      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.86      0.82      0.82      3408\n",
      "weighted avg       0.86      0.83      0.82      3408\n",
      "\n",
      "acc:  0.8280516431924883\n",
      "pre:  0.967128027681661\n",
      "rec:  0.6710684273709484\n",
      "ma F1:  0.8228128869420359\n",
      "mi F1:  0.8280516431924883\n",
      "we F1:  0.8234923160803199\n",
      "update!  Acc:  0.8436032863849765\n",
      "Epoch:  5681.942639350891  fold:  9  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29871 3020\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29871 467\n",
      "Loss:  0.1620703786611557\n",
      "Loss:  0.16361688077449799\n",
      "Loss:  0.15808847546577454\n",
      "0 **********\n",
      "Epoch:  93.88696479797363  fold:  10  kers:  128\n",
      "epoch:  1\n",
      "29871 467\n",
      "Loss:  0.1423080861568451\n",
      "Loss:  0.15516509115695953\n",
      "Loss:  0.11895902454853058\n",
      "1 **********\n",
      "Epoch:  175.53565287590027  fold:  10  kers:  128\n",
      "epoch:  2\n",
      "29871 467\n",
      "Loss:  0.10424964129924774\n",
      "Loss:  0.09364669024944305\n",
      "Loss:  0.11018872261047363\n",
      "2 **********\n",
      "Epoch:  257.17636275291443  fold:  10  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.4519112706184387\n",
      "Eval Loss:  0.3309776782989502\n",
      "Eval Loss:  0.1644388735294342\n",
      "[[1506  245]\n",
      " [ 138 1131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89      1751\n",
      "           1       0.82      0.89      0.86      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.87      0.88      0.87      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8731788079470199\n",
      "pre:  0.8219476744186046\n",
      "rec:  0.8912529550827423\n",
      "ma F1:  0.8711927637385124\n",
      "mi F1:  0.8731788079470199\n",
      "we F1:  0.8737454925611807\n",
      "update!  Acc:  0.8731788079470199\n",
      "Eval Loss:  0.43861934542655945\n",
      "Eval Loss:  0.40706318616867065\n",
      "Eval Loss:  0.3720974922180176\n",
      "Eval Loss:  0.3883970379829407\n",
      "Eval Loss:  0.37476789951324463\n",
      "Eval Loss:  0.4713645577430725\n",
      "Eval Loss:  0.4280387759208679\n",
      "Eval Loss:  0.47325584292411804\n",
      "Eval Loss:  0.47071948647499084\n",
      "Eval Loss:  0.39760056138038635\n",
      "Eval Loss:  0.3490389287471771\n",
      "Eval Loss:  0.410078227519989\n",
      "Eval Loss:  0.5012596249580383\n",
      "Eval Loss:  0.46062618494033813\n",
      "Eval Loss:  0.49938175082206726\n",
      "Eval Loss:  0.4347652196884155\n",
      "Eval Loss:  0.3484548330307007\n",
      "Eval Loss:  0.39142629504203796\n",
      "Eval Loss:  0.3249368965625763\n",
      "Eval Loss:  0.4494996964931488\n",
      "Eval Loss:  0.38054928183555603\n",
      "Eval Loss:  0.3057289123535156\n",
      "Eval Loss:  0.4172455668449402\n",
      "Eval Loss:  0.41566216945648193\n",
      "Eval Loss:  0.4144754707813263\n",
      "Eval Loss:  0.4381241500377655\n",
      "Eval Loss:  0.43034830689430237\n",
      "Eval Loss:  0.41781580448150635\n",
      "Eval Loss:  0.5278095602989197\n",
      "[[15583  2830]\n",
      " [ 2778  8680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     18413\n",
      "           1       0.75      0.76      0.76     11458\n",
      "\n",
      "    accuracy                           0.81     29871\n",
      "   macro avg       0.80      0.80      0.80     29871\n",
      "weighted avg       0.81      0.81      0.81     29871\n",
      "\n",
      "acc:  0.8122593820093067\n",
      "pre:  0.7541268462206777\n",
      "rec:  0.7575493105253971\n",
      "ma F1:  0.8016675779347306\n",
      "mi F1:  0.8122593820093067\n",
      "we F1:  0.8123391696106217\n",
      "29871 467\n",
      "Loss:  0.1166442483663559\n",
      "Loss:  0.08309091627597809\n",
      "Loss:  0.12110361456871033\n",
      "3 **********\n",
      "Epoch:  382.2599139213562  fold:  10  kers:  128\n",
      "epoch:  4\n",
      "29871 467\n",
      "Loss:  0.0819796770811081\n",
      "Loss:  0.09243431687355042\n",
      "Loss:  0.10800560563802719\n",
      "4 **********\n",
      "Epoch:  463.77695393562317  fold:  10  kers:  128\n",
      "epoch:  5\n",
      "29871 467\n",
      "Loss:  0.06222044676542282\n",
      "Loss:  0.08964239805936813\n",
      "Loss:  0.11223779618740082\n",
      "5 **********\n",
      "Epoch:  545.2890074253082  fold:  10  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.7607675194740295\n",
      "Eval Loss:  0.14329740405082703\n",
      "Eval Loss:  0.10605461895465851\n",
      "[[1660   91]\n",
      " [ 261 1008]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      1751\n",
      "           1       0.92      0.79      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.89      0.87      0.88      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8834437086092716\n",
      "pre:  0.9171974522292994\n",
      "rec:  0.7943262411347518\n",
      "ma F1:  0.8777453924512748\n",
      "mi F1:  0.8834437086092716\n",
      "we F1:  0.8819579513288124\n",
      "update!  Acc:  0.8834437086092716\n",
      "Eval Loss:  0.44866788387298584\n",
      "Eval Loss:  0.45566895604133606\n",
      "Eval Loss:  0.40831273794174194\n",
      "Eval Loss:  0.38723990321159363\n",
      "Eval Loss:  0.43212464451789856\n",
      "Eval Loss:  0.48155656456947327\n",
      "Eval Loss:  0.37336117029190063\n",
      "Eval Loss:  0.39548686146736145\n",
      "Eval Loss:  0.518234133720398\n",
      "Eval Loss:  0.4743722379207611\n",
      "Eval Loss:  0.27847447991371155\n",
      "Eval Loss:  0.38461682200431824\n",
      "Eval Loss:  0.5568086504936218\n",
      "Eval Loss:  0.4485264718532562\n",
      "Eval Loss:  0.4593212306499481\n",
      "Eval Loss:  0.45140257477760315\n",
      "Eval Loss:  0.2970249652862549\n",
      "Eval Loss:  0.4081028699874878\n",
      "Eval Loss:  0.3346433639526367\n",
      "Eval Loss:  0.4763970673084259\n",
      "Eval Loss:  0.4132745563983917\n",
      "Eval Loss:  0.2779749035835266\n",
      "Eval Loss:  0.35119497776031494\n",
      "Eval Loss:  0.4290911555290222\n",
      "Eval Loss:  0.38760364055633545\n",
      "Eval Loss:  0.40709054470062256\n",
      "Eval Loss:  0.5088620781898499\n",
      "Eval Loss:  0.4111282229423523\n",
      "Eval Loss:  0.5985313057899475\n",
      "[[17560   853]\n",
      " [ 4116  7342]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88     18413\n",
      "           1       0.90      0.64      0.75     11458\n",
      "\n",
      "    accuracy                           0.83     29871\n",
      "   macro avg       0.85      0.80      0.81     29871\n",
      "weighted avg       0.84      0.83      0.83     29871\n",
      "\n",
      "acc:  0.8336513675471193\n",
      "pre:  0.8959121415497254\n",
      "rec:  0.6407750043637633\n",
      "ma F1:  0.811607034979136\n",
      "mi F1:  0.8336513675471193\n",
      "we F1:  0.8266117651621782\n",
      "29871 467\n",
      "Loss:  0.07992395758628845\n",
      "Loss:  0.08816057443618774\n",
      "Loss:  0.06788664311170578\n",
      "6 **********\n",
      "Epoch:  670.0334663391113  fold:  10  kers:  128\n",
      "epoch:  7\n",
      "29871 467\n",
      "Loss:  0.0781150683760643\n",
      "Loss:  0.08635267615318298\n",
      "Loss:  0.07914690673351288\n",
      "7 **********\n",
      "Epoch:  751.5933918952942  fold:  10  kers:  128\n",
      "epoch:  8\n",
      "29871 467\n",
      "Loss:  0.09388411790132523\n",
      "Loss:  0.07823202759027481\n",
      "Loss:  0.09850972890853882\n",
      "8 **********\n",
      "Epoch:  833.175258398056  fold:  10  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.5016604661941528\n",
      "Eval Loss:  0.15532228350639343\n",
      "Eval Loss:  0.0955405980348587\n",
      "[[1638  113]\n",
      " [ 200 1069]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      1751\n",
      "           1       0.90      0.84      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.89      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8963576158940397\n",
      "pre:  0.9043993231810491\n",
      "rec:  0.8423955870764381\n",
      "ma F1:  0.8925430496806792\n",
      "mi F1:  0.8963576158940397\n",
      "we F1:  0.8957743693904151\n",
      "update!  Acc:  0.8963576158940397\n",
      "Eval Loss:  0.3114389181137085\n",
      "Eval Loss:  0.3289712071418762\n",
      "Eval Loss:  0.3050961494445801\n",
      "Eval Loss:  0.31451448798179626\n",
      "Eval Loss:  0.338546484708786\n",
      "Eval Loss:  0.36182349920272827\n",
      "Eval Loss:  0.3293064832687378\n",
      "Eval Loss:  0.351693332195282\n",
      "Eval Loss:  0.3157670497894287\n",
      "Eval Loss:  0.32441550493240356\n",
      "Eval Loss:  0.21595101058483124\n",
      "Eval Loss:  0.37477990984916687\n",
      "Eval Loss:  0.35060572624206543\n",
      "Eval Loss:  0.3634304106235504\n",
      "Eval Loss:  0.3507234752178192\n",
      "Eval Loss:  0.25141024589538574\n",
      "Eval Loss:  0.21591050922870636\n",
      "Eval Loss:  0.29877641797065735\n",
      "Eval Loss:  0.2768515646457672\n",
      "Eval Loss:  0.3524686396121979\n",
      "Eval Loss:  0.2770705223083496\n",
      "Eval Loss:  0.24031643569469452\n",
      "Eval Loss:  0.31265947222709656\n",
      "Eval Loss:  0.3318685293197632\n",
      "Eval Loss:  0.2983197569847107\n",
      "Eval Loss:  0.3387002646923065\n",
      "Eval Loss:  0.34836840629577637\n",
      "Eval Loss:  0.3741593062877655\n",
      "Eval Loss:  0.40094903111457825\n",
      "[[17252  1161]\n",
      " [ 2767  8691]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     18413\n",
      "           1       0.88      0.76      0.82     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.87      0.85      0.86     29871\n",
      "weighted avg       0.87      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8685012219209266\n",
      "pre:  0.8821559074299634\n",
      "rec:  0.7585093384534822\n",
      "ma F1:  0.8567334490927512\n",
      "mi F1:  0.8685012219209266\n",
      "we F1:  0.8662936476700156\n",
      "29871 467\n",
      "Loss:  0.10260976105928421\n",
      "Loss:  0.08212733268737793\n",
      "Loss:  0.08087754249572754\n",
      "9 **********\n",
      "Epoch:  958.0912578105927  fold:  10  kers:  128\n",
      "epoch:  10\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06308730691671371\n",
      "Loss:  0.049808405339717865\n",
      "Loss:  0.06631195545196533\n",
      "10 **********\n",
      "Epoch:  1039.6491889953613  fold:  10  kers:  128\n",
      "epoch:  11\n",
      "29871 467\n",
      "Loss:  0.08738826960325241\n",
      "Loss:  0.10029975324869156\n",
      "Loss:  0.06904846429824829\n",
      "11 **********\n",
      "Epoch:  1121.2121059894562  fold:  10  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.5767215490341187\n",
      "Eval Loss:  0.1409621685743332\n",
      "Eval Loss:  0.08514022827148438\n",
      "[[1631  120]\n",
      " [ 208 1061]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1751\n",
      "           1       0.90      0.84      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.88      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8913907284768212\n",
      "pre:  0.8983911939034717\n",
      "rec:  0.8360914105594957\n",
      "ma F1:  0.8873787732363141\n",
      "mi F1:  0.8913907284768212\n",
      "we F1:  0.8907713388958306\n",
      "Eval Loss:  0.2483101189136505\n",
      "Eval Loss:  0.2857535481452942\n",
      "Eval Loss:  0.2470359057188034\n",
      "Eval Loss:  0.29140737652778625\n",
      "Eval Loss:  0.2866472601890564\n",
      "Eval Loss:  0.34355273842811584\n",
      "Eval Loss:  0.2900763750076294\n",
      "Eval Loss:  0.3065933287143707\n",
      "Eval Loss:  0.22038234770298004\n",
      "Eval Loss:  0.27763810753822327\n",
      "Eval Loss:  0.18955470621585846\n",
      "Eval Loss:  0.3187161684036255\n",
      "Eval Loss:  0.29463082551956177\n",
      "Eval Loss:  0.34320783615112305\n",
      "Eval Loss:  0.2713279724121094\n",
      "Eval Loss:  0.2248670905828476\n",
      "Eval Loss:  0.21442709863185883\n",
      "Eval Loss:  0.246693953871727\n",
      "Eval Loss:  0.2517862915992737\n",
      "Eval Loss:  0.2920735776424408\n",
      "Eval Loss:  0.25760409235954285\n",
      "Eval Loss:  0.2173127830028534\n",
      "Eval Loss:  0.26208698749542236\n",
      "Eval Loss:  0.3035117983818054\n",
      "Eval Loss:  0.23933181166648865\n",
      "Eval Loss:  0.299896776676178\n",
      "Eval Loss:  0.3176124393939972\n",
      "Eval Loss:  0.30539578199386597\n",
      "Eval Loss:  0.29865604639053345\n",
      "[[16934  1479]\n",
      " [ 1872  9586]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     18413\n",
      "           1       0.87      0.84      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.88      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8878176157477152\n",
      "pre:  0.8663352914595571\n",
      "rec:  0.8366207016931402\n",
      "ma F1:  0.8805920472228003\n",
      "mi F1:  0.8878176157477152\n",
      "we F1:  0.8874311638655307\n",
      "29871 467\n",
      "Loss:  0.0922127217054367\n",
      "Loss:  0.08957380801439285\n",
      "Loss:  0.051362305879592896\n",
      "12 **********\n",
      "Epoch:  1246.0612847805023  fold:  10  kers:  128\n",
      "epoch:  13\n",
      "29871 467\n",
      "Loss:  0.045640185475349426\n",
      "Loss:  0.05518463999032974\n",
      "Loss:  0.09109900146722794\n",
      "13 **********\n",
      "Epoch:  1327.549402475357  fold:  10  kers:  128\n",
      "epoch:  14\n",
      "29871 467\n",
      "Loss:  0.06788621097803116\n",
      "Loss:  0.07418175786733627\n",
      "Loss:  0.07523605972528458\n",
      "14 **********\n",
      "Epoch:  1409.0514824390411  fold:  10  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.4777541756629944\n",
      "Eval Loss:  0.09619807451963425\n",
      "Eval Loss:  0.031701117753982544\n",
      "[[1684   67]\n",
      " [ 215 1054]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      1751\n",
      "           1       0.94      0.83      0.88      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9066225165562913\n",
      "pre:  0.9402319357716324\n",
      "rec:  0.830575256107171\n",
      "ma F1:  0.9023740471141171\n",
      "mi F1:  0.9066225165562913\n",
      "we F1:  0.9056244634174949\n",
      "update!  Acc:  0.9066225165562913\n",
      "Eval Loss:  0.2299707978963852\n",
      "Eval Loss:  0.26297420263290405\n",
      "Eval Loss:  0.232954204082489\n",
      "Eval Loss:  0.28250065445899963\n",
      "Eval Loss:  0.30021119117736816\n",
      "Eval Loss:  0.28696414828300476\n",
      "Eval Loss:  0.2813447415828705\n",
      "Eval Loss:  0.3038597106933594\n",
      "Eval Loss:  0.22364568710327148\n",
      "Eval Loss:  0.2541288137435913\n",
      "Eval Loss:  0.18092595040798187\n",
      "Eval Loss:  0.3075783848762512\n",
      "Eval Loss:  0.31733277440071106\n",
      "Eval Loss:  0.34277644753456116\n",
      "Eval Loss:  0.2377014309167862\n",
      "Eval Loss:  0.22128161787986755\n",
      "Eval Loss:  0.1988152265548706\n",
      "Eval Loss:  0.23456300795078278\n",
      "Eval Loss:  0.24318577349185944\n",
      "Eval Loss:  0.2930925488471985\n",
      "Eval Loss:  0.2693204879760742\n",
      "Eval Loss:  0.20970793068408966\n",
      "Eval Loss:  0.2521035075187683\n",
      "Eval Loss:  0.31335678696632385\n",
      "Eval Loss:  0.22569496929645538\n",
      "Eval Loss:  0.270620733499527\n",
      "Eval Loss:  0.3098727762699127\n",
      "Eval Loss:  0.27813267707824707\n",
      "Eval Loss:  0.2818174958229065\n",
      "[[17306  1107]\n",
      " [ 2138  9320]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     18413\n",
      "           1       0.89      0.81      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.891366208027853\n",
      "pre:  0.8938333173491896\n",
      "rec:  0.8134054808867167\n",
      "ma F1:  0.8830038105773135\n",
      "mi F1:  0.891366208027853\n",
      "we F1:  0.8902866147682105\n",
      "29871 467\n",
      "Loss:  0.05468698963522911\n",
      "Loss:  0.050972964614629745\n",
      "Loss:  0.05194751173257828\n",
      "15 **********\n",
      "Epoch:  1533.6453437805176  fold:  10  kers:  128\n",
      "epoch:  16\n",
      "29871 467\n",
      "Loss:  0.06584616005420685\n",
      "Loss:  0.06769685447216034\n",
      "Loss:  0.05803871154785156\n",
      "16 **********\n",
      "Epoch:  1615.1424369812012  fold:  10  kers:  128\n",
      "epoch:  17\n",
      "29871 467\n",
      "Loss:  0.07446390390396118\n",
      "Loss:  0.07460836321115494\n",
      "Loss:  0.07114529609680176\n",
      "17 **********\n",
      "Epoch:  1696.6574819087982  fold:  10  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.9907921552658081\n",
      "Eval Loss:  0.08616343140602112\n",
      "Eval Loss:  0.03106226958334446\n",
      "[[1646  105]\n",
      " [ 369  900]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87      1751\n",
      "           1       0.90      0.71      0.79      1269\n",
      "\n",
      "    accuracy                           0.84      3020\n",
      "   macro avg       0.86      0.82      0.83      3020\n",
      "weighted avg       0.85      0.84      0.84      3020\n",
      "\n",
      "acc:  0.8430463576158941\n",
      "pre:  0.8955223880597015\n",
      "rec:  0.7092198581560284\n",
      "ma F1:  0.8328468718165729\n",
      "mi F1:  0.8430463576158941\n",
      "we F1:  0.8394368881105042\n",
      "Eval Loss:  0.30742526054382324\n",
      "Eval Loss:  0.2848365604877472\n",
      "Eval Loss:  0.3150046467781067\n",
      "Eval Loss:  0.2893200218677521\n",
      "Eval Loss:  0.34747985005378723\n",
      "Eval Loss:  0.3239637613296509\n",
      "Eval Loss:  0.285565584897995\n",
      "Eval Loss:  0.31926876306533813\n",
      "Eval Loss:  0.2569909989833832\n",
      "Eval Loss:  0.2748450040817261\n",
      "Eval Loss:  0.1628562957048416\n",
      "Eval Loss:  0.3376198709011078\n",
      "Eval Loss:  0.30914682149887085\n",
      "Eval Loss:  0.3792504668235779\n",
      "Eval Loss:  0.28428101539611816\n",
      "Eval Loss:  0.2650754749774933\n",
      "Eval Loss:  0.2067365199327469\n",
      "Eval Loss:  0.2696842551231384\n",
      "Eval Loss:  0.24247169494628906\n",
      "Eval Loss:  0.32948413491249084\n",
      "Eval Loss:  0.30108100175857544\n",
      "Eval Loss:  0.2401759773492813\n",
      "Eval Loss:  0.2894449830055237\n",
      "Eval Loss:  0.2841006815433502\n",
      "Eval Loss:  0.2082212120294571\n",
      "Eval Loss:  0.2496873140335083\n",
      "Eval Loss:  0.34591740369796753\n",
      "Eval Loss:  0.3350796699523926\n",
      "Eval Loss:  0.3740837872028351\n",
      "[[17515   898]\n",
      " [ 2440  9018]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18413\n",
      "           1       0.91      0.79      0.84     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.888252820461317\n",
      "pre:  0.909439290036305\n",
      "rec:  0.787048350497469\n",
      "ma F1:  0.8784146840381083\n",
      "mi F1:  0.888252820461317\n",
      "we F1:  0.8864674366358977\n",
      "29871 467\n",
      "Loss:  0.057201847434043884\n",
      "Loss:  0.10802193731069565\n",
      "Loss:  0.09526267647743225\n",
      "18 **********\n",
      "Epoch:  1821.3700261116028  fold:  10  kers:  128\n",
      "epoch:  19\n",
      "29871 467\n",
      "Loss:  0.04381893202662468\n",
      "Loss:  0.06857109814882278\n",
      "Loss:  0.06047474965453148\n",
      "19 **********\n",
      "Epoch:  1902.8481702804565  fold:  10  kers:  128\n",
      "epoch:  20\n",
      "29871 467\n",
      "Loss:  0.07350753247737885\n",
      "Loss:  0.04636663198471069\n",
      "Loss:  0.0690702274441719\n",
      "20 **********\n",
      "Epoch:  1984.3362874984741  fold:  10  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.31944823265075684\n",
      "Eval Loss:  0.09790251404047012\n",
      "Eval Loss:  0.026478391140699387\n",
      "[[1680   71]\n",
      " [ 180 1089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      1751\n",
      "           1       0.94      0.86      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.916887417218543\n",
      "pre:  0.9387931034482758\n",
      "rec:  0.8581560283687943\n",
      "ma F1:  0.9135777316440468\n",
      "mi F1:  0.916887417218543\n",
      "we F1:  0.916277001435768\n",
      "update!  Acc:  0.916887417218543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21471728384494781\n",
      "Eval Loss:  0.2544800043106079\n",
      "Eval Loss:  0.18606586754322052\n",
      "Eval Loss:  0.2571364641189575\n",
      "Eval Loss:  0.27357515692710876\n",
      "Eval Loss:  0.25021225214004517\n",
      "Eval Loss:  0.2896520495414734\n",
      "Eval Loss:  0.26343992352485657\n",
      "Eval Loss:  0.17082908749580383\n",
      "Eval Loss:  0.22895309329032898\n",
      "Eval Loss:  0.15873046219348907\n",
      "Eval Loss:  0.2759019434452057\n",
      "Eval Loss:  0.2800922095775604\n",
      "Eval Loss:  0.3089589774608612\n",
      "Eval Loss:  0.230779230594635\n",
      "Eval Loss:  0.1648414134979248\n",
      "Eval Loss:  0.1897752583026886\n",
      "Eval Loss:  0.21153074502944946\n",
      "Eval Loss:  0.18749570846557617\n",
      "Eval Loss:  0.2425844669342041\n",
      "Eval Loss:  0.2727341949939728\n",
      "Eval Loss:  0.1595630943775177\n",
      "Eval Loss:  0.23257936537265778\n",
      "Eval Loss:  0.28307366371154785\n",
      "Eval Loss:  0.21103961765766144\n",
      "Eval Loss:  0.19332902133464813\n",
      "Eval Loss:  0.2570044696331024\n",
      "Eval Loss:  0.2552010715007782\n",
      "Eval Loss:  0.25331810116767883\n",
      "[[17370  1043]\n",
      " [ 1818  9640]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     18413\n",
      "           1       0.90      0.84      0.87     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.89      0.90     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9042214857219376\n",
      "pre:  0.9023682486193016\n",
      "rec:  0.8413335660673765\n",
      "ma F1:  0.8973471544518992\n",
      "mi F1:  0.9042214857219376\n",
      "we F1:  0.9035322739839972\n",
      "29871 467\n",
      "Loss:  0.09442431479692459\n",
      "Loss:  0.05236168950796127\n",
      "Loss:  0.0811234787106514\n",
      "21 **********\n",
      "Epoch:  2109.1256260871887  fold:  10  kers:  128\n",
      "epoch:  22\n",
      "29871 467\n",
      "Loss:  0.045801419764757156\n",
      "Loss:  0.06132739782333374\n",
      "Loss:  0.03995873034000397\n",
      "22 **********\n",
      "Epoch:  2190.61474108696  fold:  10  kers:  128\n",
      "epoch:  23\n",
      "29871 467\n",
      "Loss:  0.028868412598967552\n",
      "Loss:  0.07258763164281845\n",
      "Loss:  0.08099014312028885\n",
      "23 **********\n",
      "Epoch:  2272.109840154648  fold:  10  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.5519135594367981\n",
      "Eval Loss:  0.10090403258800507\n",
      "Eval Loss:  0.04357438161969185\n",
      "[[1602  149]\n",
      " [ 181 1088]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      1751\n",
      "           1       0.88      0.86      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.89      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.890728476821192\n",
      "pre:  0.8795472918350848\n",
      "rec:  0.8573680063041765\n",
      "ma F1:  0.887468716845276\n",
      "mi F1:  0.8907284768211922\n",
      "we F1:  0.890525534565882\n",
      "Eval Loss:  0.24635550379753113\n",
      "Eval Loss:  0.257413774728775\n",
      "Eval Loss:  0.20003969967365265\n",
      "Eval Loss:  0.30719199776649475\n",
      "Eval Loss:  0.25115063786506653\n",
      "Eval Loss:  0.24410676956176758\n",
      "Eval Loss:  0.30673182010650635\n",
      "Eval Loss:  0.280547171831131\n",
      "Eval Loss:  0.15908890962600708\n",
      "Eval Loss:  0.22864778339862823\n",
      "Eval Loss:  0.17713795602321625\n",
      "Eval Loss:  0.2560001015663147\n",
      "Eval Loss:  0.23261576890945435\n",
      "Eval Loss:  0.3507029116153717\n",
      "Eval Loss:  0.24750857055187225\n",
      "Eval Loss:  0.18280251324176788\n",
      "Eval Loss:  0.18034447729587555\n",
      "Eval Loss:  0.2334541231393814\n",
      "Eval Loss:  0.16439877450466156\n",
      "Eval Loss:  0.27361902594566345\n",
      "Eval Loss:  0.24645420908927917\n",
      "Eval Loss:  0.2178393006324768\n",
      "Eval Loss:  0.25331786274909973\n",
      "Eval Loss:  0.313918799161911\n",
      "Eval Loss:  0.2173413187265396\n",
      "Eval Loss:  0.2535547614097595\n",
      "Eval Loss:  0.26482275128364563\n",
      "Eval Loss:  0.28244340419769287\n",
      "Eval Loss:  0.22478049993515015\n",
      "[[16535  1878]\n",
      " [ 1072 10386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92     18413\n",
      "           1       0.85      0.91      0.88     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.89      0.90      0.90     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9012420072980483\n",
      "pre:  0.8468688845401174\n",
      "rec:  0.9064409146447897\n",
      "ma F1:  0.896871959067228\n",
      "mi F1:  0.9012420072980483\n",
      "we F1:  0.9018148254593822\n",
      "29871 467\n",
      "Loss:  0.08859708160161972\n",
      "Loss:  0.03976808860898018\n",
      "Loss:  0.09483347833156586\n",
      "24 **********\n",
      "Epoch:  2396.9669964313507  fold:  10  kers:  128\n",
      "epoch:  25\n",
      "29871 467\n",
      "Loss:  0.06950663775205612\n",
      "Loss:  0.04664580523967743\n",
      "Loss:  0.03569403663277626\n",
      "25 **********\n",
      "Epoch:  2478.4810445308685  fold:  10  kers:  128\n",
      "epoch:  26\n",
      "29871 467\n",
      "Loss:  0.06103617325425148\n",
      "Loss:  0.0430920235812664\n",
      "Loss:  0.05276025831699371\n",
      "26 **********\n",
      "Epoch:  2560.0210235118866  fold:  10  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.7835288047790527\n",
      "Eval Loss:  0.0846538245677948\n",
      "Eval Loss:  0.018711883574724197\n",
      "[[1651  100]\n",
      " [ 244 1025]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91      1751\n",
      "           1       0.91      0.81      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.88      0.88      3020\n",
      "weighted avg       0.89      0.89      0.88      3020\n",
      "\n",
      "acc:  0.8860927152317881\n",
      "pre:  0.9111111111111111\n",
      "rec:  0.8077226162332545\n",
      "ma F1:  0.8809787313410606\n",
      "mi F1:  0.8860927152317881\n",
      "we F1:  0.8849163355508539\n",
      "Eval Loss:  0.20723968744277954\n",
      "Eval Loss:  0.23321004211902618\n",
      "Eval Loss:  0.20056989789009094\n",
      "Eval Loss:  0.2336774468421936\n",
      "Eval Loss:  0.25605887174606323\n",
      "Eval Loss:  0.27521568536758423\n",
      "Eval Loss:  0.2819759249687195\n",
      "Eval Loss:  0.23249883949756622\n",
      "Eval Loss:  0.18385754525661469\n",
      "Eval Loss:  0.20187868177890778\n",
      "Eval Loss:  0.1301737129688263\n",
      "Eval Loss:  0.2306649088859558\n",
      "Eval Loss:  0.23785300552845\n",
      "Eval Loss:  0.27928945422172546\n",
      "Eval Loss:  0.2343323528766632\n",
      "Eval Loss:  0.1468970775604248\n",
      "Eval Loss:  0.16650986671447754\n",
      "Eval Loss:  0.2198944091796875\n",
      "Eval Loss:  0.15831387042999268\n",
      "Eval Loss:  0.2289220541715622\n",
      "Eval Loss:  0.25234469771385193\n",
      "Eval Loss:  0.1658291220664978\n",
      "Eval Loss:  0.20769281685352325\n",
      "Eval Loss:  0.2502462863922119\n",
      "Eval Loss:  0.17773856222629547\n",
      "Eval Loss:  0.19476920366287231\n",
      "Eval Loss:  0.21600082516670227\n",
      "Eval Loss:  0.22523905336856842\n",
      "Eval Loss:  0.24468837678432465\n",
      "[[17160  1253]\n",
      " [ 1379 10079]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18413\n",
      "           1       0.89      0.88      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.911887784138462\n",
      "pre:  0.889428168019767\n",
      "rec:  0.8796474079245942\n",
      "ma F1:  0.9066416059504302\n",
      "mi F1:  0.911887784138462\n",
      "we F1:  0.9117944331355398\n",
      "29871 467\n",
      "Loss:  0.058572977781295776\n",
      "Loss:  0.06610919535160065\n",
      "Loss:  0.0400003120303154\n",
      "27 **********\n",
      "Epoch:  2684.6807086467743  fold:  10  kers:  128\n",
      "epoch:  28\n",
      "29871 467\n",
      "Loss:  0.0515320710837841\n",
      "Loss:  0.07983778417110443\n",
      "Loss:  0.0796688050031662\n",
      "28 **********\n",
      "Epoch:  2766.151871919632  fold:  10  kers:  128\n",
      "epoch:  29\n",
      "29871 467\n",
      "Loss:  0.07606732100248337\n",
      "Loss:  0.04424213990569115\n",
      "Loss:  0.04856433719396591\n",
      "29 **********\n",
      "Epoch:  2847.6689116954803  fold:  10  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.6845617890357971\n",
      "Eval Loss:  0.09802871197462082\n",
      "Eval Loss:  0.014678606763482094\n",
      "[[1650  101]\n",
      " [ 210 1059]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      1751\n",
      "           1       0.91      0.83      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.89      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8970198675496689\n",
      "pre:  0.9129310344827586\n",
      "rec:  0.83451536643026\n",
      "ma F1:  0.8929190220768866\n",
      "mi F1:  0.8970198675496689\n",
      "we F1:  0.8962635356435211\n",
      "Eval Loss:  0.1964653879404068\n",
      "Eval Loss:  0.22345168888568878\n",
      "Eval Loss:  0.16689638793468475\n",
      "Eval Loss:  0.21461735665798187\n",
      "Eval Loss:  0.24413546919822693\n",
      "Eval Loss:  0.24539659917354584\n",
      "Eval Loss:  0.2622758448123932\n",
      "Eval Loss:  0.24695859849452972\n",
      "Eval Loss:  0.16088224947452545\n",
      "Eval Loss:  0.19834041595458984\n",
      "Eval Loss:  0.12639154493808746\n",
      "Eval Loss:  0.2316480576992035\n",
      "Eval Loss:  0.18697431683540344\n",
      "Eval Loss:  0.2789683938026428\n",
      "Eval Loss:  0.24597790837287903\n",
      "Eval Loss:  0.12762029469013214\n",
      "Eval Loss:  0.1405586451292038\n",
      "Eval Loss:  0.21535331010818481\n",
      "Eval Loss:  0.16907791793346405\n",
      "Eval Loss:  0.23425006866455078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.25031545758247375\n",
      "Eval Loss:  0.16134312748908997\n",
      "Eval Loss:  0.21081647276878357\n",
      "Eval Loss:  0.24164660274982452\n",
      "Eval Loss:  0.17555470764636993\n",
      "Eval Loss:  0.21336455643177032\n",
      "Eval Loss:  0.23440203070640564\n",
      "Eval Loss:  0.240980863571167\n",
      "Eval Loss:  0.24040164053440094\n",
      "[[17279  1134]\n",
      " [ 1438 10020]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18413\n",
      "           1       0.90      0.87      0.89     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9138964212781627\n",
      "pre:  0.8983324367939752\n",
      "rec:  0.87449816721941\n",
      "ma F1:  0.9084924769131972\n",
      "mi F1:  0.9138964212781628\n",
      "we F1:  0.9136701092397348\n",
      "29871 467\n",
      "Loss:  0.06858489662408829\n",
      "Loss:  0.06017056107521057\n",
      "Loss:  0.07052753865718842\n",
      "30 **********\n",
      "Epoch:  2972.329593896866  fold:  10  kers:  128\n",
      "epoch:  31\n",
      "29871 467\n",
      "Loss:  0.04945545643568039\n",
      "Loss:  0.059153106063604355\n",
      "Loss:  0.07014823704957962\n",
      "31 **********\n",
      "Epoch:  3053.8356630802155  fold:  10  kers:  128\n",
      "epoch:  32\n",
      "29871 467\n",
      "Loss:  0.051451969891786575\n",
      "Loss:  0.06666024029254913\n",
      "Loss:  0.06201603263616562\n",
      "32 **********\n",
      "Epoch:  3135.5461859703064  fold:  10  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.7097437977790833\n",
      "Eval Loss:  0.1087668389081955\n",
      "Eval Loss:  0.015765296295285225\n",
      "[[1658   93]\n",
      " [ 205 1064]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1751\n",
      "           1       0.92      0.84      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9013245033112582\n",
      "pre:  0.9196197061365601\n",
      "rec:  0.8384554767533491\n",
      "ma F1:  0.8973534724126336\n",
      "mi F1:  0.9013245033112582\n",
      "we F1:  0.9005757567445143\n",
      "Eval Loss:  0.19962148368358612\n",
      "Eval Loss:  0.2713567912578583\n",
      "Eval Loss:  0.15005892515182495\n",
      "Eval Loss:  0.21970359981060028\n",
      "Eval Loss:  0.2299196720123291\n",
      "Eval Loss:  0.24605034291744232\n",
      "Eval Loss:  0.2893606722354889\n",
      "Eval Loss:  0.2470530867576599\n",
      "Eval Loss:  0.1577148288488388\n",
      "Eval Loss:  0.17294056713581085\n",
      "Eval Loss:  0.1125984936952591\n",
      "Eval Loss:  0.20045146346092224\n",
      "Eval Loss:  0.24157477915287018\n",
      "Eval Loss:  0.25948765873908997\n",
      "Eval Loss:  0.25372761487960815\n",
      "Eval Loss:  0.10447688400745392\n",
      "Eval Loss:  0.14837998151779175\n",
      "Eval Loss:  0.2230289876461029\n",
      "Eval Loss:  0.1271418035030365\n",
      "Eval Loss:  0.2608642876148224\n",
      "Eval Loss:  0.25628286600112915\n",
      "Eval Loss:  0.15010027587413788\n",
      "Eval Loss:  0.22304187715053558\n",
      "Eval Loss:  0.2524077594280243\n",
      "Eval Loss:  0.21771454811096191\n",
      "Eval Loss:  0.19393934309482574\n",
      "Eval Loss:  0.22232133150100708\n",
      "Eval Loss:  0.19419725239276886\n",
      "Eval Loss:  0.25585201382637024\n",
      "[[17082  1331]\n",
      " [ 1318 10140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18413\n",
      "           1       0.88      0.88      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9113186702822135\n",
      "pre:  0.8839682678057711\n",
      "rec:  0.8849711991621575\n",
      "ma F1:  0.9062555867800073\n",
      "mi F1:  0.9113186702822135\n",
      "we F1:  0.9113281517119929\n",
      "29871 467\n",
      "Loss:  0.06684058904647827\n",
      "Loss:  0.07944773882627487\n",
      "Loss:  0.06057833135128021\n",
      "33 **********\n",
      "Epoch:  3260.303610086441  fold:  10  kers:  128\n",
      "epoch:  34\n",
      "29871 467\n",
      "Loss:  0.04569587856531143\n",
      "Loss:  0.03060869500041008\n",
      "Loss:  0.06812787055969238\n",
      "34 **********\n",
      "Epoch:  3341.7867407798767  fold:  10  kers:  128\n",
      "epoch:  35\n",
      "29871 467\n",
      "Loss:  0.03831746429204941\n",
      "Loss:  0.022945452481508255\n",
      "Loss:  0.04543159529566765\n",
      "35 **********\n",
      "Epoch:  3423.284831762314  fold:  10  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.8357505202293396\n",
      "Eval Loss:  0.1586860865354538\n",
      "Eval Loss:  0.012915702536702156\n",
      "[[1651  100]\n",
      " [ 214 1055]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      1751\n",
      "           1       0.91      0.83      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.89      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8960264900662251\n",
      "pre:  0.9134199134199135\n",
      "rec:  0.8313632781717888\n",
      "ma F1:  0.8918128815093899\n",
      "mi F1:  0.8960264900662251\n",
      "we F1:  0.8952205313825352\n",
      "Eval Loss:  0.1926490068435669\n",
      "Eval Loss:  0.20892339944839478\n",
      "Eval Loss:  0.14714521169662476\n",
      "Eval Loss:  0.22757893800735474\n",
      "Eval Loss:  0.20663663744926453\n",
      "Eval Loss:  0.2415781319141388\n",
      "Eval Loss:  0.22522291541099548\n",
      "Eval Loss:  0.20575955510139465\n",
      "Eval Loss:  0.1387215554714203\n",
      "Eval Loss:  0.1660565584897995\n",
      "Eval Loss:  0.10479146242141724\n",
      "Eval Loss:  0.17493918538093567\n",
      "Eval Loss:  0.18673087656497955\n",
      "Eval Loss:  0.2659284770488739\n",
      "Eval Loss:  0.2431013286113739\n",
      "Eval Loss:  0.10299744457006454\n",
      "Eval Loss:  0.11697786301374435\n",
      "Eval Loss:  0.22619690001010895\n",
      "Eval Loss:  0.1331520825624466\n",
      "Eval Loss:  0.23210982978343964\n",
      "Eval Loss:  0.22160562872886658\n",
      "Eval Loss:  0.15341289341449738\n",
      "Eval Loss:  0.1882695108652115\n",
      "Eval Loss:  0.19843629002571106\n",
      "Eval Loss:  0.16854234039783478\n",
      "Eval Loss:  0.21671481430530548\n",
      "Eval Loss:  0.21198832988739014\n",
      "Eval Loss:  0.22654998302459717\n",
      "Eval Loss:  0.21636943519115448\n",
      "[[17112  1301]\n",
      " [ 1151 10307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18413\n",
      "           1       0.89      0.90      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9179136955575642\n",
      "pre:  0.8879221226740179\n",
      "rec:  0.8995461686158143\n",
      "ma F1:  0.9134203200748525\n",
      "mi F1:  0.9179136955575642\n",
      "we F1:  0.9180127413066319\n",
      "29871 467\n",
      "Loss:  0.06520075350999832\n",
      "Loss:  0.05357476323843002\n",
      "Loss:  0.07875213772058487\n",
      "36 **********\n",
      "Epoch:  3547.9604744911194  fold:  10  kers:  128\n",
      "epoch:  37\n",
      "29871 467\n",
      "Loss:  0.0746338814496994\n",
      "Loss:  0.04377065598964691\n",
      "Loss:  0.04243282228708267\n",
      "37 **********\n",
      "Epoch:  3629.4545755386353  fold:  10  kers:  128\n",
      "epoch:  38\n",
      "29871 467\n",
      "Loss:  0.06956234574317932\n",
      "Loss:  0.07264387607574463\n",
      "Loss:  0.0677490308880806\n",
      "38 **********\n",
      "Epoch:  3710.9387032985687  fold:  10  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  1.2016520500183105\n",
      "Eval Loss:  0.1310567557811737\n",
      "Eval Loss:  0.011050507426261902\n",
      "[[1662   89]\n",
      " [ 317  952]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      1751\n",
      "           1       0.91      0.75      0.82      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.88      0.85      0.86      3020\n",
      "weighted avg       0.87      0.87      0.86      3020\n",
      "\n",
      "acc:  0.8655629139072848\n",
      "pre:  0.914505283381364\n",
      "rec:  0.7501970055161544\n",
      "ma F1:  0.8576976196279146\n",
      "mi F1:  0.8655629139072848\n",
      "we F1:  0.863037157434473\n",
      "Eval Loss:  0.20256119966506958\n",
      "Eval Loss:  0.23463115096092224\n",
      "Eval Loss:  0.16591773927211761\n",
      "Eval Loss:  0.21687710285186768\n",
      "Eval Loss:  0.24363242089748383\n",
      "Eval Loss:  0.24740715324878693\n",
      "Eval Loss:  0.25462427735328674\n",
      "Eval Loss:  0.19478486478328705\n",
      "Eval Loss:  0.13734394311904907\n",
      "Eval Loss:  0.1819796860218048\n",
      "Eval Loss:  0.12554503977298737\n",
      "Eval Loss:  0.1877668797969818\n",
      "Eval Loss:  0.19022472202777863\n",
      "Eval Loss:  0.22372384369373322\n",
      "Eval Loss:  0.23172923922538757\n",
      "Eval Loss:  0.14145337045192719\n",
      "Eval Loss:  0.1252463161945343\n",
      "Eval Loss:  0.22122299671173096\n",
      "Eval Loss:  0.13354791700839996\n",
      "Eval Loss:  0.20485422015190125\n",
      "Eval Loss:  0.21629522740840912\n",
      "Eval Loss:  0.1483096480369568\n",
      "Eval Loss:  0.18535873293876648\n",
      "Eval Loss:  0.22909536957740784\n",
      "Eval Loss:  0.16423466801643372\n",
      "Eval Loss:  0.17727383971214294\n",
      "Eval Loss:  0.2000962644815445\n",
      "Eval Loss:  0.18114891648292542\n",
      "Eval Loss:  0.21197311580181122\n",
      "[[17256  1157]\n",
      " [ 1240 10218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18413\n",
      "           1       0.90      0.89      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.91      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9197549462689565\n",
      "pre:  0.8982857142857142\n",
      "rec:  0.8917786699249433\n",
      "ma F1:  0.9150384277738643\n",
      "mi F1:  0.9197549462689565\n",
      "we F1:  0.9196993237859936\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.042860932648181915\n",
      "Loss:  0.033139798790216446\n",
      "Loss:  0.058450255542993546\n",
      "39 **********\n",
      "Epoch:  3835.749983549118  fold:  10  kers:  128\n",
      "epoch:  40\n",
      "29871 467\n",
      "Loss:  0.04081898555159569\n",
      "Loss:  0.059607669711112976\n",
      "Loss:  0.032590351998806\n",
      "40 **********\n",
      "Epoch:  3917.24707698822  fold:  10  kers:  128\n",
      "epoch:  41\n",
      "29871 467\n",
      "Loss:  0.03938143700361252\n",
      "Loss:  0.07346674054861069\n",
      "Loss:  0.07519802451133728\n",
      "41 **********\n",
      "Epoch:  3998.7681062221527  fold:  10  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  1.1443922519683838\n",
      "Eval Loss:  0.17090894281864166\n",
      "Eval Loss:  0.00833902508020401\n",
      "[[1662   89]\n",
      " [ 266 1003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      1751\n",
      "           1       0.92      0.79      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.89      0.87      0.88      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8824503311258278\n",
      "pre:  0.9184981684981685\n",
      "rec:  0.7903861308116628\n",
      "ma F1:  0.8765731853316769\n",
      "mi F1:  0.8824503311258278\n",
      "we F1:  0.8808717957607828\n",
      "Eval Loss:  0.2215099185705185\n",
      "Eval Loss:  0.24145559966564178\n",
      "Eval Loss:  0.1240718737244606\n",
      "Eval Loss:  0.21693269908428192\n",
      "Eval Loss:  0.20061452686786652\n",
      "Eval Loss:  0.21196500957012177\n",
      "Eval Loss:  0.25032466650009155\n",
      "Eval Loss:  0.18225401639938354\n",
      "Eval Loss:  0.1412477344274521\n",
      "Eval Loss:  0.17150291800498962\n",
      "Eval Loss:  0.10747018456459045\n",
      "Eval Loss:  0.17836438119411469\n",
      "Eval Loss:  0.14647401869297028\n",
      "Eval Loss:  0.21078304946422577\n",
      "Eval Loss:  0.2210853546857834\n",
      "Eval Loss:  0.08894619345664978\n",
      "Eval Loss:  0.13187143206596375\n",
      "Eval Loss:  0.20856164395809174\n",
      "Eval Loss:  0.11603289842605591\n",
      "Eval Loss:  0.21651028096675873\n",
      "Eval Loss:  0.2184586375951767\n",
      "Eval Loss:  0.15654189884662628\n",
      "Eval Loss:  0.20822778344154358\n",
      "Eval Loss:  0.22843798995018005\n",
      "Eval Loss:  0.18245342373847961\n",
      "Eval Loss:  0.19508685171604156\n",
      "Eval Loss:  0.2114848792552948\n",
      "Eval Loss:  0.2304505854845047\n",
      "Eval Loss:  0.19597730040550232\n",
      "[[17216  1197]\n",
      " [ 1198 10260]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18413\n",
      "           1       0.90      0.90      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9198219008402798\n",
      "pre:  0.8955223880597015\n",
      "rec:  0.8954442311049049\n",
      "ma F1:  0.9152247505795198\n",
      "mi F1:  0.9198219008402798\n",
      "we F1:  0.9198212399503631\n",
      "29871 467\n",
      "Loss:  0.06547703593969345\n",
      "Loss:  0.035076770931482315\n",
      "Loss:  0.05139261856675148\n",
      "42 **********\n",
      "Epoch:  4123.46967959404  fold:  10  kers:  128\n",
      "epoch:  43\n",
      "29871 467\n",
      "Loss:  0.05846849083900452\n",
      "Loss:  0.10419412702322006\n",
      "Loss:  0.09522199630737305\n",
      "43 **********\n",
      "Epoch:  4204.958794116974  fold:  10  kers:  128\n",
      "epoch:  44\n",
      "29871 467\n",
      "Loss:  0.038414813578128815\n",
      "Loss:  0.0870530903339386\n",
      "Loss:  0.07171151787042618\n",
      "44 **********\n",
      "Epoch:  4286.479823350906  fold:  10  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  1.1052796840667725\n",
      "Eval Loss:  0.14982959628105164\n",
      "Eval Loss:  0.008217720314860344\n",
      "[[1625  126]\n",
      " [ 283  986]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      1751\n",
      "           1       0.89      0.78      0.83      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.87      0.85      0.86      3020\n",
      "weighted avg       0.87      0.86      0.86      3020\n",
      "\n",
      "acc:  0.864569536423841\n",
      "pre:  0.8866906474820144\n",
      "rec:  0.77698975571316\n",
      "ma F1:  0.8582221304467051\n",
      "mi F1:  0.8645695364238412\n",
      "we F1:  0.8630100016219469\n",
      "Eval Loss:  0.2463250309228897\n",
      "Eval Loss:  0.25251081585884094\n",
      "Eval Loss:  0.1608373522758484\n",
      "Eval Loss:  0.24089568853378296\n",
      "Eval Loss:  0.21979732811450958\n",
      "Eval Loss:  0.2509928047657013\n",
      "Eval Loss:  0.2248193323612213\n",
      "Eval Loss:  0.1913927048444748\n",
      "Eval Loss:  0.14608944952487946\n",
      "Eval Loss:  0.18824534118175507\n",
      "Eval Loss:  0.12439946830272675\n",
      "Eval Loss:  0.15224958956241608\n",
      "Eval Loss:  0.21700018644332886\n",
      "Eval Loss:  0.23991477489471436\n",
      "Eval Loss:  0.25115567445755005\n",
      "Eval Loss:  0.09867224097251892\n",
      "Eval Loss:  0.12627127766609192\n",
      "Eval Loss:  0.2777971625328064\n",
      "Eval Loss:  0.13568015396595\n",
      "Eval Loss:  0.2270425260066986\n",
      "Eval Loss:  0.21959830820560455\n",
      "Eval Loss:  0.16544628143310547\n",
      "Eval Loss:  0.22695578634738922\n",
      "Eval Loss:  0.21079373359680176\n",
      "Eval Loss:  0.14802546799182892\n",
      "Eval Loss:  0.17424415051937103\n",
      "Eval Loss:  0.23041757941246033\n",
      "Eval Loss:  0.21547511219978333\n",
      "Eval Loss:  0.26527857780456543\n",
      "[[16995  1418]\n",
      " [ 1082 10376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     18413\n",
      "           1       0.88      0.91      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9163067858458036\n",
      "pre:  0.8797693742580973\n",
      "rec:  0.905568161982894\n",
      "ma F1:  0.9119852230169694\n",
      "mi F1:  0.9163067858458036\n",
      "we F1:  0.9165261611457716\n",
      "29871 467\n",
      "Loss:  0.04583699628710747\n",
      "Loss:  0.04935453087091446\n",
      "Loss:  0.07388418167829514\n",
      "45 **********\n",
      "Epoch:  4411.107594013214  fold:  10  kers:  128\n",
      "epoch:  46\n",
      "29871 467\n",
      "Loss:  0.07359625399112701\n",
      "Loss:  0.0828968957066536\n",
      "Loss:  0.052523043006658554\n",
      "46 **********\n",
      "Epoch:  4492.589727878571  fold:  10  kers:  128\n",
      "epoch:  47\n",
      "29871 467\n",
      "Loss:  0.0589054599404335\n",
      "Loss:  0.07092583179473877\n",
      "Loss:  0.056246623396873474\n",
      "47 **********\n",
      "Epoch:  4574.082831859589  fold:  10  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  1.0803601741790771\n",
      "Eval Loss:  0.13812445104122162\n",
      "Eval Loss:  0.014800245873630047\n",
      "[[1670   81]\n",
      " [ 266 1003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91      1751\n",
      "           1       0.93      0.79      0.85      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.87      0.88      3020\n",
      "weighted avg       0.89      0.89      0.88      3020\n",
      "\n",
      "acc:  0.8850993377483444\n",
      "pre:  0.9252767527675276\n",
      "rec:  0.7903861308116628\n",
      "ma F1:  0.8792071152926899\n",
      "mi F1:  0.8850993377483444\n",
      "we F1:  0.8834650631541974\n",
      "Eval Loss:  0.1887848675251007\n",
      "Eval Loss:  0.21830298006534576\n",
      "Eval Loss:  0.14461417496204376\n",
      "Eval Loss:  0.19388125836849213\n",
      "Eval Loss:  0.22060292959213257\n",
      "Eval Loss:  0.20460855960845947\n",
      "Eval Loss:  0.24833442270755768\n",
      "Eval Loss:  0.17451894283294678\n",
      "Eval Loss:  0.11533403396606445\n",
      "Eval Loss:  0.15391302108764648\n",
      "Eval Loss:  0.1195971891283989\n",
      "Eval Loss:  0.17300084233283997\n",
      "Eval Loss:  0.18255087733268738\n",
      "Eval Loss:  0.26584121584892273\n",
      "Eval Loss:  0.20929400622844696\n",
      "Eval Loss:  0.10070520639419556\n",
      "Eval Loss:  0.10944585502147675\n",
      "Eval Loss:  0.22019906342029572\n",
      "Eval Loss:  0.12735050916671753\n",
      "Eval Loss:  0.1820414662361145\n",
      "Eval Loss:  0.1846965253353119\n",
      "Eval Loss:  0.15074072778224945\n",
      "Eval Loss:  0.20920626819133759\n",
      "Eval Loss:  0.18173809349536896\n",
      "Eval Loss:  0.1547422856092453\n",
      "Eval Loss:  0.18397949635982513\n",
      "Eval Loss:  0.1986377239227295\n",
      "Eval Loss:  0.18052330613136292\n",
      "Eval Loss:  0.18076224625110626\n",
      "[[17117  1296]\n",
      " [  924 10534]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18413\n",
      "           1       0.89      0.92      0.90     11458\n",
      "\n",
      "    accuracy                           0.93     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.93      0.93      0.93     29871\n",
      "\n",
      "acc:  0.9256804258310736\n",
      "pre:  0.8904480135249366\n",
      "rec:  0.9193576540408448\n",
      "ma F1:  0.9218866336151571\n",
      "mi F1:  0.9256804258310736\n",
      "we F1:  0.9258948099575084\n",
      "29871 467\n",
      "Loss:  0.043257277458906174\n",
      "Loss:  0.041603296995162964\n",
      "Loss:  0.06647280603647232\n",
      "48 **********\n",
      "Epoch:  4698.882143497467  fold:  10  kers:  128\n",
      "epoch:  49\n",
      "29871 467\n",
      "Loss:  0.05017341300845146\n",
      "Loss:  0.029272519052028656\n",
      "Loss:  0.05998858064413071\n",
      "49 **********\n",
      "Epoch:  4780.388212680817  fold:  10  kers:  128\n",
      "epoch:  50\n",
      "29871 467\n",
      "Loss:  0.05958980694413185\n",
      "Loss:  0.05720342695713043\n",
      "Loss:  0.05038347840309143\n",
      "50 **********\n",
      "Epoch:  4861.895279407501  fold:  10  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  1.2237926721572876\n",
      "Eval Loss:  0.1444290578365326\n",
      "Eval Loss:  0.00844358466565609\n",
      "[[1659   92]\n",
      " [ 327  942]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      1751\n",
      "           1       0.91      0.74      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.87      0.84      0.85      3020\n",
      "weighted avg       0.87      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8612582781456953\n",
      "pre:  0.9110251450676983\n",
      "rec:  0.7423167848699763\n",
      "ma F1:  0.852970686278941\n",
      "mi F1:  0.8612582781456953\n",
      "we F1:  0.8585419823455737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2372698187828064\n",
      "Eval Loss:  0.22600586712360382\n",
      "Eval Loss:  0.1643049269914627\n",
      "Eval Loss:  0.21557530760765076\n",
      "Eval Loss:  0.2254588007926941\n",
      "Eval Loss:  0.20173947513103485\n",
      "Eval Loss:  0.2528715431690216\n",
      "Eval Loss:  0.2064959853887558\n",
      "Eval Loss:  0.13733519613742828\n",
      "Eval Loss:  0.16525447368621826\n",
      "Eval Loss:  0.13832728564739227\n",
      "Eval Loss:  0.1549481749534607\n",
      "Eval Loss:  0.18236012756824493\n",
      "Eval Loss:  0.2364274561405182\n",
      "Eval Loss:  0.17168095707893372\n",
      "Eval Loss:  0.10296458005905151\n",
      "Eval Loss:  0.12336094677448273\n",
      "Eval Loss:  0.19836582243442535\n",
      "Eval Loss:  0.12971845269203186\n",
      "Eval Loss:  0.1814677119255066\n",
      "Eval Loss:  0.1768541932106018\n",
      "Eval Loss:  0.19064784049987793\n",
      "Eval Loss:  0.23811109364032745\n",
      "Eval Loss:  0.18756993114948273\n",
      "Eval Loss:  0.14768703281879425\n",
      "Eval Loss:  0.1869361251592636\n",
      "Eval Loss:  0.19299529492855072\n",
      "Eval Loss:  0.19155128300189972\n",
      "Eval Loss:  0.18857614696025848\n",
      "[[17104  1309]\n",
      " [  975 10483]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18413\n",
      "           1       0.89      0.91      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9235378795487262\n",
      "pre:  0.8889925373134329\n",
      "rec:  0.9149066154651772\n",
      "ma F1:  0.9195871901220947\n",
      "mi F1:  0.9235378795487262\n",
      "we F1:  0.9237371742577573\n",
      "29871 467\n",
      "Loss:  0.04191039130091667\n",
      "Loss:  0.05315359681844711\n",
      "Loss:  0.03886763006448746\n",
      "51 **********\n",
      "Epoch:  4986.614804983139  fold:  10  kers:  128\n",
      "epoch:  52\n",
      "29871 467\n",
      "Loss:  0.09435299038887024\n",
      "Loss:  0.05732240900397301\n",
      "Loss:  0.04540461301803589\n",
      "52 **********\n",
      "Epoch:  5068.134836912155  fold:  10  kers:  128\n",
      "epoch:  53\n",
      "29871 467\n",
      "Loss:  0.058200351893901825\n",
      "Loss:  0.06061038002371788\n",
      "Loss:  0.04965551197528839\n",
      "53 **********\n",
      "Epoch:  5149.613978385925  fold:  10  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  1.2638858556747437\n",
      "Eval Loss:  0.10997074097394943\n",
      "Eval Loss:  0.007374023087322712\n",
      "[[1655   96]\n",
      " [ 280  989]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      1751\n",
      "           1       0.91      0.78      0.84      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.88      0.86      0.87      3020\n",
      "weighted avg       0.88      0.88      0.87      3020\n",
      "\n",
      "acc:  0.8754966887417218\n",
      "pre:  0.911520737327189\n",
      "rec:  0.7793538219070134\n",
      "ma F1:  0.8691321406723459\n",
      "mi F1:  0.8754966887417218\n",
      "we F1:  0.8737383151009332\n",
      "Eval Loss:  0.21163725852966309\n",
      "Eval Loss:  0.22696368396282196\n",
      "Eval Loss:  0.1300778090953827\n",
      "Eval Loss:  0.22734279930591583\n",
      "Eval Loss:  0.23655472695827484\n",
      "Eval Loss:  0.20741401612758636\n",
      "Eval Loss:  0.2181328684091568\n",
      "Eval Loss:  0.1939629465341568\n",
      "Eval Loss:  0.14463010430335999\n",
      "Eval Loss:  0.1973448246717453\n",
      "Eval Loss:  0.11467278003692627\n",
      "Eval Loss:  0.15469792485237122\n",
      "Eval Loss:  0.1823704093694687\n",
      "Eval Loss:  0.24187880754470825\n",
      "Eval Loss:  0.20289252698421478\n",
      "Eval Loss:  0.09412619471549988\n",
      "Eval Loss:  0.11404266953468323\n",
      "Eval Loss:  0.21370580792427063\n",
      "Eval Loss:  0.13344822824001312\n",
      "Eval Loss:  0.20715640485286713\n",
      "Eval Loss:  0.18888314068317413\n",
      "Eval Loss:  0.18368680775165558\n",
      "Eval Loss:  0.22421763837337494\n",
      "Eval Loss:  0.18358214199543\n",
      "Eval Loss:  0.15300090610980988\n",
      "Eval Loss:  0.1826547235250473\n",
      "Eval Loss:  0.1913813054561615\n",
      "Eval Loss:  0.2115977704524994\n",
      "Eval Loss:  0.21299034357070923\n",
      "[[17298  1115]\n",
      " [ 1155 10303]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18413\n",
      "           1       0.90      0.90      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9240065615479897\n",
      "pre:  0.9023471711332983\n",
      "rec:  0.899197067551056\n",
      "ma F1:  0.9195975074618667\n",
      "mi F1:  0.9240065615479897\n",
      "we F1:  0.9239813489442092\n",
      "29871 467\n",
      "Loss:  0.042037516832351685\n",
      "Loss:  0.07056152075529099\n",
      "Loss:  0.04872211441397667\n",
      "54 **********\n",
      "Epoch:  5274.406308889389  fold:  10  kers:  128\n",
      "epoch:  55\n",
      "29871 467\n",
      "Loss:  0.05721496045589447\n",
      "Loss:  0.06108119711279869\n",
      "Loss:  0.04000929370522499\n",
      "55 **********\n",
      "Epoch:  5355.940303325653  fold:  10  kers:  128\n",
      "epoch:  56\n",
      "29871 467\n",
      "Loss:  0.0513763464987278\n",
      "Loss:  0.03488502651453018\n",
      "Loss:  0.022978035733103752\n",
      "56 **********\n",
      "Epoch:  5437.448367595673  fold:  10  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  1.12261962890625\n",
      "Eval Loss:  0.12093620002269745\n",
      "Eval Loss:  0.009690958075225353\n",
      "[[1640  111]\n",
      " [ 304  965]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      1751\n",
      "           1       0.90      0.76      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.87      0.85      0.86      3020\n",
      "weighted avg       0.87      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8625827814569537\n",
      "pre:  0.8968401486988847\n",
      "rec:  0.760441292356186\n",
      "ma F1:  0.8553568903981927\n",
      "mi F1:  0.8625827814569537\n",
      "we F1:  0.8605167118653377\n",
      "Eval Loss:  0.20241719484329224\n",
      "Eval Loss:  0.20137371122837067\n",
      "Eval Loss:  0.1297840178012848\n",
      "Eval Loss:  0.21089336276054382\n",
      "Eval Loss:  0.1918739527463913\n",
      "Eval Loss:  0.17889001965522766\n",
      "Eval Loss:  0.22180277109146118\n",
      "Eval Loss:  0.18263718485832214\n",
      "Eval Loss:  0.09915123134851456\n",
      "Eval Loss:  0.15288865566253662\n",
      "Eval Loss:  0.11369454860687256\n",
      "Eval Loss:  0.1619207113981247\n",
      "Eval Loss:  0.15719236433506012\n",
      "Eval Loss:  0.21989502012729645\n",
      "Eval Loss:  0.23329585790634155\n",
      "Eval Loss:  0.07049495726823807\n",
      "Eval Loss:  0.11263898015022278\n",
      "Eval Loss:  0.2095206379890442\n",
      "Eval Loss:  0.11841844767332077\n",
      "Eval Loss:  0.20756042003631592\n",
      "Eval Loss:  0.18567036092281342\n",
      "Eval Loss:  0.16336393356323242\n",
      "Eval Loss:  0.1876695156097412\n",
      "Eval Loss:  0.16040576994419098\n",
      "Eval Loss:  0.17214228212833405\n",
      "Eval Loss:  0.21110935509204865\n",
      "Eval Loss:  0.1996186226606369\n",
      "Eval Loss:  0.1867809295654297\n",
      "Eval Loss:  0.19843295216560364\n",
      "[[17132  1281]\n",
      " [  859 10599]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18413\n",
      "           1       0.89      0.93      0.91     11458\n",
      "\n",
      "    accuracy                           0.93     29871\n",
      "   macro avg       0.92      0.93      0.92     29871\n",
      "weighted avg       0.93      0.93      0.93     29871\n",
      "\n",
      "acc:  0.9283586086840079\n",
      "pre:  0.8921717171717172\n",
      "rec:  0.9250305463431664\n",
      "ma F1:  0.924759652273165\n",
      "mi F1:  0.9283586086840079\n",
      "we F1:  0.9285910837498851\n",
      "29871 467\n",
      "Loss:  0.03668387234210968\n",
      "Loss:  0.02935563214123249\n",
      "Loss:  0.027926355600357056\n",
      "57 **********\n",
      "Epoch:  5562.061178445816  fold:  10  kers:  128\n",
      "epoch:  58\n",
      "29871 467\n",
      "Loss:  0.06130727007985115\n",
      "Loss:  0.06422378867864609\n",
      "Loss:  0.05602877959609032\n",
      "58 **********\n",
      "Epoch:  5643.545306444168  fold:  10  kers:  128\n",
      "epoch:  59\n",
      "29871 467\n",
      "Loss:  0.04778830707073212\n",
      "Loss:  0.052553728222846985\n",
      "Loss:  0.07790690660476685\n",
      "59 **********\n",
      "Epoch:  5725.025444984436  fold:  10  kers:  128\n",
      "Eval Loss:  1.1383792161941528\n",
      "Eval Loss:  0.16149157285690308\n",
      "Eval Loss:  0.00836776103824377\n",
      "[[1665   86]\n",
      " [ 307  962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      1751\n",
      "           1       0.92      0.76      0.83      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.88      0.85      0.86      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8698675496688741\n",
      "pre:  0.9179389312977099\n",
      "rec:  0.7580772261623325\n",
      "ma F1:  0.8624120425805548\n",
      "mi F1:  0.8698675496688741\n",
      "we F1:  0.8675237842826458\n",
      "update!  Acc:  0.916887417218543\n",
      "Epoch:  5728.981866598129  fold:  10  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "  \n",
      "kernel: 64\n",
      "  \n",
      "*********\n",
      "29459 3432\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29459 461\n",
      "Loss:  0.16120390594005585\n",
      "Loss:  0.15776154398918152\n",
      "Loss:  0.1465785801410675\n",
      "0 **********\n",
      "Epoch:  58.618265867233276  fold:  1  kers:  64\n",
      "epoch:  1\n",
      "29459 461\n",
      "Loss:  0.151450514793396\n",
      "Loss:  0.10701507329940796\n",
      "Loss:  0.11672909557819366\n",
      "1 **********\n",
      "Epoch:  104.839679479599  fold:  1  kers:  64\n",
      "epoch:  2\n",
      "29459 461\n",
      "Loss:  0.09339414536952972\n",
      "Loss:  0.10011100023984909\n",
      "Loss:  0.10910061746835709\n",
      "2 **********\n",
      "Epoch:  150.98928475379944  fold:  1  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.42739394307136536\n",
      "Eval Loss:  0.499083548784256\n",
      "Eval Loss:  0.18456771969795227\n",
      "[[ 818  221]\n",
      " [ 690 1703]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.79      0.64      1039\n",
      "           1       0.89      0.71      0.79      2393\n",
      "\n",
      "    accuracy                           0.73      3432\n",
      "   macro avg       0.71      0.75      0.72      3432\n",
      "weighted avg       0.78      0.73      0.74      3432\n",
      "\n",
      "acc:  0.7345571095571095\n",
      "pre:  0.8851351351351351\n",
      "rec:  0.7116590054325115\n",
      "ma F1:  0.7156490637583957\n",
      "mi F1:  0.7345571095571095\n",
      "we F1:  0.744577305579253\n",
      "update!  Acc:  0.7345571095571095\n",
      "Eval Loss:  0.4617387354373932\n",
      "Eval Loss:  0.44493868947029114\n",
      "Eval Loss:  0.3982350528240204\n",
      "Eval Loss:  0.32283636927604675\n",
      "Eval Loss:  0.4184800684452057\n",
      "Eval Loss:  0.34355613589286804\n",
      "Eval Loss:  0.42623913288116455\n",
      "Eval Loss:  0.3833673596382141\n",
      "Eval Loss:  0.38018691539764404\n",
      "Eval Loss:  0.35717543959617615\n",
      "Eval Loss:  0.48539745807647705\n",
      "Eval Loss:  0.39600083231925964\n",
      "Eval Loss:  0.448930948972702\n",
      "Eval Loss:  0.5189662575721741\n",
      "Eval Loss:  0.3465856909751892\n",
      "Eval Loss:  0.41775748133659363\n",
      "Eval Loss:  0.44840702414512634\n",
      "Eval Loss:  0.4091401696205139\n",
      "Eval Loss:  0.46647974848747253\n",
      "Eval Loss:  0.41837579011917114\n",
      "Eval Loss:  0.5465160608291626\n",
      "Eval Loss:  0.43300125002861023\n",
      "Eval Loss:  0.3973064720630646\n",
      "Eval Loss:  0.3493717908859253\n",
      "Eval Loss:  0.41259774565696716\n",
      "Eval Loss:  0.37586066126823425\n",
      "Eval Loss:  0.38378918170928955\n",
      "Eval Loss:  0.3880118429660797\n",
      "[[17180  1945]\n",
      " [ 3115  7219]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87     19125\n",
      "           1       0.79      0.70      0.74     10334\n",
      "\n",
      "    accuracy                           0.83     29459\n",
      "   macro avg       0.82      0.80      0.81     29459\n",
      "weighted avg       0.83      0.83      0.83     29459\n",
      "\n",
      "acc:  0.8282358532197291\n",
      "pre:  0.7877564382365779\n",
      "rec:  0.6985678343332689\n",
      "ma F1:  0.8060624828814611\n",
      "mi F1:  0.8282358532197291\n",
      "we F1:  0.8256314115677089\n",
      "29459 461\n",
      "Loss:  0.10568159073591232\n",
      "Loss:  0.08164552599191666\n",
      "Loss:  0.09035273641347885\n",
      "3 **********\n",
      "Epoch:  237.1947886943817  fold:  1  kers:  64\n",
      "epoch:  4\n",
      "29459 461\n",
      "Loss:  0.1256278157234192\n",
      "Loss:  0.11204799264669418\n",
      "Loss:  0.08826889842748642\n",
      "4 **********\n",
      "Epoch:  283.3603515625  fold:  1  kers:  64\n",
      "epoch:  5\n",
      "29459 461\n",
      "Loss:  0.10977885872125626\n",
      "Loss:  0.11637254059314728\n",
      "Loss:  0.08691629767417908\n",
      "5 **********\n",
      "Epoch:  329.53788208961487  fold:  1  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.5551156401634216\n",
      "Eval Loss:  0.585728108882904\n",
      "Eval Loss:  0.11088024824857712\n",
      "[[ 861  178]\n",
      " [ 713 1680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.83      0.66      1039\n",
      "           1       0.90      0.70      0.79      2393\n",
      "\n",
      "    accuracy                           0.74      3432\n",
      "   macro avg       0.73      0.77      0.72      3432\n",
      "weighted avg       0.80      0.74      0.75      3432\n",
      "\n",
      "acc:  0.7403846153846154\n",
      "pre:  0.9041980624327234\n",
      "rec:  0.7020476389469286\n",
      "ma F1:  0.7247074437270248\n",
      "mi F1:  0.7403846153846154\n",
      "we F1:  0.7506255028532491\n",
      "update!  Acc:  0.7403846153846154\n",
      "Eval Loss:  0.3950282335281372\n",
      "Eval Loss:  0.4079640805721283\n",
      "Eval Loss:  0.3333852291107178\n",
      "Eval Loss:  0.2407766878604889\n",
      "Eval Loss:  0.3855268359184265\n",
      "Eval Loss:  0.31034860014915466\n",
      "Eval Loss:  0.43132323026657104\n",
      "Eval Loss:  0.3159754276275635\n",
      "Eval Loss:  0.29832732677459717\n",
      "Eval Loss:  0.3713635802268982\n",
      "Eval Loss:  0.4975305497646332\n",
      "Eval Loss:  0.32647818326950073\n",
      "Eval Loss:  0.4322330355644226\n",
      "Eval Loss:  0.5242174863815308\n",
      "Eval Loss:  0.3325972259044647\n",
      "Eval Loss:  0.39840957522392273\n",
      "Eval Loss:  0.39810702204704285\n",
      "Eval Loss:  0.36613112688064575\n",
      "Eval Loss:  0.3861844837665558\n",
      "Eval Loss:  0.3737105429172516\n",
      "Eval Loss:  0.502507746219635\n",
      "Eval Loss:  0.3850688636302948\n",
      "Eval Loss:  0.36173975467681885\n",
      "Eval Loss:  0.3022582232952118\n",
      "Eval Loss:  0.38274064660072327\n",
      "Eval Loss:  0.35292595624923706\n",
      "Eval Loss:  0.3302319347858429\n",
      "Eval Loss:  0.3566991090774536\n",
      "[[18005  1120]\n",
      " [ 3218  7116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     19125\n",
      "           1       0.86      0.69      0.77     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.86      0.82      0.83     29459\n",
      "weighted avg       0.85      0.85      0.85     29459\n",
      "\n",
      "acc:  0.8527444923452935\n",
      "pre:  0.8640116561437591\n",
      "rec:  0.6886007354364234\n",
      "ma F1:  0.8294413962019926\n",
      "mi F1:  0.8527444923452936\n",
      "we F1:  0.8482546497786074\n",
      "29459 461\n",
      "Loss:  0.09015918523073196\n",
      "Loss:  0.13261684775352478\n",
      "Loss:  0.0650428757071495\n",
      "6 **********\n",
      "Epoch:  415.56386613845825  fold:  1  kers:  64\n",
      "epoch:  7\n",
      "29459 461\n",
      "Loss:  0.10156827419996262\n",
      "Loss:  0.06971108913421631\n",
      "Loss:  0.07928161323070526\n",
      "7 **********\n",
      "Epoch:  461.6705858707428  fold:  1  kers:  64\n",
      "epoch:  8\n",
      "29459 461\n",
      "Loss:  0.06608010828495026\n",
      "Loss:  0.07222180813550949\n",
      "Loss:  0.08341814577579498\n",
      "8 **********\n",
      "Epoch:  507.8201916217804  fold:  1  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.4723673462867737\n",
      "Eval Loss:  0.5943009257316589\n",
      "Eval Loss:  0.11864133924245834\n",
      "[[ 918  121]\n",
      " [ 793 1600]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.88      0.67      1039\n",
      "           1       0.93      0.67      0.78      2393\n",
      "\n",
      "    accuracy                           0.73      3432\n",
      "   macro avg       0.73      0.78      0.72      3432\n",
      "weighted avg       0.81      0.73      0.74      3432\n",
      "\n",
      "acc:  0.7336829836829837\n",
      "pre:  0.9296920395119117\n",
      "rec:  0.6686167989970748\n",
      "ma F1:  0.722734078755469\n",
      "mi F1:  0.7336829836829837\n",
      "we F1:  0.7444713474825286\n",
      "Eval Loss:  0.43618226051330566\n",
      "Eval Loss:  0.4849948585033417\n",
      "Eval Loss:  0.33570921421051025\n",
      "Eval Loss:  0.2601103186607361\n",
      "Eval Loss:  0.43202346563339233\n",
      "Eval Loss:  0.3457716703414917\n",
      "Eval Loss:  0.4773347079753876\n",
      "Eval Loss:  0.3278716206550598\n",
      "Eval Loss:  0.3641795516014099\n",
      "Eval Loss:  0.4120428264141083\n",
      "Eval Loss:  0.5886093378067017\n",
      "Eval Loss:  0.3416665196418762\n",
      "Eval Loss:  0.42775779962539673\n",
      "Eval Loss:  0.5615148544311523\n",
      "Eval Loss:  0.34198299050331116\n",
      "Eval Loss:  0.41549062728881836\n",
      "Eval Loss:  0.43178534507751465\n",
      "Eval Loss:  0.39396652579307556\n",
      "Eval Loss:  0.42145922780036926\n",
      "Eval Loss:  0.40108048915863037\n",
      "Eval Loss:  0.5211673378944397\n",
      "Eval Loss:  0.41283583641052246\n",
      "Eval Loss:  0.36062678694725037\n",
      "Eval Loss:  0.37964874505996704\n",
      "Eval Loss:  0.42612195014953613\n",
      "Eval Loss:  0.39116060733795166\n",
      "Eval Loss:  0.33360755443573\n",
      "Eval Loss:  0.4230653941631317\n",
      "[[18486   639]\n",
      " [ 3795  6539]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89     19125\n",
      "           1       0.91      0.63      0.75     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.87      0.80      0.82     29459\n",
      "weighted avg       0.86      0.85      0.84     29459\n",
      "\n",
      "acc:  0.8494857259241658\n",
      "pre:  0.9109779882975759\n",
      "rec:  0.6327656280239985\n",
      "ma F1:  0.8198581316033342\n",
      "mi F1:  0.8494857259241658\n",
      "we F1:  0.8416591010244802\n",
      "29459 461\n",
      "Loss:  0.06865911930799484\n",
      "Loss:  0.07146739959716797\n",
      "Loss:  0.10070979595184326\n",
      "9 **********\n",
      "Epoch:  593.7414557933807  fold:  1  kers:  64\n",
      "epoch:  10\n",
      "29459 461\n",
      "Loss:  0.11137466132640839\n",
      "Loss:  0.08638951182365417\n",
      "Loss:  0.0997161865234375\n",
      "10 **********\n",
      "Epoch:  639.802298784256  fold:  1  kers:  64\n",
      "epoch:  11\n",
      "29459 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.1089596226811409\n",
      "Loss:  0.08879605680704117\n",
      "Loss:  0.08306233584880829\n",
      "11 **********\n",
      "Epoch:  685.8711194992065  fold:  1  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.5553837418556213\n",
      "Eval Loss:  0.5586149096488953\n",
      "Eval Loss:  0.08704646676778793\n",
      "[[ 892  147]\n",
      " [ 740 1653]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.86      0.67      1039\n",
      "           1       0.92      0.69      0.79      2393\n",
      "\n",
      "    accuracy                           0.74      3432\n",
      "   macro avg       0.73      0.77      0.73      3432\n",
      "weighted avg       0.81      0.74      0.75      3432\n",
      "\n",
      "acc:  0.7415501165501166\n",
      "pre:  0.9183333333333333\n",
      "rec:  0.6907647304638529\n",
      "ma F1:  0.7281857953875275\n",
      "mi F1:  0.7415501165501166\n",
      "we F1:  0.75196410137195\n",
      "update!  Acc:  0.7415501165501166\n",
      "Eval Loss:  0.349822074174881\n",
      "Eval Loss:  0.39758217334747314\n",
      "Eval Loss:  0.287280410528183\n",
      "Eval Loss:  0.22711487114429474\n",
      "Eval Loss:  0.3688439726829529\n",
      "Eval Loss:  0.3032852113246918\n",
      "Eval Loss:  0.41424092650413513\n",
      "Eval Loss:  0.2922816872596741\n",
      "Eval Loss:  0.27329733967781067\n",
      "Eval Loss:  0.3418334126472473\n",
      "Eval Loss:  0.4981946349143982\n",
      "Eval Loss:  0.2763041853904724\n",
      "Eval Loss:  0.38406842947006226\n",
      "Eval Loss:  0.4648817479610443\n",
      "Eval Loss:  0.3406527638435364\n",
      "Eval Loss:  0.38899484276771545\n",
      "Eval Loss:  0.35986772179603577\n",
      "Eval Loss:  0.34986454248428345\n",
      "Eval Loss:  0.34195011854171753\n",
      "Eval Loss:  0.3464246094226837\n",
      "Eval Loss:  0.43774154782295227\n",
      "Eval Loss:  0.3603489398956299\n",
      "Eval Loss:  0.32893070578575134\n",
      "Eval Loss:  0.308879017829895\n",
      "Eval Loss:  0.35093894600868225\n",
      "Eval Loss:  0.33371490240097046\n",
      "Eval Loss:  0.3073180913925171\n",
      "Eval Loss:  0.36918243765830994\n",
      "[[18366   759]\n",
      " [ 3243  7091]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     19125\n",
      "           1       0.90      0.69      0.78     10334\n",
      "\n",
      "    accuracy                           0.86     29459\n",
      "   macro avg       0.88      0.82      0.84     29459\n",
      "weighted avg       0.87      0.86      0.86     29459\n",
      "\n",
      "acc:  0.8641501748192403\n",
      "pre:  0.903312101910828\n",
      "rec:  0.6861815366750532\n",
      "ma F1:  0.8408346227499688\n",
      "mi F1:  0.8641501748192403\n",
      "we F1:  0.8590135157203428\n",
      "29459 461\n",
      "Loss:  0.07935096323490143\n",
      "Loss:  0.09449449181556702\n",
      "Loss:  0.05320577323436737\n",
      "12 **********\n",
      "Epoch:  772.1294822692871  fold:  1  kers:  64\n",
      "epoch:  13\n",
      "29459 461\n",
      "Loss:  0.09776873141527176\n",
      "Loss:  0.07128170132637024\n",
      "Loss:  0.057982850819826126\n",
      "13 **********\n",
      "Epoch:  818.2980370521545  fold:  1  kers:  64\n",
      "epoch:  14\n",
      "29459 461\n",
      "Loss:  0.07498569041490555\n",
      "Loss:  0.06966134905815125\n",
      "Loss:  0.06572799384593964\n",
      "14 **********\n",
      "Epoch:  864.4675891399384  fold:  1  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.615325391292572\n",
      "Eval Loss:  0.9316633343696594\n",
      "Eval Loss:  0.09133276343345642\n",
      "[[ 936  103]\n",
      " [1026 1367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.90      0.62      1039\n",
      "           1       0.93      0.57      0.71      2393\n",
      "\n",
      "    accuracy                           0.67      3432\n",
      "   macro avg       0.70      0.74      0.67      3432\n",
      "weighted avg       0.79      0.67      0.68      3432\n",
      "\n",
      "acc:  0.671037296037296\n",
      "pre:  0.9299319727891157\n",
      "rec:  0.5712494776431258\n",
      "ma F1:  0.6657660838396866\n",
      "mi F1:  0.671037296037296\n",
      "we F1:  0.6823257620660514\n",
      "Eval Loss:  0.4266326427459717\n",
      "Eval Loss:  0.4869943857192993\n",
      "Eval Loss:  0.3449563682079315\n",
      "Eval Loss:  0.2664113938808441\n",
      "Eval Loss:  0.43689221143722534\n",
      "Eval Loss:  0.33779463171958923\n",
      "Eval Loss:  0.4743736982345581\n",
      "Eval Loss:  0.31062737107276917\n",
      "Eval Loss:  0.3606882095336914\n",
      "Eval Loss:  0.39586758613586426\n",
      "Eval Loss:  0.5684891939163208\n",
      "Eval Loss:  0.31121623516082764\n",
      "Eval Loss:  0.43899965286254883\n",
      "Eval Loss:  0.5756564736366272\n",
      "Eval Loss:  0.36760979890823364\n",
      "Eval Loss:  0.47876739501953125\n",
      "Eval Loss:  0.41941460967063904\n",
      "Eval Loss:  0.4262111186981201\n",
      "Eval Loss:  0.38151267170906067\n",
      "Eval Loss:  0.4151294231414795\n",
      "Eval Loss:  0.5562296509742737\n",
      "Eval Loss:  0.44604727625846863\n",
      "Eval Loss:  0.3579358756542206\n",
      "Eval Loss:  0.39022284746170044\n",
      "Eval Loss:  0.4242129325866699\n",
      "Eval Loss:  0.4239051640033722\n",
      "Eval Loss:  0.32939833402633667\n",
      "Eval Loss:  0.43649643659591675\n",
      "[[18714   411]\n",
      " [ 4153  6181]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89     19125\n",
      "           1       0.94      0.60      0.73     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.88      0.79      0.81     29459\n",
      "weighted avg       0.86      0.85      0.83     29459\n",
      "\n",
      "acc:  0.845072813062222\n",
      "pre:  0.9376516990291263\n",
      "rec:  0.5981227017611767\n",
      "ma F1:  0.8108341484084329\n",
      "mi F1:  0.845072813062222\n",
      "we F1:  0.8348501143361006\n",
      "29459 461\n",
      "Loss:  0.0732693150639534\n",
      "Loss:  0.08235844224691391\n",
      "Loss:  0.05359090864658356\n",
      "15 **********\n",
      "Epoch:  950.5953004360199  fold:  1  kers:  64\n",
      "epoch:  16\n",
      "29459 461\n",
      "Loss:  0.07014303654432297\n",
      "Loss:  0.07899190485477448\n",
      "Loss:  0.0801994577050209\n",
      "16 **********\n",
      "Epoch:  996.8625915050507  fold:  1  kers:  64\n",
      "epoch:  17\n",
      "29459 461\n",
      "Loss:  0.07011225819587708\n",
      "Loss:  0.09818913787603378\n",
      "Loss:  0.07698223739862442\n",
      "17 **********\n",
      "Epoch:  1043.0490982532501  fold:  1  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.5826538801193237\n",
      "Eval Loss:  0.5766337513923645\n",
      "Eval Loss:  0.09134819358587265\n",
      "[[ 909  130]\n",
      " [ 796 1597]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.87      0.66      1039\n",
      "           1       0.92      0.67      0.78      2393\n",
      "\n",
      "    accuracy                           0.73      3432\n",
      "   macro avg       0.73      0.77      0.72      3432\n",
      "weighted avg       0.81      0.73      0.74      3432\n",
      "\n",
      "acc:  0.7301864801864801\n",
      "pre:  0.9247249565720903\n",
      "rec:  0.6673631424989552\n",
      "ma F1:  0.718889580797645\n",
      "mi F1:  0.7301864801864802\n",
      "we F1:  0.741122141513463\n",
      "Eval Loss:  0.36661869287490845\n",
      "Eval Loss:  0.4503062069416046\n",
      "Eval Loss:  0.28862351179122925\n",
      "Eval Loss:  0.2632424235343933\n",
      "Eval Loss:  0.39875200390815735\n",
      "Eval Loss:  0.316571444272995\n",
      "Eval Loss:  0.40399369597435\n",
      "Eval Loss:  0.2932129502296448\n",
      "Eval Loss:  0.3224993944168091\n",
      "Eval Loss:  0.34329652786254883\n",
      "Eval Loss:  0.5023050904273987\n",
      "Eval Loss:  0.27480214834213257\n",
      "Eval Loss:  0.38970983028411865\n",
      "Eval Loss:  0.47178342938423157\n",
      "Eval Loss:  0.3404831886291504\n",
      "Eval Loss:  0.399448037147522\n",
      "Eval Loss:  0.38267087936401367\n",
      "Eval Loss:  0.38696834444999695\n",
      "Eval Loss:  0.3474765717983246\n",
      "Eval Loss:  0.358972430229187\n",
      "Eval Loss:  0.5187605023384094\n",
      "Eval Loss:  0.40704676508903503\n",
      "Eval Loss:  0.29643383622169495\n",
      "Eval Loss:  0.33629217743873596\n",
      "Eval Loss:  0.34983500838279724\n",
      "Eval Loss:  0.3777516782283783\n",
      "Eval Loss:  0.3152127265930176\n",
      "Eval Loss:  0.3823835849761963\n",
      "[[18669   456]\n",
      " [ 3759  6575]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90     19125\n",
      "           1       0.94      0.64      0.76     10334\n",
      "\n",
      "    accuracy                           0.86     29459\n",
      "   macro avg       0.88      0.81      0.83     29459\n",
      "weighted avg       0.87      0.86      0.85     29459\n",
      "\n",
      "acc:  0.8569197868223632\n",
      "pre:  0.93514436068838\n",
      "rec:  0.6362492742403716\n",
      "ma F1:  0.8279168260331777\n",
      "mi F1:  0.8569197868223632\n",
      "we F1:  0.8489987698315679\n",
      "29459 461\n",
      "Loss:  0.08404935151338577\n",
      "Loss:  0.05987883359193802\n",
      "Loss:  0.09430941194295883\n",
      "18 **********\n",
      "Epoch:  1137.9573328495026  fold:  1  kers:  64\n",
      "epoch:  19\n",
      "29459 461\n",
      "Loss:  0.05192369222640991\n",
      "Loss:  0.10114958882331848\n",
      "Loss:  0.07605517655611038\n",
      "19 **********\n",
      "Epoch:  1184.1308739185333  fold:  1  kers:  64\n",
      "epoch:  20\n",
      "29459 461\n",
      "Loss:  0.08048912137746811\n",
      "Loss:  0.05244804173707962\n",
      "Loss:  0.05640111863613129\n",
      "20 **********\n",
      "Epoch:  1230.330346107483  fold:  1  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.6473329663276672\n",
      "Eval Loss:  0.3576285243034363\n",
      "Eval Loss:  0.05799484625458717\n",
      "[[ 842  197]\n",
      " [ 605 1788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.81      0.68      1039\n",
      "           1       0.90      0.75      0.82      2393\n",
      "\n",
      "    accuracy                           0.77      3432\n",
      "   macro avg       0.74      0.78      0.75      3432\n",
      "weighted avg       0.80      0.77      0.77      3432\n",
      "\n",
      "acc:  0.7663170163170163\n",
      "pre:  0.9007556675062972\n",
      "rec:  0.7471792728792311\n",
      "ma F1:  0.7471023662156318\n",
      "mi F1:  0.7663170163170163\n",
      "we F1:  0.7746040958533429\n",
      "update!  Acc:  0.7663170163170163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.31273743510246277\n",
      "Eval Loss:  0.395530104637146\n",
      "Eval Loss:  0.24303123354911804\n",
      "Eval Loss:  0.2234366536140442\n",
      "Eval Loss:  0.31224510073661804\n",
      "Eval Loss:  0.29244548082351685\n",
      "Eval Loss:  0.3274606466293335\n",
      "Eval Loss:  0.24875277280807495\n",
      "Eval Loss:  0.24849823117256165\n",
      "Eval Loss:  0.28607696294784546\n",
      "Eval Loss:  0.4424380660057068\n",
      "Eval Loss:  0.2372744083404541\n",
      "Eval Loss:  0.352946400642395\n",
      "Eval Loss:  0.3859976530075073\n",
      "Eval Loss:  0.31502974033355713\n",
      "Eval Loss:  0.32874512672424316\n",
      "Eval Loss:  0.29893404245376587\n",
      "Eval Loss:  0.3061840236186981\n",
      "Eval Loss:  0.2974672019481659\n",
      "Eval Loss:  0.3006560206413269\n",
      "Eval Loss:  0.37012386322021484\n",
      "Eval Loss:  0.2964801490306854\n",
      "Eval Loss:  0.23249459266662598\n",
      "Eval Loss:  0.27785995602607727\n",
      "Eval Loss:  0.28901180624961853\n",
      "Eval Loss:  0.32151126861572266\n",
      "Eval Loss:  0.28146618604660034\n",
      "Eval Loss:  0.3260132968425751\n",
      "[[18400   725]\n",
      " [ 2831  7503]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     19125\n",
      "           1       0.91      0.73      0.81     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.89      0.84      0.86     29459\n",
      "weighted avg       0.88      0.88      0.88     29459\n",
      "\n",
      "acc:  0.8792898604840625\n",
      "pre:  0.9118862421001458\n",
      "rec:  0.7260499322624346\n",
      "ma F1:  0.8601550232667434\n",
      "mi F1:  0.8792898604840625\n",
      "we F1:  0.8755917814550019\n",
      "29459 461\n",
      "Loss:  0.06305238604545593\n",
      "Loss:  0.07409948855638504\n",
      "Loss:  0.0931098461151123\n",
      "21 **********\n",
      "Epoch:  1316.4740154743195  fold:  1  kers:  64\n",
      "epoch:  22\n",
      "29459 461\n",
      "Loss:  0.10313848406076431\n",
      "Loss:  0.09102527797222137\n",
      "Loss:  0.0849214494228363\n",
      "22 **********\n",
      "Epoch:  1362.5548050403595  fold:  1  kers:  64\n",
      "epoch:  23\n",
      "29459 461\n",
      "Loss:  0.08185264468193054\n",
      "Loss:  0.09687353670597076\n",
      "Loss:  0.08970341086387634\n",
      "23 **********\n",
      "Epoch:  1408.645567893982  fold:  1  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.9488396644592285\n",
      "Eval Loss:  0.30624979734420776\n",
      "Eval Loss:  0.04704638570547104\n",
      "[[ 749  290]\n",
      " [ 435 1958]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67      1039\n",
      "           1       0.87      0.82      0.84      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.75      0.77      0.76      3432\n",
      "weighted avg       0.80      0.79      0.79      3432\n",
      "\n",
      "acc:  0.7887529137529138\n",
      "pre:  0.8709964412811388\n",
      "rec:  0.8182198077726703\n",
      "ma F1:  0.7588239074307186\n",
      "mi F1:  0.7887529137529137\n",
      "we F1:  0.792342414097594\n",
      "update!  Acc:  0.7887529137529138\n",
      "Eval Loss:  0.27724918723106384\n",
      "Eval Loss:  0.33638882637023926\n",
      "Eval Loss:  0.21364089846611023\n",
      "Eval Loss:  0.1985832154750824\n",
      "Eval Loss:  0.2620013654232025\n",
      "Eval Loss:  0.2585834562778473\n",
      "Eval Loss:  0.28640225529670715\n",
      "Eval Loss:  0.22744707763195038\n",
      "Eval Loss:  0.2139412760734558\n",
      "Eval Loss:  0.2454352080821991\n",
      "Eval Loss:  0.39908698201179504\n",
      "Eval Loss:  0.20123672485351562\n",
      "Eval Loss:  0.32757771015167236\n",
      "Eval Loss:  0.33749812841415405\n",
      "Eval Loss:  0.2844446897506714\n",
      "Eval Loss:  0.2656305134296417\n",
      "Eval Loss:  0.24802860617637634\n",
      "Eval Loss:  0.2624098062515259\n",
      "Eval Loss:  0.24228718876838684\n",
      "Eval Loss:  0.26424267888069153\n",
      "Eval Loss:  0.3123990595340729\n",
      "Eval Loss:  0.26534733176231384\n",
      "Eval Loss:  0.20003971457481384\n",
      "Eval Loss:  0.2659033536911011\n",
      "Eval Loss:  0.2688755393028259\n",
      "Eval Loss:  0.2876532971858978\n",
      "Eval Loss:  0.25892317295074463\n",
      "Eval Loss:  0.2617831230163574\n",
      "[[18185   940]\n",
      " [ 2123  8211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     19125\n",
      "           1       0.90      0.79      0.84     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.87      0.88     29459\n",
      "weighted avg       0.90      0.90      0.89     29459\n",
      "\n",
      "acc:  0.8960249838758954\n",
      "pre:  0.89727898590318\n",
      "rec:  0.7945616411844397\n",
      "ma F1:  0.8825630486901639\n",
      "mi F1:  0.8960249838758954\n",
      "we F1:  0.8944282855277181\n",
      "29459 461\n",
      "Loss:  0.07856063544750214\n",
      "Loss:  0.0959787592291832\n",
      "Loss:  0.053670499473810196\n",
      "24 **********\n",
      "Epoch:  1494.641631603241  fold:  1  kers:  64\n",
      "epoch:  25\n",
      "29459 461\n",
      "Loss:  0.054748017340898514\n",
      "Loss:  0.09793193638324738\n",
      "Loss:  0.04583856835961342\n",
      "25 **********\n",
      "Epoch:  1540.734388589859  fold:  1  kers:  64\n",
      "epoch:  26\n",
      "29459 461\n",
      "Loss:  0.08918412774801254\n",
      "Loss:  0.0651995837688446\n",
      "Loss:  0.06801428645849228\n",
      "26 **********\n",
      "Epoch:  1586.8341274261475  fold:  1  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.8114653825759888\n",
      "Eval Loss:  0.5377891063690186\n",
      "Eval Loss:  0.06564674526453018\n",
      "[[ 863  176]\n",
      " [ 622 1771]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.83      0.68      1039\n",
      "           1       0.91      0.74      0.82      2393\n",
      "\n",
      "    accuracy                           0.77      3432\n",
      "   macro avg       0.75      0.79      0.75      3432\n",
      "weighted avg       0.81      0.77      0.78      3432\n",
      "\n",
      "acc:  0.7674825174825175\n",
      "pre:  0.9096045197740112\n",
      "rec:  0.7400752193898872\n",
      "ma F1:  0.7499821072542303\n",
      "mi F1:  0.7674825174825175\n",
      "we F1:  0.7760785339602884\n",
      "Eval Loss:  0.3025321960449219\n",
      "Eval Loss:  0.36406081914901733\n",
      "Eval Loss:  0.2244173288345337\n",
      "Eval Loss:  0.2163243293762207\n",
      "Eval Loss:  0.3389793038368225\n",
      "Eval Loss:  0.2658417820930481\n",
      "Eval Loss:  0.2996205985546112\n",
      "Eval Loss:  0.21551890671253204\n",
      "Eval Loss:  0.2508052587509155\n",
      "Eval Loss:  0.2711024582386017\n",
      "Eval Loss:  0.4616734981536865\n",
      "Eval Loss:  0.21622341871261597\n",
      "Eval Loss:  0.34780630469322205\n",
      "Eval Loss:  0.39877140522003174\n",
      "Eval Loss:  0.26679232716560364\n",
      "Eval Loss:  0.3074239492416382\n",
      "Eval Loss:  0.3119032680988312\n",
      "Eval Loss:  0.29306530952453613\n",
      "Eval Loss:  0.28553691506385803\n",
      "Eval Loss:  0.27833083271980286\n",
      "Eval Loss:  0.4028851389884949\n",
      "Eval Loss:  0.29417601227760315\n",
      "Eval Loss:  0.22052860260009766\n",
      "Eval Loss:  0.3129327893257141\n",
      "Eval Loss:  0.31531545519828796\n",
      "Eval Loss:  0.34062784910202026\n",
      "Eval Loss:  0.2771364450454712\n",
      "Eval Loss:  0.30440086126327515\n",
      "[[18608   517]\n",
      " [ 2856  7478]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     19125\n",
      "           1       0.94      0.72      0.82     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.90      0.85      0.87     29459\n",
      "weighted avg       0.89      0.89      0.88     29459\n",
      "\n",
      "acc:  0.8855018839743373\n",
      "pre:  0.9353345841150719\n",
      "rec:  0.7236307335010644\n",
      "ma F1:  0.8664366760260445\n",
      "mi F1:  0.8855018839743373\n",
      "we F1:  0.8814952782788245\n",
      "29459 461\n",
      "Loss:  0.07188848406076431\n",
      "Loss:  0.065743088722229\n",
      "Loss:  0.05583420395851135\n",
      "27 **********\n",
      "Epoch:  1672.7643673419952  fold:  1  kers:  64\n",
      "epoch:  28\n",
      "29459 461\n",
      "Loss:  0.0855904072523117\n",
      "Loss:  0.0709371417760849\n",
      "Loss:  0.08049827069044113\n",
      "28 **********\n",
      "Epoch:  1718.7085225582123  fold:  1  kers:  64\n",
      "epoch:  29\n",
      "29459 461\n",
      "Loss:  0.0832148939371109\n",
      "Loss:  0.06710182130336761\n",
      "Loss:  0.04630660265684128\n",
      "29 **********\n",
      "Epoch:  1764.9259459972382  fold:  1  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.9520434737205505\n",
      "Eval Loss:  0.3904050886631012\n",
      "Eval Loss:  0.07534945011138916\n",
      "[[ 771  268]\n",
      " [ 487 1906]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67      1039\n",
      "           1       0.88      0.80      0.83      2393\n",
      "\n",
      "    accuracy                           0.78      3432\n",
      "   macro avg       0.74      0.77      0.75      3432\n",
      "weighted avg       0.80      0.78      0.79      3432\n",
      "\n",
      "acc:  0.780011655011655\n",
      "pre:  0.8767249310027599\n",
      "rec:  0.7964897618052653\n",
      "ma F1:  0.7529970023065853\n",
      "mi F1:  0.7800116550116551\n",
      "we F1:  0.7852241739036464\n",
      "Eval Loss:  0.26416015625\n",
      "Eval Loss:  0.2954380512237549\n",
      "Eval Loss:  0.21229390799999237\n",
      "Eval Loss:  0.17459611594676971\n",
      "Eval Loss:  0.24563230574131012\n",
      "Eval Loss:  0.2713466286659241\n",
      "Eval Loss:  0.29549071192741394\n",
      "Eval Loss:  0.21452735364437103\n",
      "Eval Loss:  0.20856621861457825\n",
      "Eval Loss:  0.2640550136566162\n",
      "Eval Loss:  0.3829232454299927\n",
      "Eval Loss:  0.18094688653945923\n",
      "Eval Loss:  0.3073052763938904\n",
      "Eval Loss:  0.30606135725975037\n",
      "Eval Loss:  0.26470115780830383\n",
      "Eval Loss:  0.273328572511673\n",
      "Eval Loss:  0.24529647827148438\n",
      "Eval Loss:  0.25361713767051697\n",
      "Eval Loss:  0.25566500425338745\n",
      "Eval Loss:  0.23471157252788544\n",
      "Eval Loss:  0.322830468416214\n",
      "Eval Loss:  0.27588123083114624\n",
      "Eval Loss:  0.19319376349449158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2401060312986374\n",
      "Eval Loss:  0.25726082921028137\n",
      "Eval Loss:  0.26405423879623413\n",
      "Eval Loss:  0.2696562707424164\n",
      "Eval Loss:  0.2394324392080307\n",
      "[[18356   769]\n",
      " [ 2174  8160]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     19125\n",
      "           1       0.91      0.79      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.87      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9000984419023049\n",
      "pre:  0.9138761339455707\n",
      "rec:  0.7896264757112444\n",
      "ma F1:  0.8865024769488732\n",
      "mi F1:  0.9000984419023049\n",
      "we F1:  0.8982249296661758\n",
      "29459 461\n",
      "Loss:  0.08227957040071487\n",
      "Loss:  0.058239419013261795\n",
      "Loss:  0.06527552008628845\n",
      "30 **********\n",
      "Epoch:  1850.8721435070038  fold:  1  kers:  64\n",
      "epoch:  31\n",
      "29459 461\n",
      "Loss:  0.07238359749317169\n",
      "Loss:  0.03753442317247391\n",
      "Loss:  0.07353728264570236\n",
      "31 **********\n",
      "Epoch:  1896.9609115123749  fold:  1  kers:  64\n",
      "epoch:  32\n",
      "29459 461\n",
      "Loss:  0.0656144917011261\n",
      "Loss:  0.04116356745362282\n",
      "Loss:  0.0405074805021286\n",
      "32 **********\n",
      "Epoch:  1943.071620941162  fold:  1  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.9246231317520142\n",
      "Eval Loss:  0.26246634125709534\n",
      "Eval Loss:  0.06116316094994545\n",
      "[[ 694  345]\n",
      " [ 284 2109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69      1039\n",
      "           1       0.86      0.88      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.78      0.77      0.78      3432\n",
      "weighted avg       0.81      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8167249417249417\n",
      "pre:  0.8594132029339854\n",
      "rec:  0.8813205181780193\n",
      "ma F1:  0.7791898632615137\n",
      "mi F1:  0.8167249417249417\n",
      "we F1:  0.8151068217346457\n",
      "update!  Acc:  0.8167249417249417\n",
      "Eval Loss:  0.2536974251270294\n",
      "Eval Loss:  0.2927093207836151\n",
      "Eval Loss:  0.2032964676618576\n",
      "Eval Loss:  0.1996019184589386\n",
      "Eval Loss:  0.2480679154396057\n",
      "Eval Loss:  0.2550296485424042\n",
      "Eval Loss:  0.2652890980243683\n",
      "Eval Loss:  0.19913335144519806\n",
      "Eval Loss:  0.17259658873081207\n",
      "Eval Loss:  0.25618302822113037\n",
      "Eval Loss:  0.33742213249206543\n",
      "Eval Loss:  0.17987605929374695\n",
      "Eval Loss:  0.2701195776462555\n",
      "Eval Loss:  0.3018069267272949\n",
      "Eval Loss:  0.2802083194255829\n",
      "Eval Loss:  0.2476775348186493\n",
      "Eval Loss:  0.21505267918109894\n",
      "Eval Loss:  0.2393137663602829\n",
      "Eval Loss:  0.23960037529468536\n",
      "Eval Loss:  0.24513627588748932\n",
      "Eval Loss:  0.3088851869106293\n",
      "Eval Loss:  0.2634318470954895\n",
      "Eval Loss:  0.1807977259159088\n",
      "Eval Loss:  0.24027888476848602\n",
      "Eval Loss:  0.23410502076148987\n",
      "Eval Loss:  0.2818840444087982\n",
      "Eval Loss:  0.26245537400245667\n",
      "Eval Loss:  0.224335715174675\n",
      "[[18134   991]\n",
      " [ 1791  8543]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     19125\n",
      "           1       0.90      0.83      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.89      0.89     29459\n",
      "weighted avg       0.91      0.91      0.90     29459\n",
      "\n",
      "acc:  0.9055636647544044\n",
      "pre:  0.8960562198447661\n",
      "rec:  0.8266886007354364\n",
      "ma F1:  0.8943669215542169\n",
      "mi F1:  0.9055636647544044\n",
      "we F1:  0.9046297272546495\n",
      "29459 461\n",
      "Loss:  0.04676239937543869\n",
      "Loss:  0.056007932871580124\n",
      "Loss:  0.05362989753484726\n",
      "33 **********\n",
      "Epoch:  2029.2372314929962  fold:  1  kers:  64\n",
      "epoch:  34\n",
      "29459 461\n",
      "Loss:  0.0666891485452652\n",
      "Loss:  0.060911376029253006\n",
      "Loss:  0.08017480373382568\n",
      "34 **********\n",
      "Epoch:  2075.3619034290314  fold:  1  kers:  64\n",
      "epoch:  35\n",
      "29459 461\n",
      "Loss:  0.038970015943050385\n",
      "Loss:  0.059654783457517624\n",
      "Loss:  0.07286727428436279\n",
      "35 **********\n",
      "Epoch:  2121.5504052639008  fold:  1  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  1.0805777311325073\n",
      "Eval Loss:  0.3120861351490021\n",
      "Eval Loss:  0.07684461772441864\n",
      "[[ 761  278]\n",
      " [ 351 2042]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.71      1039\n",
      "           1       0.88      0.85      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.78      0.79      0.79      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8167249417249417\n",
      "pre:  0.8801724137931034\n",
      "rec:  0.8533221897200167\n",
      "ma F1:  0.7870586149884841\n",
      "mi F1:  0.8167249417249417\n",
      "we F1:  0.8184155286505947\n",
      "Eval Loss:  0.23660847544670105\n",
      "Eval Loss:  0.27306750416755676\n",
      "Eval Loss:  0.2020057886838913\n",
      "Eval Loss:  0.1546843945980072\n",
      "Eval Loss:  0.23552532494068146\n",
      "Eval Loss:  0.2472817748785019\n",
      "Eval Loss:  0.3012561500072479\n",
      "Eval Loss:  0.21443432569503784\n",
      "Eval Loss:  0.18164461851119995\n",
      "Eval Loss:  0.28798097372055054\n",
      "Eval Loss:  0.3575759828090668\n",
      "Eval Loss:  0.17064699530601501\n",
      "Eval Loss:  0.26301684975624084\n",
      "Eval Loss:  0.29453200101852417\n",
      "Eval Loss:  0.26530253887176514\n",
      "Eval Loss:  0.26103100180625916\n",
      "Eval Loss:  0.2204054445028305\n",
      "Eval Loss:  0.26276078820228577\n",
      "Eval Loss:  0.22684423625469208\n",
      "Eval Loss:  0.21235844492912292\n",
      "Eval Loss:  0.3284755051136017\n",
      "Eval Loss:  0.2921176552772522\n",
      "Eval Loss:  0.17826281487941742\n",
      "Eval Loss:  0.23420028388500214\n",
      "Eval Loss:  0.25015199184417725\n",
      "Eval Loss:  0.2768719494342804\n",
      "Eval Loss:  0.2629825472831726\n",
      "Eval Loss:  0.23080295324325562\n",
      "[[18334   791]\n",
      " [ 2002  8332]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     19125\n",
      "           1       0.91      0.81      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.88      0.89     29459\n",
      "weighted avg       0.91      0.91      0.90     29459\n",
      "\n",
      "acc:  0.9051902644353169\n",
      "pre:  0.913296064890935\n",
      "rec:  0.8062705631894717\n",
      "ma F1:  0.8928369734893942\n",
      "mi F1:  0.9051902644353169\n",
      "we F1:  0.9036945800386449\n",
      "29459 461\n",
      "Loss:  0.042295996099710464\n",
      "Loss:  0.07651641219854355\n",
      "Loss:  0.0331704206764698\n",
      "36 **********\n",
      "Epoch:  2207.586361885071  fold:  1  kers:  64\n",
      "epoch:  37\n",
      "29459 461\n",
      "Loss:  0.09602595865726471\n",
      "Loss:  0.06510152667760849\n",
      "Loss:  0.06614130735397339\n",
      "37 **********\n",
      "Epoch:  2253.7658874988556  fold:  1  kers:  64\n",
      "epoch:  38\n",
      "29459 461\n",
      "Loss:  0.05406755954027176\n",
      "Loss:  0.05573772266507149\n",
      "Loss:  0.04095333814620972\n",
      "38 **********\n",
      "Epoch:  2299.957381248474  fold:  1  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.5446277856826782\n",
      "Eval Loss:  0.3907466232776642\n",
      "Eval Loss:  0.05291491001844406\n",
      "[[ 832  207]\n",
      " [ 480 1913]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.80      0.71      1039\n",
      "           1       0.90      0.80      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.77      0.80      0.78      3432\n",
      "weighted avg       0.82      0.80      0.81      3432\n",
      "\n",
      "acc:  0.7998251748251748\n",
      "pre:  0.9023584905660378\n",
      "rec:  0.7994149603008776\n",
      "ma F1:  0.7777785108344786\n",
      "mi F1:  0.7998251748251749\n",
      "we F1:  0.8053929262307808\n",
      "Eval Loss:  0.29532891511917114\n",
      "Eval Loss:  0.31362447142601013\n",
      "Eval Loss:  0.22579272091388702\n",
      "Eval Loss:  0.20032605528831482\n",
      "Eval Loss:  0.32912614941596985\n",
      "Eval Loss:  0.2840352952480316\n",
      "Eval Loss:  0.3505104184150696\n",
      "Eval Loss:  0.21971888840198517\n",
      "Eval Loss:  0.24565312266349792\n",
      "Eval Loss:  0.3186842203140259\n",
      "Eval Loss:  0.41917771100997925\n",
      "Eval Loss:  0.21258492767810822\n",
      "Eval Loss:  0.3000763952732086\n",
      "Eval Loss:  0.3789755403995514\n",
      "Eval Loss:  0.27654463052749634\n",
      "Eval Loss:  0.33912938833236694\n",
      "Eval Loss:  0.30057278275489807\n",
      "Eval Loss:  0.32698601484298706\n",
      "Eval Loss:  0.284847229719162\n",
      "Eval Loss:  0.25722232460975647\n",
      "Eval Loss:  0.43702301383018494\n",
      "Eval Loss:  0.35200756788253784\n",
      "Eval Loss:  0.22240447998046875\n",
      "Eval Loss:  0.2931188642978668\n",
      "Eval Loss:  0.30694302916526794\n",
      "Eval Loss:  0.3853690028190613\n",
      "Eval Loss:  0.3238295614719391\n",
      "Eval Loss:  0.2921534776687622\n",
      "[[18529   596]\n",
      " [ 2649  7685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     19125\n",
      "           1       0.93      0.74      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.90      0.86      0.87     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8898469058691741\n",
      "pre:  0.9280280159401039\n",
      "rec:  0.74366169924521\n",
      "ma F1:  0.8725815591802117\n",
      "mi F1:  0.8898469058691741\n",
      "we F1:  0.8865782082711992\n",
      "29459 461\n",
      "Loss:  0.06389687955379486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04834507405757904\n",
      "Loss:  0.059529781341552734\n",
      "39 **********\n",
      "Epoch:  2386.073124885559  fold:  1  kers:  64\n",
      "epoch:  40\n",
      "29459 461\n",
      "Loss:  0.05368286371231079\n",
      "Loss:  0.0531047023832798\n",
      "Loss:  0.06182178854942322\n",
      "40 **********\n",
      "Epoch:  2432.168874025345  fold:  1  kers:  64\n",
      "epoch:  41\n",
      "29459 461\n",
      "Loss:  0.048567995429039\n",
      "Loss:  0.07196584343910217\n",
      "Loss:  0.04231995716691017\n",
      "41 **********\n",
      "Epoch:  2478.436164855957  fold:  1  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.9557405114173889\n",
      "Eval Loss:  0.27908527851104736\n",
      "Eval Loss:  0.12811289727687836\n",
      "[[ 747  292]\n",
      " [ 284 2109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72      1039\n",
      "           1       0.88      0.88      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.80      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8321678321678322\n",
      "pre:  0.87838400666389\n",
      "rec:  0.8813205181780193\n",
      "ma F1:  0.8007944713500572\n",
      "mi F1:  0.8321678321678322\n",
      "we F1:  0.8319835539838805\n",
      "update!  Acc:  0.8321678321678322\n",
      "Eval Loss:  0.21278920769691467\n",
      "Eval Loss:  0.22560028731822968\n",
      "Eval Loss:  0.2029515504837036\n",
      "Eval Loss:  0.16868913173675537\n",
      "Eval Loss:  0.20161345601081848\n",
      "Eval Loss:  0.22870710492134094\n",
      "Eval Loss:  0.2421526163816452\n",
      "Eval Loss:  0.19219905138015747\n",
      "Eval Loss:  0.18108145892620087\n",
      "Eval Loss:  0.2656356394290924\n",
      "Eval Loss:  0.31643691658973694\n",
      "Eval Loss:  0.16932275891304016\n",
      "Eval Loss:  0.24000072479248047\n",
      "Eval Loss:  0.2266855239868164\n",
      "Eval Loss:  0.27129000425338745\n",
      "Eval Loss:  0.2343934327363968\n",
      "Eval Loss:  0.21154581010341644\n",
      "Eval Loss:  0.23015283048152924\n",
      "Eval Loss:  0.1981096714735031\n",
      "Eval Loss:  0.19499027729034424\n",
      "Eval Loss:  0.29552140831947327\n",
      "Eval Loss:  0.2649924159049988\n",
      "Eval Loss:  0.16758914291858673\n",
      "Eval Loss:  0.19192861020565033\n",
      "Eval Loss:  0.22799089550971985\n",
      "Eval Loss:  0.2306046485900879\n",
      "Eval Loss:  0.23094217479228973\n",
      "Eval Loss:  0.21990714967250824\n",
      "[[18182   943]\n",
      " [ 1570  8764]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     19125\n",
      "           1       0.90      0.85      0.87     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.90      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9146949998302726\n",
      "pre:  0.9028536107963325\n",
      "rec:  0.8480743177859493\n",
      "ma F1:  0.9049836471188484\n",
      "mi F1:  0.9146949998302726\n",
      "we F1:  0.9140484699778556\n",
      "29459 461\n",
      "Loss:  0.07258086651563644\n",
      "Loss:  0.05085793510079384\n",
      "Loss:  0.04629536345601082\n",
      "42 **********\n",
      "Epoch:  2564.647652864456  fold:  1  kers:  64\n",
      "epoch:  43\n",
      "29459 461\n",
      "Loss:  0.06340549886226654\n",
      "Loss:  0.03041229024529457\n",
      "Loss:  0.05106612294912338\n",
      "43 **********\n",
      "Epoch:  2610.7892792224884  fold:  1  kers:  64\n",
      "epoch:  44\n",
      "29459 461\n",
      "Loss:  0.0678730309009552\n",
      "Loss:  0.05628345161676407\n",
      "Loss:  0.06803949177265167\n",
      "44 **********\n",
      "Epoch:  2656.9089646339417  fold:  1  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.7230505347251892\n",
      "Eval Loss:  0.31918996572494507\n",
      "Eval Loss:  0.06569362431764603\n",
      "[[ 796  243]\n",
      " [ 420 1973]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.71      1039\n",
      "           1       0.89      0.82      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.80      0.78      3432\n",
      "weighted avg       0.82      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8068181818181818\n",
      "pre:  0.8903429602888087\n",
      "rec:  0.8244880902632679\n",
      "ma F1:  0.7810688525631189\n",
      "mi F1:  0.8068181818181818\n",
      "we F1:  0.8106904258947716\n",
      "Eval Loss:  0.2291129231452942\n",
      "Eval Loss:  0.2705416977405548\n",
      "Eval Loss:  0.22155965864658356\n",
      "Eval Loss:  0.1925988793373108\n",
      "Eval Loss:  0.23071669042110443\n",
      "Eval Loss:  0.26660844683647156\n",
      "Eval Loss:  0.29449328780174255\n",
      "Eval Loss:  0.194704070687294\n",
      "Eval Loss:  0.20699818432331085\n",
      "Eval Loss:  0.28925248980522156\n",
      "Eval Loss:  0.35966765880584717\n",
      "Eval Loss:  0.17463460564613342\n",
      "Eval Loss:  0.2820221185684204\n",
      "Eval Loss:  0.2770214080810547\n",
      "Eval Loss:  0.29036301374435425\n",
      "Eval Loss:  0.2903747856616974\n",
      "Eval Loss:  0.2485412210226059\n",
      "Eval Loss:  0.2730892300605774\n",
      "Eval Loss:  0.24200820922851562\n",
      "Eval Loss:  0.22890599071979523\n",
      "Eval Loss:  0.3278716206550598\n",
      "Eval Loss:  0.29276254773139954\n",
      "Eval Loss:  0.1827789843082428\n",
      "Eval Loss:  0.23810316622257233\n",
      "Eval Loss:  0.26587891578674316\n",
      "Eval Loss:  0.2992918789386749\n",
      "Eval Loss:  0.2847039997577667\n",
      "Eval Loss:  0.2352118194103241\n",
      "[[18396   729]\n",
      " [ 2105  8229]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     19125\n",
      "           1       0.92      0.80      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.91      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.903798499609627\n",
      "pre:  0.9186202277294039\n",
      "rec:  0.7963034642926263\n",
      "ma F1:  0.8907905153073421\n",
      "mi F1:  0.9037984996096271\n",
      "we F1:  0.9020380012915445\n",
      "29459 461\n",
      "Loss:  0.03931953385472298\n",
      "Loss:  0.06481906026601791\n",
      "Loss:  0.06220576912164688\n",
      "45 **********\n",
      "Epoch:  2742.9529004096985  fold:  1  kers:  64\n",
      "epoch:  46\n",
      "29459 461\n",
      "Loss:  0.034610647708177567\n",
      "Loss:  0.036931972950696945\n",
      "Loss:  0.04440443962812424\n",
      "46 **********\n",
      "Epoch:  2789.0316956043243  fold:  1  kers:  64\n",
      "epoch:  47\n",
      "29459 461\n",
      "Loss:  0.047704871743917465\n",
      "Loss:  0.06467752158641815\n",
      "Loss:  0.0842825248837471\n",
      "47 **********\n",
      "Epoch:  2835.1922714710236  fold:  1  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.8042895197868347\n",
      "Eval Loss:  0.3485340476036072\n",
      "Eval Loss:  0.06871525198221207\n",
      "[[ 824  215]\n",
      " [ 457 1936]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.79      0.71      1039\n",
      "           1       0.90      0.81      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.77      0.80      0.78      3432\n",
      "weighted avg       0.82      0.80      0.81      3432\n",
      "\n",
      "acc:  0.8041958041958042\n",
      "pre:  0.900046490004649\n",
      "rec:  0.8090263267864605\n",
      "ma F1:  0.7812287518212724\n",
      "mi F1:  0.8041958041958042\n",
      "we F1:  0.8091940296226358\n",
      "Eval Loss:  0.21294784545898438\n",
      "Eval Loss:  0.2506740689277649\n",
      "Eval Loss:  0.21124359965324402\n",
      "Eval Loss:  0.16163526475429535\n",
      "Eval Loss:  0.21899187564849854\n",
      "Eval Loss:  0.2521511912345886\n",
      "Eval Loss:  0.28148916363716125\n",
      "Eval Loss:  0.19832314550876617\n",
      "Eval Loss:  0.18699754774570465\n",
      "Eval Loss:  0.22831225395202637\n",
      "Eval Loss:  0.3126607835292816\n",
      "Eval Loss:  0.15026964247226715\n",
      "Eval Loss:  0.25666433572769165\n",
      "Eval Loss:  0.26150646805763245\n",
      "Eval Loss:  0.27690431475639343\n",
      "Eval Loss:  0.2573019862174988\n",
      "Eval Loss:  0.2217353880405426\n",
      "Eval Loss:  0.23870885372161865\n",
      "Eval Loss:  0.22400595247745514\n",
      "Eval Loss:  0.204077810049057\n",
      "Eval Loss:  0.30872711539268494\n",
      "Eval Loss:  0.30198681354522705\n",
      "Eval Loss:  0.1528674215078354\n",
      "Eval Loss:  0.22982639074325562\n",
      "Eval Loss:  0.2573903203010559\n",
      "Eval Loss:  0.27567678689956665\n",
      "Eval Loss:  0.27335190773010254\n",
      "Eval Loss:  0.22561201453208923\n",
      "[[18401   724]\n",
      " [ 1933  8401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     19125\n",
      "           1       0.92      0.81      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.89      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9098068501985811\n",
      "pre:  0.9206575342465754\n",
      "rec:  0.8129475517708535\n",
      "ma F1:  0.8980603913627896\n",
      "mi F1:  0.909806850198581\n",
      "we F1:  0.9083867033253338\n",
      "29459 461\n",
      "Loss:  0.05680149048566818\n",
      "Loss:  0.034882642328739166\n",
      "Loss:  0.06699215620756149\n",
      "48 **********\n",
      "Epoch:  2921.2820851802826  fold:  1  kers:  64\n",
      "epoch:  49\n",
      "29459 461\n",
      "Loss:  0.04776686802506447\n",
      "Loss:  0.0707889050245285\n",
      "Loss:  0.06373541802167892\n",
      "49 **********\n",
      "Epoch:  2967.4815571308136  fold:  1  kers:  64\n",
      "epoch:  50\n",
      "29459 461\n",
      "Loss:  0.05240431800484657\n",
      "Loss:  0.044520556926727295\n",
      "Loss:  0.05720066651701927\n",
      "50 **********\n",
      "Epoch:  3013.636149406433  fold:  1  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.8920345902442932\n",
      "Eval Loss:  0.30797019600868225\n",
      "Eval Loss:  0.08860364556312561\n",
      "[[ 798  241]\n",
      " [ 399 1994]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.71      1039\n",
      "           1       0.89      0.83      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.80      0.79      3432\n",
      "weighted avg       0.82      0.81      0.82      3432\n",
      "\n",
      "acc:  0.8135198135198135\n",
      "pre:  0.8921700223713647\n",
      "rec:  0.8332636857501045\n",
      "ma F1:  0.7877429599405037\n",
      "mi F1:  0.8135198135198135\n",
      "we F1:  0.8169251169190869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21034790575504303\n",
      "Eval Loss:  0.2033202201128006\n",
      "Eval Loss:  0.1950134038925171\n",
      "Eval Loss:  0.16065464913845062\n",
      "Eval Loss:  0.19144374132156372\n",
      "Eval Loss:  0.220129132270813\n",
      "Eval Loss:  0.25484055280685425\n",
      "Eval Loss:  0.1848270744085312\n",
      "Eval Loss:  0.16146375238895416\n",
      "Eval Loss:  0.24326200783252716\n",
      "Eval Loss:  0.29988741874694824\n",
      "Eval Loss:  0.16082143783569336\n",
      "Eval Loss:  0.22021877765655518\n",
      "Eval Loss:  0.2471989542245865\n",
      "Eval Loss:  0.2744658887386322\n",
      "Eval Loss:  0.22772246599197388\n",
      "Eval Loss:  0.20016378164291382\n",
      "Eval Loss:  0.21815431118011475\n",
      "Eval Loss:  0.1834297478199005\n",
      "Eval Loss:  0.1933118999004364\n",
      "Eval Loss:  0.2846727967262268\n",
      "Eval Loss:  0.2949167490005493\n",
      "Eval Loss:  0.15260817110538483\n",
      "Eval Loss:  0.2018313705921173\n",
      "Eval Loss:  0.22476492822170258\n",
      "Eval Loss:  0.2360992431640625\n",
      "Eval Loss:  0.2567649781703949\n",
      "Eval Loss:  0.21469615399837494\n",
      "[[18307   818]\n",
      " [ 1619  8715]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     19125\n",
      "           1       0.91      0.84      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.90      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.917274856580332\n",
      "pre:  0.9141928039441939\n",
      "rec:  0.8433326882136636\n",
      "ma F1:  0.9074643503572142\n",
      "mi F1:  0.917274856580332\n",
      "we F1:  0.9164556097616584\n",
      "29459 461\n",
      "Loss:  0.07256381213665009\n",
      "Loss:  0.0698729157447815\n",
      "Loss:  0.052155524492263794\n",
      "51 **********\n",
      "Epoch:  3099.724964618683  fold:  1  kers:  64\n",
      "epoch:  52\n",
      "29459 461\n",
      "Loss:  0.06545741856098175\n",
      "Loss:  0.03430018201470375\n",
      "Loss:  0.07113102078437805\n",
      "52 **********\n",
      "Epoch:  3145.8835458755493  fold:  1  kers:  64\n",
      "epoch:  53\n",
      "29459 461\n",
      "Loss:  0.04097747057676315\n",
      "Loss:  0.06212407350540161\n",
      "Loss:  0.05597935616970062\n",
      "53 **********\n",
      "Epoch:  3192.2386021614075  fold:  1  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.7345410585403442\n",
      "Eval Loss:  0.4080723226070404\n",
      "Eval Loss:  0.06606204807758331\n",
      "[[ 822  217]\n",
      " [ 461 1932]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.79      0.71      1039\n",
      "           1       0.90      0.81      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.77      0.80      0.78      3432\n",
      "weighted avg       0.82      0.80      0.81      3432\n",
      "\n",
      "acc:  0.8024475524475524\n",
      "pre:  0.8990228013029316\n",
      "rec:  0.8073547847889678\n",
      "ma F1:  0.7793684440484847\n",
      "mi F1:  0.8024475524475524\n",
      "we F1:  0.8075207978974378\n",
      "Eval Loss:  0.23702731728553772\n",
      "Eval Loss:  0.2616259455680847\n",
      "Eval Loss:  0.22900626063346863\n",
      "Eval Loss:  0.2023146003484726\n",
      "Eval Loss:  0.24639829993247986\n",
      "Eval Loss:  0.25601550936698914\n",
      "Eval Loss:  0.27078360319137573\n",
      "Eval Loss:  0.1813657432794571\n",
      "Eval Loss:  0.19409053027629852\n",
      "Eval Loss:  0.2500362694263458\n",
      "Eval Loss:  0.3289796710014343\n",
      "Eval Loss:  0.16141106188297272\n",
      "Eval Loss:  0.24317289888858795\n",
      "Eval Loss:  0.2726811170578003\n",
      "Eval Loss:  0.27396509051322937\n",
      "Eval Loss:  0.2734033465385437\n",
      "Eval Loss:  0.22256794571876526\n",
      "Eval Loss:  0.2453332245349884\n",
      "Eval Loss:  0.21284633874893188\n",
      "Eval Loss:  0.2158527970314026\n",
      "Eval Loss:  0.32761716842651367\n",
      "Eval Loss:  0.31386592984199524\n",
      "Eval Loss:  0.1596059501171112\n",
      "Eval Loss:  0.22392170131206512\n",
      "Eval Loss:  0.2556110620498657\n",
      "Eval Loss:  0.2948836386203766\n",
      "Eval Loss:  0.2659375071525574\n",
      "Eval Loss:  0.23814699053764343\n",
      "[[18482   643]\n",
      " [ 2080  8254]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93     19125\n",
      "           1       0.93      0.80      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.88      0.89     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9075664482840559\n",
      "pre:  0.9277284477913904\n",
      "rec:  0.7987226630539965\n",
      "ma F1:  0.8948969055539122\n",
      "mi F1:  0.9075664482840559\n",
      "we F1:  0.9057864196466667\n",
      "29459 461\n",
      "Loss:  0.04186093434691429\n",
      "Loss:  0.07581714540719986\n",
      "Loss:  0.06657035648822784\n",
      "54 **********\n",
      "Epoch:  3278.3214342594147  fold:  1  kers:  64\n",
      "epoch:  55\n",
      "29459 461\n",
      "Loss:  0.07516374439001083\n",
      "Loss:  0.06033552810549736\n",
      "Loss:  0.058404188603162766\n",
      "55 **********\n",
      "Epoch:  3324.4650552272797  fold:  1  kers:  64\n",
      "epoch:  56\n",
      "29459 461\n",
      "Loss:  0.058834344148635864\n",
      "Loss:  0.05849944427609444\n",
      "Loss:  0.04142884537577629\n",
      "56 **********\n",
      "Epoch:  3370.634607553482  fold:  1  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.9716446399688721\n",
      "Eval Loss:  0.33869582414627075\n",
      "Eval Loss:  0.09626881778240204\n",
      "[[ 758  281]\n",
      " [ 357 2036]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70      1039\n",
      "           1       0.88      0.85      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.79      0.78      3432\n",
      "weighted avg       0.82      0.81      0.82      3432\n",
      "\n",
      "acc:  0.8141025641025641\n",
      "pre:  0.8787224859732412\n",
      "rec:  0.8508148767237776\n",
      "ma F1:  0.784175197676963\n",
      "mi F1:  0.8141025641025641\n",
      "we F1:  0.8158822822937578\n",
      "Eval Loss:  0.17425569891929626\n",
      "Eval Loss:  0.20190590620040894\n",
      "Eval Loss:  0.18561777472496033\n",
      "Eval Loss:  0.1448117345571518\n",
      "Eval Loss:  0.17183993756771088\n",
      "Eval Loss:  0.21667726337909698\n",
      "Eval Loss:  0.24567991495132446\n",
      "Eval Loss:  0.19380562007427216\n",
      "Eval Loss:  0.1534457802772522\n",
      "Eval Loss:  0.23375391960144043\n",
      "Eval Loss:  0.2806708812713623\n",
      "Eval Loss:  0.15382114052772522\n",
      "Eval Loss:  0.19498702883720398\n",
      "Eval Loss:  0.22026172280311584\n",
      "Eval Loss:  0.26585185527801514\n",
      "Eval Loss:  0.2180832475423813\n",
      "Eval Loss:  0.19034022092819214\n",
      "Eval Loss:  0.19551563262939453\n",
      "Eval Loss:  0.1781909167766571\n",
      "Eval Loss:  0.181979238986969\n",
      "Eval Loss:  0.26443034410476685\n",
      "Eval Loss:  0.24310515820980072\n",
      "Eval Loss:  0.1433587670326233\n",
      "Eval Loss:  0.20666226744651794\n",
      "Eval Loss:  0.21981653571128845\n",
      "Eval Loss:  0.23583984375\n",
      "Eval Loss:  0.22293047606945038\n",
      "Eval Loss:  0.18936918675899506\n",
      "[[18296   829]\n",
      " [ 1495  8839]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     19125\n",
      "           1       0.91      0.86      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9211106962218677\n",
      "pre:  0.9142532064542822\n",
      "rec:  0.85533191407006\n",
      "ma F1:  0.9120466255358224\n",
      "mi F1:  0.9211106962218677\n",
      "we F1:  0.920472367885513\n",
      "29459 461\n",
      "Loss:  0.04642830416560173\n",
      "Loss:  0.055465295910835266\n",
      "Loss:  0.06821749359369278\n",
      "57 **********\n",
      "Epoch:  3456.56484746933  fold:  1  kers:  64\n",
      "epoch:  58\n",
      "29459 461\n",
      "Loss:  0.056838180869817734\n",
      "Loss:  0.07216132432222366\n",
      "Loss:  0.07102087885141373\n",
      "58 **********\n",
      "Epoch:  3502.740383386612  fold:  1  kers:  64\n",
      "epoch:  59\n",
      "29459 461\n",
      "Loss:  0.061158277094364166\n",
      "Loss:  0.047400571405887604\n",
      "Loss:  0.09241823107004166\n",
      "59 **********\n",
      "Epoch:  3548.9807460308075  fold:  1  kers:  64\n",
      "Eval Loss:  0.7415810823440552\n",
      "Eval Loss:  0.27565711736679077\n",
      "Eval Loss:  0.06419309973716736\n",
      "[[ 778  261]\n",
      " [ 382 2011]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71      1039\n",
      "           1       0.89      0.84      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.79      0.78      3432\n",
      "weighted avg       0.82      0.81      0.82      3432\n",
      "\n",
      "acc:  0.8126456876456877\n",
      "pre:  0.8851232394366197\n",
      "rec:  0.8403677392394484\n",
      "ma F1:  0.78487971001142\n",
      "mi F1:  0.8126456876456877\n",
      "we F1:  0.8153704916146629\n",
      "update!  Acc:  0.8321678321678322\n",
      "Epoch:  3553.1515946388245  fold:  1  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1MklEQVR4nO3deXxU5bnA8d9DAmHfwx52BFFZIyCoiCtoFXdRq+jVIhVqtS6l1XqtS8t1qa3VQl1rrYqoqChYRMAFRSDsm0hElhAg7FuAEPLeP+ZMODM5M3Nmn2Se7+eTz8yc9T2Z5Dzn3cUYg1JKqfRTLdkJUEoplRwaAJRSKk1pAFBKqTSlAUAppdKUBgCllEpTmclOQDiaNm1q2rdvn+xkKKVUpbJo0aKdxphs/+WVKgC0b9+evLy8ZCdDKaUqFRHZ6LRci4CUUipNaQBQSqk0pQFAKaXSlAYApZRKUxoAlFIqTWkAUEqpNKUBQCml0pQGgAQ7dLSUD5dsSXYylFKqcnUEqwr+8NFKpizeQtsmtenTtlGyk6OUSmOaA0iw7fuPAFB89HiSU6KUSneuAoCIDBWRtSKSLyLjHNbfKCLLrZ9vRaRnqH1FpLGIzBSRddarPg4rpVQChQwAIpIBvAAMA7oD14tId7/NfgIGG2N6AI8BL7rYdxwwyxjTBZhlfVZKKZUgbnIA/YB8Y8x6Y0wJMAkYbt/AGPOtMWaP9fE7oI2LfYcDr1vvXwcuj/gqlFJKhc1NAGgNbLZ9LrCWBXIb8KmLfZsbY7YCWK/NnA4mIqNEJE9E8nbs2OEiuZWDwSQ7CUqpNOcmAIjDMse7l4gMwRMAfhvuvoEYY140xuQaY3KzsysMZ13piOOvRCmlEs9NACgAcmyf2wCF/huJSA/gZWC4MWaXi323i0hLa9+WQFF4SVdKKRUNNwFgIdBFRDqISA1gBDDVvoGItAWmADcZY35wue9UYKT1fiTwUeSXoZRSKlwhO4IZY0pFZCwwA8gAXjXGrBKR0db6icDDQBPgHyICUGoV2zjuax16PDBZRG4DNgHXxPjalFJKBeGqJ7AxZjow3W/ZRNv724Hb3e5rLd8FnBdOYqsCsaoAjNYBK6WSTHsCJ4ne/5VSyaYBQCml0pQGAKWUSlMaAJRSKk1pAFBKqTSlASBJjDYDUkolmQaABBPRoSCUUqlBA4BSSqUpDQBKKZWmNAAkidYAKKWSTQNAgpXXAGgEUEolmQaABNM6YKVUqtAAoJRSaUoDgFJKpSkNAEoplaY0ACSJTgqvlEq2tAoApcfLGDR+NtNXbE1aGrQOWCmVKlwFABEZKiJrRSRfRMY5rO8mIvNE5KiI3Gdb3lVEltp+9ovI3da6R0Rki23dxTG7KgeHS47z0dJCtuw9zEMfroznqZRSqlIIOSWkiGQALwAXAAXAQhGZaoxZbdtsN3AXcLl9X2PMWqCX7ThbgA9smzxrjHk6ivS7dvc7S5ixajsAuw+VULCnmE+Wb+X2MzuQmZFWGSGllALczQncD8g3xqwHEJFJwHCgPAAYY4qAIhG5JMhxzgN+NMZsjCK9EfPe/L3O/L85ANSrmcmN/dslPD06GKhSKtncPPq2BjbbPhdYy8I1Anjbb9lYEVkuIq+KSCOnnURklIjkiUjejh07IjhtcMVHj8f8mMF4RwPVAKCUSjY3AcCp3jKs25eI1AAuA961LZ4AdMJTRLQVeMZpX2PMi8aYXGNMbnZ2djinLbdt35GA6xLdGkcrgZVSqcJNACgAcmyf2wCFYZ5nGLDYGFNeDmOM2W6MOW6MKQNewlPUFBcD/jwr4Lo/Tf+esjJ9HFdKpR83AWAh0EVEOlhP8iOAqWGe53r8in9EpKXt4xVA0prmbNsfOIeglFJVVchKYGNMqYiMBWYAGcCrxphVIjLaWj9RRFoAeUB9oMxq6tndGLNfRGrjaUF0h9+hnxSRXniKkzY4rFdKKRVHbloBYYyZDkz3WzbR9n4bnqIhp32LgSYOy28KK6VKKaViShvAk5yh+bXWQSmVbBoAEkznA1BKpQoNAEoplaY0AADGZa+s42WGayfO46sfou+Q5vacSikVLxoAwrC3uIQFG3Zz9ztLozhKapQBzVlbxMhXF2ggUiqNuWoFpGIv2bfdX7yeR2mZobTMUD0jNYKSUiqxNAdAYsfl0UpgpVSq0ACglFJpSgNABHYfKkl2EpRSKmoaAIBZa7Yzc/V2XpiTH3Q70fIbFaW9xfrwoFJHWgSA63Jzgq5/5OPV/OLfeTw1Y22CUqTzAaSjOWuL6PXoTL7J35nspCgFpEkAuKxXq2QnoZzmIdJX3obdACzZtCfJKVHKIy0CQGredFMjC6A5EaXSV1oEgDpZsenuYA8kB4+WRnaMFIlGqZIOpVTypEUA6JnTMKL9ysoMh0uc5wy+6ZX5UaRIKaWSLy0CQKQe/WQ1Jz/8X0pKyyqsW7Jpb1TH1qIXpVSyuQoAIjJURNaKSL6IjHNY301E5onIURG5z2/dBhFZISJLRSTPtryxiMwUkXXWa6PoLye2JudtBuDYcU8AWLFlX8h99h0+xkKrss+J+NVIHDhyjBUFoY+rlFKxFjIAiEgG8AKeid27A9eLSHe/zXYDdwFPBzjMEGNML2NMrm3ZOGCWMaYLMMv6nLK+yd/Jza8uCLndra8t4JqJ8zha6lx05O/21/O49Pm55UFGKaUSxU0OoB+Qb4xZb4wpASYBw+0bGGOKjDELgWNhnHs48Lr1/nXg8jD2jatFG3ezbvsBn2Wbdhe72ndV4X7AfRGPtyipLMgOZWWGsjItM6oqtPhPpQo3AaA1sNn2ucBa5pYBPhORRSIyyra8uTFmK4D12sxpZxEZJSJ5IpK3Y0fk4/Bf3ddxymJHV02YxwXPflX+j/rHj1c5brds815+/vJ8xzqCWOr7+EwG/HlWXI5tUqQ5ajrwL/5TKtncBACnv9pw7hqDjDF98BQhjRGRs8PYF2PMi8aYXGNMbnZ2dji7+nj6mp48e13PsPY5fMxTjDM5r4ANOw9VWH//e8uYm7+TnxzWxdKe4mMUHTga02PqzUgp5SYAFAD2sRTaAIVuT2CMKbRei4AP8BQpAWwXkZYA1muR22NG6ore7nMB/t74bmPE+x4uOc72/Ud8lpnyV30CV0olh5sAsBDoIiIdRKQGMAKY6ubgIlJHROp53wMXAiut1VOBkdb7kcBH4SQ81dnHe7nh5e/o/ydPEY63A5Z/ObA+kSulEi1kADDGlAJjgRnAGmCyMWaViIwWkdEAItJCRAqA3wAPiUiBiNQHmgNzRWQZsACYZoz5r3Xo8cAFIrIOuMD6nHQzVm2LyXFuez2POd97MjX2PgPaA1cplSpcjZFgjJkOTPdbNtH2fhueoiF/+wHHgndjzC7gPNcpjZGOTeuwPkiZ/R1vLIrZubb5FfsopVQqSb+ewBE+gcei6V7RAQ0IsdB+3DRufS10n4xUpbU+KlWkXQCItATG2yLILtygcOjoiWN4K3+T3SY82eeP1Jy1kTcJThYt/lOpJu0CQLU4/BeGc8hAlb0JvznYzreiYB/HtaOZUmkn7QJAjcz4XnKwG7lJpcdtKykrt+zj0ufn8tysdclNj1Ip5pv8nRSXRDbse2WRdgEgs1p8H7Xt9/jfTVnBoQjnDYiHJZv2MObNxT5P+96Kau8QFlXdJ8sL+WJt3LucqEpu8+5ibnx5Pg+8tzzZSYmrtAsAT10TXm/gaBXsOVz+3un5P9I8wdx1O9m2L7xK5dH/WcS0FVvZEeNexZXJ2LeWcMtrC5OdDJXivBM+5RcdTHJK4ivtAsBJzesl9HxHHCqPwakjWHh+/sp8fvb3ryNLVIRSqghLKRW1tAsAiTb8hW98F3h7AvttF8mtdefBkkiSFJGt+w7T4XfTmbxwc+iNVVAaR1Wq0AAQhXD/j42p+KQf6sk/0qfuN+dvZNHGPSG3G/vWElfH+7HI03nuo2VbHNeP//R7V/MlpDNtBapSTWxmS09z9n/sWDfnjLQM8sEPPEMubRh/SYV1hoqRKNp0T/zyx+gOoJRKOA0AMfLF2iIOlxwPmr3fd7hikU2w5/t9xceinnvYrviou1nKouHNsYj2elJVQFUvrkvLIqBxw7rF5Dj24plbXlvIL99czNEgk8NcNWEepcdP7LN9/5GgHbCue3EeD7wfm2ZoxhgORNEk1e2w1R1+N50bXpof8XmSbf2OgyzdvDfZyVBJli7PL2kZAM7t5jj5WMR2H3JfGTvbGiHUGMP//ff78uVdHvyUV+b+5LPt99t8p6V068CRijNzTopR5a2bYavnrd8Vk3Mlw7nPfMnl/hX3SlVRaRkAYu26F79zv7Ht/jllsW+F6mOfrA773GVlhjfmbfBpbvrQhysrbLdk04kK4b/OXBf3aSxVfBWXlGqzXBU1DQCV3MfLC/nDR6t8hnII1dHrnbzYNeUs3HuYPWHkgFT0tu07QveHZ1TIMarYq+oz9mkAiEI8/zTW73DX+ufAEU+5/t7DFYt9wrGv+JirG/nc/J0+aRs4frbjhPW3vraAs56cHVWaqqpobyoFe4oB+HRlbCYvUhWlywx9aRkAmtXLislxDpdE3qpm/5HgFbKJLodesGE3vR+byc6DzrkHe2nDz/4+12edU8X3nLU72LzbMwzG2m0HuPHl7wL2ik4bLmsWr504j06/nx56QxV3Vb2UzVUAEJGhIrJWRPJFZJzD+m4iMk9EjorIfbblOSIyR0TWiMgqEfm1bd0jIrJFRJZaPxfH5pJCa1i7Bh+NGRT1cbaGORYPUF72/geHcnqvce8vdwwQ+x0qd/3L+4v2H+HbH09Uwr789XqmLit0/Yec+/jnbN13OOg2xWEGvv+dupJv8nexeFPojmnppLik1LEuZsGG3a6G59Y6gPjRVkAWEckAXgCGAd2B60Wku99mu4G7gKf9lpcC9xpjTgYGAGP89n3WGNPL+knoI0/PnIaJPJ1rxpiALXYGjQ9cpOL9e/3HF74dsh6ftoa73nbX29fr8zU6WmYidH94BiNenBf2fulyc3Jy7HhZVDlvt0b/J3ZTw6YyNzmAfkC+MWa9MaYEmAQMt29gjCkyxiwEjvkt32qMWWy9P4BnUvnWMUl5FRWsYu9AiGKjRMrbsJt7Jy9LdjIqF4cn9sW2jn6HjpaG1aQ4Fs//b83fRPtx0xI+7v3LX6/nh+3hN3O+euI8Tn74v3FIka/1OwLPGx6uXQePcvaTc1JyZFE3AaA1YH8kLSCCm7iItAd6A/ZeQmNFZLmIvCoijQLsN0pE8kQkb8eO2E4DeP7Jse0PEAuPT1sTl+NG+9Tof7O56ZUFvL+4ILqDprD246b5FFmtKNjHyi37YnLsQBWMQ57+gj6PzXR1hFjxDuGxaXdxzI7pxuPT1vCz5+aG3tDPMlsnvdnfb3fdWCKZPlu9nU27i3n56/XJTkoFbgKA019bWA8fIlIXeB+42xjjnXlkAtAJ6AVsBZ5x2tcY86IxJtcYk5udnR3OaUN6eeTpMT1eMnlv8LEoHth/+BjX/XMe/w3SyiSiliwR7PJu3mbueWcp4Ckzf2v+pvJ1KwpO3JC/W7+LRRt3V5iA54lpqyOuUJ+5env5+0ufn1uh8jvWisKcpyGWVQA/fznxvbdLjkfXF+V//pXHuc98GaPUpCc3YwEVADm2z22AQrcnEJHqeG7+bxpjpniXG2O227Z5CfjE7TFVfD01Yy0A83/a7TiYHIR38wnVpO6b/J3kNKpN2ya1K6y735qR6f6LuvL8nHyfAPDlD0Wc1qYBSzbtYYTVGe/cbs149ZYTgf2lr1OvrXy0zUDjUQcQbGjxj5cV0qphTfq2axz7E6ukcpMDWAh0EZEOIlIDGAFMdXNw8YwI9gqwxhjzF791LW0frwACN4tR5Qr3Bm6hs2XvYd5f5FwsE+u5A4KNeWS3ZNMe1hV5ynqLDhwtr8B7b1EB7yzcxKZdnqn3zn5qDtv3B25VNXD8bHYFaKJq7/i2LIHj+Ow7fCxgmhwluPa2rMyELHd2k6Rfvb2EqyaEX1ldFUQTqhdv2pOQCutohMwBGGNKRWQsMAPIAF41xqwSkdHW+oki0gLIA+oDZSJyN54WQz2Am4AVIrLUOuTvrRY/T4pILzy/4w3AHTG8ripr4PjZAZ/Kr504L2D/Au8YRJE4Xmb4bYRzo17xj2/L39/9zlL6tG3IlDsHcd+7FSuQ1+84RPP6NQMea8aq7QHXRWPp5r10aVaXOlm+/w6hcjmnP/E5JaVlAb+PWNiy9zBlZYacxhVzR6FuThO/+pEn/7uWT351JmXGUDcrk47ZdeOT0Coq0qa22/Yd4cp/fMtlPVtxRqcmMU5V7LgaDtq6YU/3WzbR9n4bnqIhf3MJUGNljLnJfTJVKIKwJUjuIBrrig6UTx4frcUxHN566rJCnv7sB9fb/8aqS7Dbf+QYl7/wDUO6ZvParf1CHmN14X4OHyulb7vGCRlPydv01x5k3OYjFm/cC3hyjaPeWFThOCp+Dh71NIhcVbgvpQNAWvYErore+G5jspMQte/8RhGdtGBTgC09ftjuXLwx7v3ljrOTTVniO/je5t3FHD3muYmvcNnC5+Lnvk6d4pAq1BHsp52HAvZCd+M/321kc4JbMlUFGgBUUDe9krjWIX+zDWgHMG7KirCPYfAMff3VDzt8ejT71y9MX7GVs56cw5c/BG5anKoDgcVysp1k9ClzKlYZ8vQXDLR1dPzV20v4p8tZ5g6XHOehD1dy7T8jC8ynPTKD0W/EtuNXZYnNGgAqoeUFexN2rq/X7ay0A2Od8ecTN5T+f/IdsG6Z9Ttcs3U/iXbseBk9HpmRsPNFci96YU4+C37aHfE5//b5urAfHuxFah8vK+TPn34fZOsTvIF6b3FkAyIeOFLKf1fFZ2C9VJ8ZTwNAJXTZ84kdKG7Kkqrb4SvYk9o/vwyv444xhkkLNjlOyGO3p/iYT2V9pBWN9r32FpfQftw0n2KzaO49T81Y6/hEfex4GUdLQ7dsefbzH/h63c7IE5Aidh4sCdoB8HDJ8ZDDr/srKS3jiWmr2RflCL6xoAFAhRTujbByivxuOf7T7zl0tJTFm/YybsoKfv9BeC2a56wNr4WWU0q9I6/+Z37wuqAy2yBzew6VsGFXeOXmA8fPputDFYdieGPeBr7Nd3fDryzFI+Bp6husA+BVE77l9Cc+D+uYU5cV8tLXP/nMCOhljPH5juJNA4BKuGCtZ7o+9CngGYqhspj45Y/0fmwmb1o330B9AwKFmMMloVsTvTL3pwrHdar0LCuDRRv3+PQXsd9w7beWqctc9+csF+hp9w8freKGJPQmtktGnc3qAEWIwVJyvMzzfZc69IS+csK3dEzgUOAaAFTCDQwyqunR0jI+WR7+jckrnMHU3Nh/5Bgf+rUeclJSWlZhik+vWWu20/exmZSWRd5s9LFPVvObycvYvv9I+eQ/exzKvFdv3c9VE75l4PjZlbTmxh37GECJrKMyxrAvjLqGcFO2JIbNpN3QAKASLlRzv7FvhTd8dTRCPTXeM2kpdzv0H/g4jKfn217PY9ehkvIA4X9TcFtWv//IMfr/aRYjHZq4OvlsdcWOc8mYQ+CnnYdoP25aTEfD/CpI6y03jh0v471FBWH/Pl76ej09H/2MLXsPx63fTSKlfQA4uWX9ZCdBJYP1f+8dPG7nwaPc9q+FFTYrDDDpz6+CzLHgvaEX7j3M27ZK2WPHk1P4ve+wc64oUQ1UvMHyo6WeAJgKVQATvviR+95dFnYxmHeAwC17Dgedn8ONyXkFFQYvTLS0DwBv/6J/spOgkmhy3okWTrOiGC7DbkXBPtqPm8bA8bP5nU9fhtjf+vYVH/MZtdTJb98Pvz9FVeety4hXSxy3GYsnpsdn+He3XA0FUZU1rF0j2UlQKSySh+RQ8z1Heg6norM7/pPHd+t389qt7oY2t9+XqlodQSq2LjJ4cgte905e5tP5MNlNQdM+B6BUMNFU3Maat6mn3YadnpZAiRiXyN4ya9D42a76AziJdT1EKve1yi86yPNz8ss/v7+4wDGQewf9c7K3uCRugUIDgFJB/BjDqQED2XmohOdnrwu9YRB3RDKUQRR3zi17D1O0310HqL/MdD9gn5Njx8sqTFkZ7fSo8W4yGs7xN+46xKDxs/n77BOBwl7B3OvRmfT842cxTZ+XBgClEiTQg+8fPlzpOKqpm8HNwr2R2dOQiAfnJ6atLn//99n5IQctnJy3uUIfkFteW0D3h32HzngmyqDi5fZ3cOx4WVSD1QVkoHCvp6HBtz+e6EgXbQWzWxoAVFra6LIH7PE49Mp0++A97G9fx/zcwcz3G401FvxnZPvDh8F7ST/z2Vqfzx8t3cI3+bFPl5fbb/e37y8n9/HPA7bkeumr9RQdiGzI9GQOOqgBQKWleA3+FUy4/+YH49BE8KSHPuWvn3uenv0D0XXWtJrxZv895G3wncfZP5f0rO1Jf/LCzUGPe7S0zHWzSm/nsZf8Jmp/a/4mOjv0xJ22fCsQ+IHgielruCtI02DwjFLr5GnbFKyJ5ioAiMhQEVkrIvkiMs5hfTcRmSciR0XkPjf7ikhjEZkpIuus10bRX05kGtWunqxTqzQSj05Y212Ww9v99fPo6huCmbqsMORYNvYRWK+eOM/nxlnkN9SEfayiB94PPSvdKf/rPMqqMYa12w5UWO5fsf7YJ6spdZHre9NhzKUDRwIHsmBiOUlSuEIGABHJAF4AhuGZ5vF6Eenut9lu4C7g6TD2HQfMMsZ0AWZZn5Pify89JVmnVmloaQLnLQ5kb3EJTve5tdsO+IzD7306deuut5fw1brgvXT9R7MNNJ5ONDbvLuZl29P9G99t5KK/fsW8Hz3FSeEWu/jPgf3R0oodyFYV7uf8v3wZ1nGDpeMbl4PrRcNNP4B+QL4xZj2AiEwChgPltTvGmCKgSET855sLtu9w4Bxru9eBL4DfRnoh0RjYOXWnbFNVh/dffeWWxM9B4K/XozOpm1Xx3/+y5+f63OzsTRjduuW1ij2q42mTQ2X5WU/OAeCcrs3o3Kxu+ZDOm3YfokPTOnELwrEc7uLGl+eT/8SwmB3PiZsioNaAvfCqwFrmRrB9mxtjtgJYr82cDiAio0QkT0TyduyIbvyPQJrVCzwRuVKxEumEJfHiVMfg/6QbTKza3+86GN0Afhc++1XAdU6TJw1+ak7EQdjtNceqtC/QtKex4iYAOF2y28uLZl/Pxsa8aIzJNcbkZmdnh7OrUqoSKHEYFjlWftpZsR9HOEEuEu3HTePwsdhU4F/8XHxbgrkJAAVAju1zG8DtCErB9t0uIi0BrNfYDMQSobvO65LM0yul4iCcJ3HPjTuy3s3+ou38lihuAsBCoIuIdBCRGsAIYKrL4wfbdyow0no/EvjIfbJj7zcXnJTM0yul4uCbH3f6TLxSXBLdDd5tvxC3fReSPX5RyEpgY0ypiIwFZgAZwKvGmFUiMtpaP1FEWgB5QH2gTETuBrobY/Y77WsdejwwWURuAzYB18T42pRScWSMZ/azxnVSd0DFJZv28uznP5S3+//jx6tD7BHcqsLkV+DHkqvRQI0x04Hpfssm2t5vw1O842pfa/ku4LxwEquUSh1D//oVh0qOs+QPFyQ7KT78h2z4aech6mWlZl+fZA9kpz2BlVIROWQVpyR7SGN/uY+HN0l7Mi34aU9Sz5/28wEopaJzztNfJDsJQU1fsS1lZ/6LywBzYdAcgFKqylsTh97GVYEGAKWUSlMaAJRSKk1pALBJ1XJCpZSKBw0ANu0a1052EpRSKmE0ANiMv+q0ZCdBKaUSRgOATcPaqdujUSmlYk0DgFJKpSkNAEoplaY0APjp3KxuspOglFIJoQHAz5+u0IpgpVR60ADgJzMjycPzKaVUgmgAUEqpNKUBQCml0pQGAKWUSlOuAoCIDBWRtSKSLyLjHNaLiDxnrV8uIn2s5V1FZKntZ781XSQi8oiIbLGtuzimVxYhrQFQSqWLkBPCiEgG8AJwAVAALBSRqcYY++Saw4Au1k9/YALQ3xizFuhlO84W4APbfs8aY56OwXUopVSVtnl3MTkxHq/MTQ6gH5BvjFlvjCkBJgHD/bYZDvzbeHwHNBSRln7bnAf8aIzZGHWqE+CUVjoyqFIqdZSWmZgf000AaA1stn0usJaFu80I4G2/ZWOtIqNXRaSR08lFZJSI5IlI3o4dO1wkNzotGtQE4KJTWsT9XEoplUxuAoBTsbh/KAq6jYjUAC4D3rWtnwB0wlNEtBV4xunkxpgXjTG5xpjc7OxsF8mNTssGtVj00PmMHdKZKXcOjPv5lFLKDWOSkwMoAHJsn9sAhWFuMwxYbIzZ7l1gjNlujDlujCkDXsJT1JQSmtTNolo1oU9bx0yJUkolXOxv/+4CwEKgi4h0sJ7kRwBT/baZCtxstQYaAOwzxmy1rb8ev+IfvzqCK4CVYadeKaXSRBwyAKFbARljSkVkLDADyABeNcasEpHR1vqJwHTgYiAfKAZu9e4vIrXxtCC6w+/QT4pILzyBbYPDeqWUUuViHwFCBgAAY8x0PDd5+7KJtvcGGBNg32KgicPym8JKqVJKpbF45AC0J7BSSqUpDQBKKVUJJKsSWCmlVJJpEVAS1MjQX5FSqmrSu1sIbZvEduwNpZSKhIlDIZAGgBDi0ftOKaXCpUVASfDc9b25pIf/uHZKKZVYGgCS4JRWDXjhhj4B15/RsUIXB6WUijktAkqipnVrVFj2x8tO4Z83901CapRS6UZzAEk0adQAANraJmQQgfo1qycrSUopFRUNAC6JeEa8zqimk0YqpaoGDQBKKVUJ7CkuifkxNQBEwW1e4P6LusY1HUqpqu/Fr9bH/JgaAMIkQIemdRzXBVo+ZkjnOKZIKaUiowEgAgM7OTf9fPzyUxOcEqWUipwGAJfaNKpF1+b1eHS47SYvvoVAboqE+ndoDMDp7XW6SaVUcrkKACIyVETWiki+iIxzWC8i8py1frmI9LGt2yAiK0RkqYjk2ZY3FpGZIrLOek3pO2JWZgYz7jmbM7s0jWj/K/u0BuDBS05mxSMX8ux1vWKYOqWUCl/IACAiGcALeCZ27w5cLyLd/TYbBnSxfkYBE/zWDzHG9DLG5NqWjQNmGWO6ALOsz5WCf3+MAR0bh9zn8ctP5YUb+tCjTUPq1awetDnped2aRZlCpZQKzU0OoB+Qb4xZb4wpASYBw/22GQ7823h8BzT0m/TdyXDgdev968Dl7pOdGircwoOUAdWukekzplCwXn2ntm4QVbqUUsoNNwGgNbDZ9rnAWuZ2GwN8JiKLRGSUbZvmxpitANar42OviIwSkTwRyduxY4eL5CZedr2aANSqnuF6n2C9uk9pVT/KFCmlVGhuJoV3eq71v38F22aQMaZQRJoBM0Xke2PMV24TaIx5EXgRIDc3NyXGZvZ/ev/TFadyVuem9G5bsRrjHzcGHkjOSc+chlx4SotokqeUqoKSNRZQAZBj+9wGKHS7jTHG+1oEfICnSAlgu7eYyHotCjfxyeZtBFSvZnWuPT3HZ13tGp7cwMWnOZeEtWpQk37tG3Nut2b869bTAeiV05B3rDGH/DWrlxWjVCullIebALAQ6CIiHUSkBjACmOq3zVTgZqs10ABgnzFmq4jUEZF6ACJSB7gQWGnbZ6T1fiTwUZTXklI+/81g3vpF/4DrRYTJo8/g1VtO55yuzVj2vxfy3ugzqBlGMRLAwgfPd1zetXm9sI7jNfmOMyLaTykVXxt3H4r5MUMGAGNMKTAWmAGsASYbY1aJyGgRGW1tNh1YD+QDLwF3WsubA3NFZBmwAJhmjPmvtW48cIGIrAMusD5XEoHzYt5cQauGtRjYyX2T0Qa1qpMZwfzD2QFyBg9f6mmo1bhOxWGs7S7v1crns+hYd0qlpNLjsS8DclMHgDFmOp6bvH3ZRNt7A4xx2G890DPAMXcB54WT2FQjDlUfX9x3Dj/uOBjzc3XMrkPRgaOO62rXyKC45LjPMm+RUf2amew+5DuI1Jf3n8Pgp74AoLpf0Im2nPGG/m15a/6m6A6ilKogHs9mrgKAcq9dkzq0a+I8JlAk7r3gJHrkNKRXm4ac9eRs9h8p5ZIeLZm2fGuFbfMeOp+6WZnsOlRCSWmZ4/EuOqW5T/pyGsd20vuHf9ZdA4BSlYQOBRGBRMwT/+7oM/j8N4P51XldGHxSNg1qV2dwV09L2Qu7N/fZ1vtkULN6BjWrZ9C6YS3HY37+m7P524jePst+dW74A9W9eXvgug2lVOWhASAK8SwvP719Yzo3q+uzrGcbTwcxN0/tbRvX5vJerXjB1gy1c7N6FSqZRYRxw7oBUD1D6NO2Ychj98oJvE1WZjU+HDOIj8eeGfI4Sin3JA43HC0CqkRuO7MDg0/KpouLFj4Z1YS/+j3t27VtXJtNu4sBGD24Ez8f0I6szGoRVUTbiUjQAKGUSh0aACLQooGn52+j2omdD1hEHG/+NatncMivEjiUT+46k33Fx8o/182q+KfwyKXdyagmTFuxle/W7y5f7l8C9rcRvfj1pKVhnV8plXwaACIwZkhnOmXX5aIk99htUMsTgN654wxmrNrmeBMPpH7N6iEntL+0Zyua1M1i2oqKFc529Wrqn5FSlZH+50agekY1Lu3ZKvSGcfTU1T3oZ80t0LlZXTo3i92sY1f2ac2UxVvK6wv8m7sal7XgHbPrsH5H8M4rtapncPhYeLkXpdLRlr2HY35MrQSupK7JzYlpc1O78Vf24OsHhlAnjByFk0m/GMCd53QKuk2fdg0rLLumb5uozquUckcDgKqgRma1oC2N3LaCbVa/Jg8M7ea4buLPPa2TBGHOfeeULx/eqxXN69d0m1TgxLhLSqnwaABQIdlbnz17nWPH7qDuv6grd5/fxWeZPXfRoemJnMyfrjiNgZ1951we1Nl5Dmav0YOD5zIeG36K26QqlVY0ACjXJv68L1f0bkNtv74EtWtk0rV5Pa7NdS66GTOkM3effxI5jT0d1B6//NTyCuy2TXxzGnWyMhnYqSk/PD6sfFnfdsFnXDulVX1W/fEin2UPXXJy+fubzmgf/MKUqgSa1g0+rlcktBJYheTNAXhbGWVmVOOynq2YuqyQs0/Kpn+Hxsy45+yQx/n012dTfLSUZlYRzysjcxnU2XnAvBqZnmeTey84iSHdmvHcrHU8c01P7n13mc92Xz8wxLG46vazOvL9tgO8t6jA9XUqlW40AKiIDD4pm6nLChk3tJvrHop1szJ9mqqed7LvkBYtG/iW/W8Yf4nP+/XWIHsdmtbhp52e1kVON/9FD3mGyH7q6h6Mv/I0V2mLhzaNalGwJ/YtN5SKFQ0AyjVjq/69qm8bzu/evLwoJ1qr/ngRGdXcd3W/+LQWFXIPDWpVZ9/hY1S3cg8iQmaGu2M2rZvFzoPOo61Gau5vz2XPoRJ6PzYzpsdVKla0DiANvHV7f+6/qGvE+zsNew3E7OYPnrL/UJPh2Fsf/ePGvtzYv53P+m/GncsHdw4M2cENqDBZj3ecJa/etjGRruztPwW2r45N63DTgHaO67Kq67+Yio14jAWkf51pYGDnpowZEnlHsVNbe26OgSafSbRA/wZ1szId52UG+ORXvoPTBZpis0ZGNZrVy+KDOwdxVhdPDuPyIAHg9PaN+ODOQTx2+amc1+3EaK0fjhkEeCrIP7hzIAsfPJ8HhnqCcKsG4TVzraqa1k2Nv6d0pgFAhXTfhSfx8dgz6daifrKTEjFvEPNqVNu3RcWFp3jqI2bcczYLrGk23XR4fnf0QBr4jQl1bW6Oz4B4vds2IrteFrcMbM9ZXZry1i+c531ON5ec1oL8J4aF3lDFjasAICJDRWStiOSLyDiH9SIiz1nrl4tIH2t5jojMEZE1IrJKRH5t2+cREdkiIkutn4tjd1kqljIzqnGaXxFJMtSwRiptGmFOxN4ruUndLOb//sSEdNfm5rD60Yt8+iR4icBVfU40cV3+yIUAnNo6vIBYu0Ymb9zWn/a2c9SJUye2AR2DN52NVI2MajStW4OzujRlwYMVJ/S7ZWB718e6/ayOcSnWqKri8ZsKGQBEJAN4ARgGdAeuF5HufpsNA7pYP6OACdbyUuBeY8zJwABgjN++zxpjelk/PlNOKuUvp3Ftnrq6BxNscxyEw79Xsr3HsYhQu0bgNhHeOpTm9bOoX7M6ax4dypRfDvLZ5ob+bYGKuY1gXh55evn7V2/JLX8fqE7BK9C8Df+4sQ93ntOJv153Yijwe84/qfx9oL4aAA1tOZl7LziJtY8PZZ3DE3reQxfwxm39aVavYlGWf0suL/+5qds0qkVO49qON7Vo6qtUeNzkAPoB+caY9caYEmASMNxvm+HAv43Hd0BDEWlpjNlqjFkMYIw5gGdS+eA1akoFcU1uDk2iLDu23zzn/nYIU8cOCrxxALVqZJT3VfA67+TmbBh/Sflw4W6c0akJPzw+jOdv6M0Qa8Y3gNvP6hB0vyl3DuKr+4dwx+COPssvPq0lDwzt5pOGX9t6YT95dU/+eVPfkOn61XldyMrMoHpGNV66OZceVg7QhBgIpJYtR9O95YkcUkO/BgPe4jX/DMDPerQMWV/18M/8nz9D61kJ56j4s18T5kDBNRpuAkBrYLPtcwEVb+IhtxGR9kBvYL5t8ViryOhVEXGsvRORUSKSJyJ5O3bscJFcpQLLf2IY744eWP65TaPa9GjT0HFb7zDXmdXiW1VWI7MaP+vRyqc4pF2TOmwYf0n5T3masjK5wJoStG2T2uV1GXVqZPB2kLqF2fcOLi/y6tvO86/22q2n87thJ3JFgeo8LujenPdsv7Ngru/XlvsuPIn3fzmQt0edSE+W1cLrD343bxHhozGDygNZuHNU9whRNNkp2/N7bB5GseGkUcHraPp38C1ea1o3i7NPynZ9fLuPxgR++Bh2qu9w8wM6BR8SJRJu/rKdcmn+fypBtxGRusD7wN3GmP3W4glAJ6AXsBV4xunkxpgXjTG5xpjc7OzIfslKeWVmVHPd3+DPV57Gb4d2Y0DHxuVPqtWjnDEtWiv+eBEv3ZxbYfnPB7TjjCA3iI7ZdcuLvJrWzWLD+EsY0rUZd4QYR8mtl27O5aFLTqZ6RjXGntuFvu0a+TQT9v7Gnear7pnT0FXTXSd/v763T9GVlzd4/8+ZwXNS1/fLCfuc79xxBn+9rpfPstduOb3CmFRuch2hqkDiVUfk5aYjWAFg/y21AQrdbiMi1fHc/N80xkzxbmCM2e59LyIvAZ+ElXKl4qxh7Rr80qo4blYvi7vP78LwXskpwZx5z9ksK9gX13O8eksuV02Y57gu0wqavwwQMLy5klBaN6zF9f1yuGlAe8f14VZ0+o8cO+zUFpQZw99G9A7Zr2T5IxdSv2Z13l6wuTxtW/YedpWGy3u3ZmDnJvR7YhZgyKgmFYoEBU/9y65DR/n3vI2OxxGEu87tzHOz8x3XP3hJd37/wQoAOmfXddwmGm4CwEKgi4h0ALYAI4Ab/LaZiqc4ZxLQH9hnjNkqnjztK8AaY8xf7Dt46wisj1cAK6O4DqXiSkS421aZGq0W9Wuybf+RCssn/rwPZQ5FMV2a13OcDtQ7LWmTGAwUFmzQvWrVxKcoyuv6fm35ZLn/82BgIvDnK3tUWO40ydAtA9vzr283BPwMVLjJt25Yi4cc6ggeGNqVogNHWbp5L4DjtdQK82k7UAfJ8vXiqX+ZsrggYAConZURMFcpCDf0b8sN/duyomBf2K3O3AiZnzXGlAJjgRl4KnEnG2NWichoERltbTYdWA/kAy8Bd1rLBwE3Aec6NPd8UkRWiMhyYAhwT8yuSqkU98ldZ5Z3FrMbempLLj6tpevjXNM3h6ev6cn/DApe1BEvf77yNFY8clHI7byz1zWqEzxQeYtENoy/hEcuOzGM94y7z6aPVXfRraVvIHxs+Knl7zMCDP3RuVk9x9+3XePaFdO2/k+BW6d7A4a3/L9bi4oBGirWrdinUO0U5Knefi2ntWkQlyazrsYCsppoTvdbNtH23gBjHPabS4BcnTHmprBSqlQV0rRuVkx6wlarJlwdYAa1Yae24NOV26I+Ryw8eMnJ3HRGO8c6AICRA9uzfschRp3tXMTUtUU9uraox+ntG9Gyge8xLu3Zig+XbGHW90V0dOjHEUq3FvX4ftsB2japzYINu6lnq4+oVk14b/QZzP9pN/lFB/lgyZbydXWzMvn6gSHlxVAXn9aS287swCtzfwp6vi/vH0Kfx2aW596uPT2Hj5cX0qBWdRZu2APAwE5NwprjO1I6GJxSVdQ/XPaXeOGGPtStGd9bQfWMakGfduvVrM5f/CpWAXrlNCwvtgEq3Py9vK2HIqmkf/sXA1hXdJDTWjdg2Kkt6N7Kt6glt31jctt7cjDP+qXRv9XSDf3blgcA75Ovf+GWdwY777zizevX5LN7BnPX20sATwA4/2R3dSrR0gCgVBXltsjgkh7ui5wS7d+39WPTruKQ2913UVca1a7BZdZNNZB/3Xo6+UUHfZY1qlOjvIjKf4jycHXKrsuDF5/ME9PXMPikZo7b1KyewbKHL6wQdId08wyxDpSPaBtvGgCUUimrfs3qrnpW183K9OnwFsg5XZtxTlfnG3Os/OLsjgzv1cqxiM/7ZO8/fhTAFb3b8NUPO32KmeJNA4BSSsVYM1vz1A5NPcVEjw4/hZtDTE9aO87t/v1pAFBKlRszpBMbXRS5KPf6tmvMrHsHu6qgvjY3hzfnb2Jwl8R0etUAoJQqd/9F3UJvFKYzOsZ+CIP6NTPZf6Q05seNl2AV4HY9cxo69lGIFw0ASqm4WfD786gfw5njvOb//nyOu5mwQQWlAUApFTfN6sdn9rNwe+0qZxoAlFLKzysjczl2vOrnMDQAKKWUn2j7A1QWOiewUkqlKQ0ASimVpjQAKKVUmtIAoJRSaUoDgFJKpSkNAEoplaY0ACilVJrSAKCUUmlKnCZjTlUisgNwnl05tKbAzhgmJ5XotVVOem2VU2W8tnbGmApDjFaqABANEckzxuQmOx3xoNdWOem1VU5V6dq0CEgppdKUBgCllEpT6RQAXkx2AuJIr61y0murnKrMtaVNHYBSSilf6ZQDUEopZaMBQCml0lRaBAARGSoia0UkX0TGJTs9bojIBhFZISJLRSTPWtZYRGaKyDrrtZFt+99Z17dWRC6yLe9rHSdfRJ4TEUnCtbwqIkUistK2LGbXIiJZIvKOtXy+iLRP8rU9IiJbrO9uqYhcXEmvLUdE5ojIGhFZJSK/tpZX+u8uyLVVie/ONWNMlf4BMoAfgY5ADWAZ0D3Z6XKR7g1AU79lTwLjrPfjgP+z3ne3risL6GBdb4a1bgFwBiDAp8CwJFzL2UAfYGU8rgW4E5hovR8BvJPka3sEuM9h28p2bS2BPtb7esAP1jVU+u8uyLVVie/O7U865AD6AfnGmPXGmBJgEjA8yWmK1HDgdev968DltuWTjDFHjTE/AflAPxFpCdQ3xswznr/Cf9v2SRhjzFfAbr/FsbwW+7HeA85LVE4nwLUFUtmubasxZrH1/gCwBmhNFfjuglxbIJXm2sKRDgGgNbDZ9rmA4F90qjDAZyKySERGWcuaG2O2gucPGGhmLQ90ja2t9/7LU0Esr6V8H2NMKbAPaBK3lLszVkSWW0VE3iKSSnttVvFFb2A+Vey787s2qGLfXTDpEACcIm5laPs6yBjTBxgGjBGRs4NsG+gaK+O1R3ItqXadE4BOQC9gK/CMtbxSXpuI1AXeB+42xuwPtqnDspS+Podrq1LfXSjpEAAKgBzb5zZAYZLS4poxptB6LQI+wFOUtd3KcmK9FlmbB7rGAuu9//JUEMtrKd9HRDKBBrgvlok5Y8x2Y8xxY0wZ8BKe7w4q4bWJSHU8N8g3jTFTrMVV4rtzuraq9N25kQ4BYCHQRUQ6iEgNPJUxU5OcpqBEpI6I1PO+By4EVuJJ90hrs5HAR9b7qcAIq9VBB6ALsMDKnh8QkQFW2ePNtn2SLZbXYj/W1cBsqzw2Kbw3R8sVeL47qGTXZqXlFWCNMeYvtlWV/rsLdG1V5btzLdm10In4AS7GU8v/I/BgstPjIr0d8bQ4WAas8qYZT/nhLGCd9drYts+D1vWtxdbSB8jF80f8I/A8Vu/vBF/P23iy08fwPBXdFstrAWoC7+KpmFsAdEzytb0BrACW47kJtKyk13YmniKL5cBS6+fiqvDdBbm2KvHduf3RoSCUUipNpUMRkFJKKQcaAJRSKk1pAFBKqTSlAUAppdKUBgCllEpTGgCUUipNaQBQSqk09f+mPehHFTagigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29797 3094\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29797 466\n",
      "Loss:  0.16806045174598694\n",
      "Loss:  0.16239474713802338\n",
      "Loss:  0.16026832163333893\n",
      "0 **********\n",
      "Epoch:  59.003235816955566  fold:  2  kers:  64\n",
      "epoch:  1\n",
      "29797 466\n",
      "Loss:  0.1481606513261795\n",
      "Loss:  0.12860475480556488\n",
      "Loss:  0.12675337493419647\n",
      "1 **********\n",
      "Epoch:  105.8529691696167  fold:  2  kers:  64\n",
      "epoch:  2\n",
      "29797 466\n",
      "Loss:  0.10718218982219696\n",
      "Loss:  0.14371101558208466\n",
      "Loss:  0.13335315883159637\n",
      "2 **********\n",
      "Epoch:  152.5431296825409  fold:  2  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  1.0701334476470947\n",
      "Eval Loss:  0.07834096252918243\n",
      "Eval Loss:  1.0925397872924805\n",
      "[[1249  181]\n",
      " [ 748  916]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.87      0.73      1430\n",
      "           1       0.84      0.55      0.66      1664\n",
      "\n",
      "    accuracy                           0.70      3094\n",
      "   macro avg       0.73      0.71      0.70      3094\n",
      "weighted avg       0.74      0.70      0.69      3094\n",
      "\n",
      "acc:  0.6997414350355526\n",
      "pre:  0.8350045578851413\n",
      "rec:  0.5504807692307693\n",
      "ma F1:  0.6962225639183987\n",
      "mi F1:  0.6997414350355526\n",
      "we F1:  0.693749843673912\n",
      "update!  Acc:  0.6997414350355526\n",
      "Eval Loss:  0.4381554424762726\n",
      "Eval Loss:  0.3765794634819031\n",
      "Eval Loss:  0.4484114646911621\n",
      "Eval Loss:  0.4982382357120514\n",
      "Eval Loss:  0.4109329879283905\n",
      "Eval Loss:  0.4038475453853607\n",
      "Eval Loss:  0.44943666458129883\n",
      "Eval Loss:  0.4943484663963318\n",
      "Eval Loss:  0.3497304618358612\n",
      "Eval Loss:  0.4488813579082489\n",
      "Eval Loss:  0.4725152850151062\n",
      "Eval Loss:  0.3883678615093231\n",
      "Eval Loss:  0.4923318028450012\n",
      "Eval Loss:  0.35173100233078003\n",
      "Eval Loss:  0.4351677894592285\n",
      "Eval Loss:  0.4694655239582062\n",
      "Eval Loss:  0.36954471468925476\n",
      "Eval Loss:  0.4014769196510315\n",
      "Eval Loss:  0.4743613600730896\n",
      "Eval Loss:  0.42214396595954895\n",
      "Eval Loss:  0.3639828860759735\n",
      "Eval Loss:  0.40447118878364563\n",
      "Eval Loss:  0.4407046139240265\n",
      "Eval Loss:  0.4635007977485657\n",
      "Eval Loss:  0.41762256622314453\n",
      "Eval Loss:  0.5025451183319092\n",
      "Eval Loss:  0.4841400682926178\n",
      "Eval Loss:  0.39284592866897583\n",
      "Eval Loss:  0.3534187078475952\n",
      "[[16961  1773]\n",
      " [ 3361  7702]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87     18734\n",
      "           1       0.81      0.70      0.75     11063\n",
      "\n",
      "    accuracy                           0.83     29797\n",
      "   macro avg       0.82      0.80      0.81     29797\n",
      "weighted avg       0.83      0.83      0.82     29797\n",
      "\n",
      "acc:  0.8277007752458301\n",
      "pre:  0.8128759894459103\n",
      "rec:  0.6961945222814788\n",
      "ma F1:  0.8092860357290165\n",
      "mi F1:  0.8277007752458301\n",
      "we F1:  0.8245424853276208\n",
      "29797 466\n",
      "Loss:  0.08566122502088547\n",
      "Loss:  0.12709222733974457\n",
      "Loss:  0.10354803502559662\n",
      "3 **********\n",
      "Epoch:  239.3530170917511  fold:  2  kers:  64\n",
      "epoch:  4\n",
      "29797 466\n",
      "Loss:  0.08175528049468994\n",
      "Loss:  0.0746845155954361\n",
      "Loss:  0.09633084386587143\n",
      "4 **********\n",
      "Epoch:  286.009268283844  fold:  2  kers:  64\n",
      "epoch:  5\n",
      "29797 466\n",
      "Loss:  0.08233185857534409\n",
      "Loss:  0.06690176576375961\n",
      "Loss:  0.06503775715827942\n",
      "5 **********\n",
      "Epoch:  332.74929451942444  fold:  2  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.8261213898658752\n",
      "Eval Loss:  0.1555342823266983\n",
      "Eval Loss:  0.5060425996780396\n",
      "[[1229  201]\n",
      " [ 610 1054]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75      1430\n",
      "           1       0.84      0.63      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.74      3094\n",
      "\n",
      "acc:  0.737879767291532\n",
      "pre:  0.8398406374501992\n",
      "rec:  0.6334134615384616\n",
      "ma F1:  0.7370385123531643\n",
      "mi F1:  0.737879767291532\n",
      "we F1:  0.7359136343212898\n",
      "update!  Acc:  0.737879767291532\n",
      "Eval Loss:  0.35068124532699585\n",
      "Eval Loss:  0.2562088966369629\n",
      "Eval Loss:  0.3000011742115021\n",
      "Eval Loss:  0.39022836089134216\n",
      "Eval Loss:  0.3470454216003418\n",
      "Eval Loss:  0.316944420337677\n",
      "Eval Loss:  0.3490738570690155\n",
      "Eval Loss:  0.37880900502204895\n",
      "Eval Loss:  0.26396888494491577\n",
      "Eval Loss:  0.3609845042228699\n",
      "Eval Loss:  0.3850339651107788\n",
      "Eval Loss:  0.30278244614601135\n",
      "Eval Loss:  0.39211204648017883\n",
      "Eval Loss:  0.21711020171642303\n",
      "Eval Loss:  0.3216992914676666\n",
      "Eval Loss:  0.3794161081314087\n",
      "Eval Loss:  0.33619657158851624\n",
      "Eval Loss:  0.27727800607681274\n",
      "Eval Loss:  0.3401995301246643\n",
      "Eval Loss:  0.332567036151886\n",
      "Eval Loss:  0.3372137248516083\n",
      "Eval Loss:  0.320810467004776\n",
      "Eval Loss:  0.3379955589771271\n",
      "Eval Loss:  0.3099406957626343\n",
      "Eval Loss:  0.33898431062698364\n",
      "Eval Loss:  0.3747105598449707\n",
      "Eval Loss:  0.36170437932014465\n",
      "Eval Loss:  0.2964331805706024\n",
      "Eval Loss:  0.31648948788642883\n",
      "[[17182  1552]\n",
      " [ 2522  8541]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89     18734\n",
      "           1       0.85      0.77      0.81     11063\n",
      "\n",
      "    accuracy                           0.86     29797\n",
      "   macro avg       0.86      0.84      0.85     29797\n",
      "weighted avg       0.86      0.86      0.86     29797\n",
      "\n",
      "acc:  0.8632748263247978\n",
      "pre:  0.8462300604379273\n",
      "rec:  0.7720329024676851\n",
      "ma F1:  0.8507208254900667\n",
      "mi F1:  0.8632748263247978\n",
      "we F1:  0.8618655703579319\n",
      "29797 466\n",
      "Loss:  0.09744349122047424\n",
      "Loss:  0.048102956265211105\n",
      "Loss:  0.09467138350009918\n",
      "6 **********\n",
      "Epoch:  420.0777966976166  fold:  2  kers:  64\n",
      "epoch:  7\n",
      "29797 466\n",
      "Loss:  0.07120836526155472\n",
      "Loss:  0.07362890243530273\n",
      "Loss:  0.09223703294992447\n",
      "7 **********\n",
      "Epoch:  466.87666511535645  fold:  2  kers:  64\n",
      "epoch:  8\n",
      "29797 466\n",
      "Loss:  0.09219615161418915\n",
      "Loss:  0.0742356926202774\n",
      "Loss:  0.0902847945690155\n",
      "8 **********\n",
      "Epoch:  513.6406283378601  fold:  2  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.9982200264930725\n",
      "Eval Loss:  0.04523198679089546\n",
      "Eval Loss:  0.824670672416687\n",
      "[[1347   83]\n",
      " [ 906  758]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73      1430\n",
      "           1       0.90      0.46      0.61      1664\n",
      "\n",
      "    accuracy                           0.68      3094\n",
      "   macro avg       0.75      0.70      0.67      3094\n",
      "weighted avg       0.76      0.68      0.66      3094\n",
      "\n",
      "acc:  0.6803490627020039\n",
      "pre:  0.901307966706302\n",
      "rec:  0.45552884615384615\n",
      "ma F1:  0.6683292659860838\n",
      "mi F1:  0.6803490627020039\n",
      "we F1:  0.6635539986999627\n",
      "Eval Loss:  0.3824729919433594\n",
      "Eval Loss:  0.30280330777168274\n",
      "Eval Loss:  0.3791992962360382\n",
      "Eval Loss:  0.4599742889404297\n",
      "Eval Loss:  0.34036341309547424\n",
      "Eval Loss:  0.33214524388313293\n",
      "Eval Loss:  0.35169389843940735\n",
      "Eval Loss:  0.4398253858089447\n",
      "Eval Loss:  0.3095380663871765\n",
      "Eval Loss:  0.43841686844825745\n",
      "Eval Loss:  0.41652604937553406\n",
      "Eval Loss:  0.33199644088745117\n",
      "Eval Loss:  0.40973418951034546\n",
      "Eval Loss:  0.28228655457496643\n",
      "Eval Loss:  0.3415466547012329\n",
      "Eval Loss:  0.4249383211135864\n",
      "Eval Loss:  0.3685011565685272\n",
      "Eval Loss:  0.42589443922042847\n",
      "Eval Loss:  0.4092920422554016\n",
      "Eval Loss:  0.29946306347846985\n",
      "Eval Loss:  0.3435108959674835\n",
      "Eval Loss:  0.39729738235473633\n",
      "Eval Loss:  0.3886275291442871\n",
      "Eval Loss:  0.3331967890262604\n",
      "Eval Loss:  0.3864668607711792\n",
      "Eval Loss:  0.429898202419281\n",
      "Eval Loss:  0.4211135804653168\n",
      "Eval Loss:  0.3529006242752075\n",
      "Eval Loss:  0.3478982746601105\n",
      "[[18069   665]\n",
      " [ 3656  7407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18734\n",
      "           1       0.92      0.67      0.77     11063\n",
      "\n",
      "    accuracy                           0.85     29797\n",
      "   macro avg       0.87      0.82      0.83     29797\n",
      "weighted avg       0.86      0.85      0.85     29797\n",
      "\n",
      "acc:  0.8549854012148874\n",
      "pre:  0.9176164519326065\n",
      "rec:  0.6695290608334087\n",
      "ma F1:  0.8336919787430352\n",
      "mi F1:  0.8549854012148874\n",
      "we F1:  0.8490119790977132\n",
      "29797 466\n",
      "Loss:  0.07490804046392441\n",
      "Loss:  0.07625582814216614\n",
      "Loss:  0.08603720366954803\n",
      "9 **********\n",
      "Epoch:  600.3019132614136  fold:  2  kers:  64\n",
      "epoch:  10\n",
      "29797 466\n",
      "Loss:  0.08528351783752441\n",
      "Loss:  0.09598369896411896\n",
      "Loss:  0.07863747328519821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 **********\n",
      "Epoch:  646.906302690506  fold:  2  kers:  64\n",
      "epoch:  11\n",
      "29797 466\n",
      "Loss:  0.04771063104271889\n",
      "Loss:  0.07942476123571396\n",
      "Loss:  0.08525129407644272\n",
      "11 **********\n",
      "Epoch:  693.4767825603485  fold:  2  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.4544822573661804\n",
      "Eval Loss:  0.1816198080778122\n",
      "Eval Loss:  0.3768421411514282\n",
      "[[1242  188]\n",
      " [ 575 1089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.77      1430\n",
      "           1       0.85      0.65      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.77      0.76      0.75      3094\n",
      "weighted avg       0.77      0.75      0.75      3094\n",
      "\n",
      "acc:  0.753393665158371\n",
      "pre:  0.8527799530148786\n",
      "rec:  0.6544471153846154\n",
      "ma F1:  0.7527891464063761\n",
      "mi F1:  0.753393665158371\n",
      "we F1:  0.7518645883150895\n",
      "update!  Acc:  0.753393665158371\n",
      "Eval Loss:  0.2937602698802948\n",
      "Eval Loss:  0.19152584671974182\n",
      "Eval Loss:  0.2527463734149933\n",
      "Eval Loss:  0.3193848133087158\n",
      "Eval Loss:  0.2768700122833252\n",
      "Eval Loss:  0.23956158757209778\n",
      "Eval Loss:  0.2922535240650177\n",
      "Eval Loss:  0.3203356862068176\n",
      "Eval Loss:  0.23614637553691864\n",
      "Eval Loss:  0.331032931804657\n",
      "Eval Loss:  0.33009544014930725\n",
      "Eval Loss:  0.27176371216773987\n",
      "Eval Loss:  0.3569679260253906\n",
      "Eval Loss:  0.1684006154537201\n",
      "Eval Loss:  0.27065810561180115\n",
      "Eval Loss:  0.32004910707473755\n",
      "Eval Loss:  0.3069104850292206\n",
      "Eval Loss:  0.2672087550163269\n",
      "Eval Loss:  0.2729557156562805\n",
      "Eval Loss:  0.2763378322124481\n",
      "Eval Loss:  0.2822522222995758\n",
      "Eval Loss:  0.2894844114780426\n",
      "Eval Loss:  0.28369051218032837\n",
      "Eval Loss:  0.2216654270887375\n",
      "Eval Loss:  0.3366650640964508\n",
      "Eval Loss:  0.291790246963501\n",
      "Eval Loss:  0.3254186511039734\n",
      "Eval Loss:  0.26306742429733276\n",
      "Eval Loss:  0.30879709124565125\n",
      "[[17459  1275]\n",
      " [ 2160  8903]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18734\n",
      "           1       0.87      0.80      0.84     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.88      0.87      0.87     29797\n",
      "weighted avg       0.88      0.88      0.88     29797\n",
      "\n",
      "acc:  0.884719938248817\n",
      "pre:  0.874729809392808\n",
      "rec:  0.804754587363283\n",
      "ma F1:  0.8743608519076245\n",
      "mi F1:  0.884719938248817\n",
      "we F1:  0.883648433876218\n",
      "29797 466\n",
      "Loss:  0.08851354569196701\n",
      "Loss:  0.058140408247709274\n",
      "Loss:  0.06836235523223877\n",
      "12 **********\n",
      "Epoch:  780.0991721153259  fold:  2  kers:  64\n",
      "epoch:  13\n",
      "29797 466\n",
      "Loss:  0.0616317093372345\n",
      "Loss:  0.06505704671144485\n",
      "Loss:  0.08570729196071625\n",
      "13 **********\n",
      "Epoch:  826.7554228305817  fold:  2  kers:  64\n",
      "epoch:  14\n",
      "29797 466\n",
      "Loss:  0.05638428032398224\n",
      "Loss:  0.04576075077056885\n",
      "Loss:  0.07650977373123169\n",
      "14 **********\n",
      "Epoch:  873.422643661499  fold:  2  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.4398062527179718\n",
      "Eval Loss:  0.294116348028183\n",
      "Eval Loss:  0.3213544487953186\n",
      "[[1197  233]\n",
      " [ 496 1168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      1430\n",
      "           1       0.83      0.70      0.76      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.77      0.76      3094\n",
      "weighted avg       0.78      0.76      0.76      3094\n",
      "\n",
      "acc:  0.764382676147382\n",
      "pre:  0.8336902212705211\n",
      "rec:  0.7019230769230769\n",
      "ma F1:  0.7643619746980646\n",
      "mi F1:  0.764382676147382\n",
      "we F1:  0.7641949354173646\n",
      "update!  Acc:  0.764382676147382\n",
      "Eval Loss:  0.26902779936790466\n",
      "Eval Loss:  0.1751485913991928\n",
      "Eval Loss:  0.22702394425868988\n",
      "Eval Loss:  0.29586583375930786\n",
      "Eval Loss:  0.2808508276939392\n",
      "Eval Loss:  0.23332710564136505\n",
      "Eval Loss:  0.2756249010562897\n",
      "Eval Loss:  0.30472394824028015\n",
      "Eval Loss:  0.23992674052715302\n",
      "Eval Loss:  0.3113691806793213\n",
      "Eval Loss:  0.3073444962501526\n",
      "Eval Loss:  0.26312360167503357\n",
      "Eval Loss:  0.3463757336139679\n",
      "Eval Loss:  0.14266063272953033\n",
      "Eval Loss:  0.26252564787864685\n",
      "Eval Loss:  0.29574862122535706\n",
      "Eval Loss:  0.2955803871154785\n",
      "Eval Loss:  0.23091784119606018\n",
      "Eval Loss:  0.23799346387386322\n",
      "Eval Loss:  0.28920218348503113\n",
      "Eval Loss:  0.24028870463371277\n",
      "Eval Loss:  0.2733986973762512\n",
      "Eval Loss:  0.2701284885406494\n",
      "Eval Loss:  0.18617284297943115\n",
      "Eval Loss:  0.31832581758499146\n",
      "Eval Loss:  0.2613735496997833\n",
      "Eval Loss:  0.3273662328720093\n",
      "Eval Loss:  0.25717705488204956\n",
      "Eval Loss:  0.27572381496429443\n",
      "[[17309  1425]\n",
      " [ 1851  9212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     18734\n",
      "           1       0.87      0.83      0.85     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.88      0.88      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8900560459106621\n",
      "pre:  0.866033656106045\n",
      "rec:  0.8326855283377023\n",
      "ma F1:  0.8812902885298038\n",
      "mi F1:  0.890056045910662\n",
      "we F1:  0.8895948611948111\n",
      "29797 466\n",
      "Loss:  0.07938756793737411\n",
      "Loss:  0.06202143803238869\n",
      "Loss:  0.0874602198600769\n",
      "15 **********\n",
      "Epoch:  959.8864572048187  fold:  2  kers:  64\n",
      "epoch:  16\n",
      "29797 466\n",
      "Loss:  0.07553662359714508\n",
      "Loss:  0.057817112654447556\n",
      "Loss:  0.10008731484413147\n",
      "16 **********\n",
      "Epoch:  1006.4479613304138  fold:  2  kers:  64\n",
      "epoch:  17\n",
      "29797 466\n",
      "Loss:  0.06606704741716385\n",
      "Loss:  0.0955829918384552\n",
      "Loss:  0.056081704795360565\n",
      "17 **********\n",
      "Epoch:  1053.0713002681732  fold:  2  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.4508095979690552\n",
      "Eval Loss:  0.21550163626670837\n",
      "Eval Loss:  0.30943021178245544\n",
      "[[1241  189]\n",
      " [ 566 1098]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77      1430\n",
      "           1       0.85      0.66      0.74      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.76      0.76      3094\n",
      "weighted avg       0.78      0.76      0.75      3094\n",
      "\n",
      "acc:  0.7559793148028442\n",
      "pre:  0.8531468531468531\n",
      "rec:  0.6598557692307693\n",
      "ma F1:  0.7554569344814023\n",
      "mi F1:  0.7559793148028442\n",
      "we F1:  0.754602130319043\n",
      "Eval Loss:  0.252115935087204\n",
      "Eval Loss:  0.1637955754995346\n",
      "Eval Loss:  0.23484951257705688\n",
      "Eval Loss:  0.31253886222839355\n",
      "Eval Loss:  0.24126693606376648\n",
      "Eval Loss:  0.22882677614688873\n",
      "Eval Loss:  0.3022875487804413\n",
      "Eval Loss:  0.3106084167957306\n",
      "Eval Loss:  0.24412427842617035\n",
      "Eval Loss:  0.29938948154449463\n",
      "Eval Loss:  0.3139508366584778\n",
      "Eval Loss:  0.25990018248558044\n",
      "Eval Loss:  0.3427125811576843\n",
      "Eval Loss:  0.1651546210050583\n",
      "Eval Loss:  0.24422933161258698\n",
      "Eval Loss:  0.2954379618167877\n",
      "Eval Loss:  0.2837193012237549\n",
      "Eval Loss:  0.23549506068229675\n",
      "Eval Loss:  0.24962706863880157\n",
      "Eval Loss:  0.25748559832572937\n",
      "Eval Loss:  0.23630563914775848\n",
      "Eval Loss:  0.28738588094711304\n",
      "Eval Loss:  0.27580103278160095\n",
      "Eval Loss:  0.186653733253479\n",
      "Eval Loss:  0.30145198106765747\n",
      "Eval Loss:  0.31656980514526367\n",
      "Eval Loss:  0.3605382740497589\n",
      "Eval Loss:  0.23602814972400665\n",
      "Eval Loss:  0.2518047094345093\n",
      "[[17769   965]\n",
      " [ 2204  8859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18734\n",
      "           1       0.90      0.80      0.85     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.90      0.87      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8936470114441051\n",
      "pre:  0.9017711726384365\n",
      "rec:  0.8007773659947574\n",
      "ma F1:  0.8832036688062559\n",
      "mi F1:  0.8936470114441051\n",
      "we F1:  0.8921947890503571\n",
      "29797 466\n",
      "Loss:  0.04581313207745552\n",
      "Loss:  0.05925114080309868\n",
      "Loss:  0.04770112782716751\n",
      "18 **********\n",
      "Epoch:  1139.4313905239105  fold:  2  kers:  64\n",
      "epoch:  19\n",
      "29797 466\n",
      "Loss:  0.06354554742574692\n",
      "Loss:  0.08951839804649353\n",
      "Loss:  0.04593628644943237\n",
      "19 **********\n",
      "Epoch:  1186.181390762329  fold:  2  kers:  64\n",
      "epoch:  20\n",
      "29797 466\n",
      "Loss:  0.06443452090024948\n",
      "Loss:  0.03871773183345795\n",
      "Loss:  0.06421757489442825\n",
      "20 **********\n",
      "Epoch:  1232.8386385440826  fold:  2  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.4533630609512329\n",
      "Eval Loss:  0.16050204634666443\n",
      "Eval Loss:  0.3980512320995331\n",
      "[[1302  128]\n",
      " [ 682  982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.91      0.76      1430\n",
      "           1       0.88      0.59      0.71      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.77      0.75      0.74      3094\n",
      "weighted avg       0.78      0.74      0.73      3094\n",
      "\n",
      "acc:  0.7382029734970912\n",
      "pre:  0.8846846846846846\n",
      "rec:  0.5901442307692307\n",
      "ma F1:  0.7353722679716119\n",
      "mi F1:  0.7382029734970911\n",
      "we F1:  0.7333023145561052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2611646056175232\n",
      "Eval Loss:  0.19658492505550385\n",
      "Eval Loss:  0.24498306214809418\n",
      "Eval Loss:  0.30816975235939026\n",
      "Eval Loss:  0.20718951523303986\n",
      "Eval Loss:  0.2504676282405853\n",
      "Eval Loss:  0.31622114777565\n",
      "Eval Loss:  0.316725492477417\n",
      "Eval Loss:  0.2634119689464569\n",
      "Eval Loss:  0.3073429763317108\n",
      "Eval Loss:  0.30603912472724915\n",
      "Eval Loss:  0.2623254954814911\n",
      "Eval Loss:  0.3900183141231537\n",
      "Eval Loss:  0.16647279262542725\n",
      "Eval Loss:  0.2486683577299118\n",
      "Eval Loss:  0.2910500764846802\n",
      "Eval Loss:  0.2785073518753052\n",
      "Eval Loss:  0.23393292725086212\n",
      "Eval Loss:  0.2806752920150757\n",
      "Eval Loss:  0.27085429430007935\n",
      "Eval Loss:  0.23197491466999054\n",
      "Eval Loss:  0.29599663615226746\n",
      "Eval Loss:  0.28714972734451294\n",
      "Eval Loss:  0.19667421281337738\n",
      "Eval Loss:  0.2870662212371826\n",
      "Eval Loss:  0.3595665991306305\n",
      "Eval Loss:  0.4000025987625122\n",
      "Eval Loss:  0.23206685483455658\n",
      "Eval Loss:  0.22464720904827118\n",
      "[[18011   723]\n",
      " [ 2525  8538]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18734\n",
      "           1       0.92      0.77      0.84     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.90      0.87      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8909957378259556\n",
      "pre:  0.9219306770327178\n",
      "rec:  0.7717617282834675\n",
      "ma F1:  0.8787397458849351\n",
      "mi F1:  0.8909957378259556\n",
      "we F1:  0.8886643436026136\n",
      "29797 466\n",
      "Loss:  0.04377206042408943\n",
      "Loss:  0.0644652247428894\n",
      "Loss:  0.06239379569888115\n",
      "21 **********\n",
      "Epoch:  1319.314419746399  fold:  2  kers:  64\n",
      "epoch:  22\n",
      "29797 466\n",
      "Loss:  0.07038731127977371\n",
      "Loss:  0.04960586130619049\n",
      "Loss:  0.10959213227033615\n",
      "22 **********\n",
      "Epoch:  1365.8091025352478  fold:  2  kers:  64\n",
      "epoch:  23\n",
      "29797 466\n",
      "Loss:  0.043499499559402466\n",
      "Loss:  0.07909321039915085\n",
      "Loss:  0.06375482678413391\n",
      "23 **********\n",
      "Epoch:  1412.3905537128448  fold:  2  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.4295673072338104\n",
      "Eval Loss:  0.22492866218090057\n",
      "Eval Loss:  0.22832979261875153\n",
      "[[1231  199]\n",
      " [ 529 1135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77      1430\n",
      "           1       0.85      0.68      0.76      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.78      0.77      0.76      3094\n",
      "weighted avg       0.78      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7647058823529411\n",
      "pre:  0.8508245877061469\n",
      "rec:  0.6820913461538461\n",
      "ma F1:  0.764479140743777\n",
      "mi F1:  0.7647058823529412\n",
      "we F1:  0.763926458071439\n",
      "update!  Acc:  0.7647058823529411\n",
      "Eval Loss:  0.23761676251888275\n",
      "Eval Loss:  0.1647615134716034\n",
      "Eval Loss:  0.2068164050579071\n",
      "Eval Loss:  0.26228296756744385\n",
      "Eval Loss:  0.19979654252529144\n",
      "Eval Loss:  0.23042917251586914\n",
      "Eval Loss:  0.2672009766101837\n",
      "Eval Loss:  0.265453577041626\n",
      "Eval Loss:  0.23366285860538483\n",
      "Eval Loss:  0.24069981276988983\n",
      "Eval Loss:  0.26776936650276184\n",
      "Eval Loss:  0.22424599528312683\n",
      "Eval Loss:  0.31867265701293945\n",
      "Eval Loss:  0.1376824975013733\n",
      "Eval Loss:  0.24477459490299225\n",
      "Eval Loss:  0.24841125309467316\n",
      "Eval Loss:  0.25412890315055847\n",
      "Eval Loss:  0.17964041233062744\n",
      "Eval Loss:  0.21069695055484772\n",
      "Eval Loss:  0.25975725054740906\n",
      "Eval Loss:  0.18893484771251678\n",
      "Eval Loss:  0.26391005516052246\n",
      "Eval Loss:  0.27007460594177246\n",
      "Eval Loss:  0.16752691566944122\n",
      "Eval Loss:  0.23827439546585083\n",
      "Eval Loss:  0.29900258779525757\n",
      "Eval Loss:  0.3569694757461548\n",
      "Eval Loss:  0.20964309573173523\n",
      "Eval Loss:  0.20083142817020416\n",
      "[[17707  1027]\n",
      " [ 1838  9225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18734\n",
      "           1       0.90      0.83      0.87     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.89      0.90     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9038493808101487\n",
      "pre:  0.8998244245025361\n",
      "rec:  0.8338606164693121\n",
      "ma F1:  0.8953711994819178\n",
      "mi F1:  0.9038493808101487\n",
      "we F1:  0.9030387459295551\n",
      "29797 466\n",
      "Loss:  0.08286671340465546\n",
      "Loss:  0.05511606112122536\n",
      "Loss:  0.046238239854574203\n",
      "24 **********\n",
      "Epoch:  1499.284217119217  fold:  2  kers:  64\n",
      "epoch:  25\n",
      "29797 466\n",
      "Loss:  0.03616992011666298\n",
      "Loss:  0.04940692335367203\n",
      "Loss:  0.07422755658626556\n",
      "25 **********\n",
      "Epoch:  1546.1150012016296  fold:  2  kers:  64\n",
      "epoch:  26\n",
      "29797 466\n",
      "Loss:  0.05230581760406494\n",
      "Loss:  0.04081381484866142\n",
      "Loss:  0.07407909631729126\n",
      "26 **********\n",
      "Epoch:  1592.7732470035553  fold:  2  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.5737046599388123\n",
      "Eval Loss:  0.2032395452260971\n",
      "Eval Loss:  0.5524502396583557\n",
      "[[1298  132]\n",
      " [ 719  945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75      1430\n",
      "           1       0.88      0.57      0.69      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.76      0.74      0.72      3094\n",
      "weighted avg       0.77      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7249515190691661\n",
      "pre:  0.8774373259052924\n",
      "rec:  0.5679086538461539\n",
      "ma F1:  0.7213240113727157\n",
      "mi F1:  0.724951519069166\n",
      "we F1:  0.7189193745427742\n",
      "Eval Loss:  0.2504064440727234\n",
      "Eval Loss:  0.19618497788906097\n",
      "Eval Loss:  0.24403975903987885\n",
      "Eval Loss:  0.326643705368042\n",
      "Eval Loss:  0.22950129210948944\n",
      "Eval Loss:  0.2656085789203644\n",
      "Eval Loss:  0.33368632197380066\n",
      "Eval Loss:  0.29904550313949585\n",
      "Eval Loss:  0.23761558532714844\n",
      "Eval Loss:  0.2985834777355194\n",
      "Eval Loss:  0.31535351276397705\n",
      "Eval Loss:  0.2370050549507141\n",
      "Eval Loss:  0.3470832407474518\n",
      "Eval Loss:  0.1402072161436081\n",
      "Eval Loss:  0.19182083010673523\n",
      "Eval Loss:  0.29300588369369507\n",
      "Eval Loss:  0.2546764016151428\n",
      "Eval Loss:  0.24535444378852844\n",
      "Eval Loss:  0.2708498537540436\n",
      "Eval Loss:  0.2986651360988617\n",
      "Eval Loss:  0.22366003692150116\n",
      "Eval Loss:  0.2851910889148712\n",
      "Eval Loss:  0.29343947768211365\n",
      "Eval Loss:  0.17496848106384277\n",
      "Eval Loss:  0.22424884140491486\n",
      "Eval Loss:  0.35986196994781494\n",
      "Eval Loss:  0.4080214500427246\n",
      "Eval Loss:  0.204311802983284\n",
      "Eval Loss:  0.2022237330675125\n",
      "[[18087   647]\n",
      " [ 2440  8623]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18734\n",
      "           1       0.93      0.78      0.85     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.87      0.88     29797\n",
      "weighted avg       0.90      0.90      0.89     29797\n",
      "\n",
      "acc:  0.8963989663388932\n",
      "pre:  0.9302049622437972\n",
      "rec:  0.7794449968363012\n",
      "ma F1:  0.8847750966128185\n",
      "mi F1:  0.8963989663388932\n",
      "we F1:  0.8941967687037651\n",
      "29797 466\n",
      "Loss:  0.045841000974178314\n",
      "Loss:  0.05313635244965553\n",
      "Loss:  0.051677100360393524\n",
      "27 **********\n",
      "Epoch:  1679.642974615097  fold:  2  kers:  64\n",
      "epoch:  28\n",
      "29797 466\n",
      "Loss:  0.06980776786804199\n",
      "Loss:  0.04763851687312126\n",
      "Loss:  0.06760363280773163\n",
      "28 **********\n",
      "Epoch:  1726.3052101135254  fold:  2  kers:  64\n",
      "epoch:  29\n",
      "29797 466\n",
      "Loss:  0.10017234086990356\n",
      "Loss:  0.05347852781414986\n",
      "Loss:  0.05889468640089035\n",
      "29 **********\n",
      "Epoch:  1772.983401298523  fold:  2  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.7376855611801147\n",
      "Eval Loss:  0.38287025690078735\n",
      "Eval Loss:  0.31275674700737\n",
      "[[1105  325]\n",
      " [ 467 1197]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.74      1430\n",
      "           1       0.79      0.72      0.75      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.74      0.75      0.74      3094\n",
      "weighted avg       0.75      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7440206851971558\n",
      "pre:  0.7864651773981604\n",
      "rec:  0.7193509615384616\n",
      "ma F1:  0.7437941560616839\n",
      "mi F1:  0.7440206851971558\n",
      "we F1:  0.7443703279932101\n",
      "Eval Loss:  0.2571452260017395\n",
      "Eval Loss:  0.1509133130311966\n",
      "Eval Loss:  0.22074228525161743\n",
      "Eval Loss:  0.27258291840553284\n",
      "Eval Loss:  0.21698486804962158\n",
      "Eval Loss:  0.232168510556221\n",
      "Eval Loss:  0.29955413937568665\n",
      "Eval Loss:  0.2575981914997101\n",
      "Eval Loss:  0.22806473076343536\n",
      "Eval Loss:  0.2717314660549164\n",
      "Eval Loss:  0.2724953889846802\n",
      "Eval Loss:  0.182733952999115\n",
      "Eval Loss:  0.3186917006969452\n",
      "Eval Loss:  0.1642226129770279\n",
      "Eval Loss:  0.23345190286636353\n",
      "Eval Loss:  0.2623395025730133\n",
      "Eval Loss:  0.26662102341651917\n",
      "Eval Loss:  0.18567177653312683\n",
      "Eval Loss:  0.26087450981140137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2637179493904114\n",
      "Eval Loss:  0.1967349648475647\n",
      "Eval Loss:  0.27772119641304016\n",
      "Eval Loss:  0.27443957328796387\n",
      "Eval Loss:  0.1436881422996521\n",
      "Eval Loss:  0.24241499602794647\n",
      "Eval Loss:  0.3014715611934662\n",
      "Eval Loss:  0.39356642961502075\n",
      "Eval Loss:  0.18520070612430573\n",
      "Eval Loss:  0.20588964223861694\n",
      "[[17696  1038]\n",
      " [ 1923  9140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18734\n",
      "           1       0.90      0.83      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.89      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9006275799577138\n",
      "pre:  0.8980153271762625\n",
      "rec:  0.8261773479164783\n",
      "ma F1:  0.8916979570592363\n",
      "mi F1:  0.9006275799577138\n",
      "we F1:  0.899703933830417\n",
      "29797 466\n",
      "Loss:  0.08841132372617722\n",
      "Loss:  0.040988367050886154\n",
      "Loss:  0.0651932880282402\n",
      "30 **********\n",
      "Epoch:  1859.942889213562  fold:  2  kers:  64\n",
      "epoch:  31\n",
      "29797 466\n",
      "Loss:  0.06339739263057709\n",
      "Loss:  0.04782010242342949\n",
      "Loss:  0.04187822341918945\n",
      "31 **********\n",
      "Epoch:  1906.7906279563904  fold:  2  kers:  64\n",
      "epoch:  32\n",
      "29797 466\n",
      "Loss:  0.08033168315887451\n",
      "Loss:  0.055627960711717606\n",
      "Loss:  0.08558616042137146\n",
      "32 **********\n",
      "Epoch:  1953.609444141388  fold:  2  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.5554361343383789\n",
      "Eval Loss:  0.17357002198696136\n",
      "Eval Loss:  0.6089772582054138\n",
      "[[1278  152]\n",
      " [ 689  975]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75      1430\n",
      "           1       0.87      0.59      0.70      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.76      0.74      0.73      3094\n",
      "weighted avg       0.77      0.73      0.72      3094\n",
      "\n",
      "acc:  0.7281835811247576\n",
      "pre:  0.865128660159716\n",
      "rec:  0.5859375\n",
      "ma F1:  0.7255514618827686\n",
      "mi F1:  0.7281835811247577\n",
      "we F1:  0.7235187361315296\n",
      "Eval Loss:  0.2524462044239044\n",
      "Eval Loss:  0.18641497194766998\n",
      "Eval Loss:  0.22182857990264893\n",
      "Eval Loss:  0.2888438105583191\n",
      "Eval Loss:  0.20438338816165924\n",
      "Eval Loss:  0.2375933825969696\n",
      "Eval Loss:  0.34201866388320923\n",
      "Eval Loss:  0.2517016530036926\n",
      "Eval Loss:  0.21962125599384308\n",
      "Eval Loss:  0.28209370374679565\n",
      "Eval Loss:  0.24684368073940277\n",
      "Eval Loss:  0.20072467625141144\n",
      "Eval Loss:  0.3210744559764862\n",
      "Eval Loss:  0.1204557865858078\n",
      "Eval Loss:  0.19270148873329163\n",
      "Eval Loss:  0.30388498306274414\n",
      "Eval Loss:  0.24146029353141785\n",
      "Eval Loss:  0.20503368973731995\n",
      "Eval Loss:  0.29187434911727905\n",
      "Eval Loss:  0.23778925836086273\n",
      "Eval Loss:  0.19227474927902222\n",
      "Eval Loss:  0.2594643235206604\n",
      "Eval Loss:  0.2525363564491272\n",
      "Eval Loss:  0.15779274702072144\n",
      "Eval Loss:  0.22199350595474243\n",
      "Eval Loss:  0.31613689661026\n",
      "Eval Loss:  0.3857344686985016\n",
      "Eval Loss:  0.19905845820903778\n",
      "Eval Loss:  0.20361191034317017\n",
      "[[18114   620]\n",
      " [ 2233  8830]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     18734\n",
      "           1       0.93      0.80      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.88      0.89     29797\n",
      "weighted avg       0.91      0.90      0.90     29797\n",
      "\n",
      "acc:  0.904252105916703\n",
      "pre:  0.9343915343915344\n",
      "rec:  0.7981560155473199\n",
      "ma F1:  0.8939576204132333\n",
      "mi F1:  0.904252105916703\n",
      "we F1:  0.9024635444004281\n",
      "29797 466\n",
      "Loss:  0.08880925178527832\n",
      "Loss:  0.08370514214038849\n",
      "Loss:  0.07485498487949371\n",
      "33 **********\n",
      "Epoch:  2040.4233212471008  fold:  2  kers:  64\n",
      "epoch:  34\n",
      "29797 466\n",
      "Loss:  0.06741439551115036\n",
      "Loss:  0.08670514822006226\n",
      "Loss:  0.06592360138893127\n",
      "34 **********\n",
      "Epoch:  2087.17232465744  fold:  2  kers:  64\n",
      "epoch:  35\n",
      "29797 466\n",
      "Loss:  0.056671466678380966\n",
      "Loss:  0.06912630051374435\n",
      "Loss:  0.06626783311367035\n",
      "35 **********\n",
      "Epoch:  2133.9013800621033  fold:  2  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.6399665474891663\n",
      "Eval Loss:  0.3342359662055969\n",
      "Eval Loss:  0.3183826208114624\n",
      "[[1088  342]\n",
      " [ 423 1241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      1430\n",
      "           1       0.78      0.75      0.76      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.75      0.75      0.75      3094\n",
      "weighted avg       0.75      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7527472527472527\n",
      "pre:  0.7839545167403664\n",
      "rec:  0.7457932692307693\n",
      "ma F1:  0.752141149411373\n",
      "mi F1:  0.7527472527472527\n",
      "we F1:  0.7530681309838949\n",
      "Eval Loss:  0.24340751767158508\n",
      "Eval Loss:  0.093864805996418\n",
      "Eval Loss:  0.1680709719657898\n",
      "Eval Loss:  0.2278025597333908\n",
      "Eval Loss:  0.17387008666992188\n",
      "Eval Loss:  0.20852425694465637\n",
      "Eval Loss:  0.2781655490398407\n",
      "Eval Loss:  0.2209988534450531\n",
      "Eval Loss:  0.1900300681591034\n",
      "Eval Loss:  0.24149078130722046\n",
      "Eval Loss:  0.2478378713130951\n",
      "Eval Loss:  0.1478188931941986\n",
      "Eval Loss:  0.2925400137901306\n",
      "Eval Loss:  0.12953577935695648\n",
      "Eval Loss:  0.2385757565498352\n",
      "Eval Loss:  0.25807756185531616\n",
      "Eval Loss:  0.24928109347820282\n",
      "Eval Loss:  0.1414654552936554\n",
      "Eval Loss:  0.22738654911518097\n",
      "Eval Loss:  0.19898588955402374\n",
      "Eval Loss:  0.17397496104240417\n",
      "Eval Loss:  0.23875530064105988\n",
      "Eval Loss:  0.25452959537506104\n",
      "Eval Loss:  0.11778099834918976\n",
      "Eval Loss:  0.22633901238441467\n",
      "Eval Loss:  0.2896953821182251\n",
      "Eval Loss:  0.3495137393474579\n",
      "Eval Loss:  0.18667134642601013\n",
      "Eval Loss:  0.19726310670375824\n",
      "[[17528  1206]\n",
      " [ 1444  9619]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18734\n",
      "           1       0.89      0.87      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9110648723025808\n",
      "pre:  0.8885912240184758\n",
      "rec:  0.8694748259965651\n",
      "ma F1:  0.9043242508095102\n",
      "mi F1:  0.9110648723025808\n",
      "we F1:  0.9108620314990216\n",
      "29797 466\n",
      "Loss:  0.04915618523955345\n",
      "Loss:  0.06487599015235901\n",
      "Loss:  0.05946628376841545\n",
      "36 **********\n",
      "Epoch:  2220.5526921749115  fold:  2  kers:  64\n",
      "epoch:  37\n",
      "29797 466\n",
      "Loss:  0.04757096990942955\n",
      "Loss:  0.041807182133197784\n",
      "Loss:  0.036362726241350174\n",
      "37 **********\n",
      "Epoch:  2267.280750513077  fold:  2  kers:  64\n",
      "epoch:  38\n",
      "29797 466\n",
      "Loss:  0.05110412836074829\n",
      "Loss:  0.05483003705739975\n",
      "Loss:  0.0285450741648674\n",
      "38 **********\n",
      "Epoch:  2314.0277585983276  fold:  2  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.4701097905635834\n",
      "Eval Loss:  0.34119713306427\n",
      "Eval Loss:  0.5300222039222717\n",
      "[[1141  289]\n",
      " [ 502 1162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74      1430\n",
      "           1       0.80      0.70      0.75      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.75      0.74      0.74      3094\n",
      "\n",
      "acc:  0.744343891402715\n",
      "pre:  0.8008270158511371\n",
      "rec:  0.6983173076923077\n",
      "ma F1:  0.744332113332139\n",
      "mi F1:  0.744343891402715\n",
      "we F1:  0.7444633546899858\n",
      "Eval Loss:  0.25736284255981445\n",
      "Eval Loss:  0.11151069402694702\n",
      "Eval Loss:  0.16750004887580872\n",
      "Eval Loss:  0.25201675295829773\n",
      "Eval Loss:  0.1971600502729416\n",
      "Eval Loss:  0.23141613602638245\n",
      "Eval Loss:  0.3017173111438751\n",
      "Eval Loss:  0.20865610241889954\n",
      "Eval Loss:  0.21217843890190125\n",
      "Eval Loss:  0.274054616689682\n",
      "Eval Loss:  0.22748680412769318\n",
      "Eval Loss:  0.17372103035449982\n",
      "Eval Loss:  0.2775242328643799\n",
      "Eval Loss:  0.1255795657634735\n",
      "Eval Loss:  0.20856887102127075\n",
      "Eval Loss:  0.2503923177719116\n",
      "Eval Loss:  0.24582470953464508\n",
      "Eval Loss:  0.16521814465522766\n",
      "Eval Loss:  0.25523754954338074\n",
      "Eval Loss:  0.21474915742874146\n",
      "Eval Loss:  0.14126862585544586\n",
      "Eval Loss:  0.23703055083751678\n",
      "Eval Loss:  0.21541021764278412\n",
      "Eval Loss:  0.11427267640829086\n",
      "Eval Loss:  0.1981918215751648\n",
      "Eval Loss:  0.28201520442962646\n",
      "Eval Loss:  0.3705698847770691\n",
      "Eval Loss:  0.16727839410305023\n",
      "Eval Loss:  0.20249176025390625\n",
      "[[17764   970]\n",
      " [ 1628  9435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18734\n",
      "           1       0.91      0.85      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.912810014430983\n",
      "pre:  0.9067755886592984\n",
      "rec:  0.8528428093645485\n",
      "ma F1:  0.9054200984661287\n",
      "mi F1:  0.912810014430983\n",
      "we F1:  0.912226203084498\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0580563098192215\n",
      "Loss:  0.06066669523715973\n",
      "Loss:  0.046976059675216675\n",
      "39 **********\n",
      "Epoch:  2400.8506121635437  fold:  2  kers:  64\n",
      "epoch:  40\n",
      "29797 466\n",
      "Loss:  0.04916606843471527\n",
      "Loss:  0.049120232462882996\n",
      "Loss:  0.06319957226514816\n",
      "40 **********\n",
      "Epoch:  2447.627539873123  fold:  2  kers:  64\n",
      "epoch:  41\n",
      "29797 466\n",
      "Loss:  0.06541381776332855\n",
      "Loss:  0.0593021996319294\n",
      "Loss:  0.018021076917648315\n",
      "41 **********\n",
      "Epoch:  2494.379534959793  fold:  2  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.4376211166381836\n",
      "Eval Loss:  0.16958074271678925\n",
      "Eval Loss:  0.7322851419448853\n",
      "[[1251  179]\n",
      " [ 648 1016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.75      1430\n",
      "           1       0.85      0.61      0.71      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.75      0.74      0.73      3094\n",
      "weighted avg       0.76      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7327084680025856\n",
      "pre:  0.8502092050209205\n",
      "rec:  0.6105769230769231\n",
      "ma F1:  0.7311575352260142\n",
      "mi F1:  0.7327084680025856\n",
      "we F1:  0.7296132021633857\n",
      "Eval Loss:  0.25338977575302124\n",
      "Eval Loss:  0.14566068351268768\n",
      "Eval Loss:  0.19578513503074646\n",
      "Eval Loss:  0.3067806661128998\n",
      "Eval Loss:  0.18990856409072876\n",
      "Eval Loss:  0.25076156854629517\n",
      "Eval Loss:  0.32616108655929565\n",
      "Eval Loss:  0.2308887094259262\n",
      "Eval Loss:  0.2044682651758194\n",
      "Eval Loss:  0.2645273208618164\n",
      "Eval Loss:  0.22795982658863068\n",
      "Eval Loss:  0.18994095921516418\n",
      "Eval Loss:  0.3043123781681061\n",
      "Eval Loss:  0.12252327799797058\n",
      "Eval Loss:  0.18070600926876068\n",
      "Eval Loss:  0.2951890826225281\n",
      "Eval Loss:  0.2351863980293274\n",
      "Eval Loss:  0.17278538644313812\n",
      "Eval Loss:  0.2883211076259613\n",
      "Eval Loss:  0.22034773230552673\n",
      "Eval Loss:  0.16279028356075287\n",
      "Eval Loss:  0.26043808460235596\n",
      "Eval Loss:  0.2348417192697525\n",
      "Eval Loss:  0.1235063374042511\n",
      "Eval Loss:  0.17786236107349396\n",
      "Eval Loss:  0.2978478968143463\n",
      "Eval Loss:  0.35566288232803345\n",
      "Eval Loss:  0.1906631737947464\n",
      "Eval Loss:  0.20344506204128265\n",
      "[[18158   576]\n",
      " [ 2061  9002]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93     18734\n",
      "           1       0.94      0.81      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.92      0.89      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9115011578346813\n",
      "pre:  0.939862184172061\n",
      "rec:  0.8137033354424659\n",
      "ma F1:  0.9022737968266968\n",
      "mi F1:  0.9115011578346813\n",
      "we F1:  0.9100045838835175\n",
      "29797 466\n",
      "Loss:  0.061798445880413055\n",
      "Loss:  0.04197864979505539\n",
      "Loss:  0.053341202437877655\n",
      "42 **********\n",
      "Epoch:  2581.3120942115784  fold:  2  kers:  64\n",
      "epoch:  43\n",
      "29797 466\n",
      "Loss:  0.04299880564212799\n",
      "Loss:  0.0787714272737503\n",
      "Loss:  0.041941456496715546\n",
      "43 **********\n",
      "Epoch:  2628.1169481277466  fold:  2  kers:  64\n",
      "epoch:  44\n",
      "29797 466\n",
      "Loss:  0.061873309314250946\n",
      "Loss:  0.04697006195783615\n",
      "Loss:  0.05960319936275482\n",
      "44 **********\n",
      "Epoch:  2674.8130917549133  fold:  2  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.5294678807258606\n",
      "Eval Loss:  0.2822173237800598\n",
      "Eval Loss:  0.4690532088279724\n",
      "[[1159  271]\n",
      " [ 516 1148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75      1430\n",
      "           1       0.81      0.69      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.75      0.75      0.75      3094\n",
      "weighted avg       0.75      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7456367162249515\n",
      "pre:  0.8090204369274137\n",
      "rec:  0.6899038461538461\n",
      "ma F1:  0.7456335010495976\n",
      "mi F1:  0.7456367162249515\n",
      "we F1:  0.7455651055011626\n",
      "Eval Loss:  0.23932121694087982\n",
      "Eval Loss:  0.13113637268543243\n",
      "Eval Loss:  0.1776334047317505\n",
      "Eval Loss:  0.3009473979473114\n",
      "Eval Loss:  0.2157302051782608\n",
      "Eval Loss:  0.24417608976364136\n",
      "Eval Loss:  0.3189048767089844\n",
      "Eval Loss:  0.20724332332611084\n",
      "Eval Loss:  0.20375099778175354\n",
      "Eval Loss:  0.2566855847835541\n",
      "Eval Loss:  0.20954474806785583\n",
      "Eval Loss:  0.1743689924478531\n",
      "Eval Loss:  0.26030173897743225\n",
      "Eval Loss:  0.1142660602927208\n",
      "Eval Loss:  0.17443397641181946\n",
      "Eval Loss:  0.2591877579689026\n",
      "Eval Loss:  0.24548077583312988\n",
      "Eval Loss:  0.16505490243434906\n",
      "Eval Loss:  0.2644389867782593\n",
      "Eval Loss:  0.20548494160175323\n",
      "Eval Loss:  0.12579083442687988\n",
      "Eval Loss:  0.226186603307724\n",
      "Eval Loss:  0.23309150338172913\n",
      "Eval Loss:  0.11868602782487869\n",
      "Eval Loss:  0.17147178947925568\n",
      "Eval Loss:  0.2629263997077942\n",
      "Eval Loss:  0.3345913887023926\n",
      "Eval Loss:  0.19489403069019318\n",
      "Eval Loss:  0.20015424489974976\n",
      "[[17990   744]\n",
      " [ 1752  9311]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     18734\n",
      "           1       0.93      0.84      0.88     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.90      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.916233177836695\n",
      "pre:  0.9260069617105917\n",
      "rec:  0.8416342764168852\n",
      "ma F1:  0.9084676905114702\n",
      "mi F1:  0.916233177836695\n",
      "we F1:  0.9153312754027939\n",
      "29797 466\n",
      "Loss:  0.03446142002940178\n",
      "Loss:  0.0587800070643425\n",
      "Loss:  0.05493519827723503\n",
      "45 **********\n",
      "Epoch:  2761.427502632141  fold:  2  kers:  64\n",
      "epoch:  46\n",
      "29797 466\n",
      "Loss:  0.05072799324989319\n",
      "Loss:  0.026464059948921204\n",
      "Loss:  0.06741538643836975\n",
      "46 **********\n",
      "Epoch:  2808.1485798358917  fold:  2  kers:  64\n",
      "epoch:  47\n",
      "29797 466\n",
      "Loss:  0.0737176388502121\n",
      "Loss:  0.06218239665031433\n",
      "Loss:  0.07169873267412186\n",
      "47 **********\n",
      "Epoch:  2854.8776364326477  fold:  2  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.7971236109733582\n",
      "Eval Loss:  0.5689804553985596\n",
      "Eval Loss:  0.6333314776420593\n",
      "[[ 956  474]\n",
      " [ 393 1271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69      1430\n",
      "           1       0.73      0.76      0.75      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.72      0.72      0.72      3094\n",
      "weighted avg       0.72      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7197802197802198\n",
      "pre:  0.7283667621776504\n",
      "rec:  0.7638221153846154\n",
      "ma F1:  0.7168452451763112\n",
      "mi F1:  0.7197802197802198\n",
      "we F1:  0.7190255120249289\n",
      "Eval Loss:  0.2439715713262558\n",
      "Eval Loss:  0.10283026099205017\n",
      "Eval Loss:  0.20315095782279968\n",
      "Eval Loss:  0.25855860114097595\n",
      "Eval Loss:  0.21979176998138428\n",
      "Eval Loss:  0.2062087506055832\n",
      "Eval Loss:  0.31668567657470703\n",
      "Eval Loss:  0.2046341449022293\n",
      "Eval Loss:  0.18003293871879578\n",
      "Eval Loss:  0.27240657806396484\n",
      "Eval Loss:  0.2252933382987976\n",
      "Eval Loss:  0.1478126347064972\n",
      "Eval Loss:  0.24422046542167664\n",
      "Eval Loss:  0.11635851114988327\n",
      "Eval Loss:  0.2182636708021164\n",
      "Eval Loss:  0.2516741156578064\n",
      "Eval Loss:  0.2718615233898163\n",
      "Eval Loss:  0.1432025283575058\n",
      "Eval Loss:  0.22128985822200775\n",
      "Eval Loss:  0.19838064908981323\n",
      "Eval Loss:  0.13713330030441284\n",
      "Eval Loss:  0.221351757645607\n",
      "Eval Loss:  0.2632931172847748\n",
      "Eval Loss:  0.1085035502910614\n",
      "Eval Loss:  0.1954861432313919\n",
      "Eval Loss:  0.26744651794433594\n",
      "Eval Loss:  0.32412606477737427\n",
      "Eval Loss:  0.15430286526679993\n",
      "Eval Loss:  0.19547194242477417\n",
      "[[17605  1129]\n",
      " [ 1458  9605]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18734\n",
      "           1       0.89      0.87      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9131791791119911\n",
      "pre:  0.8948201975032607\n",
      "rec:  0.8682093464702161\n",
      "ma F1:  0.9064346783682591\n",
      "mi F1:  0.9131791791119911\n",
      "we F1:  0.9129018115189053\n",
      "29797 466\n",
      "Loss:  0.02680974453687668\n",
      "Loss:  0.04109418764710426\n",
      "Loss:  0.06944693624973297\n",
      "48 **********\n",
      "Epoch:  2941.688521385193  fold:  2  kers:  64\n",
      "epoch:  49\n",
      "29797 466\n",
      "Loss:  0.07275842130184174\n",
      "Loss:  0.04284263774752617\n",
      "Loss:  0.05332150682806969\n",
      "49 **********\n",
      "Epoch:  2988.521300315857  fold:  2  kers:  64\n",
      "epoch:  50\n",
      "29797 466\n",
      "Loss:  0.04798046126961708\n",
      "Loss:  0.0633329525589943\n",
      "Loss:  0.06906498968601227\n",
      "50 **********\n",
      "Epoch:  3035.328148126602  fold:  2  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.525038480758667\n",
      "Eval Loss:  0.155339777469635\n",
      "Eval Loss:  1.0262227058410645\n",
      "[[1199  231]\n",
      " [ 653 1011]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.84      0.73      1430\n",
      "           1       0.81      0.61      0.70      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.73      0.72      0.71      3094\n",
      "weighted avg       0.74      0.71      0.71      3094\n",
      "\n",
      "acc:  0.7142857142857143\n",
      "pre:  0.8140096618357487\n",
      "rec:  0.6075721153846154\n",
      "ma F1:  0.7132269154196931\n",
      "mi F1:  0.7142857142857143\n",
      "we F1:  0.7119090487460284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23361720144748688\n",
      "Eval Loss:  0.11945218592882156\n",
      "Eval Loss:  0.19075652956962585\n",
      "Eval Loss:  0.28285446763038635\n",
      "Eval Loss:  0.18869319558143616\n",
      "Eval Loss:  0.21723006665706635\n",
      "Eval Loss:  0.30192694067955017\n",
      "Eval Loss:  0.2413419783115387\n",
      "Eval Loss:  0.1648862212896347\n",
      "Eval Loss:  0.2470960021018982\n",
      "Eval Loss:  0.2340988963842392\n",
      "Eval Loss:  0.16512958705425262\n",
      "Eval Loss:  0.28770872950553894\n",
      "Eval Loss:  0.11374802887439728\n",
      "Eval Loss:  0.1615629941225052\n",
      "Eval Loss:  0.25180017948150635\n",
      "Eval Loss:  0.2265169769525528\n",
      "Eval Loss:  0.16523703932762146\n",
      "Eval Loss:  0.2755885720252991\n",
      "Eval Loss:  0.20902353525161743\n",
      "Eval Loss:  0.12547700107097626\n",
      "Eval Loss:  0.22590775787830353\n",
      "Eval Loss:  0.2424718290567398\n",
      "Eval Loss:  0.09842395037412643\n",
      "Eval Loss:  0.19161450862884521\n",
      "Eval Loss:  0.2712189257144928\n",
      "Eval Loss:  0.3204469382762909\n",
      "Eval Loss:  0.16021467745304108\n",
      "Eval Loss:  0.21923333406448364\n",
      "[[18119   615]\n",
      " [ 1790  9273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     18734\n",
      "           1       0.94      0.84      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.90      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9192871765613988\n",
      "pre:  0.9378033980582524\n",
      "rec:  0.8381994034167948\n",
      "ma F1:  0.9114859872326126\n",
      "mi F1:  0.9192871765613988\n",
      "we F1:  0.918250957088041\n",
      "29797 466\n",
      "Loss:  0.0656302198767662\n",
      "Loss:  0.048456307500600815\n",
      "Loss:  0.06532599031925201\n",
      "51 **********\n",
      "Epoch:  3122.1440200805664  fold:  2  kers:  64\n",
      "epoch:  52\n",
      "29797 466\n",
      "Loss:  0.052791934460401535\n",
      "Loss:  0.06710906326770782\n",
      "Loss:  0.04781371355056763\n",
      "52 **********\n",
      "Epoch:  3168.9279296398163  fold:  2  kers:  64\n",
      "epoch:  53\n",
      "29797 466\n",
      "Loss:  0.06756087392568588\n",
      "Loss:  0.09349944442510605\n",
      "Loss:  0.04701460525393486\n",
      "53 **********\n",
      "Epoch:  3215.633049249649  fold:  2  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.5461183190345764\n",
      "Eval Loss:  0.18293213844299316\n",
      "Eval Loss:  0.7146214246749878\n",
      "[[1177  253]\n",
      " [ 590 1074]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.74      1430\n",
      "           1       0.81      0.65      0.72      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.74      0.73      0.73      3094\n",
      "weighted avg       0.74      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7275371687136393\n",
      "pre:  0.8093443858327054\n",
      "rec:  0.6454326923076923\n",
      "ma F1:  0.7272348794898928\n",
      "mi F1:  0.7275371687136393\n",
      "we F1:  0.7265481253310905\n",
      "Eval Loss:  0.2362903356552124\n",
      "Eval Loss:  0.10601741075515747\n",
      "Eval Loss:  0.15455687046051025\n",
      "Eval Loss:  0.26880204677581787\n",
      "Eval Loss:  0.18016943335533142\n",
      "Eval Loss:  0.20851558446884155\n",
      "Eval Loss:  0.2972184419631958\n",
      "Eval Loss:  0.2217779904603958\n",
      "Eval Loss:  0.1603773981332779\n",
      "Eval Loss:  0.23765332996845245\n",
      "Eval Loss:  0.200385183095932\n",
      "Eval Loss:  0.15918295085430145\n",
      "Eval Loss:  0.2732321321964264\n",
      "Eval Loss:  0.10118182003498077\n",
      "Eval Loss:  0.15028177201747894\n",
      "Eval Loss:  0.2176951766014099\n",
      "Eval Loss:  0.22748684883117676\n",
      "Eval Loss:  0.1488129049539566\n",
      "Eval Loss:  0.2299032360315323\n",
      "Eval Loss:  0.1982952505350113\n",
      "Eval Loss:  0.10690157860517502\n",
      "Eval Loss:  0.21970319747924805\n",
      "Eval Loss:  0.21980716288089752\n",
      "Eval Loss:  0.09553943574428558\n",
      "Eval Loss:  0.1453007608652115\n",
      "Eval Loss:  0.256624698638916\n",
      "Eval Loss:  0.32131245732307434\n",
      "Eval Loss:  0.17316661775112152\n",
      "Eval Loss:  0.1872079223394394\n",
      "[[18048   686]\n",
      " [ 1609  9454]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18734\n",
      "           1       0.93      0.85      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.93      0.91      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9229788233714804\n",
      "pre:  0.9323471400394477\n",
      "rec:  0.8545602458645937\n",
      "ma F1:  0.9159904820314768\n",
      "mi F1:  0.9229788233714804\n",
      "we F1:  0.9222282719336373\n",
      "29797 466\n",
      "Loss:  0.07596692442893982\n",
      "Loss:  0.025113821029663086\n",
      "Loss:  0.057414405047893524\n",
      "54 **********\n",
      "Epoch:  3302.3481907844543  fold:  2  kers:  64\n",
      "epoch:  55\n",
      "29797 466\n",
      "Loss:  0.04259740561246872\n",
      "Loss:  0.07395510375499725\n",
      "Loss:  0.06318362057209015\n",
      "55 **********\n",
      "Epoch:  3349.106168985367  fold:  2  kers:  64\n",
      "epoch:  56\n",
      "29797 466\n",
      "Loss:  0.04552663862705231\n",
      "Loss:  0.061028629541397095\n",
      "Loss:  0.04724166542291641\n",
      "56 **********\n",
      "Epoch:  3395.728511095047  fold:  2  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.6648440361022949\n",
      "Eval Loss:  0.1913769692182541\n",
      "Eval Loss:  0.5232091546058655\n",
      "[[1071  359]\n",
      " [ 474 1190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72      1430\n",
      "           1       0.77      0.72      0.74      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.73      0.73      0.73      3094\n",
      "weighted avg       0.73      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7307692307692307\n",
      "pre:  0.7682375726275016\n",
      "rec:  0.7151442307692307\n",
      "ma F1:  0.7303703703703703\n",
      "mi F1:  0.7307692307692306\n",
      "we F1:  0.7311546840958606\n",
      "Eval Loss:  0.2561197280883789\n",
      "Eval Loss:  0.12091474235057831\n",
      "Eval Loss:  0.19824659824371338\n",
      "Eval Loss:  0.2863468825817108\n",
      "Eval Loss:  0.23550796508789062\n",
      "Eval Loss:  0.23853681981563568\n",
      "Eval Loss:  0.3045709729194641\n",
      "Eval Loss:  0.2341853231191635\n",
      "Eval Loss:  0.17007628083229065\n",
      "Eval Loss:  0.2628120481967926\n",
      "Eval Loss:  0.2247212678194046\n",
      "Eval Loss:  0.16549095511436462\n",
      "Eval Loss:  0.27884283661842346\n",
      "Eval Loss:  0.1300910860300064\n",
      "Eval Loss:  0.17755740880966187\n",
      "Eval Loss:  0.2646300494670868\n",
      "Eval Loss:  0.2739711105823517\n",
      "Eval Loss:  0.15675897896289825\n",
      "Eval Loss:  0.21694958209991455\n",
      "Eval Loss:  0.1973055750131607\n",
      "Eval Loss:  0.12607036530971527\n",
      "Eval Loss:  0.2322700470685959\n",
      "Eval Loss:  0.2204522043466568\n",
      "Eval Loss:  0.09051427990198135\n",
      "Eval Loss:  0.17658664286136627\n",
      "Eval Loss:  0.2972942590713501\n",
      "Eval Loss:  0.3367564082145691\n",
      "Eval Loss:  0.16516485810279846\n",
      "Eval Loss:  0.185838982462883\n",
      "[[17900   834]\n",
      " [ 1653  9410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18734\n",
      "           1       0.92      0.85      0.88     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.90      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9165352216666107\n",
      "pre:  0.9185864896524795\n",
      "rec:  0.8505830244960679\n",
      "ma F1:  0.9091605110948946\n",
      "mi F1:  0.9165352216666107\n",
      "we F1:  0.9158238096573956\n",
      "29797 466\n",
      "Loss:  0.053994860500097275\n",
      "Loss:  0.06560354679822922\n",
      "Loss:  0.046446457505226135\n",
      "57 **********\n",
      "Epoch:  3482.411737680435  fold:  2  kers:  64\n",
      "epoch:  58\n",
      "29797 466\n",
      "Loss:  0.032957032322883606\n",
      "Loss:  0.04177124425768852\n",
      "Loss:  0.025697093456983566\n",
      "58 **********\n",
      "Epoch:  3529.04305434227  fold:  2  kers:  64\n",
      "epoch:  59\n",
      "29797 466\n",
      "Loss:  0.022964367642998695\n",
      "Loss:  0.053121618926525116\n",
      "Loss:  0.026913169771432877\n",
      "59 **********\n",
      "Epoch:  3575.7471771240234  fold:  2  kers:  64\n",
      "Eval Loss:  0.5620900988578796\n",
      "Eval Loss:  0.2351355254650116\n",
      "Eval Loss:  0.6948001980781555\n",
      "[[1105  325]\n",
      " [ 532 1132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72      1430\n",
      "           1       0.78      0.68      0.73      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.73      0.73      0.72      3094\n",
      "weighted avg       0.73      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7230122818358112\n",
      "pre:  0.7769389155799589\n",
      "rec:  0.6802884615384616\n",
      "ma F1:  0.7229911867888648\n",
      "mi F1:  0.7230122818358112\n",
      "we F1:  0.7231740105290675\n",
      "update!  Acc:  0.7647058823529411\n",
      "Epoch:  3579.5869104862213  fold:  2  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.1687367707490921\n",
      "Loss:  0.163202166557312\n",
      "Loss:  0.1543501615524292\n",
      "0 **********\n",
      "Epoch:  58.56241583824158  fold:  3  kers:  64\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.13723498582839966\n",
      "Loss:  0.15141001343727112\n",
      "Loss:  0.12283705919981003\n",
      "1 **********\n",
      "Epoch:  104.84965300559998  fold:  3  kers:  64\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.11597554385662079\n",
      "Loss:  0.11690101027488708\n",
      "Loss:  0.12261530756950378\n",
      "2 **********\n",
      "Epoch:  151.16681098937988  fold:  3  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.8268907070159912\n",
      "Eval Loss:  0.9309386610984802\n",
      "Eval Loss:  0.37742936611175537\n",
      "[[1310  226]\n",
      " [ 588 1307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1536\n",
      "           1       0.85      0.69      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7627513844360245\n",
      "pre:  0.852576647097195\n",
      "rec:  0.6897097625329816\n",
      "ma F1:  0.7627512030494696\n",
      "mi F1:  0.7627513844360245\n",
      "we F1:  0.76272949712507\n",
      "update!  Acc:  0.7627513844360245\n",
      "Eval Loss:  0.3420387804508209\n",
      "Eval Loss:  0.4588439166545868\n",
      "Eval Loss:  0.36414316296577454\n",
      "Eval Loss:  0.43178892135620117\n",
      "Eval Loss:  0.39820197224617004\n",
      "Eval Loss:  0.4152321219444275\n",
      "Eval Loss:  0.34229740500450134\n",
      "Eval Loss:  0.4522275924682617\n",
      "Eval Loss:  0.47894227504730225\n",
      "Eval Loss:  0.4403117597103119\n",
      "Eval Loss:  0.489633172750473\n",
      "Eval Loss:  0.3980010151863098\n",
      "Eval Loss:  0.4058592915534973\n",
      "Eval Loss:  0.523727536201477\n",
      "Eval Loss:  0.45861560106277466\n",
      "Eval Loss:  0.39693742990493774\n",
      "Eval Loss:  0.4228726029396057\n",
      "Eval Loss:  0.4073909819126129\n",
      "Eval Loss:  0.3898475766181946\n",
      "Eval Loss:  0.39212602376937866\n",
      "Eval Loss:  0.5313429236412048\n",
      "Eval Loss:  0.38732489943504333\n",
      "Eval Loss:  0.45527178049087524\n",
      "Eval Loss:  0.4799617826938629\n",
      "Eval Loss:  0.4206483066082001\n",
      "Eval Loss:  0.4508267343044281\n",
      "Eval Loss:  0.39785662293434143\n",
      "Eval Loss:  0.26083624362945557\n",
      "[[16431  2197]\n",
      " [ 2824  8008]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87     18628\n",
      "           1       0.78      0.74      0.76     10832\n",
      "\n",
      "    accuracy                           0.83     29460\n",
      "   macro avg       0.82      0.81      0.81     29460\n",
      "weighted avg       0.83      0.83      0.83     29460\n",
      "\n",
      "acc:  0.8295655125594026\n",
      "pre:  0.7847133757961784\n",
      "rec:  0.7392909896602659\n",
      "ma F1:  0.8143928112168781\n",
      "mi F1:  0.8295655125594026\n",
      "we F1:  0.8284360712983599\n",
      "29460 461\n",
      "Loss:  0.12925365567207336\n",
      "Loss:  0.10667864978313446\n",
      "Loss:  0.10455038398504257\n",
      "3 **********\n",
      "Epoch:  237.42716813087463  fold:  3  kers:  64\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.09598203003406525\n",
      "Loss:  0.13975350558757782\n",
      "Loss:  0.08025910705327988\n",
      "4 **********\n",
      "Epoch:  283.7323577404022  fold:  3  kers:  64\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.06283451616764069\n",
      "Loss:  0.07036365568637848\n",
      "Loss:  0.08109915256500244\n",
      "5 **********\n",
      "Epoch:  329.8680000305176  fold:  3  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  1.0151453018188477\n",
      "Eval Loss:  0.6959290504455566\n",
      "Eval Loss:  0.5627310276031494\n",
      "[[1408  128]\n",
      " [ 718 1177]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.92      0.77      1536\n",
      "           1       0.90      0.62      0.74      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.77      0.75      3431\n",
      "weighted avg       0.79      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7534246575342466\n",
      "pre:  0.9019157088122606\n",
      "rec:  0.6211081794195251\n",
      "ma F1:  0.7523018500819225\n",
      "mi F1:  0.7534246575342466\n",
      "we F1:  0.7505568809244144\n",
      "Eval Loss:  0.3112523555755615\n",
      "Eval Loss:  0.4637300968170166\n",
      "Eval Loss:  0.3903244733810425\n",
      "Eval Loss:  0.41478076577186584\n",
      "Eval Loss:  0.4033995568752289\n",
      "Eval Loss:  0.36721062660217285\n",
      "Eval Loss:  0.33597710728645325\n",
      "Eval Loss:  0.45737266540527344\n",
      "Eval Loss:  0.5285108089447021\n",
      "Eval Loss:  0.42279496788978577\n",
      "Eval Loss:  0.46335941553115845\n",
      "Eval Loss:  0.386069655418396\n",
      "Eval Loss:  0.428880512714386\n",
      "Eval Loss:  0.48277032375335693\n",
      "Eval Loss:  0.4586539566516876\n",
      "Eval Loss:  0.3923054337501526\n",
      "Eval Loss:  0.4194210171699524\n",
      "Eval Loss:  0.3834185302257538\n",
      "Eval Loss:  0.3773302435874939\n",
      "Eval Loss:  0.3671480119228363\n",
      "Eval Loss:  0.45369070768356323\n",
      "Eval Loss:  0.35272324085235596\n",
      "Eval Loss:  0.45635512471199036\n",
      "Eval Loss:  0.4684579372406006\n",
      "Eval Loss:  0.43676528334617615\n",
      "Eval Loss:  0.4400468170642853\n",
      "Eval Loss:  0.4498584270477295\n",
      "Eval Loss:  0.2346244603395462\n",
      "[[17737   891]\n",
      " [ 3592  7240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     18628\n",
      "           1       0.89      0.67      0.76     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.86      0.81      0.83     29460\n",
      "weighted avg       0.85      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8478275627970129\n",
      "pre:  0.890419382609765\n",
      "rec:  0.6683899556868538\n",
      "ma F1:  0.8256983241639089\n",
      "mi F1:  0.8478275627970129\n",
      "we F1:  0.8421334527133687\n",
      "29460 461\n",
      "Loss:  0.07129750400781631\n",
      "Loss:  0.07844896614551544\n",
      "Loss:  0.06761165708303452\n",
      "6 **********\n",
      "Epoch:  416.1502990722656  fold:  3  kers:  64\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.059466298669576645\n",
      "Loss:  0.06597763299942017\n",
      "Loss:  0.09622504562139511\n",
      "7 **********\n",
      "Epoch:  462.1882028579712  fold:  3  kers:  64\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.08536405861377716\n",
      "Loss:  0.06515993922948837\n",
      "Loss:  0.08376094698905945\n",
      "8 **********\n",
      "Epoch:  508.48541355133057  fold:  3  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.9006853699684143\n",
      "Eval Loss:  0.3839094042778015\n",
      "Eval Loss:  0.5735305547714233\n",
      "[[1364  172]\n",
      " [ 613 1282]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78      1536\n",
      "           1       0.88      0.68      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.78      0.77      3431\n",
      "weighted avg       0.80      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7712037306907608\n",
      "pre:  0.8817056396148556\n",
      "rec:  0.6765171503957783\n",
      "ma F1:  0.7710729681513113\n",
      "mi F1:  0.7712037306907608\n",
      "we F1:  0.7705004833749417\n",
      "update!  Acc:  0.7712037306907608\n",
      "Eval Loss:  0.2729112207889557\n",
      "Eval Loss:  0.4275411367416382\n",
      "Eval Loss:  0.36295366287231445\n",
      "Eval Loss:  0.36436334252357483\n",
      "Eval Loss:  0.34929654002189636\n",
      "Eval Loss:  0.3104226589202881\n",
      "Eval Loss:  0.30687329173088074\n",
      "Eval Loss:  0.39270609617233276\n",
      "Eval Loss:  0.4417020082473755\n",
      "Eval Loss:  0.33462318778038025\n",
      "Eval Loss:  0.39301615953445435\n",
      "Eval Loss:  0.33067163825035095\n",
      "Eval Loss:  0.35226768255233765\n",
      "Eval Loss:  0.3882737457752228\n",
      "Eval Loss:  0.37379348278045654\n",
      "Eval Loss:  0.32657843828201294\n",
      "Eval Loss:  0.37022554874420166\n",
      "Eval Loss:  0.3028450906276703\n",
      "Eval Loss:  0.32364973425865173\n",
      "Eval Loss:  0.31219232082366943\n",
      "Eval Loss:  0.3484368324279785\n",
      "Eval Loss:  0.31169962882995605\n",
      "Eval Loss:  0.40977928042411804\n",
      "Eval Loss:  0.38837072253227234\n",
      "Eval Loss:  0.3874197006225586\n",
      "Eval Loss:  0.39483803510665894\n",
      "Eval Loss:  0.3924536406993866\n",
      "Eval Loss:  0.21944032609462738\n",
      "[[17727   901]\n",
      " [ 3005  7827]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18628\n",
      "           1       0.90      0.72      0.80     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.84      0.85     29460\n",
      "weighted avg       0.87      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8674134419551934\n",
      "pre:  0.8967690192483959\n",
      "rec:  0.7225812407680945\n",
      "ma F1:  0.8505344717941044\n",
      "mi F1:  0.8674134419551934\n",
      "we F1:  0.8638262345593417\n",
      "29460 461\n",
      "Loss:  0.08382479101419449\n",
      "Loss:  0.09985026717185974\n",
      "Loss:  0.0790141373872757\n",
      "9 **********\n",
      "Epoch:  594.5512912273407  fold:  3  kers:  64\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.10014212876558304\n",
      "Loss:  0.07326248288154602\n",
      "Loss:  0.07304925471544266\n",
      "10 **********\n",
      "Epoch:  640.7557497024536  fold:  3  kers:  64\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08451235294342041\n",
      "Loss:  0.09965884685516357\n",
      "Loss:  0.07006005942821503\n",
      "11 **********\n",
      "Epoch:  686.8993713855743  fold:  3  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  1.0912144184112549\n",
      "Eval Loss:  0.3911237120628357\n",
      "Eval Loss:  0.7841521501541138\n",
      "[[1409  127]\n",
      " [ 796 1099]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.92      0.75      1536\n",
      "           1       0.90      0.58      0.70      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.77      0.75      0.73      3431\n",
      "weighted avg       0.78      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7309822209268435\n",
      "pre:  0.8964110929853181\n",
      "rec:  0.5799472295514512\n",
      "ma F1:  0.7287679900949504\n",
      "mi F1:  0.7309822209268436\n",
      "we F1:  0.7262037679380164\n",
      "Eval Loss:  0.31507185101509094\n",
      "Eval Loss:  0.48703449964523315\n",
      "Eval Loss:  0.42281630635261536\n",
      "Eval Loss:  0.43633779883384705\n",
      "Eval Loss:  0.41602054238319397\n",
      "Eval Loss:  0.3519074618816376\n",
      "Eval Loss:  0.3553663194179535\n",
      "Eval Loss:  0.43038904666900635\n",
      "Eval Loss:  0.5694586038589478\n",
      "Eval Loss:  0.4467288553714752\n",
      "Eval Loss:  0.46326687932014465\n",
      "Eval Loss:  0.41618624329566956\n",
      "Eval Loss:  0.4211696982383728\n",
      "Eval Loss:  0.4519367218017578\n",
      "Eval Loss:  0.4817768335342407\n",
      "Eval Loss:  0.4151897430419922\n",
      "Eval Loss:  0.4683554768562317\n",
      "Eval Loss:  0.41342708468437195\n",
      "Eval Loss:  0.38761579990386963\n",
      "Eval Loss:  0.37698978185653687\n",
      "Eval Loss:  0.4822326898574829\n",
      "Eval Loss:  0.3645341992378235\n",
      "Eval Loss:  0.526405394077301\n",
      "Eval Loss:  0.46698758006095886\n",
      "Eval Loss:  0.48159870505332947\n",
      "Eval Loss:  0.4639933705329895\n",
      "Eval Loss:  0.47199487686157227\n",
      "Eval Loss:  0.25749799609184265\n",
      "[[18236   392]\n",
      " [ 4156  6676]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     18628\n",
      "           1       0.94      0.62      0.75     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.88      0.80      0.82     29460\n",
      "weighted avg       0.86      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8456211812627291\n",
      "pre:  0.944538766270515\n",
      "rec:  0.6163220088626292\n",
      "ma F1:  0.8175245213535297\n",
      "mi F1:  0.8456211812627291\n",
      "we F1:  0.8364727532438514\n",
      "29460 461\n",
      "Loss:  0.04698172211647034\n",
      "Loss:  0.06770942360162735\n",
      "Loss:  0.07019635289907455\n",
      "12 **********\n",
      "Epoch:  773.212587594986  fold:  3  kers:  64\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.06483405828475952\n",
      "Loss:  0.06001773104071617\n",
      "Loss:  0.06689474731683731\n",
      "13 **********\n",
      "Epoch:  819.2644536495209  fold:  3  kers:  64\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.0768394023180008\n",
      "Loss:  0.06399456411600113\n",
      "Loss:  0.06202925369143486\n",
      "14 **********\n",
      "Epoch:  865.315322637558  fold:  3  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.7883385419845581\n",
      "Eval Loss:  0.21308165788650513\n",
      "Eval Loss:  0.6913294792175293\n",
      "[[1314  222]\n",
      " [ 597 1298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.76      1536\n",
      "           1       0.85      0.68      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7612940833576217\n",
      "pre:  0.8539473684210527\n",
      "rec:  0.6849604221635884\n",
      "ma F1:  0.7612888921170233\n",
      "mi F1:  0.7612940833576217\n",
      "we F1:  0.7611724136560964\n",
      "Eval Loss:  0.23745092749595642\n",
      "Eval Loss:  0.33983948826789856\n",
      "Eval Loss:  0.3266347050666809\n",
      "Eval Loss:  0.31882792711257935\n",
      "Eval Loss:  0.29425716400146484\n",
      "Eval Loss:  0.2596645653247833\n",
      "Eval Loss:  0.278148889541626\n",
      "Eval Loss:  0.3031768202781677\n",
      "Eval Loss:  0.4132641851902008\n",
      "Eval Loss:  0.2954848110675812\n",
      "Eval Loss:  0.34072649478912354\n",
      "Eval Loss:  0.2784310281276703\n",
      "Eval Loss:  0.31468552350997925\n",
      "Eval Loss:  0.3114200234413147\n",
      "Eval Loss:  0.2864030599594116\n",
      "Eval Loss:  0.3041541278362274\n",
      "Eval Loss:  0.3743848502635956\n",
      "Eval Loss:  0.2866904139518738\n",
      "Eval Loss:  0.2841036915779114\n",
      "Eval Loss:  0.28158891201019287\n",
      "Eval Loss:  0.33469337224960327\n",
      "Eval Loss:  0.30578145384788513\n",
      "Eval Loss:  0.38885506987571716\n",
      "Eval Loss:  0.32723426818847656\n",
      "Eval Loss:  0.3342934548854828\n",
      "Eval Loss:  0.36428794264793396\n",
      "Eval Loss:  0.33871203660964966\n",
      "Eval Loss:  0.18626154959201813\n",
      "[[17842   786]\n",
      " [ 2649  8183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     18628\n",
      "           1       0.91      0.76      0.83     10832\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.86      0.87     29460\n",
      "weighted avg       0.89      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8834012219959266\n",
      "pre:  0.9123648121306723\n",
      "rec:  0.7554468242245199\n",
      "ma F1:  0.8693574599306351\n",
      "mi F1:  0.8834012219959266\n",
      "we F1:  0.8806925017632277\n",
      "29460 461\n",
      "Loss:  0.09773771464824677\n",
      "Loss:  0.08074832707643509\n",
      "Loss:  0.068745456635952\n",
      "15 **********\n",
      "Epoch:  951.270495891571  fold:  3  kers:  64\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.07113853842020035\n",
      "Loss:  0.0407852940261364\n",
      "Loss:  0.06728799641132355\n",
      "16 **********\n",
      "Epoch:  997.4520161151886  fold:  3  kers:  64\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.08892247080802917\n",
      "Loss:  0.08730940520763397\n",
      "Loss:  0.06750621646642685\n",
      "17 **********\n",
      "Epoch:  1044.863248348236  fold:  3  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.8148475885391235\n",
      "Eval Loss:  0.19909067451953888\n",
      "Eval Loss:  0.8371840119361877\n",
      "[[1323  213]\n",
      " [ 639 1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.76      1536\n",
      "           1       0.86      0.66      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.77      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7516758962401632\n",
      "pre:  0.85500340367597\n",
      "rec:  0.6627968337730871\n",
      "ma F1:  0.7515811651162648\n",
      "mi F1:  0.7516758962401633\n",
      "we F1:  0.751073575959854\n",
      "Eval Loss:  0.22503015398979187\n",
      "Eval Loss:  0.3446916937828064\n",
      "Eval Loss:  0.3356093168258667\n",
      "Eval Loss:  0.3122236132621765\n",
      "Eval Loss:  0.2841437757015228\n",
      "Eval Loss:  0.2622077167034149\n",
      "Eval Loss:  0.2809450626373291\n",
      "Eval Loss:  0.2848255932331085\n",
      "Eval Loss:  0.4044867753982544\n",
      "Eval Loss:  0.28421977162361145\n",
      "Eval Loss:  0.33296823501586914\n",
      "Eval Loss:  0.29439759254455566\n",
      "Eval Loss:  0.28492236137390137\n",
      "Eval Loss:  0.3161068856716156\n",
      "Eval Loss:  0.26547813415527344\n",
      "Eval Loss:  0.28244149684906006\n",
      "Eval Loss:  0.3678601086139679\n",
      "Eval Loss:  0.25799858570098877\n",
      "Eval Loss:  0.2715380787849426\n",
      "Eval Loss:  0.27796196937561035\n",
      "Eval Loss:  0.3612605035305023\n",
      "Eval Loss:  0.2967565655708313\n",
      "Eval Loss:  0.39603790640830994\n",
      "Eval Loss:  0.3104340732097626\n",
      "Eval Loss:  0.33306679129600525\n",
      "Eval Loss:  0.36037635803222656\n",
      "Eval Loss:  0.3247075378894806\n",
      "Eval Loss:  0.18344807624816895\n",
      "[[17936   692]\n",
      " [ 2674  8158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     18628\n",
      "           1       0.92      0.75      0.83     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.86      0.87     29460\n",
      "weighted avg       0.89      0.89      0.88     29460\n",
      "\n",
      "acc:  0.8857433808553972\n",
      "pre:  0.9218079096045197\n",
      "rec:  0.753138847858198\n",
      "ma F1:  0.8715983029190584\n",
      "mi F1:  0.8857433808553972\n",
      "we F1:  0.8828761744256749\n",
      "29460 461\n",
      "Loss:  0.06376145780086517\n",
      "Loss:  0.09888351708650589\n",
      "Loss:  0.06801781058311462\n",
      "18 **********\n",
      "Epoch:  1130.8553230762482  fold:  3  kers:  64\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.04239020496606827\n",
      "Loss:  0.07121194899082184\n",
      "Loss:  0.05870414897799492\n",
      "19 **********\n",
      "Epoch:  1176.8553280830383  fold:  3  kers:  64\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.08109446614980698\n",
      "Loss:  0.04376132786273956\n",
      "Loss:  0.07207610458135605\n",
      "20 **********\n",
      "Epoch:  1222.9032053947449  fold:  3  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.7062113881111145\n",
      "Eval Loss:  0.14154773950576782\n",
      "Eval Loss:  0.6320710182189941\n",
      "[[1287  249]\n",
      " [ 546 1349]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1536\n",
      "           1       0.84      0.71      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7682891285339551\n",
      "pre:  0.844180225281602\n",
      "rec:  0.7118733509234828\n",
      "ma F1:  0.7682134399826239\n",
      "mi F1:  0.7682891285339551\n",
      "we F1:  0.7686517011104931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18357916176319122\n",
      "Eval Loss:  0.27643951773643494\n",
      "Eval Loss:  0.3072718381881714\n",
      "Eval Loss:  0.25392815470695496\n",
      "Eval Loss:  0.2641800343990326\n",
      "Eval Loss:  0.22845596075057983\n",
      "Eval Loss:  0.24156717956066132\n",
      "Eval Loss:  0.22208601236343384\n",
      "Eval Loss:  0.32806581258773804\n",
      "Eval Loss:  0.21234102547168732\n",
      "Eval Loss:  0.27368584275245667\n",
      "Eval Loss:  0.22590021789073944\n",
      "Eval Loss:  0.2567719519138336\n",
      "Eval Loss:  0.26099199056625366\n",
      "Eval Loss:  0.23236966133117676\n",
      "Eval Loss:  0.24486403167247772\n",
      "Eval Loss:  0.30074164271354675\n",
      "Eval Loss:  0.19979941844940186\n",
      "Eval Loss:  0.24160273373126984\n",
      "Eval Loss:  0.24425771832466125\n",
      "Eval Loss:  0.30847251415252686\n",
      "Eval Loss:  0.25921717286109924\n",
      "Eval Loss:  0.34524473547935486\n",
      "Eval Loss:  0.25063982605934143\n",
      "Eval Loss:  0.3139837682247162\n",
      "Eval Loss:  0.3132350444793701\n",
      "Eval Loss:  0.27707362174987793\n",
      "Eval Loss:  0.16886253654956818\n",
      "[[17708   920]\n",
      " [ 1988  8844]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18628\n",
      "           1       0.91      0.82      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9012898845892736\n",
      "pre:  0.9057763211798443\n",
      "rec:  0.8164697193500738\n",
      "ma F1:  0.8914640954538573\n",
      "mi F1:  0.9012898845892736\n",
      "we F1:  0.9001060011510263\n",
      "29460 461\n",
      "Loss:  0.060913361608982086\n",
      "Loss:  0.05856079235672951\n",
      "Loss:  0.05466361716389656\n",
      "21 **********\n",
      "Epoch:  1308.964096069336  fold:  3  kers:  64\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.043677520006895065\n",
      "Loss:  0.04000471159815788\n",
      "Loss:  0.09553846716880798\n",
      "22 **********\n",
      "Epoch:  1355.2652962207794  fold:  3  kers:  64\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.04479450732469559\n",
      "Loss:  0.08830196410417557\n",
      "Loss:  0.04459565877914429\n",
      "23 **********\n",
      "Epoch:  1401.5774672031403  fold:  3  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.5164862871170044\n",
      "Eval Loss:  0.1418977975845337\n",
      "Eval Loss:  0.7731749415397644\n",
      "[[1248  288]\n",
      " [ 480 1415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76      1536\n",
      "           1       0.83      0.75      0.79      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.78      0.78      3431\n",
      "weighted avg       0.78      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7761585543573303\n",
      "pre:  0.830886670581327\n",
      "rec:  0.7467018469656992\n",
      "ma F1:  0.7756269823104338\n",
      "mi F1:  0.7761585543573302\n",
      "we F1:  0.7767697030579536\n",
      "update!  Acc:  0.7761585543573303\n",
      "Eval Loss:  0.21027906239032745\n",
      "Eval Loss:  0.2507452070713043\n",
      "Eval Loss:  0.28701674938201904\n",
      "Eval Loss:  0.23807595670223236\n",
      "Eval Loss:  0.25433456897735596\n",
      "Eval Loss:  0.21387101709842682\n",
      "Eval Loss:  0.23633693158626556\n",
      "Eval Loss:  0.21257758140563965\n",
      "Eval Loss:  0.2994844317436218\n",
      "Eval Loss:  0.22171103954315186\n",
      "Eval Loss:  0.24674634635448456\n",
      "Eval Loss:  0.2066316455602646\n",
      "Eval Loss:  0.2420441210269928\n",
      "Eval Loss:  0.23055285215377808\n",
      "Eval Loss:  0.185727059841156\n",
      "Eval Loss:  0.2627458870410919\n",
      "Eval Loss:  0.29593849182128906\n",
      "Eval Loss:  0.22160324454307556\n",
      "Eval Loss:  0.21132540702819824\n",
      "Eval Loss:  0.23641912639141083\n",
      "Eval Loss:  0.2861819267272949\n",
      "Eval Loss:  0.26845765113830566\n",
      "Eval Loss:  0.3330847918987274\n",
      "Eval Loss:  0.23273266851902008\n",
      "Eval Loss:  0.31870290637016296\n",
      "Eval Loss:  0.3087380826473236\n",
      "Eval Loss:  0.2590946853160858\n",
      "Eval Loss:  0.15402036905288696\n",
      "[[17415  1213]\n",
      " [ 1560  9272]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18628\n",
      "           1       0.88      0.86      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9058723693143245\n",
      "pre:  0.8843109203624225\n",
      "rec:  0.8559822747415067\n",
      "ma F1:  0.8980859566495554\n",
      "mi F1:  0.9058723693143245\n",
      "we F1:  0.9055405646729545\n",
      "29460 461\n",
      "Loss:  0.08065342903137207\n",
      "Loss:  0.03833392634987831\n",
      "Loss:  0.06935079395771027\n",
      "24 **********\n",
      "Epoch:  1487.8557767868042  fold:  3  kers:  64\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.044277653098106384\n",
      "Loss:  0.0742509737610817\n",
      "Loss:  0.030780812725424767\n",
      "25 **********\n",
      "Epoch:  1534.065221786499  fold:  3  kers:  64\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.09286172688007355\n",
      "Loss:  0.08000656217336655\n",
      "Loss:  0.040989458560943604\n",
      "26 **********\n",
      "Epoch:  1580.493083000183  fold:  3  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.4692419767379761\n",
      "Eval Loss:  0.15270380675792694\n",
      "Eval Loss:  0.9587069749832153\n",
      "[[1272  264]\n",
      " [ 592 1303]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.83      0.75      1536\n",
      "           1       0.83      0.69      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.750510055377441\n",
      "pre:  0.8315252074026803\n",
      "rec:  0.687598944591029\n",
      "ma F1:  0.7504896863424746\n",
      "mi F1:  0.750510055377441\n",
      "we F1:  0.7507255729086981\n",
      "Eval Loss:  0.18980897963047028\n",
      "Eval Loss:  0.26800379157066345\n",
      "Eval Loss:  0.27059727907180786\n",
      "Eval Loss:  0.24993495643138885\n",
      "Eval Loss:  0.27404385805130005\n",
      "Eval Loss:  0.20657771825790405\n",
      "Eval Loss:  0.24670755863189697\n",
      "Eval Loss:  0.19836033880710602\n",
      "Eval Loss:  0.3188894987106323\n",
      "Eval Loss:  0.23360741138458252\n",
      "Eval Loss:  0.2656584084033966\n",
      "Eval Loss:  0.2224169224500656\n",
      "Eval Loss:  0.22641174495220184\n",
      "Eval Loss:  0.239190474152565\n",
      "Eval Loss:  0.2317982316017151\n",
      "Eval Loss:  0.26396644115448\n",
      "Eval Loss:  0.30441322922706604\n",
      "Eval Loss:  0.24589474499225616\n",
      "Eval Loss:  0.22375935316085815\n",
      "Eval Loss:  0.24319449067115784\n",
      "Eval Loss:  0.31521981954574585\n",
      "Eval Loss:  0.24760834872722626\n",
      "Eval Loss:  0.3417193591594696\n",
      "Eval Loss:  0.25473785400390625\n",
      "Eval Loss:  0.29901808500289917\n",
      "Eval Loss:  0.3191041946411133\n",
      "Eval Loss:  0.2669638693332672\n",
      "Eval Loss:  0.14504125714302063\n",
      "[[17869   759]\n",
      " [ 1989  8843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18628\n",
      "           1       0.92      0.82      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9067209775967413\n",
      "pre:  0.9209539679233493\n",
      "rec:  0.8163774002954209\n",
      "ma F1:  0.8970578329682566\n",
      "mi F1:  0.9067209775967413\n",
      "we F1:  0.9054041519937016\n",
      "29460 461\n",
      "Loss:  0.058440614491701126\n",
      "Loss:  0.04311387613415718\n",
      "Loss:  0.057011883705854416\n",
      "27 **********\n",
      "Epoch:  1666.6846241950989  fold:  3  kers:  64\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.059508778154850006\n",
      "Loss:  0.09397970885038376\n",
      "Loss:  0.05155213922262192\n",
      "28 **********\n",
      "Epoch:  1713.0705969333649  fold:  3  kers:  64\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.05855987221002579\n",
      "Loss:  0.04692722111940384\n",
      "Loss:  0.05075443908572197\n",
      "29 **********\n",
      "Epoch:  1759.1992588043213  fold:  3  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.30744028091430664\n",
      "Eval Loss:  0.12809604406356812\n",
      "Eval Loss:  0.9827117323875427\n",
      "[[1195  341]\n",
      " [ 429 1466]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      1536\n",
      "           1       0.81      0.77      0.79      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.77      0.78      0.77      3431\n",
      "weighted avg       0.78      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7755756339259691\n",
      "pre:  0.811289429994466\n",
      "rec:  0.7736147757255937\n",
      "ma F1:  0.7741667179560826\n",
      "mi F1:  0.7755756339259691\n",
      "we F1:  0.7760331416947884\n",
      "Eval Loss:  0.21983179450035095\n",
      "Eval Loss:  0.24092739820480347\n",
      "Eval Loss:  0.2534174621105194\n",
      "Eval Loss:  0.23357421159744263\n",
      "Eval Loss:  0.2571558654308319\n",
      "Eval Loss:  0.23647978901863098\n",
      "Eval Loss:  0.244749054312706\n",
      "Eval Loss:  0.20533649623394012\n",
      "Eval Loss:  0.27373772859573364\n",
      "Eval Loss:  0.1970222294330597\n",
      "Eval Loss:  0.2643398642539978\n",
      "Eval Loss:  0.19995251297950745\n",
      "Eval Loss:  0.23588912189006805\n",
      "Eval Loss:  0.21832393109798431\n",
      "Eval Loss:  0.1938190907239914\n",
      "Eval Loss:  0.26071956753730774\n",
      "Eval Loss:  0.3048340380191803\n",
      "Eval Loss:  0.2386285364627838\n",
      "Eval Loss:  0.18882937729358673\n",
      "Eval Loss:  0.23881542682647705\n",
      "Eval Loss:  0.2820291519165039\n",
      "Eval Loss:  0.26328641176223755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.31196433305740356\n",
      "Eval Loss:  0.22937056422233582\n",
      "Eval Loss:  0.3012295663356781\n",
      "Eval Loss:  0.31398022174835205\n",
      "Eval Loss:  0.21768556535243988\n",
      "Eval Loss:  0.13306845724582672\n",
      "[[17200  1428]\n",
      " [ 1238  9594]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     18628\n",
      "           1       0.87      0.89      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9095044127630686\n",
      "pre:  0.8704409363091998\n",
      "rec:  0.8857090103397341\n",
      "ma F1:  0.903041424241916\n",
      "mi F1:  0.9095044127630686\n",
      "we F1:  0.9096658600177386\n",
      "29460 461\n",
      "Loss:  0.04899701476097107\n",
      "Loss:  0.09114792943000793\n",
      "Loss:  0.06890004873275757\n",
      "30 **********\n",
      "Epoch:  1845.6850135326385  fold:  3  kers:  64\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.03967028856277466\n",
      "Loss:  0.06674664467573166\n",
      "Loss:  0.07796847075223923\n",
      "31 **********\n",
      "Epoch:  1892.0759737491608  fold:  3  kers:  64\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.05379272624850273\n",
      "Loss:  0.042086996138095856\n",
      "Loss:  0.1088126003742218\n",
      "32 **********\n",
      "Epoch:  1938.4210557937622  fold:  3  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.4675581157207489\n",
      "Eval Loss:  0.15506020188331604\n",
      "Eval Loss:  1.054087519645691\n",
      "[[1278  258]\n",
      " [ 564 1331]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.76      1536\n",
      "           1       0.84      0.70      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.76041970271058\n",
      "pre:  0.8376337319068596\n",
      "rec:  0.7023746701846966\n",
      "ma F1:  0.7603625199592963\n",
      "mi F1:  0.76041970271058\n",
      "we F1:  0.7607498521802558\n",
      "Eval Loss:  0.1801675409078598\n",
      "Eval Loss:  0.2609183192253113\n",
      "Eval Loss:  0.2560589611530304\n",
      "Eval Loss:  0.21399827301502228\n",
      "Eval Loss:  0.2472827434539795\n",
      "Eval Loss:  0.19692926108837128\n",
      "Eval Loss:  0.22247545421123505\n",
      "Eval Loss:  0.17640794813632965\n",
      "Eval Loss:  0.2980026304721832\n",
      "Eval Loss:  0.2288987636566162\n",
      "Eval Loss:  0.24618864059448242\n",
      "Eval Loss:  0.20574603974819183\n",
      "Eval Loss:  0.23499652743339539\n",
      "Eval Loss:  0.20929783582687378\n",
      "Eval Loss:  0.220117449760437\n",
      "Eval Loss:  0.2563847303390503\n",
      "Eval Loss:  0.3212909400463104\n",
      "Eval Loss:  0.2296203374862671\n",
      "Eval Loss:  0.20775622129440308\n",
      "Eval Loss:  0.22904643416404724\n",
      "Eval Loss:  0.2854737639427185\n",
      "Eval Loss:  0.24835506081581116\n",
      "Eval Loss:  0.3100898563861847\n",
      "Eval Loss:  0.24288630485534668\n",
      "Eval Loss:  0.27867642045021057\n",
      "Eval Loss:  0.3102695941925049\n",
      "Eval Loss:  0.24828894436359406\n",
      "Eval Loss:  0.12703676521778107\n",
      "[[17806   822]\n",
      " [ 1811  9021]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18628\n",
      "           1       0.92      0.83      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9106245756958588\n",
      "pre:  0.9164888753428833\n",
      "rec:  0.8328101920236337\n",
      "ma F1:  0.9019012625118109\n",
      "mi F1:  0.9106245756958588\n",
      "we F1:  0.9096425202901646\n",
      "29460 461\n",
      "Loss:  0.0659257173538208\n",
      "Loss:  0.04855500906705856\n",
      "Loss:  0.05081406235694885\n",
      "33 **********\n",
      "Epoch:  2024.6405234336853  fold:  3  kers:  64\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.07308623939752579\n",
      "Loss:  0.06807789206504822\n",
      "Loss:  0.06639847904443741\n",
      "34 **********\n",
      "Epoch:  2070.8888640403748  fold:  3  kers:  64\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.060347143560647964\n",
      "Loss:  0.06939021497964859\n",
      "Loss:  0.07214220613241196\n",
      "35 **********\n",
      "Epoch:  2117.1142666339874  fold:  3  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.46242818236351013\n",
      "Eval Loss:  0.14365772902965546\n",
      "Eval Loss:  1.0588222742080688\n",
      "[[1311  225]\n",
      " [ 597 1298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1536\n",
      "           1       0.85      0.68      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.76041970271058\n",
      "pre:  0.8522652659225214\n",
      "rec:  0.6849604221635884\n",
      "ma F1:  0.7604162631528515\n",
      "mi F1:  0.76041970271058\n",
      "we F1:  0.7603212784432685\n",
      "Eval Loss:  0.18226569890975952\n",
      "Eval Loss:  0.2776598036289215\n",
      "Eval Loss:  0.26928281784057617\n",
      "Eval Loss:  0.22785860300064087\n",
      "Eval Loss:  0.25228291749954224\n",
      "Eval Loss:  0.22457143664360046\n",
      "Eval Loss:  0.25815051794052124\n",
      "Eval Loss:  0.16611114144325256\n",
      "Eval Loss:  0.34076592326164246\n",
      "Eval Loss:  0.2308257520198822\n",
      "Eval Loss:  0.22076798975467682\n",
      "Eval Loss:  0.22029490768909454\n",
      "Eval Loss:  0.2455577254295349\n",
      "Eval Loss:  0.21686092019081116\n",
      "Eval Loss:  0.22891733050346375\n",
      "Eval Loss:  0.25692713260650635\n",
      "Eval Loss:  0.3004365563392639\n",
      "Eval Loss:  0.22551773488521576\n",
      "Eval Loss:  0.23131394386291504\n",
      "Eval Loss:  0.21836353838443756\n",
      "Eval Loss:  0.32897576689720154\n",
      "Eval Loss:  0.23224683105945587\n",
      "Eval Loss:  0.317395955324173\n",
      "Eval Loss:  0.27196428179740906\n",
      "Eval Loss:  0.2940498888492584\n",
      "Eval Loss:  0.3232059180736542\n",
      "Eval Loss:  0.2662152349948883\n",
      "Eval Loss:  0.12757453322410583\n",
      "[[17840   788]\n",
      " [ 1851  8981]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18628\n",
      "           1       0.92      0.83      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9104209097080788\n",
      "pre:  0.9193366772443443\n",
      "rec:  0.8291174298375185\n",
      "ma F1:  0.9015150964970575\n",
      "mi F1:  0.9104209097080788\n",
      "we F1:  0.9093522925454967\n",
      "29460 461\n",
      "Loss:  0.1032969206571579\n",
      "Loss:  0.06084142625331879\n",
      "Loss:  0.04947911202907562\n",
      "36 **********\n",
      "Epoch:  2203.4603946208954  fold:  3  kers:  64\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.09400554746389389\n",
      "Loss:  0.04988444223999977\n",
      "Loss:  0.07886795699596405\n",
      "37 **********\n",
      "Epoch:  2249.7586023807526  fold:  3  kers:  64\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.04448128119111061\n",
      "Loss:  0.04937808960676193\n",
      "Loss:  0.06408889591693878\n",
      "38 **********\n",
      "Epoch:  2296.1854667663574  fold:  3  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.5194758176803589\n",
      "Eval Loss:  0.12264209240674973\n",
      "Eval Loss:  1.0918185710906982\n",
      "[[1245  291]\n",
      " [ 597 1298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74      1536\n",
      "           1       0.82      0.68      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.741183328475663\n",
      "pre:  0.81686595342983\n",
      "rec:  0.6849604221635884\n",
      "ma F1:  0.7411215544085828\n",
      "mi F1:  0.7411833284756629\n",
      "we F1:  0.7415399862969186\n",
      "Eval Loss:  0.16259664297103882\n",
      "Eval Loss:  0.2649562656879425\n",
      "Eval Loss:  0.26934394240379333\n",
      "Eval Loss:  0.23005172610282898\n",
      "Eval Loss:  0.26404082775115967\n",
      "Eval Loss:  0.18555982410907745\n",
      "Eval Loss:  0.23050902783870697\n",
      "Eval Loss:  0.1624899059534073\n",
      "Eval Loss:  0.3234524130821228\n",
      "Eval Loss:  0.2395295351743698\n",
      "Eval Loss:  0.25608527660369873\n",
      "Eval Loss:  0.22630666196346283\n",
      "Eval Loss:  0.2433205544948578\n",
      "Eval Loss:  0.23264116048812866\n",
      "Eval Loss:  0.21333494782447815\n",
      "Eval Loss:  0.248601496219635\n",
      "Eval Loss:  0.31495893001556396\n",
      "Eval Loss:  0.203759104013443\n",
      "Eval Loss:  0.17526935040950775\n",
      "Eval Loss:  0.23384259641170502\n",
      "Eval Loss:  0.27515411376953125\n",
      "Eval Loss:  0.23188729584217072\n",
      "Eval Loss:  0.3347429633140564\n",
      "Eval Loss:  0.22791428864002228\n",
      "Eval Loss:  0.2776504456996918\n",
      "Eval Loss:  0.30962127447128296\n",
      "Eval Loss:  0.2365371584892273\n",
      "Eval Loss:  0.11389602720737457\n",
      "[[17779   849]\n",
      " [ 1743  9089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.91      0.84      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9120162932790224\n",
      "pre:  0.9145703360837191\n",
      "rec:  0.8390878877400295\n",
      "ma F1:  0.9036311445772869\n",
      "mi F1:  0.9120162932790224\n",
      "we F1:  0.9111536554263928\n",
      "29460 461\n",
      "Loss:  0.06091869994997978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04720069095492363\n",
      "Loss:  0.060686830431222916\n",
      "39 **********\n",
      "Epoch:  2382.57049036026  fold:  3  kers:  64\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.06233273446559906\n",
      "Loss:  0.05796503275632858\n",
      "Loss:  0.03712897375226021\n",
      "40 **********\n",
      "Epoch:  2428.81982922554  fold:  3  kers:  64\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.056123096495866776\n",
      "Loss:  0.04591398686170578\n",
      "Loss:  0.03766292333602905\n",
      "41 **********\n",
      "Epoch:  2475.01331782341  fold:  3  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.30852246284484863\n",
      "Eval Loss:  0.0938921868801117\n",
      "Eval Loss:  0.8918675780296326\n",
      "[[1203  333]\n",
      " [ 440 1455]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.76      1536\n",
      "           1       0.81      0.77      0.79      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.78      0.77      3431\n",
      "weighted avg       0.78      0.77      0.78      3431\n",
      "\n",
      "acc:  0.7747012532789275\n",
      "pre:  0.8137583892617449\n",
      "rec:  0.7678100263852242\n",
      "ma F1:  0.7734792633950553\n",
      "mi F1:  0.7747012532789275\n",
      "we F1:  0.7752201140629525\n",
      "Eval Loss:  0.16986489295959473\n",
      "Eval Loss:  0.20075774192810059\n",
      "Eval Loss:  0.23153218626976013\n",
      "Eval Loss:  0.16620388627052307\n",
      "Eval Loss:  0.23565827310085297\n",
      "Eval Loss:  0.18142563104629517\n",
      "Eval Loss:  0.19891823828220367\n",
      "Eval Loss:  0.1272062361240387\n",
      "Eval Loss:  0.2520429790019989\n",
      "Eval Loss:  0.18754808604717255\n",
      "Eval Loss:  0.20415179431438446\n",
      "Eval Loss:  0.2039909064769745\n",
      "Eval Loss:  0.18408524990081787\n",
      "Eval Loss:  0.17290540039539337\n",
      "Eval Loss:  0.1884739100933075\n",
      "Eval Loss:  0.2422693520784378\n",
      "Eval Loss:  0.2696182131767273\n",
      "Eval Loss:  0.19563519954681396\n",
      "Eval Loss:  0.16751818358898163\n",
      "Eval Loss:  0.21264755725860596\n",
      "Eval Loss:  0.24852332472801208\n",
      "Eval Loss:  0.22176657617092133\n",
      "Eval Loss:  0.2928691506385803\n",
      "Eval Loss:  0.19717316329479218\n",
      "Eval Loss:  0.2726770043373108\n",
      "Eval Loss:  0.29499462246894836\n",
      "Eval Loss:  0.21993452310562134\n",
      "Eval Loss:  0.11702553927898407\n",
      "[[17415  1213]\n",
      " [ 1159  9673]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18628\n",
      "           1       0.89      0.89      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9194840461642906\n",
      "pre:  0.8885724784126401\n",
      "rec:  0.8930022156573116\n",
      "ma F1:  0.9135109135229489\n",
      "mi F1:  0.9194840461642906\n",
      "we F1:  0.9195257084172784\n",
      "29460 461\n",
      "Loss:  0.042420919984579086\n",
      "Loss:  0.04497213661670685\n",
      "Loss:  0.04632091894745827\n",
      "42 **********\n",
      "Epoch:  2561.2846455574036  fold:  3  kers:  64\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.05919492989778519\n",
      "Loss:  0.0677238181233406\n",
      "Loss:  0.05664097145199776\n",
      "43 **********\n",
      "Epoch:  2607.5150349140167  fold:  3  kers:  64\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.08001191169023514\n",
      "Loss:  0.023499861359596252\n",
      "Loss:  0.04231098294258118\n",
      "44 **********\n",
      "Epoch:  2653.633722782135  fold:  3  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.4133150577545166\n",
      "Eval Loss:  0.12603983283042908\n",
      "Eval Loss:  1.154434084892273\n",
      "[[1250  286]\n",
      " [ 555 1340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75      1536\n",
      "           1       0.82      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.77      0.75      0.76      3431\n",
      "\n",
      "acc:  0.7548819586126494\n",
      "pre:  0.8241082410824109\n",
      "rec:  0.7071240105540897\n",
      "ma F1:  0.7547131798510684\n",
      "mi F1:  0.7548819586126494\n",
      "we F1:  0.7553864195778189\n",
      "Eval Loss:  0.17072302103042603\n",
      "Eval Loss:  0.2607228755950928\n",
      "Eval Loss:  0.2553001046180725\n",
      "Eval Loss:  0.20323628187179565\n",
      "Eval Loss:  0.24506691098213196\n",
      "Eval Loss:  0.16320689022541046\n",
      "Eval Loss:  0.24073204398155212\n",
      "Eval Loss:  0.15381310880184174\n",
      "Eval Loss:  0.2971448302268982\n",
      "Eval Loss:  0.23497503995895386\n",
      "Eval Loss:  0.22610785067081451\n",
      "Eval Loss:  0.22459983825683594\n",
      "Eval Loss:  0.19490793347358704\n",
      "Eval Loss:  0.2036256343126297\n",
      "Eval Loss:  0.2159377783536911\n",
      "Eval Loss:  0.26621466875076294\n",
      "Eval Loss:  0.31451910734176636\n",
      "Eval Loss:  0.2122388631105423\n",
      "Eval Loss:  0.20158874988555908\n",
      "Eval Loss:  0.2340760976076126\n",
      "Eval Loss:  0.24423716962337494\n",
      "Eval Loss:  0.2294720709323883\n",
      "Eval Loss:  0.3124794363975525\n",
      "Eval Loss:  0.2245265394449234\n",
      "Eval Loss:  0.280135840177536\n",
      "Eval Loss:  0.3165777623653412\n",
      "Eval Loss:  0.24807243049144745\n",
      "Eval Loss:  0.08749610930681229\n",
      "[[17796   832]\n",
      " [ 1654  9178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18628\n",
      "           1       0.92      0.85      0.88     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.90      0.91     29460\n",
      "weighted avg       0.92      0.92      0.91     29460\n",
      "\n",
      "acc:  0.9156143923964698\n",
      "pre:  0.9168831168831169\n",
      "rec:  0.8473042836041359\n",
      "ma F1:  0.9077172887097403\n",
      "mi F1:  0.9156143923964698\n",
      "we F1:  0.9148611527549646\n",
      "29460 461\n",
      "Loss:  0.07744003087282181\n",
      "Loss:  0.06317505985498428\n",
      "Loss:  0.0798865556716919\n",
      "45 **********\n",
      "Epoch:  2739.9808478355408  fold:  3  kers:  64\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.03841998800635338\n",
      "Loss:  0.06930200010538101\n",
      "Loss:  0.06267571449279785\n",
      "46 **********\n",
      "Epoch:  2786.1005334854126  fold:  3  kers:  64\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.05007989704608917\n",
      "Loss:  0.06035877764225006\n",
      "Loss:  0.0446881465613842\n",
      "47 **********\n",
      "Epoch:  2832.1593816280365  fold:  3  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.3589935600757599\n",
      "Eval Loss:  0.11831427365541458\n",
      "Eval Loss:  0.9973398447036743\n",
      "[[1227  309]\n",
      " [ 497 1398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75      1536\n",
      "           1       0.82      0.74      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7650830661614689\n",
      "pre:  0.8189806678383128\n",
      "rec:  0.7377308707124011\n",
      "ma F1:  0.7644980804801695\n",
      "mi F1:  0.7650830661614688\n",
      "we F1:  0.7657262083140087\n",
      "Eval Loss:  0.17259308695793152\n",
      "Eval Loss:  0.2201249748468399\n",
      "Eval Loss:  0.2412635087966919\n",
      "Eval Loss:  0.16494907438755035\n",
      "Eval Loss:  0.22638095915317535\n",
      "Eval Loss:  0.17543543875217438\n",
      "Eval Loss:  0.19585105776786804\n",
      "Eval Loss:  0.146890327334404\n",
      "Eval Loss:  0.27176380157470703\n",
      "Eval Loss:  0.17800602316856384\n",
      "Eval Loss:  0.20056866109371185\n",
      "Eval Loss:  0.19770577549934387\n",
      "Eval Loss:  0.17995719611644745\n",
      "Eval Loss:  0.17852972447872162\n",
      "Eval Loss:  0.17614376544952393\n",
      "Eval Loss:  0.21052846312522888\n",
      "Eval Loss:  0.2600178122520447\n",
      "Eval Loss:  0.19743913412094116\n",
      "Eval Loss:  0.16236267983913422\n",
      "Eval Loss:  0.20537877082824707\n",
      "Eval Loss:  0.23421616852283478\n",
      "Eval Loss:  0.21100707352161407\n",
      "Eval Loss:  0.26477089524269104\n",
      "Eval Loss:  0.17422430217266083\n",
      "Eval Loss:  0.25195643305778503\n",
      "Eval Loss:  0.28887316584587097\n",
      "Eval Loss:  0.20877988636493683\n",
      "Eval Loss:  0.0948677510023117\n",
      "[[17643   985]\n",
      " [ 1277  9555]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.91      0.88      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9232179226069246\n",
      "pre:  0.9065464895635673\n",
      "rec:  0.8821085672082718\n",
      "ma F1:  0.9169588474198282\n",
      "mi F1:  0.9232179226069246\n",
      "we F1:  0.9229919520388445\n",
      "29460 461\n",
      "Loss:  0.053758472204208374\n",
      "Loss:  0.05371353030204773\n",
      "Loss:  0.03056301921606064\n",
      "48 **********\n",
      "Epoch:  2918.3559098243713  fold:  3  kers:  64\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.04636729508638382\n",
      "Loss:  0.06139981746673584\n",
      "Loss:  0.0905887708067894\n",
      "49 **********\n",
      "Epoch:  2964.4795842170715  fold:  3  kers:  64\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.06280581653118134\n",
      "Loss:  0.05386941134929657\n",
      "Loss:  0.0770600289106369\n",
      "50 **********\n",
      "Epoch:  3010.6830456256866  fold:  3  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.25114086270332336\n",
      "Eval Loss:  0.09022600948810577\n",
      "Eval Loss:  1.1497604846954346\n",
      "[[1180  356]\n",
      " [ 469 1426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74      1536\n",
      "           1       0.80      0.75      0.78      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7595453220635383\n",
      "pre:  0.8002244668911336\n",
      "rec:  0.7525065963060686\n",
      "ma F1:  0.7583028106746977\n",
      "mi F1:  0.7595453220635383\n",
      "we F1:  0.7601160691649165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19017158448696136\n",
      "Eval Loss:  0.21559514105319977\n",
      "Eval Loss:  0.234521746635437\n",
      "Eval Loss:  0.16200250387191772\n",
      "Eval Loss:  0.23508119583129883\n",
      "Eval Loss:  0.1939825415611267\n",
      "Eval Loss:  0.19016586244106293\n",
      "Eval Loss:  0.1509253978729248\n",
      "Eval Loss:  0.22691847383975983\n",
      "Eval Loss:  0.18425406515598297\n",
      "Eval Loss:  0.18652060627937317\n",
      "Eval Loss:  0.2028922289609909\n",
      "Eval Loss:  0.19220417737960815\n",
      "Eval Loss:  0.1687590330839157\n",
      "Eval Loss:  0.1641765832901001\n",
      "Eval Loss:  0.22398430109024048\n",
      "Eval Loss:  0.28994500637054443\n",
      "Eval Loss:  0.22387045621871948\n",
      "Eval Loss:  0.13828755915164948\n",
      "Eval Loss:  0.19513976573944092\n",
      "Eval Loss:  0.23704802989959717\n",
      "Eval Loss:  0.25698980689048767\n",
      "Eval Loss:  0.2714070975780487\n",
      "Eval Loss:  0.18339787423610687\n",
      "Eval Loss:  0.2604648768901825\n",
      "Eval Loss:  0.2892758846282959\n",
      "Eval Loss:  0.19177761673927307\n",
      "Eval Loss:  0.1142486184835434\n",
      "[[17234  1394]\n",
      " [  961  9871]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18628\n",
      "           1       0.88      0.91      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.92      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.920061099796334\n",
      "pre:  0.8762538837106081\n",
      "rec:  0.911281388478582\n",
      "ma F1:  0.9147349265805425\n",
      "mi F1:  0.920061099796334\n",
      "we F1:  0.9203743190007939\n",
      "29460 461\n",
      "Loss:  0.044367458671331406\n",
      "Loss:  0.08032426983118057\n",
      "Loss:  0.0827956572175026\n",
      "51 **********\n",
      "Epoch:  3096.638218641281  fold:  3  kers:  64\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.05704718083143234\n",
      "Loss:  0.0729493796825409\n",
      "Loss:  0.051754485815763474\n",
      "52 **********\n",
      "Epoch:  3142.744938850403  fold:  3  kers:  64\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.04482954740524292\n",
      "Loss:  0.07360662519931793\n",
      "Loss:  0.022706981748342514\n",
      "53 **********\n",
      "Epoch:  3188.7329761981964  fold:  3  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.35113510489463806\n",
      "Eval Loss:  0.07452619075775146\n",
      "Eval Loss:  1.123839020729065\n",
      "[[1187  349]\n",
      " [ 470 1425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74      1536\n",
      "           1       0.80      0.75      0.78      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7612940833576217\n",
      "pre:  0.8032694475760992\n",
      "rec:  0.7519788918205804\n",
      "ma F1:  0.7601399115348144\n",
      "mi F1:  0.7612940833576217\n",
      "we F1:  0.761880868191906\n",
      "Eval Loss:  0.22014972567558289\n",
      "Eval Loss:  0.20279495418071747\n",
      "Eval Loss:  0.2518689036369324\n",
      "Eval Loss:  0.1799456775188446\n",
      "Eval Loss:  0.22650505602359772\n",
      "Eval Loss:  0.18935327231884003\n",
      "Eval Loss:  0.17728929221630096\n",
      "Eval Loss:  0.17541873455047607\n",
      "Eval Loss:  0.24517056345939636\n",
      "Eval Loss:  0.17326053977012634\n",
      "Eval Loss:  0.18386393785476685\n",
      "Eval Loss:  0.19797654449939728\n",
      "Eval Loss:  0.18189415335655212\n",
      "Eval Loss:  0.18351753056049347\n",
      "Eval Loss:  0.16095814108848572\n",
      "Eval Loss:  0.20139728486537933\n",
      "Eval Loss:  0.25377508997917175\n",
      "Eval Loss:  0.20661640167236328\n",
      "Eval Loss:  0.14416608214378357\n",
      "Eval Loss:  0.19783812761306763\n",
      "Eval Loss:  0.1975918412208557\n",
      "Eval Loss:  0.23288941383361816\n",
      "Eval Loss:  0.25990763306617737\n",
      "Eval Loss:  0.17544391751289368\n",
      "Eval Loss:  0.25359901785850525\n",
      "Eval Loss:  0.31031227111816406\n",
      "Eval Loss:  0.18576757609844208\n",
      "Eval Loss:  0.10744064301252365\n",
      "[[17245  1383]\n",
      " [  946  9886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18628\n",
      "           1       0.88      0.91      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9209436524100475\n",
      "pre:  0.8772739373502529\n",
      "rec:  0.9126661742983752\n",
      "ma F1:  0.9156823842430047\n",
      "mi F1:  0.9209436524100475\n",
      "we F1:  0.9212560826572275\n",
      "29460 461\n",
      "Loss:  0.05147945135831833\n",
      "Loss:  0.05272514745593071\n",
      "Loss:  0.04392443597316742\n",
      "54 **********\n",
      "Epoch:  3274.8716588020325  fold:  3  kers:  64\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.04990999773144722\n",
      "Loss:  0.03211616352200508\n",
      "Loss:  0.06191128492355347\n",
      "55 **********\n",
      "Epoch:  3321.0402131080627  fold:  3  kers:  64\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.045109909027814865\n",
      "Loss:  0.06590501964092255\n",
      "Loss:  0.0722702369093895\n",
      "56 **********\n",
      "Epoch:  3367.233701467514  fold:  3  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.27993044257164\n",
      "Eval Loss:  0.13906797766685486\n",
      "Eval Loss:  1.03774893283844\n",
      "[[1196  340]\n",
      " [ 466 1429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75      1536\n",
      "           1       0.81      0.75      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.76      0.77      0.76      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7650830661614689\n",
      "pre:  0.8078010175240249\n",
      "rec:  0.754089709762533\n",
      "ma F1:  0.7639946568679661\n",
      "mi F1:  0.7650830661614688\n",
      "we F1:  0.7656716480111745\n",
      "Eval Loss:  0.18278299272060394\n",
      "Eval Loss:  0.1965368390083313\n",
      "Eval Loss:  0.22753864526748657\n",
      "Eval Loss:  0.15641820430755615\n",
      "Eval Loss:  0.22045917809009552\n",
      "Eval Loss:  0.16246645152568817\n",
      "Eval Loss:  0.15883876383304596\n",
      "Eval Loss:  0.1420593559741974\n",
      "Eval Loss:  0.24105623364448547\n",
      "Eval Loss:  0.17809969186782837\n",
      "Eval Loss:  0.19657224416732788\n",
      "Eval Loss:  0.1888834536075592\n",
      "Eval Loss:  0.1702215075492859\n",
      "Eval Loss:  0.15464097261428833\n",
      "Eval Loss:  0.15632466971874237\n",
      "Eval Loss:  0.21053734421730042\n",
      "Eval Loss:  0.21799342334270477\n",
      "Eval Loss:  0.18795253336429596\n",
      "Eval Loss:  0.15697799623012543\n",
      "Eval Loss:  0.18425734341144562\n",
      "Eval Loss:  0.197992742061615\n",
      "Eval Loss:  0.21242736279964447\n",
      "Eval Loss:  0.2404998242855072\n",
      "Eval Loss:  0.16718703508377075\n",
      "Eval Loss:  0.22896836698055267\n",
      "Eval Loss:  0.2763327658176422\n",
      "Eval Loss:  0.20715540647506714\n",
      "Eval Loss:  0.09779040515422821\n",
      "[[17441  1187]\n",
      " [  995  9837]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     18628\n",
      "           1       0.89      0.91      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9259334691106585\n",
      "pre:  0.8923258345428157\n",
      "rec:  0.908142540620384\n",
      "ma F1:  0.9206467863430562\n",
      "mi F1:  0.9259334691106585\n",
      "we F1:  0.9260669571552904\n",
      "29460 461\n",
      "Loss:  0.05820951610803604\n",
      "Loss:  0.07532966881990433\n",
      "Loss:  0.0564284510910511\n",
      "57 **********\n",
      "Epoch:  3453.30157327652  fold:  3  kers:  64\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.030000576749444008\n",
      "Loss:  0.06856311112642288\n",
      "Loss:  0.04402066767215729\n",
      "58 **********\n",
      "Epoch:  3499.4801013469696  fold:  3  kers:  64\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.06781579554080963\n",
      "Loss:  0.06297068297863007\n",
      "Loss:  0.06359469145536423\n",
      "59 **********\n",
      "Epoch:  3545.6366877555847  fold:  3  kers:  64\n",
      "Eval Loss:  0.4228585362434387\n",
      "Eval Loss:  0.09195251762866974\n",
      "Eval Loss:  0.8671603798866272\n",
      "[[1212  324]\n",
      " [ 515 1380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74      1536\n",
      "           1       0.81      0.73      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7554648790440105\n",
      "pre:  0.8098591549295775\n",
      "rec:  0.7282321899736148\n",
      "ma F1:  0.754877172013849\n",
      "mi F1:  0.7554648790440105\n",
      "we F1:  0.756133045965206\n",
      "update!  Acc:  0.7761585543573303\n",
      "Epoch:  3549.821499109268  fold:  3  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29520 3371\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29520 462\n",
      "Loss:  0.16954565048217773\n",
      "Loss:  0.1689925193786621\n",
      "Loss:  0.15845155715942383\n",
      "0 **********\n",
      "Epoch:  58.773850440979004  fold:  4  kers:  64\n",
      "epoch:  1\n",
      "29520 462\n",
      "Loss:  0.1515325903892517\n",
      "Loss:  0.12973934412002563\n",
      "Loss:  0.12956126034259796\n",
      "1 **********\n",
      "Epoch:  105.18375992774963  fold:  4  kers:  64\n",
      "epoch:  2\n",
      "29520 462\n",
      "Loss:  0.11198706179857254\n",
      "Loss:  0.09549795836210251\n",
      "Loss:  0.10816886276006699\n",
      "2 **********\n",
      "Epoch:  151.57771134376526  fold:  4  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.5630228519439697\n",
      "Eval Loss:  0.48591122031211853\n",
      "Eval Loss:  0.13856995105743408\n",
      "[[2620  517]\n",
      " [ 120  114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.89      3137\n",
      "           1       0.18      0.49      0.26       234\n",
      "\n",
      "    accuracy                           0.81      3371\n",
      "   macro avg       0.57      0.66      0.58      3371\n",
      "weighted avg       0.90      0.81      0.85      3371\n",
      "\n",
      "acc:  0.8110353010975971\n",
      "pre:  0.18066561014263074\n",
      "rec:  0.48717948717948717\n",
      "ma F1:  0.577597590686137\n",
      "mi F1:  0.8110353010975971\n",
      "we F1:  0.84801645474219\n",
      "update!  Acc:  0.8110353010975971\n",
      "Eval Loss:  0.36859118938446045\n",
      "Eval Loss:  0.4228209853172302\n",
      "Eval Loss:  0.46603021025657654\n",
      "Eval Loss:  0.4468115568161011\n",
      "Eval Loss:  0.3901061415672302\n",
      "Eval Loss:  0.3692742884159088\n",
      "Eval Loss:  0.47239309549331665\n",
      "Eval Loss:  0.4778183698654175\n",
      "Eval Loss:  0.33219635486602783\n",
      "Eval Loss:  0.422789603471756\n",
      "Eval Loss:  0.3443743586540222\n",
      "Eval Loss:  0.47816523909568787\n",
      "Eval Loss:  0.3870793581008911\n",
      "Eval Loss:  0.4645979106426239\n",
      "Eval Loss:  0.45222654938697815\n",
      "Eval Loss:  0.43486595153808594\n",
      "Eval Loss:  0.34544089436531067\n",
      "Eval Loss:  0.38413652777671814\n",
      "Eval Loss:  0.3569236993789673\n",
      "Eval Loss:  0.4443652927875519\n",
      "Eval Loss:  0.4563516676425934\n",
      "Eval Loss:  0.4508736729621887\n",
      "Eval Loss:  0.496822327375412\n",
      "Eval Loss:  0.45412617921829224\n",
      "Eval Loss:  0.47353145480155945\n",
      "Eval Loss:  0.5851339101791382\n",
      "Eval Loss:  0.5499207973480225\n",
      "Eval Loss:  0.39335206151008606\n",
      "[[14201  2826]\n",
      " [ 2720  9773]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84     17027\n",
      "           1       0.78      0.78      0.78     12493\n",
      "\n",
      "    accuracy                           0.81     29520\n",
      "   macro avg       0.81      0.81      0.81     29520\n",
      "weighted avg       0.81      0.81      0.81     29520\n",
      "\n",
      "acc:  0.8121273712737127\n",
      "pre:  0.7756964838479244\n",
      "rec:  0.7822780757224046\n",
      "ma F1:  0.807802937364412\n",
      "mi F1:  0.8121273712737127\n",
      "we F1:  0.8122308920493193\n",
      "29520 462\n",
      "Loss:  0.09220869094133377\n",
      "Loss:  0.10588262230157852\n",
      "Loss:  0.10471328347921371\n",
      "3 **********\n",
      "Epoch:  238.14425039291382  fold:  4  kers:  64\n",
      "epoch:  4\n",
      "29520 462\n",
      "Loss:  0.09450667351484299\n",
      "Loss:  0.11057013273239136\n",
      "Loss:  0.10482771694660187\n",
      "4 **********\n",
      "Epoch:  284.46539759635925  fold:  4  kers:  64\n",
      "epoch:  5\n",
      "29520 462\n",
      "Loss:  0.09074068069458008\n",
      "Loss:  0.11641384661197662\n",
      "Loss:  0.08544263988733292\n",
      "5 **********\n",
      "Epoch:  330.80649042129517  fold:  4  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.23851589858531952\n",
      "Eval Loss:  0.23458166420459747\n",
      "Eval Loss:  0.07665450870990753\n",
      "[[3053   84]\n",
      " [ 223   11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3137\n",
      "           1       0.12      0.05      0.07       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.52      0.51      0.51      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9089291011569267\n",
      "pre:  0.11578947368421053\n",
      "rec:  0.04700854700854701\n",
      "ma F1:  0.5094988949592796\n",
      "mi F1:  0.9089291011569267\n",
      "we F1:  0.8906776880532209\n",
      "update!  Acc:  0.9089291011569267\n",
      "Eval Loss:  0.3586001694202423\n",
      "Eval Loss:  0.38149604201316833\n",
      "Eval Loss:  0.4579584002494812\n",
      "Eval Loss:  0.3333987295627594\n",
      "Eval Loss:  0.35510802268981934\n",
      "Eval Loss:  0.33085018396377563\n",
      "Eval Loss:  0.39337974786758423\n",
      "Eval Loss:  0.44903239607810974\n",
      "Eval Loss:  0.3094114065170288\n",
      "Eval Loss:  0.4150341749191284\n",
      "Eval Loss:  0.3608275353908539\n",
      "Eval Loss:  0.42322108149528503\n",
      "Eval Loss:  0.3557577431201935\n",
      "Eval Loss:  0.3822176158428192\n",
      "Eval Loss:  0.4209013879299164\n",
      "Eval Loss:  0.3939482271671295\n",
      "Eval Loss:  0.34392550587654114\n",
      "Eval Loss:  0.3952525556087494\n",
      "Eval Loss:  0.32600006461143494\n",
      "Eval Loss:  0.45486676692962646\n",
      "Eval Loss:  0.38243433833122253\n",
      "Eval Loss:  0.39745715260505676\n",
      "Eval Loss:  0.49436116218566895\n",
      "Eval Loss:  0.3931322991847992\n",
      "Eval Loss:  0.46084579825401306\n",
      "Eval Loss:  0.5338191986083984\n",
      "Eval Loss:  0.48956233263015747\n",
      "Eval Loss:  0.3473956286907196\n",
      "[[15783  1244]\n",
      " [ 3562  8931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87     17027\n",
      "           1       0.88      0.71      0.79     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.85      0.82      0.83     29520\n",
      "weighted avg       0.84      0.84      0.83     29520\n",
      "\n",
      "acc:  0.8371951219512195\n",
      "pre:  0.8777395577395577\n",
      "rec:  0.7148803329864725\n",
      "ma F1:  0.8279242253900448\n",
      "mi F1:  0.8371951219512195\n",
      "we F1:  0.8340588204000224\n",
      "29520 462\n",
      "Loss:  0.0948973223567009\n",
      "Loss:  0.10451109707355499\n",
      "Loss:  0.07452898472547531\n",
      "6 **********\n",
      "Epoch:  417.0768210887909  fold:  4  kers:  64\n",
      "epoch:  7\n",
      "29520 462\n",
      "Loss:  0.07376273721456528\n",
      "Loss:  0.07002593576908112\n",
      "Loss:  0.067194364964962\n",
      "7 **********\n",
      "Epoch:  463.33214378356934  fold:  4  kers:  64\n",
      "epoch:  8\n",
      "29520 462\n",
      "Loss:  0.05879797041416168\n",
      "Loss:  0.07955780625343323\n",
      "Loss:  0.1180746853351593\n",
      "8 **********\n",
      "Epoch:  509.5256314277649  fold:  4  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.15012674033641815\n",
      "Eval Loss:  0.14817173779010773\n",
      "Eval Loss:  0.0487990565598011\n",
      "[[3085   52]\n",
      " [ 224   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.16      0.04      0.07       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.55      0.51      0.51      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9181251854049244\n",
      "pre:  0.16129032258064516\n",
      "rec:  0.042735042735042736\n",
      "ma F1:  0.5123751582795952\n",
      "mi F1:  0.9181251854049244\n",
      "we F1:  0.8954295741315726\n",
      "update!  Acc:  0.9181251854049244\n",
      "Eval Loss:  0.3884757459163666\n",
      "Eval Loss:  0.43281033635139465\n",
      "Eval Loss:  0.4828934371471405\n",
      "Eval Loss:  0.36964812874794006\n",
      "Eval Loss:  0.34147873520851135\n",
      "Eval Loss:  0.30657219886779785\n",
      "Eval Loss:  0.3847600519657135\n",
      "Eval Loss:  0.518775463104248\n",
      "Eval Loss:  0.3515252470970154\n",
      "Eval Loss:  0.42744162678718567\n",
      "Eval Loss:  0.40155911445617676\n",
      "Eval Loss:  0.43975844979286194\n",
      "Eval Loss:  0.3904675841331482\n",
      "Eval Loss:  0.3977718949317932\n",
      "Eval Loss:  0.46032485365867615\n",
      "Eval Loss:  0.45943641662597656\n",
      "Eval Loss:  0.3909977674484253\n",
      "Eval Loss:  0.43156448006629944\n",
      "Eval Loss:  0.3843262195587158\n",
      "Eval Loss:  0.5185155868530273\n",
      "Eval Loss:  0.347181499004364\n",
      "Eval Loss:  0.431440532207489\n",
      "Eval Loss:  0.5506250262260437\n",
      "Eval Loss:  0.4182760417461395\n",
      "Eval Loss:  0.4846578538417816\n",
      "Eval Loss:  0.5065796971321106\n",
      "Eval Loss:  0.5229098200798035\n",
      "Eval Loss:  0.35996752977371216\n",
      "[[16279   748]\n",
      " [ 4140  8353]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87     17027\n",
      "           1       0.92      0.67      0.77     12493\n",
      "\n",
      "    accuracy                           0.83     29520\n",
      "   macro avg       0.86      0.81      0.82     29520\n",
      "weighted avg       0.85      0.83      0.83     29520\n",
      "\n",
      "acc:  0.8344173441734417\n",
      "pre:  0.9178112295352159\n",
      "rec:  0.6686144240774834\n",
      "ma F1:  0.8215530948060623\n",
      "mi F1:  0.8344173441734417\n",
      "we F1:  0.8289119778027438\n",
      "29520 462\n",
      "Loss:  0.06488919258117676\n",
      "Loss:  0.09739749878644943\n",
      "Loss:  0.07182065397500992\n",
      "9 **********\n",
      "Epoch:  596.0612530708313  fold:  4  kers:  64\n",
      "epoch:  10\n",
      "29520 462\n",
      "Loss:  0.06732849776744843\n",
      "Loss:  0.08616747707128525\n",
      "Loss:  0.073074571788311\n",
      "10 **********\n",
      "Epoch:  642.3604581356049  fold:  4  kers:  64\n",
      "epoch:  11\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.10479593276977539\n",
      "Loss:  0.0791606456041336\n",
      "Loss:  0.08159205317497253\n",
      "11 **********\n",
      "Epoch:  688.7025489807129  fold:  4  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.11516693979501724\n",
      "Eval Loss:  0.13260583579540253\n",
      "Eval Loss:  0.04393521696329117\n",
      "[[3095   42]\n",
      " [ 225    9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.18      0.04      0.06       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.55      0.51      0.51      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9207950163156333\n",
      "pre:  0.17647058823529413\n",
      "rec:  0.038461538461538464\n",
      "ma F1:  0.5109037111906295\n",
      "mi F1:  0.9207950163156334\n",
      "we F1:  0.8964884353571513\n",
      "update!  Acc:  0.9207950163156333\n",
      "Eval Loss:  0.37132376432418823\n",
      "Eval Loss:  0.4227798283100128\n",
      "Eval Loss:  0.42019039392471313\n",
      "Eval Loss:  0.32799598574638367\n",
      "Eval Loss:  0.326572060585022\n",
      "Eval Loss:  0.28660720586776733\n",
      "Eval Loss:  0.34696266055107117\n",
      "Eval Loss:  0.45903775095939636\n",
      "Eval Loss:  0.34645920991897583\n",
      "Eval Loss:  0.38457927107810974\n",
      "Eval Loss:  0.36795809864997864\n",
      "Eval Loss:  0.43444743752479553\n",
      "Eval Loss:  0.37754571437835693\n",
      "Eval Loss:  0.3778473138809204\n",
      "Eval Loss:  0.44377392530441284\n",
      "Eval Loss:  0.4234781861305237\n",
      "Eval Loss:  0.38229307532310486\n",
      "Eval Loss:  0.3863881826400757\n",
      "Eval Loss:  0.3782634735107422\n",
      "Eval Loss:  0.4837607145309448\n",
      "Eval Loss:  0.3037307560443878\n",
      "Eval Loss:  0.3703756034374237\n",
      "Eval Loss:  0.4635598361492157\n",
      "Eval Loss:  0.4167160391807556\n",
      "Eval Loss:  0.47503578662872314\n",
      "Eval Loss:  0.4872727394104004\n",
      "Eval Loss:  0.4777030944824219\n",
      "Eval Loss:  0.33990323543548584\n",
      "[[16415   612]\n",
      " [ 4068  8425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.88     17027\n",
      "           1       0.93      0.67      0.78     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.87      0.82      0.83     29520\n",
      "weighted avg       0.86      0.84      0.84     29520\n",
      "\n",
      "acc:  0.8414634146341463\n",
      "pre:  0.9322784109770942\n",
      "rec:  0.6743776514848315\n",
      "ma F1:  0.8289310805243699\n",
      "mi F1:  0.8414634146341463\n",
      "we F1:  0.8360426703683908\n",
      "29520 462\n",
      "Loss:  0.07984878867864609\n",
      "Loss:  0.09039716422557831\n",
      "Loss:  0.06387468427419662\n",
      "12 **********\n",
      "Epoch:  774.5141060352325  fold:  4  kers:  64\n",
      "epoch:  13\n",
      "29520 462\n",
      "Loss:  0.09233853220939636\n",
      "Loss:  0.05088095739483833\n",
      "Loss:  0.06730286031961441\n",
      "13 **********\n",
      "Epoch:  820.436320066452  fold:  4  kers:  64\n",
      "epoch:  14\n",
      "29520 462\n",
      "Loss:  0.0554012730717659\n",
      "Loss:  0.09752685576677322\n",
      "Loss:  0.07972505688667297\n",
      "14 **********\n",
      "Epoch:  866.466245174408  fold:  4  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.06669003516435623\n",
      "Eval Loss:  0.16500647366046906\n",
      "Eval Loss:  0.039748404175043106\n",
      "[[3071   66]\n",
      " [ 212   22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.25      0.09      0.14       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.59      0.54      0.55      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9175318896469891\n",
      "pre:  0.25\n",
      "rec:  0.09401709401709402\n",
      "ma F1:  0.5466718910237804\n",
      "mi F1:  0.9175318896469891\n",
      "we F1:  0.8997734246424012\n",
      "Eval Loss:  0.30733367800712585\n",
      "Eval Loss:  0.36911773681640625\n",
      "Eval Loss:  0.3615248501300812\n",
      "Eval Loss:  0.25372615456581116\n",
      "Eval Loss:  0.24699482321739197\n",
      "Eval Loss:  0.2284778207540512\n",
      "Eval Loss:  0.30499449372291565\n",
      "Eval Loss:  0.3883233368396759\n",
      "Eval Loss:  0.2954992949962616\n",
      "Eval Loss:  0.3203955888748169\n",
      "Eval Loss:  0.315977543592453\n",
      "Eval Loss:  0.3621738851070404\n",
      "Eval Loss:  0.3200577199459076\n",
      "Eval Loss:  0.31629303097724915\n",
      "Eval Loss:  0.34501931071281433\n",
      "Eval Loss:  0.3576803207397461\n",
      "Eval Loss:  0.3160679042339325\n",
      "Eval Loss:  0.3200298547744751\n",
      "Eval Loss:  0.3270057439804077\n",
      "Eval Loss:  0.405195951461792\n",
      "Eval Loss:  0.25891923904418945\n",
      "Eval Loss:  0.3208659291267395\n",
      "Eval Loss:  0.38117748498916626\n",
      "Eval Loss:  0.3268943727016449\n",
      "Eval Loss:  0.41216611862182617\n",
      "Eval Loss:  0.3926003575325012\n",
      "Eval Loss:  0.3960549235343933\n",
      "Eval Loss:  0.28446733951568604\n",
      "[[16267   760]\n",
      " [ 3151  9342]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89     17027\n",
      "           1       0.92      0.75      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.88      0.85      0.86     29520\n",
      "weighted avg       0.87      0.87      0.86     29520\n",
      "\n",
      "acc:  0.8675135501355014\n",
      "pre:  0.9247673727974659\n",
      "rec:  0.7477787561034179\n",
      "ma F1:  0.8597981097842372\n",
      "mi F1:  0.8675135501355014\n",
      "we F1:  0.8648496341961697\n",
      "29520 462\n",
      "Loss:  0.06538750976324081\n",
      "Loss:  0.09570050984621048\n",
      "Loss:  0.06219787523150444\n",
      "15 **********\n",
      "Epoch:  952.4274022579193  fold:  4  kers:  64\n",
      "epoch:  16\n",
      "29520 462\n",
      "Loss:  0.04844706133008003\n",
      "Loss:  0.11204929649829865\n",
      "Loss:  0.09236946702003479\n",
      "16 **********\n",
      "Epoch:  998.6288690567017  fold:  4  kers:  64\n",
      "epoch:  17\n",
      "29520 462\n",
      "Loss:  0.10153717547655106\n",
      "Loss:  0.06036567687988281\n",
      "Loss:  0.04435890167951584\n",
      "17 **********\n",
      "Epoch:  1044.8482882976532  fold:  4  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.017876502126455307\n",
      "Eval Loss:  0.1947208195924759\n",
      "Eval Loss:  0.01807399094104767\n",
      "[[3088   49]\n",
      " [ 224   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.17      0.04      0.07       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.55      0.51      0.51      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9190151290418274\n",
      "pre:  0.1694915254237288\n",
      "rec:  0.042735042735042736\n",
      "ma F1:  0.5129636205734995\n",
      "mi F1:  0.9190151290418275\n",
      "we F1:  0.8959290296324844\n",
      "Eval Loss:  0.33822405338287354\n",
      "Eval Loss:  0.39525914192199707\n",
      "Eval Loss:  0.3962061107158661\n",
      "Eval Loss:  0.27486127614974976\n",
      "Eval Loss:  0.28227999806404114\n",
      "Eval Loss:  0.2892437279224396\n",
      "Eval Loss:  0.3370831608772278\n",
      "Eval Loss:  0.41048920154571533\n",
      "Eval Loss:  0.3753757178783417\n",
      "Eval Loss:  0.3517632484436035\n",
      "Eval Loss:  0.4203585982322693\n",
      "Eval Loss:  0.3850518763065338\n",
      "Eval Loss:  0.37236887216567993\n",
      "Eval Loss:  0.3545207977294922\n",
      "Eval Loss:  0.4387553036212921\n",
      "Eval Loss:  0.3655555248260498\n",
      "Eval Loss:  0.33834028244018555\n",
      "Eval Loss:  0.36514610052108765\n",
      "Eval Loss:  0.36063551902770996\n",
      "Eval Loss:  0.47653284668922424\n",
      "Eval Loss:  0.3099834620952606\n",
      "Eval Loss:  0.3404741883277893\n",
      "Eval Loss:  0.42172956466674805\n",
      "Eval Loss:  0.38228321075439453\n",
      "Eval Loss:  0.38321104645729065\n",
      "Eval Loss:  0.4575710892677307\n",
      "Eval Loss:  0.4542313814163208\n",
      "Eval Loss:  0.35681989789009094\n",
      "[[16440   587]\n",
      " [ 3628  8865]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     17027\n",
      "           1       0.94      0.71      0.81     12493\n",
      "\n",
      "    accuracy                           0.86     29520\n",
      "   macro avg       0.88      0.84      0.85     29520\n",
      "weighted avg       0.87      0.86      0.85     29520\n",
      "\n",
      "acc:  0.8572154471544715\n",
      "pre:  0.9378967414303852\n",
      "rec:  0.7095973745297367\n",
      "ma F1:  0.8471508698592786\n",
      "mi F1:  0.8572154471544715\n",
      "we F1:  0.853175001008639\n",
      "29520 462\n",
      "Loss:  0.06217163801193237\n",
      "Loss:  0.06081691011786461\n",
      "Loss:  0.0805453360080719\n",
      "18 **********\n",
      "Epoch:  1131.102661371231  fold:  4  kers:  64\n",
      "epoch:  19\n",
      "29520 462\n",
      "Loss:  0.05266226828098297\n",
      "Loss:  0.09335505962371826\n",
      "Loss:  0.03967635706067085\n",
      "19 **********\n",
      "Epoch:  1177.4377706050873  fold:  4  kers:  64\n",
      "epoch:  20\n",
      "29520 462\n",
      "Loss:  0.0512680858373642\n",
      "Loss:  0.08939240127801895\n",
      "Loss:  0.0861092358827591\n",
      "20 **********\n",
      "Epoch:  1223.7299945354462  fold:  4  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.02977358177304268\n",
      "Eval Loss:  0.25794491171836853\n",
      "Eval Loss:  0.0219050832092762\n",
      "[[3027  110]\n",
      " [ 208   26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.19      0.11      0.14       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.56      0.54      0.55      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9056659744882825\n",
      "pre:  0.19117647058823528\n",
      "rec:  0.1111111111111111\n",
      "ma F1:  0.5453173512495546\n",
      "mi F1:  0.9056659744882825\n",
      "we F1:  0.8938985086177741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2878645360469818\n",
      "Eval Loss:  0.2967740595340729\n",
      "Eval Loss:  0.3024132549762726\n",
      "Eval Loss:  0.20623980462551117\n",
      "Eval Loss:  0.18707814812660217\n",
      "Eval Loss:  0.22894008457660675\n",
      "Eval Loss:  0.2513083517551422\n",
      "Eval Loss:  0.30103227496147156\n",
      "Eval Loss:  0.29778966307640076\n",
      "Eval Loss:  0.3010859191417694\n",
      "Eval Loss:  0.275221586227417\n",
      "Eval Loss:  0.31601545214653015\n",
      "Eval Loss:  0.2946106195449829\n",
      "Eval Loss:  0.2966694235801697\n",
      "Eval Loss:  0.3116375207901001\n",
      "Eval Loss:  0.2829910218715668\n",
      "Eval Loss:  0.25581368803977966\n",
      "Eval Loss:  0.27861520648002625\n",
      "Eval Loss:  0.2825610339641571\n",
      "Eval Loss:  0.37567347288131714\n",
      "Eval Loss:  0.2531326711177826\n",
      "Eval Loss:  0.27690351009368896\n",
      "Eval Loss:  0.3453369140625\n",
      "Eval Loss:  0.2894963324069977\n",
      "Eval Loss:  0.3195493221282959\n",
      "Eval Loss:  0.36274275183677673\n",
      "Eval Loss:  0.3431866466999054\n",
      "Eval Loss:  0.30377939343452454\n",
      "[[16145   882]\n",
      " [ 2506  9987]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17027\n",
      "           1       0.92      0.80      0.85     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.87      0.88     29520\n",
      "weighted avg       0.89      0.89      0.88     29520\n",
      "\n",
      "acc:  0.885230352303523\n",
      "pre:  0.9188517802925752\n",
      "rec:  0.7994076682942448\n",
      "ma F1:  0.8800088449148644\n",
      "mi F1:  0.885230352303523\n",
      "we F1:  0.8838533259964133\n",
      "29520 462\n",
      "Loss:  0.06229659542441368\n",
      "Loss:  0.05306950956583023\n",
      "Loss:  0.07027850300073624\n",
      "21 **********\n",
      "Epoch:  1309.8597009181976  fold:  4  kers:  64\n",
      "epoch:  22\n",
      "29520 462\n",
      "Loss:  0.04670872539281845\n",
      "Loss:  0.061061132699251175\n",
      "Loss:  0.11540265381336212\n",
      "22 **********\n",
      "Epoch:  1356.1289863586426  fold:  4  kers:  64\n",
      "epoch:  23\n",
      "29520 462\n",
      "Loss:  0.057549137622117996\n",
      "Loss:  0.06374314427375793\n",
      "Loss:  0.08157305419445038\n",
      "23 **********\n",
      "Epoch:  1405.489007472992  fold:  4  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.032192837446928024\n",
      "Eval Loss:  0.2028861790895462\n",
      "Eval Loss:  0.009803497232496738\n",
      "[[3077   60]\n",
      " [ 214   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.25      0.09      0.13       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.59      0.53      0.54      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9187184811628597\n",
      "pre:  0.25\n",
      "rec:  0.08547008547008547\n",
      "ma F1:  0.5423812619154258\n",
      "mi F1:  0.9187184811628597\n",
      "we F1:  0.8997600474814385\n",
      "Eval Loss:  0.2806297540664673\n",
      "Eval Loss:  0.30947616696357727\n",
      "Eval Loss:  0.30349859595298767\n",
      "Eval Loss:  0.19733411073684692\n",
      "Eval Loss:  0.1902478188276291\n",
      "Eval Loss:  0.22056728601455688\n",
      "Eval Loss:  0.23981545865535736\n",
      "Eval Loss:  0.29545965790748596\n",
      "Eval Loss:  0.3175957202911377\n",
      "Eval Loss:  0.2977418005466461\n",
      "Eval Loss:  0.26706206798553467\n",
      "Eval Loss:  0.3134116232395172\n",
      "Eval Loss:  0.29267263412475586\n",
      "Eval Loss:  0.29596570134162903\n",
      "Eval Loss:  0.33606740832328796\n",
      "Eval Loss:  0.30117154121398926\n",
      "Eval Loss:  0.26551318168640137\n",
      "Eval Loss:  0.2783190608024597\n",
      "Eval Loss:  0.2935316264629364\n",
      "Eval Loss:  0.4018046259880066\n",
      "Eval Loss:  0.25424933433532715\n",
      "Eval Loss:  0.2707532048225403\n",
      "Eval Loss:  0.35436463356018066\n",
      "Eval Loss:  0.3108966052532196\n",
      "Eval Loss:  0.33579719066619873\n",
      "Eval Loss:  0.36171823740005493\n",
      "Eval Loss:  0.368743896484375\n",
      "Eval Loss:  0.3030177354812622\n",
      "[[16307   720]\n",
      " [ 2702  9791]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     17027\n",
      "           1       0.93      0.78      0.85     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.89      0.87      0.88     29520\n",
      "weighted avg       0.89      0.88      0.88     29520\n",
      "\n",
      "acc:  0.8840785907859079\n",
      "pre:  0.9315003329844924\n",
      "rec:  0.7837188825742416\n",
      "ma F1:  0.8781413335403946\n",
      "mi F1:  0.8840785907859079\n",
      "we F1:  0.8822726294813333\n",
      "29520 462\n",
      "Loss:  0.07546757906675339\n",
      "Loss:  0.07854118943214417\n",
      "Loss:  0.09137528389692307\n",
      "24 **********\n",
      "Epoch:  1491.6376633644104  fold:  4  kers:  64\n",
      "epoch:  25\n",
      "29520 462\n",
      "Loss:  0.04400677978992462\n",
      "Loss:  0.07210341095924377\n",
      "Loss:  0.0714581236243248\n",
      "25 **********\n",
      "Epoch:  1537.8022291660309  fold:  4  kers:  64\n",
      "epoch:  26\n",
      "29520 462\n",
      "Loss:  0.04725201055407524\n",
      "Loss:  0.061451613903045654\n",
      "Loss:  0.051347605884075165\n",
      "26 **********\n",
      "Epoch:  1584.0156638622284  fold:  4  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.024393390864133835\n",
      "Eval Loss:  0.2112254947423935\n",
      "Eval Loss:  0.009149637073278427\n",
      "[[3064   73]\n",
      " [ 220   14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      3137\n",
      "           1       0.16      0.06      0.09       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.55      0.52      0.52      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9130821714624741\n",
      "pre:  0.16091954022988506\n",
      "rec:  0.05982905982905983\n",
      "ma F1:  0.5207979463801845\n",
      "mi F1:  0.9130821714624741\n",
      "we F1:  0.8941753579912948\n",
      "Eval Loss:  0.2824265658855438\n",
      "Eval Loss:  0.2635616064071655\n",
      "Eval Loss:  0.2788602113723755\n",
      "Eval Loss:  0.1743345409631729\n",
      "Eval Loss:  0.15767802298069\n",
      "Eval Loss:  0.19247695803642273\n",
      "Eval Loss:  0.23289035260677338\n",
      "Eval Loss:  0.2540969252586365\n",
      "Eval Loss:  0.2601228654384613\n",
      "Eval Loss:  0.2754806578159332\n",
      "Eval Loss:  0.2553435266017914\n",
      "Eval Loss:  0.2829994559288025\n",
      "Eval Loss:  0.27826690673828125\n",
      "Eval Loss:  0.26590242981910706\n",
      "Eval Loss:  0.27964287996292114\n",
      "Eval Loss:  0.25069549679756165\n",
      "Eval Loss:  0.18581432104110718\n",
      "Eval Loss:  0.2667140066623688\n",
      "Eval Loss:  0.25244227051734924\n",
      "Eval Loss:  0.36464396119117737\n",
      "Eval Loss:  0.22723577916622162\n",
      "Eval Loss:  0.2735089361667633\n",
      "Eval Loss:  0.2820581793785095\n",
      "Eval Loss:  0.24325475096702576\n",
      "Eval Loss:  0.2959757149219513\n",
      "Eval Loss:  0.34708598256111145\n",
      "Eval Loss:  0.33863094449043274\n",
      "Eval Loss:  0.29325753450393677\n",
      "[[16044   983]\n",
      " [ 2099 10394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     17027\n",
      "           1       0.91      0.83      0.87     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.89      0.89     29520\n",
      "weighted avg       0.90      0.90      0.89     29520\n",
      "\n",
      "acc:  0.8955962059620596\n",
      "pre:  0.9135976092115672\n",
      "rec:  0.831985912110782\n",
      "ma F1:  0.8916262253160452\n",
      "mi F1:  0.8955962059620596\n",
      "we F1:  0.8948120469530416\n",
      "29520 462\n",
      "Loss:  0.09975126385688782\n",
      "Loss:  0.08345872163772583\n",
      "Loss:  0.10434728115797043\n",
      "27 **********\n",
      "Epoch:  1670.1393866539001  fold:  4  kers:  64\n",
      "epoch:  28\n",
      "29520 462\n",
      "Loss:  0.06875555217266083\n",
      "Loss:  0.09035256505012512\n",
      "Loss:  0.08509722352027893\n",
      "28 **********\n",
      "Epoch:  1716.3049490451813  fold:  4  kers:  64\n",
      "epoch:  29\n",
      "29520 462\n",
      "Loss:  0.04092436656355858\n",
      "Loss:  0.07088178396224976\n",
      "Loss:  0.0556810237467289\n",
      "29 **********\n",
      "Epoch:  1762.6241009235382  fold:  4  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.03825156390666962\n",
      "Eval Loss:  0.21505405008792877\n",
      "Eval Loss:  0.013154139742255211\n",
      "[[3035  102]\n",
      " [ 206   28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.22      0.12      0.15       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.58      0.54      0.55      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.908632453277959\n",
      "pre:  0.2153846153846154\n",
      "rec:  0.11965811965811966\n",
      "ma F1:  0.552777576766288\n",
      "mi F1:  0.908632453277959\n",
      "we F1:  0.8963248685898269\n",
      "Eval Loss:  0.2666560709476471\n",
      "Eval Loss:  0.24343936145305634\n",
      "Eval Loss:  0.2522253096103668\n",
      "Eval Loss:  0.15134574472904205\n",
      "Eval Loss:  0.1357283592224121\n",
      "Eval Loss:  0.17339292168617249\n",
      "Eval Loss:  0.20715205371379852\n",
      "Eval Loss:  0.24969536066055298\n",
      "Eval Loss:  0.23339185118675232\n",
      "Eval Loss:  0.2517423927783966\n",
      "Eval Loss:  0.20750589668750763\n",
      "Eval Loss:  0.26821085810661316\n",
      "Eval Loss:  0.2355341762304306\n",
      "Eval Loss:  0.2344309240579605\n",
      "Eval Loss:  0.24305997788906097\n",
      "Eval Loss:  0.24380069971084595\n",
      "Eval Loss:  0.17921176552772522\n",
      "Eval Loss:  0.23687823116779327\n",
      "Eval Loss:  0.23078574240207672\n",
      "Eval Loss:  0.3004756271839142\n",
      "Eval Loss:  0.1805804967880249\n",
      "Eval Loss:  0.2292814552783966\n",
      "Eval Loss:  0.24147211015224457\n",
      "Eval Loss:  0.24838466942310333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.276787668466568\n",
      "Eval Loss:  0.3239593505859375\n",
      "Eval Loss:  0.30020052194595337\n",
      "Eval Loss:  0.24541696906089783\n",
      "[[16015  1012]\n",
      " [ 1787 10706]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17027\n",
      "           1       0.91      0.86      0.88     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.91      0.90     29520\n",
      "\n",
      "acc:  0.9051829268292683\n",
      "pre:  0.913637139443591\n",
      "rec:  0.8569598975426239\n",
      "ma F1:  0.902013663956628\n",
      "mi F1:  0.9051829268292682\n",
      "we F1:  0.9047202825033507\n",
      "29520 462\n",
      "Loss:  0.06403074413537979\n",
      "Loss:  0.10170065611600876\n",
      "Loss:  0.05913490802049637\n",
      "30 **********\n",
      "Epoch:  1848.9283409118652  fold:  4  kers:  64\n",
      "epoch:  31\n",
      "29520 462\n",
      "Loss:  0.05642078071832657\n",
      "Loss:  0.054221261292696\n",
      "Loss:  0.07021482288837433\n",
      "31 **********\n",
      "Epoch:  1895.0300743579865  fold:  4  kers:  64\n",
      "epoch:  32\n",
      "29520 462\n",
      "Loss:  0.07164038717746735\n",
      "Loss:  0.03724699467420578\n",
      "Loss:  0.04348810389637947\n",
      "32 **********\n",
      "Epoch:  1941.0839359760284  fold:  4  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.041861359030008316\n",
      "Eval Loss:  0.17218290269374847\n",
      "Eval Loss:  0.007926102727651596\n",
      "[[3057   80]\n",
      " [ 214   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3137\n",
      "           1       0.20      0.09      0.12       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.57      0.53      0.54      3371\n",
      "weighted avg       0.88      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9127855235835064\n",
      "pre:  0.2\n",
      "rec:  0.08547008547008547\n",
      "ma F1:  0.536940164614591\n",
      "mi F1:  0.9127855235835064\n",
      "we F1:  0.8962022907544531\n",
      "Eval Loss:  0.2626858651638031\n",
      "Eval Loss:  0.2527788281440735\n",
      "Eval Loss:  0.2833288013935089\n",
      "Eval Loss:  0.16245099902153015\n",
      "Eval Loss:  0.14274394512176514\n",
      "Eval Loss:  0.18822124600410461\n",
      "Eval Loss:  0.2301022708415985\n",
      "Eval Loss:  0.2725825607776642\n",
      "Eval Loss:  0.265022337436676\n",
      "Eval Loss:  0.24386689066886902\n",
      "Eval Loss:  0.2325323075056076\n",
      "Eval Loss:  0.24424293637275696\n",
      "Eval Loss:  0.21497683227062225\n",
      "Eval Loss:  0.2310757339000702\n",
      "Eval Loss:  0.29234981536865234\n",
      "Eval Loss:  0.26436394453048706\n",
      "Eval Loss:  0.20379005372524261\n",
      "Eval Loss:  0.2571549415588379\n",
      "Eval Loss:  0.23279991745948792\n",
      "Eval Loss:  0.34478867053985596\n",
      "Eval Loss:  0.18581373989582062\n",
      "Eval Loss:  0.2259504497051239\n",
      "Eval Loss:  0.2535955309867859\n",
      "Eval Loss:  0.2792116105556488\n",
      "Eval Loss:  0.2761351764202118\n",
      "Eval Loss:  0.28722256422042847\n",
      "Eval Loss:  0.30339324474334717\n",
      "Eval Loss:  0.24989892542362213\n",
      "[[16171   856]\n",
      " [ 2093 10400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17027\n",
      "           1       0.92      0.83      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.89      0.90     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9001016260162602\n",
      "pre:  0.923951670220327\n",
      "rec:  0.8324661810613944\n",
      "ma F1:  0.8961319846197486\n",
      "mi F1:  0.9001016260162602\n",
      "we F1:  0.8992507429097822\n",
      "29520 462\n",
      "Loss:  0.050749272108078\n",
      "Loss:  0.06430262327194214\n",
      "Loss:  0.06402604281902313\n",
      "33 **********\n",
      "Epoch:  2026.690042257309  fold:  4  kers:  64\n",
      "epoch:  34\n",
      "29520 462\n",
      "Loss:  0.04837340861558914\n",
      "Loss:  0.04417680948972702\n",
      "Loss:  0.06087740510702133\n",
      "34 **********\n",
      "Epoch:  2072.684063434601  fold:  4  kers:  64\n",
      "epoch:  35\n",
      "29520 462\n",
      "Loss:  0.08441952615976334\n",
      "Loss:  0.05400490760803223\n",
      "Loss:  0.05871904268860817\n",
      "35 **********\n",
      "Epoch:  2118.760863304138  fold:  4  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.05521020293235779\n",
      "Eval Loss:  0.1580328792333603\n",
      "Eval Loss:  0.00826193206012249\n",
      "[[3039   98]\n",
      " [ 202   32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.25      0.14      0.18       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.59      0.55      0.56      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9110056363097004\n",
      "pre:  0.24615384615384617\n",
      "rec:  0.13675213675213677\n",
      "ma F1:  0.5643937436035272\n",
      "mi F1:  0.9110056363097004\n",
      "we F1:  0.8990177291459351\n",
      "Eval Loss:  0.24884767830371857\n",
      "Eval Loss:  0.22304068505764008\n",
      "Eval Loss:  0.27997204661369324\n",
      "Eval Loss:  0.1328810453414917\n",
      "Eval Loss:  0.13279031217098236\n",
      "Eval Loss:  0.15477611124515533\n",
      "Eval Loss:  0.2188107818365097\n",
      "Eval Loss:  0.234322190284729\n",
      "Eval Loss:  0.21853585541248322\n",
      "Eval Loss:  0.2567285895347595\n",
      "Eval Loss:  0.20480376482009888\n",
      "Eval Loss:  0.2539249658584595\n",
      "Eval Loss:  0.2546931207180023\n",
      "Eval Loss:  0.2283133566379547\n",
      "Eval Loss:  0.21672026813030243\n",
      "Eval Loss:  0.23220692574977875\n",
      "Eval Loss:  0.17011819779872894\n",
      "Eval Loss:  0.23600813746452332\n",
      "Eval Loss:  0.22432661056518555\n",
      "Eval Loss:  0.2630377411842346\n",
      "Eval Loss:  0.1780567169189453\n",
      "Eval Loss:  0.21537896990776062\n",
      "Eval Loss:  0.21687088906764984\n",
      "Eval Loss:  0.23392190039157867\n",
      "Eval Loss:  0.2569815516471863\n",
      "Eval Loss:  0.2539690136909485\n",
      "Eval Loss:  0.24375903606414795\n",
      "Eval Loss:  0.2284170240163803\n",
      "[[15812  1215]\n",
      " [ 1457 11036]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     17027\n",
      "           1       0.90      0.88      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.91      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9094850948509485\n",
      "pre:  0.9008244224961227\n",
      "rec:  0.8833746898263027\n",
      "ma F1:  0.90705213266282\n",
      "mi F1:  0.9094850948509486\n",
      "we F1:  0.9093618166161228\n",
      "29520 462\n",
      "Loss:  0.0927019789814949\n",
      "Loss:  0.038322120904922485\n",
      "Loss:  0.078630730509758\n",
      "36 **********\n",
      "Epoch:  2204.346025943756  fold:  4  kers:  64\n",
      "epoch:  37\n",
      "29520 462\n",
      "Loss:  0.04880724474787712\n",
      "Loss:  0.05527837947010994\n",
      "Loss:  0.07243435829877853\n",
      "37 **********\n",
      "Epoch:  2250.5644483566284  fold:  4  kers:  64\n",
      "epoch:  38\n",
      "29520 462\n",
      "Loss:  0.05566684156656265\n",
      "Loss:  0.0489986389875412\n",
      "Loss:  0.09144359827041626\n",
      "38 **********\n",
      "Epoch:  2296.5664472579956  fold:  4  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.02002064138650894\n",
      "Eval Loss:  0.27086955308914185\n",
      "Eval Loss:  0.0059386733919382095\n",
      "[[3013  124]\n",
      " [ 223   11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      3137\n",
      "           1       0.08      0.05      0.06       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.51      0.50      0.50      3371\n",
      "weighted avg       0.87      0.90      0.88      3371\n",
      "\n",
      "acc:  0.8970631859982201\n",
      "pre:  0.08148148148148149\n",
      "rec:  0.04700854700854701\n",
      "ma F1:  0.5025860708944451\n",
      "mi F1:  0.8970631859982201\n",
      "we F1:  0.8840541139145179\n",
      "Eval Loss:  0.2569950222969055\n",
      "Eval Loss:  0.23465663194656372\n",
      "Eval Loss:  0.2571999728679657\n",
      "Eval Loss:  0.1462658941745758\n",
      "Eval Loss:  0.15886175632476807\n",
      "Eval Loss:  0.18094222247600555\n",
      "Eval Loss:  0.21880555152893066\n",
      "Eval Loss:  0.2789478302001953\n",
      "Eval Loss:  0.2771911323070526\n",
      "Eval Loss:  0.28141602873802185\n",
      "Eval Loss:  0.2524699568748474\n",
      "Eval Loss:  0.2720522880554199\n",
      "Eval Loss:  0.2870495021343231\n",
      "Eval Loss:  0.2627585530281067\n",
      "Eval Loss:  0.28240612149238586\n",
      "Eval Loss:  0.24967031180858612\n",
      "Eval Loss:  0.18547473847866058\n",
      "Eval Loss:  0.2501398026943207\n",
      "Eval Loss:  0.22258545458316803\n",
      "Eval Loss:  0.33075568079948425\n",
      "Eval Loss:  0.21633309125900269\n",
      "Eval Loss:  0.22250056266784668\n",
      "Eval Loss:  0.2620665729045868\n",
      "Eval Loss:  0.288687139749527\n",
      "Eval Loss:  0.26886627078056335\n",
      "Eval Loss:  0.28651660680770874\n",
      "Eval Loss:  0.3347775936126709\n",
      "Eval Loss:  0.2609789967536926\n",
      "[[16375   652]\n",
      " [ 2324 10169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17027\n",
      "           1       0.94      0.81      0.87     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.91      0.89      0.89     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.8991869918699187\n",
      "pre:  0.9397467886516958\n",
      "rec:  0.8139758264628192\n",
      "ma F1:  0.8945253497386443\n",
      "mi F1:  0.8991869918699187\n",
      "we F1:  0.8979310676605261\n",
      "29520 462\n",
      "Loss:  0.08187174797058105\n",
      "Loss:  0.0684908777475357\n",
      "Loss:  0.040457833558321\n",
      "39 **********\n",
      "Epoch:  2382.7480158805847  fold:  4  kers:  64\n",
      "epoch:  40\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0648476630449295\n",
      "Loss:  0.04216671735048294\n",
      "Loss:  0.07481829822063446\n",
      "40 **********\n",
      "Epoch:  2429.0252799987793  fold:  4  kers:  64\n",
      "epoch:  41\n",
      "29520 462\n",
      "Loss:  0.056216929107904434\n",
      "Loss:  0.07139991223812103\n",
      "Loss:  0.04368395358324051\n",
      "41 **********\n",
      "Epoch:  2475.391306400299  fold:  4  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.018941815942525864\n",
      "Eval Loss:  0.12463360279798508\n",
      "Eval Loss:  0.005100960843265057\n",
      "[[3080   57]\n",
      " [ 219   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.21      0.06      0.10       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.57      0.52      0.53      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9181251854049244\n",
      "pre:  0.20833333333333334\n",
      "rec:  0.0641025641025641\n",
      "ma F1:  0.5275777184708563\n",
      "mi F1:  0.9181251854049244\n",
      "we F1:  0.8974828723075935\n",
      "Eval Loss:  0.22019660472869873\n",
      "Eval Loss:  0.21121053397655487\n",
      "Eval Loss:  0.2725081741809845\n",
      "Eval Loss:  0.14265698194503784\n",
      "Eval Loss:  0.15062454342842102\n",
      "Eval Loss:  0.16632020473480225\n",
      "Eval Loss:  0.1868593543767929\n",
      "Eval Loss:  0.2418060302734375\n",
      "Eval Loss:  0.2624260485172272\n",
      "Eval Loss:  0.2635343372821808\n",
      "Eval Loss:  0.24337992072105408\n",
      "Eval Loss:  0.2585796117782593\n",
      "Eval Loss:  0.23624378442764282\n",
      "Eval Loss:  0.2364136427640915\n",
      "Eval Loss:  0.244865283370018\n",
      "Eval Loss:  0.2656208872795105\n",
      "Eval Loss:  0.1777801662683487\n",
      "Eval Loss:  0.25327494740486145\n",
      "Eval Loss:  0.2202790528535843\n",
      "Eval Loss:  0.3406742513179779\n",
      "Eval Loss:  0.20205727219581604\n",
      "Eval Loss:  0.2089633345603943\n",
      "Eval Loss:  0.2611563801765442\n",
      "Eval Loss:  0.25243183970451355\n",
      "Eval Loss:  0.24459592998027802\n",
      "Eval Loss:  0.2587951719760895\n",
      "Eval Loss:  0.328074187040329\n",
      "Eval Loss:  0.240461066365242\n",
      "[[16342   685]\n",
      " [ 2111 10382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     17027\n",
      "           1       0.94      0.83      0.88     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.91      0.90     29520\n",
      "\n",
      "acc:  0.9052845528455284\n",
      "pre:  0.9381042739676516\n",
      "rec:  0.8310253742095574\n",
      "ma F1:  0.9012596589484403\n",
      "mi F1:  0.9052845528455284\n",
      "we F1:  0.9043215497084063\n",
      "29520 462\n",
      "Loss:  0.06767898052930832\n",
      "Loss:  0.029469083994627\n",
      "Loss:  0.042155422270298004\n",
      "42 **********\n",
      "Epoch:  2561.080191373825  fold:  4  kers:  64\n",
      "epoch:  43\n",
      "29520 462\n",
      "Loss:  0.05687381699681282\n",
      "Loss:  0.05164145305752754\n",
      "Loss:  0.03798036277294159\n",
      "43 **********\n",
      "Epoch:  2607.05925321579  fold:  4  kers:  64\n",
      "epoch:  44\n",
      "29520 462\n",
      "Loss:  0.08620904386043549\n",
      "Loss:  0.04072175174951553\n",
      "Loss:  0.09615888446569443\n",
      "44 **********\n",
      "Epoch:  2653.020362138748  fold:  4  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.035855308175086975\n",
      "Eval Loss:  0.12034790962934494\n",
      "Eval Loss:  0.007630021311342716\n",
      "[[3071   66]\n",
      " [ 218   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.20      0.07      0.10       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.56      0.52      0.53      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.915752002373183\n",
      "pre:  0.1951219512195122\n",
      "rec:  0.06837606837606838\n",
      "ma F1:  0.5285351834123242\n",
      "mi F1:  0.915752002373183\n",
      "we F1:  0.8964862228373236\n",
      "Eval Loss:  0.2279805690050125\n",
      "Eval Loss:  0.19629016518592834\n",
      "Eval Loss:  0.27491721510887146\n",
      "Eval Loss:  0.13981737196445465\n",
      "Eval Loss:  0.1389314830303192\n",
      "Eval Loss:  0.16863898932933807\n",
      "Eval Loss:  0.18830306828022003\n",
      "Eval Loss:  0.255906879901886\n",
      "Eval Loss:  0.20812608301639557\n",
      "Eval Loss:  0.21799740195274353\n",
      "Eval Loss:  0.21596355736255646\n",
      "Eval Loss:  0.24192844331264496\n",
      "Eval Loss:  0.1874963939189911\n",
      "Eval Loss:  0.23504184186458588\n",
      "Eval Loss:  0.17913906276226044\n",
      "Eval Loss:  0.24503925442695618\n",
      "Eval Loss:  0.14753635227680206\n",
      "Eval Loss:  0.2456444948911667\n",
      "Eval Loss:  0.1979554146528244\n",
      "Eval Loss:  0.28549623489379883\n",
      "Eval Loss:  0.1312970370054245\n",
      "Eval Loss:  0.19497458636760712\n",
      "Eval Loss:  0.20764639973640442\n",
      "Eval Loss:  0.2721845805644989\n",
      "Eval Loss:  0.24698492884635925\n",
      "Eval Loss:  0.24682819843292236\n",
      "Eval Loss:  0.31462523341178894\n",
      "Eval Loss:  0.21619544923305511\n",
      "[[16202   825]\n",
      " [ 1738 10755]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     17027\n",
      "           1       0.93      0.86      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9131775067750677\n",
      "pre:  0.9287564766839378\n",
      "rec:  0.8608820939726247\n",
      "ma F1:  0.9101172461517624\n",
      "mi F1:  0.9131775067750678\n",
      "we F1:  0.912664560575494\n",
      "29520 462\n",
      "Loss:  0.04231917858123779\n",
      "Loss:  0.05204932019114494\n",
      "Loss:  0.07204582542181015\n",
      "45 **********\n",
      "Epoch:  2738.5915625095367  fold:  4  kers:  64\n",
      "epoch:  46\n",
      "29520 462\n",
      "Loss:  0.08766090869903564\n",
      "Loss:  0.0334099717438221\n",
      "Loss:  0.05706808343529701\n",
      "46 **********\n",
      "Epoch:  2784.4868474006653  fold:  4  kers:  64\n",
      "epoch:  47\n",
      "29520 462\n",
      "Loss:  0.03934065252542496\n",
      "Loss:  0.050930023193359375\n",
      "Loss:  0.05311112105846405\n",
      "47 **********\n",
      "Epoch:  2830.5117859840393  fold:  4  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.08310592174530029\n",
      "Eval Loss:  0.14532442390918732\n",
      "Eval Loss:  0.007143616210669279\n",
      "[[3013  124]\n",
      " [ 204   30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.19      0.13      0.15       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.57      0.54      0.55      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9026994956986057\n",
      "pre:  0.19480519480519481\n",
      "rec:  0.1282051282051282\n",
      "ma F1:  0.5515090745662282\n",
      "mi F1:  0.9026994956986057\n",
      "we F1:  0.8932810465901276\n",
      "Eval Loss:  0.20050956308841705\n",
      "Eval Loss:  0.18960827589035034\n",
      "Eval Loss:  0.22990825772285461\n",
      "Eval Loss:  0.11850961297750473\n",
      "Eval Loss:  0.12069982290267944\n",
      "Eval Loss:  0.14007243514060974\n",
      "Eval Loss:  0.1729796826839447\n",
      "Eval Loss:  0.20417238771915436\n",
      "Eval Loss:  0.1840207278728485\n",
      "Eval Loss:  0.23226025700569153\n",
      "Eval Loss:  0.162217378616333\n",
      "Eval Loss:  0.21830998361110687\n",
      "Eval Loss:  0.1953967809677124\n",
      "Eval Loss:  0.21508418023586273\n",
      "Eval Loss:  0.18003179132938385\n",
      "Eval Loss:  0.2142137736082077\n",
      "Eval Loss:  0.15112338960170746\n",
      "Eval Loss:  0.2259804606437683\n",
      "Eval Loss:  0.21084658801555634\n",
      "Eval Loss:  0.25000742077827454\n",
      "Eval Loss:  0.13184291124343872\n",
      "Eval Loss:  0.1751234382390976\n",
      "Eval Loss:  0.2217550277709961\n",
      "Eval Loss:  0.24405036866664886\n",
      "Eval Loss:  0.22684931755065918\n",
      "Eval Loss:  0.2275737076997757\n",
      "Eval Loss:  0.2390231490135193\n",
      "Eval Loss:  0.18984510004520416\n",
      "[[15988  1039]\n",
      " [ 1386 11107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17027\n",
      "           1       0.91      0.89      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9178523035230353\n",
      "pre:  0.9144574345463528\n",
      "rec:  0.8890578724085488\n",
      "ma F1:  0.9155433304921674\n",
      "mi F1:  0.9178523035230353\n",
      "we F1:  0.9176881540369236\n",
      "29520 462\n",
      "Loss:  0.04403804987668991\n",
      "Loss:  0.07432800531387329\n",
      "Loss:  0.05538450926542282\n",
      "48 **********\n",
      "Epoch:  2916.125871896744  fold:  4  kers:  64\n",
      "epoch:  49\n",
      "29520 462\n",
      "Loss:  0.06869743764400482\n",
      "Loss:  0.051943693310022354\n",
      "Loss:  0.06157843768596649\n",
      "49 **********\n",
      "Epoch:  2962.164772748947  fold:  4  kers:  64\n",
      "epoch:  50\n",
      "29520 462\n",
      "Loss:  0.04404139518737793\n",
      "Loss:  0.051014699041843414\n",
      "Loss:  0.06755058467388153\n",
      "50 **********\n",
      "Epoch:  3008.2016797065735  fold:  4  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.08889323472976685\n",
      "Eval Loss:  0.16098521649837494\n",
      "Eval Loss:  0.006155391689389944\n",
      "[[3032  105]\n",
      " [ 201   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.24      0.14      0.18       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.59      0.55      0.56      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9092257490358944\n",
      "pre:  0.2391304347826087\n",
      "rec:  0.14102564102564102\n",
      "ma F1:  0.5646908391148022\n",
      "mi F1:  0.9092257490358944\n",
      "we F1:  0.8981969556539586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18932603299617767\n",
      "Eval Loss:  0.17408789694309235\n",
      "Eval Loss:  0.23791547119617462\n",
      "Eval Loss:  0.12037045508623123\n",
      "Eval Loss:  0.13120682537555695\n",
      "Eval Loss:  0.1275402307510376\n",
      "Eval Loss:  0.2029595673084259\n",
      "Eval Loss:  0.20564967393875122\n",
      "Eval Loss:  0.19501376152038574\n",
      "Eval Loss:  0.20618394017219543\n",
      "Eval Loss:  0.1724502295255661\n",
      "Eval Loss:  0.21522054076194763\n",
      "Eval Loss:  0.19751471281051636\n",
      "Eval Loss:  0.18769334256649017\n",
      "Eval Loss:  0.19157548248767853\n",
      "Eval Loss:  0.23937518894672394\n",
      "Eval Loss:  0.15384548902511597\n",
      "Eval Loss:  0.21266911923885345\n",
      "Eval Loss:  0.21147508919239044\n",
      "Eval Loss:  0.25576964020729065\n",
      "Eval Loss:  0.14527681469917297\n",
      "Eval Loss:  0.16961005330085754\n",
      "Eval Loss:  0.23447196185588837\n",
      "Eval Loss:  0.26305609941482544\n",
      "Eval Loss:  0.2053007036447525\n",
      "Eval Loss:  0.22888264060020447\n",
      "Eval Loss:  0.24416494369506836\n",
      "Eval Loss:  0.18954706192016602\n",
      "[[16001  1026]\n",
      " [ 1453 11040]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17027\n",
      "           1       0.91      0.88      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9160230352303523\n",
      "pre:  0.9149676777722526\n",
      "rec:  0.8836948691267109\n",
      "ma F1:  0.9135823706641759\n",
      "mi F1:  0.9160230352303523\n",
      "we F1:  0.9158129639201816\n",
      "29520 462\n",
      "Loss:  0.034990184009075165\n",
      "Loss:  0.04869559034705162\n",
      "Loss:  0.03654896095395088\n",
      "51 **********\n",
      "Epoch:  3093.7549273967743  fold:  4  kers:  64\n",
      "epoch:  52\n",
      "29520 462\n",
      "Loss:  0.07723498344421387\n",
      "Loss:  0.05106611177325249\n",
      "Loss:  0.04441165551543236\n",
      "52 **********\n",
      "Epoch:  3139.692100763321  fold:  4  kers:  64\n",
      "epoch:  53\n",
      "29520 462\n",
      "Loss:  0.05572321265935898\n",
      "Loss:  0.044066134840250015\n",
      "Loss:  0.06670933216810226\n",
      "53 **********\n",
      "Epoch:  3185.6392476558685  fold:  4  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.14498621225357056\n",
      "Eval Loss:  0.21695487201213837\n",
      "Eval Loss:  0.008346041664481163\n",
      "[[2985  152]\n",
      " [ 202   32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      3137\n",
      "           1       0.17      0.14      0.15       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.56      0.54      0.55      3371\n",
      "weighted avg       0.88      0.89      0.89      3371\n",
      "\n",
      "acc:  0.8949866508454465\n",
      "pre:  0.17391304347826086\n",
      "rec:  0.13675213675213677\n",
      "ma F1:  0.548566409122686\n",
      "mi F1:  0.8949866508454465\n",
      "we F1:  0.8891210863056097\n",
      "Eval Loss:  0.19086238741874695\n",
      "Eval Loss:  0.1771542727947235\n",
      "Eval Loss:  0.22796238958835602\n",
      "Eval Loss:  0.12224112451076508\n",
      "Eval Loss:  0.12268033623695374\n",
      "Eval Loss:  0.13240739703178406\n",
      "Eval Loss:  0.19669950008392334\n",
      "Eval Loss:  0.20658884942531586\n",
      "Eval Loss:  0.16313768923282623\n",
      "Eval Loss:  0.2054501473903656\n",
      "Eval Loss:  0.16578416526317596\n",
      "Eval Loss:  0.19449326395988464\n",
      "Eval Loss:  0.16526132822036743\n",
      "Eval Loss:  0.1873682588338852\n",
      "Eval Loss:  0.17125825583934784\n",
      "Eval Loss:  0.2141658216714859\n",
      "Eval Loss:  0.14719870686531067\n",
      "Eval Loss:  0.22465012967586517\n",
      "Eval Loss:  0.20341932773590088\n",
      "Eval Loss:  0.23122644424438477\n",
      "Eval Loss:  0.1271657943725586\n",
      "Eval Loss:  0.16451653838157654\n",
      "Eval Loss:  0.20961618423461914\n",
      "Eval Loss:  0.26227065920829773\n",
      "Eval Loss:  0.21503308415412903\n",
      "Eval Loss:  0.2222239226102829\n",
      "Eval Loss:  0.23613271117210388\n",
      "Eval Loss:  0.1694355458021164\n",
      "[[15912  1115]\n",
      " [ 1259 11234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17027\n",
      "           1       0.91      0.90      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.92      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.919579945799458\n",
      "pre:  0.9097092882014738\n",
      "rec:  0.89922356519651\n",
      "ma F1:  0.9175083857307267\n",
      "mi F1:  0.919579945799458\n",
      "we F1:  0.9195161782385566\n",
      "29520 462\n",
      "Loss:  0.06981958448886871\n",
      "Loss:  0.03761312738060951\n",
      "Loss:  0.06246314197778702\n",
      "54 **********\n",
      "Epoch:  3271.253333091736  fold:  4  kers:  64\n",
      "epoch:  55\n",
      "29520 462\n",
      "Loss:  0.051392972469329834\n",
      "Loss:  0.056279297918081284\n",
      "Loss:  0.04161587357521057\n",
      "55 **********\n",
      "Epoch:  3317.3251469135284  fold:  4  kers:  64\n",
      "epoch:  56\n",
      "29520 462\n",
      "Loss:  0.03661321476101875\n",
      "Loss:  0.041113998740911484\n",
      "Loss:  0.050131410360336304\n",
      "56 **********\n",
      "Epoch:  3363.329141139984  fold:  4  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.09369965642690659\n",
      "Eval Loss:  0.11944612115621567\n",
      "Eval Loss:  0.005795982666313648\n",
      "[[3047   90]\n",
      " [ 209   25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.22      0.11      0.14       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.58      0.54      0.55      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9113022841886681\n",
      "pre:  0.21739130434782608\n",
      "rec:  0.10683760683760683\n",
      "ma F1:  0.5482482855307806\n",
      "mi F1:  0.9113022841886681\n",
      "we F1:  0.8970059817928081\n",
      "Eval Loss:  0.18493570387363434\n",
      "Eval Loss:  0.15137702226638794\n",
      "Eval Loss:  0.23556314408779144\n",
      "Eval Loss:  0.11965775489807129\n",
      "Eval Loss:  0.1250932365655899\n",
      "Eval Loss:  0.12549760937690735\n",
      "Eval Loss:  0.1803169846534729\n",
      "Eval Loss:  0.1982518583536148\n",
      "Eval Loss:  0.17974652349948883\n",
      "Eval Loss:  0.19940520823001862\n",
      "Eval Loss:  0.16465416550636292\n",
      "Eval Loss:  0.19249829649925232\n",
      "Eval Loss:  0.17939096689224243\n",
      "Eval Loss:  0.19814930856227875\n",
      "Eval Loss:  0.1685020923614502\n",
      "Eval Loss:  0.22377406060695648\n",
      "Eval Loss:  0.13690979778766632\n",
      "Eval Loss:  0.2332109808921814\n",
      "Eval Loss:  0.1950240433216095\n",
      "Eval Loss:  0.2532092034816742\n",
      "Eval Loss:  0.11986053735017776\n",
      "Eval Loss:  0.16386201977729797\n",
      "Eval Loss:  0.18934102356433868\n",
      "Eval Loss:  0.23866650462150574\n",
      "Eval Loss:  0.20204821228981018\n",
      "Eval Loss:  0.21180959045886993\n",
      "Eval Loss:  0.24010886251926422\n",
      "Eval Loss:  0.18877997994422913\n",
      "[[15974  1053]\n",
      " [ 1242 11251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     17027\n",
      "           1       0.91      0.90      0.91     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.92      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9222560975609756\n",
      "pre:  0.9144180754226268\n",
      "rec:  0.900584327223245\n",
      "ma F1:  0.920213742339542\n",
      "mi F1:  0.9222560975609756\n",
      "we F1:  0.9221743687579159\n",
      "29520 462\n",
      "Loss:  0.06152493506669998\n",
      "Loss:  0.053275227546691895\n",
      "Loss:  0.07272785156965256\n",
      "57 **********\n",
      "Epoch:  3448.9182929992676  fold:  4  kers:  64\n",
      "epoch:  58\n",
      "29520 462\n",
      "Loss:  0.047421637922525406\n",
      "Loss:  0.04056710749864578\n",
      "Loss:  0.056494005024433136\n",
      "58 **********\n",
      "Epoch:  3494.8963572978973  fold:  4  kers:  64\n",
      "epoch:  59\n",
      "29520 462\n",
      "Loss:  0.061089735478162766\n",
      "Loss:  0.058118388056755066\n",
      "Loss:  0.05949186161160469\n",
      "59 **********\n",
      "Epoch:  3540.8993542194366  fold:  4  kers:  64\n",
      "Eval Loss:  0.09059891104698181\n",
      "Eval Loss:  0.07719568908214569\n",
      "Eval Loss:  0.0048546744510531425\n",
      "[[3079   58]\n",
      " [ 213   21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.27      0.09      0.13       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.60      0.54      0.55      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9196084247997627\n",
      "pre:  0.26582278481012656\n",
      "rec:  0.08974358974358974\n",
      "ma F1:  0.5460162790709232\n",
      "mi F1:  0.9196084247997627\n",
      "we F1:  0.9006722630639975\n",
      "update!  Acc:  0.9207950163156333\n",
      "Epoch:  3544.953514814377  fold:  4  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29673 3218\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29673 464\n",
      "Loss:  0.17323820292949677\n",
      "Loss:  0.1659143716096878\n",
      "Loss:  0.1574469655752182\n",
      "0 **********\n",
      "Epoch:  58.923449993133545  fold:  5  kers:  64\n",
      "epoch:  1\n",
      "29673 464\n",
      "Loss:  0.139614999294281\n",
      "Loss:  0.1358591914176941\n",
      "Loss:  0.12939120829105377\n",
      "1 **********\n",
      "Epoch:  105.54878449440002  fold:  5  kers:  64\n",
      "epoch:  2\n",
      "29673 464\n",
      "Loss:  0.12377418577671051\n",
      "Loss:  0.11779651790857315\n",
      "Loss:  0.09125981479883194\n",
      "2 **********\n",
      "Epoch:  151.91580820083618  fold:  5  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.1663045883178711\n",
      "Eval Loss:  0.3274106979370117\n",
      "Eval Loss:  0.38810527324676514\n",
      "[[2687  410]\n",
      " [  43   78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      3097\n",
      "           1       0.16      0.64      0.26       121\n",
      "\n",
      "    accuracy                           0.86      3218\n",
      "   macro avg       0.57      0.76      0.59      3218\n",
      "weighted avg       0.95      0.86      0.90      3218\n",
      "\n",
      "acc:  0.8592293349906774\n",
      "pre:  0.1598360655737705\n",
      "rec:  0.6446280991735537\n",
      "ma F1:  0.5892080437508084\n",
      "mi F1:  0.8592293349906774\n",
      "we F1:  0.8972123989558103\n",
      "update!  Acc:  0.8592293349906774\n",
      "Eval Loss:  0.432457834482193\n",
      "Eval Loss:  0.5452970862388611\n",
      "Eval Loss:  0.5073707699775696\n",
      "Eval Loss:  0.4258878529071808\n",
      "Eval Loss:  0.43532148003578186\n",
      "Eval Loss:  0.36294466257095337\n",
      "Eval Loss:  0.3927045464515686\n",
      "Eval Loss:  0.49026304483413696\n",
      "Eval Loss:  0.30358654260635376\n",
      "Eval Loss:  0.4619368314743042\n",
      "Eval Loss:  0.47657686471939087\n",
      "Eval Loss:  0.4488469958305359\n",
      "Eval Loss:  0.4394169747829437\n",
      "Eval Loss:  0.4327773153781891\n",
      "Eval Loss:  0.4348006248474121\n",
      "Eval Loss:  0.36585918068885803\n",
      "Eval Loss:  0.4873609244823456\n",
      "Eval Loss:  0.40287137031555176\n",
      "Eval Loss:  0.4452252984046936\n",
      "Eval Loss:  0.4237896203994751\n",
      "Eval Loss:  0.4619414210319519\n",
      "Eval Loss:  0.5037750601768494\n",
      "Eval Loss:  0.4540736675262451\n",
      "Eval Loss:  0.46466511487960815\n",
      "Eval Loss:  0.3874485492706299\n",
      "Eval Loss:  0.5345340371131897\n",
      "Eval Loss:  0.5110998749732971\n",
      "Eval Loss:  0.41421008110046387\n",
      "Eval Loss:  0.5064115524291992\n",
      "[[14172  2895]\n",
      " [ 2998  9608]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83     17067\n",
      "           1       0.77      0.76      0.77     12606\n",
      "\n",
      "    accuracy                           0.80     29673\n",
      "   macro avg       0.80      0.80      0.80     29673\n",
      "weighted avg       0.80      0.80      0.80     29673\n",
      "\n",
      "acc:  0.8014019478987632\n",
      "pre:  0.7684555706630408\n",
      "rec:  0.7621767412343329\n",
      "ma F1:  0.7965897759577281\n",
      "mi F1:  0.8014019478987632\n",
      "we F1:  0.8012933471735383\n",
      "29673 464\n",
      "Loss:  0.09065902233123779\n",
      "Loss:  0.1233343780040741\n",
      "Loss:  0.08544492721557617\n",
      "3 **********\n",
      "Epoch:  238.21705555915833  fold:  5  kers:  64\n",
      "epoch:  4\n",
      "29673 464\n",
      "Loss:  0.1441648006439209\n",
      "Loss:  0.08417615294456482\n",
      "Loss:  0.12943536043167114\n",
      "4 **********\n",
      "Epoch:  284.5900638103485  fold:  5  kers:  64\n",
      "epoch:  5\n",
      "29673 464\n",
      "Loss:  0.1059492975473404\n",
      "Loss:  0.11694755405187607\n",
      "Loss:  0.09072666615247726\n",
      "5 **********\n",
      "Epoch:  330.9750406742096  fold:  5  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.13312377035617828\n",
      "Eval Loss:  0.26230528950691223\n",
      "Eval Loss:  0.20127059519290924\n",
      "[[2936  161]\n",
      " [  38   83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      3097\n",
      "           1       0.34      0.69      0.45       121\n",
      "\n",
      "    accuracy                           0.94      3218\n",
      "   macro avg       0.66      0.82      0.71      3218\n",
      "weighted avg       0.96      0.94      0.95      3218\n",
      "\n",
      "acc:  0.9381603480422622\n",
      "pre:  0.3401639344262295\n",
      "rec:  0.6859504132231405\n",
      "ma F1:  0.7110078680815826\n",
      "mi F1:  0.9381603480422622\n",
      "we F1:  0.9479534623202726\n",
      "update!  Acc:  0.9381603480422622\n",
      "Eval Loss:  0.36404362320899963\n",
      "Eval Loss:  0.4682307839393616\n",
      "Eval Loss:  0.402854323387146\n",
      "Eval Loss:  0.3636339008808136\n",
      "Eval Loss:  0.3636839985847473\n",
      "Eval Loss:  0.3030484616756439\n",
      "Eval Loss:  0.31006184220314026\n",
      "Eval Loss:  0.4191998541355133\n",
      "Eval Loss:  0.26055410504341125\n",
      "Eval Loss:  0.37654101848602295\n",
      "Eval Loss:  0.348881334066391\n",
      "Eval Loss:  0.35324040055274963\n",
      "Eval Loss:  0.35313284397125244\n",
      "Eval Loss:  0.40722036361694336\n",
      "Eval Loss:  0.3202921152114868\n",
      "Eval Loss:  0.3345588147640228\n",
      "Eval Loss:  0.4301398992538452\n",
      "Eval Loss:  0.3207314610481262\n",
      "Eval Loss:  0.36662447452545166\n",
      "Eval Loss:  0.3751644194126129\n",
      "Eval Loss:  0.38851198554039\n",
      "Eval Loss:  0.46599245071411133\n",
      "Eval Loss:  0.34414514899253845\n",
      "Eval Loss:  0.4144710898399353\n",
      "Eval Loss:  0.3074921667575836\n",
      "Eval Loss:  0.44482481479644775\n",
      "Eval Loss:  0.4667404890060425\n",
      "Eval Loss:  0.3539206385612488\n",
      "Eval Loss:  0.40007102489471436\n",
      "[[15572  1495]\n",
      " [ 3198  9408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87     17067\n",
      "           1       0.86      0.75      0.80     12606\n",
      "\n",
      "    accuracy                           0.84     29673\n",
      "   macro avg       0.85      0.83      0.83     29673\n",
      "weighted avg       0.84      0.84      0.84     29673\n",
      "\n",
      "acc:  0.8418427526707781\n",
      "pre:  0.8628817756580758\n",
      "rec:  0.746311280342694\n",
      "ma F1:  0.8347101414073551\n",
      "mi F1:  0.841842752670778\n",
      "we F1:  0.839872143166948\n",
      "29673 464\n",
      "Loss:  0.07618523389101028\n",
      "Loss:  0.05224724858999252\n",
      "Loss:  0.08042709529399872\n",
      "6 **********\n",
      "Epoch:  417.48772263526917  fold:  5  kers:  64\n",
      "epoch:  7\n",
      "29673 464\n",
      "Loss:  0.10047515481710434\n",
      "Loss:  0.11946647614240646\n",
      "Loss:  0.09281733632087708\n",
      "7 **********\n",
      "Epoch:  464.0083363056183  fold:  5  kers:  64\n",
      "epoch:  8\n",
      "29673 464\n",
      "Loss:  0.09370919317007065\n",
      "Loss:  0.10440940409898758\n",
      "Loss:  0.08866620808839798\n",
      "8 **********\n",
      "Epoch:  510.56684732437134  fold:  5  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.09348902851343155\n",
      "Eval Loss:  0.16368351876735687\n",
      "Eval Loss:  0.12026424705982208\n",
      "[[3024   73]\n",
      " [  31   90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.55      0.74      0.63       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.86      0.81      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9676817899316346\n",
      "pre:  0.5521472392638037\n",
      "rec:  0.743801652892562\n",
      "ma F1:  0.8084488726899761\n",
      "mi F1:  0.9676817899316346\n",
      "we F1:  0.9699611977449099\n",
      "update!  Acc:  0.9676817899316346\n",
      "Eval Loss:  0.32288920879364014\n",
      "Eval Loss:  0.4424338638782501\n",
      "Eval Loss:  0.35978105664253235\n",
      "Eval Loss:  0.351155161857605\n",
      "Eval Loss:  0.35030120611190796\n",
      "Eval Loss:  0.30025622248649597\n",
      "Eval Loss:  0.28017741441726685\n",
      "Eval Loss:  0.3481477200984955\n",
      "Eval Loss:  0.23470082879066467\n",
      "Eval Loss:  0.3412706255912781\n",
      "Eval Loss:  0.3568241596221924\n",
      "Eval Loss:  0.30945277214050293\n",
      "Eval Loss:  0.3522869944572449\n",
      "Eval Loss:  0.38825497031211853\n",
      "Eval Loss:  0.3091781735420227\n",
      "Eval Loss:  0.3283446431159973\n",
      "Eval Loss:  0.4057298004627228\n",
      "Eval Loss:  0.34036993980407715\n",
      "Eval Loss:  0.37009677290916443\n",
      "Eval Loss:  0.36684542894363403\n",
      "Eval Loss:  0.36924952268600464\n",
      "Eval Loss:  0.42399802803993225\n",
      "Eval Loss:  0.33650416135787964\n",
      "Eval Loss:  0.39506447315216064\n",
      "Eval Loss:  0.2986769676208496\n",
      "Eval Loss:  0.4287036061286926\n",
      "Eval Loss:  0.42725953459739685\n",
      "Eval Loss:  0.3771825134754181\n",
      "Eval Loss:  0.366961270570755\n",
      "[[15991  1076]\n",
      " [ 3382  9224]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88     17067\n",
      "           1       0.90      0.73      0.81     12606\n",
      "\n",
      "    accuracy                           0.85     29673\n",
      "   macro avg       0.86      0.83      0.84     29673\n",
      "weighted avg       0.86      0.85      0.85     29673\n",
      "\n",
      "acc:  0.8497624102719644\n",
      "pre:  0.8955339805825243\n",
      "rec:  0.7317150563223862\n",
      "ma F1:  0.8415202067189504\n",
      "mi F1:  0.8497624102719644\n",
      "we F1:  0.8469537031058272\n",
      "29673 464\n",
      "Loss:  0.06864377856254578\n",
      "Loss:  0.06775608658790588\n",
      "Loss:  0.06599997729063034\n",
      "9 **********\n",
      "Epoch:  596.752405166626  fold:  5  kers:  64\n",
      "epoch:  10\n",
      "29673 464\n",
      "Loss:  0.07186788320541382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09848019480705261\n",
      "Loss:  0.08863704651594162\n",
      "10 **********\n",
      "Epoch:  643.0386447906494  fold:  5  kers:  64\n",
      "epoch:  11\n",
      "29673 464\n",
      "Loss:  0.06579716503620148\n",
      "Loss:  0.09169545769691467\n",
      "Loss:  0.10249143838882446\n",
      "11 **********\n",
      "Epoch:  689.4385807514191  fold:  5  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.09872129559516907\n",
      "Eval Loss:  0.1581062376499176\n",
      "Eval Loss:  0.08145857602357864\n",
      "[[3036   61]\n",
      " [  24   97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.61      0.80      0.70       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.80      0.89      0.84      3218\n",
      "weighted avg       0.98      0.97      0.98      3218\n",
      "\n",
      "acc:  0.973586078309509\n",
      "pre:  0.6139240506329114\n",
      "rec:  0.8016528925619835\n",
      "ma F1:  0.8407675385361418\n",
      "mi F1:  0.973586078309509\n",
      "we F1:  0.9752581728898474\n",
      "update!  Acc:  0.973586078309509\n",
      "Eval Loss:  0.25083380937576294\n",
      "Eval Loss:  0.36700600385665894\n",
      "Eval Loss:  0.28793036937713623\n",
      "Eval Loss:  0.28833144903182983\n",
      "Eval Loss:  0.3126579821109772\n",
      "Eval Loss:  0.27372831106185913\n",
      "Eval Loss:  0.26098760962486267\n",
      "Eval Loss:  0.28070756793022156\n",
      "Eval Loss:  0.20386774837970734\n",
      "Eval Loss:  0.31549134850502014\n",
      "Eval Loss:  0.24354207515716553\n",
      "Eval Loss:  0.2553187608718872\n",
      "Eval Loss:  0.29848864674568176\n",
      "Eval Loss:  0.3464464247226715\n",
      "Eval Loss:  0.25613933801651\n",
      "Eval Loss:  0.2948225438594818\n",
      "Eval Loss:  0.3433281183242798\n",
      "Eval Loss:  0.2971622049808502\n",
      "Eval Loss:  0.31849488615989685\n",
      "Eval Loss:  0.3059987723827362\n",
      "Eval Loss:  0.31087526679039\n",
      "Eval Loss:  0.35169073939323425\n",
      "Eval Loss:  0.30072644352912903\n",
      "Eval Loss:  0.33391278982162476\n",
      "Eval Loss:  0.25860801339149475\n",
      "Eval Loss:  0.3457663655281067\n",
      "Eval Loss:  0.3560774028301239\n",
      "Eval Loss:  0.3279346525669098\n",
      "Eval Loss:  0.297195166349411\n",
      "[[15690  1377]\n",
      " [ 2461 10145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     17067\n",
      "           1       0.88      0.80      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.87      0.86      0.87     29673\n",
      "weighted avg       0.87      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8706568260708388\n",
      "pre:  0.8804894983509808\n",
      "rec:  0.8047755037283834\n",
      "ma F1:  0.8659766671379012\n",
      "mi F1:  0.8706568260708388\n",
      "we F1:  0.8697418950909824\n",
      "29673 464\n",
      "Loss:  0.10479974001646042\n",
      "Loss:  0.05733836442232132\n",
      "Loss:  0.07814802974462509\n",
      "12 **********\n",
      "Epoch:  775.6909596920013  fold:  5  kers:  64\n",
      "epoch:  13\n",
      "29673 464\n",
      "Loss:  0.07872266322374344\n",
      "Loss:  0.10076914727687836\n",
      "Loss:  0.09714857488870621\n",
      "13 **********\n",
      "Epoch:  822.1786608695984  fold:  5  kers:  64\n",
      "epoch:  14\n",
      "29673 464\n",
      "Loss:  0.07390392571687698\n",
      "Loss:  0.08222845196723938\n",
      "Loss:  0.08374866843223572\n",
      "14 **********\n",
      "Epoch:  868.6494076251984  fold:  5  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.0824480652809143\n",
      "Eval Loss:  0.11367204040288925\n",
      "Eval Loss:  0.061202775686979294\n",
      "[[3051   46]\n",
      " [  31   90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.66      0.74      0.70       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.83      0.86      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9760720944686141\n",
      "pre:  0.6617647058823529\n",
      "rec:  0.743801652892562\n",
      "ma F1:  0.8439637708492993\n",
      "mi F1:  0.9760720944686141\n",
      "we F1:  0.9767413362296036\n",
      "update!  Acc:  0.9760720944686141\n",
      "Eval Loss:  0.23806728422641754\n",
      "Eval Loss:  0.3409669101238251\n",
      "Eval Loss:  0.2773666977882385\n",
      "Eval Loss:  0.26915693283081055\n",
      "Eval Loss:  0.3075121343135834\n",
      "Eval Loss:  0.27452850341796875\n",
      "Eval Loss:  0.22803862392902374\n",
      "Eval Loss:  0.27770647406578064\n",
      "Eval Loss:  0.2076685130596161\n",
      "Eval Loss:  0.3210676610469818\n",
      "Eval Loss:  0.23944126069545746\n",
      "Eval Loss:  0.2418333739042282\n",
      "Eval Loss:  0.3019835948944092\n",
      "Eval Loss:  0.34275689721107483\n",
      "Eval Loss:  0.23562072217464447\n",
      "Eval Loss:  0.25981611013412476\n",
      "Eval Loss:  0.3154117465019226\n",
      "Eval Loss:  0.2966296970844269\n",
      "Eval Loss:  0.2843509614467621\n",
      "Eval Loss:  0.27113237977027893\n",
      "Eval Loss:  0.3005886673927307\n",
      "Eval Loss:  0.33580416440963745\n",
      "Eval Loss:  0.30973491072654724\n",
      "Eval Loss:  0.34367233514785767\n",
      "Eval Loss:  0.2279268354177475\n",
      "Eval Loss:  0.3174585700035095\n",
      "Eval Loss:  0.33963707089424133\n",
      "Eval Loss:  0.32789915800094604\n",
      "Eval Loss:  0.2812036871910095\n",
      "[[16007  1060]\n",
      " [ 2608  9998]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     17067\n",
      "           1       0.90      0.79      0.84     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.88      0.87      0.87     29673\n",
      "weighted avg       0.88      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8763859400802076\n",
      "pre:  0.9041417977934527\n",
      "rec:  0.7931143899730287\n",
      "ma F1:  0.8710998454570478\n",
      "mi F1:  0.8763859400802076\n",
      "we F1:  0.8750241703220696\n",
      "29673 464\n",
      "Loss:  0.09901896119117737\n",
      "Loss:  0.0785999670624733\n",
      "Loss:  0.08588103950023651\n",
      "15 **********\n",
      "Epoch:  955.1361594200134  fold:  5  kers:  64\n",
      "epoch:  16\n",
      "29673 464\n",
      "Loss:  0.06676992028951645\n",
      "Loss:  0.06602352112531662\n",
      "Loss:  0.08635604381561279\n",
      "16 **********\n",
      "Epoch:  1001.5450713634491  fold:  5  kers:  64\n",
      "epoch:  17\n",
      "29673 464\n",
      "Loss:  0.06391175091266632\n",
      "Loss:  0.0730789378285408\n",
      "Loss:  0.08697400987148285\n",
      "17 **********\n",
      "Epoch:  1047.8921484947205  fold:  5  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.06142653152346611\n",
      "Eval Loss:  0.06336766481399536\n",
      "Eval Loss:  0.038206715136766434\n",
      "[[3078   19]\n",
      " [  40   81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.81      0.67      0.73       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.90      0.83      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9816656308266004\n",
      "pre:  0.81\n",
      "rec:  0.6694214876033058\n",
      "ma F1:  0.8617692562512969\n",
      "mi F1:  0.9816656308266004\n",
      "we F1:  0.9808255160898364\n",
      "update!  Acc:  0.9816656308266004\n",
      "Eval Loss:  0.2763459086418152\n",
      "Eval Loss:  0.37638935446739197\n",
      "Eval Loss:  0.2803304195404053\n",
      "Eval Loss:  0.28138843178749084\n",
      "Eval Loss:  0.3265361487865448\n",
      "Eval Loss:  0.29694706201553345\n",
      "Eval Loss:  0.2476912885904312\n",
      "Eval Loss:  0.28858381509780884\n",
      "Eval Loss:  0.2232838273048401\n",
      "Eval Loss:  0.322672963142395\n",
      "Eval Loss:  0.29813894629478455\n",
      "Eval Loss:  0.23375701904296875\n",
      "Eval Loss:  0.3242638111114502\n",
      "Eval Loss:  0.36611127853393555\n",
      "Eval Loss:  0.23543787002563477\n",
      "Eval Loss:  0.2306104451417923\n",
      "Eval Loss:  0.33446046710014343\n",
      "Eval Loss:  0.303011029958725\n",
      "Eval Loss:  0.2545066177845001\n",
      "Eval Loss:  0.2605811655521393\n",
      "Eval Loss:  0.3598249554634094\n",
      "Eval Loss:  0.34078603982925415\n",
      "Eval Loss:  0.3398088812828064\n",
      "Eval Loss:  0.37137433886528015\n",
      "Eval Loss:  0.25148412585258484\n",
      "Eval Loss:  0.3286890983581543\n",
      "Eval Loss:  0.37969765067100525\n",
      "Eval Loss:  0.3700101375579834\n",
      "Eval Loss:  0.3022579848766327\n",
      "[[16295   772]\n",
      " [ 3126  9480]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     17067\n",
      "           1       0.92      0.75      0.83     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.85      0.86     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8686347858322381\n",
      "pre:  0.92469761997659\n",
      "rec:  0.752022846263684\n",
      "ma F1:  0.8613196261471043\n",
      "mi F1:  0.8686347858322382\n",
      "we F1:  0.8661080234112835\n",
      "29673 464\n",
      "Loss:  0.0566336028277874\n",
      "Loss:  0.09937730431556702\n",
      "Loss:  0.07513337582349777\n",
      "18 **********\n",
      "Epoch:  1134.3350183963776  fold:  5  kers:  64\n",
      "epoch:  19\n",
      "29673 464\n",
      "Loss:  0.08509683609008789\n",
      "Loss:  0.08597882091999054\n",
      "Loss:  0.05800051987171173\n",
      "19 **********\n",
      "Epoch:  1180.6342234611511  fold:  5  kers:  64\n",
      "epoch:  20\n",
      "29673 464\n",
      "Loss:  0.05672410503029823\n",
      "Loss:  0.08441212773323059\n",
      "Loss:  0.06846208870410919\n",
      "20 **********\n",
      "Epoch:  1227.0112211704254  fold:  5  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.06019996106624603\n",
      "Eval Loss:  0.06565169990062714\n",
      "Eval Loss:  0.03535045310854912\n",
      "[[3068   29]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.75      0.73      0.74       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.86      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.980733374766936\n",
      "pre:  0.7521367521367521\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.8647462857359788\n",
      "mi F1:  0.980733374766936\n",
      "we F1:  0.980577687399109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23728956282138824\n",
      "Eval Loss:  0.3319576382637024\n",
      "Eval Loss:  0.27200374007225037\n",
      "Eval Loss:  0.23601990938186646\n",
      "Eval Loss:  0.2833268344402313\n",
      "Eval Loss:  0.24992819130420685\n",
      "Eval Loss:  0.22575078904628754\n",
      "Eval Loss:  0.25812163949012756\n",
      "Eval Loss:  0.19836659729480743\n",
      "Eval Loss:  0.2967589199542999\n",
      "Eval Loss:  0.2151084691286087\n",
      "Eval Loss:  0.21614301204681396\n",
      "Eval Loss:  0.2855837643146515\n",
      "Eval Loss:  0.30070674419403076\n",
      "Eval Loss:  0.18542546033859253\n",
      "Eval Loss:  0.2096043825149536\n",
      "Eval Loss:  0.294287770986557\n",
      "Eval Loss:  0.2971707582473755\n",
      "Eval Loss:  0.22951333224773407\n",
      "Eval Loss:  0.2436080425977707\n",
      "Eval Loss:  0.2830454111099243\n",
      "Eval Loss:  0.28143811225891113\n",
      "Eval Loss:  0.26862064003944397\n",
      "Eval Loss:  0.32234102487564087\n",
      "Eval Loss:  0.21923519670963287\n",
      "Eval Loss:  0.3021406829357147\n",
      "Eval Loss:  0.3317197263240814\n",
      "Eval Loss:  0.29575806856155396\n",
      "Eval Loss:  0.2651975750923157\n",
      "[[16083   984]\n",
      " [ 2466 10140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     17067\n",
      "           1       0.91      0.80      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.87      0.88     29673\n",
      "weighted avg       0.89      0.88      0.88     29673\n",
      "\n",
      "acc:  0.883732686280457\n",
      "pre:  0.9115426105717368\n",
      "rec:  0.8043788672060923\n",
      "ma F1:  0.8788739176585645\n",
      "mi F1:  0.8837326862804571\n",
      "we F1:  0.8825210599810048\n",
      "29673 464\n",
      "Loss:  0.09087759256362915\n",
      "Loss:  0.06641678512096405\n",
      "Loss:  0.06860031187534332\n",
      "21 **********\n",
      "Epoch:  1313.299503326416  fold:  5  kers:  64\n",
      "epoch:  22\n",
      "29673 464\n",
      "Loss:  0.08949001878499985\n",
      "Loss:  0.06292318552732468\n",
      "Loss:  0.07649940997362137\n",
      "22 **********\n",
      "Epoch:  1360.5731036663055  fold:  5  kers:  64\n",
      "epoch:  23\n",
      "29673 464\n",
      "Loss:  0.06940539181232452\n",
      "Loss:  0.07609056681394577\n",
      "Loss:  0.06992447376251221\n",
      "23 **********\n",
      "Epoch:  1407.0278928279877  fold:  5  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.05376512557268143\n",
      "Eval Loss:  0.06498430669307709\n",
      "Eval Loss:  0.03472622483968735\n",
      "[[3070   27]\n",
      " [  37   84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.76      0.69      0.72       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.84      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9801118707271598\n",
      "pre:  0.7567567567567568\n",
      "rec:  0.6942148760330579\n",
      "ma F1:  0.8569110029124702\n",
      "mi F1:  0.9801118707271598\n",
      "we F1:  0.9796992757244313\n",
      "Eval Loss:  0.20791636407375336\n",
      "Eval Loss:  0.30910834670066833\n",
      "Eval Loss:  0.26078251004219055\n",
      "Eval Loss:  0.23920951783657074\n",
      "Eval Loss:  0.29719075560569763\n",
      "Eval Loss:  0.25036823749542236\n",
      "Eval Loss:  0.21900372207164764\n",
      "Eval Loss:  0.25249597430229187\n",
      "Eval Loss:  0.206614688038826\n",
      "Eval Loss:  0.28143951296806335\n",
      "Eval Loss:  0.21688349545001984\n",
      "Eval Loss:  0.22293342649936676\n",
      "Eval Loss:  0.2622048258781433\n",
      "Eval Loss:  0.30800661444664\n",
      "Eval Loss:  0.17252419888973236\n",
      "Eval Loss:  0.22078494727611542\n",
      "Eval Loss:  0.28780537843704224\n",
      "Eval Loss:  0.3010235130786896\n",
      "Eval Loss:  0.21848921477794647\n",
      "Eval Loss:  0.23944014310836792\n",
      "Eval Loss:  0.2890893220901489\n",
      "Eval Loss:  0.3008095324039459\n",
      "Eval Loss:  0.2563091814517975\n",
      "Eval Loss:  0.33303210139274597\n",
      "Eval Loss:  0.22387884557247162\n",
      "Eval Loss:  0.29498621821403503\n",
      "Eval Loss:  0.31615376472473145\n",
      "Eval Loss:  0.3170461654663086\n",
      "Eval Loss:  0.27133122086524963\n",
      "[[16154   913]\n",
      " [ 2513 10093]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.90     17067\n",
      "           1       0.92      0.80      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.87      0.88     29673\n",
      "weighted avg       0.89      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8845415023758972\n",
      "pre:  0.9170452480465201\n",
      "rec:  0.8006504838965572\n",
      "ma F1:  0.879514604499387\n",
      "mi F1:  0.8845415023758972\n",
      "we F1:  0.8832144875924595\n",
      "29673 464\n",
      "Loss:  0.087339848279953\n",
      "Loss:  0.06423579901456833\n",
      "Loss:  0.09372393786907196\n",
      "24 **********\n",
      "Epoch:  1493.5146460533142  fold:  5  kers:  64\n",
      "epoch:  25\n",
      "29673 464\n",
      "Loss:  0.056880220770835876\n",
      "Loss:  0.046490106731653214\n",
      "Loss:  0.08198928833007812\n",
      "25 **********\n",
      "Epoch:  1545.59539103508  fold:  5  kers:  64\n",
      "epoch:  26\n",
      "29673 464\n",
      "Loss:  0.052006132900714874\n",
      "Loss:  0.064997099339962\n",
      "Loss:  0.06644494086503983\n",
      "26 **********\n",
      "Epoch:  1592.0202605724335  fold:  5  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.05497128516435623\n",
      "Eval Loss:  0.07091373205184937\n",
      "Eval Loss:  0.018755288794636726\n",
      "[[3065   32]\n",
      " [  27   94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.75      0.78      0.76       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.88      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9816656308266004\n",
      "pre:  0.746031746031746\n",
      "rec:  0.7768595041322314\n",
      "ma F1:  0.8758002803720588\n",
      "mi F1:  0.9816656308266004\n",
      "we F1:  0.9818437953342654\n",
      "Eval Loss:  0.17542648315429688\n",
      "Eval Loss:  0.3014867901802063\n",
      "Eval Loss:  0.25419870018959045\n",
      "Eval Loss:  0.25141653418540955\n",
      "Eval Loss:  0.26805779337882996\n",
      "Eval Loss:  0.22060143947601318\n",
      "Eval Loss:  0.23738381266593933\n",
      "Eval Loss:  0.23380161821842194\n",
      "Eval Loss:  0.22176505625247955\n",
      "Eval Loss:  0.27119016647338867\n",
      "Eval Loss:  0.19115403294563293\n",
      "Eval Loss:  0.18789063394069672\n",
      "Eval Loss:  0.24190394580364227\n",
      "Eval Loss:  0.28674769401550293\n",
      "Eval Loss:  0.1540510505437851\n",
      "Eval Loss:  0.2209206074476242\n",
      "Eval Loss:  0.2600478529930115\n",
      "Eval Loss:  0.2884664833545685\n",
      "Eval Loss:  0.2178150713443756\n",
      "Eval Loss:  0.2287735790014267\n",
      "Eval Loss:  0.22914816439151764\n",
      "Eval Loss:  0.3083871901035309\n",
      "Eval Loss:  0.22359122335910797\n",
      "Eval Loss:  0.3157668709754944\n",
      "Eval Loss:  0.2027651071548462\n",
      "Eval Loss:  0.26329296827316284\n",
      "Eval Loss:  0.3168039917945862\n",
      "Eval Loss:  0.29401376843452454\n",
      "Eval Loss:  0.23419371247291565\n",
      "[[16004  1063]\n",
      " [ 2132 10474]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     17067\n",
      "           1       0.91      0.83      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.88      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8923263572945102\n",
      "pre:  0.9078616624772471\n",
      "rec:  0.8308741868951293\n",
      "ma F1:  0.8884520973318097\n",
      "mi F1:  0.8923263572945102\n",
      "we F1:  0.8915774271136553\n",
      "29673 464\n",
      "Loss:  0.0588374100625515\n",
      "Loss:  0.04943224415183067\n",
      "Loss:  0.11774735152721405\n",
      "27 **********\n",
      "Epoch:  1678.2915887832642  fold:  5  kers:  64\n",
      "epoch:  28\n",
      "29673 464\n",
      "Loss:  0.06250762194395065\n",
      "Loss:  0.06533554196357727\n",
      "Loss:  0.06369123607873917\n",
      "28 **********\n",
      "Epoch:  1724.6606075763702  fold:  5  kers:  64\n",
      "epoch:  29\n",
      "29673 464\n",
      "Loss:  0.06963596493005753\n",
      "Loss:  0.049280621111392975\n",
      "Loss:  0.08024407923221588\n",
      "29 **********\n",
      "Epoch:  1771.0455837249756  fold:  5  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.05282697081565857\n",
      "Eval Loss:  0.046090975403785706\n",
      "Eval Loss:  0.02463635429739952\n",
      "[[3075   22]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.80      0.74      0.77       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.90      0.86      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.983219390926041\n",
      "pre:  0.8018018018018018\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.8792686587073968\n",
      "mi F1:  0.983219390926041\n",
      "we F1:  0.9828712638924889\n",
      "update!  Acc:  0.983219390926041\n",
      "Eval Loss:  0.1879585236310959\n",
      "Eval Loss:  0.3123248219490051\n",
      "Eval Loss:  0.23519586026668549\n",
      "Eval Loss:  0.2340749204158783\n",
      "Eval Loss:  0.27434563636779785\n",
      "Eval Loss:  0.21967902779579163\n",
      "Eval Loss:  0.20630648732185364\n",
      "Eval Loss:  0.23126032948493958\n",
      "Eval Loss:  0.1898813247680664\n",
      "Eval Loss:  0.28866028785705566\n",
      "Eval Loss:  0.19040104746818542\n",
      "Eval Loss:  0.2084088772535324\n",
      "Eval Loss:  0.25145426392555237\n",
      "Eval Loss:  0.2830784320831299\n",
      "Eval Loss:  0.17571339011192322\n",
      "Eval Loss:  0.18531347811222076\n",
      "Eval Loss:  0.2701987028121948\n",
      "Eval Loss:  0.28919023275375366\n",
      "Eval Loss:  0.20582109689712524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2418426275253296\n",
      "Eval Loss:  0.2446470409631729\n",
      "Eval Loss:  0.29590871930122375\n",
      "Eval Loss:  0.2284747213125229\n",
      "Eval Loss:  0.31431227922439575\n",
      "Eval Loss:  0.19263297319412231\n",
      "Eval Loss:  0.27468493580818176\n",
      "Eval Loss:  0.3040519952774048\n",
      "Eval Loss:  0.29109469056129456\n",
      "Eval Loss:  0.23476798832416534\n",
      "[[16197   870]\n",
      " [ 2378 10228]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17067\n",
      "           1       0.92      0.81      0.86     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.88      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8905402217504128\n",
      "pre:  0.9216074968462786\n",
      "rec:  0.8113596699984135\n",
      "ma F1:  0.8859241344102469\n",
      "mi F1:  0.8905402217504128\n",
      "we F1:  0.8893740197552763\n",
      "29673 464\n",
      "Loss:  0.07856995612382889\n",
      "Loss:  0.055713899433612823\n",
      "Loss:  0.08615994453430176\n",
      "30 **********\n",
      "Epoch:  1857.2012207508087  fold:  5  kers:  64\n",
      "epoch:  31\n",
      "29673 464\n",
      "Loss:  0.1208612471818924\n",
      "Loss:  0.08351165801286697\n",
      "Loss:  0.07340826839208603\n",
      "31 **********\n",
      "Epoch:  1903.5253596305847  fold:  5  kers:  64\n",
      "epoch:  32\n",
      "29673 464\n",
      "Loss:  0.04251997172832489\n",
      "Loss:  0.07185199111700058\n",
      "Loss:  0.089040607213974\n",
      "32 **********\n",
      "Epoch:  1949.836532831192  fold:  5  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.05398774892091751\n",
      "Eval Loss:  0.04951673746109009\n",
      "Eval Loss:  0.027850301936268806\n",
      "[[3064   33]\n",
      " [  23   98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.75      0.81      0.78       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.90      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9825978868862648\n",
      "pre:  0.7480916030534351\n",
      "rec:  0.8099173553719008\n",
      "ma F1:  0.8843610751760816\n",
      "mi F1:  0.9825978868862648\n",
      "we F1:  0.9829290966357935\n",
      "Eval Loss:  0.1713407337665558\n",
      "Eval Loss:  0.2905580401420593\n",
      "Eval Loss:  0.2215491235256195\n",
      "Eval Loss:  0.21905358135700226\n",
      "Eval Loss:  0.24435240030288696\n",
      "Eval Loss:  0.19159428775310516\n",
      "Eval Loss:  0.216360405087471\n",
      "Eval Loss:  0.2187657505273819\n",
      "Eval Loss:  0.18437810242176056\n",
      "Eval Loss:  0.3033340871334076\n",
      "Eval Loss:  0.1533394157886505\n",
      "Eval Loss:  0.20983128249645233\n",
      "Eval Loss:  0.23169556260108948\n",
      "Eval Loss:  0.26564833521842957\n",
      "Eval Loss:  0.19569005072116852\n",
      "Eval Loss:  0.20427754521369934\n",
      "Eval Loss:  0.2695084512233734\n",
      "Eval Loss:  0.2749568819999695\n",
      "Eval Loss:  0.19433419406414032\n",
      "Eval Loss:  0.23002028465270996\n",
      "Eval Loss:  0.2048034518957138\n",
      "Eval Loss:  0.2722422778606415\n",
      "Eval Loss:  0.19389081001281738\n",
      "Eval Loss:  0.28092122077941895\n",
      "Eval Loss:  0.21517328917980194\n",
      "Eval Loss:  0.2666560709476471\n",
      "Eval Loss:  0.2786719501018524\n",
      "Eval Loss:  0.23285353183746338\n",
      "Eval Loss:  0.24377857148647308\n",
      "[[15830  1237]\n",
      " [ 1737 10869]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     17067\n",
      "           1       0.90      0.86      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.8997742055066896\n",
      "pre:  0.8978192631752849\n",
      "rec:  0.8622084721561162\n",
      "ma F1:  0.8968921163347644\n",
      "mi F1:  0.8997742055066895\n",
      "we F1:  0.899483730887467\n",
      "29673 464\n",
      "Loss:  0.06756619364023209\n",
      "Loss:  0.09270337969064713\n",
      "Loss:  0.06851539015769958\n",
      "33 **********\n",
      "Epoch:  2036.1078610420227  fold:  5  kers:  64\n",
      "epoch:  34\n",
      "29673 464\n",
      "Loss:  0.05431397631764412\n",
      "Loss:  0.10128725320100784\n",
      "Loss:  0.09644578397274017\n",
      "34 **********\n",
      "Epoch:  2082.3163089752197  fold:  5  kers:  64\n",
      "epoch:  35\n",
      "29673 464\n",
      "Loss:  0.053414855152368546\n",
      "Loss:  0.07141342759132385\n",
      "Loss:  0.09878768026828766\n",
      "35 **********\n",
      "Epoch:  2128.663386106491  fold:  5  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.056653089821338654\n",
      "Eval Loss:  0.0537046417593956\n",
      "Eval Loss:  0.021076204255223274\n",
      "[[3073   24]\n",
      " [  41   80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.77      0.66      0.71       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.83      0.85      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9798011187072716\n",
      "pre:  0.7692307692307693\n",
      "rec:  0.6611570247933884\n",
      "ma F1:  0.8503229038086548\n",
      "mi F1:  0.9798011187072716\n",
      "we F1:  0.9790656928291304\n",
      "Eval Loss:  0.19842202961444855\n",
      "Eval Loss:  0.30671876668930054\n",
      "Eval Loss:  0.2217685878276825\n",
      "Eval Loss:  0.21067039668560028\n",
      "Eval Loss:  0.28844574093818665\n",
      "Eval Loss:  0.2215791642665863\n",
      "Eval Loss:  0.2295338213443756\n",
      "Eval Loss:  0.2390155792236328\n",
      "Eval Loss:  0.1943226456642151\n",
      "Eval Loss:  0.2600639760494232\n",
      "Eval Loss:  0.2106807976961136\n",
      "Eval Loss:  0.18167643249034882\n",
      "Eval Loss:  0.2218305766582489\n",
      "Eval Loss:  0.27470266819000244\n",
      "Eval Loss:  0.14970381557941437\n",
      "Eval Loss:  0.18897578120231628\n",
      "Eval Loss:  0.2573697865009308\n",
      "Eval Loss:  0.2691335678100586\n",
      "Eval Loss:  0.19536900520324707\n",
      "Eval Loss:  0.2512969374656677\n",
      "Eval Loss:  0.2396288961172104\n",
      "Eval Loss:  0.28913620114326477\n",
      "Eval Loss:  0.23053227365016937\n",
      "Eval Loss:  0.29591360688209534\n",
      "Eval Loss:  0.2106303721666336\n",
      "Eval Loss:  0.2606460452079773\n",
      "Eval Loss:  0.278990238904953\n",
      "Eval Loss:  0.28779396414756775\n",
      "Eval Loss:  0.22164691984653473\n",
      "[[16316   751]\n",
      " [ 2325 10281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91     17067\n",
      "           1       0.93      0.82      0.87     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.8963367371010683\n",
      "pre:  0.9319253081943437\n",
      "rec:  0.8155640171346977\n",
      "ma F1:  0.8918636931136347\n",
      "mi F1:  0.8963367371010683\n",
      "we F1:  0.895170113863915\n",
      "29673 464\n",
      "Loss:  0.09747112542390823\n",
      "Loss:  0.08489174395799637\n",
      "Loss:  0.06942090392112732\n",
      "36 **********\n",
      "Epoch:  2214.926735639572  fold:  5  kers:  64\n",
      "epoch:  37\n",
      "29673 464\n",
      "Loss:  0.05427328497171402\n",
      "Loss:  0.06555186212062836\n",
      "Loss:  0.05211109295487404\n",
      "37 **********\n",
      "Epoch:  2261.215967655182  fold:  5  kers:  64\n",
      "epoch:  38\n",
      "29673 464\n",
      "Loss:  0.06856773793697357\n",
      "Loss:  0.051417041569948196\n",
      "Loss:  0.03326749801635742\n",
      "38 **********\n",
      "Epoch:  2307.6288685798645  fold:  5  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.05417715758085251\n",
      "Eval Loss:  0.03406462445855141\n",
      "Eval Loss:  0.011011593975126743\n",
      "[[3083   14]\n",
      " [  29   92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3097\n",
      "           1       0.87      0.76      0.81       121\n",
      "\n",
      "    accuracy                           0.99      3218\n",
      "   macro avg       0.93      0.88      0.90      3218\n",
      "weighted avg       0.99      0.99      0.99      3218\n",
      "\n",
      "acc:  0.9866376631448105\n",
      "pre:  0.8679245283018868\n",
      "rec:  0.7603305785123967\n",
      "ma F1:  0.9018236281992248\n",
      "mi F1:  0.9866376631448105\n",
      "we F1:  0.9862123169314422\n",
      "update!  Acc:  0.9866376631448105\n",
      "Eval Loss:  0.20623303949832916\n",
      "Eval Loss:  0.3561524748802185\n",
      "Eval Loss:  0.263235479593277\n",
      "Eval Loss:  0.28571733832359314\n",
      "Eval Loss:  0.29319316148757935\n",
      "Eval Loss:  0.28254491090774536\n",
      "Eval Loss:  0.24538008868694305\n",
      "Eval Loss:  0.24767279624938965\n",
      "Eval Loss:  0.19804053008556366\n",
      "Eval Loss:  0.3063046932220459\n",
      "Eval Loss:  0.22711269557476044\n",
      "Eval Loss:  0.19134975969791412\n",
      "Eval Loss:  0.25177982449531555\n",
      "Eval Loss:  0.26760736107826233\n",
      "Eval Loss:  0.17680341005325317\n",
      "Eval Loss:  0.21287380158901215\n",
      "Eval Loss:  0.30581656098365784\n",
      "Eval Loss:  0.31652843952178955\n",
      "Eval Loss:  0.2069152593612671\n",
      "Eval Loss:  0.2834945619106293\n",
      "Eval Loss:  0.27878278493881226\n",
      "Eval Loss:  0.31072404980659485\n",
      "Eval Loss:  0.2208036333322525\n",
      "Eval Loss:  0.37556955218315125\n",
      "Eval Loss:  0.24146553874015808\n",
      "Eval Loss:  0.3139936625957489\n",
      "Eval Loss:  0.2887535095214844\n",
      "Eval Loss:  0.31795254349708557\n",
      "Eval Loss:  0.23720204830169678\n",
      "[[16331   736]\n",
      " [ 2554 10052]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     17067\n",
      "           1       0.93      0.80      0.86     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.88      0.88     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8891247935833924\n",
      "pre:  0.9317760474601409\n",
      "rec:  0.7973980644137713\n",
      "ma F1:  0.883927372942499\n",
      "mi F1:  0.8891247935833924\n",
      "we F1:  0.8876199503400185\n",
      "29673 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08092297613620758\n",
      "Loss:  0.04654014855623245\n",
      "Loss:  0.05109188333153725\n",
      "39 **********\n",
      "Epoch:  2394.1126289367676  fold:  5  kers:  64\n",
      "epoch:  40\n",
      "29673 464\n",
      "Loss:  0.06161317601799965\n",
      "Loss:  0.0833810344338417\n",
      "Loss:  0.049876078963279724\n",
      "40 **********\n",
      "Epoch:  2440.5434823036194  fold:  5  kers:  64\n",
      "epoch:  41\n",
      "29673 464\n",
      "Loss:  0.07691427320241928\n",
      "Loss:  0.07264600694179535\n",
      "Loss:  0.10255929827690125\n",
      "41 **********\n",
      "Epoch:  2487.057114124298  fold:  5  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.05607952922582626\n",
      "Eval Loss:  0.051035791635513306\n",
      "Eval Loss:  0.019553137943148613\n",
      "[[3074   23]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.79      0.74      0.76       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.89      0.86      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9829086389061529\n",
      "pre:  0.7946428571428571\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.8775409102199614\n",
      "mi F1:  0.9829086389061529\n",
      "we F1:  0.982590947261873\n",
      "Eval Loss:  0.1617012619972229\n",
      "Eval Loss:  0.2956956624984741\n",
      "Eval Loss:  0.21342994272708893\n",
      "Eval Loss:  0.219447523355484\n",
      "Eval Loss:  0.2725141942501068\n",
      "Eval Loss:  0.20993542671203613\n",
      "Eval Loss:  0.21687909960746765\n",
      "Eval Loss:  0.24202466011047363\n",
      "Eval Loss:  0.168064683675766\n",
      "Eval Loss:  0.2629416882991791\n",
      "Eval Loss:  0.20592042803764343\n",
      "Eval Loss:  0.2161303013563156\n",
      "Eval Loss:  0.22845326364040375\n",
      "Eval Loss:  0.24365882575511932\n",
      "Eval Loss:  0.1552790105342865\n",
      "Eval Loss:  0.20074962079524994\n",
      "Eval Loss:  0.24585595726966858\n",
      "Eval Loss:  0.2908112704753876\n",
      "Eval Loss:  0.1851111352443695\n",
      "Eval Loss:  0.2722029387950897\n",
      "Eval Loss:  0.2304919958114624\n",
      "Eval Loss:  0.26617011427879333\n",
      "Eval Loss:  0.18033091723918915\n",
      "Eval Loss:  0.28430286049842834\n",
      "Eval Loss:  0.2248595505952835\n",
      "Eval Loss:  0.26738953590393066\n",
      "Eval Loss:  0.25588977336883545\n",
      "Eval Loss:  0.27500230073928833\n",
      "Eval Loss:  0.2191026210784912\n",
      "[[16232   835]\n",
      " [ 2220 10386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     17067\n",
      "           1       0.93      0.82      0.87     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.8970444511845785\n",
      "pre:  0.9255859549059798\n",
      "rec:  0.8238933841028082\n",
      "ma F1:  0.8928869030593831\n",
      "mi F1:  0.8970444511845785\n",
      "we F1:  0.8960594692903953\n",
      "29673 464\n",
      "Loss:  0.040756065398454666\n",
      "Loss:  0.08199802786111832\n",
      "Loss:  0.06117137894034386\n",
      "42 **********\n",
      "Epoch:  2573.418202161789  fold:  5  kers:  64\n",
      "epoch:  43\n",
      "29673 464\n",
      "Loss:  0.061371006071567535\n",
      "Loss:  0.0657539963722229\n",
      "Loss:  0.06671960651874542\n",
      "43 **********\n",
      "Epoch:  2619.7553062438965  fold:  5  kers:  64\n",
      "epoch:  44\n",
      "29673 464\n",
      "Loss:  0.07347362488508224\n",
      "Loss:  0.06135372072458267\n",
      "Loss:  0.07004162669181824\n",
      "44 **********\n",
      "Epoch:  2666.1163461208344  fold:  5  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.05686841905117035\n",
      "Eval Loss:  0.0590624175965786\n",
      "Eval Loss:  0.014390082098543644\n",
      "[[3075   22]\n",
      " [  26   95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.81      0.79      0.80       121\n",
      "\n",
      "    accuracy                           0.99      3218\n",
      "   macro avg       0.90      0.89      0.90      3218\n",
      "weighted avg       0.98      0.99      0.98      3218\n",
      "\n",
      "acc:  0.9850839030453697\n",
      "pre:  0.811965811965812\n",
      "rec:  0.7851239669421488\n",
      "ma F1:  0.895287447021403\n",
      "mi F1:  0.9850839030453697\n",
      "we F1:  0.9849633708896329\n",
      "Eval Loss:  0.14032098650932312\n",
      "Eval Loss:  0.2943519651889801\n",
      "Eval Loss:  0.23387719690799713\n",
      "Eval Loss:  0.22639471292495728\n",
      "Eval Loss:  0.2523745596408844\n",
      "Eval Loss:  0.21788667142391205\n",
      "Eval Loss:  0.24570469558238983\n",
      "Eval Loss:  0.21200913190841675\n",
      "Eval Loss:  0.19940844178199768\n",
      "Eval Loss:  0.2987429201602936\n",
      "Eval Loss:  0.18123668432235718\n",
      "Eval Loss:  0.19057944416999817\n",
      "Eval Loss:  0.21089449524879456\n",
      "Eval Loss:  0.2357199788093567\n",
      "Eval Loss:  0.16409245133399963\n",
      "Eval Loss:  0.19407524168491364\n",
      "Eval Loss:  0.2481112778186798\n",
      "Eval Loss:  0.29377877712249756\n",
      "Eval Loss:  0.18544495105743408\n",
      "Eval Loss:  0.24225261807441711\n",
      "Eval Loss:  0.20889827609062195\n",
      "Eval Loss:  0.2335694283246994\n",
      "Eval Loss:  0.19661518931388855\n",
      "Eval Loss:  0.30149298906326294\n",
      "Eval Loss:  0.2315068542957306\n",
      "Eval Loss:  0.276042103767395\n",
      "Eval Loss:  0.2700440287590027\n",
      "Eval Loss:  0.26508477330207825\n",
      "Eval Loss:  0.21866212785243988\n",
      "[[16008  1059]\n",
      " [ 1882 10724]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     17067\n",
      "           1       0.91      0.85      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.90088632763792\n",
      "pre:  0.9101247560044131\n",
      "rec:  0.850706013009678\n",
      "ma F1:  0.8976404582685151\n",
      "mi F1:  0.90088632763792\n",
      "we F1:  0.9003807730408308\n",
      "29673 464\n",
      "Loss:  0.04692120477557182\n",
      "Loss:  0.07979574799537659\n",
      "Loss:  0.06945393234491348\n",
      "45 **********\n",
      "Epoch:  2752.4784314632416  fold:  5  kers:  64\n",
      "epoch:  46\n",
      "29673 464\n",
      "Loss:  0.07679182291030884\n",
      "Loss:  0.0795445367693901\n",
      "Loss:  0.053420938551425934\n",
      "46 **********\n",
      "Epoch:  2798.8235144615173  fold:  5  kers:  64\n",
      "epoch:  47\n",
      "29673 464\n",
      "Loss:  0.04295606538653374\n",
      "Loss:  0.06692702323198318\n",
      "Loss:  0.05623995512723923\n",
      "47 **********\n",
      "Epoch:  2845.174580812454  fold:  5  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.05596884340047836\n",
      "Eval Loss:  0.07189007103443146\n",
      "Eval Loss:  0.014738252386450768\n",
      "[[3071   26]\n",
      " [  22   99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.79      0.82      0.80       121\n",
      "\n",
      "    accuracy                           0.99      3218\n",
      "   macro avg       0.89      0.90      0.90      3218\n",
      "weighted avg       0.99      0.99      0.99      3218\n",
      "\n",
      "acc:  0.9850839030453697\n",
      "pre:  0.792\n",
      "rec:  0.8181818181818182\n",
      "ma F1:  0.8985618030655267\n",
      "mi F1:  0.9850839030453697\n",
      "we F1:  0.985200352708869\n",
      "Eval Loss:  0.15144579112529755\n",
      "Eval Loss:  0.28630906343460083\n",
      "Eval Loss:  0.2218320071697235\n",
      "Eval Loss:  0.23311622440814972\n",
      "Eval Loss:  0.2712012529373169\n",
      "Eval Loss:  0.21651649475097656\n",
      "Eval Loss:  0.24496370553970337\n",
      "Eval Loss:  0.21665561199188232\n",
      "Eval Loss:  0.19212943315505981\n",
      "Eval Loss:  0.2667216360569\n",
      "Eval Loss:  0.17155766487121582\n",
      "Eval Loss:  0.1857573240995407\n",
      "Eval Loss:  0.19058628380298615\n",
      "Eval Loss:  0.24113991856575012\n",
      "Eval Loss:  0.17122815549373627\n",
      "Eval Loss:  0.19359350204467773\n",
      "Eval Loss:  0.23793187737464905\n",
      "Eval Loss:  0.2858520746231079\n",
      "Eval Loss:  0.16578979790210724\n",
      "Eval Loss:  0.26030194759368896\n",
      "Eval Loss:  0.2013697326183319\n",
      "Eval Loss:  0.24740560352802277\n",
      "Eval Loss:  0.17018811404705048\n",
      "Eval Loss:  0.2696866989135742\n",
      "Eval Loss:  0.1859433501958847\n",
      "Eval Loss:  0.2669159770011902\n",
      "Eval Loss:  0.24551883339881897\n",
      "Eval Loss:  0.25014379620552063\n",
      "Eval Loss:  0.19441252946853638\n",
      "[[16061  1006]\n",
      " [ 1867 10739]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17067\n",
      "           1       0.91      0.85      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.91      0.90      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9031779732416675\n",
      "pre:  0.9143465304384845\n",
      "rec:  0.8518959225765509\n",
      "ma F1:  0.8999598615638487\n",
      "mi F1:  0.9031779732416675\n",
      "we F1:  0.9026573429984126\n",
      "29673 464\n",
      "Loss:  0.061942510306835175\n",
      "Loss:  0.053304098546504974\n",
      "Loss:  0.06194128841161728\n",
      "48 **********\n",
      "Epoch:  2931.5526237487793  fold:  5  kers:  64\n",
      "epoch:  49\n",
      "29673 464\n",
      "Loss:  0.04816839098930359\n",
      "Loss:  0.03832913935184479\n",
      "Loss:  0.0670815110206604\n",
      "49 **********\n",
      "Epoch:  2977.9086763858795  fold:  5  kers:  64\n",
      "epoch:  50\n",
      "29673 464\n",
      "Loss:  0.041620999574661255\n",
      "Loss:  0.05939944460988045\n",
      "Loss:  0.0708705261349678\n",
      "50 **********\n",
      "Epoch:  3024.361471414566  fold:  5  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.05687876418232918\n",
      "Eval Loss:  0.07145483791828156\n",
      "Eval Loss:  0.014485779218375683\n",
      "[[3077   20]\n",
      " [  28   93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.82      0.77      0.79       121\n",
      "\n",
      "    accuracy                           0.99      3218\n",
      "   macro avg       0.91      0.88      0.89      3218\n",
      "weighted avg       0.98      0.99      0.98      3218\n",
      "\n",
      "acc:  0.9850839030453697\n",
      "pre:  0.8230088495575221\n",
      "rec:  0.768595041322314\n",
      "ma F1:  0.8935661779905573\n",
      "mi F1:  0.9850839030453697\n",
      "we F1:  0.9848385472141237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.15511810779571533\n",
      "Eval Loss:  0.2922767102718353\n",
      "Eval Loss:  0.22309502959251404\n",
      "Eval Loss:  0.21941091120243073\n",
      "Eval Loss:  0.2781291902065277\n",
      "Eval Loss:  0.22382493317127228\n",
      "Eval Loss:  0.22617076337337494\n",
      "Eval Loss:  0.24119305610656738\n",
      "Eval Loss:  0.19086487591266632\n",
      "Eval Loss:  0.26278769969940186\n",
      "Eval Loss:  0.1886788159608841\n",
      "Eval Loss:  0.1811217963695526\n",
      "Eval Loss:  0.20937688648700714\n",
      "Eval Loss:  0.235567107796669\n",
      "Eval Loss:  0.1779971420764923\n",
      "Eval Loss:  0.18338380753993988\n",
      "Eval Loss:  0.2333555966615677\n",
      "Eval Loss:  0.2720823585987091\n",
      "Eval Loss:  0.17371296882629395\n",
      "Eval Loss:  0.2543390393257141\n",
      "Eval Loss:  0.20924389362335205\n",
      "Eval Loss:  0.23509781062602997\n",
      "Eval Loss:  0.18908755481243134\n",
      "Eval Loss:  0.2569938600063324\n",
      "Eval Loss:  0.2006123811006546\n",
      "Eval Loss:  0.2624383866786957\n",
      "Eval Loss:  0.2518801987171173\n",
      "Eval Loss:  0.26750874519348145\n",
      "Eval Loss:  0.2060413658618927\n",
      "[[16239   828]\n",
      " [ 2070 10536]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17067\n",
      "           1       0.93      0.84      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.91      0.89      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9023354564755839\n",
      "pre:  0.9271383315733897\n",
      "rec:  0.8357924797715374\n",
      "ma F1:  0.898589463933037\n",
      "mi F1:  0.9023354564755839\n",
      "we F1:  0.9015196537861497\n",
      "29673 464\n",
      "Loss:  0.06578982621431351\n",
      "Loss:  0.04613451659679413\n",
      "Loss:  0.054031021893024445\n",
      "51 **********\n",
      "Epoch:  3110.6736896038055  fold:  5  kers:  64\n",
      "epoch:  52\n",
      "29673 464\n",
      "Loss:  0.07790970057249069\n",
      "Loss:  0.06133328750729561\n",
      "Loss:  0.047125715762376785\n",
      "52 **********\n",
      "Epoch:  3157.051684856415  fold:  5  kers:  64\n",
      "epoch:  53\n",
      "29673 464\n",
      "Loss:  0.04477563127875328\n",
      "Loss:  0.05261104181408882\n",
      "Loss:  0.05656241998076439\n",
      "53 **********\n",
      "Epoch:  3203.5214335918427  fold:  5  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.05821804702281952\n",
      "Eval Loss:  0.062273867428302765\n",
      "Eval Loss:  0.021281668916344643\n",
      "[[3065   32]\n",
      " [  30   91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.74      0.75      0.75       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.87      0.87      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.980733374766936\n",
      "pre:  0.7398373983739838\n",
      "rec:  0.7520661157024794\n",
      "ma F1:  0.8679443597238108\n",
      "mi F1:  0.980733374766936\n",
      "we F1:  0.9808092248106771\n",
      "Eval Loss:  0.15237896144390106\n",
      "Eval Loss:  0.2707667946815491\n",
      "Eval Loss:  0.1900772899389267\n",
      "Eval Loss:  0.18727558851242065\n",
      "Eval Loss:  0.24260881543159485\n",
      "Eval Loss:  0.18202431499958038\n",
      "Eval Loss:  0.19442139565944672\n",
      "Eval Loss:  0.21509477496147156\n",
      "Eval Loss:  0.16856525838375092\n",
      "Eval Loss:  0.2316311001777649\n",
      "Eval Loss:  0.16379575431346893\n",
      "Eval Loss:  0.1789669692516327\n",
      "Eval Loss:  0.18606777489185333\n",
      "Eval Loss:  0.2218458354473114\n",
      "Eval Loss:  0.1433413177728653\n",
      "Eval Loss:  0.19332437217235565\n",
      "Eval Loss:  0.21995648741722107\n",
      "Eval Loss:  0.24916212260723114\n",
      "Eval Loss:  0.1778818815946579\n",
      "Eval Loss:  0.2442728877067566\n",
      "Eval Loss:  0.19981370866298676\n",
      "Eval Loss:  0.2019498199224472\n",
      "Eval Loss:  0.16245460510253906\n",
      "Eval Loss:  0.2214284986257553\n",
      "Eval Loss:  0.19137555360794067\n",
      "Eval Loss:  0.2541087865829468\n",
      "Eval Loss:  0.2210187315940857\n",
      "Eval Loss:  0.24969817698001862\n",
      "Eval Loss:  0.1936289519071579\n",
      "[[16124   943]\n",
      " [ 1720 10886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17067\n",
      "           1       0.92      0.86      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9102551140767702\n",
      "pre:  0.9202806661594387\n",
      "rec:  0.8635570363319054\n",
      "ma F1:  0.90736865060657\n",
      "mi F1:  0.9102551140767703\n",
      "we F1:  0.9098269387968263\n",
      "29673 464\n",
      "Loss:  0.05838234722614288\n",
      "Loss:  0.07109348475933075\n",
      "Loss:  0.052542563527822495\n",
      "54 **********\n",
      "Epoch:  3289.955327272415  fold:  5  kers:  64\n",
      "epoch:  55\n",
      "29673 464\n",
      "Loss:  0.03928496688604355\n",
      "Loss:  0.08778053522109985\n",
      "Loss:  0.06965980678796768\n",
      "55 **********\n",
      "Epoch:  3336.3572585582733  fold:  5  kers:  64\n",
      "epoch:  56\n",
      "29673 464\n",
      "Loss:  0.06567828357219696\n",
      "Loss:  0.0395897775888443\n",
      "Loss:  0.04836601763963699\n",
      "56 **********\n",
      "Epoch:  3382.777140855789  fold:  5  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.05460747703909874\n",
      "Eval Loss:  0.08723722398281097\n",
      "Eval Loss:  0.016571814194321632\n",
      "[[3070   27]\n",
      " [  29   92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.77      0.76      0.77       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.88      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9825978868862648\n",
      "pre:  0.773109243697479\n",
      "rec:  0.7603305785123967\n",
      "ma F1:  0.8788142887884657\n",
      "mi F1:  0.9825978868862648\n",
      "we F1:  0.9825281866860648\n",
      "Eval Loss:  0.13018760085105896\n",
      "Eval Loss:  0.3046092092990875\n",
      "Eval Loss:  0.19826173782348633\n",
      "Eval Loss:  0.19301225244998932\n",
      "Eval Loss:  0.27060019969940186\n",
      "Eval Loss:  0.19970321655273438\n",
      "Eval Loss:  0.20803026854991913\n",
      "Eval Loss:  0.2331843376159668\n",
      "Eval Loss:  0.15991948544979095\n",
      "Eval Loss:  0.2495611011981964\n",
      "Eval Loss:  0.17609260976314545\n",
      "Eval Loss:  0.19327066838741302\n",
      "Eval Loss:  0.2128191590309143\n",
      "Eval Loss:  0.2339695245027542\n",
      "Eval Loss:  0.1687518060207367\n",
      "Eval Loss:  0.18619191646575928\n",
      "Eval Loss:  0.25657546520233154\n",
      "Eval Loss:  0.26732298731803894\n",
      "Eval Loss:  0.17261750996112823\n",
      "Eval Loss:  0.24395255744457245\n",
      "Eval Loss:  0.225715771317482\n",
      "Eval Loss:  0.21616165339946747\n",
      "Eval Loss:  0.17617544531822205\n",
      "Eval Loss:  0.25509142875671387\n",
      "Eval Loss:  0.1742582619190216\n",
      "Eval Loss:  0.258064866065979\n",
      "Eval Loss:  0.23078188300132751\n",
      "Eval Loss:  0.23058389127254486\n",
      "Eval Loss:  0.19508546590805054\n",
      "[[16196   871]\n",
      " [ 1839 10767]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17067\n",
      "           1       0.93      0.85      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9086711825565329\n",
      "pre:  0.9251589620209658\n",
      "rec:  0.8541170871013803\n",
      "ma F1:  0.9055080937857665\n",
      "mi F1:  0.9086711825565328\n",
      "we F1:  0.9081071984102624\n",
      "29673 464\n",
      "Loss:  0.05617779493331909\n",
      "Loss:  0.0370405912399292\n",
      "Loss:  0.06479164212942123\n",
      "57 **********\n",
      "Epoch:  3469.063428401947  fold:  5  kers:  64\n",
      "epoch:  58\n",
      "29673 464\n",
      "Loss:  0.03466106951236725\n",
      "Loss:  0.08830976486206055\n",
      "Loss:  0.07913704961538315\n",
      "58 **********\n",
      "Epoch:  3515.437434196472  fold:  5  kers:  64\n",
      "epoch:  59\n",
      "29673 464\n",
      "Loss:  0.0503845289349556\n",
      "Loss:  0.07272425293922424\n",
      "Loss:  0.05975160375237465\n",
      "59 **********\n",
      "Epoch:  3561.809444665909  fold:  5  kers:  64\n",
      "Eval Loss:  0.05674364045262337\n",
      "Eval Loss:  0.08397258818149567\n",
      "Eval Loss:  0.013331468217074871\n",
      "[[3074   23]\n",
      " [  19  102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.82      0.84      0.83       121\n",
      "\n",
      "    accuracy                           0.99      3218\n",
      "   macro avg       0.90      0.92      0.91      3218\n",
      "weighted avg       0.99      0.99      0.99      3218\n",
      "\n",
      "acc:  0.9869484151646986\n",
      "pre:  0.816\n",
      "rec:  0.8429752066115702\n",
      "ma F1:  0.9112415776823357\n",
      "mi F1:  0.9869484151646986\n",
      "we F1:  0.9870503086202603\n",
      "update!  Acc:  0.9869484151646986\n",
      "Epoch:  3565.7459194660187  fold:  5  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29479 3412\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29479 461\n",
      "Loss:  0.16245673596858978\n",
      "Loss:  0.16621242463588715\n",
      "Loss:  0.16979621350765228\n",
      "0 **********\n",
      "Epoch:  58.69805288314819  fold:  6  kers:  64\n",
      "epoch:  1\n",
      "29479 461\n",
      "Loss:  0.15875662863254547\n",
      "Loss:  0.1479576826095581\n",
      "Loss:  0.12842902541160583\n",
      "1 **********\n",
      "Epoch:  105.13987684249878  fold:  6  kers:  64\n",
      "epoch:  2\n",
      "29479 461\n",
      "Loss:  0.14032863080501556\n",
      "Loss:  0.09481532871723175\n",
      "Loss:  0.12096717208623886\n",
      "2 **********\n",
      "Epoch:  151.48196697235107  fold:  6  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.12569008767604828\n",
      "Eval Loss:  0.3420523703098297\n",
      "Eval Loss:  0.5792286396026611\n",
      "[[1897  335]\n",
      " [ 162 1018]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88      2232\n",
      "           1       0.75      0.86      0.80      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.84      0.86      0.84      3412\n",
      "weighted avg       0.86      0.85      0.86      3412\n",
      "\n",
      "acc:  0.854337631887456\n",
      "pre:  0.7524020694752402\n",
      "rec:  0.8627118644067797\n",
      "ma F1:  0.8439830775363892\n",
      "mi F1:  0.854337631887456\n",
      "we F1:  0.85637555896679\n",
      "update!  Acc:  0.854337631887456\n",
      "Eval Loss:  0.3873001039028168\n",
      "Eval Loss:  0.4306756556034088\n",
      "Eval Loss:  0.4367647171020508\n",
      "Eval Loss:  0.41156941652297974\n",
      "Eval Loss:  0.4332282543182373\n",
      "Eval Loss:  0.4495755732059479\n",
      "Eval Loss:  0.4594005346298218\n",
      "Eval Loss:  0.3820858895778656\n",
      "Eval Loss:  0.5283023715019226\n",
      "Eval Loss:  0.5306824445724487\n",
      "Eval Loss:  0.42015400528907776\n",
      "Eval Loss:  0.4852762222290039\n",
      "Eval Loss:  0.486406147480011\n",
      "Eval Loss:  0.4950089454650879\n",
      "Eval Loss:  0.4140593409538269\n",
      "Eval Loss:  0.3646504282951355\n",
      "Eval Loss:  0.44321495294570923\n",
      "Eval Loss:  0.4532029926776886\n",
      "Eval Loss:  0.4273362159729004\n",
      "Eval Loss:  0.4244699478149414\n",
      "Eval Loss:  0.374426931142807\n",
      "Eval Loss:  0.4145869314670563\n",
      "Eval Loss:  0.4304826259613037\n",
      "Eval Loss:  0.4581998884677887\n",
      "Eval Loss:  0.40469837188720703\n",
      "Eval Loss:  0.45989421010017395\n",
      "Eval Loss:  0.44045212864875793\n",
      "Eval Loss:  0.42113009095191956\n",
      "[[16027  1905]\n",
      " [ 3800  7747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85     17932\n",
      "           1       0.80      0.67      0.73     11547\n",
      "\n",
      "    accuracy                           0.81     29479\n",
      "   macro avg       0.81      0.78      0.79     29479\n",
      "weighted avg       0.81      0.81      0.80     29479\n",
      "\n",
      "acc:  0.8064724040842634\n",
      "pre:  0.8026315789473685\n",
      "rec:  0.6709101931237551\n",
      "ma F1:  0.7898968629191578\n",
      "mi F1:  0.8064724040842634\n",
      "we F1:  0.8026788472596409\n",
      "29479 461\n",
      "Loss:  0.11867670714855194\n",
      "Loss:  0.11061575263738632\n",
      "Loss:  0.140394926071167\n",
      "3 **********\n",
      "Epoch:  237.98766899108887  fold:  6  kers:  64\n",
      "epoch:  4\n",
      "29479 461\n",
      "Loss:  0.11211812496185303\n",
      "Loss:  0.07353401184082031\n",
      "Loss:  0.09612534940242767\n",
      "4 **********\n",
      "Epoch:  284.4733762741089  fold:  6  kers:  64\n",
      "epoch:  5\n",
      "29479 461\n",
      "Loss:  0.09801280498504639\n",
      "Loss:  0.11937243491411209\n",
      "Loss:  0.08509305119514465\n",
      "5 **********\n",
      "Epoch:  331.104692697525  fold:  6  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.07691165804862976\n",
      "Eval Loss:  0.24247461557388306\n",
      "Eval Loss:  0.5486992001533508\n",
      "[[1995  237]\n",
      " [ 169 1011]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      2232\n",
      "           1       0.81      0.86      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.88      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8810082063305978\n",
      "pre:  0.8100961538461539\n",
      "rec:  0.8567796610169491\n",
      "ma F1:  0.8702137483079571\n",
      "mi F1:  0.8810082063305978\n",
      "we F1:  0.8817541648118373\n",
      "update!  Acc:  0.8810082063305978\n",
      "Eval Loss:  0.32683977484703064\n",
      "Eval Loss:  0.3117377758026123\n",
      "Eval Loss:  0.3916912376880646\n",
      "Eval Loss:  0.3714889883995056\n",
      "Eval Loss:  0.302481085062027\n",
      "Eval Loss:  0.37893936038017273\n",
      "Eval Loss:  0.4333697259426117\n",
      "Eval Loss:  0.2983681261539459\n",
      "Eval Loss:  0.44921478629112244\n",
      "Eval Loss:  0.4319639503955841\n",
      "Eval Loss:  0.34102052450180054\n",
      "Eval Loss:  0.43786174058914185\n",
      "Eval Loss:  0.38688477873802185\n",
      "Eval Loss:  0.38192063570022583\n",
      "Eval Loss:  0.3160126805305481\n",
      "Eval Loss:  0.30067822337150574\n",
      "Eval Loss:  0.38464394211769104\n",
      "Eval Loss:  0.42151620984077454\n",
      "Eval Loss:  0.41037482023239136\n",
      "Eval Loss:  0.39730966091156006\n",
      "Eval Loss:  0.27807438373565674\n",
      "Eval Loss:  0.3090898096561432\n",
      "Eval Loss:  0.400125116109848\n",
      "Eval Loss:  0.3177061975002289\n",
      "Eval Loss:  0.29598355293273926\n",
      "Eval Loss:  0.3512974679470062\n",
      "Eval Loss:  0.30988481640815735\n",
      "Eval Loss:  0.33593785762786865\n",
      "[[16771  1161]\n",
      " [ 3298  8249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88     17932\n",
      "           1       0.88      0.71      0.79     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.86      0.82      0.83     29479\n",
      "weighted avg       0.85      0.85      0.85     29479\n",
      "\n",
      "acc:  0.8487397808609518\n",
      "pre:  0.8766206163655685\n",
      "rec:  0.7143846886637222\n",
      "ma F1:  0.8349459897043492\n",
      "mi F1:  0.8487397808609519\n",
      "we F1:  0.8452808121092903\n",
      "29479 461\n",
      "Loss:  0.11169246584177017\n",
      "Loss:  0.06363638490438461\n",
      "Loss:  0.0710030272603035\n",
      "6 **********\n",
      "Epoch:  417.7759518623352  fold:  6  kers:  64\n",
      "epoch:  7\n",
      "29479 461\n",
      "Loss:  0.09672567993402481\n",
      "Loss:  0.10733097046613693\n",
      "Loss:  0.05980756878852844\n",
      "7 **********\n",
      "Epoch:  464.1190390586853  fold:  6  kers:  64\n",
      "epoch:  8\n",
      "29479 461\n",
      "Loss:  0.0955914780497551\n",
      "Loss:  0.0974321961402893\n",
      "Loss:  0.07654953747987747\n",
      "8 **********\n",
      "Epoch:  510.5838017463684  fold:  6  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.05048643425107002\n",
      "Eval Loss:  0.2872755229473114\n",
      "Eval Loss:  0.4748975336551666\n",
      "[[2061  171]\n",
      " [ 204  976]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2232\n",
      "           1       0.85      0.83      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8900937866354045\n",
      "pre:  0.8509154315605929\n",
      "rec:  0.8271186440677966\n",
      "ma F1:  0.8777296882924097\n",
      "mi F1:  0.8900937866354045\n",
      "we F1:  0.8897177357180599\n",
      "update!  Acc:  0.8900937866354045\n",
      "Eval Loss:  0.339266300201416\n",
      "Eval Loss:  0.29114291071891785\n",
      "Eval Loss:  0.424119234085083\n",
      "Eval Loss:  0.34788212180137634\n",
      "Eval Loss:  0.2721746265888214\n",
      "Eval Loss:  0.3507019579410553\n",
      "Eval Loss:  0.4923563003540039\n",
      "Eval Loss:  0.2979922592639923\n",
      "Eval Loss:  0.4404717683792114\n",
      "Eval Loss:  0.4575482904911041\n",
      "Eval Loss:  0.3220171332359314\n",
      "Eval Loss:  0.4855598509311676\n",
      "Eval Loss:  0.3996092677116394\n",
      "Eval Loss:  0.40173453092575073\n",
      "Eval Loss:  0.2938901484012604\n",
      "Eval Loss:  0.303884893655777\n",
      "Eval Loss:  0.39800068736076355\n",
      "Eval Loss:  0.47402966022491455\n",
      "Eval Loss:  0.40883463621139526\n",
      "Eval Loss:  0.38968411087989807\n",
      "Eval Loss:  0.24814677238464355\n",
      "Eval Loss:  0.30344900488853455\n",
      "Eval Loss:  0.3832307457923889\n",
      "Eval Loss:  0.29571643471717834\n",
      "Eval Loss:  0.3088103234767914\n",
      "Eval Loss:  0.385873943567276\n",
      "Eval Loss:  0.28592348098754883\n",
      "Eval Loss:  0.36026808619499207\n",
      "[[17137   795]\n",
      " [ 3594  7953]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     17932\n",
      "           1       0.91      0.69      0.78     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.87      0.82      0.84     29479\n",
      "weighted avg       0.86      0.85      0.85     29479\n",
      "\n",
      "acc:  0.8511143525899794\n",
      "pre:  0.909122085048011\n",
      "rec:  0.6887503247596778\n",
      "ma F1:  0.835110225969704\n",
      "mi F1:  0.8511143525899794\n",
      "we F1:  0.8462367883031597\n",
      "29479 461\n",
      "Loss:  0.08322818577289581\n",
      "Loss:  0.0739656463265419\n",
      "Loss:  0.09679947793483734\n",
      "9 **********\n",
      "Epoch:  597.0835194587708  fold:  6  kers:  64\n",
      "epoch:  10\n",
      "29479 461\n",
      "Loss:  0.08643277734518051\n",
      "Loss:  0.0788506492972374\n",
      "Loss:  0.05791714787483215\n",
      "10 **********\n",
      "Epoch:  643.5383093357086  fold:  6  kers:  64\n",
      "epoch:  11\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07806126028299332\n",
      "Loss:  0.10503178089857101\n",
      "Loss:  0.08206231892108917\n",
      "11 **********\n",
      "Epoch:  689.865439414978  fold:  6  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.03752889856696129\n",
      "Eval Loss:  0.3443944752216339\n",
      "Eval Loss:  0.5734321475028992\n",
      "[[2120  112]\n",
      " [ 266  914]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      2232\n",
      "           1       0.89      0.77      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.86      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8892145369284877\n",
      "pre:  0.8908382066276803\n",
      "rec:  0.7745762711864407\n",
      "ma F1:  0.8733977612142481\n",
      "mi F1:  0.8892145369284877\n",
      "we F1:  0.8871948159832199\n",
      "Eval Loss:  0.31534403562545776\n",
      "Eval Loss:  0.30598482489585876\n",
      "Eval Loss:  0.397531658411026\n",
      "Eval Loss:  0.33459949493408203\n",
      "Eval Loss:  0.26886093616485596\n",
      "Eval Loss:  0.35175517201423645\n",
      "Eval Loss:  0.5007504820823669\n",
      "Eval Loss:  0.28155437111854553\n",
      "Eval Loss:  0.42973843216896057\n",
      "Eval Loss:  0.45535123348236084\n",
      "Eval Loss:  0.2994379699230194\n",
      "Eval Loss:  0.4680221676826477\n",
      "Eval Loss:  0.3748907446861267\n",
      "Eval Loss:  0.4196535050868988\n",
      "Eval Loss:  0.27512338757514954\n",
      "Eval Loss:  0.29739171266555786\n",
      "Eval Loss:  0.369681715965271\n",
      "Eval Loss:  0.4869720935821533\n",
      "Eval Loss:  0.40318968892097473\n",
      "Eval Loss:  0.3659029006958008\n",
      "Eval Loss:  0.2192884087562561\n",
      "Eval Loss:  0.316732257604599\n",
      "Eval Loss:  0.3515265882015228\n",
      "Eval Loss:  0.3150276839733124\n",
      "Eval Loss:  0.31291308999061584\n",
      "Eval Loss:  0.3685046136379242\n",
      "Eval Loss:  0.27952417731285095\n",
      "Eval Loss:  0.3602297306060791\n",
      "[[17343   589]\n",
      " [ 3805  7742]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     17932\n",
      "           1       0.93      0.67      0.78     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.87      0.82      0.83     29479\n",
      "weighted avg       0.86      0.85      0.85     29479\n",
      "\n",
      "acc:  0.8509447403236202\n",
      "pre:  0.929300204057136\n",
      "rec:  0.6704771802199706\n",
      "ma F1:  0.8332577880650268\n",
      "mi F1:  0.8509447403236202\n",
      "we F1:  0.8450202284536446\n",
      "29479 461\n",
      "Loss:  0.11036928743124008\n",
      "Loss:  0.07319018244743347\n",
      "Loss:  0.07260358333587646\n",
      "12 **********\n",
      "Epoch:  776.3182818889618  fold:  6  kers:  64\n",
      "epoch:  13\n",
      "29479 461\n",
      "Loss:  0.11281045526266098\n",
      "Loss:  0.06439539045095444\n",
      "Loss:  0.06176586076617241\n",
      "13 **********\n",
      "Epoch:  822.5067837238312  fold:  6  kers:  64\n",
      "epoch:  14\n",
      "29479 461\n",
      "Loss:  0.09385672956705093\n",
      "Loss:  0.06900490075349808\n",
      "Loss:  0.07718357443809509\n",
      "14 **********\n",
      "Epoch:  868.7421598434448  fold:  6  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.07466257363557816\n",
      "Eval Loss:  0.18092620372772217\n",
      "Eval Loss:  0.5068203806877136\n",
      "[[2013  219]\n",
      " [ 129 1051]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      2232\n",
      "           1       0.83      0.89      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.88      0.90      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8980070339976554\n",
      "pre:  0.8275590551181102\n",
      "rec:  0.8906779661016949\n",
      "ma F1:  0.8891990705747319\n",
      "mi F1:  0.8980070339976554\n",
      "we F1:  0.8988310638397168\n",
      "update!  Acc:  0.8980070339976554\n",
      "Eval Loss:  0.23702235519886017\n",
      "Eval Loss:  0.2028328776359558\n",
      "Eval Loss:  0.2818762958049774\n",
      "Eval Loss:  0.3203175961971283\n",
      "Eval Loss:  0.2578539252281189\n",
      "Eval Loss:  0.2855427861213684\n",
      "Eval Loss:  0.3495851755142212\n",
      "Eval Loss:  0.2380748838186264\n",
      "Eval Loss:  0.3056604862213135\n",
      "Eval Loss:  0.2997296452522278\n",
      "Eval Loss:  0.23786887526512146\n",
      "Eval Loss:  0.3184588551521301\n",
      "Eval Loss:  0.2264052778482437\n",
      "Eval Loss:  0.28237617015838623\n",
      "Eval Loss:  0.19943833351135254\n",
      "Eval Loss:  0.20555385947227478\n",
      "Eval Loss:  0.247103750705719\n",
      "Eval Loss:  0.3340247571468353\n",
      "Eval Loss:  0.28366905450820923\n",
      "Eval Loss:  0.28266316652297974\n",
      "Eval Loss:  0.22534795105457306\n",
      "Eval Loss:  0.24680548906326294\n",
      "Eval Loss:  0.2930791676044464\n",
      "Eval Loss:  0.24177174270153046\n",
      "Eval Loss:  0.30578792095184326\n",
      "Eval Loss:  0.21965673565864563\n",
      "Eval Loss:  0.17855165898799896\n",
      "Eval Loss:  0.22886823117733002\n",
      "[[16553  1379]\n",
      " [ 1985  9562]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91     17932\n",
      "           1       0.87      0.83      0.85     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.88      0.88      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8858848671935955\n",
      "pre:  0.8739603326935381\n",
      "rec:  0.8280938771975405\n",
      "ma F1:  0.879084454828396\n",
      "mi F1:  0.8858848671935955\n",
      "we F1:  0.8852953878782884\n",
      "29479 461\n",
      "Loss:  0.06657112389802933\n",
      "Loss:  0.09660909324884415\n",
      "Loss:  0.08346013724803925\n",
      "15 **********\n",
      "Epoch:  954.714287519455  fold:  6  kers:  64\n",
      "epoch:  16\n",
      "29479 461\n",
      "Loss:  0.06797231733798981\n",
      "Loss:  0.03341697156429291\n",
      "Loss:  0.06436745077371597\n",
      "16 **********\n",
      "Epoch:  1000.8459405899048  fold:  6  kers:  64\n",
      "epoch:  17\n",
      "29479 461\n",
      "Loss:  0.09350466728210449\n",
      "Loss:  0.036512359976768494\n",
      "Loss:  0.05939914658665657\n",
      "17 **********\n",
      "Epoch:  1046.9446821212769  fold:  6  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.04658551141619682\n",
      "Eval Loss:  0.2976483106613159\n",
      "Eval Loss:  0.5008029937744141\n",
      "[[2097  135]\n",
      " [ 234  946]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      2232\n",
      "           1       0.88      0.80      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.87      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8918522860492379\n",
      "pre:  0.8751156336725254\n",
      "rec:  0.8016949152542373\n",
      "ma F1:  0.8779650134734678\n",
      "mi F1:  0.8918522860492379\n",
      "we F1:  0.8906578116921561\n",
      "Eval Loss:  0.2354976087808609\n",
      "Eval Loss:  0.21256086230278015\n",
      "Eval Loss:  0.2769274115562439\n",
      "Eval Loss:  0.30228763818740845\n",
      "Eval Loss:  0.2317689210176468\n",
      "Eval Loss:  0.27822551131248474\n",
      "Eval Loss:  0.3760209083557129\n",
      "Eval Loss:  0.2399488091468811\n",
      "Eval Loss:  0.3188117742538452\n",
      "Eval Loss:  0.3345288336277008\n",
      "Eval Loss:  0.23480646312236786\n",
      "Eval Loss:  0.3099789619445801\n",
      "Eval Loss:  0.2568778693675995\n",
      "Eval Loss:  0.31533971428871155\n",
      "Eval Loss:  0.19731909036636353\n",
      "Eval Loss:  0.23975609242916107\n",
      "Eval Loss:  0.2869194447994232\n",
      "Eval Loss:  0.3624306321144104\n",
      "Eval Loss:  0.2850201427936554\n",
      "Eval Loss:  0.28423890471458435\n",
      "Eval Loss:  0.205025315284729\n",
      "Eval Loss:  0.24825754761695862\n",
      "Eval Loss:  0.2903713285923004\n",
      "Eval Loss:  0.23820853233337402\n",
      "Eval Loss:  0.2660127580165863\n",
      "Eval Loss:  0.23498836159706116\n",
      "Eval Loss:  0.18395884335041046\n",
      "Eval Loss:  0.25943589210510254\n",
      "[[17043   889]\n",
      " [ 2507  9040]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17932\n",
      "           1       0.91      0.78      0.84     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.89      0.87      0.88     29479\n",
      "weighted avg       0.89      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8847993486888972\n",
      "pre:  0.9104642965051868\n",
      "rec:  0.7828873300424353\n",
      "ma F1:  0.8756332523686616\n",
      "mi F1:  0.8847993486888972\n",
      "we F1:  0.8829462006386484\n",
      "29479 461\n",
      "Loss:  0.07330076396465302\n",
      "Loss:  0.1034884974360466\n",
      "Loss:  0.088831827044487\n",
      "18 **********\n",
      "Epoch:  1132.9327676296234  fold:  6  kers:  64\n",
      "epoch:  19\n",
      "29479 461\n",
      "Loss:  0.07139043509960175\n",
      "Loss:  0.05353926867246628\n",
      "Loss:  0.06939845532178879\n",
      "19 **********\n",
      "Epoch:  1179.1053113937378  fold:  6  kers:  64\n",
      "epoch:  20\n",
      "29479 461\n",
      "Loss:  0.08098901808261871\n",
      "Loss:  0.056091051548719406\n",
      "Loss:  0.07810034602880478\n",
      "20 **********\n",
      "Epoch:  1225.3925487995148  fold:  6  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.0301746167242527\n",
      "Eval Loss:  0.2879416346549988\n",
      "Eval Loss:  0.5952651500701904\n",
      "[[2123  109]\n",
      " [ 268  912]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      2232\n",
      "           1       0.89      0.77      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.86      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8895076201641267\n",
      "pre:  0.8932419196865817\n",
      "rec:  0.7728813559322034\n",
      "ma F1:  0.8735827214794211\n",
      "mi F1:  0.8895076201641267\n",
      "we F1:  0.8874167375127077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22553043067455292\n",
      "Eval Loss:  0.21636107563972473\n",
      "Eval Loss:  0.27213045954704285\n",
      "Eval Loss:  0.28584420680999756\n",
      "Eval Loss:  0.2255856841802597\n",
      "Eval Loss:  0.2769603133201599\n",
      "Eval Loss:  0.43166542053222656\n",
      "Eval Loss:  0.26120150089263916\n",
      "Eval Loss:  0.31577610969543457\n",
      "Eval Loss:  0.3518562316894531\n",
      "Eval Loss:  0.23437534272670746\n",
      "Eval Loss:  0.3316604793071747\n",
      "Eval Loss:  0.30632472038269043\n",
      "Eval Loss:  0.34171968698501587\n",
      "Eval Loss:  0.16554312407970428\n",
      "Eval Loss:  0.2270427942276001\n",
      "Eval Loss:  0.29585960507392883\n",
      "Eval Loss:  0.3554657995700836\n",
      "Eval Loss:  0.28624215722084045\n",
      "Eval Loss:  0.277197003364563\n",
      "Eval Loss:  0.18948064744472504\n",
      "Eval Loss:  0.24850249290466309\n",
      "Eval Loss:  0.29191750288009644\n",
      "Eval Loss:  0.2649184465408325\n",
      "Eval Loss:  0.2735424041748047\n",
      "Eval Loss:  0.24979570508003235\n",
      "Eval Loss:  0.20503486692905426\n",
      "Eval Loss:  0.29487547278404236\n",
      "[[17243   689]\n",
      " [ 2704  8843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     17932\n",
      "           1       0.93      0.77      0.84     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.90      0.86      0.87     29479\n",
      "weighted avg       0.89      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8849011160487127\n",
      "pre:  0.927717163239614\n",
      "rec:  0.7658266216333247\n",
      "ma F1:  0.8747297056979073\n",
      "mi F1:  0.8849011160487127\n",
      "we F1:  0.8824611884467041\n",
      "29479 461\n",
      "Loss:  0.05211891233921051\n",
      "Loss:  0.07411394268274307\n",
      "Loss:  0.05172896385192871\n",
      "21 **********\n",
      "Epoch:  1311.3666713237762  fold:  6  kers:  64\n",
      "epoch:  22\n",
      "29479 461\n",
      "Loss:  0.09968724846839905\n",
      "Loss:  0.04669433832168579\n",
      "Loss:  0.06348443776369095\n",
      "22 **********\n",
      "Epoch:  1357.5053062438965  fold:  6  kers:  64\n",
      "epoch:  23\n",
      "29479 461\n",
      "Loss:  0.042467404156923294\n",
      "Loss:  0.09712962806224823\n",
      "Loss:  0.04702555388212204\n",
      "23 **********\n",
      "Epoch:  1403.5462024211884  fold:  6  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.044496241956949234\n",
      "Eval Loss:  0.10470730066299438\n",
      "Eval Loss:  0.4842524230480194\n",
      "[[1965  267]\n",
      " [ 127 1053]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91      2232\n",
      "           1       0.80      0.89      0.84      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.89      0.88      3412\n",
      "weighted avg       0.89      0.88      0.89      3412\n",
      "\n",
      "acc:  0.8845252051582649\n",
      "pre:  0.7977272727272727\n",
      "rec:  0.8923728813559322\n",
      "ma F1:  0.8756403330249768\n",
      "mi F1:  0.8845252051582649\n",
      "we F1:  0.8858891109681994\n",
      "Eval Loss:  0.1719455122947693\n",
      "Eval Loss:  0.1876024454832077\n",
      "Eval Loss:  0.24240034818649292\n",
      "Eval Loss:  0.3200128376483917\n",
      "Eval Loss:  0.24318744242191315\n",
      "Eval Loss:  0.2671683728694916\n",
      "Eval Loss:  0.31993722915649414\n",
      "Eval Loss:  0.23859725892543793\n",
      "Eval Loss:  0.26941394805908203\n",
      "Eval Loss:  0.28003042936325073\n",
      "Eval Loss:  0.25819775462150574\n",
      "Eval Loss:  0.24538913369178772\n",
      "Eval Loss:  0.21087141335010529\n",
      "Eval Loss:  0.2734571099281311\n",
      "Eval Loss:  0.16620813310146332\n",
      "Eval Loss:  0.19758881628513336\n",
      "Eval Loss:  0.20234455168247223\n",
      "Eval Loss:  0.24202924966812134\n",
      "Eval Loss:  0.24641069769859314\n",
      "Eval Loss:  0.2771388292312622\n",
      "Eval Loss:  0.22986836731433868\n",
      "Eval Loss:  0.24046748876571655\n",
      "Eval Loss:  0.2688888609409332\n",
      "Eval Loss:  0.22036254405975342\n",
      "Eval Loss:  0.2662590742111206\n",
      "Eval Loss:  0.1828237771987915\n",
      "Eval Loss:  0.17779918015003204\n",
      "Eval Loss:  0.22915615141391754\n",
      "[[16175  1757]\n",
      " [ 1211 10336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     17932\n",
      "           1       0.85      0.90      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.89      0.90      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8993181586892364\n",
      "pre:  0.8547093359794923\n",
      "rec:  0.8951242747033862\n",
      "ma F1:  0.8952068079730798\n",
      "mi F1:  0.8993181586892364\n",
      "we F1:  0.8997026076515625\n",
      "29479 461\n",
      "Loss:  0.06229045242071152\n",
      "Loss:  0.055371154099702835\n",
      "Loss:  0.05686701089143753\n",
      "24 **********\n",
      "Epoch:  1489.441535949707  fold:  6  kers:  64\n",
      "epoch:  25\n",
      "29479 461\n",
      "Loss:  0.046263713389635086\n",
      "Loss:  0.04678036645054817\n",
      "Loss:  0.04828657954931259\n",
      "25 **********\n",
      "Epoch:  1535.4405438899994  fold:  6  kers:  64\n",
      "epoch:  26\n",
      "29479 461\n",
      "Loss:  0.07725314050912857\n",
      "Loss:  0.06945735961198807\n",
      "Loss:  0.05074441060423851\n",
      "26 **********\n",
      "Epoch:  1581.5163459777832  fold:  6  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.04785102605819702\n",
      "Eval Loss:  0.10886818915605545\n",
      "Eval Loss:  0.5115476846694946\n",
      "[[2051  181]\n",
      " [ 180 1000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2232\n",
      "           1       0.85      0.85      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8941969519343493\n",
      "pre:  0.8467400508044031\n",
      "rec:  0.847457627118644\n",
      "ma F1:  0.8831056957279597\n",
      "mi F1:  0.8941969519343493\n",
      "we F1:  0.8942075049849739\n",
      "Eval Loss:  0.18516108393669128\n",
      "Eval Loss:  0.1655910313129425\n",
      "Eval Loss:  0.22695019841194153\n",
      "Eval Loss:  0.2677637040615082\n",
      "Eval Loss:  0.23062194883823395\n",
      "Eval Loss:  0.24276624619960785\n",
      "Eval Loss:  0.3240109980106354\n",
      "Eval Loss:  0.2373645007610321\n",
      "Eval Loss:  0.23047782480716705\n",
      "Eval Loss:  0.2583681046962738\n",
      "Eval Loss:  0.22423695027828217\n",
      "Eval Loss:  0.23801301419734955\n",
      "Eval Loss:  0.19041495025157928\n",
      "Eval Loss:  0.2453259825706482\n",
      "Eval Loss:  0.15026415884494781\n",
      "Eval Loss:  0.1656334400177002\n",
      "Eval Loss:  0.17618997395038605\n",
      "Eval Loss:  0.24799036979675293\n",
      "Eval Loss:  0.2227180153131485\n",
      "Eval Loss:  0.2392662763595581\n",
      "Eval Loss:  0.19563090801239014\n",
      "Eval Loss:  0.22623559832572937\n",
      "Eval Loss:  0.2634125053882599\n",
      "Eval Loss:  0.21508371829986572\n",
      "Eval Loss:  0.27078843116760254\n",
      "Eval Loss:  0.16314610838890076\n",
      "Eval Loss:  0.1703415811061859\n",
      "Eval Loss:  0.2199326902627945\n",
      "[[16530  1402]\n",
      " [ 1374 10173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     17932\n",
      "           1       0.88      0.88      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.905831269717426\n",
      "pre:  0.8788768898488121\n",
      "rec:  0.8810080540400104\n",
      "ma F1:  0.9012385894399091\n",
      "mi F1:  0.905831269717426\n",
      "we F1:  0.9058514986064885\n",
      "29479 461\n",
      "Loss:  0.05419348180294037\n",
      "Loss:  0.054292548447847366\n",
      "Loss:  0.05671121925115585\n",
      "27 **********\n",
      "Epoch:  1667.534351348877  fold:  6  kers:  64\n",
      "epoch:  28\n",
      "29479 461\n",
      "Loss:  0.07535208016633987\n",
      "Loss:  0.06287968903779984\n",
      "Loss:  0.07523294538259506\n",
      "28 **********\n",
      "Epoch:  1713.5931994915009  fold:  6  kers:  64\n",
      "epoch:  29\n",
      "29479 461\n",
      "Loss:  0.096904456615448\n",
      "Loss:  0.07461696118116379\n",
      "Loss:  0.05754002183675766\n",
      "29 **********\n",
      "Epoch:  1759.790676832199  fold:  6  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.02398531883955002\n",
      "Eval Loss:  0.18132944405078888\n",
      "Eval Loss:  0.4364156126976013\n",
      "[[2047  185]\n",
      " [ 203  977]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      2232\n",
      "           1       0.84      0.83      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.87      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8862837045720985\n",
      "pre:  0.8407917383820999\n",
      "rec:  0.8279661016949152\n",
      "ma F1:  0.8738805682927173\n",
      "mi F1:  0.8862837045720985\n",
      "we F1:  0.8860750536814175\n",
      "Eval Loss:  0.1631370186805725\n",
      "Eval Loss:  0.16091178357601166\n",
      "Eval Loss:  0.2000053972005844\n",
      "Eval Loss:  0.2575627267360687\n",
      "Eval Loss:  0.2137291580438614\n",
      "Eval Loss:  0.234373539686203\n",
      "Eval Loss:  0.3122907280921936\n",
      "Eval Loss:  0.20933149755001068\n",
      "Eval Loss:  0.2299415022134781\n",
      "Eval Loss:  0.24872829020023346\n",
      "Eval Loss:  0.21855056285858154\n",
      "Eval Loss:  0.23056016862392426\n",
      "Eval Loss:  0.2206701636314392\n",
      "Eval Loss:  0.2610686421394348\n",
      "Eval Loss:  0.13188396394252777\n",
      "Eval Loss:  0.16064493358135223\n",
      "Eval Loss:  0.20344802737236023\n",
      "Eval Loss:  0.28094884753227234\n",
      "Eval Loss:  0.21566486358642578\n",
      "Eval Loss:  0.19419747591018677\n",
      "Eval Loss:  0.1811523139476776\n",
      "Eval Loss:  0.21767064929008484\n",
      "Eval Loss:  0.24170278012752533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2141130566596985\n",
      "Eval Loss:  0.24856863915920258\n",
      "Eval Loss:  0.15699361264705658\n",
      "Eval Loss:  0.14814668893814087\n",
      "Eval Loss:  0.22296220064163208\n",
      "[[16745  1187]\n",
      " [ 1500 10047]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     17932\n",
      "           1       0.89      0.87      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.908850368058618\n",
      "pre:  0.8943386149189959\n",
      "rec:  0.8700961288646402\n",
      "ma F1:  0.9038885610089584\n",
      "mi F1:  0.9088503680586179\n",
      "we F1:  0.9086185009928456\n",
      "29479 461\n",
      "Loss:  0.06336139142513275\n",
      "Loss:  0.06600989401340485\n",
      "Loss:  0.06811963766813278\n",
      "30 **********\n",
      "Epoch:  1845.9333488941193  fold:  6  kers:  64\n",
      "epoch:  31\n",
      "29479 461\n",
      "Loss:  0.06101448833942413\n",
      "Loss:  0.06221618503332138\n",
      "Loss:  0.05805538594722748\n",
      "31 **********\n",
      "Epoch:  1892.04306101799  fold:  6  kers:  64\n",
      "epoch:  32\n",
      "29479 461\n",
      "Loss:  0.03747320920228958\n",
      "Loss:  0.050554148852825165\n",
      "Loss:  0.06692031025886536\n",
      "32 **********\n",
      "Epoch:  1938.2744472026825  fold:  6  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.04411204904317856\n",
      "Eval Loss:  0.10093250870704651\n",
      "Eval Loss:  0.4288138747215271\n",
      "[[2017  215]\n",
      " [ 140 1040]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      2232\n",
      "           1       0.83      0.88      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.88      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8959554513481829\n",
      "pre:  0.8286852589641435\n",
      "rec:  0.8813559322033898\n",
      "ma F1:  0.8866627086663832\n",
      "mi F1:  0.8959554513481829\n",
      "we F1:  0.8966688143994983\n",
      "Eval Loss:  0.1803494095802307\n",
      "Eval Loss:  0.1768800914287567\n",
      "Eval Loss:  0.21036165952682495\n",
      "Eval Loss:  0.26527297496795654\n",
      "Eval Loss:  0.23275010287761688\n",
      "Eval Loss:  0.2799113392829895\n",
      "Eval Loss:  0.3300339877605438\n",
      "Eval Loss:  0.25292733311653137\n",
      "Eval Loss:  0.23421894013881683\n",
      "Eval Loss:  0.22897285223007202\n",
      "Eval Loss:  0.2229274958372116\n",
      "Eval Loss:  0.2337874472141266\n",
      "Eval Loss:  0.21503566205501556\n",
      "Eval Loss:  0.26159757375717163\n",
      "Eval Loss:  0.13124944269657135\n",
      "Eval Loss:  0.17840373516082764\n",
      "Eval Loss:  0.1696886569261551\n",
      "Eval Loss:  0.24676205217838287\n",
      "Eval Loss:  0.21412843465805054\n",
      "Eval Loss:  0.2446313500404358\n",
      "Eval Loss:  0.19480690360069275\n",
      "Eval Loss:  0.2357172966003418\n",
      "Eval Loss:  0.2295731008052826\n",
      "Eval Loss:  0.21344061195850372\n",
      "Eval Loss:  0.2744166851043701\n",
      "Eval Loss:  0.17572596669197083\n",
      "Eval Loss:  0.16822615265846252\n",
      "Eval Loss:  0.22174249589443207\n",
      "[[16306  1626]\n",
      " [ 1123 10424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92     17932\n",
      "           1       0.87      0.90      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.90      0.91      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9067471759557652\n",
      "pre:  0.8650622406639004\n",
      "rec:  0.9027453018099939\n",
      "ma F1:  0.9028805629954818\n",
      "mi F1:  0.9067471759557652\n",
      "we F1:  0.9070778298692338\n",
      "29479 461\n",
      "Loss:  0.046529676765203476\n",
      "Loss:  0.04778910428285599\n",
      "Loss:  0.04574006050825119\n",
      "33 **********\n",
      "Epoch:  2024.7093381881714  fold:  6  kers:  64\n",
      "epoch:  34\n",
      "29479 461\n",
      "Loss:  0.08644109219312668\n",
      "Loss:  0.038588110357522964\n",
      "Loss:  0.0447249673306942\n",
      "34 **********\n",
      "Epoch:  2071.0524258613586  fold:  6  kers:  64\n",
      "epoch:  35\n",
      "29479 461\n",
      "Loss:  0.05485699325799942\n",
      "Loss:  0.05112352967262268\n",
      "Loss:  0.06682702153921127\n",
      "35 **********\n",
      "Epoch:  2117.1611409187317  fold:  6  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.0330771803855896\n",
      "Eval Loss:  0.1454252004623413\n",
      "Eval Loss:  0.4289166033267975\n",
      "[[2049  183]\n",
      " [ 159 1021]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      2232\n",
      "           1       0.85      0.87      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8997655334114889\n",
      "pre:  0.8480066445182725\n",
      "rec:  0.8652542372881356\n",
      "ma F1:  0.8897582985670234\n",
      "mi F1:  0.8997655334114889\n",
      "we F1:  0.899999165353383\n",
      "update!  Acc:  0.8997655334114889\n",
      "Eval Loss:  0.18217308819293976\n",
      "Eval Loss:  0.15906073153018951\n",
      "Eval Loss:  0.19066520035266876\n",
      "Eval Loss:  0.2638775110244751\n",
      "Eval Loss:  0.24532325565814972\n",
      "Eval Loss:  0.25853630900382996\n",
      "Eval Loss:  0.2755794823169708\n",
      "Eval Loss:  0.22770968079566956\n",
      "Eval Loss:  0.202579066157341\n",
      "Eval Loss:  0.23598550260066986\n",
      "Eval Loss:  0.22680649161338806\n",
      "Eval Loss:  0.24802175164222717\n",
      "Eval Loss:  0.20905937254428864\n",
      "Eval Loss:  0.22211109101772308\n",
      "Eval Loss:  0.12033339589834213\n",
      "Eval Loss:  0.15906357765197754\n",
      "Eval Loss:  0.17254433035850525\n",
      "Eval Loss:  0.25061583518981934\n",
      "Eval Loss:  0.21177704632282257\n",
      "Eval Loss:  0.20280085504055023\n",
      "Eval Loss:  0.17441147565841675\n",
      "Eval Loss:  0.2221582978963852\n",
      "Eval Loss:  0.22677719593048096\n",
      "Eval Loss:  0.20242652297019958\n",
      "Eval Loss:  0.2586260735988617\n",
      "Eval Loss:  0.1609671264886856\n",
      "Eval Loss:  0.16443265974521637\n",
      "Eval Loss:  0.18763935565948486\n",
      "[[16412  1520]\n",
      " [ 1136 10411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     17932\n",
      "           1       0.87      0.90      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.90      0.91      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9099019641100444\n",
      "pre:  0.8726007878635488\n",
      "rec:  0.9016194682601542\n",
      "ma F1:  0.9060068707849311\n",
      "mi F1:  0.9099019641100444\n",
      "we F1:  0.910151208542113\n",
      "29479 461\n",
      "Loss:  0.0544656440615654\n",
      "Loss:  0.05384517088532448\n",
      "Loss:  0.04460085555911064\n",
      "36 **********\n",
      "Epoch:  2203.5012850761414  fold:  6  kers:  64\n",
      "epoch:  37\n",
      "29479 461\n",
      "Loss:  0.0657813549041748\n",
      "Loss:  0.05698531121015549\n",
      "Loss:  0.0636415034532547\n",
      "37 **********\n",
      "Epoch:  2249.65687417984  fold:  6  kers:  64\n",
      "epoch:  38\n",
      "29479 461\n",
      "Loss:  0.051963239908218384\n",
      "Loss:  0.04309876263141632\n",
      "Loss:  0.06879185885190964\n",
      "38 **********\n",
      "Epoch:  2295.8583409786224  fold:  6  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.02000034786760807\n",
      "Eval Loss:  0.18220098316669464\n",
      "Eval Loss:  0.4254406690597534\n",
      "[[2049  183]\n",
      " [ 228  952]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2232\n",
      "           1       0.84      0.81      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8795427901524033\n",
      "pre:  0.8387665198237886\n",
      "rec:  0.8067796610169492\n",
      "ma F1:  0.8656555858764832\n",
      "mi F1:  0.8795427901524033\n",
      "we F1:  0.8789731236141932\n",
      "Eval Loss:  0.16826677322387695\n",
      "Eval Loss:  0.14897331595420837\n",
      "Eval Loss:  0.2095412313938141\n",
      "Eval Loss:  0.25310686230659485\n",
      "Eval Loss:  0.1962919384241104\n",
      "Eval Loss:  0.23494015634059906\n",
      "Eval Loss:  0.299353688955307\n",
      "Eval Loss:  0.21610116958618164\n",
      "Eval Loss:  0.2277648150920868\n",
      "Eval Loss:  0.24318544566631317\n",
      "Eval Loss:  0.22231513261795044\n",
      "Eval Loss:  0.20178619027137756\n",
      "Eval Loss:  0.22790832817554474\n",
      "Eval Loss:  0.21996788680553436\n",
      "Eval Loss:  0.12106888741254807\n",
      "Eval Loss:  0.178177610039711\n",
      "Eval Loss:  0.1488819569349289\n",
      "Eval Loss:  0.24837814271450043\n",
      "Eval Loss:  0.18258604407310486\n",
      "Eval Loss:  0.1852182000875473\n",
      "Eval Loss:  0.16859781742095947\n",
      "Eval Loss:  0.21032246947288513\n",
      "Eval Loss:  0.23416447639465332\n",
      "Eval Loss:  0.20007139444351196\n",
      "Eval Loss:  0.22873912751674652\n",
      "Eval Loss:  0.1335565447807312\n",
      "Eval Loss:  0.14196175336837769\n",
      "Eval Loss:  0.2069823145866394\n",
      "[[16621  1311]\n",
      " [ 1226 10321]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17932\n",
      "           1       0.89      0.89      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9139387360493911\n",
      "pre:  0.8872936726272352\n",
      "rec:  0.8938252359920326\n",
      "ma F1:  0.909819981369564\n",
      "mi F1:  0.9139387360493911\n",
      "we F1:  0.9139943065490396\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07542604207992554\n",
      "Loss:  0.052857737988233566\n",
      "Loss:  0.1087040901184082\n",
      "39 **********\n",
      "Epoch:  2382.146624803543  fold:  6  kers:  64\n",
      "epoch:  40\n",
      "29479 461\n",
      "Loss:  0.038828957825899124\n",
      "Loss:  0.03322867304086685\n",
      "Loss:  0.04687800258398056\n",
      "40 **********\n",
      "Epoch:  2428.4458289146423  fold:  6  kers:  64\n",
      "epoch:  41\n",
      "29479 461\n",
      "Loss:  0.09225578606128693\n",
      "Loss:  0.03971157595515251\n",
      "Loss:  0.04462512582540512\n",
      "41 **********\n",
      "Epoch:  2474.741044998169  fold:  6  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.027596471831202507\n",
      "Eval Loss:  0.18427181243896484\n",
      "Eval Loss:  0.36888107657432556\n",
      "[[2092  140]\n",
      " [ 219  961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92      2232\n",
      "           1       0.87      0.81      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8947831184056272\n",
      "pre:  0.8728428701180745\n",
      "rec:  0.8144067796610169\n",
      "ma F1:  0.881795108420362\n",
      "mi F1:  0.8947831184056271\n",
      "we F1:  0.8938759099274345\n",
      "Eval Loss:  0.16280341148376465\n",
      "Eval Loss:  0.150800883769989\n",
      "Eval Loss:  0.19316816329956055\n",
      "Eval Loss:  0.23844590783119202\n",
      "Eval Loss:  0.20831291377544403\n",
      "Eval Loss:  0.2187170833349228\n",
      "Eval Loss:  0.3058314919471741\n",
      "Eval Loss:  0.20327910780906677\n",
      "Eval Loss:  0.2031652331352234\n",
      "Eval Loss:  0.24314886331558228\n",
      "Eval Loss:  0.20766977965831757\n",
      "Eval Loss:  0.22187356650829315\n",
      "Eval Loss:  0.234514981508255\n",
      "Eval Loss:  0.23151220381259918\n",
      "Eval Loss:  0.09805609285831451\n",
      "Eval Loss:  0.13462547957897186\n",
      "Eval Loss:  0.13800080120563507\n",
      "Eval Loss:  0.21535658836364746\n",
      "Eval Loss:  0.19426566362380981\n",
      "Eval Loss:  0.1813374012708664\n",
      "Eval Loss:  0.1678706854581833\n",
      "Eval Loss:  0.21073807775974274\n",
      "Eval Loss:  0.22065521776676178\n",
      "Eval Loss:  0.19672606885433197\n",
      "Eval Loss:  0.25136420130729675\n",
      "Eval Loss:  0.13499955832958221\n",
      "Eval Loss:  0.13753998279571533\n",
      "Eval Loss:  0.17794321477413177\n",
      "[[16782  1150]\n",
      " [ 1292 10255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     17932\n",
      "           1       0.90      0.89      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9171613691102141\n",
      "pre:  0.8991670320035072\n",
      "rec:  0.8881094656620767\n",
      "ma F1:  0.9128910067794557\n",
      "mi F1:  0.9171613691102141\n",
      "we F1:  0.9170684640311628\n",
      "29479 461\n",
      "Loss:  0.06788982450962067\n",
      "Loss:  0.06639088690280914\n",
      "Loss:  0.08812810480594635\n",
      "42 **********\n",
      "Epoch:  2561.1121060848236  fold:  6  kers:  64\n",
      "epoch:  43\n",
      "29479 461\n",
      "Loss:  0.08383630216121674\n",
      "Loss:  0.055977508425712585\n",
      "Loss:  0.07056478410959244\n",
      "43 **********\n",
      "Epoch:  2607.364436864853  fold:  6  kers:  64\n",
      "epoch:  44\n",
      "29479 461\n",
      "Loss:  0.044413644820451736\n",
      "Loss:  0.06206153333187103\n",
      "Loss:  0.07317151874303818\n",
      "44 **********\n",
      "Epoch:  2653.6626448631287  fold:  6  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.026648715138435364\n",
      "Eval Loss:  0.12947984039783478\n",
      "Eval Loss:  0.3702726364135742\n",
      "[[2064  168]\n",
      " [ 221  959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2232\n",
      "           1       0.85      0.81      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.87      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8859906213364596\n",
      "pre:  0.8509316770186336\n",
      "rec:  0.8127118644067797\n",
      "ma F1:  0.872631821278359\n",
      "mi F1:  0.8859906213364596\n",
      "we F1:  0.8853498825101435\n",
      "Eval Loss:  0.15988674759864807\n",
      "Eval Loss:  0.1434159129858017\n",
      "Eval Loss:  0.24075257778167725\n",
      "Eval Loss:  0.27206844091415405\n",
      "Eval Loss:  0.220278799533844\n",
      "Eval Loss:  0.221650168299675\n",
      "Eval Loss:  0.30720067024230957\n",
      "Eval Loss:  0.19041480123996735\n",
      "Eval Loss:  0.20482192933559418\n",
      "Eval Loss:  0.2610586881637573\n",
      "Eval Loss:  0.22976434230804443\n",
      "Eval Loss:  0.21842755377292633\n",
      "Eval Loss:  0.19975124299526215\n",
      "Eval Loss:  0.1981572061777115\n",
      "Eval Loss:  0.1190773993730545\n",
      "Eval Loss:  0.15264396369457245\n",
      "Eval Loss:  0.13924476504325867\n",
      "Eval Loss:  0.19415609538555145\n",
      "Eval Loss:  0.18100500106811523\n",
      "Eval Loss:  0.18834520876407623\n",
      "Eval Loss:  0.1786457896232605\n",
      "Eval Loss:  0.22633619606494904\n",
      "Eval Loss:  0.22015748918056488\n",
      "Eval Loss:  0.20562171936035156\n",
      "Eval Loss:  0.25669065117836\n",
      "Eval Loss:  0.11239239573478699\n",
      "Eval Loss:  0.149008646607399\n",
      "Eval Loss:  0.1761101931333542\n",
      "[[16413  1519]\n",
      " [ 1003 10544]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     17932\n",
      "           1       0.87      0.91      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.92      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9144475728484684\n",
      "pre:  0.8740777584348836\n",
      "rec:  0.9131376115008227\n",
      "ma F1:  0.9109165565615711\n",
      "mi F1:  0.9144475728484684\n",
      "we F1:  0.9147580183083489\n",
      "29479 461\n",
      "Loss:  0.06816552579402924\n",
      "Loss:  0.06268304586410522\n",
      "Loss:  0.06616190820932388\n",
      "45 **********\n",
      "Epoch:  2740.270074367523  fold:  6  kers:  64\n",
      "epoch:  46\n",
      "29479 461\n",
      "Loss:  0.06417024880647659\n",
      "Loss:  0.04197701811790466\n",
      "Loss:  0.02464468404650688\n",
      "46 **********\n",
      "Epoch:  2786.546340942383  fold:  6  kers:  64\n",
      "epoch:  47\n",
      "29479 461\n",
      "Loss:  0.05807274580001831\n",
      "Loss:  0.05140259861946106\n",
      "Loss:  0.054788507521152496\n",
      "47 **********\n",
      "Epoch:  2832.745812892914  fold:  6  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.024852490052580833\n",
      "Eval Loss:  0.08921018242835999\n",
      "Eval Loss:  0.41951724886894226\n",
      "[[2014  218]\n",
      " [ 208  972]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      2232\n",
      "           1       0.82      0.82      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.86      0.86      0.86      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8751465416178195\n",
      "pre:  0.8168067226890756\n",
      "rec:  0.823728813559322\n",
      "ma F1:  0.8623043999704434\n",
      "mi F1:  0.8751465416178195\n",
      "we F1:  0.8752697867391955\n",
      "Eval Loss:  0.18178558349609375\n",
      "Eval Loss:  0.16800415515899658\n",
      "Eval Loss:  0.2746497094631195\n",
      "Eval Loss:  0.2561848759651184\n",
      "Eval Loss:  0.18042095005512238\n",
      "Eval Loss:  0.20112529397010803\n",
      "Eval Loss:  0.35422658920288086\n",
      "Eval Loss:  0.1832112967967987\n",
      "Eval Loss:  0.2533600926399231\n",
      "Eval Loss:  0.2698509693145752\n",
      "Eval Loss:  0.22894126176834106\n",
      "Eval Loss:  0.2580592930316925\n",
      "Eval Loss:  0.21247786283493042\n",
      "Eval Loss:  0.2211691290140152\n",
      "Eval Loss:  0.1308770477771759\n",
      "Eval Loss:  0.1663505584001541\n",
      "Eval Loss:  0.12099700421094894\n",
      "Eval Loss:  0.22291849553585052\n",
      "Eval Loss:  0.17709162831306458\n",
      "Eval Loss:  0.21121391654014587\n",
      "Eval Loss:  0.1784331500530243\n",
      "Eval Loss:  0.2433408498764038\n",
      "Eval Loss:  0.2349848449230194\n",
      "Eval Loss:  0.21158917248249054\n",
      "Eval Loss:  0.2859674394130707\n",
      "Eval Loss:  0.11422108858823776\n",
      "Eval Loss:  0.14573006331920624\n",
      "Eval Loss:  0.20111478865146637\n",
      "[[16659  1273]\n",
      " [ 1271 10276]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17932\n",
      "           1       0.89      0.89      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9137012788764883\n",
      "pre:  0.8897740064074812\n",
      "rec:  0.8899281198579718\n",
      "ma F1:  0.9094562292505755\n",
      "mi F1:  0.9137012788764883\n",
      "we F1:  0.9137026089876041\n",
      "29479 461\n",
      "Loss:  0.051362354308366776\n",
      "Loss:  0.05856678634881973\n",
      "Loss:  0.05063147842884064\n",
      "48 **********\n",
      "Epoch:  2919.0909440517426  fold:  6  kers:  64\n",
      "epoch:  49\n",
      "29479 461\n",
      "Loss:  0.0618734173476696\n",
      "Loss:  0.05570202320814133\n",
      "Loss:  0.06753171980381012\n",
      "49 **********\n",
      "Epoch:  2965.2624905109406  fold:  6  kers:  64\n",
      "epoch:  50\n",
      "29479 461\n",
      "Loss:  0.02983054518699646\n",
      "Loss:  0.04096008837223053\n",
      "Loss:  0.04846148192882538\n",
      "50 **********\n",
      "Epoch:  3011.5208048820496  fold:  6  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.01388149056583643\n",
      "Eval Loss:  0.3214767575263977\n",
      "Eval Loss:  0.380668967962265\n",
      "[[2102  130]\n",
      " [ 280  900]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      2232\n",
      "           1       0.87      0.76      0.81      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.88      0.85      0.86      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8798358733880423\n",
      "pre:  0.8737864077669902\n",
      "rec:  0.7627118644067796\n",
      "ma F1:  0.8628098233391586\n",
      "mi F1:  0.8798358733880421\n",
      "we F1:  0.8777111583237056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18178021907806396\n",
      "Eval Loss:  0.17869390547275543\n",
      "Eval Loss:  0.252442866563797\n",
      "Eval Loss:  0.2612714171409607\n",
      "Eval Loss:  0.19873367249965668\n",
      "Eval Loss:  0.19116352498531342\n",
      "Eval Loss:  0.34800854325294495\n",
      "Eval Loss:  0.19486676156520844\n",
      "Eval Loss:  0.23164711892604828\n",
      "Eval Loss:  0.2778545022010803\n",
      "Eval Loss:  0.23002299666404724\n",
      "Eval Loss:  0.25127798318862915\n",
      "Eval Loss:  0.20859000086784363\n",
      "Eval Loss:  0.21160899102687836\n",
      "Eval Loss:  0.11699233949184418\n",
      "Eval Loss:  0.13847489655017853\n",
      "Eval Loss:  0.13833914697170258\n",
      "Eval Loss:  0.2377355396747589\n",
      "Eval Loss:  0.16853190958499908\n",
      "Eval Loss:  0.1896311193704605\n",
      "Eval Loss:  0.16140490770339966\n",
      "Eval Loss:  0.22219723463058472\n",
      "Eval Loss:  0.2387111485004425\n",
      "Eval Loss:  0.20298641920089722\n",
      "Eval Loss:  0.2739031910896301\n",
      "Eval Loss:  0.13604380190372467\n",
      "Eval Loss:  0.12908025085926056\n",
      "Eval Loss:  0.1868799328804016\n",
      "[[16911  1021]\n",
      " [ 1414 10133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17932\n",
      "           1       0.91      0.88      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9173988262831168\n",
      "pre:  0.9084633315402546\n",
      "rec:  0.8775439508097341\n",
      "ma F1:  0.9127882788732917\n",
      "mi F1:  0.9173988262831168\n",
      "we F1:  0.917131498880924\n",
      "29479 461\n",
      "Loss:  0.05030713975429535\n",
      "Loss:  0.07884526252746582\n",
      "Loss:  0.06955514848232269\n",
      "51 **********\n",
      "Epoch:  3097.690404891968  fold:  6  kers:  64\n",
      "epoch:  52\n",
      "29479 461\n",
      "Loss:  0.05251002684235573\n",
      "Loss:  0.07186492532491684\n",
      "Loss:  0.043330419808626175\n",
      "52 **********\n",
      "Epoch:  3143.946725130081  fold:  6  kers:  64\n",
      "epoch:  53\n",
      "29479 461\n",
      "Loss:  0.08136123418807983\n",
      "Loss:  0.056529223918914795\n",
      "Loss:  0.03672967851161957\n",
      "53 **********\n",
      "Epoch:  3190.1561703681946  fold:  6  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.02116854302585125\n",
      "Eval Loss:  0.15282419323921204\n",
      "Eval Loss:  0.3477577865123749\n",
      "[[2049  183]\n",
      " [ 230  950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2232\n",
      "           1       0.84      0.81      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.86      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8789566236811255\n",
      "pre:  0.8384819064430715\n",
      "rec:  0.8050847457627118\n",
      "ma F1:  0.8649450164717212\n",
      "mi F1:  0.8789566236811255\n",
      "we F1:  0.878357401170805\n",
      "Eval Loss:  0.15768320858478546\n",
      "Eval Loss:  0.1668447107076645\n",
      "Eval Loss:  0.24805791676044464\n",
      "Eval Loss:  0.27763205766677856\n",
      "Eval Loss:  0.18522809445858002\n",
      "Eval Loss:  0.23012451827526093\n",
      "Eval Loss:  0.3318783640861511\n",
      "Eval Loss:  0.18787865340709686\n",
      "Eval Loss:  0.21162763237953186\n",
      "Eval Loss:  0.268656849861145\n",
      "Eval Loss:  0.23547525703907013\n",
      "Eval Loss:  0.2382868081331253\n",
      "Eval Loss:  0.20366111397743225\n",
      "Eval Loss:  0.2104133516550064\n",
      "Eval Loss:  0.1399756371974945\n",
      "Eval Loss:  0.16050200164318085\n",
      "Eval Loss:  0.13520517945289612\n",
      "Eval Loss:  0.23728032410144806\n",
      "Eval Loss:  0.17853258550167084\n",
      "Eval Loss:  0.1785256713628769\n",
      "Eval Loss:  0.16370229423046112\n",
      "Eval Loss:  0.2343115508556366\n",
      "Eval Loss:  0.23611585795879364\n",
      "Eval Loss:  0.21018490195274353\n",
      "Eval Loss:  0.26965031027793884\n",
      "Eval Loss:  0.12798766791820526\n",
      "Eval Loss:  0.1492970585823059\n",
      "Eval Loss:  0.16410943865776062\n",
      "[[16513  1419]\n",
      " [ 1128 10419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     17932\n",
      "           1       0.88      0.90      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9135995115166728\n",
      "pre:  0.8801317790167258\n",
      "rec:  0.9023122889062094\n",
      "ma F1:  0.9097423908017963\n",
      "mi F1:  0.9135995115166727\n",
      "we F1:  0.9137836963095889\n",
      "29479 461\n",
      "Loss:  0.08444955945014954\n",
      "Loss:  0.04069274663925171\n",
      "Loss:  0.06545641273260117\n",
      "54 **********\n",
      "Epoch:  3276.5631358623505  fold:  6  kers:  64\n",
      "epoch:  55\n",
      "29479 461\n",
      "Loss:  0.057507384568452835\n",
      "Loss:  0.03721626102924347\n",
      "Loss:  0.04463038221001625\n",
      "55 **********\n",
      "Epoch:  3322.7596158981323  fold:  6  kers:  64\n",
      "epoch:  56\n",
      "29479 461\n",
      "Loss:  0.05919567868113518\n",
      "Loss:  0.07094912976026535\n",
      "Loss:  0.08473819494247437\n",
      "56 **********\n",
      "Epoch:  3368.9969861507416  fold:  6  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.017906703054904938\n",
      "Eval Loss:  0.21463489532470703\n",
      "Eval Loss:  0.33150190114974976\n",
      "[[2070  162]\n",
      " [ 247  933]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      2232\n",
      "           1       0.85      0.79      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8801289566236812\n",
      "pre:  0.852054794520548\n",
      "rec:  0.7906779661016949\n",
      "ma F1:  0.8651549549593075\n",
      "mi F1:  0.8801289566236812\n",
      "we F1:  0.8790095281791149\n",
      "Eval Loss:  0.15782831609249115\n",
      "Eval Loss:  0.16147500276565552\n",
      "Eval Loss:  0.22660239040851593\n",
      "Eval Loss:  0.26774337887763977\n",
      "Eval Loss:  0.18824096024036407\n",
      "Eval Loss:  0.18918874859809875\n",
      "Eval Loss:  0.30808091163635254\n",
      "Eval Loss:  0.18394728004932404\n",
      "Eval Loss:  0.22894501686096191\n",
      "Eval Loss:  0.24558156728744507\n",
      "Eval Loss:  0.23747698962688446\n",
      "Eval Loss:  0.19524744153022766\n",
      "Eval Loss:  0.19910649955272675\n",
      "Eval Loss:  0.23033644258975983\n",
      "Eval Loss:  0.13878878951072693\n",
      "Eval Loss:  0.1799020618200302\n",
      "Eval Loss:  0.10229478031396866\n",
      "Eval Loss:  0.23443689942359924\n",
      "Eval Loss:  0.1891147941350937\n",
      "Eval Loss:  0.18749567866325378\n",
      "Eval Loss:  0.13275457918643951\n",
      "Eval Loss:  0.2192736566066742\n",
      "Eval Loss:  0.21821345388889313\n",
      "Eval Loss:  0.20251522958278656\n",
      "Eval Loss:  0.2570376396179199\n",
      "Eval Loss:  0.12105918675661087\n",
      "Eval Loss:  0.1408320665359497\n",
      "Eval Loss:  0.20290544629096985\n",
      "[[16656  1276]\n",
      " [ 1180 10367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17932\n",
      "           1       0.89      0.90      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9166864547644086\n",
      "pre:  0.8904062526840162\n",
      "rec:  0.8978089547068503\n",
      "ma F1:  0.9127137764534783\n",
      "mi F1:  0.9166864547644086\n",
      "we F1:  0.9167470966976012\n",
      "29479 461\n",
      "Loss:  0.0416790209710598\n",
      "Loss:  0.0393713042140007\n",
      "Loss:  0.05055549740791321\n",
      "57 **********\n",
      "Epoch:  3455.44583940506  fold:  6  kers:  64\n",
      "epoch:  58\n",
      "29479 461\n",
      "Loss:  0.03747729957103729\n",
      "Loss:  0.07228802144527435\n",
      "Loss:  0.05380614474415779\n",
      "58 **********\n",
      "Epoch:  3501.713130235672  fold:  6  kers:  64\n",
      "epoch:  59\n",
      "29479 461\n",
      "Loss:  0.07591506838798523\n",
      "Loss:  0.05839153379201889\n",
      "Loss:  0.0762351006269455\n",
      "59 **********\n",
      "Epoch:  3547.960474252701  fold:  6  kers:  64\n",
      "Eval Loss:  0.013492275960743427\n",
      "Eval Loss:  0.1896444708108902\n",
      "Eval Loss:  0.35074684023857117\n",
      "[[2079  153]\n",
      " [ 241  939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      2232\n",
      "           1       0.86      0.80      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.88      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8845252051582649\n",
      "pre:  0.8598901098901099\n",
      "rec:  0.7957627118644067\n",
      "ma F1:  0.8700145733805291\n",
      "mi F1:  0.8845252051582649\n",
      "we F1:  0.8834050862140186\n",
      "update!  Acc:  0.8997655334114889\n",
      "Epoch:  3552.122346162796  fold:  6  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.16951455175876617\n",
      "Loss:  0.16208255290985107\n",
      "Loss:  0.14904078841209412\n",
      "0 **********\n",
      "Epoch:  58.6701283454895  fold:  7  kers:  64\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.1335020661354065\n",
      "Loss:  0.1370077133178711\n",
      "Loss:  0.10317380726337433\n",
      "1 **********\n",
      "Epoch:  105.04313588142395  fold:  7  kers:  64\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.09013862907886505\n",
      "Loss:  0.09504035115242004\n",
      "Loss:  0.09355852752923965\n",
      "2 **********\n",
      "Epoch:  151.33436226844788  fold:  7  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.6545333862304688\n",
      "Eval Loss:  0.2114296704530716\n",
      "Eval Loss:  1.7217671871185303\n",
      "[[1610  517]\n",
      " [ 543  761]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75      2127\n",
      "           1       0.60      0.58      0.59      1304\n",
      "\n",
      "    accuracy                           0.69      3431\n",
      "   macro avg       0.67      0.67      0.67      3431\n",
      "weighted avg       0.69      0.69      0.69      3431\n",
      "\n",
      "acc:  0.6910521713786069\n",
      "pre:  0.5954616588419406\n",
      "rec:  0.5835889570552147\n",
      "ma F1:  0.6709009895972838\n",
      "mi F1:  0.6910521713786069\n",
      "we F1:  0.6904350562710515\n",
      "update!  Acc:  0.6910521713786069\n",
      "Eval Loss:  0.4397938847541809\n",
      "Eval Loss:  0.33852332830429077\n",
      "Eval Loss:  0.3418821096420288\n",
      "Eval Loss:  0.42018577456474304\n",
      "Eval Loss:  0.35936757922172546\n",
      "Eval Loss:  0.42314714193344116\n",
      "Eval Loss:  0.428307443857193\n",
      "Eval Loss:  0.3418799340724945\n",
      "Eval Loss:  0.3148089349269867\n",
      "Eval Loss:  0.3182224929332733\n",
      "Eval Loss:  0.32706013321876526\n",
      "Eval Loss:  0.308054119348526\n",
      "Eval Loss:  0.4296133518218994\n",
      "Eval Loss:  0.3404202461242676\n",
      "Eval Loss:  0.4640032649040222\n",
      "Eval Loss:  0.39054134488105774\n",
      "Eval Loss:  0.35973769426345825\n",
      "Eval Loss:  0.4460570812225342\n",
      "Eval Loss:  0.3450557291507721\n",
      "Eval Loss:  0.3992956280708313\n",
      "Eval Loss:  0.37752652168273926\n",
      "Eval Loss:  0.36985209584236145\n",
      "Eval Loss:  0.3105117678642273\n",
      "Eval Loss:  0.4523235857486725\n",
      "Eval Loss:  0.317624568939209\n",
      "Eval Loss:  0.4162854552268982\n",
      "Eval Loss:  0.3873571753501892\n",
      "Eval Loss:  0.38509565591812134\n",
      "[[15052  2985]\n",
      " [ 1936  9487]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86     18037\n",
      "           1       0.76      0.83      0.79     11423\n",
      "\n",
      "    accuracy                           0.83     29460\n",
      "   macro avg       0.82      0.83      0.83     29460\n",
      "weighted avg       0.84      0.83      0.83     29460\n",
      "\n",
      "acc:  0.83295994568907\n",
      "pre:  0.76066388710712\n",
      "rec:  0.8305173772213954\n",
      "ma F1:  0.8267788455291329\n",
      "mi F1:  0.8329599456890701\n",
      "we F1:  0.8341250802924436\n",
      "29460 461\n",
      "Loss:  0.08811194449663162\n",
      "Loss:  0.09153696894645691\n",
      "Loss:  0.09395009279251099\n",
      "3 **********\n",
      "Epoch:  237.57377576828003  fold:  7  kers:  64\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.12611828744411469\n",
      "Loss:  0.1461571604013443\n",
      "Loss:  0.09288366138935089\n",
      "4 **********\n",
      "Epoch:  283.62664008140564  fold:  7  kers:  64\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.09118016064167023\n",
      "Loss:  0.1029977798461914\n",
      "Loss:  0.10855047404766083\n",
      "5 **********\n",
      "Epoch:  329.7802345752716  fold:  7  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.9199628233909607\n",
      "Eval Loss:  0.04885233938694\n",
      "Eval Loss:  2.844155788421631\n",
      "[[2036   91]\n",
      " [ 939  365]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.80      2127\n",
      "           1       0.80      0.28      0.41      1304\n",
      "\n",
      "    accuracy                           0.70      3431\n",
      "   macro avg       0.74      0.62      0.61      3431\n",
      "weighted avg       0.73      0.70      0.65      3431\n",
      "\n",
      "acc:  0.6997959778490236\n",
      "pre:  0.8004385964912281\n",
      "rec:  0.2799079754601227\n",
      "ma F1:  0.6064455561099034\n",
      "mi F1:  0.6997959778490236\n",
      "we F1:  0.6524224544290512\n",
      "update!  Acc:  0.6997959778490236\n",
      "Eval Loss:  0.48668932914733887\n",
      "Eval Loss:  0.34240996837615967\n",
      "Eval Loss:  0.44268956780433655\n",
      "Eval Loss:  0.4827662706375122\n",
      "Eval Loss:  0.3128736615180969\n",
      "Eval Loss:  0.5107408165931702\n",
      "Eval Loss:  0.523247241973877\n",
      "Eval Loss:  0.38310733437538147\n",
      "Eval Loss:  0.36134815216064453\n",
      "Eval Loss:  0.3586207628250122\n",
      "Eval Loss:  0.32896432280540466\n",
      "Eval Loss:  0.3599921464920044\n",
      "Eval Loss:  0.48412030935287476\n",
      "Eval Loss:  0.36752939224243164\n",
      "Eval Loss:  0.44408121705055237\n",
      "Eval Loss:  0.4035419225692749\n",
      "Eval Loss:  0.40829676389694214\n",
      "Eval Loss:  0.4405195415019989\n",
      "Eval Loss:  0.35439789295196533\n",
      "Eval Loss:  0.4718002676963806\n",
      "Eval Loss:  0.4452129602432251\n",
      "Eval Loss:  0.44339197874069214\n",
      "Eval Loss:  0.33546561002731323\n",
      "Eval Loss:  0.4112858474254608\n",
      "Eval Loss:  0.32664644718170166\n",
      "Eval Loss:  0.4660278558731079\n",
      "Eval Loss:  0.5015207529067993\n",
      "Eval Loss:  0.39913979172706604\n",
      "[[17257   780]\n",
      " [ 3898  7525]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88     18037\n",
      "           1       0.91      0.66      0.76     11423\n",
      "\n",
      "    accuracy                           0.84     29460\n",
      "   macro avg       0.86      0.81      0.82     29460\n",
      "weighted avg       0.85      0.84      0.83     29460\n",
      "\n",
      "acc:  0.8412084181941616\n",
      "pre:  0.9060806742925949\n",
      "rec:  0.6587586448393592\n",
      "ma F1:  0.821757003638957\n",
      "mi F1:  0.8412084181941616\n",
      "we F1:  0.8349764503989368\n",
      "29460 461\n",
      "Loss:  0.11815408617258072\n",
      "Loss:  0.08923005312681198\n",
      "Loss:  0.08058115839958191\n",
      "6 **********\n",
      "Epoch:  415.825168132782  fold:  7  kers:  64\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.0874803438782692\n",
      "Loss:  0.11905531585216522\n",
      "Loss:  0.07556480914354324\n",
      "7 **********\n",
      "Epoch:  462.01666140556335  fold:  7  kers:  64\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.109128437936306\n",
      "Loss:  0.0974760577082634\n",
      "Loss:  0.08829014748334885\n",
      "8 **********\n",
      "Epoch:  508.19718384742737  fold:  7  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.6355743408203125\n",
      "Eval Loss:  0.1273341178894043\n",
      "Eval Loss:  2.322606325149536\n",
      "[[1982  145]\n",
      " [ 718  586]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82      2127\n",
      "           1       0.80      0.45      0.58      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.69      0.70      3431\n",
      "weighted avg       0.76      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7484698338676771\n",
      "pre:  0.801641586867305\n",
      "rec:  0.4493865030674847\n",
      "ma F1:  0.6985676902395361\n",
      "mi F1:  0.7484698338676772\n",
      "we F1:  0.7279870772065562\n",
      "update!  Acc:  0.7484698338676771\n",
      "Eval Loss:  0.423198938369751\n",
      "Eval Loss:  0.21656587719917297\n",
      "Eval Loss:  0.24376867711544037\n",
      "Eval Loss:  0.32295918464660645\n",
      "Eval Loss:  0.2802414894104004\n",
      "Eval Loss:  0.3810618221759796\n",
      "Eval Loss:  0.3810475170612335\n",
      "Eval Loss:  0.2647477686405182\n",
      "Eval Loss:  0.2919752895832062\n",
      "Eval Loss:  0.2679339051246643\n",
      "Eval Loss:  0.2214096039533615\n",
      "Eval Loss:  0.22324323654174805\n",
      "Eval Loss:  0.34369704127311707\n",
      "Eval Loss:  0.25418713688850403\n",
      "Eval Loss:  0.36102011799812317\n",
      "Eval Loss:  0.3153521418571472\n",
      "Eval Loss:  0.29662859439849854\n",
      "Eval Loss:  0.3681463599205017\n",
      "Eval Loss:  0.2907273769378662\n",
      "Eval Loss:  0.36388784646987915\n",
      "Eval Loss:  0.2965982258319855\n",
      "Eval Loss:  0.3355547785758972\n",
      "Eval Loss:  0.2553461194038391\n",
      "Eval Loss:  0.3366982340812683\n",
      "Eval Loss:  0.2581008970737457\n",
      "Eval Loss:  0.3606760501861572\n",
      "Eval Loss:  0.40054792165756226\n",
      "Eval Loss:  0.2824375331401825\n",
      "[[16826  1211]\n",
      " [ 2489  8934]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     18037\n",
      "           1       0.88      0.78      0.83     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.86      0.86     29460\n",
      "weighted avg       0.87      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8744059742023083\n",
      "pre:  0.8806308526367669\n",
      "rec:  0.7821062768099448\n",
      "ma F1:  0.8646959704230124\n",
      "mi F1:  0.8744059742023083\n",
      "we F1:  0.872833573691672\n",
      "29460 461\n",
      "Loss:  0.0725664496421814\n",
      "Loss:  0.08131182193756104\n",
      "Loss:  0.08068104088306427\n",
      "9 **********\n",
      "Epoch:  594.3219044208527  fold:  7  kers:  64\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.05792447552084923\n",
      "Loss:  0.09711244702339172\n",
      "Loss:  0.07709337025880814\n",
      "10 **********\n",
      "Epoch:  640.4715092182159  fold:  7  kers:  64\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07782480865716934\n",
      "Loss:  0.05338394269347191\n",
      "Loss:  0.08842752873897552\n",
      "11 **********\n",
      "Epoch:  686.6021649837494  fold:  7  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.9040823578834534\n",
      "Eval Loss:  0.03573606535792351\n",
      "Eval Loss:  2.768890380859375\n",
      "[[2083   44]\n",
      " [ 884  420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82      2127\n",
      "           1       0.91      0.32      0.48      1304\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.80      0.65      0.65      3431\n",
      "weighted avg       0.78      0.73      0.69      3431\n",
      "\n",
      "acc:  0.7295249198484407\n",
      "pre:  0.9051724137931034\n",
      "rec:  0.3220858895705521\n",
      "ma F1:  0.6464690071008924\n",
      "mi F1:  0.7295249198484407\n",
      "we F1:  0.6875724443776405\n",
      "Eval Loss:  0.43919819593429565\n",
      "Eval Loss:  0.2699838876724243\n",
      "Eval Loss:  0.34447604417800903\n",
      "Eval Loss:  0.36925452947616577\n",
      "Eval Loss:  0.27708324790000916\n",
      "Eval Loss:  0.4779096245765686\n",
      "Eval Loss:  0.4201166331768036\n",
      "Eval Loss:  0.27675098180770874\n",
      "Eval Loss:  0.3068651854991913\n",
      "Eval Loss:  0.30428439378738403\n",
      "Eval Loss:  0.28773176670074463\n",
      "Eval Loss:  0.2739356458187103\n",
      "Eval Loss:  0.41416090726852417\n",
      "Eval Loss:  0.3044278621673584\n",
      "Eval Loss:  0.3517400622367859\n",
      "Eval Loss:  0.3939703702926636\n",
      "Eval Loss:  0.3400390148162842\n",
      "Eval Loss:  0.3679799735546112\n",
      "Eval Loss:  0.29600539803504944\n",
      "Eval Loss:  0.44793596863746643\n",
      "Eval Loss:  0.3591909110546112\n",
      "Eval Loss:  0.3914247453212738\n",
      "Eval Loss:  0.31416040658950806\n",
      "Eval Loss:  0.382754921913147\n",
      "Eval Loss:  0.2995879650115967\n",
      "Eval Loss:  0.37837839126586914\n",
      "Eval Loss:  0.47695624828338623\n",
      "Eval Loss:  0.3289123475551605\n",
      "[[17484   553]\n",
      " [ 3473  7950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     18037\n",
      "           1       0.93      0.70      0.80     11423\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.88      0.83      0.85     29460\n",
      "weighted avg       0.87      0.86      0.86     29460\n",
      "\n",
      "acc:  0.8633401221995927\n",
      "pre:  0.9349641303069505\n",
      "rec:  0.6959642825877616\n",
      "ma F1:  0.8473528853187011\n",
      "mi F1:  0.8633401221995927\n",
      "we F1:  0.8584436745708741\n",
      "29460 461\n",
      "Loss:  0.08789259195327759\n",
      "Loss:  0.06433703005313873\n",
      "Loss:  0.06050126627087593\n",
      "12 **********\n",
      "Epoch:  772.7966985702515  fold:  7  kers:  64\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.05058911070227623\n",
      "Loss:  0.05676615983247757\n",
      "Loss:  0.06442884355783463\n",
      "13 **********\n",
      "Epoch:  819.0699732303619  fold:  7  kers:  64\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.05668916925787926\n",
      "Loss:  0.05093088373541832\n",
      "Loss:  0.0888214185833931\n",
      "14 **********\n",
      "Epoch:  865.2006294727325  fold:  7  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.7594875693321228\n",
      "Eval Loss:  0.03651617467403412\n",
      "Eval Loss:  2.4893126487731934\n",
      "[[2052   75]\n",
      " [ 799  505]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      2127\n",
      "           1       0.87      0.39      0.54      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.80      0.68      0.68      3431\n",
      "weighted avg       0.78      0.75      0.71      3431\n",
      "\n",
      "acc:  0.7452637714951909\n",
      "pre:  0.8706896551724138\n",
      "rec:  0.38726993865030673\n",
      "ma F1:  0.680260449587527\n",
      "mi F1:  0.745263771495191\n",
      "we F1:  0.714842048766588\n",
      "Eval Loss:  0.40048840641975403\n",
      "Eval Loss:  0.23448319733142853\n",
      "Eval Loss:  0.24498261511325836\n",
      "Eval Loss:  0.2851799428462982\n",
      "Eval Loss:  0.26798155903816223\n",
      "Eval Loss:  0.39790427684783936\n",
      "Eval Loss:  0.3599757254123688\n",
      "Eval Loss:  0.20774011313915253\n",
      "Eval Loss:  0.2622023820877075\n",
      "Eval Loss:  0.2552814781665802\n",
      "Eval Loss:  0.22178727388381958\n",
      "Eval Loss:  0.20670923590660095\n",
      "Eval Loss:  0.3863161504268646\n",
      "Eval Loss:  0.24982735514640808\n",
      "Eval Loss:  0.30583256483078003\n",
      "Eval Loss:  0.3614141345024109\n",
      "Eval Loss:  0.27876806259155273\n",
      "Eval Loss:  0.31165069341659546\n",
      "Eval Loss:  0.275784432888031\n",
      "Eval Loss:  0.3722430467605591\n",
      "Eval Loss:  0.31227222084999084\n",
      "Eval Loss:  0.34352415800094604\n",
      "Eval Loss:  0.26775050163269043\n",
      "Eval Loss:  0.340776264667511\n",
      "Eval Loss:  0.245332732796669\n",
      "Eval Loss:  0.3394638001918793\n",
      "Eval Loss:  0.4143349826335907\n",
      "Eval Loss:  0.2964719831943512\n",
      "[[17324   713]\n",
      " [ 2720  8703]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18037\n",
      "           1       0.92      0.76      0.84     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.86      0.87     29460\n",
      "weighted avg       0.89      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8834691106585201\n",
      "pre:  0.9242778249787595\n",
      "rec:  0.761883918410225\n",
      "ma F1:  0.8725554327592686\n",
      "mi F1:  0.8834691106585201\n",
      "we F1:  0.8809283669462132\n",
      "29460 461\n",
      "Loss:  0.049960143864154816\n",
      "Loss:  0.05644494295120239\n",
      "Loss:  0.06955254077911377\n",
      "15 **********\n",
      "Epoch:  951.348287820816  fold:  7  kers:  64\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.07286135107278824\n",
      "Loss:  0.06175556406378746\n",
      "Loss:  0.05252990499138832\n",
      "16 **********\n",
      "Epoch:  997.469967842102  fold:  7  kers:  64\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.06755617260932922\n",
      "Loss:  0.07600271701812744\n",
      "Loss:  0.0917574018239975\n",
      "17 **********\n",
      "Epoch:  1043.6963675022125  fold:  7  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.4840983748435974\n",
      "Eval Loss:  0.06995910406112671\n",
      "Eval Loss:  2.0001986026763916\n",
      "[[1988  139]\n",
      " [ 645  659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84      2127\n",
      "           1       0.83      0.51      0.63      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.72      0.73      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7714951909064413\n",
      "pre:  0.8258145363408521\n",
      "rec:  0.5053680981595092\n",
      "ma F1:  0.7311580007835675\n",
      "mi F1:  0.7714951909064413\n",
      "we F1:  0.7561373141553698\n",
      "update!  Acc:  0.7714951909064413\n",
      "Eval Loss:  0.34037843346595764\n",
      "Eval Loss:  0.19240641593933105\n",
      "Eval Loss:  0.15743547677993774\n",
      "Eval Loss:  0.23914700746536255\n",
      "Eval Loss:  0.25211119651794434\n",
      "Eval Loss:  0.32754063606262207\n",
      "Eval Loss:  0.2999956011772156\n",
      "Eval Loss:  0.15829017758369446\n",
      "Eval Loss:  0.22946609556674957\n",
      "Eval Loss:  0.20163200795650482\n",
      "Eval Loss:  0.1903945952653885\n",
      "Eval Loss:  0.17527790367603302\n",
      "Eval Loss:  0.2954494059085846\n",
      "Eval Loss:  0.2268243432044983\n",
      "Eval Loss:  0.2644919455051422\n",
      "Eval Loss:  0.30023571848869324\n",
      "Eval Loss:  0.2733789086341858\n",
      "Eval Loss:  0.27924248576164246\n",
      "Eval Loss:  0.26459676027297974\n",
      "Eval Loss:  0.3070982098579407\n",
      "Eval Loss:  0.25411123037338257\n",
      "Eval Loss:  0.256902277469635\n",
      "Eval Loss:  0.20926186442375183\n",
      "Eval Loss:  0.26277193427085876\n",
      "Eval Loss:  0.19709919393062592\n",
      "Eval Loss:  0.26082128286361694\n",
      "Eval Loss:  0.3286292552947998\n",
      "Eval Loss:  0.21794641017913818\n",
      "[[16841  1196]\n",
      " [ 1722  9701]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18037\n",
      "           1       0.89      0.85      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9009504412763069\n",
      "pre:  0.8902450215655685\n",
      "rec:  0.8492515101111792\n",
      "ma F1:  0.8947692285093132\n",
      "mi F1:  0.9009504412763069\n",
      "we F1:  0.9004950746214835\n",
      "29460 461\n",
      "Loss:  0.08158272504806519\n",
      "Loss:  0.055714357644319534\n",
      "Loss:  0.053068291395902634\n",
      "18 **********\n",
      "Epoch:  1129.7363142967224  fold:  7  kers:  64\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.05459607020020485\n",
      "Loss:  0.06526954472064972\n",
      "Loss:  0.0567457415163517\n",
      "19 **********\n",
      "Epoch:  1175.812117099762  fold:  7  kers:  64\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.05193173140287399\n",
      "Loss:  0.053768597543239594\n",
      "Loss:  0.03866487741470337\n",
      "20 **********\n",
      "Epoch:  1221.9716954231262  fold:  7  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.4043349325656891\n",
      "Eval Loss:  0.08509239554405212\n",
      "Eval Loss:  1.7168694734573364\n",
      "[[1871  256]\n",
      " [ 524  780]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83      2127\n",
      "           1       0.75      0.60      0.67      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.74      0.75      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7726610317691636\n",
      "pre:  0.752895752895753\n",
      "rec:  0.598159509202454\n",
      "ma F1:  0.7470883090078138\n",
      "mi F1:  0.7726610317691636\n",
      "we F1:  0.7663791896976313\n",
      "update!  Acc:  0.7726610317691636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.31836867332458496\n",
      "Eval Loss:  0.20826391875743866\n",
      "Eval Loss:  0.15007422864437103\n",
      "Eval Loss:  0.20503060519695282\n",
      "Eval Loss:  0.2562713027000427\n",
      "Eval Loss:  0.3202592730522156\n",
      "Eval Loss:  0.26968371868133545\n",
      "Eval Loss:  0.1470925658941269\n",
      "Eval Loss:  0.22014570236206055\n",
      "Eval Loss:  0.20014160871505737\n",
      "Eval Loss:  0.2006320059299469\n",
      "Eval Loss:  0.18127994239330292\n",
      "Eval Loss:  0.25964483618736267\n",
      "Eval Loss:  0.22078156471252441\n",
      "Eval Loss:  0.24210229516029358\n",
      "Eval Loss:  0.29843220114707947\n",
      "Eval Loss:  0.24278651177883148\n",
      "Eval Loss:  0.3053027093410492\n",
      "Eval Loss:  0.26549792289733887\n",
      "Eval Loss:  0.3038182854652405\n",
      "Eval Loss:  0.2293778955936432\n",
      "Eval Loss:  0.24132540822029114\n",
      "Eval Loss:  0.18165193498134613\n",
      "Eval Loss:  0.23401735723018646\n",
      "Eval Loss:  0.2001493275165558\n",
      "Eval Loss:  0.25031840801239014\n",
      "Eval Loss:  0.27674421668052673\n",
      "Eval Loss:  0.23406697809696198\n",
      "[[16453  1584]\n",
      " [ 1225 10198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     18037\n",
      "           1       0.87      0.89      0.88     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.91      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9046503733876443\n",
      "pre:  0.8655576302834833\n",
      "rec:  0.8927602206075462\n",
      "ma F1:  0.9001490377432271\n",
      "mi F1:  0.9046503733876443\n",
      "we F1:  0.9049087234270281\n",
      "29460 461\n",
      "Loss:  0.06357841193675995\n",
      "Loss:  0.08140317350625992\n",
      "Loss:  0.07571657747030258\n",
      "21 **********\n",
      "Epoch:  1307.968757390976  fold:  7  kers:  64\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.08718334138393402\n",
      "Loss:  0.07042068243026733\n",
      "Loss:  0.06233030557632446\n",
      "22 **********\n",
      "Epoch:  1353.9787356853485  fold:  7  kers:  64\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.05186305567622185\n",
      "Loss:  0.058570604771375656\n",
      "Loss:  0.059055395424366\n",
      "23 **********\n",
      "Epoch:  1400.877338886261  fold:  7  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.4545225203037262\n",
      "Eval Loss:  0.06859990954399109\n",
      "Eval Loss:  1.7107406854629517\n",
      "[[1974  153]\n",
      " [ 585  719]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84      2127\n",
      "           1       0.82      0.55      0.66      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.80      0.74      0.75      3431\n",
      "weighted avg       0.79      0.78      0.77      3431\n",
      "\n",
      "acc:  0.784902360827747\n",
      "pre:  0.8245412844036697\n",
      "rec:  0.5513803680981595\n",
      "ma F1:  0.7516775956541386\n",
      "mi F1:  0.784902360827747\n",
      "we F1:  0.7734656289114131\n",
      "update!  Acc:  0.784902360827747\n",
      "Eval Loss:  0.32096946239471436\n",
      "Eval Loss:  0.18922679126262665\n",
      "Eval Loss:  0.14403590559959412\n",
      "Eval Loss:  0.20844632387161255\n",
      "Eval Loss:  0.2401580661535263\n",
      "Eval Loss:  0.32681480050086975\n",
      "Eval Loss:  0.2565121054649353\n",
      "Eval Loss:  0.1380786895751953\n",
      "Eval Loss:  0.1990787833929062\n",
      "Eval Loss:  0.19293780624866486\n",
      "Eval Loss:  0.21105435490608215\n",
      "Eval Loss:  0.18093593418598175\n",
      "Eval Loss:  0.2798912227153778\n",
      "Eval Loss:  0.22111035883426666\n",
      "Eval Loss:  0.23681560158729553\n",
      "Eval Loss:  0.2914930284023285\n",
      "Eval Loss:  0.24736008048057556\n",
      "Eval Loss:  0.2954195737838745\n",
      "Eval Loss:  0.2413311004638672\n",
      "Eval Loss:  0.2629068195819855\n",
      "Eval Loss:  0.2172529548406601\n",
      "Eval Loss:  0.22078056633472443\n",
      "Eval Loss:  0.17486293613910675\n",
      "Eval Loss:  0.24507610499858856\n",
      "Eval Loss:  0.17463116347789764\n",
      "Eval Loss:  0.24178263545036316\n",
      "Eval Loss:  0.3031947910785675\n",
      "Eval Loss:  0.2184656262397766\n",
      "[[16810  1227]\n",
      " [ 1495  9928]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18037\n",
      "           1       0.89      0.87      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9076035302104548\n",
      "pre:  0.890004482294935\n",
      "rec:  0.8691236978026788\n",
      "ma F1:  0.9022702988746016\n",
      "mi F1:  0.9076035302104548\n",
      "we F1:  0.9073958426199276\n",
      "29460 461\n",
      "Loss:  0.08642923831939697\n",
      "Loss:  0.06775311380624771\n",
      "Loss:  0.05302906408905983\n",
      "24 **********\n",
      "Epoch:  1486.7118344306946  fold:  7  kers:  64\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.06457509100437164\n",
      "Loss:  0.061415478587150574\n",
      "Loss:  0.05682702735066414\n",
      "25 **********\n",
      "Epoch:  1532.9073190689087  fold:  7  kers:  64\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.06713786721229553\n",
      "Loss:  0.07114798575639725\n",
      "Loss:  0.054128773510456085\n",
      "26 **********\n",
      "Epoch:  1578.9940903186798  fold:  7  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.45132264494895935\n",
      "Eval Loss:  0.04099433869123459\n",
      "Eval Loss:  1.924580693244934\n",
      "[[1971  156]\n",
      " [ 636  668]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.83      2127\n",
      "           1       0.81      0.51      0.63      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.72      0.73      3431\n",
      "weighted avg       0.78      0.77      0.75      3431\n",
      "\n",
      "acc:  0.7691635091809967\n",
      "pre:  0.8106796116504854\n",
      "rec:  0.5122699386503068\n",
      "ma F1:  0.7302595843220218\n",
      "mi F1:  0.7691635091809967\n",
      "we F1:  0.75483205566426\n",
      "Eval Loss:  0.28719058632850647\n",
      "Eval Loss:  0.19378051161766052\n",
      "Eval Loss:  0.156896710395813\n",
      "Eval Loss:  0.21599796414375305\n",
      "Eval Loss:  0.19967791438102722\n",
      "Eval Loss:  0.31520986557006836\n",
      "Eval Loss:  0.24839673936367035\n",
      "Eval Loss:  0.13914519548416138\n",
      "Eval Loss:  0.19206735491752625\n",
      "Eval Loss:  0.18530124425888062\n",
      "Eval Loss:  0.18843421339988708\n",
      "Eval Loss:  0.16990694403648376\n",
      "Eval Loss:  0.28270602226257324\n",
      "Eval Loss:  0.21835099160671234\n",
      "Eval Loss:  0.23764824867248535\n",
      "Eval Loss:  0.29443272948265076\n",
      "Eval Loss:  0.21412386000156403\n",
      "Eval Loss:  0.26679959893226624\n",
      "Eval Loss:  0.2193327695131302\n",
      "Eval Loss:  0.25725242495536804\n",
      "Eval Loss:  0.22015899419784546\n",
      "Eval Loss:  0.22017408907413483\n",
      "Eval Loss:  0.1689942181110382\n",
      "Eval Loss:  0.25017115473747253\n",
      "Eval Loss:  0.1751307249069214\n",
      "Eval Loss:  0.26489758491516113\n",
      "Eval Loss:  0.29203686118125916\n",
      "Eval Loss:  0.23927661776542664\n",
      "[[16979  1058]\n",
      " [ 1599  9824]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18037\n",
      "           1       0.90      0.86      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9098099117447386\n",
      "pre:  0.902775225142437\n",
      "rec:  0.8600192593889521\n",
      "ma F1:  0.9041564192228684\n",
      "mi F1:  0.9098099117447386\n",
      "we F1:  0.9093824429181373\n",
      "29460 461\n",
      "Loss:  0.07999194413423538\n",
      "Loss:  0.03887929022312164\n",
      "Loss:  0.03704138100147247\n",
      "27 **********\n",
      "Epoch:  1665.178650856018  fold:  7  kers:  64\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.07132786512374878\n",
      "Loss:  0.08965861797332764\n",
      "Loss:  0.049337927252054214\n",
      "28 **********\n",
      "Epoch:  1711.1826453208923  fold:  7  kers:  64\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.06877908110618591\n",
      "Loss:  0.07484817504882812\n",
      "Loss:  0.05739332363009453\n",
      "29 **********\n",
      "Epoch:  1763.6852638721466  fold:  7  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.4100690186023712\n",
      "Eval Loss:  0.05822446569800377\n",
      "Eval Loss:  1.7506446838378906\n",
      "[[1946  181]\n",
      " [ 593  711]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83      2127\n",
      "           1       0.80      0.55      0.65      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.73      0.74      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7744097930632469\n",
      "pre:  0.797085201793722\n",
      "rec:  0.5452453987730062\n",
      "ma F1:  0.7408300717432702\n",
      "mi F1:  0.7744097930632469\n",
      "we F1:  0.7632074892706717\n",
      "Eval Loss:  0.28929299116134644\n",
      "Eval Loss:  0.21347078680992126\n",
      "Eval Loss:  0.14406578242778778\n",
      "Eval Loss:  0.2069595456123352\n",
      "Eval Loss:  0.22302289307117462\n",
      "Eval Loss:  0.3244156241416931\n",
      "Eval Loss:  0.25110024213790894\n",
      "Eval Loss:  0.13224539160728455\n",
      "Eval Loss:  0.19105271995067596\n",
      "Eval Loss:  0.18416903913021088\n",
      "Eval Loss:  0.1945776790380478\n",
      "Eval Loss:  0.19715867936611176\n",
      "Eval Loss:  0.26369941234588623\n",
      "Eval Loss:  0.2146928906440735\n",
      "Eval Loss:  0.20599813759326935\n",
      "Eval Loss:  0.2740786373615265\n",
      "Eval Loss:  0.21898075938224792\n",
      "Eval Loss:  0.30529657006263733\n",
      "Eval Loss:  0.25249603390693665\n",
      "Eval Loss:  0.25313353538513184\n",
      "Eval Loss:  0.20047250390052795\n",
      "Eval Loss:  0.20480380952358246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1677425056695938\n",
      "Eval Loss:  0.21023356914520264\n",
      "Eval Loss:  0.17677611112594604\n",
      "Eval Loss:  0.24427258968353271\n",
      "Eval Loss:  0.284830778837204\n",
      "Eval Loss:  0.22421443462371826\n",
      "[[16563  1474]\n",
      " [ 1218 10205]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     18037\n",
      "           1       0.87      0.89      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.91      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9086218601493551\n",
      "pre:  0.8737905642606387\n",
      "rec:  0.8933730193469316\n",
      "ma F1:  0.9041577752190844\n",
      "mi F1:  0.9086218601493551\n",
      "we F1:  0.9088016031097436\n",
      "29460 461\n",
      "Loss:  0.05950253829360008\n",
      "Loss:  0.09210433810949326\n",
      "Loss:  0.05664406716823578\n",
      "30 **********\n",
      "Epoch:  1849.7601175308228  fold:  7  kers:  64\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.03408012539148331\n",
      "Loss:  0.07937490195035934\n",
      "Loss:  0.08811833709478378\n",
      "31 **********\n",
      "Epoch:  1895.886783838272  fold:  7  kers:  64\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.06937550008296967\n",
      "Loss:  0.06132449954748154\n",
      "Loss:  0.05683784931898117\n",
      "32 **********\n",
      "Epoch:  1941.9097278118134  fold:  7  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.4086008071899414\n",
      "Eval Loss:  0.06289432942867279\n",
      "Eval Loss:  1.4781702756881714\n",
      "[[1949  178]\n",
      " [ 536  768]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85      2127\n",
      "           1       0.81      0.59      0.68      1304\n",
      "\n",
      "    accuracy                           0.79      3431\n",
      "   macro avg       0.80      0.75      0.76      3431\n",
      "weighted avg       0.79      0.79      0.78      3431\n",
      "\n",
      "acc:  0.7918974060040804\n",
      "pre:  0.8118393234672304\n",
      "rec:  0.588957055214724\n",
      "ma F1:  0.763926568372362\n",
      "mi F1:  0.7918974060040804\n",
      "we F1:  0.7834185238091987\n",
      "update!  Acc:  0.7918974060040804\n",
      "Eval Loss:  0.2898595333099365\n",
      "Eval Loss:  0.2032351791858673\n",
      "Eval Loss:  0.1416742503643036\n",
      "Eval Loss:  0.19582708179950714\n",
      "Eval Loss:  0.23086485266685486\n",
      "Eval Loss:  0.29657670855522156\n",
      "Eval Loss:  0.2321890890598297\n",
      "Eval Loss:  0.11933014541864395\n",
      "Eval Loss:  0.19012713432312012\n",
      "Eval Loss:  0.18614448606967926\n",
      "Eval Loss:  0.1768803745508194\n",
      "Eval Loss:  0.17215563356876373\n",
      "Eval Loss:  0.23170815408229828\n",
      "Eval Loss:  0.20202475786209106\n",
      "Eval Loss:  0.18944880366325378\n",
      "Eval Loss:  0.2909013628959656\n",
      "Eval Loss:  0.19383540749549866\n",
      "Eval Loss:  0.28093421459198\n",
      "Eval Loss:  0.24286392331123352\n",
      "Eval Loss:  0.256066232919693\n",
      "Eval Loss:  0.19937072694301605\n",
      "Eval Loss:  0.21283195912837982\n",
      "Eval Loss:  0.13660025596618652\n",
      "Eval Loss:  0.24760428071022034\n",
      "Eval Loss:  0.15604077279567719\n",
      "Eval Loss:  0.22920845448970795\n",
      "Eval Loss:  0.28000324964523315\n",
      "Eval Loss:  0.20299693942070007\n",
      "[[16726  1311]\n",
      " [ 1248 10175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18037\n",
      "           1       0.89      0.89      0.89     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9131364562118126\n",
      "pre:  0.885861048232631\n",
      "rec:  0.8907467390352797\n",
      "ma F1:  0.9086177778609532\n",
      "mi F1:  0.9131364562118126\n",
      "we F1:  0.913179911674506\n",
      "29460 461\n",
      "Loss:  0.06026766076683998\n",
      "Loss:  0.0627157911658287\n",
      "Loss:  0.07487183064222336\n",
      "33 **********\n",
      "Epoch:  2028.0773332118988  fold:  7  kers:  64\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.08413798362016678\n",
      "Loss:  0.03395475447177887\n",
      "Loss:  0.07559492439031601\n",
      "34 **********\n",
      "Epoch:  2074.314703941345  fold:  7  kers:  64\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.06680264323949814\n",
      "Loss:  0.04789464548230171\n",
      "Loss:  0.06972581148147583\n",
      "35 **********\n",
      "Epoch:  2120.4613173007965  fold:  7  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.41500845551490784\n",
      "Eval Loss:  0.06053703650832176\n",
      "Eval Loss:  1.6685943603515625\n",
      "[[1956  171]\n",
      " [ 585  719]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      2127\n",
      "           1       0.81      0.55      0.66      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.79      0.74      0.75      3431\n",
      "weighted avg       0.78      0.78      0.77      3431\n",
      "\n",
      "acc:  0.779656076945497\n",
      "pre:  0.8078651685393259\n",
      "rec:  0.5513803680981595\n",
      "ma F1:  0.7467350779058568\n",
      "mi F1:  0.779656076945497\n",
      "we F1:  0.7686380546315027\n",
      "Eval Loss:  0.27534353733062744\n",
      "Eval Loss:  0.2007276564836502\n",
      "Eval Loss:  0.14663434028625488\n",
      "Eval Loss:  0.2201339155435562\n",
      "Eval Loss:  0.23210248351097107\n",
      "Eval Loss:  0.2987404465675354\n",
      "Eval Loss:  0.23207934200763702\n",
      "Eval Loss:  0.12796297669410706\n",
      "Eval Loss:  0.18152883648872375\n",
      "Eval Loss:  0.1833915412425995\n",
      "Eval Loss:  0.18058110773563385\n",
      "Eval Loss:  0.17172051966190338\n",
      "Eval Loss:  0.2371765375137329\n",
      "Eval Loss:  0.21551881730556488\n",
      "Eval Loss:  0.18482504785060883\n",
      "Eval Loss:  0.2953164577484131\n",
      "Eval Loss:  0.198454812169075\n",
      "Eval Loss:  0.27548208832740784\n",
      "Eval Loss:  0.22251570224761963\n",
      "Eval Loss:  0.23504702746868134\n",
      "Eval Loss:  0.1908228099346161\n",
      "Eval Loss:  0.20479978621006012\n",
      "Eval Loss:  0.1360565721988678\n",
      "Eval Loss:  0.24339497089385986\n",
      "Eval Loss:  0.13420143723487854\n",
      "Eval Loss:  0.24059715867042542\n",
      "Eval Loss:  0.25956541299819946\n",
      "Eval Loss:  0.21774804592132568\n",
      "[[16931  1106]\n",
      " [ 1363 10060]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18037\n",
      "           1       0.90      0.88      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9161914460285132\n",
      "pre:  0.9009493104065914\n",
      "rec:  0.8806793311739473\n",
      "ma F1:  0.9113702600232985\n",
      "mi F1:  0.9161914460285132\n",
      "we F1:  0.9160111164107952\n",
      "29460 461\n",
      "Loss:  0.04396691918373108\n",
      "Loss:  0.040541574358940125\n",
      "Loss:  0.05008433759212494\n",
      "36 **********\n",
      "Epoch:  2206.4623680114746  fold:  7  kers:  64\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.059268102049827576\n",
      "Loss:  0.041999757289886475\n",
      "Loss:  0.03880437836050987\n",
      "37 **********\n",
      "Epoch:  2252.63191986084  fold:  7  kers:  64\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.06332824379205704\n",
      "Loss:  0.04625241830945015\n",
      "Loss:  0.03818648308515549\n",
      "38 **********\n",
      "Epoch:  2298.796484708786  fold:  7  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.36959394812583923\n",
      "Eval Loss:  0.12581461668014526\n",
      "Eval Loss:  1.177192211151123\n",
      "[[1886  241]\n",
      " [ 472  832]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84      2127\n",
      "           1       0.78      0.64      0.70      1304\n",
      "\n",
      "    accuracy                           0.79      3431\n",
      "   macro avg       0.79      0.76      0.77      3431\n",
      "weighted avg       0.79      0.79      0.79      3431\n",
      "\n",
      "acc:  0.792188866219761\n",
      "pre:  0.7753960857409133\n",
      "rec:  0.6380368098159509\n",
      "ma F1:  0.7705338554307843\n",
      "mi F1:  0.792188866219761\n",
      "we F1:  0.7874428439310953\n",
      "update!  Acc:  0.792188866219761\n",
      "Eval Loss:  0.27044743299484253\n",
      "Eval Loss:  0.21079185605049133\n",
      "Eval Loss:  0.13868393003940582\n",
      "Eval Loss:  0.18729746341705322\n",
      "Eval Loss:  0.23202775418758392\n",
      "Eval Loss:  0.2788652777671814\n",
      "Eval Loss:  0.23713994026184082\n",
      "Eval Loss:  0.11536657810211182\n",
      "Eval Loss:  0.17503689229488373\n",
      "Eval Loss:  0.1772281378507614\n",
      "Eval Loss:  0.1625266969203949\n",
      "Eval Loss:  0.17396527528762817\n",
      "Eval Loss:  0.2302747219800949\n",
      "Eval Loss:  0.18805626034736633\n",
      "Eval Loss:  0.19828681647777557\n",
      "Eval Loss:  0.26970142126083374\n",
      "Eval Loss:  0.20455443859100342\n",
      "Eval Loss:  0.30060285329818726\n",
      "Eval Loss:  0.2418452799320221\n",
      "Eval Loss:  0.2687356770038605\n",
      "Eval Loss:  0.19707420468330383\n",
      "Eval Loss:  0.2001342922449112\n",
      "Eval Loss:  0.16436971724033356\n",
      "Eval Loss:  0.21028877794742584\n",
      "Eval Loss:  0.13639454543590546\n",
      "Eval Loss:  0.22914566099643707\n",
      "Eval Loss:  0.2562465965747833\n",
      "Eval Loss:  0.20432810485363007\n",
      "[[16616  1421]\n",
      " [ 1108 10315]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     18037\n",
      "           1       0.88      0.90      0.89     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9141547861507129\n",
      "pre:  0.8789195637355146\n",
      "rec:  0.9030027138229887\n",
      "ma F1:  0.9100394474087912\n",
      "mi F1:  0.9141547861507129\n",
      "we F1:  0.9143592141821714\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06075645610690117\n",
      "Loss:  0.04795825853943825\n",
      "Loss:  0.04213060811161995\n",
      "39 **********\n",
      "Epoch:  2384.8364317417145  fold:  7  kers:  64\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.067262202501297\n",
      "Loss:  0.04158344492316246\n",
      "Loss:  0.025018809363245964\n",
      "40 **********\n",
      "Epoch:  2430.9810502529144  fold:  7  kers:  64\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.0506473109126091\n",
      "Loss:  0.04676968231797218\n",
      "Loss:  0.05617499351501465\n",
      "41 **********\n",
      "Epoch:  2477.1286613941193  fold:  7  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.47046610713005066\n",
      "Eval Loss:  0.05635964497923851\n",
      "Eval Loss:  1.8009138107299805\n",
      "[[1942  185]\n",
      " [ 616  688]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      2127\n",
      "           1       0.79      0.53      0.63      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.72      0.73      3431\n",
      "weighted avg       0.77      0.77      0.75      3431\n",
      "\n",
      "acc:  0.7665403672398717\n",
      "pre:  0.7880870561282932\n",
      "rec:  0.5276073619631901\n",
      "ma F1:  0.7305456433294817\n",
      "mi F1:  0.7665403672398717\n",
      "we F1:  0.7541689748910855\n",
      "Eval Loss:  0.2320655882358551\n",
      "Eval Loss:  0.1766146719455719\n",
      "Eval Loss:  0.13565464317798615\n",
      "Eval Loss:  0.1933569461107254\n",
      "Eval Loss:  0.1950160264968872\n",
      "Eval Loss:  0.3138623535633087\n",
      "Eval Loss:  0.23800718784332275\n",
      "Eval Loss:  0.11091150343418121\n",
      "Eval Loss:  0.17880043387413025\n",
      "Eval Loss:  0.18390418589115143\n",
      "Eval Loss:  0.15890257060527802\n",
      "Eval Loss:  0.1802344024181366\n",
      "Eval Loss:  0.23595762252807617\n",
      "Eval Loss:  0.2148115336894989\n",
      "Eval Loss:  0.183584064245224\n",
      "Eval Loss:  0.306246817111969\n",
      "Eval Loss:  0.1723271906375885\n",
      "Eval Loss:  0.2546290159225464\n",
      "Eval Loss:  0.22058837115764618\n",
      "Eval Loss:  0.23137818276882172\n",
      "Eval Loss:  0.18395069241523743\n",
      "Eval Loss:  0.19154535233974457\n",
      "Eval Loss:  0.1405446082353592\n",
      "Eval Loss:  0.2334689348936081\n",
      "Eval Loss:  0.12893852591514587\n",
      "Eval Loss:  0.26224586367607117\n",
      "Eval Loss:  0.2389821857213974\n",
      "Eval Loss:  0.195076584815979\n",
      "[[17034  1003]\n",
      " [ 1407 10016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18037\n",
      "           1       0.91      0.88      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.918194161575017\n",
      "pre:  0.9089754061167075\n",
      "rec:  0.8768274533835244\n",
      "ma F1:  0.9132724240316072\n",
      "mi F1:  0.918194161575017\n",
      "we F1:  0.9179108355608337\n",
      "29460 461\n",
      "Loss:  0.05041995272040367\n",
      "Loss:  0.0419062077999115\n",
      "Loss:  0.051757797598838806\n",
      "42 **********\n",
      "Epoch:  2563.132703781128  fold:  7  kers:  64\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.05617682635784149\n",
      "Loss:  0.06609403342008591\n",
      "Loss:  0.07998248934745789\n",
      "43 **********\n",
      "Epoch:  2609.2414186000824  fold:  7  kers:  64\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.060153089463710785\n",
      "Loss:  0.060790129005908966\n",
      "Loss:  0.057425230741500854\n",
      "44 **********\n",
      "Epoch:  2655.3222076892853  fold:  7  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.47553229331970215\n",
      "Eval Loss:  0.0891687199473381\n",
      "Eval Loss:  1.8572514057159424\n",
      "[[1917  210]\n",
      " [ 584  720]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83      2127\n",
      "           1       0.77      0.55      0.64      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.73      0.74      3431\n",
      "weighted avg       0.77      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7685805887496356\n",
      "pre:  0.7741935483870968\n",
      "rec:  0.5521472392638037\n",
      "ma F1:  0.7365096578453987\n",
      "mi F1:  0.7685805887496356\n",
      "we F1:  0.7585600973894145\n",
      "Eval Loss:  0.27495110034942627\n",
      "Eval Loss:  0.17853088676929474\n",
      "Eval Loss:  0.14335525035858154\n",
      "Eval Loss:  0.2204502522945404\n",
      "Eval Loss:  0.2173055112361908\n",
      "Eval Loss:  0.32222262024879456\n",
      "Eval Loss:  0.24577540159225464\n",
      "Eval Loss:  0.13586311042308807\n",
      "Eval Loss:  0.19584737718105316\n",
      "Eval Loss:  0.16484513878822327\n",
      "Eval Loss:  0.17423656582832336\n",
      "Eval Loss:  0.17817869782447815\n",
      "Eval Loss:  0.2488825023174286\n",
      "Eval Loss:  0.20774021744728088\n",
      "Eval Loss:  0.17690138518810272\n",
      "Eval Loss:  0.2768166959285736\n",
      "Eval Loss:  0.18901842832565308\n",
      "Eval Loss:  0.2643864154815674\n",
      "Eval Loss:  0.21696406602859497\n",
      "Eval Loss:  0.20251592993736267\n",
      "Eval Loss:  0.1897808164358139\n",
      "Eval Loss:  0.16634692251682281\n",
      "Eval Loss:  0.13824085891246796\n",
      "Eval Loss:  0.2290438413619995\n",
      "Eval Loss:  0.12342889606952667\n",
      "Eval Loss:  0.2726507782936096\n",
      "Eval Loss:  0.2568465769290924\n",
      "Eval Loss:  0.21271972358226776\n",
      "[[16940  1097]\n",
      " [ 1373 10050]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18037\n",
      "           1       0.90      0.88      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9161575016972165\n",
      "pre:  0.9015878711761012\n",
      "rec:  0.8798039044033966\n",
      "ma F1:  0.911306106205423\n",
      "mi F1:  0.9161575016972165\n",
      "we F1:  0.9159631642290402\n",
      "29460 461\n",
      "Loss:  0.05015967786312103\n",
      "Loss:  0.05385291948914528\n",
      "Loss:  0.06005077064037323\n",
      "45 **********\n",
      "Epoch:  2741.3631522655487  fold:  7  kers:  64\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.07136887311935425\n",
      "Loss:  0.04217948764562607\n",
      "Loss:  0.055349044501781464\n",
      "46 **********\n",
      "Epoch:  2787.316282272339  fold:  7  kers:  64\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.0641852542757988\n",
      "Loss:  0.04642564803361893\n",
      "Loss:  0.04695834219455719\n",
      "47 **********\n",
      "Epoch:  2833.414026737213  fold:  7  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.46539366245269775\n",
      "Eval Loss:  0.08547285199165344\n",
      "Eval Loss:  1.9774826765060425\n",
      "[[1912  215]\n",
      " [ 600  704]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82      2127\n",
      "           1       0.77      0.54      0.63      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.72      0.73      3431\n",
      "weighted avg       0.76      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7624599242203439\n",
      "pre:  0.766050054406964\n",
      "rec:  0.5398773006134969\n",
      "ma F1:  0.7288469514221434\n",
      "mi F1:  0.7624599242203439\n",
      "we F1:  0.7517471804063478\n",
      "Eval Loss:  0.2718134820461273\n",
      "Eval Loss:  0.1925479918718338\n",
      "Eval Loss:  0.14415450394153595\n",
      "Eval Loss:  0.21501624584197998\n",
      "Eval Loss:  0.2025698870420456\n",
      "Eval Loss:  0.34985020756721497\n",
      "Eval Loss:  0.2464779168367386\n",
      "Eval Loss:  0.12109576165676117\n",
      "Eval Loss:  0.20073847472667694\n",
      "Eval Loss:  0.18628978729248047\n",
      "Eval Loss:  0.175679013133049\n",
      "Eval Loss:  0.2021748125553131\n",
      "Eval Loss:  0.23205578327178955\n",
      "Eval Loss:  0.20238833129405975\n",
      "Eval Loss:  0.1857294738292694\n",
      "Eval Loss:  0.29340746998786926\n",
      "Eval Loss:  0.20113439857959747\n",
      "Eval Loss:  0.26504379510879517\n",
      "Eval Loss:  0.22058270871639252\n",
      "Eval Loss:  0.22543519735336304\n",
      "Eval Loss:  0.1627178192138672\n",
      "Eval Loss:  0.17667709290981293\n",
      "Eval Loss:  0.1548052728176117\n",
      "Eval Loss:  0.20344045758247375\n",
      "Eval Loss:  0.13251850008964539\n",
      "Eval Loss:  0.23698566854000092\n",
      "Eval Loss:  0.24268266558647156\n",
      "Eval Loss:  0.19694387912750244\n",
      "[[16859  1178]\n",
      " [ 1272 10151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18037\n",
      "           1       0.90      0.89      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9168363883231501\n",
      "pre:  0.896019066113514\n",
      "rec:  0.8886457147859581\n",
      "ma F1:  0.9122888603768442\n",
      "mi F1:  0.9168363883231501\n",
      "we F1:  0.9167726632744092\n",
      "29460 461\n",
      "Loss:  0.05666032433509827\n",
      "Loss:  0.034880381077528\n",
      "Loss:  0.08707842230796814\n",
      "48 **********\n",
      "Epoch:  2919.3482558727264  fold:  7  kers:  64\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.04866929352283478\n",
      "Loss:  0.04126004874706268\n",
      "Loss:  0.036943469196558\n",
      "49 **********\n",
      "Epoch:  2965.3811733722687  fold:  7  kers:  64\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.06865082681179047\n",
      "Loss:  0.04566383361816406\n",
      "Loss:  0.09640634059906006\n",
      "50 **********\n",
      "Epoch:  3011.327322244644  fold:  7  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.4190208911895752\n",
      "Eval Loss:  0.042658284306526184\n",
      "Eval Loss:  2.0801031589508057\n",
      "[[1962  165]\n",
      " [ 687  617]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82      2127\n",
      "           1       0.79      0.47      0.59      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.70      0.71      3431\n",
      "weighted avg       0.76      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7516758962401632\n",
      "pre:  0.789002557544757\n",
      "rec:  0.473159509202454\n",
      "ma F1:  0.706585419908748\n",
      "mi F1:  0.7516758962401633\n",
      "we F1:  0.7341760979910936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23035882413387299\n",
      "Eval Loss:  0.1819102168083191\n",
      "Eval Loss:  0.1490570306777954\n",
      "Eval Loss:  0.22152630984783173\n",
      "Eval Loss:  0.18845508992671967\n",
      "Eval Loss:  0.347363144159317\n",
      "Eval Loss:  0.22287024557590485\n",
      "Eval Loss:  0.12446505576372147\n",
      "Eval Loss:  0.17609356343746185\n",
      "Eval Loss:  0.1613476425409317\n",
      "Eval Loss:  0.17917697131633759\n",
      "Eval Loss:  0.1811496764421463\n",
      "Eval Loss:  0.24438495934009552\n",
      "Eval Loss:  0.21297842264175415\n",
      "Eval Loss:  0.19090773165225983\n",
      "Eval Loss:  0.25939905643463135\n",
      "Eval Loss:  0.18956679105758667\n",
      "Eval Loss:  0.2534114718437195\n",
      "Eval Loss:  0.17999067902565002\n",
      "Eval Loss:  0.19805575907230377\n",
      "Eval Loss:  0.1706259399652481\n",
      "Eval Loss:  0.20379213988780975\n",
      "Eval Loss:  0.13278549909591675\n",
      "Eval Loss:  0.2380257397890091\n",
      "Eval Loss:  0.11394429951906204\n",
      "Eval Loss:  0.24741779267787933\n",
      "Eval Loss:  0.2502197325229645\n",
      "Eval Loss:  0.19059734046459198\n",
      "[[17250   787]\n",
      " [ 1620  9803]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18037\n",
      "           1       0.93      0.86      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.918295994568907\n",
      "pre:  0.9256846081208687\n",
      "rec:  0.8581808631707958\n",
      "ma F1:  0.9127187707041102\n",
      "mi F1:  0.918295994568907\n",
      "we F1:  0.9176721423493052\n",
      "29460 461\n",
      "Loss:  0.048358254134655\n",
      "Loss:  0.044335052371025085\n",
      "Loss:  0.055441826581954956\n",
      "51 **********\n",
      "Epoch:  3097.310421228409  fold:  7  kers:  64\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.044393498450517654\n",
      "Loss:  0.035303570330142975\n",
      "Loss:  0.03580484166741371\n",
      "52 **********\n",
      "Epoch:  3143.305439710617  fold:  7  kers:  64\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.06476300954818726\n",
      "Loss:  0.036710646003484726\n",
      "Loss:  0.038694992661476135\n",
      "53 **********\n",
      "Epoch:  3189.378250360489  fold:  7  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.39310458302497864\n",
      "Eval Loss:  0.07377453148365021\n",
      "Eval Loss:  1.1919876337051392\n",
      "[[1887  240]\n",
      " [ 495  809]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84      2127\n",
      "           1       0.77      0.62      0.69      1304\n",
      "\n",
      "    accuracy                           0.79      3431\n",
      "   macro avg       0.78      0.75      0.76      3431\n",
      "weighted avg       0.78      0.79      0.78      3431\n",
      "\n",
      "acc:  0.7857767414747887\n",
      "pre:  0.771210676835081\n",
      "rec:  0.620398773006135\n",
      "ma F1:  0.7623127452419145\n",
      "mi F1:  0.7857767414747887\n",
      "we F1:  0.7802263527555096\n",
      "Eval Loss:  0.2693534791469574\n",
      "Eval Loss:  0.18655388057231903\n",
      "Eval Loss:  0.13375736773014069\n",
      "Eval Loss:  0.1644953191280365\n",
      "Eval Loss:  0.1793210208415985\n",
      "Eval Loss:  0.271488755941391\n",
      "Eval Loss:  0.21106813848018646\n",
      "Eval Loss:  0.10579387843608856\n",
      "Eval Loss:  0.18034039437770844\n",
      "Eval Loss:  0.15860770642757416\n",
      "Eval Loss:  0.13376380503177643\n",
      "Eval Loss:  0.18012675642967224\n",
      "Eval Loss:  0.19783152639865875\n",
      "Eval Loss:  0.18530258536338806\n",
      "Eval Loss:  0.16710613667964935\n",
      "Eval Loss:  0.26292726397514343\n",
      "Eval Loss:  0.18132753670215607\n",
      "Eval Loss:  0.29251644015312195\n",
      "Eval Loss:  0.20958472788333893\n",
      "Eval Loss:  0.20377324521541595\n",
      "Eval Loss:  0.16601461172103882\n",
      "Eval Loss:  0.18606363236904144\n",
      "Eval Loss:  0.139303058385849\n",
      "Eval Loss:  0.21808604896068573\n",
      "Eval Loss:  0.12473661452531815\n",
      "Eval Loss:  0.23615892231464386\n",
      "Eval Loss:  0.2344525307416916\n",
      "Eval Loss:  0.19212135672569275\n",
      "[[16811  1226]\n",
      " [ 1072 10351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18037\n",
      "           1       0.89      0.91      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9219959266802444\n",
      "pre:  0.8941003714261034\n",
      "rec:  0.906154250196971\n",
      "ma F1:  0.9180557277040767\n",
      "mi F1:  0.9219959266802444\n",
      "we F1:  0.9220898571202336\n",
      "29460 461\n",
      "Loss:  0.04860641434788704\n",
      "Loss:  0.028389204293489456\n",
      "Loss:  0.054298657923936844\n",
      "54 **********\n",
      "Epoch:  3275.2586238384247  fold:  7  kers:  64\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.0776829868555069\n",
      "Loss:  0.052147816866636276\n",
      "Loss:  0.08023212850093842\n",
      "55 **********\n",
      "Epoch:  3321.3294398784637  fold:  7  kers:  64\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.06464677304029465\n",
      "Loss:  0.05832143500447273\n",
      "Loss:  0.07461673766374588\n",
      "56 **********\n",
      "Epoch:  3367.405242204666  fold:  7  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.3690294623374939\n",
      "Eval Loss:  0.1044803112745285\n",
      "Eval Loss:  1.209139108657837\n",
      "[[1847  280]\n",
      " [ 459  845]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83      2127\n",
      "           1       0.75      0.65      0.70      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.76      0.76      3431\n",
      "weighted avg       0.78      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7846109006120664\n",
      "pre:  0.7511111111111111\n",
      "rec:  0.6480061349693251\n",
      "ma F1:  0.7645276541809032\n",
      "mi F1:  0.7846109006120663\n",
      "we F1:  0.7810231749522079\n",
      "Eval Loss:  0.26006749272346497\n",
      "Eval Loss:  0.17893198132514954\n",
      "Eval Loss:  0.1343795657157898\n",
      "Eval Loss:  0.16041281819343567\n",
      "Eval Loss:  0.17070171236991882\n",
      "Eval Loss:  0.2785225808620453\n",
      "Eval Loss:  0.23096227645874023\n",
      "Eval Loss:  0.11190371960401535\n",
      "Eval Loss:  0.18925617635250092\n",
      "Eval Loss:  0.17052263021469116\n",
      "Eval Loss:  0.13109110295772552\n",
      "Eval Loss:  0.1886187493801117\n",
      "Eval Loss:  0.17490561306476593\n",
      "Eval Loss:  0.18327133357524872\n",
      "Eval Loss:  0.16795074939727783\n",
      "Eval Loss:  0.22481010854244232\n",
      "Eval Loss:  0.18526703119277954\n",
      "Eval Loss:  0.26436764001846313\n",
      "Eval Loss:  0.208348348736763\n",
      "Eval Loss:  0.22188691794872284\n",
      "Eval Loss:  0.15740613639354706\n",
      "Eval Loss:  0.1602681577205658\n",
      "Eval Loss:  0.12529528141021729\n",
      "Eval Loss:  0.19568434357643127\n",
      "Eval Loss:  0.120649553835392\n",
      "Eval Loss:  0.23214039206504822\n",
      "Eval Loss:  0.2088983654975891\n",
      "Eval Loss:  0.16454477608203888\n",
      "[[16768  1269]\n",
      " [ 1017 10406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18037\n",
      "           1       0.89      0.91      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9224032586558045\n",
      "pre:  0.8913062098501071\n",
      "rec:  0.9109690974349995\n",
      "ma F1:  0.9186074299436668\n",
      "mi F1:  0.9224032586558045\n",
      "we F1:  0.9225536121351284\n",
      "29460 461\n",
      "Loss:  0.04991954565048218\n",
      "Loss:  0.0455048643052578\n",
      "Loss:  0.03849232569336891\n",
      "57 **********\n",
      "Epoch:  3453.8780319690704  fold:  7  kers:  64\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.04213593900203705\n",
      "Loss:  0.050122275948524475\n",
      "Loss:  0.06977687776088715\n",
      "58 **********\n",
      "Epoch:  3499.982757091522  fold:  7  kers:  64\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.03746353089809418\n",
      "Loss:  0.05203156918287277\n",
      "Loss:  0.07608150690793991\n",
      "59 **********\n",
      "Epoch:  3546.047589302063  fold:  7  kers:  64\n",
      "Eval Loss:  0.4501405358314514\n",
      "Eval Loss:  0.10972500592470169\n",
      "Eval Loss:  1.7057301998138428\n",
      "[[1901  226]\n",
      " [ 590  714]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82      2127\n",
      "           1       0.76      0.55      0.64      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.72      0.73      3431\n",
      "weighted avg       0.76      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7621684640046633\n",
      "pre:  0.7595744680851064\n",
      "rec:  0.5475460122699386\n",
      "ma F1:  0.7298318831450058\n",
      "mi F1:  0.7621684640046633\n",
      "we F1:  0.7522522757713734\n",
      "update!  Acc:  0.792188866219761\n",
      "Epoch:  3550.2084641456604  fold:  7  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29817 3074\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29817 466\n",
      "Loss:  0.16753911972045898\n",
      "Loss:  0.17048269510269165\n",
      "Loss:  0.15664838254451752\n",
      "0 **********\n",
      "Epoch:  59.0391411781311  fold:  8  kers:  64\n",
      "epoch:  1\n",
      "29817 466\n",
      "Loss:  0.1361137479543686\n",
      "Loss:  0.12910319864749908\n",
      "Loss:  0.12621955573558807\n",
      "1 **********\n",
      "Epoch:  105.89884829521179  fold:  8  kers:  64\n",
      "epoch:  2\n",
      "29817 466\n",
      "Loss:  0.11976270377635956\n",
      "Loss:  0.11647810786962509\n",
      "Loss:  0.10955226421356201\n",
      "2 **********\n",
      "Epoch:  152.64785075187683  fold:  8  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.2689191401004791\n",
      "Eval Loss:  1.0577698945999146\n",
      "Eval Loss:  0.24236778914928436\n",
      "[[1839  234]\n",
      " [ 396  605]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      2073\n",
      "           1       0.72      0.60      0.66      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.77      0.75      0.76      3074\n",
      "weighted avg       0.79      0.80      0.79      3074\n",
      "\n",
      "acc:  0.7950553025374105\n",
      "pre:  0.7210965435041716\n",
      "rec:  0.6043956043956044\n",
      "ma F1:  0.7556845706673125\n",
      "mi F1:  0.7950553025374105\n",
      "we F1:  0.7898866975431189\n",
      "update!  Acc:  0.7950553025374105\n",
      "Eval Loss:  0.3284015953540802\n",
      "Eval Loss:  0.4293113052845001\n",
      "Eval Loss:  0.4562493860721588\n",
      "Eval Loss:  0.43780967593193054\n",
      "Eval Loss:  0.44003257155418396\n",
      "Eval Loss:  0.5114380717277527\n",
      "Eval Loss:  0.47666966915130615\n",
      "Eval Loss:  0.5659657716751099\n",
      "Eval Loss:  0.47154751420021057\n",
      "Eval Loss:  0.37050315737724304\n",
      "Eval Loss:  0.4079292118549347\n",
      "Eval Loss:  0.38046276569366455\n",
      "Eval Loss:  0.41613078117370605\n",
      "Eval Loss:  0.4286889135837555\n",
      "Eval Loss:  0.4261478781700134\n",
      "Eval Loss:  0.3871959149837494\n",
      "Eval Loss:  0.3957146108150482\n",
      "Eval Loss:  0.4743395447731018\n",
      "Eval Loss:  0.3762204647064209\n",
      "Eval Loss:  0.3728914260864258\n",
      "Eval Loss:  0.5060728192329407\n",
      "Eval Loss:  0.4882171154022217\n",
      "Eval Loss:  0.41023245453834534\n",
      "Eval Loss:  0.393406480550766\n",
      "Eval Loss:  0.5033360123634338\n",
      "Eval Loss:  0.4646992087364197\n",
      "Eval Loss:  0.423153281211853\n",
      "Eval Loss:  0.4422638416290283\n",
      "Eval Loss:  0.3952559232711792\n",
      "[[15488  2603]\n",
      " [ 3041  8685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85     18091\n",
      "           1       0.77      0.74      0.75     11726\n",
      "\n",
      "    accuracy                           0.81     29817\n",
      "   macro avg       0.80      0.80      0.80     29817\n",
      "weighted avg       0.81      0.81      0.81     29817\n",
      "\n",
      "acc:  0.8107120099272227\n",
      "pre:  0.7694011339475549\n",
      "rec:  0.7406617772471431\n",
      "ma F1:  0.8003172717938603\n",
      "mi F1:  0.8107120099272227\n",
      "we F1:  0.8100427617569431\n",
      "29817 466\n",
      "Loss:  0.11522544920444489\n",
      "Loss:  0.10116901248693466\n",
      "Loss:  0.0923338457942009\n",
      "3 **********\n",
      "Epoch:  239.7190399169922  fold:  8  kers:  64\n",
      "epoch:  4\n",
      "29817 466\n",
      "Loss:  0.10007217526435852\n",
      "Loss:  0.09989403933286667\n",
      "Loss:  0.09435325115919113\n",
      "4 **********\n",
      "Epoch:  286.52788281440735  fold:  8  kers:  64\n",
      "epoch:  5\n",
      "29817 466\n",
      "Loss:  0.06039367988705635\n",
      "Loss:  0.12045541405677795\n",
      "Loss:  0.0717848613858223\n",
      "5 **********\n",
      "Epoch:  333.27788257598877  fold:  8  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.40047770738601685\n",
      "Eval Loss:  1.3336639404296875\n",
      "Eval Loss:  0.27425241470336914\n",
      "[[1797  276]\n",
      " [ 290  711]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      2073\n",
      "           1       0.72      0.71      0.72      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.79      0.79      0.79      3074\n",
      "weighted avg       0.82      0.82      0.82      3074\n",
      "\n",
      "acc:  0.8158750813272609\n",
      "pre:  0.7203647416413373\n",
      "rec:  0.7102897102897103\n",
      "ma F1:  0.7896170290976628\n",
      "mi F1:  0.8158750813272609\n",
      "we F1:  0.8155365797331409\n",
      "update!  Acc:  0.8158750813272609\n",
      "Eval Loss:  0.2931162714958191\n",
      "Eval Loss:  0.3313489854335785\n",
      "Eval Loss:  0.4235838055610657\n",
      "Eval Loss:  0.4224914312362671\n",
      "Eval Loss:  0.3050103485584259\n",
      "Eval Loss:  0.3737888038158417\n",
      "Eval Loss:  0.40746498107910156\n",
      "Eval Loss:  0.41390925645828247\n",
      "Eval Loss:  0.3923725485801697\n",
      "Eval Loss:  0.266192227602005\n",
      "Eval Loss:  0.26743701100349426\n",
      "Eval Loss:  0.4004610478878021\n",
      "Eval Loss:  0.3552442193031311\n",
      "Eval Loss:  0.2728287875652313\n",
      "Eval Loss:  0.3712174892425537\n",
      "Eval Loss:  0.33730053901672363\n",
      "Eval Loss:  0.3430704176425934\n",
      "Eval Loss:  0.35693585872650146\n",
      "Eval Loss:  0.2749030590057373\n",
      "Eval Loss:  0.30618301033973694\n",
      "Eval Loss:  0.3429569602012634\n",
      "Eval Loss:  0.37757861614227295\n",
      "Eval Loss:  0.3307414650917053\n",
      "Eval Loss:  0.36227357387542725\n",
      "Eval Loss:  0.4032093286514282\n",
      "Eval Loss:  0.2747098505496979\n",
      "Eval Loss:  0.35834261775016785\n",
      "Eval Loss:  0.34399279952049255\n",
      "Eval Loss:  0.2724885046482086\n",
      "[[15696  2395]\n",
      " [ 1795  9931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88     18091\n",
      "           1       0.81      0.85      0.83     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.85      0.86      0.85     29817\n",
      "weighted avg       0.86      0.86      0.86     29817\n",
      "\n",
      "acc:  0.8594761377737532\n",
      "pre:  0.805695278273568\n",
      "rec:  0.8469213713116153\n",
      "ma F1:  0.8540189719531388\n",
      "mi F1:  0.8594761377737532\n",
      "we F1:  0.8600440995243809\n",
      "29817 466\n",
      "Loss:  0.11323478072881699\n",
      "Loss:  0.0882604792714119\n",
      "Loss:  0.0811932310461998\n",
      "6 **********\n",
      "Epoch:  420.10871410369873  fold:  8  kers:  64\n",
      "epoch:  7\n",
      "29817 466\n",
      "Loss:  0.08793815225362778\n",
      "Loss:  0.057648349553346634\n",
      "Loss:  0.09558932483196259\n",
      "7 **********\n",
      "Epoch:  466.83178663253784  fold:  8  kers:  64\n",
      "epoch:  8\n",
      "29817 466\n",
      "Loss:  0.0792168453335762\n",
      "Loss:  0.07613356411457062\n",
      "Loss:  0.08738350123167038\n",
      "8 **********\n",
      "Epoch:  513.6276640892029  fold:  8  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.2349589467048645\n",
      "Eval Loss:  1.6600818634033203\n",
      "Eval Loss:  0.13951724767684937\n",
      "[[1982   91]\n",
      " [ 464  537]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      2073\n",
      "           1       0.86      0.54      0.66      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.83      0.75      0.77      3074\n",
      "weighted avg       0.82      0.82      0.81      3074\n",
      "\n",
      "acc:  0.8194534808067664\n",
      "pre:  0.8550955414012739\n",
      "rec:  0.5364635364635365\n",
      "ma F1:  0.7682427010653199\n",
      "mi F1:  0.8194534808067664\n",
      "we F1:  0.8062343660361371\n",
      "update!  Acc:  0.8194534808067664\n",
      "Eval Loss:  0.28484082221984863\n",
      "Eval Loss:  0.30555278062820435\n",
      "Eval Loss:  0.3858935236930847\n",
      "Eval Loss:  0.40084603428840637\n",
      "Eval Loss:  0.3392716348171234\n",
      "Eval Loss:  0.40124815702438354\n",
      "Eval Loss:  0.4351598620414734\n",
      "Eval Loss:  0.3962988257408142\n",
      "Eval Loss:  0.3665258586406708\n",
      "Eval Loss:  0.28970909118652344\n",
      "Eval Loss:  0.27492958307266235\n",
      "Eval Loss:  0.29811590909957886\n",
      "Eval Loss:  0.3172234892845154\n",
      "Eval Loss:  0.2731945812702179\n",
      "Eval Loss:  0.3526788651943207\n",
      "Eval Loss:  0.32500192523002625\n",
      "Eval Loss:  0.3346470296382904\n",
      "Eval Loss:  0.3513002395629883\n",
      "Eval Loss:  0.26216182112693787\n",
      "Eval Loss:  0.32837286591529846\n",
      "Eval Loss:  0.4525194466114044\n",
      "Eval Loss:  0.4713827073574066\n",
      "Eval Loss:  0.3180760443210602\n",
      "Eval Loss:  0.30972418189048767\n",
      "Eval Loss:  0.4835684597492218\n",
      "Eval Loss:  0.3047065734863281\n",
      "Eval Loss:  0.4059286415576935\n",
      "Eval Loss:  0.3388786017894745\n",
      "Eval Loss:  0.282583624124527\n",
      "[[17180   911]\n",
      " [ 3093  8633]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     18091\n",
      "           1       0.90      0.74      0.81     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.88      0.84      0.85     29817\n",
      "weighted avg       0.87      0.87      0.86     29817\n",
      "\n",
      "acc:  0.8657141898916725\n",
      "pre:  0.904547359597653\n",
      "rec:  0.7362271874466997\n",
      "ma F1:  0.8536924823298289\n",
      "mi F1:  0.8657141898916725\n",
      "we F1:  0.8626451170123064\n",
      "29817 466\n",
      "Loss:  0.07021306455135345\n",
      "Loss:  0.10056138783693314\n",
      "Loss:  0.1133543848991394\n",
      "9 **********\n",
      "Epoch:  600.3916747570038  fold:  8  kers:  64\n",
      "epoch:  10\n",
      "29817 466\n",
      "Loss:  0.07266976684331894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08743362128734589\n",
      "Loss:  0.0932920053601265\n",
      "10 **********\n",
      "Epoch:  647.0309703350067  fold:  8  kers:  64\n",
      "epoch:  11\n",
      "29817 466\n",
      "Loss:  0.07692914456129074\n",
      "Loss:  0.09951178729534149\n",
      "Loss:  0.11795330792665482\n",
      "11 **********\n",
      "Epoch:  693.7380847930908  fold:  8  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.22873423993587494\n",
      "Eval Loss:  1.539627194404602\n",
      "Eval Loss:  0.10725206881761551\n",
      "[[2006   67]\n",
      " [ 530  471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87      2073\n",
      "           1       0.88      0.47      0.61      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.83      0.72      0.74      3074\n",
      "weighted avg       0.82      0.81      0.79      3074\n",
      "\n",
      "acc:  0.8057905009759271\n",
      "pre:  0.8754646840148699\n",
      "rec:  0.47052947052947053\n",
      "ma F1:  0.7412782939726791\n",
      "mi F1:  0.8057905009759271\n",
      "we F1:  0.7863317701339051\n",
      "Eval Loss:  0.29430779814720154\n",
      "Eval Loss:  0.28948065638542175\n",
      "Eval Loss:  0.4195237159729004\n",
      "Eval Loss:  0.4001220762729645\n",
      "Eval Loss:  0.36548423767089844\n",
      "Eval Loss:  0.3938651382923126\n",
      "Eval Loss:  0.4598470628261566\n",
      "Eval Loss:  0.3942842483520508\n",
      "Eval Loss:  0.3809758722782135\n",
      "Eval Loss:  0.29452669620513916\n",
      "Eval Loss:  0.26347342133522034\n",
      "Eval Loss:  0.256214439868927\n",
      "Eval Loss:  0.3517811894416809\n",
      "Eval Loss:  0.26258766651153564\n",
      "Eval Loss:  0.34040623903274536\n",
      "Eval Loss:  0.34149429202079773\n",
      "Eval Loss:  0.3188035488128662\n",
      "Eval Loss:  0.36019593477249146\n",
      "Eval Loss:  0.2791377305984497\n",
      "Eval Loss:  0.3609362840652466\n",
      "Eval Loss:  0.4877779185771942\n",
      "Eval Loss:  0.5044452548027039\n",
      "Eval Loss:  0.30577248334884644\n",
      "Eval Loss:  0.30022937059402466\n",
      "Eval Loss:  0.5120042562484741\n",
      "Eval Loss:  0.3675345182418823\n",
      "Eval Loss:  0.40274953842163086\n",
      "Eval Loss:  0.3533284664154053\n",
      "Eval Loss:  0.2759353220462799\n",
      "[[17512   579]\n",
      " [ 3517  8209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     18091\n",
      "           1       0.93      0.70      0.80     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.88      0.83      0.85     29817\n",
      "weighted avg       0.87      0.86      0.86     29817\n",
      "\n",
      "acc:  0.8626287017473253\n",
      "pre:  0.9341147018661812\n",
      "rec:  0.7000682244584684\n",
      "ma F1:  0.8478140022286142\n",
      "mi F1:  0.8626287017473253\n",
      "we F1:  0.8579500403277861\n",
      "29817 466\n",
      "Loss:  0.11918824166059494\n",
      "Loss:  0.08423218131065369\n",
      "Loss:  0.07111991941928864\n",
      "12 **********\n",
      "Epoch:  780.4731736183167  fold:  8  kers:  64\n",
      "epoch:  13\n",
      "29817 466\n",
      "Loss:  0.08737283945083618\n",
      "Loss:  0.02642921730875969\n",
      "Loss:  0.0520394891500473\n",
      "13 **********\n",
      "Epoch:  827.0955145359039  fold:  8  kers:  64\n",
      "epoch:  14\n",
      "29817 466\n",
      "Loss:  0.07427281141281128\n",
      "Loss:  0.04667234420776367\n",
      "Loss:  0.0554051473736763\n",
      "14 **********\n",
      "Epoch:  873.8265652656555  fold:  8  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.37053632736206055\n",
      "Eval Loss:  1.2156089544296265\n",
      "Eval Loss:  0.10940179228782654\n",
      "[[1889  184]\n",
      " [ 337  664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      2073\n",
      "           1       0.78      0.66      0.72      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.82      0.79      0.80      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8305139882888745\n",
      "pre:  0.7830188679245284\n",
      "rec:  0.6633366633366633\n",
      "ma F1:  0.7985175467498384\n",
      "mi F1:  0.8305139882888745\n",
      "we F1:  0.826517698039509\n",
      "update!  Acc:  0.8305139882888745\n",
      "Eval Loss:  0.25929883122444153\n",
      "Eval Loss:  0.27101802825927734\n",
      "Eval Loss:  0.3540214002132416\n",
      "Eval Loss:  0.3394629955291748\n",
      "Eval Loss:  0.29935383796691895\n",
      "Eval Loss:  0.33251717686653137\n",
      "Eval Loss:  0.3834907114505768\n",
      "Eval Loss:  0.30127933621406555\n",
      "Eval Loss:  0.32804808020591736\n",
      "Eval Loss:  0.21767373383045197\n",
      "Eval Loss:  0.20549148321151733\n",
      "Eval Loss:  0.25271978974342346\n",
      "Eval Loss:  0.306633323431015\n",
      "Eval Loss:  0.20028164982795715\n",
      "Eval Loss:  0.2896648049354553\n",
      "Eval Loss:  0.25019702315330505\n",
      "Eval Loss:  0.25348934531211853\n",
      "Eval Loss:  0.28675001859664917\n",
      "Eval Loss:  0.24956563115119934\n",
      "Eval Loss:  0.2744847536087036\n",
      "Eval Loss:  0.3898659944534302\n",
      "Eval Loss:  0.38165155053138733\n",
      "Eval Loss:  0.2437896728515625\n",
      "Eval Loss:  0.2701330780982971\n",
      "Eval Loss:  0.4062258303165436\n",
      "Eval Loss:  0.2682066261768341\n",
      "Eval Loss:  0.31976819038391113\n",
      "Eval Loss:  0.29612892866134644\n",
      "Eval Loss:  0.2016882747411728\n",
      "[[17123   968]\n",
      " [ 2418  9308]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18091\n",
      "           1       0.91      0.79      0.85     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.89      0.87      0.88     29817\n",
      "weighted avg       0.89      0.89      0.88     29817\n",
      "\n",
      "acc:  0.8864406211221786\n",
      "pre:  0.905799922148696\n",
      "rec:  0.7937915742793792\n",
      "ma F1:  0.8780641419541637\n",
      "mi F1:  0.8864406211221787\n",
      "we F1:  0.8848864439252981\n",
      "29817 466\n",
      "Loss:  0.07892335206270218\n",
      "Loss:  0.07950495183467865\n",
      "Loss:  0.0803297758102417\n",
      "15 **********\n",
      "Epoch:  960.7062664031982  fold:  8  kers:  64\n",
      "epoch:  16\n",
      "29817 466\n",
      "Loss:  0.05488118901848793\n",
      "Loss:  0.06770628690719604\n",
      "Loss:  0.049611132591962814\n",
      "16 **********\n",
      "Epoch:  1007.4203624725342  fold:  8  kers:  64\n",
      "epoch:  17\n",
      "29817 466\n",
      "Loss:  0.0771530270576477\n",
      "Loss:  0.06478026509284973\n",
      "Loss:  0.06634097546339035\n",
      "17 **********\n",
      "Epoch:  1054.0077974796295  fold:  8  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.37285974621772766\n",
      "Eval Loss:  1.2029727697372437\n",
      "Eval Loss:  0.10137937217950821\n",
      "[[1949  124]\n",
      " [ 393  608]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      2073\n",
      "           1       0.83      0.61      0.70      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.83      0.77      0.79      3074\n",
      "weighted avg       0.83      0.83      0.82      3074\n",
      "\n",
      "acc:  0.8318152244632401\n",
      "pre:  0.8306010928961749\n",
      "rec:  0.6073926073926074\n",
      "ma F1:  0.7922863029892716\n",
      "mi F1:  0.8318152244632401\n",
      "we F1:  0.8238858584106693\n",
      "update!  Acc:  0.8318152244632401\n",
      "Eval Loss:  0.24976186454296112\n",
      "Eval Loss:  0.25210487842559814\n",
      "Eval Loss:  0.35192009806632996\n",
      "Eval Loss:  0.3163582384586334\n",
      "Eval Loss:  0.2668794095516205\n",
      "Eval Loss:  0.3154345154762268\n",
      "Eval Loss:  0.3816818594932556\n",
      "Eval Loss:  0.2737730145454407\n",
      "Eval Loss:  0.3413843810558319\n",
      "Eval Loss:  0.2395530790090561\n",
      "Eval Loss:  0.19737760722637177\n",
      "Eval Loss:  0.21548214554786682\n",
      "Eval Loss:  0.2880169749259949\n",
      "Eval Loss:  0.19791662693023682\n",
      "Eval Loss:  0.28993794322013855\n",
      "Eval Loss:  0.26556596159935\n",
      "Eval Loss:  0.23399564623832703\n",
      "Eval Loss:  0.26691362261772156\n",
      "Eval Loss:  0.23956182599067688\n",
      "Eval Loss:  0.2699185311794281\n",
      "Eval Loss:  0.3821357488632202\n",
      "Eval Loss:  0.37547457218170166\n",
      "Eval Loss:  0.2450406551361084\n",
      "Eval Loss:  0.2673543095588684\n",
      "Eval Loss:  0.38962000608444214\n",
      "Eval Loss:  0.3099312484264374\n",
      "Eval Loss:  0.3037685453891754\n",
      "Eval Loss:  0.2591082751750946\n",
      "Eval Loss:  0.20105405151844025\n",
      "[[17339   752]\n",
      " [ 2568  9158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     18091\n",
      "           1       0.92      0.78      0.85     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.87      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8886541234866016\n",
      "pre:  0.924117053481332\n",
      "rec:  0.7809994883165615\n",
      "ma F1:  0.8795895116294326\n",
      "mi F1:  0.8886541234866016\n",
      "we F1:  0.8866419813117306\n",
      "29817 466\n",
      "Loss:  0.061533309519290924\n",
      "Loss:  0.06666788458824158\n",
      "Loss:  0.05317351222038269\n",
      "18 **********\n",
      "Epoch:  1140.880517244339  fold:  8  kers:  64\n",
      "epoch:  19\n",
      "29817 466\n",
      "Loss:  0.053134236484766006\n",
      "Loss:  0.04448089376091957\n",
      "Loss:  0.055361293256282806\n",
      "19 **********\n",
      "Epoch:  1187.6494665145874  fold:  8  kers:  64\n",
      "epoch:  20\n",
      "29817 466\n",
      "Loss:  0.054503388702869415\n",
      "Loss:  0.06716179847717285\n",
      "Loss:  0.056906312704086304\n",
      "20 **********\n",
      "Epoch:  1234.477258682251  fold:  8  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.6701565384864807\n",
      "Eval Loss:  1.1915866136550903\n",
      "Eval Loss:  0.1172509416937828\n",
      "[[1697  376]\n",
      " [ 273  728]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      2073\n",
      "           1       0.66      0.73      0.69      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.76      0.77      0.77      3074\n",
      "weighted avg       0.80      0.79      0.79      3074\n",
      "\n",
      "acc:  0.7888744307091737\n",
      "pre:  0.6594202898550725\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.7655810488554453\n",
      "mi F1:  0.7888744307091737\n",
      "we F1:  0.7913504042189095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24694640934467316\n",
      "Eval Loss:  0.23115915060043335\n",
      "Eval Loss:  0.31112244725227356\n",
      "Eval Loss:  0.31071698665618896\n",
      "Eval Loss:  0.22762706875801086\n",
      "Eval Loss:  0.3053041994571686\n",
      "Eval Loss:  0.37246572971343994\n",
      "Eval Loss:  0.2681671380996704\n",
      "Eval Loss:  0.30925795435905457\n",
      "Eval Loss:  0.20521272718906403\n",
      "Eval Loss:  0.16717886924743652\n",
      "Eval Loss:  0.23752523958683014\n",
      "Eval Loss:  0.2730357348918915\n",
      "Eval Loss:  0.1791231483221054\n",
      "Eval Loss:  0.28429582715034485\n",
      "Eval Loss:  0.2301788479089737\n",
      "Eval Loss:  0.21484260261058807\n",
      "Eval Loss:  0.24911536276340485\n",
      "Eval Loss:  0.22503358125686646\n",
      "Eval Loss:  0.2421816736459732\n",
      "Eval Loss:  0.3088226616382599\n",
      "Eval Loss:  0.3116115629673004\n",
      "Eval Loss:  0.23613382875919342\n",
      "Eval Loss:  0.29661062359809875\n",
      "Eval Loss:  0.3362765312194824\n",
      "Eval Loss:  0.23726671934127808\n",
      "Eval Loss:  0.27769309282302856\n",
      "Eval Loss:  0.24844375252723694\n",
      "Eval Loss:  0.16771996021270752\n",
      "[[17068  1023]\n",
      " [ 2027  9699]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     18091\n",
      "           1       0.90      0.83      0.86     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8977093604319684\n",
      "pre:  0.9045886961387801\n",
      "rec:  0.8271362783557905\n",
      "ma F1:  0.8910551598427645\n",
      "mi F1:  0.8977093604319685\n",
      "we F1:  0.8968027493054165\n",
      "29817 466\n",
      "Loss:  0.06674517691135406\n",
      "Loss:  0.10368353128433228\n",
      "Loss:  0.07844337075948715\n",
      "21 **********\n",
      "Epoch:  1321.2312960624695  fold:  8  kers:  64\n",
      "epoch:  22\n",
      "29817 466\n",
      "Loss:  0.04689789563417435\n",
      "Loss:  0.060170043259859085\n",
      "Loss:  0.06810876727104187\n",
      "22 **********\n",
      "Epoch:  1367.8735835552216  fold:  8  kers:  64\n",
      "epoch:  23\n",
      "29817 466\n",
      "Loss:  0.06882855296134949\n",
      "Loss:  0.08498919010162354\n",
      "Loss:  0.06178435683250427\n",
      "23 **********\n",
      "Epoch:  1414.4680001735687  fold:  8  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.36759403347969055\n",
      "Eval Loss:  0.9588639736175537\n",
      "Eval Loss:  0.10109826922416687\n",
      "[[1934  139]\n",
      " [ 352  649]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      2073\n",
      "           1       0.82      0.65      0.73      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.83      0.79      0.81      3074\n",
      "weighted avg       0.84      0.84      0.83      3074\n",
      "\n",
      "acc:  0.8402732595966168\n",
      "pre:  0.8236040609137056\n",
      "rec:  0.6483516483516484\n",
      "ma F1:  0.8064522416629063\n",
      "mi F1:  0.8402732595966169\n",
      "we F1:  0.8346671297756982\n",
      "update!  Acc:  0.8402732595966168\n",
      "Eval Loss:  0.22686463594436646\n",
      "Eval Loss:  0.2583121359348297\n",
      "Eval Loss:  0.3436031937599182\n",
      "Eval Loss:  0.2818929851055145\n",
      "Eval Loss:  0.27756112813949585\n",
      "Eval Loss:  0.30580413341522217\n",
      "Eval Loss:  0.3621421456336975\n",
      "Eval Loss:  0.28295764327049255\n",
      "Eval Loss:  0.327875554561615\n",
      "Eval Loss:  0.20599780976772308\n",
      "Eval Loss:  0.18289333581924438\n",
      "Eval Loss:  0.21261997520923615\n",
      "Eval Loss:  0.2649487555027008\n",
      "Eval Loss:  0.18405495584011078\n",
      "Eval Loss:  0.29814863204956055\n",
      "Eval Loss:  0.23845845460891724\n",
      "Eval Loss:  0.23373880982398987\n",
      "Eval Loss:  0.27198225259780884\n",
      "Eval Loss:  0.2524065375328064\n",
      "Eval Loss:  0.2341887205839157\n",
      "Eval Loss:  0.36761045455932617\n",
      "Eval Loss:  0.3058949112892151\n",
      "Eval Loss:  0.2761269807815552\n",
      "Eval Loss:  0.29427626729011536\n",
      "Eval Loss:  0.3637165427207947\n",
      "Eval Loss:  0.28346914052963257\n",
      "Eval Loss:  0.2842436134815216\n",
      "Eval Loss:  0.2806897759437561\n",
      "Eval Loss:  0.20710761845111847\n",
      "[[17194   897]\n",
      " [ 2240  9486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     18091\n",
      "           1       0.91      0.81      0.86     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.88      0.89     29817\n",
      "weighted avg       0.90      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8947915618606835\n",
      "pre:  0.9136087835885582\n",
      "rec:  0.8089715162885894\n",
      "ma F1:  0.8872572397270153\n",
      "mi F1:  0.8947915618606835\n",
      "we F1:  0.893478822547565\n",
      "29817 466\n",
      "Loss:  0.052909571677446365\n",
      "Loss:  0.06013857573270798\n",
      "Loss:  0.055922962725162506\n",
      "24 **********\n",
      "Epoch:  1501.2160532474518  fold:  8  kers:  64\n",
      "epoch:  25\n",
      "29817 466\n",
      "Loss:  0.07427185028791428\n",
      "Loss:  0.06148368865251541\n",
      "Loss:  0.06590133160352707\n",
      "25 **********\n",
      "Epoch:  1547.9291520118713  fold:  8  kers:  64\n",
      "epoch:  26\n",
      "29817 466\n",
      "Loss:  0.07663053274154663\n",
      "Loss:  0.06375863403081894\n",
      "Loss:  0.03977830708026886\n",
      "26 **********\n",
      "Epoch:  1594.9175145626068  fold:  8  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.3325967490673065\n",
      "Eval Loss:  1.0912117958068848\n",
      "Eval Loss:  0.0951787531375885\n",
      "[[1885  188]\n",
      " [ 365  636]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87      2073\n",
      "           1       0.77      0.64      0.70      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.80      0.77      0.78      3074\n",
      "weighted avg       0.82      0.82      0.82      3074\n",
      "\n",
      "acc:  0.8201040988939493\n",
      "pre:  0.7718446601941747\n",
      "rec:  0.6353646353646354\n",
      "ma F1:  0.7845329378697568\n",
      "mi F1:  0.8201040988939493\n",
      "we F1:  0.815063189765621\n",
      "Eval Loss:  0.24031208455562592\n",
      "Eval Loss:  0.22565096616744995\n",
      "Eval Loss:  0.3021202087402344\n",
      "Eval Loss:  0.26513755321502686\n",
      "Eval Loss:  0.2652488052845001\n",
      "Eval Loss:  0.3129845857620239\n",
      "Eval Loss:  0.33648738265037537\n",
      "Eval Loss:  0.2898333668708801\n",
      "Eval Loss:  0.29168495535850525\n",
      "Eval Loss:  0.21834102272987366\n",
      "Eval Loss:  0.1993633210659027\n",
      "Eval Loss:  0.18763136863708496\n",
      "Eval Loss:  0.2525455951690674\n",
      "Eval Loss:  0.19221840798854828\n",
      "Eval Loss:  0.28134363889694214\n",
      "Eval Loss:  0.24093836545944214\n",
      "Eval Loss:  0.2280336171388626\n",
      "Eval Loss:  0.264217734336853\n",
      "Eval Loss:  0.24827565252780914\n",
      "Eval Loss:  0.23544859886169434\n",
      "Eval Loss:  0.36514756083488464\n",
      "Eval Loss:  0.3262532949447632\n",
      "Eval Loss:  0.24733339250087738\n",
      "Eval Loss:  0.28419938683509827\n",
      "Eval Loss:  0.3340270221233368\n",
      "Eval Loss:  0.27592381834983826\n",
      "Eval Loss:  0.29931843280792236\n",
      "Eval Loss:  0.26544690132141113\n",
      "Eval Loss:  0.2008272111415863\n",
      "[[17443   648]\n",
      " [ 2391  9335]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18091\n",
      "           1       0.94      0.80      0.86     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.91      0.88      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8980782774927055\n",
      "pre:  0.9350896524090955\n",
      "rec:  0.7960941497526863\n",
      "ma F1:  0.8899400687216688\n",
      "mi F1:  0.8980782774927055\n",
      "we F1:  0.8963287834266082\n",
      "29817 466\n",
      "Loss:  0.09017391502857208\n",
      "Loss:  0.06846736371517181\n",
      "Loss:  0.055373162031173706\n",
      "27 **********\n",
      "Epoch:  1681.4102506637573  fold:  8  kers:  64\n",
      "epoch:  28\n",
      "29817 466\n",
      "Loss:  0.07085663825273514\n",
      "Loss:  0.05035846680402756\n",
      "Loss:  0.040189437568187714\n",
      "28 **********\n",
      "Epoch:  1728.0684957504272  fold:  8  kers:  64\n",
      "epoch:  29\n",
      "29817 466\n",
      "Loss:  0.04317430406808853\n",
      "Loss:  0.09543199837207794\n",
      "Loss:  0.06858537346124649\n",
      "29 **********\n",
      "Epoch:  1774.6379790306091  fold:  8  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.34137481451034546\n",
      "Eval Loss:  0.9976661801338196\n",
      "Eval Loss:  0.10950135439634323\n",
      "[[1898  175]\n",
      " [ 284  717]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      2073\n",
      "           1       0.80      0.72      0.76      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.82      0.82      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.850683148991542\n",
      "pre:  0.8038116591928252\n",
      "rec:  0.7162837162837162\n",
      "ma F1:  0.8248273216370785\n",
      "mi F1:  0.8506831489915418\n",
      "we F1:  0.8482967940536618\n",
      "update!  Acc:  0.850683148991542\n",
      "Eval Loss:  0.21781377494335175\n",
      "Eval Loss:  0.22507385909557343\n",
      "Eval Loss:  0.28183913230895996\n",
      "Eval Loss:  0.2550751864910126\n",
      "Eval Loss:  0.22636760771274567\n",
      "Eval Loss:  0.28835445642471313\n",
      "Eval Loss:  0.3039536774158478\n",
      "Eval Loss:  0.2596842050552368\n",
      "Eval Loss:  0.26825863122940063\n",
      "Eval Loss:  0.2092932015657425\n",
      "Eval Loss:  0.19876907765865326\n",
      "Eval Loss:  0.19524061679840088\n",
      "Eval Loss:  0.24086888134479523\n",
      "Eval Loss:  0.18250279128551483\n",
      "Eval Loss:  0.28414207696914673\n",
      "Eval Loss:  0.22449055314064026\n",
      "Eval Loss:  0.2210969626903534\n",
      "Eval Loss:  0.24173234403133392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2681911587715149\n",
      "Eval Loss:  0.21747121214866638\n",
      "Eval Loss:  0.3267286419868469\n",
      "Eval Loss:  0.3043312430381775\n",
      "Eval Loss:  0.22801434993743896\n",
      "Eval Loss:  0.28304415941238403\n",
      "Eval Loss:  0.291792094707489\n",
      "Eval Loss:  0.2564898729324341\n",
      "Eval Loss:  0.25666284561157227\n",
      "Eval Loss:  0.258669376373291\n",
      "Eval Loss:  0.20026858150959015\n",
      "[[17187   904]\n",
      " [ 2012  9714]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18091\n",
      "           1       0.91      0.83      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.91      0.89      0.90     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.9022034409900392\n",
      "pre:  0.9148615558485591\n",
      "rec:  0.8284154869520723\n",
      "ma F1:  0.8956486291006219\n",
      "mi F1:  0.9022034409900392\n",
      "we F1:  0.9012315780737441\n",
      "29817 466\n",
      "Loss:  0.0603579618036747\n",
      "Loss:  0.057631783187389374\n",
      "Loss:  0.04792429134249687\n",
      "30 **********\n",
      "Epoch:  1865.1409919261932  fold:  8  kers:  64\n",
      "epoch:  31\n",
      "29817 466\n",
      "Loss:  0.04097811132669449\n",
      "Loss:  0.07521330565214157\n",
      "Loss:  0.029237041249871254\n",
      "31 **********\n",
      "Epoch:  1911.888997554779  fold:  8  kers:  64\n",
      "epoch:  32\n",
      "29817 466\n",
      "Loss:  0.057320527732372284\n",
      "Loss:  0.07869035005569458\n",
      "Loss:  0.09078095853328705\n",
      "32 **********\n",
      "Epoch:  1958.7746345996857  fold:  8  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.507103443145752\n",
      "Eval Loss:  0.9299060106277466\n",
      "Eval Loss:  0.09881656616926193\n",
      "[[1895  178]\n",
      " [ 275  726]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      2073\n",
      "           1       0.80      0.73      0.76      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.82      0.83      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8526350032530904\n",
      "pre:  0.8030973451327433\n",
      "rec:  0.7252747252747253\n",
      "ma F1:  0.8277203211960042\n",
      "mi F1:  0.8526350032530904\n",
      "we F1:  0.8505676600883878\n",
      "update!  Acc:  0.8526350032530904\n",
      "Eval Loss:  0.21925435960292816\n",
      "Eval Loss:  0.21773281693458557\n",
      "Eval Loss:  0.2575611174106598\n",
      "Eval Loss:  0.24108798801898956\n",
      "Eval Loss:  0.22218506038188934\n",
      "Eval Loss:  0.28361350297927856\n",
      "Eval Loss:  0.3180369734764099\n",
      "Eval Loss:  0.2637728154659271\n",
      "Eval Loss:  0.24314197897911072\n",
      "Eval Loss:  0.19610701501369476\n",
      "Eval Loss:  0.1915857046842575\n",
      "Eval Loss:  0.19944916665554047\n",
      "Eval Loss:  0.24731336534023285\n",
      "Eval Loss:  0.15807196497917175\n",
      "Eval Loss:  0.2582857608795166\n",
      "Eval Loss:  0.21188458800315857\n",
      "Eval Loss:  0.2221144735813141\n",
      "Eval Loss:  0.2299685776233673\n",
      "Eval Loss:  0.2517280578613281\n",
      "Eval Loss:  0.21691544353961945\n",
      "Eval Loss:  0.30811750888824463\n",
      "Eval Loss:  0.2506861388683319\n",
      "Eval Loss:  0.2310679852962494\n",
      "Eval Loss:  0.2687414884567261\n",
      "Eval Loss:  0.28516483306884766\n",
      "Eval Loss:  0.24028779566287994\n",
      "Eval Loss:  0.2580089867115021\n",
      "Eval Loss:  0.23570086061954498\n",
      "Eval Loss:  0.216871440410614\n",
      "[[17231   860]\n",
      " [ 1895  9831]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     18091\n",
      "           1       0.92      0.84      0.88     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.90      0.90     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9076030452426468\n",
      "pre:  0.9195585071555514\n",
      "rec:  0.8383933140030702\n",
      "ma F1:  0.9015384441050096\n",
      "mi F1:  0.9076030452426468\n",
      "we F1:  0.9067548206240719\n",
      "29817 466\n",
      "Loss:  0.08393022418022156\n",
      "Loss:  0.05307205766439438\n",
      "Loss:  0.049018632620573044\n",
      "33 **********\n",
      "Epoch:  2045.5954928398132  fold:  8  kers:  64\n",
      "epoch:  34\n",
      "29817 466\n",
      "Loss:  0.04335220903158188\n",
      "Loss:  0.056400544941425323\n",
      "Loss:  0.039471667259931564\n",
      "34 **********\n",
      "Epoch:  2092.378404855728  fold:  8  kers:  64\n",
      "epoch:  35\n",
      "29817 466\n",
      "Loss:  0.07308439910411835\n",
      "Loss:  0.07782111316919327\n",
      "Loss:  0.07689063996076584\n",
      "35 **********\n",
      "Epoch:  2139.1064636707306  fold:  8  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.3325936794281006\n",
      "Eval Loss:  0.9890556931495667\n",
      "Eval Loss:  0.10791988670825958\n",
      "[[1917  156]\n",
      " [ 321  680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      2073\n",
      "           1       0.81      0.68      0.74      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.83      0.80      0.81      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8448275862068966\n",
      "pre:  0.8133971291866029\n",
      "rec:  0.6793206793206793\n",
      "ma F1:  0.8148451625880901\n",
      "mi F1:  0.8448275862068967\n",
      "we F1:  0.8408283138567728\n",
      "Eval Loss:  0.20244435966014862\n",
      "Eval Loss:  0.20203572511672974\n",
      "Eval Loss:  0.26583579182624817\n",
      "Eval Loss:  0.23113682866096497\n",
      "Eval Loss:  0.2165917158126831\n",
      "Eval Loss:  0.2849127948284149\n",
      "Eval Loss:  0.29960015416145325\n",
      "Eval Loss:  0.21915538609027863\n",
      "Eval Loss:  0.24749431014060974\n",
      "Eval Loss:  0.19518928229808807\n",
      "Eval Loss:  0.15841460227966309\n",
      "Eval Loss:  0.16544292867183685\n",
      "Eval Loss:  0.24031665921211243\n",
      "Eval Loss:  0.16947390139102936\n",
      "Eval Loss:  0.26138484477996826\n",
      "Eval Loss:  0.2122248411178589\n",
      "Eval Loss:  0.20213556289672852\n",
      "Eval Loss:  0.24630799889564514\n",
      "Eval Loss:  0.22359131276607513\n",
      "Eval Loss:  0.20334115624427795\n",
      "Eval Loss:  0.34837594628334045\n",
      "Eval Loss:  0.29668188095092773\n",
      "Eval Loss:  0.19696633517742157\n",
      "Eval Loss:  0.2531380355358124\n",
      "Eval Loss:  0.2786760926246643\n",
      "Eval Loss:  0.23421142995357513\n",
      "Eval Loss:  0.24786697328090668\n",
      "Eval Loss:  0.20044758915901184\n",
      "Eval Loss:  0.17010092735290527\n",
      "[[17403   688]\n",
      " [ 1960  9766]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18091\n",
      "           1       0.93      0.83      0.88     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.92      0.90      0.90     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.911191602106181\n",
      "pre:  0.9341878706715133\n",
      "rec:  0.8328500767525158\n",
      "ma F1:  0.9049565531374031\n",
      "mi F1:  0.911191602106181\n",
      "we F1:  0.9101531076334449\n",
      "29817 466\n",
      "Loss:  0.04881390184164047\n",
      "Loss:  0.06847774237394333\n",
      "Loss:  0.05814015865325928\n",
      "36 **********\n",
      "Epoch:  2225.9442777633667  fold:  8  kers:  64\n",
      "epoch:  37\n",
      "29817 466\n",
      "Loss:  0.09002473950386047\n",
      "Loss:  0.07050663232803345\n",
      "Loss:  0.044921938329935074\n",
      "37 **********\n",
      "Epoch:  2272.643413066864  fold:  8  kers:  64\n",
      "epoch:  38\n",
      "29817 466\n",
      "Loss:  0.07099974155426025\n",
      "Loss:  0.05878632143139839\n",
      "Loss:  0.04894225299358368\n",
      "38 **********\n",
      "Epoch:  2319.2797169685364  fold:  8  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.33352914452552795\n",
      "Eval Loss:  1.1222769021987915\n",
      "Eval Loss:  0.11729706823825836\n",
      "[[1910  163]\n",
      " [ 316  685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      2073\n",
      "           1       0.81      0.68      0.74      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.83      0.80      0.81      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8441769681197138\n",
      "pre:  0.8077830188679245\n",
      "rec:  0.6843156843156843\n",
      "ma F1:  0.8147598942287382\n",
      "mi F1:  0.8441769681197138\n",
      "we F1:  0.8405028356255754\n",
      "Eval Loss:  0.2160443812608719\n",
      "Eval Loss:  0.255854994058609\n",
      "Eval Loss:  0.27155324816703796\n",
      "Eval Loss:  0.2593497335910797\n",
      "Eval Loss:  0.24214409291744232\n",
      "Eval Loss:  0.2849617898464203\n",
      "Eval Loss:  0.30772829055786133\n",
      "Eval Loss:  0.2914736866950989\n",
      "Eval Loss:  0.2931646704673767\n",
      "Eval Loss:  0.22432491183280945\n",
      "Eval Loss:  0.2143278270959854\n",
      "Eval Loss:  0.19705350697040558\n",
      "Eval Loss:  0.22625811398029327\n",
      "Eval Loss:  0.16954320669174194\n",
      "Eval Loss:  0.2766655683517456\n",
      "Eval Loss:  0.22213952243328094\n",
      "Eval Loss:  0.23573780059814453\n",
      "Eval Loss:  0.2522644102573395\n",
      "Eval Loss:  0.26562538743019104\n",
      "Eval Loss:  0.23931404948234558\n",
      "Eval Loss:  0.37211471796035767\n",
      "Eval Loss:  0.3132794201374054\n",
      "Eval Loss:  0.25934091210365295\n",
      "Eval Loss:  0.2516375482082367\n",
      "Eval Loss:  0.28860902786254883\n",
      "Eval Loss:  0.28072768449783325\n",
      "Eval Loss:  0.2516450881958008\n",
      "Eval Loss:  0.25736531615257263\n",
      "Eval Loss:  0.24534408748149872\n",
      "[[17444   647]\n",
      " [ 2310  9416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18091\n",
      "           1       0.94      0.80      0.86     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.91      0.88      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.900828386490928\n",
      "pre:  0.9357050581337574\n",
      "rec:  0.8030018761726079\n",
      "ma F1:  0.8930774121644139\n",
      "mi F1:  0.900828386490928\n",
      "we F1:  0.899222772352289\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.03851437196135521\n",
      "Loss:  0.05505647510290146\n",
      "Loss:  0.06708227097988129\n",
      "39 **********\n",
      "Epoch:  2406.014805316925  fold:  8  kers:  64\n",
      "epoch:  40\n",
      "29817 466\n",
      "Loss:  0.03807135671377182\n",
      "Loss:  0.10217343270778656\n",
      "Loss:  0.023000434041023254\n",
      "40 **********\n",
      "Epoch:  2452.5992476940155  fold:  8  kers:  64\n",
      "epoch:  41\n",
      "29817 466\n",
      "Loss:  0.0620003379881382\n",
      "Loss:  0.08073431998491287\n",
      "Loss:  0.04552794620394707\n",
      "41 **********\n",
      "Epoch:  2499.1916692256927  fold:  8  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.2663673460483551\n",
      "Eval Loss:  1.0099650621414185\n",
      "Eval Loss:  0.10728032886981964\n",
      "[[1770  303]\n",
      " [ 258  743]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      2073\n",
      "           1       0.71      0.74      0.73      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.79      0.80      0.79      3074\n",
      "weighted avg       0.82      0.82      0.82      3074\n",
      "\n",
      "acc:  0.817501626545218\n",
      "pre:  0.7103250478011472\n",
      "rec:  0.7422577422577422\n",
      "ma F1:  0.794572248574019\n",
      "mi F1:  0.817501626545218\n",
      "we F1:  0.818506321782515\n",
      "Eval Loss:  0.19951727986335754\n",
      "Eval Loss:  0.19891366362571716\n",
      "Eval Loss:  0.22510723769664764\n",
      "Eval Loss:  0.22873952984809875\n",
      "Eval Loss:  0.16158929467201233\n",
      "Eval Loss:  0.2554089426994324\n",
      "Eval Loss:  0.28484591841697693\n",
      "Eval Loss:  0.2186717540025711\n",
      "Eval Loss:  0.25069376826286316\n",
      "Eval Loss:  0.1952536702156067\n",
      "Eval Loss:  0.1544998586177826\n",
      "Eval Loss:  0.16638222336769104\n",
      "Eval Loss:  0.21146419644355774\n",
      "Eval Loss:  0.14894917607307434\n",
      "Eval Loss:  0.25091981887817383\n",
      "Eval Loss:  0.22354896366596222\n",
      "Eval Loss:  0.18329507112503052\n",
      "Eval Loss:  0.24153859913349152\n",
      "Eval Loss:  0.23636846244335175\n",
      "Eval Loss:  0.18375355005264282\n",
      "Eval Loss:  0.3169350028038025\n",
      "Eval Loss:  0.2564321756362915\n",
      "Eval Loss:  0.1594352424144745\n",
      "Eval Loss:  0.2119860202074051\n",
      "Eval Loss:  0.2524302005767822\n",
      "Eval Loss:  0.21926607191562653\n",
      "Eval Loss:  0.22441482543945312\n",
      "Eval Loss:  0.1992626190185547\n",
      "Eval Loss:  0.1569492369890213\n",
      "[[17260   831]\n",
      " [ 1626 10100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18091\n",
      "           1       0.92      0.86      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9175973437971627\n",
      "pre:  0.9239776781630226\n",
      "rec:  0.8613337881630565\n",
      "ma F1:  0.9125549915892851\n",
      "mi F1:  0.9175973437971627\n",
      "we F1:  0.9170374736846957\n",
      "29817 466\n",
      "Loss:  0.03905287757515907\n",
      "Loss:  0.08490084111690521\n",
      "Loss:  0.049048181623220444\n",
      "42 **********\n",
      "Epoch:  2585.9277544021606  fold:  8  kers:  64\n",
      "epoch:  43\n",
      "29817 466\n",
      "Loss:  0.05749073997139931\n",
      "Loss:  0.04208056628704071\n",
      "Loss:  0.048612117767333984\n",
      "43 **********\n",
      "Epoch:  2632.579018354416  fold:  8  kers:  64\n",
      "epoch:  44\n",
      "29817 466\n",
      "Loss:  0.05752239003777504\n",
      "Loss:  0.04672474414110184\n",
      "Loss:  0.05402788519859314\n",
      "44 **********\n",
      "Epoch:  2679.3190450668335  fold:  8  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.35348305106163025\n",
      "Eval Loss:  0.9886285066604614\n",
      "Eval Loss:  0.14945974946022034\n",
      "[[1833  240]\n",
      " [ 285  716]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      2073\n",
      "           1       0.75      0.72      0.73      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.80      0.80      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8292127521145087\n",
      "pre:  0.7489539748953975\n",
      "rec:  0.7152847152847153\n",
      "ma F1:  0.8032319054371932\n",
      "mi F1:  0.8292127521145087\n",
      "we F1:  0.8281660752116627\n",
      "Eval Loss:  0.1976758986711502\n",
      "Eval Loss:  0.20109398663043976\n",
      "Eval Loss:  0.2510339319705963\n",
      "Eval Loss:  0.24202902615070343\n",
      "Eval Loss:  0.1722194254398346\n",
      "Eval Loss:  0.2657695710659027\n",
      "Eval Loss:  0.2987750470638275\n",
      "Eval Loss:  0.21440331637859344\n",
      "Eval Loss:  0.2447807937860489\n",
      "Eval Loss:  0.20836612582206726\n",
      "Eval Loss:  0.15638963878154755\n",
      "Eval Loss:  0.16769126057624817\n",
      "Eval Loss:  0.22782868146896362\n",
      "Eval Loss:  0.1544516384601593\n",
      "Eval Loss:  0.25111979246139526\n",
      "Eval Loss:  0.2143511027097702\n",
      "Eval Loss:  0.1993722766637802\n",
      "Eval Loss:  0.2297169715166092\n",
      "Eval Loss:  0.2426839917898178\n",
      "Eval Loss:  0.20331959426403046\n",
      "Eval Loss:  0.34299594163894653\n",
      "Eval Loss:  0.2843395173549652\n",
      "Eval Loss:  0.18465936183929443\n",
      "Eval Loss:  0.20612190663814545\n",
      "Eval Loss:  0.2760288119316101\n",
      "Eval Loss:  0.25074896216392517\n",
      "Eval Loss:  0.23964977264404297\n",
      "Eval Loss:  0.20013034343719482\n",
      "Eval Loss:  0.18172362446784973\n",
      "[[17408   683]\n",
      " [ 1841  9885]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18091\n",
      "           1       0.94      0.84      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.90      0.91     29817\n",
      "weighted avg       0.92      0.92      0.91     29817\n",
      "\n",
      "acc:  0.9153503035181273\n",
      "pre:  0.9353709311127933\n",
      "rec:  0.8429984649496844\n",
      "ma F1:  0.9095953049689139\n",
      "mi F1:  0.9153503035181273\n",
      "we F1:  0.9144644483645995\n",
      "29817 466\n",
      "Loss:  0.038192540407180786\n",
      "Loss:  0.024869780987501144\n",
      "Loss:  0.042910702526569366\n",
      "45 **********\n",
      "Epoch:  2766.052139043808  fold:  8  kers:  64\n",
      "epoch:  46\n",
      "29817 466\n",
      "Loss:  0.05622069165110588\n",
      "Loss:  0.08224615454673767\n",
      "Loss:  0.05399181693792343\n",
      "46 **********\n",
      "Epoch:  2812.7363142967224  fold:  8  kers:  64\n",
      "epoch:  47\n",
      "29817 466\n",
      "Loss:  0.05252828449010849\n",
      "Loss:  0.048177868127822876\n",
      "Loss:  0.06128288060426712\n",
      "47 **********\n",
      "Epoch:  2859.383589029312  fold:  8  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.4451923370361328\n",
      "Eval Loss:  0.9077762365341187\n",
      "Eval Loss:  0.15459467470645905\n",
      "[[1671  402]\n",
      " [ 241  760]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      2073\n",
      "           1       0.65      0.76      0.70      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.76      0.78      0.77      3074\n",
      "weighted avg       0.80      0.79      0.79      3074\n",
      "\n",
      "acc:  0.7908262849707222\n",
      "pre:  0.6540447504302926\n",
      "rec:  0.7592407592407593\n",
      "ma F1:  0.7706863057315605\n",
      "mi F1:  0.7908262849707222\n",
      "we F1:  0.7943856007308815\n",
      "Eval Loss:  0.1856835037469864\n",
      "Eval Loss:  0.1796513795852661\n",
      "Eval Loss:  0.20474570989608765\n",
      "Eval Loss:  0.21695181727409363\n",
      "Eval Loss:  0.15864276885986328\n",
      "Eval Loss:  0.23046259582042694\n",
      "Eval Loss:  0.27336183190345764\n",
      "Eval Loss:  0.1913355141878128\n",
      "Eval Loss:  0.22376757860183716\n",
      "Eval Loss:  0.18296021223068237\n",
      "Eval Loss:  0.13140976428985596\n",
      "Eval Loss:  0.1647319495677948\n",
      "Eval Loss:  0.21014703810214996\n",
      "Eval Loss:  0.15325984358787537\n",
      "Eval Loss:  0.2313898801803589\n",
      "Eval Loss:  0.2246766835451126\n",
      "Eval Loss:  0.18897032737731934\n",
      "Eval Loss:  0.24534308910369873\n",
      "Eval Loss:  0.20085373520851135\n",
      "Eval Loss:  0.19954413175582886\n",
      "Eval Loss:  0.30372774600982666\n",
      "Eval Loss:  0.21822276711463928\n",
      "Eval Loss:  0.1342664510011673\n",
      "Eval Loss:  0.20956231653690338\n",
      "Eval Loss:  0.2580510675907135\n",
      "Eval Loss:  0.21257495880126953\n",
      "Eval Loss:  0.21525409817695618\n",
      "Eval Loss:  0.18027232587337494\n",
      "Eval Loss:  0.16357001662254333\n",
      "[[17193   898]\n",
      " [ 1406 10320]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18091\n",
      "           1       0.92      0.88      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.92      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9227286447328705\n",
      "pre:  0.9199500802282047\n",
      "rec:  0.8800955142418557\n",
      "ma F1:  0.9183925938343533\n",
      "mi F1:  0.9227286447328705\n",
      "we F1:  0.922408156757249\n",
      "29817 466\n",
      "Loss:  0.056856121867895126\n",
      "Loss:  0.05614869296550751\n",
      "Loss:  0.05733520910143852\n",
      "48 **********\n",
      "Epoch:  2945.969077348709  fold:  8  kers:  64\n",
      "epoch:  49\n",
      "29817 466\n",
      "Loss:  0.04774089157581329\n",
      "Loss:  0.04016485437750816\n",
      "Loss:  0.06114710867404938\n",
      "49 **********\n",
      "Epoch:  2992.667215824127  fold:  8  kers:  64\n",
      "epoch:  50\n",
      "29817 466\n",
      "Loss:  0.04016352444887161\n",
      "Loss:  0.04867388680577278\n",
      "Loss:  0.060548897832632065\n",
      "50 **********\n",
      "Epoch:  3039.3753275871277  fold:  8  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.24626627564430237\n",
      "Eval Loss:  0.9633765816688538\n",
      "Eval Loss:  0.11837201565504074\n",
      "[[1845  228]\n",
      " [ 241  760]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      2073\n",
      "           1       0.77      0.76      0.76      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.83      0.82      0.83      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8474300585556278\n",
      "pre:  0.7692307692307693\n",
      "rec:  0.7592407592407593\n",
      "ma F1:  0.8257178124793361\n",
      "mi F1:  0.8474300585556278\n",
      "we F1:  0.8471699118284464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19362139701843262\n",
      "Eval Loss:  0.19579030573368073\n",
      "Eval Loss:  0.21266573667526245\n",
      "Eval Loss:  0.21522535383701324\n",
      "Eval Loss:  0.1586395800113678\n",
      "Eval Loss:  0.23903797566890717\n",
      "Eval Loss:  0.29750218987464905\n",
      "Eval Loss:  0.1902906596660614\n",
      "Eval Loss:  0.24443712830543518\n",
      "Eval Loss:  0.21134883165359497\n",
      "Eval Loss:  0.1672361046075821\n",
      "Eval Loss:  0.1741878092288971\n",
      "Eval Loss:  0.21666038036346436\n",
      "Eval Loss:  0.15976621210575104\n",
      "Eval Loss:  0.23524142801761627\n",
      "Eval Loss:  0.2073393613100052\n",
      "Eval Loss:  0.19615952670574188\n",
      "Eval Loss:  0.23343493044376373\n",
      "Eval Loss:  0.22444550693035126\n",
      "Eval Loss:  0.19923590123653412\n",
      "Eval Loss:  0.2903844118118286\n",
      "Eval Loss:  0.24553346633911133\n",
      "Eval Loss:  0.15371805429458618\n",
      "Eval Loss:  0.19744691252708435\n",
      "Eval Loss:  0.2563992142677307\n",
      "Eval Loss:  0.24590928852558136\n",
      "Eval Loss:  0.20902767777442932\n",
      "Eval Loss:  0.21109601855278015\n",
      "Eval Loss:  0.19305962324142456\n",
      "[[17334   757]\n",
      " [ 1678 10048]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18091\n",
      "           1       0.93      0.86      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9183351779186371\n",
      "pre:  0.9299398426654327\n",
      "rec:  0.856899198362613\n",
      "ma F1:  0.9131492812366375\n",
      "mi F1:  0.9183351779186371\n",
      "we F1:  0.9176796452746457\n",
      "29817 466\n",
      "Loss:  0.04955750331282616\n",
      "Loss:  0.056917037814855576\n",
      "Loss:  0.051962971687316895\n",
      "51 **********\n",
      "Epoch:  3126.100442647934  fold:  8  kers:  64\n",
      "epoch:  52\n",
      "29817 466\n",
      "Loss:  0.052350133657455444\n",
      "Loss:  0.05791570618748665\n",
      "Loss:  0.05461954325437546\n",
      "52 **********\n",
      "Epoch:  3172.8334879875183  fold:  8  kers:  64\n",
      "epoch:  53\n",
      "29817 466\n",
      "Loss:  0.04710952565073967\n",
      "Loss:  0.030327405780553818\n",
      "Loss:  0.06320759654045105\n",
      "53 **********\n",
      "Epoch:  3219.6054294109344  fold:  8  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.4554562568664551\n",
      "Eval Loss:  0.948759913444519\n",
      "Eval Loss:  0.16481591761112213\n",
      "[[1700  373]\n",
      " [ 229  772]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      2073\n",
      "           1       0.67      0.77      0.72      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.78      0.80      0.78      3074\n",
      "weighted avg       0.81      0.80      0.81      3074\n",
      "\n",
      "acc:  0.8041639557579701\n",
      "pre:  0.674235807860262\n",
      "rec:  0.7712287712287712\n",
      "ma F1:  0.7845266555911234\n",
      "mi F1:  0.80416395575797\n",
      "we F1:  0.8072111230252393\n",
      "Eval Loss:  0.17164786159992218\n",
      "Eval Loss:  0.17384716868400574\n",
      "Eval Loss:  0.2134992927312851\n",
      "Eval Loss:  0.23023973405361176\n",
      "Eval Loss:  0.15056192874908447\n",
      "Eval Loss:  0.2416849583387375\n",
      "Eval Loss:  0.2687785029411316\n",
      "Eval Loss:  0.1920754760503769\n",
      "Eval Loss:  0.24140068888664246\n",
      "Eval Loss:  0.21140624582767487\n",
      "Eval Loss:  0.13800831139087677\n",
      "Eval Loss:  0.16601693630218506\n",
      "Eval Loss:  0.21273048222064972\n",
      "Eval Loss:  0.1540285050868988\n",
      "Eval Loss:  0.23827141523361206\n",
      "Eval Loss:  0.22097398340702057\n",
      "Eval Loss:  0.18913471698760986\n",
      "Eval Loss:  0.23827317357063293\n",
      "Eval Loss:  0.24201740324497223\n",
      "Eval Loss:  0.1877901703119278\n",
      "Eval Loss:  0.3426859378814697\n",
      "Eval Loss:  0.25548380613327026\n",
      "Eval Loss:  0.15619409084320068\n",
      "Eval Loss:  0.19033962488174438\n",
      "Eval Loss:  0.25654906034469604\n",
      "Eval Loss:  0.24840079247951508\n",
      "Eval Loss:  0.23263870179653168\n",
      "Eval Loss:  0.18942977488040924\n",
      "Eval Loss:  0.15890783071517944\n",
      "[[17350   741]\n",
      " [ 1640 10086]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     18091\n",
      "           1       0.93      0.86      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9201462253077104\n",
      "pre:  0.9315599889165974\n",
      "rec:  0.8601398601398601\n",
      "ma F1:  0.9151078401547348\n",
      "mi F1:  0.9201462253077104\n",
      "we F1:  0.9195226696562063\n",
      "29817 466\n",
      "Loss:  0.06788421422243118\n",
      "Loss:  0.06185871735215187\n",
      "Loss:  0.07014462351799011\n",
      "54 **********\n",
      "Epoch:  3306.2228322029114  fold:  8  kers:  64\n",
      "epoch:  55\n",
      "29817 466\n",
      "Loss:  0.054084885865449905\n",
      "Loss:  0.0853460431098938\n",
      "Loss:  0.05404362455010414\n",
      "55 **********\n",
      "Epoch:  3352.9060106277466  fold:  8  kers:  64\n",
      "epoch:  56\n",
      "29817 466\n",
      "Loss:  0.028917957097291946\n",
      "Loss:  0.04691064730286598\n",
      "Loss:  0.09582251310348511\n",
      "56 **********\n",
      "Epoch:  3399.6131253242493  fold:  8  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.1609274446964264\n",
      "Eval Loss:  0.9943572878837585\n",
      "Eval Loss:  0.11024773865938187\n",
      "[[1943  130]\n",
      " [ 346  655]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      2073\n",
      "           1       0.83      0.65      0.73      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.80      0.81      3074\n",
      "weighted avg       0.84      0.85      0.84      3074\n",
      "\n",
      "acc:  0.845152895250488\n",
      "pre:  0.8343949044585988\n",
      "rec:  0.6543456543456544\n",
      "ma F1:  0.8121791939241121\n",
      "mi F1:  0.8451528952504879\n",
      "we F1:  0.8396231440963753\n",
      "Eval Loss:  0.18383769690990448\n",
      "Eval Loss:  0.22461673617362976\n",
      "Eval Loss:  0.21271912753582\n",
      "Eval Loss:  0.2173781543970108\n",
      "Eval Loss:  0.18055161833763123\n",
      "Eval Loss:  0.2628116309642792\n",
      "Eval Loss:  0.331656813621521\n",
      "Eval Loss:  0.21714453399181366\n",
      "Eval Loss:  0.2256709188222885\n",
      "Eval Loss:  0.23090121150016785\n",
      "Eval Loss:  0.19355091452598572\n",
      "Eval Loss:  0.179646834731102\n",
      "Eval Loss:  0.21894904971122742\n",
      "Eval Loss:  0.15932698547840118\n",
      "Eval Loss:  0.24825307726860046\n",
      "Eval Loss:  0.1794261485338211\n",
      "Eval Loss:  0.21380463242530823\n",
      "Eval Loss:  0.25482022762298584\n",
      "Eval Loss:  0.22525548934936523\n",
      "Eval Loss:  0.22249636054039001\n",
      "Eval Loss:  0.3604832589626312\n",
      "Eval Loss:  0.25074878334999084\n",
      "Eval Loss:  0.17431962490081787\n",
      "Eval Loss:  0.20556950569152832\n",
      "Eval Loss:  0.31023234128952026\n",
      "Eval Loss:  0.2802444398403168\n",
      "Eval Loss:  0.27648964524269104\n",
      "Eval Loss:  0.2323712408542633\n",
      "Eval Loss:  0.22364021837711334\n",
      "[[17498   593]\n",
      " [ 2031  9695]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93     18091\n",
      "           1       0.94      0.83      0.88     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.92      0.90      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9119965120568803\n",
      "pre:  0.9423600311041991\n",
      "rec:  0.8267951560634488\n",
      "ma F1:  0.9055264961879412\n",
      "mi F1:  0.9119965120568803\n",
      "we F1:  0.910804165162156\n",
      "29817 466\n",
      "Loss:  0.0358244962990284\n",
      "Loss:  0.05367083102464676\n",
      "Loss:  0.03545980155467987\n",
      "57 **********\n",
      "Epoch:  3486.2793974876404  fold:  8  kers:  64\n",
      "epoch:  58\n",
      "29817 466\n",
      "Loss:  0.051449254155159\n",
      "Loss:  0.04762706160545349\n",
      "Loss:  0.07261446118354797\n",
      "58 **********\n",
      "Epoch:  3532.8917651176453  fold:  8  kers:  64\n",
      "epoch:  59\n",
      "29817 466\n",
      "Loss:  0.06238816678524017\n",
      "Loss:  0.053791601210832596\n",
      "Loss:  0.043146125972270966\n",
      "59 **********\n",
      "Epoch:  3579.584918498993  fold:  8  kers:  64\n",
      "Eval Loss:  0.23174050450325012\n",
      "Eval Loss:  0.9675911664962769\n",
      "Eval Loss:  0.21320559084415436\n",
      "[[1581  492]\n",
      " [ 281  720]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80      2073\n",
      "           1       0.59      0.72      0.65      1001\n",
      "\n",
      "    accuracy                           0.75      3074\n",
      "   macro avg       0.72      0.74      0.73      3074\n",
      "weighted avg       0.77      0.75      0.75      3074\n",
      "\n",
      "acc:  0.7485361093038386\n",
      "pre:  0.594059405940594\n",
      "rec:  0.7192807192807192\n",
      "ma F1:  0.7271291105865708\n",
      "mi F1:  0.7485361093038386\n",
      "we F1:  0.7537821914517404\n",
      "update!  Acc:  0.8526350032530904\n",
      "Epoch:  3583.317936182022  fold:  8  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29483 3408\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29483 461\n",
      "Loss:  0.1683669537305832\n",
      "Loss:  0.15711364150047302\n",
      "Loss:  0.15906424820423126\n",
      "0 **********\n",
      "Epoch:  58.66015410423279  fold:  9  kers:  64\n",
      "epoch:  1\n",
      "29483 461\n",
      "Loss:  0.14459559321403503\n",
      "Loss:  0.13168421387672424\n",
      "Loss:  0.14317627251148224\n",
      "1 **********\n",
      "Epoch:  104.9344265460968  fold:  9  kers:  64\n",
      "epoch:  2\n",
      "29483 461\n",
      "Loss:  0.12678834795951843\n",
      "Loss:  0.1253966987133026\n",
      "Loss:  0.10336471349000931\n",
      "2 **********\n",
      "Epoch:  151.11295413970947  fold:  9  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.2324240654706955\n",
      "Eval Loss:  1.019953727722168\n",
      "Eval Loss:  0.3485068678855896\n",
      "[[1524  218]\n",
      " [ 432 1234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      1742\n",
      "           1       0.85      0.74      0.79      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.81      0.81      0.81      3408\n",
      "weighted avg       0.81      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8092723004694836\n",
      "pre:  0.849862258953168\n",
      "rec:  0.7406962785114045\n",
      "ma F1:  0.8078811735691953\n",
      "mi F1:  0.8092723004694836\n",
      "we F1:  0.8082457447568571\n",
      "update!  Acc:  0.8092723004694836\n",
      "Eval Loss:  0.4577452540397644\n",
      "Eval Loss:  0.4183711111545563\n",
      "Eval Loss:  0.355678528547287\n",
      "Eval Loss:  0.38340455293655396\n",
      "Eval Loss:  0.4547577500343323\n",
      "Eval Loss:  0.46901267766952515\n",
      "Eval Loss:  0.416659951210022\n",
      "Eval Loss:  0.5282555818557739\n",
      "Eval Loss:  0.3666999042034149\n",
      "Eval Loss:  0.5264358520507812\n",
      "Eval Loss:  0.40465664863586426\n",
      "Eval Loss:  0.38510891795158386\n",
      "Eval Loss:  0.4446766972541809\n",
      "Eval Loss:  0.4913620054721832\n",
      "Eval Loss:  0.4778274893760681\n",
      "Eval Loss:  0.48071298003196716\n",
      "Eval Loss:  0.39781826734542847\n",
      "Eval Loss:  0.5298699140548706\n",
      "Eval Loss:  0.45229583978652954\n",
      "Eval Loss:  0.3812616467475891\n",
      "Eval Loss:  0.3781101405620575\n",
      "Eval Loss:  0.39756789803504944\n",
      "Eval Loss:  0.38608503341674805\n",
      "Eval Loss:  0.44012251496315\n",
      "Eval Loss:  0.4392288625240326\n",
      "Eval Loss:  0.49548599123954773\n",
      "Eval Loss:  0.4804641008377075\n",
      "Eval Loss:  0.39472123980522156\n",
      "[[16228  2194]\n",
      " [ 3600  7461]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85     18422\n",
      "           1       0.77      0.67      0.72     11061\n",
      "\n",
      "    accuracy                           0.80     29483\n",
      "   macro avg       0.80      0.78      0.78     29483\n",
      "weighted avg       0.80      0.80      0.80     29483\n",
      "\n",
      "acc:  0.8034799715090052\n",
      "pre:  0.7727602278612118\n",
      "rec:  0.6745321399511798\n",
      "ma F1:  0.7844178387580816\n",
      "mi F1:  0.8034799715090053\n",
      "we F1:  0.8004228985481521\n",
      "29483 461\n",
      "Loss:  0.15046808123588562\n",
      "Loss:  0.08466250449419022\n",
      "Loss:  0.12381614744663239\n",
      "3 **********\n",
      "Epoch:  236.9813597202301  fold:  9  kers:  64\n",
      "epoch:  4\n",
      "29483 461\n",
      "Loss:  0.12586598098278046\n",
      "Loss:  0.09898887574672699\n",
      "Loss:  0.07871357351541519\n",
      "4 **********\n",
      "Epoch:  282.9933331012726  fold:  9  kers:  64\n",
      "epoch:  5\n",
      "29483 461\n",
      "Loss:  0.08316575735807419\n",
      "Loss:  0.09103978425264359\n",
      "Loss:  0.06404518336057663\n",
      "5 **********\n",
      "Epoch:  328.9953329563141  fold:  9  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.09416305273771286\n",
      "Eval Loss:  1.728201985359192\n",
      "Eval Loss:  0.25202807784080505\n",
      "[[1635  107]\n",
      " [ 554 1112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83      1742\n",
      "           1       0.91      0.67      0.77      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.83      0.80      0.80      3408\n",
      "weighted avg       0.83      0.81      0.80      3408\n",
      "\n",
      "acc:  0.8060446009389671\n",
      "pre:  0.9122231337161608\n",
      "rec:  0.6674669867947179\n",
      "ma F1:  0.8013666421683927\n",
      "mi F1:  0.8060446009389671\n",
      "we F1:  0.802046422027979\n",
      "Eval Loss:  0.3942224383354187\n",
      "Eval Loss:  0.364193856716156\n",
      "Eval Loss:  0.3203403949737549\n",
      "Eval Loss:  0.35045313835144043\n",
      "Eval Loss:  0.3879240155220032\n",
      "Eval Loss:  0.3410382568836212\n",
      "Eval Loss:  0.431363582611084\n",
      "Eval Loss:  0.502606213092804\n",
      "Eval Loss:  0.29568129777908325\n",
      "Eval Loss:  0.45784902572631836\n",
      "Eval Loss:  0.371995210647583\n",
      "Eval Loss:  0.3784034252166748\n",
      "Eval Loss:  0.4050670862197876\n",
      "Eval Loss:  0.40574881434440613\n",
      "Eval Loss:  0.4139224886894226\n",
      "Eval Loss:  0.5001119375228882\n",
      "Eval Loss:  0.3214121460914612\n",
      "Eval Loss:  0.4889620244503021\n",
      "Eval Loss:  0.38994890451431274\n",
      "Eval Loss:  0.377148300409317\n",
      "Eval Loss:  0.3511401414871216\n",
      "Eval Loss:  0.3017911911010742\n",
      "Eval Loss:  0.28139784932136536\n",
      "Eval Loss:  0.3780680000782013\n",
      "Eval Loss:  0.3846737742424011\n",
      "Eval Loss:  0.4413028657436371\n",
      "Eval Loss:  0.3396475613117218\n",
      "Eval Loss:  0.3175307512283325\n",
      "[[17238  1184]\n",
      " [ 3282  7779]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     18422\n",
      "           1       0.87      0.70      0.78     11061\n",
      "\n",
      "    accuracy                           0.85     29483\n",
      "   macro avg       0.85      0.82      0.83     29483\n",
      "weighted avg       0.85      0.85      0.84     29483\n",
      "\n",
      "acc:  0.8485228775904758\n",
      "pre:  0.8679013723083789\n",
      "rec:  0.703281800922159\n",
      "ma F1:  0.8311421317786742\n",
      "mi F1:  0.8485228775904758\n",
      "we F1:  0.8446678395618091\n",
      "29483 461\n",
      "Loss:  0.05845220386981964\n",
      "Loss:  0.08520685881376266\n",
      "Loss:  0.09841450303792953\n",
      "6 **********\n",
      "Epoch:  414.9215838909149  fold:  9  kers:  64\n",
      "epoch:  7\n",
      "29483 461\n",
      "Loss:  0.09522465616464615\n",
      "Loss:  0.08059508353471756\n",
      "Loss:  0.07736297696828842\n",
      "7 **********\n",
      "Epoch:  461.0063621997833  fold:  9  kers:  64\n",
      "epoch:  8\n",
      "29483 461\n",
      "Loss:  0.08928479999303818\n",
      "Loss:  0.07969003170728683\n",
      "Loss:  0.09781553596258163\n",
      "8 **********\n",
      "Epoch:  507.12903928756714  fold:  9  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.06606701016426086\n",
      "Eval Loss:  1.8157262802124023\n",
      "Eval Loss:  0.2472703754901886\n",
      "[[1665   77]\n",
      " [ 591 1075]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83      1742\n",
      "           1       0.93      0.65      0.76      1666\n",
      "\n",
      "    accuracy                           0.80      3408\n",
      "   macro avg       0.84      0.80      0.80      3408\n",
      "weighted avg       0.83      0.80      0.80      3408\n",
      "\n",
      "acc:  0.8039906103286385\n",
      "pre:  0.9331597222222222\n",
      "rec:  0.6452581032412965\n",
      "ma F1:  0.7979344533870909\n",
      "mi F1:  0.8039906103286385\n",
      "we F1:  0.7987145685185445\n",
      "Eval Loss:  0.4120368957519531\n",
      "Eval Loss:  0.3744664788246155\n",
      "Eval Loss:  0.35947421193122864\n",
      "Eval Loss:  0.35614708065986633\n",
      "Eval Loss:  0.37979626655578613\n",
      "Eval Loss:  0.3135632574558258\n",
      "Eval Loss:  0.4001491665840149\n",
      "Eval Loss:  0.49509087204933167\n",
      "Eval Loss:  0.28607794642448425\n",
      "Eval Loss:  0.42199772596359253\n",
      "Eval Loss:  0.3639730215072632\n",
      "Eval Loss:  0.3623255789279938\n",
      "Eval Loss:  0.37447986006736755\n",
      "Eval Loss:  0.42075449228286743\n",
      "Eval Loss:  0.40650448203086853\n",
      "Eval Loss:  0.4942675232887268\n",
      "Eval Loss:  0.30853718519210815\n",
      "Eval Loss:  0.4506331980228424\n",
      "Eval Loss:  0.408049076795578\n",
      "Eval Loss:  0.360466331243515\n",
      "Eval Loss:  0.35774654150009155\n",
      "Eval Loss:  0.2737942039966583\n",
      "Eval Loss:  0.27087509632110596\n",
      "Eval Loss:  0.3607305884361267\n",
      "Eval Loss:  0.37997135519981384\n",
      "Eval Loss:  0.43493038415908813\n",
      "Eval Loss:  0.317776083946228\n",
      "Eval Loss:  0.29753565788269043\n",
      "[[17576   846]\n",
      " [ 3420  7641]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18422\n",
      "           1       0.90      0.69      0.78     11061\n",
      "\n",
      "    accuracy                           0.86     29483\n",
      "   macro avg       0.87      0.82      0.84     29483\n",
      "weighted avg       0.86      0.86      0.85     29483\n",
      "\n",
      "acc:  0.8553064477834684\n",
      "pre:  0.9003181336161188\n",
      "rec:  0.6908055329536208\n",
      "ma F1:  0.8367716434340651\n",
      "mi F1:  0.8553064477834684\n",
      "we F1:  0.8505043756752284\n",
      "29483 461\n",
      "Loss:  0.11091278493404388\n",
      "Loss:  0.12004189193248749\n",
      "Loss:  0.07343664765357971\n",
      "9 **********\n",
      "Epoch:  593.1340794563293  fold:  9  kers:  64\n",
      "epoch:  10\n",
      "29483 461\n",
      "Loss:  0.06193094700574875\n",
      "Loss:  0.05931452661752701\n",
      "Loss:  0.0745229721069336\n",
      "10 **********\n",
      "Epoch:  639.2547619342804  fold:  9  kers:  64\n",
      "epoch:  11\n",
      "29483 461\n",
      "Loss:  0.060525160282850266\n",
      "Loss:  0.0899817943572998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0755285993218422\n",
      "11 **********\n",
      "Epoch:  685.2717220783234  fold:  9  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.06867527961730957\n",
      "Eval Loss:  1.3732303380966187\n",
      "Eval Loss:  0.19550371170043945\n",
      "[[1633  109]\n",
      " [ 484 1182]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85      1742\n",
      "           1       0.92      0.71      0.80      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.84      0.82      0.82      3408\n",
      "weighted avg       0.84      0.83      0.82      3408\n",
      "\n",
      "acc:  0.8259976525821596\n",
      "pre:  0.9155693261037955\n",
      "rec:  0.709483793517407\n",
      "ma F1:  0.8228960790068374\n",
      "mi F1:  0.8259976525821596\n",
      "we F1:  0.8234187388554505\n",
      "update!  Acc:  0.8259976525821596\n",
      "Eval Loss:  0.3280686140060425\n",
      "Eval Loss:  0.3336132764816284\n",
      "Eval Loss:  0.30804282426834106\n",
      "Eval Loss:  0.3176891803741455\n",
      "Eval Loss:  0.3040211796760559\n",
      "Eval Loss:  0.23530271649360657\n",
      "Eval Loss:  0.3398672938346863\n",
      "Eval Loss:  0.3814864456653595\n",
      "Eval Loss:  0.26681452989578247\n",
      "Eval Loss:  0.3416260778903961\n",
      "Eval Loss:  0.33830976486206055\n",
      "Eval Loss:  0.34322699904441833\n",
      "Eval Loss:  0.3104742765426636\n",
      "Eval Loss:  0.30169132351875305\n",
      "Eval Loss:  0.32539135217666626\n",
      "Eval Loss:  0.37245967984199524\n",
      "Eval Loss:  0.280460000038147\n",
      "Eval Loss:  0.33431604504585266\n",
      "Eval Loss:  0.35865864157676697\n",
      "Eval Loss:  0.3103730082511902\n",
      "Eval Loss:  0.3341575264930725\n",
      "Eval Loss:  0.23548147082328796\n",
      "Eval Loss:  0.23776188492774963\n",
      "Eval Loss:  0.30879178643226624\n",
      "Eval Loss:  0.3009318709373474\n",
      "Eval Loss:  0.382581889629364\n",
      "Eval Loss:  0.2572926878929138\n",
      "Eval Loss:  0.24526502192020416\n",
      "[[17113  1309]\n",
      " [ 2357  8704]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     18422\n",
      "           1       0.87      0.79      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.87      0.86      0.86     29483\n",
      "weighted avg       0.88      0.88      0.87     29483\n",
      "\n",
      "acc:  0.8756571583624462\n",
      "pre:  0.8692699490662139\n",
      "rec:  0.7869089594069252\n",
      "ma F1:  0.8646464568696067\n",
      "mi F1:  0.8756571583624462\n",
      "we F1:  0.8742849125348214\n",
      "29483 461\n",
      "Loss:  0.0714828222990036\n",
      "Loss:  0.08276925981044769\n",
      "Loss:  0.11107594519853592\n",
      "12 **********\n",
      "Epoch:  771.3984370231628  fold:  9  kers:  64\n",
      "epoch:  13\n",
      "29483 461\n",
      "Loss:  0.07384198158979416\n",
      "Loss:  0.06400950998067856\n",
      "Loss:  0.06958724558353424\n",
      "13 **********\n",
      "Epoch:  817.5261006355286  fold:  9  kers:  64\n",
      "epoch:  14\n",
      "29483 461\n",
      "Loss:  0.07943203300237656\n",
      "Loss:  0.0613420233130455\n",
      "Loss:  0.05390206351876259\n",
      "14 **********\n",
      "Epoch:  863.6906657218933  fold:  9  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.06779339164495468\n",
      "Eval Loss:  1.2017689943313599\n",
      "Eval Loss:  0.16133783757686615\n",
      "[[1645   97]\n",
      " [ 442 1224]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      1742\n",
      "           1       0.93      0.73      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.86      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8418427230046949\n",
      "pre:  0.9265707797123391\n",
      "rec:  0.7346938775510204\n",
      "ma F1:  0.8393917824283046\n",
      "mi F1:  0.8418427230046949\n",
      "we F1:  0.8398342325086031\n",
      "update!  Acc:  0.8418427230046949\n",
      "Eval Loss:  0.3242224156856537\n",
      "Eval Loss:  0.3189840614795685\n",
      "Eval Loss:  0.30859607458114624\n",
      "Eval Loss:  0.3081345856189728\n",
      "Eval Loss:  0.2699582278728485\n",
      "Eval Loss:  0.20565511286258698\n",
      "Eval Loss:  0.3191298246383667\n",
      "Eval Loss:  0.33565622568130493\n",
      "Eval Loss:  0.2763892114162445\n",
      "Eval Loss:  0.32625243067741394\n",
      "Eval Loss:  0.3239181339740753\n",
      "Eval Loss:  0.33212125301361084\n",
      "Eval Loss:  0.29856571555137634\n",
      "Eval Loss:  0.28312939405441284\n",
      "Eval Loss:  0.3155444264411926\n",
      "Eval Loss:  0.32392263412475586\n",
      "Eval Loss:  0.2697327435016632\n",
      "Eval Loss:  0.28935667872428894\n",
      "Eval Loss:  0.3279045522212982\n",
      "Eval Loss:  0.28383171558380127\n",
      "Eval Loss:  0.3218086361885071\n",
      "Eval Loss:  0.21942929923534393\n",
      "Eval Loss:  0.23626480996608734\n",
      "Eval Loss:  0.2773888111114502\n",
      "Eval Loss:  0.258681058883667\n",
      "Eval Loss:  0.3547835350036621\n",
      "Eval Loss:  0.2626906931400299\n",
      "Eval Loss:  0.2373507171869278\n",
      "[[16988  1434]\n",
      " [ 2084  8977]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91     18422\n",
      "           1       0.86      0.81      0.84     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.88      0.87      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8806770003052606\n",
      "pre:  0.8622610700220921\n",
      "rec:  0.8115902721272941\n",
      "ma F1:  0.8711651862310886\n",
      "mi F1:  0.8806770003052606\n",
      "we F1:  0.8799052266005781\n",
      "29483 461\n",
      "Loss:  0.0695074126124382\n",
      "Loss:  0.08535152673721313\n",
      "Loss:  0.06994292885065079\n",
      "15 **********\n",
      "Epoch:  949.7535512447357  fold:  9  kers:  64\n",
      "epoch:  16\n",
      "29483 461\n",
      "Loss:  0.08111488074064255\n",
      "Loss:  0.08096512407064438\n",
      "Loss:  0.04804900288581848\n",
      "16 **********\n",
      "Epoch:  995.9131300449371  fold:  9  kers:  64\n",
      "epoch:  17\n",
      "29483 461\n",
      "Loss:  0.06838425248861313\n",
      "Loss:  0.08359070867300034\n",
      "Loss:  0.08818214386701584\n",
      "17 **********\n",
      "Epoch:  1041.9929220676422  fold:  9  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.04815172031521797\n",
      "Eval Loss:  1.2328318357467651\n",
      "Eval Loss:  0.20188084244728088\n",
      "[[1664   78]\n",
      " [ 477 1189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86      1742\n",
      "           1       0.94      0.71      0.81      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.83      0.83      3408\n",
      "weighted avg       0.86      0.84      0.83      3408\n",
      "\n",
      "acc:  0.8371478873239436\n",
      "pre:  0.9384372533543804\n",
      "rec:  0.7136854741896759\n",
      "ma F1:  0.8339216139590699\n",
      "mi F1:  0.8371478873239436\n",
      "we F1:  0.8344378176974496\n",
      "Eval Loss:  0.3271058201789856\n",
      "Eval Loss:  0.30920493602752686\n",
      "Eval Loss:  0.3017834722995758\n",
      "Eval Loss:  0.2981869578361511\n",
      "Eval Loss:  0.26775339245796204\n",
      "Eval Loss:  0.20752635598182678\n",
      "Eval Loss:  0.32395583391189575\n",
      "Eval Loss:  0.33526843786239624\n",
      "Eval Loss:  0.25240615010261536\n",
      "Eval Loss:  0.3027343451976776\n",
      "Eval Loss:  0.2763208746910095\n",
      "Eval Loss:  0.3245421350002289\n",
      "Eval Loss:  0.2785972058773041\n",
      "Eval Loss:  0.26986080408096313\n",
      "Eval Loss:  0.320234090089798\n",
      "Eval Loss:  0.2990056574344635\n",
      "Eval Loss:  0.2551327049732208\n",
      "Eval Loss:  0.2917550802230835\n",
      "Eval Loss:  0.3253663182258606\n",
      "Eval Loss:  0.3063041865825653\n",
      "Eval Loss:  0.31881824135780334\n",
      "Eval Loss:  0.2124987095594406\n",
      "Eval Loss:  0.23776516318321228\n",
      "Eval Loss:  0.278594970703125\n",
      "Eval Loss:  0.2587853670120239\n",
      "Eval Loss:  0.36323538422584534\n",
      "Eval Loss:  0.23233672976493835\n",
      "Eval Loss:  0.22560250759124756\n",
      "[[17300  1122]\n",
      " [ 2221  8840]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     18422\n",
      "           1       0.89      0.80      0.84     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8866126242241291\n",
      "pre:  0.8873720136518771\n",
      "rec:  0.7992044118976585\n",
      "ma F1:  0.8764389207804977\n",
      "mi F1:  0.8866126242241291\n",
      "we F1:  0.8852910048287921\n",
      "29483 461\n",
      "Loss:  0.09350308775901794\n",
      "Loss:  0.08421074599027634\n",
      "Loss:  0.07301291078329086\n",
      "18 **********\n",
      "Epoch:  1128.1216320991516  fold:  9  kers:  64\n",
      "epoch:  19\n",
      "29483 461\n",
      "Loss:  0.09084262698888779\n",
      "Loss:  0.04979616403579712\n",
      "Loss:  0.0918750986456871\n",
      "19 **********\n",
      "Epoch:  1174.122633934021  fold:  9  kers:  64\n",
      "epoch:  20\n",
      "29483 461\n",
      "Loss:  0.06947992742061615\n",
      "Loss:  0.0662178173661232\n",
      "Loss:  0.06256985664367676\n",
      "20 **********\n",
      "Epoch:  1220.2403252124786  fold:  9  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.04677436128258705\n",
      "Eval Loss:  1.0282301902770996\n",
      "Eval Loss:  0.19400794804096222\n",
      "[[1672   70]\n",
      " [ 460 1206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86      1742\n",
      "           1       0.95      0.72      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.86      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8444835680751174\n",
      "pre:  0.945141065830721\n",
      "rec:  0.723889555822329\n",
      "ma F1:  0.841520471325334\n",
      "mi F1:  0.8444835680751174\n",
      "we F1:  0.8420037231557708\n",
      "update!  Acc:  0.8444835680751174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.32925257086753845\n",
      "Eval Loss:  0.2897546887397766\n",
      "Eval Loss:  0.2956920266151428\n",
      "Eval Loss:  0.28470319509506226\n",
      "Eval Loss:  0.25186559557914734\n",
      "Eval Loss:  0.1887015700340271\n",
      "Eval Loss:  0.3096809685230255\n",
      "Eval Loss:  0.3156905770301819\n",
      "Eval Loss:  0.2476394772529602\n",
      "Eval Loss:  0.26949840784072876\n",
      "Eval Loss:  0.25443118810653687\n",
      "Eval Loss:  0.32515907287597656\n",
      "Eval Loss:  0.24221624433994293\n",
      "Eval Loss:  0.2469744235277176\n",
      "Eval Loss:  0.2976900041103363\n",
      "Eval Loss:  0.2574928104877472\n",
      "Eval Loss:  0.2254287302494049\n",
      "Eval Loss:  0.26335206627845764\n",
      "Eval Loss:  0.300115704536438\n",
      "Eval Loss:  0.28233808279037476\n",
      "Eval Loss:  0.3136990964412689\n",
      "Eval Loss:  0.1963334083557129\n",
      "Eval Loss:  0.22188997268676758\n",
      "Eval Loss:  0.2512705326080322\n",
      "Eval Loss:  0.2414959967136383\n",
      "Eval Loss:  0.3341839909553528\n",
      "Eval Loss:  0.22815503180027008\n",
      "Eval Loss:  0.19726146757602692\n",
      "[[17293  1129]\n",
      " [ 1980  9081]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18422\n",
      "           1       0.89      0.82      0.85     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.88      0.89     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8945494013499304\n",
      "pre:  0.8894221351616063\n",
      "rec:  0.8209926769731489\n",
      "ma F1:  0.8856803886709644\n",
      "mi F1:  0.8945494013499304\n",
      "we F1:  0.8936303158908707\n",
      "29483 461\n",
      "Loss:  0.055753082036972046\n",
      "Loss:  0.07571610808372498\n",
      "Loss:  0.06606348603963852\n",
      "21 **********\n",
      "Epoch:  1306.007999420166  fold:  9  kers:  64\n",
      "epoch:  22\n",
      "29483 461\n",
      "Loss:  0.05401742085814476\n",
      "Loss:  0.07211977988481522\n",
      "Loss:  0.057750146836042404\n",
      "22 **********\n",
      "Epoch:  1352.0708374977112  fold:  9  kers:  64\n",
      "epoch:  23\n",
      "29483 461\n",
      "Loss:  0.08006845414638519\n",
      "Loss:  0.052187543362379074\n",
      "Loss:  0.049438584595918655\n",
      "23 **********\n",
      "Epoch:  1398.1157219409943  fold:  9  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.03833818435668945\n",
      "Eval Loss:  1.0039411783218384\n",
      "Eval Loss:  0.22386416792869568\n",
      "[[1690   52]\n",
      " [ 530 1136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85      1742\n",
      "           1       0.96      0.68      0.80      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.86      0.83      0.82      3408\n",
      "weighted avg       0.86      0.83      0.83      3408\n",
      "\n",
      "acc:  0.829225352112676\n",
      "pre:  0.9562289562289562\n",
      "rec:  0.6818727490996399\n",
      "ma F1:  0.8245900879660206\n",
      "mi F1:  0.829225352112676\n",
      "we F1:  0.8252259725781971\n",
      "Eval Loss:  0.3337225019931793\n",
      "Eval Loss:  0.30189526081085205\n",
      "Eval Loss:  0.3082348108291626\n",
      "Eval Loss:  0.2714460492134094\n",
      "Eval Loss:  0.2618165910243988\n",
      "Eval Loss:  0.19515809416770935\n",
      "Eval Loss:  0.30983319878578186\n",
      "Eval Loss:  0.32422930002212524\n",
      "Eval Loss:  0.2507022023200989\n",
      "Eval Loss:  0.2508668899536133\n",
      "Eval Loss:  0.25487250089645386\n",
      "Eval Loss:  0.32326653599739075\n",
      "Eval Loss:  0.2311403751373291\n",
      "Eval Loss:  0.2824456989765167\n",
      "Eval Loss:  0.3303792476654053\n",
      "Eval Loss:  0.27178314328193665\n",
      "Eval Loss:  0.2062186598777771\n",
      "Eval Loss:  0.26951444149017334\n",
      "Eval Loss:  0.31106871366500854\n",
      "Eval Loss:  0.29304778575897217\n",
      "Eval Loss:  0.29694610834121704\n",
      "Eval Loss:  0.1999267190694809\n",
      "Eval Loss:  0.2188366949558258\n",
      "Eval Loss:  0.2523502707481384\n",
      "Eval Loss:  0.26746660470962524\n",
      "Eval Loss:  0.3257323205471039\n",
      "Eval Loss:  0.22822940349578857\n",
      "Eval Loss:  0.20081749558448792\n",
      "[[17711   711]\n",
      " [ 2338  8723]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18422\n",
      "           1       0.92      0.79      0.85     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.89     29483\n",
      "\n",
      "acc:  0.8965844724078282\n",
      "pre:  0.9246343014627941\n",
      "rec:  0.7886267064460718\n",
      "ma F1:  0.8859887522073082\n",
      "mi F1:  0.8965844724078282\n",
      "we F1:  0.8946664442851929\n",
      "29483 461\n",
      "Loss:  0.07779691368341446\n",
      "Loss:  0.05488848313689232\n",
      "Loss:  0.10898970067501068\n",
      "24 **********\n",
      "Epoch:  1484.0040740966797  fold:  9  kers:  64\n",
      "epoch:  25\n",
      "29483 461\n",
      "Loss:  0.05555987358093262\n",
      "Loss:  0.045455463230609894\n",
      "Loss:  0.040904756635427475\n",
      "25 **********\n",
      "Epoch:  1530.0908472537994  fold:  9  kers:  64\n",
      "epoch:  26\n",
      "29483 461\n",
      "Loss:  0.05373995006084442\n",
      "Loss:  0.06681180000305176\n",
      "Loss:  0.06083925440907478\n",
      "26 **********\n",
      "Epoch:  1576.1117963790894  fold:  9  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.04486154019832611\n",
      "Eval Loss:  0.8977888226509094\n",
      "Eval Loss:  0.12590374052524567\n",
      "[[1649   93]\n",
      " [ 355 1311]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1742\n",
      "           1       0.93      0.79      0.85      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.88      0.87      0.87      3408\n",
      "weighted avg       0.88      0.87      0.87      3408\n",
      "\n",
      "acc:  0.8685446009389671\n",
      "pre:  0.9337606837606838\n",
      "rec:  0.7869147659063626\n",
      "ma F1:  0.8672387136941728\n",
      "mi F1:  0.8685446009389672\n",
      "we F1:  0.8675323451456649\n",
      "update!  Acc:  0.8685446009389671\n",
      "Eval Loss:  0.3076756000518799\n",
      "Eval Loss:  0.2986451983451843\n",
      "Eval Loss:  0.25020840764045715\n",
      "Eval Loss:  0.2649357318878174\n",
      "Eval Loss:  0.24718263745307922\n",
      "Eval Loss:  0.17657798528671265\n",
      "Eval Loss:  0.2761304974555969\n",
      "Eval Loss:  0.27026695013046265\n",
      "Eval Loss:  0.25403696298599243\n",
      "Eval Loss:  0.2846843898296356\n",
      "Eval Loss:  0.2670744061470032\n",
      "Eval Loss:  0.3342256546020508\n",
      "Eval Loss:  0.24058353900909424\n",
      "Eval Loss:  0.2138742059469223\n",
      "Eval Loss:  0.2843533158302307\n",
      "Eval Loss:  0.24108892679214478\n",
      "Eval Loss:  0.2328430712223053\n",
      "Eval Loss:  0.2526346445083618\n",
      "Eval Loss:  0.26991817355155945\n",
      "Eval Loss:  0.2881087064743042\n",
      "Eval Loss:  0.3101221024990082\n",
      "Eval Loss:  0.22365544736385345\n",
      "Eval Loss:  0.20237232744693756\n",
      "Eval Loss:  0.23269468545913696\n",
      "Eval Loss:  0.2404545545578003\n",
      "Eval Loss:  0.28141963481903076\n",
      "Eval Loss:  0.24307818710803986\n",
      "Eval Loss:  0.19178825616836548\n",
      "[[16811  1611]\n",
      " [ 1413  9648]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92     18422\n",
      "           1       0.86      0.87      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.89      0.89      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8974324186819523\n",
      "pre:  0.8569144684252598\n",
      "rec:  0.8722538649308381\n",
      "ma F1:  0.8909984454581146\n",
      "mi F1:  0.8974324186819523\n",
      "we F1:  0.8976102668877767\n",
      "29483 461\n",
      "Loss:  0.07165473699569702\n",
      "Loss:  0.08891133964061737\n",
      "Loss:  0.058738432824611664\n",
      "27 **********\n",
      "Epoch:  1662.2454929351807  fold:  9  kers:  64\n",
      "epoch:  28\n",
      "29483 461\n",
      "Loss:  0.10769889503717422\n",
      "Loss:  0.05992358177900314\n",
      "Loss:  0.06600607186555862\n",
      "28 **********\n",
      "Epoch:  1708.4758820533752  fold:  9  kers:  64\n",
      "epoch:  29\n",
      "29483 461\n",
      "Loss:  0.10862034559249878\n",
      "Loss:  0.069689080119133\n",
      "Loss:  0.052864644676446915\n",
      "29 **********\n",
      "Epoch:  1754.6364583969116  fold:  9  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.043768465518951416\n",
      "Eval Loss:  0.609146237373352\n",
      "Eval Loss:  0.16168683767318726\n",
      "[[1636  106]\n",
      " [ 365 1301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87      1742\n",
      "           1       0.92      0.78      0.85      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.87      0.86      0.86      3408\n",
      "weighted avg       0.87      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8617957746478874\n",
      "pre:  0.9246624022743426\n",
      "rec:  0.7809123649459784\n",
      "ma F1:  0.8604473442083754\n",
      "mi F1:  0.8617957746478874\n",
      "we F1:  0.8607532567856975\n",
      "Eval Loss:  0.30019304156303406\n",
      "Eval Loss:  0.298249751329422\n",
      "Eval Loss:  0.26651138067245483\n",
      "Eval Loss:  0.24468910694122314\n",
      "Eval Loss:  0.2351725548505783\n",
      "Eval Loss:  0.16335006058216095\n",
      "Eval Loss:  0.27081894874572754\n",
      "Eval Loss:  0.27876925468444824\n",
      "Eval Loss:  0.22934973239898682\n",
      "Eval Loss:  0.22472742199897766\n",
      "Eval Loss:  0.2348945587873459\n",
      "Eval Loss:  0.3109135031700134\n",
      "Eval Loss:  0.2208346426486969\n",
      "Eval Loss:  0.19815810024738312\n",
      "Eval Loss:  0.27727210521698\n",
      "Eval Loss:  0.25006842613220215\n",
      "Eval Loss:  0.20139287412166595\n",
      "Eval Loss:  0.2314435839653015\n",
      "Eval Loss:  0.2709416151046753\n",
      "Eval Loss:  0.2960225045681\n",
      "Eval Loss:  0.30032601952552795\n",
      "Eval Loss:  0.1905028223991394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.196876659989357\n",
      "Eval Loss:  0.20328202843666077\n",
      "Eval Loss:  0.2531474232673645\n",
      "Eval Loss:  0.26247620582580566\n",
      "Eval Loss:  0.23016898334026337\n",
      "Eval Loss:  0.20025625824928284\n",
      "[[16960  1462]\n",
      " [ 1428  9633]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     18422\n",
      "           1       0.87      0.87      0.87     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.90      0.90     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9019774107112574\n",
      "pre:  0.8682289319513294\n",
      "rec:  0.8708977488473013\n",
      "ma F1:  0.8955250092709035\n",
      "mi F1:  0.9019774107112574\n",
      "we F1:  0.9020073522492635\n",
      "29483 461\n",
      "Loss:  0.05588905140757561\n",
      "Loss:  0.06717289239168167\n",
      "Loss:  0.06411962956190109\n",
      "30 **********\n",
      "Epoch:  1840.641497850418  fold:  9  kers:  64\n",
      "epoch:  31\n",
      "29483 461\n",
      "Loss:  0.09238483756780624\n",
      "Loss:  0.08163879066705704\n",
      "Loss:  0.058333270251750946\n",
      "31 **********\n",
      "Epoch:  1886.8629112243652  fold:  9  kers:  64\n",
      "epoch:  32\n",
      "29483 461\n",
      "Loss:  0.07542847096920013\n",
      "Loss:  0.06921017169952393\n",
      "Loss:  0.09869495779275894\n",
      "32 **********\n",
      "Epoch:  1933.0414395332336  fold:  9  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.04153110086917877\n",
      "Eval Loss:  0.8276910781860352\n",
      "Eval Loss:  0.1815868467092514\n",
      "[[1682   60]\n",
      " [ 484 1182]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86      1742\n",
      "           1       0.95      0.71      0.81      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.86      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8403755868544601\n",
      "pre:  0.9516908212560387\n",
      "rec:  0.709483793517407\n",
      "ma F1:  0.8368641055134672\n",
      "mi F1:  0.8403755868544601\n",
      "we F1:  0.8373978506772981\n",
      "Eval Loss:  0.26338204741477966\n",
      "Eval Loss:  0.2823481261730194\n",
      "Eval Loss:  0.2596392035484314\n",
      "Eval Loss:  0.2313300520181656\n",
      "Eval Loss:  0.21263691782951355\n",
      "Eval Loss:  0.157855823636055\n",
      "Eval Loss:  0.24444611370563507\n",
      "Eval Loss:  0.25344473123550415\n",
      "Eval Loss:  0.22749215364456177\n",
      "Eval Loss:  0.21086208522319794\n",
      "Eval Loss:  0.22585324943065643\n",
      "Eval Loss:  0.2793195843696594\n",
      "Eval Loss:  0.18620994687080383\n",
      "Eval Loss:  0.18948431313037872\n",
      "Eval Loss:  0.27956902980804443\n",
      "Eval Loss:  0.2525535225868225\n",
      "Eval Loss:  0.18388168513774872\n",
      "Eval Loss:  0.23578424751758575\n",
      "Eval Loss:  0.25658783316612244\n",
      "Eval Loss:  0.26875370740890503\n",
      "Eval Loss:  0.2867709994316101\n",
      "Eval Loss:  0.18466471135616302\n",
      "Eval Loss:  0.1884659379720688\n",
      "Eval Loss:  0.19339874386787415\n",
      "Eval Loss:  0.2518220543861389\n",
      "Eval Loss:  0.25935429334640503\n",
      "Eval Loss:  0.22028149664402008\n",
      "Eval Loss:  0.1898469179868698\n",
      "[[17384  1038]\n",
      " [ 1637  9424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18422\n",
      "           1       0.90      0.85      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.90      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9092697486687243\n",
      "pre:  0.9007837889504875\n",
      "rec:  0.8520025314166892\n",
      "ma F1:  0.9021362135145199\n",
      "mi F1:  0.9092697486687243\n",
      "we F1:  0.9087329411866428\n",
      "29483 461\n",
      "Loss:  0.07770120352506638\n",
      "Loss:  0.0734395906329155\n",
      "Loss:  0.05273876339197159\n",
      "33 **********\n",
      "Epoch:  2019.122277021408  fold:  9  kers:  64\n",
      "epoch:  34\n",
      "29483 461\n",
      "Loss:  0.07875921577215195\n",
      "Loss:  0.050480619072914124\n",
      "Loss:  0.08870982378721237\n",
      "34 **********\n",
      "Epoch:  2065.298810005188  fold:  9  kers:  64\n",
      "epoch:  35\n",
      "29483 461\n",
      "Loss:  0.04623408243060112\n",
      "Loss:  0.0533386766910553\n",
      "Loss:  0.07994059473276138\n",
      "35 **********\n",
      "Epoch:  2111.4514076709747  fold:  9  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.04739483445882797\n",
      "Eval Loss:  0.4961751103401184\n",
      "Eval Loss:  0.12307953834533691\n",
      "[[1596  146]\n",
      " [ 262 1404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      1742\n",
      "           1       0.91      0.84      0.87      1666\n",
      "\n",
      "    accuracy                           0.88      3408\n",
      "   macro avg       0.88      0.88      0.88      3408\n",
      "weighted avg       0.88      0.88      0.88      3408\n",
      "\n",
      "acc:  0.8802816901408451\n",
      "pre:  0.9058064516129032\n",
      "rec:  0.8427370948379351\n",
      "ma F1:  0.8799004975124378\n",
      "mi F1:  0.8802816901408451\n",
      "we F1:  0.8800513862611823\n",
      "update!  Acc:  0.8802816901408451\n",
      "Eval Loss:  0.26786336302757263\n",
      "Eval Loss:  0.26667600870132446\n",
      "Eval Loss:  0.2731072008609772\n",
      "Eval Loss:  0.23962056636810303\n",
      "Eval Loss:  0.2631336450576782\n",
      "Eval Loss:  0.14978447556495667\n",
      "Eval Loss:  0.23276394605636597\n",
      "Eval Loss:  0.25370925664901733\n",
      "Eval Loss:  0.2538706660270691\n",
      "Eval Loss:  0.23504406213760376\n",
      "Eval Loss:  0.2324897199869156\n",
      "Eval Loss:  0.3395307660102844\n",
      "Eval Loss:  0.20380280911922455\n",
      "Eval Loss:  0.19817200303077698\n",
      "Eval Loss:  0.253629595041275\n",
      "Eval Loss:  0.2390509694814682\n",
      "Eval Loss:  0.2235911637544632\n",
      "Eval Loss:  0.22622525691986084\n",
      "Eval Loss:  0.2330203503370285\n",
      "Eval Loss:  0.2620221972465515\n",
      "Eval Loss:  0.31070441007614136\n",
      "Eval Loss:  0.1825575977563858\n",
      "Eval Loss:  0.17172954976558685\n",
      "Eval Loss:  0.2108250856399536\n",
      "Eval Loss:  0.23398442566394806\n",
      "Eval Loss:  0.27068445086479187\n",
      "Eval Loss:  0.23881420493125916\n",
      "Eval Loss:  0.19309014081954956\n",
      "[[16574  1848]\n",
      " [  925 10136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92     18422\n",
      "           1       0.85      0.92      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.90      0.91      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.905945799274158\n",
      "pre:  0.8457943925233645\n",
      "rec:  0.9163728415152337\n",
      "ma F1:  0.9012365138756525\n",
      "mi F1:  0.905945799274158\n",
      "we F1:  0.90662095777413\n",
      "29483 461\n",
      "Loss:  0.06956558674573898\n",
      "Loss:  0.06934676319360733\n",
      "Loss:  0.030440954491496086\n",
      "36 **********\n",
      "Epoch:  2197.777589082718  fold:  9  kers:  64\n",
      "epoch:  37\n",
      "29483 461\n",
      "Loss:  0.024495046585798264\n",
      "Loss:  0.054966654628515244\n",
      "Loss:  0.07790342718362808\n",
      "37 **********\n",
      "Epoch:  2245.8865942955017  fold:  9  kers:  64\n",
      "epoch:  38\n",
      "29483 461\n",
      "Loss:  0.03483603522181511\n",
      "Loss:  0.05492664873600006\n",
      "Loss:  0.05905117467045784\n",
      "38 **********\n",
      "Epoch:  2292.583735704422  fold:  9  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.032298218458890915\n",
      "Eval Loss:  0.9493898749351501\n",
      "Eval Loss:  0.16100718080997467\n",
      "[[1655   87]\n",
      " [ 423 1243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87      1742\n",
      "           1       0.93      0.75      0.83      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.87      0.85      0.85      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8503521126760564\n",
      "pre:  0.9345864661654135\n",
      "rec:  0.7460984393757503\n",
      "ma F1:  0.8481325886522345\n",
      "mi F1:  0.8503521126760564\n",
      "we F1:  0.8485420154139104\n",
      "Eval Loss:  0.2845136821269989\n",
      "Eval Loss:  0.2594149112701416\n",
      "Eval Loss:  0.24972841143608093\n",
      "Eval Loss:  0.18971699476242065\n",
      "Eval Loss:  0.20750455558300018\n",
      "Eval Loss:  0.12854069471359253\n",
      "Eval Loss:  0.22065502405166626\n",
      "Eval Loss:  0.23798131942749023\n",
      "Eval Loss:  0.2263135015964508\n",
      "Eval Loss:  0.1864265501499176\n",
      "Eval Loss:  0.21842169761657715\n",
      "Eval Loss:  0.27631157636642456\n",
      "Eval Loss:  0.1743609607219696\n",
      "Eval Loss:  0.1804395318031311\n",
      "Eval Loss:  0.2799740731716156\n",
      "Eval Loss:  0.20267276465892792\n",
      "Eval Loss:  0.18629157543182373\n",
      "Eval Loss:  0.1981017291545868\n",
      "Eval Loss:  0.2283535897731781\n",
      "Eval Loss:  0.2424197494983673\n",
      "Eval Loss:  0.295020192861557\n",
      "Eval Loss:  0.17295420169830322\n",
      "Eval Loss:  0.16978277266025543\n",
      "Eval Loss:  0.19316112995147705\n",
      "Eval Loss:  0.21784338355064392\n",
      "Eval Loss:  0.25929099321365356\n",
      "Eval Loss:  0.19205591082572937\n",
      "Eval Loss:  0.1964346021413803\n",
      "[[17370  1052]\n",
      " [ 1388  9673]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18422\n",
      "           1       0.90      0.87      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9172404436454906\n",
      "pre:  0.9019114219114219\n",
      "rec:  0.8745140584033994\n",
      "ma F1:  0.9111873939109496\n",
      "mi F1:  0.9172404436454906\n",
      "we F1:  0.9169762076170631\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.056525085121393204\n",
      "Loss:  0.06084674224257469\n",
      "Loss:  0.043785460293293\n",
      "39 **********\n",
      "Epoch:  2378.609719991684  fold:  9  kers:  64\n",
      "epoch:  40\n",
      "29483 461\n",
      "Loss:  0.050398651510477066\n",
      "Loss:  0.059556446969509125\n",
      "Loss:  0.054594505578279495\n",
      "40 **********\n",
      "Epoch:  2424.8411061763763  fold:  9  kers:  64\n",
      "epoch:  41\n",
      "29483 461\n",
      "Loss:  0.055235475301742554\n",
      "Loss:  0.04203944653272629\n",
      "Loss:  0.05845721438527107\n",
      "41 **********\n",
      "Epoch:  2470.9179062843323  fold:  9  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.04296527057886124\n",
      "Eval Loss:  0.6736876964569092\n",
      "Eval Loss:  0.18146544694900513\n",
      "[[1645   97]\n",
      " [ 387 1279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87      1742\n",
      "           1       0.93      0.77      0.84      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.87      0.86      0.86      3408\n",
      "weighted avg       0.87      0.86      0.86      3408\n",
      "\n",
      "acc:  0.857981220657277\n",
      "pre:  0.9295058139534884\n",
      "rec:  0.7677070828331333\n",
      "ma F1:  0.8563241278173405\n",
      "mi F1:  0.857981220657277\n",
      "we F1:  0.8566682235983109\n",
      "Eval Loss:  0.2623285949230194\n",
      "Eval Loss:  0.25819554924964905\n",
      "Eval Loss:  0.24338439106941223\n",
      "Eval Loss:  0.19379889965057373\n",
      "Eval Loss:  0.20316781103610992\n",
      "Eval Loss:  0.14040404558181763\n",
      "Eval Loss:  0.21741381287574768\n",
      "Eval Loss:  0.23922374844551086\n",
      "Eval Loss:  0.21572603285312653\n",
      "Eval Loss:  0.193312868475914\n",
      "Eval Loss:  0.21757972240447998\n",
      "Eval Loss:  0.268257200717926\n",
      "Eval Loss:  0.16763484477996826\n",
      "Eval Loss:  0.19365675747394562\n",
      "Eval Loss:  0.2639964818954468\n",
      "Eval Loss:  0.20951595902442932\n",
      "Eval Loss:  0.18468032777309418\n",
      "Eval Loss:  0.20222553610801697\n",
      "Eval Loss:  0.21952813863754272\n",
      "Eval Loss:  0.25368502736091614\n",
      "Eval Loss:  0.2614760398864746\n",
      "Eval Loss:  0.17273938655853271\n",
      "Eval Loss:  0.15364865958690643\n",
      "Eval Loss:  0.17873135209083557\n",
      "Eval Loss:  0.24794059991836548\n",
      "Eval Loss:  0.25736740231513977\n",
      "Eval Loss:  0.19402152299880981\n",
      "Eval Loss:  0.16811439394950867\n",
      "[[17397  1025]\n",
      " [ 1368  9693]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18422\n",
      "           1       0.90      0.88      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9188345826408438\n",
      "pre:  0.9043664862847546\n",
      "rec:  0.8763222131814483\n",
      "ma F1:  0.9128865342141419\n",
      "mi F1:  0.9188345826408438\n",
      "we F1:  0.9185697616893435\n",
      "29483 461\n",
      "Loss:  0.0324535146355629\n",
      "Loss:  0.05176703631877899\n",
      "Loss:  0.10200390964746475\n",
      "42 **********\n",
      "Epoch:  2557.1533300876617  fold:  9  kers:  64\n",
      "epoch:  43\n",
      "29483 461\n",
      "Loss:  0.09764555096626282\n",
      "Loss:  0.048981860280036926\n",
      "Loss:  0.03221629932522774\n",
      "43 **********\n",
      "Epoch:  2603.233122110367  fold:  9  kers:  64\n",
      "epoch:  44\n",
      "29483 461\n",
      "Loss:  0.05234411358833313\n",
      "Loss:  0.06406355649232864\n",
      "Loss:  0.07492555677890778\n",
      "44 **********\n",
      "Epoch:  2649.4675006866455  fold:  9  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.04219161719083786\n",
      "Eval Loss:  0.590313196182251\n",
      "Eval Loss:  0.14389784634113312\n",
      "[[1617  125]\n",
      " [ 318 1348]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      1742\n",
      "           1       0.92      0.81      0.86      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.88      0.87      0.87      3408\n",
      "weighted avg       0.87      0.87      0.87      3408\n",
      "\n",
      "acc:  0.8700117370892019\n",
      "pre:  0.9151391717583164\n",
      "rec:  0.8091236494597839\n",
      "ma F1:  0.8691968006177038\n",
      "mi F1:  0.8700117370892019\n",
      "we F1:  0.8694270428921791\n",
      "Eval Loss:  0.2772887051105499\n",
      "Eval Loss:  0.2410602867603302\n",
      "Eval Loss:  0.23513559997081757\n",
      "Eval Loss:  0.18799631297588348\n",
      "Eval Loss:  0.2116411328315735\n",
      "Eval Loss:  0.13154493272304535\n",
      "Eval Loss:  0.22678104043006897\n",
      "Eval Loss:  0.2155129611492157\n",
      "Eval Loss:  0.22489921748638153\n",
      "Eval Loss:  0.17199718952178955\n",
      "Eval Loss:  0.21528786420822144\n",
      "Eval Loss:  0.2913322448730469\n",
      "Eval Loss:  0.1919698268175125\n",
      "Eval Loss:  0.15727746486663818\n",
      "Eval Loss:  0.26138630509376526\n",
      "Eval Loss:  0.20078271627426147\n",
      "Eval Loss:  0.19139288365840912\n",
      "Eval Loss:  0.16571380198001862\n",
      "Eval Loss:  0.19350117444992065\n",
      "Eval Loss:  0.22963456809520721\n",
      "Eval Loss:  0.27843189239501953\n",
      "Eval Loss:  0.16432909667491913\n",
      "Eval Loss:  0.152352973818779\n",
      "Eval Loss:  0.17182663083076477\n",
      "Eval Loss:  0.22167177498340607\n",
      "Eval Loss:  0.24633915722370148\n",
      "Eval Loss:  0.20249268412590027\n",
      "Eval Loss:  0.1725739687681198\n",
      "[[17081  1341]\n",
      " [ 1069  9992]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18422\n",
      "           1       0.88      0.90      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.92      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9182579791744395\n",
      "pre:  0.88167299038207\n",
      "rec:  0.9033541271132809\n",
      "ma F1:  0.9132422400763567\n",
      "mi F1:  0.9182579791744395\n",
      "we F1:  0.9184504295954691\n",
      "29483 461\n",
      "Loss:  0.05916052684187889\n",
      "Loss:  0.04963956028223038\n",
      "Loss:  0.06911195814609528\n",
      "45 **********\n",
      "Epoch:  2735.61216711998  fold:  9  kers:  64\n",
      "epoch:  46\n",
      "29483 461\n",
      "Loss:  0.0642908588051796\n",
      "Loss:  0.0426187589764595\n",
      "Loss:  0.0632980465888977\n",
      "46 **********\n",
      "Epoch:  2781.8734741210938  fold:  9  kers:  64\n",
      "epoch:  47\n",
      "29483 461\n",
      "Loss:  0.05112609639763832\n",
      "Loss:  0.03905973583459854\n",
      "Loss:  0.08251042664051056\n",
      "47 **********\n",
      "Epoch:  2828.076935529709  fold:  9  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.03784266859292984\n",
      "Eval Loss:  1.1720529794692993\n",
      "Eval Loss:  0.1718030571937561\n",
      "[[1657   85]\n",
      " [ 490 1176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85      1742\n",
      "           1       0.93      0.71      0.80      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8312793427230047\n",
      "pre:  0.9325931800158604\n",
      "rec:  0.7058823529411765\n",
      "ma F1:  0.8278501037898014\n",
      "mi F1:  0.8312793427230047\n",
      "we F1:  0.8283919378000374\n",
      "Eval Loss:  0.29636552929878235\n",
      "Eval Loss:  0.23644179105758667\n",
      "Eval Loss:  0.25551652908325195\n",
      "Eval Loss:  0.17982782423496246\n",
      "Eval Loss:  0.2074204385280609\n",
      "Eval Loss:  0.12743575870990753\n",
      "Eval Loss:  0.2410777360200882\n",
      "Eval Loss:  0.239995539188385\n",
      "Eval Loss:  0.22792090475559235\n",
      "Eval Loss:  0.16492757201194763\n",
      "Eval Loss:  0.22163158655166626\n",
      "Eval Loss:  0.25986698269844055\n",
      "Eval Loss:  0.16471156477928162\n",
      "Eval Loss:  0.19353289902210236\n",
      "Eval Loss:  0.28430137038230896\n",
      "Eval Loss:  0.19513002038002014\n",
      "Eval Loss:  0.18532352149486542\n",
      "Eval Loss:  0.22169551253318787\n",
      "Eval Loss:  0.19453558325767517\n",
      "Eval Loss:  0.21828147768974304\n",
      "Eval Loss:  0.2622341811656952\n",
      "Eval Loss:  0.17292264103889465\n",
      "Eval Loss:  0.16412551701068878\n",
      "Eval Loss:  0.1708771288394928\n",
      "Eval Loss:  0.2146443873643875\n",
      "Eval Loss:  0.2692403197288513\n",
      "Eval Loss:  0.18615946173667908\n",
      "Eval Loss:  0.18101370334625244\n",
      "[[17480   942]\n",
      " [ 1416  9645]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18422\n",
      "           1       0.91      0.87      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9200217074246175\n",
      "pre:  0.9110229526778124\n",
      "rec:  0.8719826417141308\n",
      "ma F1:  0.9139443610372601\n",
      "mi F1:  0.9200217074246175\n",
      "we F1:  0.9196540415423448\n",
      "29483 461\n",
      "Loss:  0.05220711976289749\n",
      "Loss:  0.037890851497650146\n",
      "Loss:  0.05145539343357086\n",
      "48 **********\n",
      "Epoch:  2914.366215467453  fold:  9  kers:  64\n",
      "epoch:  49\n",
      "29483 461\n",
      "Loss:  0.02631963975727558\n",
      "Loss:  0.04172675311565399\n",
      "Loss:  0.06111828610301018\n",
      "49 **********\n",
      "Epoch:  2960.5716712474823  fold:  9  kers:  64\n",
      "epoch:  50\n",
      "29483 461\n",
      "Loss:  0.05217675864696503\n",
      "Loss:  0.03857411816716194\n",
      "Loss:  0.09557367116212845\n",
      "50 **********\n",
      "Epoch:  3006.8269941806793  fold:  9  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.0409967266023159\n",
      "Eval Loss:  1.0350744724273682\n",
      "Eval Loss:  0.15025116503238678\n",
      "[[1636  106]\n",
      " [ 414 1252]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      1742\n",
      "           1       0.92      0.75      0.83      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.86      0.85      0.85      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8474178403755869\n",
      "pre:  0.9219440353460973\n",
      "rec:  0.751500600240096\n",
      "ma F1:  0.8454557631772821\n",
      "mi F1:  0.8474178403755869\n",
      "we F1:  0.8458440909561132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2635391652584076\n",
      "Eval Loss:  0.2599422335624695\n",
      "Eval Loss:  0.2605604827404022\n",
      "Eval Loss:  0.17395815253257751\n",
      "Eval Loss:  0.22313830256462097\n",
      "Eval Loss:  0.12364669144153595\n",
      "Eval Loss:  0.23156464099884033\n",
      "Eval Loss:  0.23742759227752686\n",
      "Eval Loss:  0.23826676607131958\n",
      "Eval Loss:  0.18514153361320496\n",
      "Eval Loss:  0.20709756016731262\n",
      "Eval Loss:  0.27676430344581604\n",
      "Eval Loss:  0.19522877037525177\n",
      "Eval Loss:  0.17258161306381226\n",
      "Eval Loss:  0.2595506012439728\n",
      "Eval Loss:  0.18254271149635315\n",
      "Eval Loss:  0.19960711896419525\n",
      "Eval Loss:  0.20003819465637207\n",
      "Eval Loss:  0.17423246800899506\n",
      "Eval Loss:  0.2007017731666565\n",
      "Eval Loss:  0.26939576864242554\n",
      "Eval Loss:  0.1710205376148224\n",
      "Eval Loss:  0.16343079507350922\n",
      "Eval Loss:  0.16663478314876556\n",
      "Eval Loss:  0.2090035080909729\n",
      "Eval Loss:  0.22882241010665894\n",
      "Eval Loss:  0.20825845003128052\n",
      "Eval Loss:  0.17954248189926147\n",
      "[[17133  1289]\n",
      " [ 1096  9965]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18422\n",
      "           1       0.89      0.90      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.92      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9191059254485636\n",
      "pre:  0.8854629465079082\n",
      "rec:  0.9009131181629148\n",
      "ma F1:  0.9140239801684641\n",
      "mi F1:  0.9191059254485636\n",
      "we F1:  0.9192427579595929\n",
      "29483 461\n",
      "Loss:  0.050957486033439636\n",
      "Loss:  0.05613435432314873\n",
      "Loss:  0.039237044751644135\n",
      "51 **********\n",
      "Epoch:  3093.0125517845154  fold:  9  kers:  64\n",
      "epoch:  52\n",
      "29483 461\n",
      "Loss:  0.11140556633472443\n",
      "Loss:  0.06747791916131973\n",
      "Loss:  0.043001361191272736\n",
      "52 **********\n",
      "Epoch:  3139.230973005295  fold:  9  kers:  64\n",
      "epoch:  53\n",
      "29483 461\n",
      "Loss:  0.05656684190034866\n",
      "Loss:  0.08592820912599564\n",
      "Loss:  0.12646646797657013\n",
      "53 **********\n",
      "Epoch:  3185.3775861263275  fold:  9  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.03443135693669319\n",
      "Eval Loss:  0.7813650369644165\n",
      "Eval Loss:  0.1488034576177597\n",
      "[[1627  115]\n",
      " [ 360 1306]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      1742\n",
      "           1       0.92      0.78      0.85      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.87      0.86      0.86      3408\n",
      "weighted avg       0.87      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8606220657276995\n",
      "pre:  0.9190710767065446\n",
      "rec:  0.7839135654261705\n",
      "ma F1:  0.8593744665624745\n",
      "mi F1:  0.8606220657276995\n",
      "we F1:  0.8596698482962973\n",
      "Eval Loss:  0.23146899044513702\n",
      "Eval Loss:  0.2516942620277405\n",
      "Eval Loss:  0.2353765219449997\n",
      "Eval Loss:  0.16892504692077637\n",
      "Eval Loss:  0.20811086893081665\n",
      "Eval Loss:  0.12861984968185425\n",
      "Eval Loss:  0.1914888173341751\n",
      "Eval Loss:  0.18804101645946503\n",
      "Eval Loss:  0.22374552488327026\n",
      "Eval Loss:  0.1620834320783615\n",
      "Eval Loss:  0.20336073637008667\n",
      "Eval Loss:  0.25491008162498474\n",
      "Eval Loss:  0.1402336210012436\n",
      "Eval Loss:  0.17249904572963715\n",
      "Eval Loss:  0.24118733406066895\n",
      "Eval Loss:  0.1876523196697235\n",
      "Eval Loss:  0.17148303985595703\n",
      "Eval Loss:  0.1757565140724182\n",
      "Eval Loss:  0.1595303863286972\n",
      "Eval Loss:  0.2063661366701126\n",
      "Eval Loss:  0.24947793781757355\n",
      "Eval Loss:  0.154327854514122\n",
      "Eval Loss:  0.14145487546920776\n",
      "Eval Loss:  0.1531316637992859\n",
      "Eval Loss:  0.2121489942073822\n",
      "Eval Loss:  0.23510365188121796\n",
      "Eval Loss:  0.18852251768112183\n",
      "Eval Loss:  0.16307957470417023\n",
      "[[17306  1116]\n",
      " [ 1054 10007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18422\n",
      "           1       0.90      0.90      0.90     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9263982634060306\n",
      "pre:  0.8996673559291558\n",
      "rec:  0.9047102431968177\n",
      "ma F1:  0.9215927522248168\n",
      "mi F1:  0.9263982634060306\n",
      "we F1:  0.9264390829283262\n",
      "29483 461\n",
      "Loss:  0.04248730093240738\n",
      "Loss:  0.05010247975587845\n",
      "Loss:  0.05113615095615387\n",
      "54 **********\n",
      "Epoch:  3271.688807487488  fold:  9  kers:  64\n",
      "epoch:  55\n",
      "29483 461\n",
      "Loss:  0.053849957883358\n",
      "Loss:  0.038945749402046204\n",
      "Loss:  0.02644818089902401\n",
      "55 **********\n",
      "Epoch:  3317.888279438019  fold:  9  kers:  64\n",
      "epoch:  56\n",
      "29483 461\n",
      "Loss:  0.04972386732697487\n",
      "Loss:  0.06914933770895004\n",
      "Loss:  0.05831551179289818\n",
      "56 **********\n",
      "Epoch:  3364.0348930358887  fold:  9  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.032714731991291046\n",
      "Eval Loss:  0.8617057800292969\n",
      "Eval Loss:  0.12849248945713043\n",
      "[[1600  142]\n",
      " [ 313 1353]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88      1742\n",
      "           1       0.91      0.81      0.86      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.87      0.87      0.87      3408\n",
      "weighted avg       0.87      0.87      0.87      3408\n",
      "\n",
      "acc:  0.8664906103286385\n",
      "pre:  0.9050167224080268\n",
      "rec:  0.812124849939976\n",
      "ma F1:  0.8657856026617146\n",
      "mi F1:  0.8664906103286385\n",
      "we F1:  0.8660025280976912\n",
      "Eval Loss:  0.24335800111293793\n",
      "Eval Loss:  0.24928465485572815\n",
      "Eval Loss:  0.2263331413269043\n",
      "Eval Loss:  0.1594376266002655\n",
      "Eval Loss:  0.20838207006454468\n",
      "Eval Loss:  0.11977493017911911\n",
      "Eval Loss:  0.19813229143619537\n",
      "Eval Loss:  0.201552614569664\n",
      "Eval Loss:  0.2189544290304184\n",
      "Eval Loss:  0.16365531086921692\n",
      "Eval Loss:  0.20588478446006775\n",
      "Eval Loss:  0.2924831509590149\n",
      "Eval Loss:  0.15837763249874115\n",
      "Eval Loss:  0.17287634313106537\n",
      "Eval Loss:  0.23646323382854462\n",
      "Eval Loss:  0.18036459386348724\n",
      "Eval Loss:  0.20400981605052948\n",
      "Eval Loss:  0.18459391593933105\n",
      "Eval Loss:  0.1700001060962677\n",
      "Eval Loss:  0.21652281284332275\n",
      "Eval Loss:  0.2740953266620636\n",
      "Eval Loss:  0.1603747010231018\n",
      "Eval Loss:  0.14171907305717468\n",
      "Eval Loss:  0.15841595828533173\n",
      "Eval Loss:  0.19771532714366913\n",
      "Eval Loss:  0.23234999179840088\n",
      "Eval Loss:  0.19346357882022858\n",
      "Eval Loss:  0.18122462928295135\n",
      "[[17031  1391]\n",
      " [  893 10168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     18422\n",
      "           1       0.88      0.92      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9225316283960249\n",
      "pre:  0.8796608703175015\n",
      "rec:  0.9192658891601121\n",
      "ma F1:  0.9180934658702928\n",
      "mi F1:  0.9225316283960249\n",
      "we F1:  0.9228536748680946\n",
      "29483 461\n",
      "Loss:  0.06749225407838821\n",
      "Loss:  0.05406360328197479\n",
      "Loss:  0.07891664654016495\n",
      "57 **********\n",
      "Epoch:  3450.2523646354675  fold:  9  kers:  64\n",
      "epoch:  58\n",
      "29483 461\n",
      "Loss:  0.0474805049598217\n",
      "Loss:  0.059729065746068954\n",
      "Loss:  0.059217389672994614\n",
      "58 **********\n",
      "Epoch:  3496.634349346161  fold:  9  kers:  64\n",
      "epoch:  59\n",
      "29483 461\n",
      "Loss:  0.04159276559948921\n",
      "Loss:  0.06995018571615219\n",
      "Loss:  0.0822995975613594\n",
      "59 **********\n",
      "Epoch:  3542.8846848011017  fold:  9  kers:  64\n",
      "Eval Loss:  0.05356138199567795\n",
      "Eval Loss:  1.4662483930587769\n",
      "Eval Loss:  0.12284587323665619\n",
      "[[1629  113]\n",
      " [ 401 1265]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      1742\n",
      "           1       0.92      0.76      0.83      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.86      0.85      0.85      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8491784037558685\n",
      "pre:  0.9179970972423802\n",
      "rec:  0.7593037214885955\n",
      "ma F1:  0.8474380001755797\n",
      "mi F1:  0.8491784037558685\n",
      "we F1:  0.8478013811428926\n",
      "update!  Acc:  0.8802816901408451\n",
      "Epoch:  3547.037580728531  fold:  9  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29871 3020\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29871 467\n",
      "Loss:  0.16691268980503082\n",
      "Loss:  0.16852331161499023\n",
      "Loss:  0.16503284871578217\n",
      "0 **********\n",
      "Epoch:  59.25057554244995  fold:  10  kers:  64\n",
      "epoch:  1\n",
      "29871 467\n",
      "Loss:  0.13754843175411224\n",
      "Loss:  0.1566823571920395\n",
      "Loss:  0.14102160930633545\n",
      "1 **********\n",
      "Epoch:  106.26686358451843  fold:  10  kers:  64\n",
      "epoch:  2\n",
      "29871 467\n",
      "Loss:  0.09890947490930557\n",
      "Loss:  0.12081484496593475\n",
      "Loss:  0.12292919307947159\n",
      "2 **********\n",
      "Epoch:  153.1774342060089  fold:  10  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.3779889643192291\n",
      "Eval Loss:  0.37529823184013367\n",
      "Eval Loss:  0.17370852828025818\n",
      "[[1481  270]\n",
      " [ 130 1139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88      1751\n",
      "           1       0.81      0.90      0.85      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.86      0.87      0.87      3020\n",
      "weighted avg       0.87      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8675496688741722\n",
      "pre:  0.808374733853797\n",
      "rec:  0.8975571315996848\n",
      "ma F1:  0.8658290012835099\n",
      "mi F1:  0.8675496688741722\n",
      "we F1:  0.8682540357241507\n",
      "update!  Acc:  0.8675496688741722\n",
      "Eval Loss:  0.41935816407203674\n",
      "Eval Loss:  0.409749299287796\n",
      "Eval Loss:  0.3921661972999573\n",
      "Eval Loss:  0.45567840337753296\n",
      "Eval Loss:  0.44525155425071716\n",
      "Eval Loss:  0.4162040948867798\n",
      "Eval Loss:  0.4105812609195709\n",
      "Eval Loss:  0.39448076486587524\n",
      "Eval Loss:  0.476500928401947\n",
      "Eval Loss:  0.46426594257354736\n",
      "Eval Loss:  0.42710036039352417\n",
      "Eval Loss:  0.4593318998813629\n",
      "Eval Loss:  0.3646479845046997\n",
      "Eval Loss:  0.45925796031951904\n",
      "Eval Loss:  0.46930956840515137\n",
      "Eval Loss:  0.4693778455257416\n",
      "Eval Loss:  0.40582412481307983\n",
      "Eval Loss:  0.4564610421657562\n",
      "Eval Loss:  0.42914676666259766\n",
      "Eval Loss:  0.49487408995628357\n",
      "Eval Loss:  0.41416171193122864\n",
      "Eval Loss:  0.4052262008190155\n",
      "Eval Loss:  0.4474140703678131\n",
      "Eval Loss:  0.46651557087898254\n",
      "Eval Loss:  0.4158424735069275\n",
      "Eval Loss:  0.3879956603050232\n",
      "Eval Loss:  0.3512853682041168\n",
      "Eval Loss:  0.4425467252731323\n",
      "Eval Loss:  0.5003846287727356\n",
      "[[15340  3073]\n",
      " [ 2855  8603]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84     18413\n",
      "           1       0.74      0.75      0.74     11458\n",
      "\n",
      "    accuracy                           0.80     29871\n",
      "   macro avg       0.79      0.79      0.79     29871\n",
      "weighted avg       0.80      0.80      0.80     29871\n",
      "\n",
      "acc:  0.8015466505975696\n",
      "pre:  0.736810551558753\n",
      "rec:  0.7508291150288008\n",
      "ma F1:  0.7909109820649654\n",
      "mi F1:  0.8015466505975696\n",
      "we F1:  0.8018908061178467\n",
      "29871 467\n",
      "Loss:  0.10476753115653992\n",
      "Loss:  0.12157652527093887\n",
      "Loss:  0.1080135852098465\n",
      "3 **********\n",
      "Epoch:  240.37129545211792  fold:  10  kers:  64\n",
      "epoch:  4\n",
      "29871 467\n",
      "Loss:  0.10834948718547821\n",
      "Loss:  0.0859377309679985\n",
      "Loss:  0.07189753651618958\n",
      "4 **********\n",
      "Epoch:  287.33971190452576  fold:  10  kers:  64\n",
      "epoch:  5\n",
      "29871 467\n",
      "Loss:  0.09394935518503189\n",
      "Loss:  0.09702291339635849\n",
      "Loss:  0.06098376587033272\n",
      "5 **********\n",
      "Epoch:  334.37195682525635  fold:  10  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.31900015473365784\n",
      "Eval Loss:  0.26037389039993286\n",
      "Eval Loss:  0.19115670025348663\n",
      "[[1554  197]\n",
      " [ 136 1133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90      1751\n",
      "           1       0.85      0.89      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.89      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8897350993377483\n",
      "pre:  0.8518796992481203\n",
      "rec:  0.8928289992119779\n",
      "ma F1:  0.88754980203304\n",
      "mi F1:  0.8897350993377484\n",
      "we F1:  0.8900517338640839\n",
      "update!  Acc:  0.8897350993377483\n",
      "Eval Loss:  0.3333297669887543\n",
      "Eval Loss:  0.30054524540901184\n",
      "Eval Loss:  0.3203442692756653\n",
      "Eval Loss:  0.37436580657958984\n",
      "Eval Loss:  0.3704506456851959\n",
      "Eval Loss:  0.35820719599723816\n",
      "Eval Loss:  0.3730887174606323\n",
      "Eval Loss:  0.31457918882369995\n",
      "Eval Loss:  0.4383949339389801\n",
      "Eval Loss:  0.401920884847641\n",
      "Eval Loss:  0.30978068709373474\n",
      "Eval Loss:  0.37153515219688416\n",
      "Eval Loss:  0.2759491503238678\n",
      "Eval Loss:  0.3876766562461853\n",
      "Eval Loss:  0.41176438331604004\n",
      "Eval Loss:  0.47382843494415283\n",
      "Eval Loss:  0.3589932918548584\n",
      "Eval Loss:  0.390325129032135\n",
      "Eval Loss:  0.34771376848220825\n",
      "Eval Loss:  0.367464542388916\n",
      "Eval Loss:  0.3308161497116089\n",
      "Eval Loss:  0.3678690791130066\n",
      "Eval Loss:  0.3797686696052551\n",
      "Eval Loss:  0.39681461453437805\n",
      "Eval Loss:  0.32740575075149536\n",
      "Eval Loss:  0.30823126435279846\n",
      "Eval Loss:  0.2828214764595032\n",
      "Eval Loss:  0.40372151136398315\n",
      "Eval Loss:  0.42165258526802063\n",
      "[[16528  1885]\n",
      " [ 2651  8807]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88     18413\n",
      "           1       0.82      0.77      0.80     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.84      0.83      0.84     29871\n",
      "weighted avg       0.85      0.85      0.85     29871\n",
      "\n",
      "acc:  0.8481470322386261\n",
      "pre:  0.8236999625888515\n",
      "rec:  0.7686332693314715\n",
      "ma F1:  0.8372752379474621\n",
      "mi F1:  0.8481470322386261\n",
      "we F1:  0.8470684421043129\n",
      "29871 467\n",
      "Loss:  0.07686889916658401\n",
      "Loss:  0.08340008556842804\n",
      "Loss:  0.08798088878393173\n",
      "6 **********\n",
      "Epoch:  421.59274673461914  fold:  10  kers:  64\n",
      "epoch:  7\n",
      "29871 467\n",
      "Loss:  0.09247308224439621\n",
      "Loss:  0.08599694073200226\n",
      "Loss:  0.08915400505065918\n",
      "7 **********\n",
      "Epoch:  468.5860958099365  fold:  10  kers:  64\n",
      "epoch:  8\n",
      "29871 467\n",
      "Loss:  0.08596328645944595\n",
      "Loss:  0.08147371560335159\n",
      "Loss:  0.05807707831263542\n",
      "8 **********\n",
      "Epoch:  515.4398181438446  fold:  10  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.49725285172462463\n",
      "Eval Loss:  0.12795525789260864\n",
      "Eval Loss:  0.11326448619365692\n",
      "[[1654   97]\n",
      " [ 205 1064]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      1751\n",
      "           1       0.92      0.84      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9\n",
      "pre:  0.9164513350559862\n",
      "rec:  0.8384554767533491\n",
      "ma F1:  0.8960318274568813\n",
      "mi F1:  0.9\n",
      "we F1:  0.8992736226531238\n",
      "update!  Acc:  0.9\n",
      "Eval Loss:  0.3371449410915375\n",
      "Eval Loss:  0.3089340329170227\n",
      "Eval Loss:  0.35792720317840576\n",
      "Eval Loss:  0.2996448278427124\n",
      "Eval Loss:  0.38505756855010986\n",
      "Eval Loss:  0.3453710675239563\n",
      "Eval Loss:  0.361518919467926\n",
      "Eval Loss:  0.31309938430786133\n",
      "Eval Loss:  0.4125235080718994\n",
      "Eval Loss:  0.4273192584514618\n",
      "Eval Loss:  0.2983916699886322\n",
      "Eval Loss:  0.4218834638595581\n",
      "Eval Loss:  0.2688402235507965\n",
      "Eval Loss:  0.3153078556060791\n",
      "Eval Loss:  0.41821184754371643\n",
      "Eval Loss:  0.4886624813079834\n",
      "Eval Loss:  0.3565960228443146\n",
      "Eval Loss:  0.4155890941619873\n",
      "Eval Loss:  0.3630525469779968\n",
      "Eval Loss:  0.3609730005264282\n",
      "Eval Loss:  0.3275028467178345\n",
      "Eval Loss:  0.3733879327774048\n",
      "Eval Loss:  0.4100482165813446\n",
      "Eval Loss:  0.4058210849761963\n",
      "Eval Loss:  0.35606223344802856\n",
      "Eval Loss:  0.33329614996910095\n",
      "Eval Loss:  0.2431751787662506\n",
      "Eval Loss:  0.3762621283531189\n",
      "Eval Loss:  0.4078473448753357\n",
      "[[17495   918]\n",
      " [ 3448  8010]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18413\n",
      "           1       0.90      0.70      0.79     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.87      0.82      0.84     29871\n",
      "weighted avg       0.86      0.85      0.85     29871\n",
      "\n",
      "acc:  0.8538381708011115\n",
      "pre:  0.8971774193548387\n",
      "rec:  0.6990748821783906\n",
      "ma F1:  0.8374486721749452\n",
      "mi F1:  0.8538381708011115\n",
      "we F1:  0.8494664858749964\n",
      "29871 467\n",
      "Loss:  0.10617166012525558\n",
      "Loss:  0.08045326918363571\n",
      "Loss:  0.08674989640712738\n",
      "9 **********\n",
      "Epoch:  602.341460943222  fold:  10  kers:  64\n",
      "epoch:  10\n",
      "29871 467\n",
      "Loss:  0.07780243456363678\n",
      "Loss:  0.07365003973245621\n",
      "Loss:  0.10729195922613144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 **********\n",
      "Epoch:  649.1104099750519  fold:  10  kers:  64\n",
      "epoch:  11\n",
      "29871 467\n",
      "Loss:  0.08777517825365067\n",
      "Loss:  0.07030722498893738\n",
      "Loss:  0.0614631250500679\n",
      "11 **********\n",
      "Epoch:  696.0269649028778  fold:  10  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.6174484491348267\n",
      "Eval Loss:  0.09045177698135376\n",
      "Eval Loss:  0.06092023849487305\n",
      "[[1684   67]\n",
      " [ 298  971]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      1751\n",
      "           1       0.94      0.77      0.84      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.89      0.86      0.87      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8791390728476821\n",
      "pre:  0.9354527938342967\n",
      "rec:  0.7651694247438928\n",
      "ma F1:  0.8720046409493881\n",
      "mi F1:  0.8791390728476821\n",
      "we F1:  0.8768276369872251\n",
      "Eval Loss:  0.34481507539749146\n",
      "Eval Loss:  0.3148517906665802\n",
      "Eval Loss:  0.356751024723053\n",
      "Eval Loss:  0.27117881178855896\n",
      "Eval Loss:  0.40968602895736694\n",
      "Eval Loss:  0.3365907669067383\n",
      "Eval Loss:  0.36496061086654663\n",
      "Eval Loss:  0.3550100326538086\n",
      "Eval Loss:  0.40470364689826965\n",
      "Eval Loss:  0.47200098633766174\n",
      "Eval Loss:  0.3448357582092285\n",
      "Eval Loss:  0.45070964097976685\n",
      "Eval Loss:  0.2863617539405823\n",
      "Eval Loss:  0.3096211850643158\n",
      "Eval Loss:  0.47162219882011414\n",
      "Eval Loss:  0.5184564590454102\n",
      "Eval Loss:  0.37157192826271057\n",
      "Eval Loss:  0.41336268186569214\n",
      "Eval Loss:  0.33086761832237244\n",
      "Eval Loss:  0.3674478828907013\n",
      "Eval Loss:  0.3487776815891266\n",
      "Eval Loss:  0.38608965277671814\n",
      "Eval Loss:  0.4450584053993225\n",
      "Eval Loss:  0.41655901074409485\n",
      "Eval Loss:  0.4112694263458252\n",
      "Eval Loss:  0.38010522723197937\n",
      "Eval Loss:  0.24948841333389282\n",
      "Eval Loss:  0.3812049329280853\n",
      "Eval Loss:  0.4602694809436798\n",
      "[[17886   527]\n",
      " [ 4100  7358]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89     18413\n",
      "           1       0.93      0.64      0.76     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.87      0.81      0.82     29871\n",
      "weighted avg       0.86      0.85      0.84     29871\n",
      "\n",
      "acc:  0.8451005992434133\n",
      "pre:  0.9331642358909321\n",
      "rec:  0.6421714086227963\n",
      "ma F1:  0.8231297399250521\n",
      "mi F1:  0.8451005992434133\n",
      "we F1:  0.8376441136483807\n",
      "29871 467\n",
      "Loss:  0.08494802564382553\n",
      "Loss:  0.07071429491043091\n",
      "Loss:  0.05763548985123634\n",
      "12 **********\n",
      "Epoch:  783.251743555069  fold:  10  kers:  64\n",
      "epoch:  13\n",
      "29871 467\n",
      "Loss:  0.06348687410354614\n",
      "Loss:  0.06389401108026505\n",
      "Loss:  0.06760179251432419\n",
      "13 **********\n",
      "Epoch:  830.1772742271423  fold:  10  kers:  64\n",
      "epoch:  14\n",
      "29871 467\n",
      "Loss:  0.06895073503255844\n",
      "Loss:  0.06378382444381714\n",
      "Loss:  0.04048212617635727\n",
      "14 **********\n",
      "Epoch:  877.022020816803  fold:  10  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.7151595950126648\n",
      "Eval Loss:  0.08553974330425262\n",
      "Eval Loss:  0.06795835494995117\n",
      "[[1668   83]\n",
      " [ 307  962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.90      1751\n",
      "           1       0.92      0.76      0.83      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.88      0.86      0.86      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8708609271523179\n",
      "pre:  0.9205741626794258\n",
      "rec:  0.7580772261623325\n",
      "ma F1:  0.8633953934393602\n",
      "mi F1:  0.8708609271523179\n",
      "we F1:  0.8684922592320593\n",
      "Eval Loss:  0.31324538588523865\n",
      "Eval Loss:  0.2613729238510132\n",
      "Eval Loss:  0.29263654351234436\n",
      "Eval Loss:  0.22625309228897095\n",
      "Eval Loss:  0.38651058077812195\n",
      "Eval Loss:  0.2764134109020233\n",
      "Eval Loss:  0.3052068054676056\n",
      "Eval Loss:  0.31813549995422363\n",
      "Eval Loss:  0.34495681524276733\n",
      "Eval Loss:  0.39880067110061646\n",
      "Eval Loss:  0.27614447474479675\n",
      "Eval Loss:  0.4057530164718628\n",
      "Eval Loss:  0.2428959310054779\n",
      "Eval Loss:  0.2628258764743805\n",
      "Eval Loss:  0.418095201253891\n",
      "Eval Loss:  0.45134666562080383\n",
      "Eval Loss:  0.317722350358963\n",
      "Eval Loss:  0.38898077607154846\n",
      "Eval Loss:  0.27498894929885864\n",
      "Eval Loss:  0.28626570105552673\n",
      "Eval Loss:  0.29867056012153625\n",
      "Eval Loss:  0.31460079550743103\n",
      "Eval Loss:  0.3833247721195221\n",
      "Eval Loss:  0.37328845262527466\n",
      "Eval Loss:  0.34877535700798035\n",
      "Eval Loss:  0.307870477437973\n",
      "Eval Loss:  0.2148052453994751\n",
      "Eval Loss:  0.32261475920677185\n",
      "Eval Loss:  0.37276697158813477\n",
      "[[17771   642]\n",
      " [ 3358  8100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     18413\n",
      "           1       0.93      0.71      0.80     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.88      0.84      0.85     29871\n",
      "weighted avg       0.87      0.87      0.86     29871\n",
      "\n",
      "acc:  0.8660908573532858\n",
      "pre:  0.9265614275909403\n",
      "rec:  0.7069296561354512\n",
      "ma F1:  0.8504109679593725\n",
      "mi F1:  0.8660908573532858\n",
      "we F1:  0.861687323117543\n",
      "29871 467\n",
      "Loss:  0.0674411803483963\n",
      "Loss:  0.09048736840486526\n",
      "Loss:  0.06788544356822968\n",
      "15 **********\n",
      "Epoch:  964.04234623909  fold:  10  kers:  64\n",
      "epoch:  16\n",
      "29871 467\n",
      "Loss:  0.06208490580320358\n",
      "Loss:  0.09326411038637161\n",
      "Loss:  0.0524294376373291\n",
      "16 **********\n",
      "Epoch:  1010.9090344905853  fold:  10  kers:  64\n",
      "epoch:  17\n",
      "29871 467\n",
      "Loss:  0.06898749619722366\n",
      "Loss:  0.08715455234050751\n",
      "Loss:  0.05086302384734154\n",
      "17 **********\n",
      "Epoch:  1057.7677433490753  fold:  10  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.731020450592041\n",
      "Eval Loss:  0.0871715396642685\n",
      "Eval Loss:  0.051652517169713974\n",
      "[[1671   80]\n",
      " [ 331  938]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      1751\n",
      "           1       0.92      0.74      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.88      0.85      0.86      3020\n",
      "weighted avg       0.87      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8639072847682119\n",
      "pre:  0.9214145383104125\n",
      "rec:  0.7391646966115051\n",
      "ma F1:  0.8553880987907531\n",
      "mi F1:  0.8639072847682119\n",
      "we F1:  0.8609900737445526\n",
      "Eval Loss:  0.2774485945701599\n",
      "Eval Loss:  0.23840205371379852\n",
      "Eval Loss:  0.25900477170944214\n",
      "Eval Loss:  0.20541313290596008\n",
      "Eval Loss:  0.338376522064209\n",
      "Eval Loss:  0.2491251826286316\n",
      "Eval Loss:  0.2728618383407593\n",
      "Eval Loss:  0.2910817861557007\n",
      "Eval Loss:  0.31053078174591064\n",
      "Eval Loss:  0.3537178933620453\n",
      "Eval Loss:  0.2424750030040741\n",
      "Eval Loss:  0.4200762212276459\n",
      "Eval Loss:  0.2194201499223709\n",
      "Eval Loss:  0.22021858394145966\n",
      "Eval Loss:  0.3816412389278412\n",
      "Eval Loss:  0.3896509110927582\n",
      "Eval Loss:  0.30139610171318054\n",
      "Eval Loss:  0.35773715376853943\n",
      "Eval Loss:  0.2832849621772766\n",
      "Eval Loss:  0.263708233833313\n",
      "Eval Loss:  0.253033846616745\n",
      "Eval Loss:  0.29611736536026\n",
      "Eval Loss:  0.2975892126560211\n",
      "Eval Loss:  0.36049535870552063\n",
      "Eval Loss:  0.2718691825866699\n",
      "Eval Loss:  0.2631863057613373\n",
      "Eval Loss:  0.20703738927841187\n",
      "Eval Loss:  0.33095961809158325\n",
      "Eval Loss:  0.3230884373188019\n",
      "[[17628   785]\n",
      " [ 2723  8735]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     18413\n",
      "           1       0.92      0.76      0.83     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.89      0.86      0.87     29871\n",
      "weighted avg       0.89      0.88      0.88     29871\n",
      "\n",
      "acc:  0.8825616818988317\n",
      "pre:  0.9175420168067226\n",
      "rec:  0.762349450165823\n",
      "ma F1:  0.871140429174742\n",
      "mi F1:  0.8825616818988317\n",
      "we F1:  0.8800727144211206\n",
      "29871 467\n",
      "Loss:  0.058602504432201385\n",
      "Loss:  0.08143850415945053\n",
      "Loss:  0.061934418976306915\n",
      "18 **********\n",
      "Epoch:  1144.7850770950317  fold:  10  kers:  64\n",
      "epoch:  19\n",
      "29871 467\n",
      "Loss:  0.06211967021226883\n",
      "Loss:  0.0880662202835083\n",
      "Loss:  0.0673268586397171\n",
      "19 **********\n",
      "Epoch:  1191.618852853775  fold:  10  kers:  64\n",
      "epoch:  20\n",
      "29871 467\n",
      "Loss:  0.07956632971763611\n",
      "Loss:  0.051706649363040924\n",
      "Loss:  0.047485265880823135\n",
      "20 **********\n",
      "Epoch:  1238.439663887024  fold:  10  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.40926459431648254\n",
      "Eval Loss:  0.09423435479402542\n",
      "Eval Loss:  0.04053022339940071\n",
      "[[1665   86]\n",
      " [ 224 1045]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1751\n",
      "           1       0.92      0.82      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.89      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8973509933774835\n",
      "pre:  0.9239610963748894\n",
      "rec:  0.8234830575256107\n",
      "ma F1:  0.8928342490842489\n",
      "mi F1:  0.8973509933774835\n",
      "we F1:  0.8963456535186667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22909697890281677\n",
      "Eval Loss:  0.2125735729932785\n",
      "Eval Loss:  0.23821786046028137\n",
      "Eval Loss:  0.18380676209926605\n",
      "Eval Loss:  0.32941877841949463\n",
      "Eval Loss:  0.23405486345291138\n",
      "Eval Loss:  0.2583298981189728\n",
      "Eval Loss:  0.2279367744922638\n",
      "Eval Loss:  0.26683276891708374\n",
      "Eval Loss:  0.2874070405960083\n",
      "Eval Loss:  0.18943607807159424\n",
      "Eval Loss:  0.34646204113960266\n",
      "Eval Loss:  0.17124822735786438\n",
      "Eval Loss:  0.2077566534280777\n",
      "Eval Loss:  0.36053645610809326\n",
      "Eval Loss:  0.3550398349761963\n",
      "Eval Loss:  0.2833315432071686\n",
      "Eval Loss:  0.33137038350105286\n",
      "Eval Loss:  0.22173991799354553\n",
      "Eval Loss:  0.2380138784646988\n",
      "Eval Loss:  0.21260838210582733\n",
      "Eval Loss:  0.24384747445583344\n",
      "Eval Loss:  0.28214383125305176\n",
      "Eval Loss:  0.32828372716903687\n",
      "Eval Loss:  0.21474072337150574\n",
      "Eval Loss:  0.22328335046768188\n",
      "Eval Loss:  0.19555337727069855\n",
      "Eval Loss:  0.3121728301048279\n",
      "Eval Loss:  0.2964650094509125\n",
      "[[17485   928]\n",
      " [ 2191  9267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18413\n",
      "           1       0.91      0.81      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.88      0.89     29871\n",
      "weighted avg       0.90      0.90      0.89     29871\n",
      "\n",
      "acc:  0.8955843460212246\n",
      "pre:  0.9089749877390878\n",
      "rec:  0.8087798917786699\n",
      "ma F1:  0.887034067928009\n",
      "mi F1:  0.8955843460212246\n",
      "we F1:  0.8942702791884513\n",
      "29871 467\n",
      "Loss:  0.08500400930643082\n",
      "Loss:  0.06647367030382156\n",
      "Loss:  0.0771738588809967\n",
      "21 **********\n",
      "Epoch:  1325.421092748642  fold:  10  kers:  64\n",
      "epoch:  22\n",
      "29871 467\n",
      "Loss:  0.07888595014810562\n",
      "Loss:  0.0878543108701706\n",
      "Loss:  0.042078472673892975\n",
      "22 **********\n",
      "Epoch:  1372.341637134552  fold:  10  kers:  64\n",
      "epoch:  23\n",
      "29871 467\n",
      "Loss:  0.03450695052742958\n",
      "Loss:  0.04527490958571434\n",
      "Loss:  0.0954609140753746\n",
      "23 **********\n",
      "Epoch:  1419.3868479728699  fold:  10  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.6276044845581055\n",
      "Eval Loss:  0.08041700720787048\n",
      "Eval Loss:  0.02030258998274803\n",
      "[[1676   75]\n",
      " [ 283  986]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.90      1751\n",
      "           1       0.93      0.78      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.89      0.87      0.87      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8814569536423841\n",
      "pre:  0.9293119698397738\n",
      "rec:  0.77698975571316\n",
      "ma F1:  0.8749279872285785\n",
      "mi F1:  0.8814569536423841\n",
      "we F1:  0.8794888014480775\n",
      "Eval Loss:  0.24343793094158173\n",
      "Eval Loss:  0.2164747714996338\n",
      "Eval Loss:  0.2433978021144867\n",
      "Eval Loss:  0.18745356798171997\n",
      "Eval Loss:  0.3197805881500244\n",
      "Eval Loss:  0.2364998608827591\n",
      "Eval Loss:  0.24034181237220764\n",
      "Eval Loss:  0.26392340660095215\n",
      "Eval Loss:  0.25734782218933105\n",
      "Eval Loss:  0.2717549502849579\n",
      "Eval Loss:  0.1927681863307953\n",
      "Eval Loss:  0.4330334961414337\n",
      "Eval Loss:  0.1856793463230133\n",
      "Eval Loss:  0.19935181736946106\n",
      "Eval Loss:  0.3931044340133667\n",
      "Eval Loss:  0.3690725862979889\n",
      "Eval Loss:  0.29004091024398804\n",
      "Eval Loss:  0.35363519191741943\n",
      "Eval Loss:  0.263307124376297\n",
      "Eval Loss:  0.23571240901947021\n",
      "Eval Loss:  0.21104910969734192\n",
      "Eval Loss:  0.2531283497810364\n",
      "Eval Loss:  0.3020152747631073\n",
      "Eval Loss:  0.3362760841846466\n",
      "Eval Loss:  0.23045940697193146\n",
      "Eval Loss:  0.24167755246162415\n",
      "Eval Loss:  0.2100462168455124\n",
      "Eval Loss:  0.2936308979988098\n",
      "Eval Loss:  0.2861604690551758\n",
      "[[17620   793]\n",
      " [ 2443  9015]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18413\n",
      "           1       0.92      0.79      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.90      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8916675035988082\n",
      "pre:  0.919147634584013\n",
      "rec:  0.7867865246989003\n",
      "ma F1:  0.8818639218457207\n",
      "mi F1:  0.8916675035988082\n",
      "we F1:  0.8897876767664322\n",
      "29871 467\n",
      "Loss:  0.08063612878322601\n",
      "Loss:  0.050730641931295395\n",
      "Loss:  0.08028692752122879\n",
      "24 **********\n",
      "Epoch:  1506.2775192260742  fold:  10  kers:  64\n",
      "epoch:  25\n",
      "29871 467\n",
      "Loss:  0.05685541033744812\n",
      "Loss:  0.05441684648394585\n",
      "Loss:  0.0305048618465662\n",
      "25 **********\n",
      "Epoch:  1553.0125596523285  fold:  10  kers:  64\n",
      "epoch:  26\n",
      "29871 467\n",
      "Loss:  0.03866678476333618\n",
      "Loss:  0.08173727989196777\n",
      "Loss:  0.06154172122478485\n",
      "26 **********\n",
      "Epoch:  1599.8283836841583  fold:  10  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.28450965881347656\n",
      "Eval Loss:  0.11569865792989731\n",
      "Eval Loss:  0.0357477106153965\n",
      "[[1653   98]\n",
      " [ 167 1102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1751\n",
      "           1       0.92      0.87      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9122516556291391\n",
      "pre:  0.9183333333333333\n",
      "rec:  0.8684003152088259\n",
      "ma F1:  0.9092300958658579\n",
      "mi F1:  0.9122516556291391\n",
      "we F1:  0.9118732751869132\n",
      "update!  Acc:  0.9122516556291391\n",
      "Eval Loss:  0.22455507516860962\n",
      "Eval Loss:  0.21596366167068481\n",
      "Eval Loss:  0.25165289640426636\n",
      "Eval Loss:  0.174033984541893\n",
      "Eval Loss:  0.30284416675567627\n",
      "Eval Loss:  0.23595783114433289\n",
      "Eval Loss:  0.2409568428993225\n",
      "Eval Loss:  0.22661548852920532\n",
      "Eval Loss:  0.2643206715583801\n",
      "Eval Loss:  0.2547138035297394\n",
      "Eval Loss:  0.17239287495613098\n",
      "Eval Loss:  0.3147701323032379\n",
      "Eval Loss:  0.1498170793056488\n",
      "Eval Loss:  0.19316984713077545\n",
      "Eval Loss:  0.37396878004074097\n",
      "Eval Loss:  0.33148840069770813\n",
      "Eval Loss:  0.2983435392379761\n",
      "Eval Loss:  0.3314478397369385\n",
      "Eval Loss:  0.2028723806142807\n",
      "Eval Loss:  0.21071423590183258\n",
      "Eval Loss:  0.19605687260627747\n",
      "Eval Loss:  0.22860708832740784\n",
      "Eval Loss:  0.2850320637226105\n",
      "Eval Loss:  0.2927849590778351\n",
      "Eval Loss:  0.18670623004436493\n",
      "Eval Loss:  0.20901048183441162\n",
      "Eval Loss:  0.20080772042274475\n",
      "Eval Loss:  0.29483017325401306\n",
      "Eval Loss:  0.2958437502384186\n",
      "[[17375  1038]\n",
      " [ 1860  9598]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18413\n",
      "           1       0.90      0.84      0.87     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.89      0.90     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9029828261524555\n",
      "pre:  0.9024069198946972\n",
      "rec:  0.8376680048874149\n",
      "ma F1:  0.8959284833903864\n",
      "mi F1:  0.9029828261524555\n",
      "we F1:  0.9022372083370485\n",
      "29871 467\n",
      "Loss:  0.06592468917369843\n",
      "Loss:  0.050277575850486755\n",
      "Loss:  0.07294947654008865\n",
      "27 **********\n",
      "Epoch:  1686.49764752388  fold:  10  kers:  64\n",
      "epoch:  28\n",
      "29871 467\n",
      "Loss:  0.06563224643468857\n",
      "Loss:  0.060149796307086945\n",
      "Loss:  0.04900125041604042\n",
      "28 **********\n",
      "Epoch:  1733.280559539795  fold:  10  kers:  64\n",
      "epoch:  29\n",
      "29871 467\n",
      "Loss:  0.059483326971530914\n",
      "Loss:  0.07342525571584702\n",
      "Loss:  0.06670688837766647\n",
      "29 **********\n",
      "Epoch:  1780.034548997879  fold:  10  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.4578397572040558\n",
      "Eval Loss:  0.09842386841773987\n",
      "Eval Loss:  0.03129550442099571\n",
      "[[1654   97]\n",
      " [ 193 1076]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      1751\n",
      "           1       0.92      0.85      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9039735099337748\n",
      "pre:  0.9173060528559249\n",
      "rec:  0.8479117415287628\n",
      "ma F1:  0.90032227386313\n",
      "mi F1:  0.9039735099337748\n",
      "we F1:  0.9033670762611418\n",
      "Eval Loss:  0.19932201504707336\n",
      "Eval Loss:  0.23199397325515747\n",
      "Eval Loss:  0.2621108889579773\n",
      "Eval Loss:  0.1818331629037857\n",
      "Eval Loss:  0.31314709782600403\n",
      "Eval Loss:  0.2560560405254364\n",
      "Eval Loss:  0.23116232454776764\n",
      "Eval Loss:  0.22569890320301056\n",
      "Eval Loss:  0.2602531611919403\n",
      "Eval Loss:  0.2925722599029541\n",
      "Eval Loss:  0.1738034337759018\n",
      "Eval Loss:  0.3911340534687042\n",
      "Eval Loss:  0.1477164477109909\n",
      "Eval Loss:  0.19077256321907043\n",
      "Eval Loss:  0.3806833028793335\n",
      "Eval Loss:  0.31821945309638977\n",
      "Eval Loss:  0.2840641736984253\n",
      "Eval Loss:  0.34150391817092896\n",
      "Eval Loss:  0.2544569969177246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2232331484556198\n",
      "Eval Loss:  0.1808539628982544\n",
      "Eval Loss:  0.25418156385421753\n",
      "Eval Loss:  0.2764758765697479\n",
      "Eval Loss:  0.32663053274154663\n",
      "Eval Loss:  0.1709911823272705\n",
      "Eval Loss:  0.17766018211841583\n",
      "Eval Loss:  0.19732621312141418\n",
      "Eval Loss:  0.3070557415485382\n",
      "Eval Loss:  0.29523611068725586\n",
      "[[17369  1044]\n",
      " [ 1836  9622]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18413\n",
      "           1       0.90      0.84      0.87     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.89      0.90     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9035854172943658\n",
      "pre:  0.9021188824301519\n",
      "rec:  0.8397626112759644\n",
      "ma F1:  0.8966327653955402\n",
      "mi F1:  0.9035854172943658\n",
      "we F1:  0.9028746259811\n",
      "29871 467\n",
      "Loss:  0.06727205216884613\n",
      "Loss:  0.08676587045192719\n",
      "Loss:  0.059970371425151825\n",
      "30 **********\n",
      "Epoch:  1869.0146346092224  fold:  10  kers:  64\n",
      "epoch:  31\n",
      "29871 467\n",
      "Loss:  0.06169462949037552\n",
      "Loss:  0.05564148351550102\n",
      "Loss:  0.07397405058145523\n",
      "31 **********\n",
      "Epoch:  1915.684847831726  fold:  10  kers:  64\n",
      "epoch:  32\n",
      "29871 467\n",
      "Loss:  0.07617843896150589\n",
      "Loss:  0.0597979798913002\n",
      "Loss:  0.05282435566186905\n",
      "32 **********\n",
      "Epoch:  1962.3640370368958  fold:  10  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.5103106498718262\n",
      "Eval Loss:  0.08370686322450638\n",
      "Eval Loss:  0.03170536458492279\n",
      "[[1675   76]\n",
      " [ 238 1031]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91      1751\n",
      "           1       0.93      0.81      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.88      0.89      3020\n",
      "weighted avg       0.90      0.90      0.89      3020\n",
      "\n",
      "acc:  0.8960264900662251\n",
      "pre:  0.931345980126468\n",
      "rec:  0.8124507486209613\n",
      "ma F1:  0.8910732139443931\n",
      "mi F1:  0.8960264900662251\n",
      "we F1:  0.8947804796132177\n",
      "Eval Loss:  0.21811263263225555\n",
      "Eval Loss:  0.2474304735660553\n",
      "Eval Loss:  0.24104955792427063\n",
      "Eval Loss:  0.19147318601608276\n",
      "Eval Loss:  0.2971097230911255\n",
      "Eval Loss:  0.20838189125061035\n",
      "Eval Loss:  0.2576904296875\n",
      "Eval Loss:  0.25750571489334106\n",
      "Eval Loss:  0.2795368731021881\n",
      "Eval Loss:  0.2991652190685272\n",
      "Eval Loss:  0.18904408812522888\n",
      "Eval Loss:  0.35913747549057007\n",
      "Eval Loss:  0.1759500801563263\n",
      "Eval Loss:  0.20335984230041504\n",
      "Eval Loss:  0.39927610754966736\n",
      "Eval Loss:  0.3857705295085907\n",
      "Eval Loss:  0.286754846572876\n",
      "Eval Loss:  0.3564879298210144\n",
      "Eval Loss:  0.23634931445121765\n",
      "Eval Loss:  0.22077445685863495\n",
      "Eval Loss:  0.20267310738563538\n",
      "Eval Loss:  0.24258476495742798\n",
      "Eval Loss:  0.30560120940208435\n",
      "Eval Loss:  0.3401869833469391\n",
      "Eval Loss:  0.19595953822135925\n",
      "Eval Loss:  0.20050938427448273\n",
      "Eval Loss:  0.20786835253238678\n",
      "Eval Loss:  0.3011608123779297\n",
      "Eval Loss:  0.307294636964798\n",
      "[[17735   678]\n",
      " [ 2324  9134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18413\n",
      "           1       0.93      0.80      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.91      0.88      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.899501188443641\n",
      "pre:  0.930900937627395\n",
      "rec:  0.7971722813754581\n",
      "ma F1:  0.8904157358338165\n",
      "mi F1:  0.899501188443641\n",
      "we F1:  0.8977624772477603\n",
      "29871 467\n",
      "Loss:  0.027175674214959145\n",
      "Loss:  0.07597948610782623\n",
      "Loss:  0.03693149611353874\n",
      "33 **********\n",
      "Epoch:  2049.1699352264404  fold:  10  kers:  64\n",
      "epoch:  34\n",
      "29871 467\n",
      "Loss:  0.05195595696568489\n",
      "Loss:  0.031654540449380875\n",
      "Loss:  0.06981394439935684\n",
      "34 **********\n",
      "Epoch:  2095.9438717365265  fold:  10  kers:  64\n",
      "epoch:  35\n",
      "29871 467\n",
      "Loss:  0.052179690450429916\n",
      "Loss:  0.06048557162284851\n",
      "Loss:  0.04718547686934471\n",
      "35 **********\n",
      "Epoch:  2142.7646820545197  fold:  10  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.5005979537963867\n",
      "Eval Loss:  0.0884174033999443\n",
      "Eval Loss:  0.01957966387271881\n",
      "[[1679   72]\n",
      " [ 212 1057]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      1751\n",
      "           1       0.94      0.83      0.88      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9059602649006623\n",
      "pre:  0.9362267493356953\n",
      "rec:  0.8329393223010244\n",
      "ma F1:  0.9017944204831136\n",
      "mi F1:  0.9059602649006623\n",
      "we F1:  0.9050226150317605\n",
      "Eval Loss:  0.1915753185749054\n",
      "Eval Loss:  0.22575391829013824\n",
      "Eval Loss:  0.24976353347301483\n",
      "Eval Loss:  0.1600346565246582\n",
      "Eval Loss:  0.302613765001297\n",
      "Eval Loss:  0.2037862092256546\n",
      "Eval Loss:  0.22268739342689514\n",
      "Eval Loss:  0.19759908318519592\n",
      "Eval Loss:  0.2579146921634674\n",
      "Eval Loss:  0.26089268922805786\n",
      "Eval Loss:  0.1706753373146057\n",
      "Eval Loss:  0.3689298629760742\n",
      "Eval Loss:  0.16042794287204742\n",
      "Eval Loss:  0.1736249476671219\n",
      "Eval Loss:  0.3644988536834717\n",
      "Eval Loss:  0.36500847339630127\n",
      "Eval Loss:  0.2585776150226593\n",
      "Eval Loss:  0.3099546432495117\n",
      "Eval Loss:  0.23761014640331268\n",
      "Eval Loss:  0.19415068626403809\n",
      "Eval Loss:  0.1829654425382614\n",
      "Eval Loss:  0.2457684427499771\n",
      "Eval Loss:  0.30118173360824585\n",
      "Eval Loss:  0.31052014231681824\n",
      "Eval Loss:  0.17791621387004852\n",
      "Eval Loss:  0.15216800570487976\n",
      "Eval Loss:  0.2087537795305252\n",
      "Eval Loss:  0.29217615723609924\n",
      "Eval Loss:  0.2742514908313751\n",
      "[[17683   730]\n",
      " [ 2064  9394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18413\n",
      "           1       0.93      0.82      0.87     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.89      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9064644638612701\n",
      "pre:  0.9278941129988147\n",
      "rec:  0.8198638505847443\n",
      "ma F1:  0.8986611178427866\n",
      "mi F1:  0.9064644638612701\n",
      "we F1:  0.9052086231580903\n",
      "29871 467\n",
      "Loss:  0.09864845126867294\n",
      "Loss:  0.059019505977630615\n",
      "Loss:  0.05578969791531563\n",
      "36 **********\n",
      "Epoch:  2229.5775623321533  fold:  10  kers:  64\n",
      "epoch:  37\n",
      "29871 467\n",
      "Loss:  0.05018928274512291\n",
      "Loss:  0.059316981583833694\n",
      "Loss:  0.07070092856884003\n",
      "37 **********\n",
      "Epoch:  2276.244783639908  fold:  10  kers:  64\n",
      "epoch:  38\n",
      "29871 467\n",
      "Loss:  0.049125317484140396\n",
      "Loss:  0.08847171068191528\n",
      "Loss:  0.07290452718734741\n",
      "38 **********\n",
      "Epoch:  2322.9937868118286  fold:  10  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.5615071654319763\n",
      "Eval Loss:  0.09839148819446564\n",
      "Eval Loss:  0.02523440681397915\n",
      "[[1661   90]\n",
      " [ 232 1037]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1751\n",
      "           1       0.92      0.82      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.88      0.89      3020\n",
      "weighted avg       0.90      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8933774834437086\n",
      "pre:  0.9201419698314108\n",
      "rec:  0.8171788810086682\n",
      "ma F1:  0.8886224571138506\n",
      "mi F1:  0.8933774834437086\n",
      "we F1:  0.8922954101442858\n",
      "Eval Loss:  0.1893543154001236\n",
      "Eval Loss:  0.23473677039146423\n",
      "Eval Loss:  0.24581260979175568\n",
      "Eval Loss:  0.19434119760990143\n",
      "Eval Loss:  0.30724117159843445\n",
      "Eval Loss:  0.24427413940429688\n",
      "Eval Loss:  0.22392988204956055\n",
      "Eval Loss:  0.20824846625328064\n",
      "Eval Loss:  0.25630733370780945\n",
      "Eval Loss:  0.25348663330078125\n",
      "Eval Loss:  0.14797461032867432\n",
      "Eval Loss:  0.2968046963214874\n",
      "Eval Loss:  0.12851987779140472\n",
      "Eval Loss:  0.19640502333641052\n",
      "Eval Loss:  0.34909993410110474\n",
      "Eval Loss:  0.34125956892967224\n",
      "Eval Loss:  0.27523553371429443\n",
      "Eval Loss:  0.34358343482017517\n",
      "Eval Loss:  0.2486659437417984\n",
      "Eval Loss:  0.20540274679660797\n",
      "Eval Loss:  0.2016570121049881\n",
      "Eval Loss:  0.24085849523544312\n",
      "Eval Loss:  0.2984820306301117\n",
      "Eval Loss:  0.29836639761924744\n",
      "Eval Loss:  0.14319774508476257\n",
      "Eval Loss:  0.16139495372772217\n",
      "Eval Loss:  0.21782246232032776\n",
      "Eval Loss:  0.29684409499168396\n",
      "Eval Loss:  0.25466078519821167\n",
      "[[17381  1032]\n",
      " [ 1655  9803]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18413\n",
      "           1       0.90      0.86      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9100465334270698\n",
      "pre:  0.9047531149053991\n",
      "rec:  0.8555594344562751\n",
      "ma F1:  0.9038589885015793\n",
      "mi F1:  0.9100465334270698\n",
      "we F1:  0.9095378450543354\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.044457271695137024\n",
      "Loss:  0.0647883415222168\n",
      "Loss:  0.05562061071395874\n",
      "39 **********\n",
      "Epoch:  2409.7597913742065  fold:  10  kers:  64\n",
      "epoch:  40\n",
      "29871 467\n",
      "Loss:  0.0703054890036583\n",
      "Loss:  0.06562768667936325\n",
      "Loss:  0.043166689574718475\n",
      "40 **********\n",
      "Epoch:  2456.5367193222046  fold:  10  kers:  64\n",
      "epoch:  41\n",
      "29871 467\n",
      "Loss:  0.033472079783678055\n",
      "Loss:  0.06314123421907425\n",
      "Loss:  0.07877983152866364\n",
      "41 **********\n",
      "Epoch:  2503.434324979782  fold:  10  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.7869558334350586\n",
      "Eval Loss:  0.08995693922042847\n",
      "Eval Loss:  0.010549227707087994\n",
      "[[1679   72]\n",
      " [ 307  962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      1751\n",
      "           1       0.93      0.76      0.84      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.89      0.86      0.87      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8745033112582782\n",
      "pre:  0.9303675048355899\n",
      "rec:  0.7580772261623325\n",
      "ma F1:  0.8670068976126939\n",
      "mi F1:  0.8745033112582782\n",
      "we F1:  0.8720463277063782\n",
      "Eval Loss:  0.19581322371959686\n",
      "Eval Loss:  0.24575024843215942\n",
      "Eval Loss:  0.27729931473731995\n",
      "Eval Loss:  0.17170022428035736\n",
      "Eval Loss:  0.29084062576293945\n",
      "Eval Loss:  0.2479969710111618\n",
      "Eval Loss:  0.23645146191120148\n",
      "Eval Loss:  0.2283497154712677\n",
      "Eval Loss:  0.25286880135536194\n",
      "Eval Loss:  0.26262885332107544\n",
      "Eval Loss:  0.14257241785526276\n",
      "Eval Loss:  0.3730278015136719\n",
      "Eval Loss:  0.1435530036687851\n",
      "Eval Loss:  0.18193282186985016\n",
      "Eval Loss:  0.3697877526283264\n",
      "Eval Loss:  0.3185431957244873\n",
      "Eval Loss:  0.25992485880851746\n",
      "Eval Loss:  0.35552042722702026\n",
      "Eval Loss:  0.24475936591625214\n",
      "Eval Loss:  0.2044205516576767\n",
      "Eval Loss:  0.2006443440914154\n",
      "Eval Loss:  0.23700159788131714\n",
      "Eval Loss:  0.3395731449127197\n",
      "Eval Loss:  0.312389612197876\n",
      "Eval Loss:  0.14223165810108185\n",
      "Eval Loss:  0.20025238394737244\n",
      "Eval Loss:  0.21564055979251862\n",
      "Eval Loss:  0.2843625545501709\n",
      "Eval Loss:  0.2533019483089447\n",
      "[[17619   794]\n",
      " [ 2009  9449]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18413\n",
      "           1       0.92      0.82      0.87     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.89      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9061631682903151\n",
      "pre:  0.9224836473689348\n",
      "rec:  0.8246639902251702\n",
      "ma F1:  0.8985758941321876\n",
      "mi F1:  0.9061631682903151\n",
      "we F1:  0.9050348282533353\n",
      "29871 467\n",
      "Loss:  0.0986601784825325\n",
      "Loss:  0.08029597997665405\n",
      "Loss:  0.05865364894270897\n",
      "42 **********\n",
      "Epoch:  2590.0806500911713  fold:  10  kers:  64\n",
      "epoch:  43\n",
      "29871 467\n",
      "Loss:  0.04056619107723236\n",
      "Loss:  0.05088387057185173\n",
      "Loss:  0.05385352671146393\n",
      "43 **********\n",
      "Epoch:  2636.84361577034  fold:  10  kers:  64\n",
      "epoch:  44\n",
      "29871 467\n",
      "Loss:  0.05448209121823311\n",
      "Loss:  0.035650741308927536\n",
      "Loss:  0.04686024785041809\n",
      "44 **********\n",
      "Epoch:  2683.591621160507  fold:  10  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.9026191234588623\n",
      "Eval Loss:  0.08263620734214783\n",
      "Eval Loss:  0.008069746196269989\n",
      "[[1693   58]\n",
      " [ 353  916]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89      1751\n",
      "           1       0.94      0.72      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.88      0.84      0.85      3020\n",
      "weighted avg       0.87      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8639072847682119\n",
      "pre:  0.9404517453798767\n",
      "rec:  0.7218282111899134\n",
      "ma F1:  0.8542599567366169\n",
      "mi F1:  0.8639072847682119\n",
      "we F1:  0.86024452830834\n",
      "Eval Loss:  0.20408859848976135\n",
      "Eval Loss:  0.22625073790550232\n",
      "Eval Loss:  0.26943355798721313\n",
      "Eval Loss:  0.16022801399230957\n",
      "Eval Loss:  0.28902265429496765\n",
      "Eval Loss:  0.22706764936447144\n",
      "Eval Loss:  0.22242440283298492\n",
      "Eval Loss:  0.2215222418308258\n",
      "Eval Loss:  0.2577052414417267\n",
      "Eval Loss:  0.26771268248558044\n",
      "Eval Loss:  0.17723269760608673\n",
      "Eval Loss:  0.39879319071769714\n",
      "Eval Loss:  0.16588735580444336\n",
      "Eval Loss:  0.16290557384490967\n",
      "Eval Loss:  0.3442073464393616\n",
      "Eval Loss:  0.3407249450683594\n",
      "Eval Loss:  0.24531103670597076\n",
      "Eval Loss:  0.3002181351184845\n",
      "Eval Loss:  0.27969443798065186\n",
      "Eval Loss:  0.20393206179141998\n",
      "Eval Loss:  0.18459837138652802\n",
      "Eval Loss:  0.2313629537820816\n",
      "Eval Loss:  0.31312355399131775\n",
      "Eval Loss:  0.29469072818756104\n",
      "Eval Loss:  0.16484837234020233\n",
      "Eval Loss:  0.18819165229797363\n",
      "Eval Loss:  0.2329230010509491\n",
      "Eval Loss:  0.27091845870018005\n",
      "Eval Loss:  0.27430257201194763\n",
      "[[17888   525]\n",
      " [ 2261  9197]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     18413\n",
      "           1       0.95      0.80      0.87     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.92      0.89      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9067322821465635\n",
      "pre:  0.9459987656860728\n",
      "rec:  0.8026706231454006\n",
      "ma F1:  0.8981067610042794\n",
      "mi F1:  0.9067322821465635\n",
      "we F1:  0.905009361343088\n",
      "29871 467\n",
      "Loss:  0.04092196747660637\n",
      "Loss:  0.050482530146837234\n",
      "Loss:  0.0259843897074461\n",
      "45 **********\n",
      "Epoch:  2770.2788367271423  fold:  10  kers:  64\n",
      "epoch:  46\n",
      "29871 467\n",
      "Loss:  0.07283259928226471\n",
      "Loss:  0.06696733087301254\n",
      "Loss:  0.04164080694317818\n",
      "46 **********\n",
      "Epoch:  2817.007892847061  fold:  10  kers:  64\n",
      "epoch:  47\n",
      "29871 467\n",
      "Loss:  0.024050120264291763\n",
      "Loss:  0.05872679874300957\n",
      "Loss:  0.04702208563685417\n",
      "47 **********\n",
      "Epoch:  2863.823716878891  fold:  10  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.9484632611274719\n",
      "Eval Loss:  0.08973462134599686\n",
      "Eval Loss:  0.015182098373770714\n",
      "[[1688   63]\n",
      " [ 372  897]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89      1751\n",
      "           1       0.93      0.71      0.80      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.88      0.84      0.85      3020\n",
      "weighted avg       0.87      0.86      0.85      3020\n",
      "\n",
      "acc:  0.8559602649006622\n",
      "pre:  0.934375\n",
      "rec:  0.706855791962175\n",
      "ma F1:  0.8453509762948015\n",
      "mi F1:  0.8559602649006622\n",
      "we F1:  0.8518158019686636\n",
      "Eval Loss:  0.19507130980491638\n",
      "Eval Loss:  0.21491959691047668\n",
      "Eval Loss:  0.29316768050193787\n",
      "Eval Loss:  0.16629986464977264\n",
      "Eval Loss:  0.2667512595653534\n",
      "Eval Loss:  0.2415441870689392\n",
      "Eval Loss:  0.21703453361988068\n",
      "Eval Loss:  0.22864732146263123\n",
      "Eval Loss:  0.25526899099349976\n",
      "Eval Loss:  0.27187180519104004\n",
      "Eval Loss:  0.15049625933170319\n",
      "Eval Loss:  0.37712857127189636\n",
      "Eval Loss:  0.12484651058912277\n",
      "Eval Loss:  0.189173623919487\n",
      "Eval Loss:  0.3656894564628601\n",
      "Eval Loss:  0.3212782144546509\n",
      "Eval Loss:  0.25946807861328125\n",
      "Eval Loss:  0.3156874477863312\n",
      "Eval Loss:  0.2772485613822937\n",
      "Eval Loss:  0.19445201754570007\n",
      "Eval Loss:  0.18931476771831512\n",
      "Eval Loss:  0.22658120095729828\n",
      "Eval Loss:  0.33743229508399963\n",
      "Eval Loss:  0.2995080053806305\n",
      "Eval Loss:  0.15899115800857544\n",
      "Eval Loss:  0.18178512156009674\n",
      "Eval Loss:  0.20563721656799316\n",
      "Eval Loss:  0.25577402114868164\n",
      "Eval Loss:  0.2711098790168762\n",
      "[[17704   709]\n",
      " [ 2009  9449]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18413\n",
      "           1       0.93      0.82      0.87     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.89      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9090087375715576\n",
      "pre:  0.93020279582595\n",
      "rec:  0.8246639902251702\n",
      "ma F1:  0.9014849370855832\n",
      "mi F1:  0.9090087375715576\n",
      "we F1:  0.9078238871013254\n",
      "29871 467\n",
      "Loss:  0.06747465580701828\n",
      "Loss:  0.06117963790893555\n",
      "Loss:  0.032584138214588165\n",
      "48 **********\n",
      "Epoch:  2950.5129277706146  fold:  10  kers:  64\n",
      "epoch:  49\n",
      "29871 467\n",
      "Loss:  0.06604726612567902\n",
      "Loss:  0.05360909923911095\n",
      "Loss:  0.07553069293498993\n",
      "49 **********\n",
      "Epoch:  2997.2120633125305  fold:  10  kers:  64\n",
      "epoch:  50\n",
      "29871 467\n",
      "Loss:  0.07180777937173843\n",
      "Loss:  0.08481281995773315\n",
      "Loss:  0.09203919023275375\n",
      "50 **********\n",
      "Epoch:  3043.941119670868  fold:  10  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.6032959818840027\n",
      "Eval Loss:  0.146071195602417\n",
      "Eval Loss:  0.012966963462531567\n",
      "[[1659   92]\n",
      " [ 197 1072]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1751\n",
      "           1       0.92      0.84      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9043046357615894\n",
      "pre:  0.9209621993127147\n",
      "rec:  0.8447596532702916\n",
      "ma F1:  0.9005473099926378\n",
      "mi F1:  0.9043046357615894\n",
      "we F1:  0.9036325417143323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19548572599887848\n",
      "Eval Loss:  0.21576103568077087\n",
      "Eval Loss:  0.2823399603366852\n",
      "Eval Loss:  0.17035163938999176\n",
      "Eval Loss:  0.2625579535961151\n",
      "Eval Loss:  0.23008394241333008\n",
      "Eval Loss:  0.2113974392414093\n",
      "Eval Loss:  0.21546857059001923\n",
      "Eval Loss:  0.24708907306194305\n",
      "Eval Loss:  0.25767019391059875\n",
      "Eval Loss:  0.14296425879001617\n",
      "Eval Loss:  0.3126859962940216\n",
      "Eval Loss:  0.11365059018135071\n",
      "Eval Loss:  0.18157252669334412\n",
      "Eval Loss:  0.3166433274745941\n",
      "Eval Loss:  0.3203583359718323\n",
      "Eval Loss:  0.255505234003067\n",
      "Eval Loss:  0.29803773760795593\n",
      "Eval Loss:  0.2426605522632599\n",
      "Eval Loss:  0.15973995625972748\n",
      "Eval Loss:  0.15003390610218048\n",
      "Eval Loss:  0.2410503476858139\n",
      "Eval Loss:  0.29525256156921387\n",
      "Eval Loss:  0.256791889667511\n",
      "Eval Loss:  0.13892683386802673\n",
      "Eval Loss:  0.16463494300842285\n",
      "Eval Loss:  0.17785760760307312\n",
      "Eval Loss:  0.2593272626399994\n",
      "Eval Loss:  0.23375551402568817\n",
      "[[17428   985]\n",
      " [ 1515  9943]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18413\n",
      "           1       0.91      0.87      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9163067858458036\n",
      "pre:  0.9098645680819912\n",
      "rec:  0.8677779717228138\n",
      "ma F1:  0.9106997027793373\n",
      "mi F1:  0.9163067858458036\n",
      "we F1:  0.9159097579199216\n",
      "29871 467\n",
      "Loss:  0.07890158891677856\n",
      "Loss:  0.055062584578990936\n",
      "Loss:  0.0624607689678669\n",
      "51 **********\n",
      "Epoch:  3130.6582555770874  fold:  10  kers:  64\n",
      "epoch:  52\n",
      "29871 467\n",
      "Loss:  0.054723720997571945\n",
      "Loss:  0.0388791561126709\n",
      "Loss:  0.04123219475150108\n",
      "52 **********\n",
      "Epoch:  3177.390303850174  fold:  10  kers:  64\n",
      "epoch:  53\n",
      "29871 467\n",
      "Loss:  0.06719186902046204\n",
      "Loss:  0.04968327656388283\n",
      "Loss:  0.06787808239459991\n",
      "53 **********\n",
      "Epoch:  3224.110383749008  fold:  10  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.7383324503898621\n",
      "Eval Loss:  0.09596332162618637\n",
      "Eval Loss:  0.012520474381744862\n",
      "[[1677   74]\n",
      " [ 301  968]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      1751\n",
      "           1       0.93      0.76      0.84      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.89      0.86      0.87      3020\n",
      "weighted avg       0.88      0.88      0.87      3020\n",
      "\n",
      "acc:  0.8758278145695364\n",
      "pre:  0.9289827255278311\n",
      "rec:  0.7628053585500394\n",
      "ma F1:  0.8685847148183876\n",
      "mi F1:  0.8758278145695364\n",
      "we F1:  0.873508796736658\n",
      "Eval Loss:  0.17107471823692322\n",
      "Eval Loss:  0.19773676991462708\n",
      "Eval Loss:  0.27689263224601746\n",
      "Eval Loss:  0.14379572868347168\n",
      "Eval Loss:  0.2609224319458008\n",
      "Eval Loss:  0.20587311685085297\n",
      "Eval Loss:  0.2023056298494339\n",
      "Eval Loss:  0.20066441595554352\n",
      "Eval Loss:  0.22564788162708282\n",
      "Eval Loss:  0.2719343900680542\n",
      "Eval Loss:  0.14854992926120758\n",
      "Eval Loss:  0.35111480951309204\n",
      "Eval Loss:  0.1142887994647026\n",
      "Eval Loss:  0.16599583625793457\n",
      "Eval Loss:  0.313346266746521\n",
      "Eval Loss:  0.28607508540153503\n",
      "Eval Loss:  0.23150396347045898\n",
      "Eval Loss:  0.2861946225166321\n",
      "Eval Loss:  0.2815997898578644\n",
      "Eval Loss:  0.18125711381435394\n",
      "Eval Loss:  0.1771032065153122\n",
      "Eval Loss:  0.24636128544807434\n",
      "Eval Loss:  0.30237773060798645\n",
      "Eval Loss:  0.2645660936832428\n",
      "Eval Loss:  0.12876802682876587\n",
      "Eval Loss:  0.17510490119457245\n",
      "Eval Loss:  0.18102560937404633\n",
      "Eval Loss:  0.24570916593074799\n",
      "Eval Loss:  0.26142966747283936\n",
      "[[17692   721]\n",
      " [ 1834  9624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18413\n",
      "           1       0.93      0.84      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.92      0.90      0.91     29871\n",
      "weighted avg       0.92      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9144655351344113\n",
      "pre:  0.9303044949250846\n",
      "rec:  0.8399371618083435\n",
      "ma F1:  0.9077346715706671\n",
      "mi F1:  0.9144655351344113\n",
      "we F1:  0.9135369963210191\n",
      "29871 467\n",
      "Loss:  0.0533253476023674\n",
      "Loss:  0.061982251703739166\n",
      "Loss:  0.1302022933959961\n",
      "54 **********\n",
      "Epoch:  3310.788623571396  fold:  10  kers:  64\n",
      "epoch:  55\n",
      "29871 467\n",
      "Loss:  0.10364239662885666\n",
      "Loss:  0.07048451155424118\n",
      "Loss:  0.03292651101946831\n",
      "55 **********\n",
      "Epoch:  3357.4458718299866  fold:  10  kers:  64\n",
      "epoch:  56\n",
      "29871 467\n",
      "Loss:  0.04685143008828163\n",
      "Loss:  0.0480131097137928\n",
      "Loss:  0.05068657919764519\n",
      "56 **********\n",
      "Epoch:  3404.164954185486  fold:  10  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.8708033561706543\n",
      "Eval Loss:  0.13227877020835876\n",
      "Eval Loss:  0.012923362664878368\n",
      "[[1659   92]\n",
      " [ 324  945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      1751\n",
      "           1       0.91      0.74      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.87      0.85      0.85      3020\n",
      "weighted avg       0.87      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8622516556291391\n",
      "pre:  0.9112825458052073\n",
      "rec:  0.7446808510638298\n",
      "ma F1:  0.854096181870633\n",
      "mi F1:  0.8622516556291391\n",
      "we F1:  0.8596016977692322\n",
      "Eval Loss:  0.16097134351730347\n",
      "Eval Loss:  0.1894698590040207\n",
      "Eval Loss:  0.27742522954940796\n",
      "Eval Loss:  0.15356165170669556\n",
      "Eval Loss:  0.25411468744277954\n",
      "Eval Loss:  0.22957223653793335\n",
      "Eval Loss:  0.21324537694454193\n",
      "Eval Loss:  0.18730096518993378\n",
      "Eval Loss:  0.22415563464164734\n",
      "Eval Loss:  0.226872518658638\n",
      "Eval Loss:  0.11121383309364319\n",
      "Eval Loss:  0.31421804428100586\n",
      "Eval Loss:  0.10506942868232727\n",
      "Eval Loss:  0.17290237545967102\n",
      "Eval Loss:  0.3011757731437683\n",
      "Eval Loss:  0.29042747616767883\n",
      "Eval Loss:  0.2377009242773056\n",
      "Eval Loss:  0.28516536951065063\n",
      "Eval Loss:  0.24939049780368805\n",
      "Eval Loss:  0.15497693419456482\n",
      "Eval Loss:  0.16471463441848755\n",
      "Eval Loss:  0.2242618054151535\n",
      "Eval Loss:  0.3155243992805481\n",
      "Eval Loss:  0.2172267735004425\n",
      "Eval Loss:  0.13445232808589935\n",
      "Eval Loss:  0.15080490708351135\n",
      "Eval Loss:  0.1802731305360794\n",
      "Eval Loss:  0.23404690623283386\n",
      "Eval Loss:  0.22825688123703003\n",
      "[[17510   903]\n",
      " [ 1421 10037]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18413\n",
      "           1       0.92      0.88      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.91      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9221987881222591\n",
      "pre:  0.9174588665447898\n",
      "rec:  0.8759818467446325\n",
      "ma F1:  0.9170042582070423\n",
      "mi F1:  0.9221987881222591\n",
      "we F1:  0.9218387230217528\n",
      "29871 467\n",
      "Loss:  0.045785170048475266\n",
      "Loss:  0.059611354023218155\n",
      "Loss:  0.042288150638341904\n",
      "57 **********\n",
      "Epoch:  3490.8601489067078  fold:  10  kers:  64\n",
      "epoch:  58\n",
      "29871 467\n",
      "Loss:  0.0587259978055954\n",
      "Loss:  0.07204076647758484\n",
      "Loss:  0.06046566367149353\n",
      "58 **********\n",
      "Epoch:  3537.592196702957  fold:  10  kers:  64\n",
      "epoch:  59\n",
      "29871 467\n",
      "Loss:  0.06577914208173752\n",
      "Loss:  0.04665043205022812\n",
      "Loss:  0.046153247356414795\n",
      "59 **********\n",
      "Epoch:  3584.3581540584564  fold:  10  kers:  64\n",
      "Eval Loss:  0.5919293761253357\n",
      "Eval Loss:  0.15750902891159058\n",
      "Eval Loss:  0.0170044656842947\n",
      "[[1666   85]\n",
      " [ 225 1044]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1751\n",
      "           1       0.92      0.82      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.89      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8973509933774835\n",
      "pre:  0.9247121346324181\n",
      "rec:  0.8226950354609929\n",
      "ma F1:  0.8928037688372015\n",
      "mi F1:  0.8973509933774835\n",
      "we F1:  0.8963275023234006\n",
      "update!  Acc:  0.9122516556291391\n",
      "Epoch:  3588.0103890895844  fold:  10  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "  \n",
      "kernel: 32\n",
      "  \n",
      "*********\n",
      "29459 3432\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29459 461\n",
      "Loss:  0.16888916492462158\n",
      "Loss:  0.1631631702184677\n",
      "Loss:  0.15524300932884216\n",
      "0 **********\n",
      "Epoch:  53.65254354476929  fold:  1  kers:  32\n",
      "epoch:  1\n",
      "29459 461\n",
      "Loss:  0.16406859457492828\n",
      "Loss:  0.12794677913188934\n",
      "Loss:  0.17403219640254974\n",
      "1 **********\n",
      "Epoch:  95.10171675682068  fold:  1  kers:  32\n",
      "epoch:  2\n",
      "29459 461\n",
      "Loss:  0.10998481512069702\n",
      "Loss:  0.09889017790555954\n",
      "Loss:  0.12096758186817169\n",
      "2 **********\n",
      "Epoch:  136.4322075843811  fold:  1  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.38574936985969543\n",
      "Eval Loss:  0.5305024981498718\n",
      "Eval Loss:  0.26517727971076965\n",
      "[[ 790  249]\n",
      " [ 621 1772]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.76      0.64      1039\n",
      "           1       0.88      0.74      0.80      2393\n",
      "\n",
      "    accuracy                           0.75      3432\n",
      "   macro avg       0.72      0.75      0.72      3432\n",
      "weighted avg       0.78      0.75      0.76      3432\n",
      "\n",
      "acc:  0.7465034965034965\n",
      "pre:  0.8767936665017318\n",
      "rec:  0.7404931048892603\n",
      "ma F1:  0.7238989116262726\n",
      "mi F1:  0.7465034965034966\n",
      "we F1:  0.7550665368032188\n",
      "update!  Acc:  0.7465034965034965\n",
      "Eval Loss:  0.38979610800743103\n",
      "Eval Loss:  0.3458024263381958\n",
      "Eval Loss:  0.31368082761764526\n",
      "Eval Loss:  0.4278333783149719\n",
      "Eval Loss:  0.327379047870636\n",
      "Eval Loss:  0.4030226767063141\n",
      "Eval Loss:  0.441829115152359\n",
      "Eval Loss:  0.3898778259754181\n",
      "Eval Loss:  0.44288793206214905\n",
      "Eval Loss:  0.456557959318161\n",
      "Eval Loss:  0.3421444892883301\n",
      "Eval Loss:  0.4549490511417389\n",
      "Eval Loss:  0.465612530708313\n",
      "Eval Loss:  0.39702892303466797\n",
      "Eval Loss:  0.3284408450126648\n",
      "Eval Loss:  0.45118167996406555\n",
      "Eval Loss:  0.4047858417034149\n",
      "Eval Loss:  0.499182790517807\n",
      "Eval Loss:  0.45532459020614624\n",
      "Eval Loss:  0.44215700030326843\n",
      "Eval Loss:  0.4114169478416443\n",
      "Eval Loss:  0.39285412430763245\n",
      "Eval Loss:  0.3710426986217499\n",
      "Eval Loss:  0.41064026951789856\n",
      "Eval Loss:  0.40884438157081604\n",
      "Eval Loss:  0.4347647428512573\n",
      "Eval Loss:  0.3138186037540436\n",
      "Eval Loss:  0.46818193793296814\n",
      "[[16387  2738]\n",
      " [ 2668  7666]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86     19125\n",
      "           1       0.74      0.74      0.74     10334\n",
      "\n",
      "    accuracy                           0.82     29459\n",
      "   macro avg       0.80      0.80      0.80     29459\n",
      "weighted avg       0.82      0.82      0.82     29459\n",
      "\n",
      "acc:  0.8164907159102481\n",
      "pre:  0.7368319876970396\n",
      "rec:  0.7418231081865686\n",
      "ma F1:  0.7988633337645996\n",
      "mi F1:  0.8164907159102481\n",
      "we F1:  0.8166322038990332\n",
      "29459 461\n",
      "Loss:  0.12043175101280212\n",
      "Loss:  0.1237378641963005\n",
      "Loss:  0.08693063259124756\n",
      "3 **********\n",
      "Epoch:  216.48316764831543  fold:  1  kers:  32\n",
      "epoch:  4\n",
      "29459 461\n",
      "Loss:  0.11949903517961502\n",
      "Loss:  0.07421527057886124\n",
      "Loss:  0.07206026464700699\n",
      "4 **********\n",
      "Epoch:  257.7697756290436  fold:  1  kers:  32\n",
      "epoch:  5\n",
      "29459 461\n",
      "Loss:  0.08846084773540497\n",
      "Loss:  0.06627952307462692\n",
      "Loss:  0.09257780760526657\n",
      "5 **********\n",
      "Epoch:  299.2787892818451  fold:  1  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.47004079818725586\n",
      "Eval Loss:  0.5909412503242493\n",
      "Eval Loss:  0.15054838359355927\n",
      "[[ 847  192]\n",
      " [ 724 1669]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.82      0.65      1039\n",
      "           1       0.90      0.70      0.78      2393\n",
      "\n",
      "    accuracy                           0.73      3432\n",
      "   macro avg       0.72      0.76      0.72      3432\n",
      "weighted avg       0.79      0.73      0.74      3432\n",
      "\n",
      "acc:  0.7331002331002331\n",
      "pre:  0.8968296614723267\n",
      "rec:  0.6974508984538237\n",
      "ma F1:  0.7168576971504845\n",
      "mi F1:  0.7331002331002331\n",
      "we F1:  0.7436124339825523\n",
      "Eval Loss:  0.40002819895744324\n",
      "Eval Loss:  0.30553001165390015\n",
      "Eval Loss:  0.2649230360984802\n",
      "Eval Loss:  0.4200928211212158\n",
      "Eval Loss:  0.3186628222465515\n",
      "Eval Loss:  0.39523279666900635\n",
      "Eval Loss:  0.3960812985897064\n",
      "Eval Loss:  0.3801383078098297\n",
      "Eval Loss:  0.3761359751224518\n",
      "Eval Loss:  0.4071909189224243\n",
      "Eval Loss:  0.2887844145298004\n",
      "Eval Loss:  0.3543616533279419\n",
      "Eval Loss:  0.41145676374435425\n",
      "Eval Loss:  0.41458776593208313\n",
      "Eval Loss:  0.2330031543970108\n",
      "Eval Loss:  0.48444873094558716\n",
      "Eval Loss:  0.3690759837627411\n",
      "Eval Loss:  0.45867830514907837\n",
      "Eval Loss:  0.43414726853370667\n",
      "Eval Loss:  0.41402170062065125\n",
      "Eval Loss:  0.3865993022918701\n",
      "Eval Loss:  0.3552744686603546\n",
      "Eval Loss:  0.3349931538105011\n",
      "Eval Loss:  0.3947848081588745\n",
      "Eval Loss:  0.37738701701164246\n",
      "Eval Loss:  0.4275696277618408\n",
      "Eval Loss:  0.30973348021507263\n",
      "Eval Loss:  0.417010098695755\n",
      "[[17932  1193]\n",
      " [ 3381  6953]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     19125\n",
      "           1       0.85      0.67      0.75     10334\n",
      "\n",
      "    accuracy                           0.84     29459\n",
      "   macro avg       0.85      0.81      0.82     29459\n",
      "weighted avg       0.85      0.84      0.84     29459\n",
      "\n",
      "acc:  0.8447333582266879\n",
      "pre:  0.8535477534986496\n",
      "rec:  0.6728275595122896\n",
      "ma F1:  0.8196888738229804\n",
      "mi F1:  0.8447333582266879\n",
      "we F1:  0.8397422541302028\n",
      "29459 461\n",
      "Loss:  0.06691611558198929\n",
      "Loss:  0.1092149093747139\n",
      "Loss:  0.0718197152018547\n",
      "6 **********\n",
      "Epoch:  380.05281591415405  fold:  1  kers:  32\n",
      "epoch:  7\n",
      "29459 461\n",
      "Loss:  0.07394339144229889\n",
      "Loss:  0.0992327407002449\n",
      "Loss:  0.07050575315952301\n",
      "7 **********\n",
      "Epoch:  421.42419695854187  fold:  1  kers:  32\n",
      "epoch:  8\n",
      "29459 461\n",
      "Loss:  0.07836693525314331\n",
      "Loss:  0.09560012817382812\n",
      "Loss:  0.0927143543958664\n",
      "8 **********\n",
      "Epoch:  462.941189289093  fold:  1  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.4744393527507782\n",
      "Eval Loss:  0.7857760787010193\n",
      "Eval Loss:  0.1366213858127594\n",
      "[[ 904  135]\n",
      " [ 876 1517]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.87      0.64      1039\n",
      "           1       0.92      0.63      0.75      2393\n",
      "\n",
      "    accuracy                           0.71      3432\n",
      "   macro avg       0.71      0.75      0.70      3432\n",
      "weighted avg       0.79      0.71      0.72      3432\n",
      "\n",
      "acc:  0.7054195804195804\n",
      "pre:  0.9182808716707022\n",
      "rec:  0.6339323025491016\n",
      "ma F1:  0.695711994934602\n",
      "mi F1:  0.7054195804195804\n",
      "we F1:  0.7171541984364957\n",
      "Eval Loss:  0.42512598633766174\n",
      "Eval Loss:  0.3418799340724945\n",
      "Eval Loss:  0.2809329926967621\n",
      "Eval Loss:  0.41309013962745667\n",
      "Eval Loss:  0.36200714111328125\n",
      "Eval Loss:  0.4506603181362152\n",
      "Eval Loss:  0.42427968978881836\n",
      "Eval Loss:  0.38795414566993713\n",
      "Eval Loss:  0.39656174182891846\n",
      "Eval Loss:  0.4418353736400604\n",
      "Eval Loss:  0.30998101830482483\n",
      "Eval Loss:  0.384924054145813\n",
      "Eval Loss:  0.45587748289108276\n",
      "Eval Loss:  0.47474461793899536\n",
      "Eval Loss:  0.20689772069454193\n",
      "Eval Loss:  0.5161306262016296\n",
      "Eval Loss:  0.3683193325996399\n",
      "Eval Loss:  0.48409900069236755\n",
      "Eval Loss:  0.4918156862258911\n",
      "Eval Loss:  0.4731422960758209\n",
      "Eval Loss:  0.3991141617298126\n",
      "Eval Loss:  0.3951593041419983\n",
      "Eval Loss:  0.33406901359558105\n",
      "Eval Loss:  0.38867291808128357\n",
      "Eval Loss:  0.408827543258667\n",
      "Eval Loss:  0.4457954466342926\n",
      "Eval Loss:  0.3262816071510315\n",
      "Eval Loss:  0.4324934780597687\n",
      "[[18459   666]\n",
      " [ 4005  6329]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     19125\n",
      "           1       0.90      0.61      0.73     10334\n",
      "\n",
      "    accuracy                           0.84     29459\n",
      "   macro avg       0.86      0.79      0.81     29459\n",
      "weighted avg       0.85      0.84      0.83     29459\n",
      "\n",
      "acc:  0.8414406463220069\n",
      "pre:  0.9047891350964975\n",
      "rec:  0.6124443584284884\n",
      "ma F1:  0.8090692458209353\n",
      "mi F1:  0.841440646322007\n",
      "we F1:  0.8325298378905907\n",
      "29459 461\n",
      "Loss:  0.09239573031663895\n",
      "Loss:  0.08490967750549316\n",
      "Loss:  0.0733969509601593\n",
      "9 **********\n",
      "Epoch:  543.2773861885071  fold:  1  kers:  32\n",
      "epoch:  10\n",
      "29459 461\n",
      "Loss:  0.08280611783266068\n",
      "Loss:  0.09425473213195801\n",
      "Loss:  0.08352559059858322\n",
      "10 **********\n",
      "Epoch:  584.4223725795746  fold:  1  kers:  32\n",
      "epoch:  11\n",
      "29459 461\n",
      "Loss:  0.08054155111312866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0661291629076004\n",
      "Loss:  0.12098350375890732\n",
      "11 **********\n",
      "Epoch:  625.415765285492  fold:  1  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.5431379079818726\n",
      "Eval Loss:  0.6056039333343506\n",
      "Eval Loss:  0.10961399227380753\n",
      "[[ 879  160]\n",
      " [ 736 1657]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.85      0.66      1039\n",
      "           1       0.91      0.69      0.79      2393\n",
      "\n",
      "    accuracy                           0.74      3432\n",
      "   macro avg       0.73      0.77      0.72      3432\n",
      "weighted avg       0.80      0.74      0.75      3432\n",
      "\n",
      "acc:  0.7389277389277389\n",
      "pre:  0.9119427627958173\n",
      "rec:  0.6924362724613455\n",
      "ma F1:  0.7247848897464859\n",
      "mi F1:  0.738927738927739\n",
      "we F1:  0.7493985372932941\n",
      "Eval Loss:  0.38933447003364563\n",
      "Eval Loss:  0.3083855211734772\n",
      "Eval Loss:  0.2514030337333679\n",
      "Eval Loss:  0.3713875412940979\n",
      "Eval Loss:  0.30022647976875305\n",
      "Eval Loss:  0.38611871004104614\n",
      "Eval Loss:  0.3502621650695801\n",
      "Eval Loss:  0.33332815766334534\n",
      "Eval Loss:  0.3191203773021698\n",
      "Eval Loss:  0.379707008600235\n",
      "Eval Loss:  0.26854875683784485\n",
      "Eval Loss:  0.34106189012527466\n",
      "Eval Loss:  0.4008009135723114\n",
      "Eval Loss:  0.3794277310371399\n",
      "Eval Loss:  0.19819296896457672\n",
      "Eval Loss:  0.4604068994522095\n",
      "Eval Loss:  0.3399941623210907\n",
      "Eval Loss:  0.3824911117553711\n",
      "Eval Loss:  0.41546016931533813\n",
      "Eval Loss:  0.3800848126411438\n",
      "Eval Loss:  0.3530674874782562\n",
      "Eval Loss:  0.3427943289279938\n",
      "Eval Loss:  0.30014050006866455\n",
      "Eval Loss:  0.3096601963043213\n",
      "Eval Loss:  0.3338000476360321\n",
      "Eval Loss:  0.40816816687583923\n",
      "Eval Loss:  0.3034169673919678\n",
      "Eval Loss:  0.36283591389656067\n",
      "[[18286   839]\n",
      " [ 3372  6962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     19125\n",
      "           1       0.89      0.67      0.77     10334\n",
      "\n",
      "    accuracy                           0.86     29459\n",
      "   macro avg       0.87      0.81      0.83     29459\n",
      "weighted avg       0.86      0.86      0.85     29459\n",
      "\n",
      "acc:  0.857055568756577\n",
      "pre:  0.8924496859377002\n",
      "rec:  0.6736984710663828\n",
      "ma F1:  0.8322716353706495\n",
      "mi F1:  0.857055568756577\n",
      "we F1:  0.8515117941834089\n",
      "29459 461\n",
      "Loss:  0.10516870766878128\n",
      "Loss:  0.07110738009214401\n",
      "Loss:  0.06863338500261307\n",
      "12 **********\n",
      "Epoch:  705.4437863826752  fold:  1  kers:  32\n",
      "epoch:  13\n",
      "29459 461\n",
      "Loss:  0.08664406090974808\n",
      "Loss:  0.06732859462499619\n",
      "Loss:  0.06231550872325897\n",
      "13 **********\n",
      "Epoch:  746.6805276870728  fold:  1  kers:  32\n",
      "epoch:  14\n",
      "29459 461\n",
      "Loss:  0.09817413985729218\n",
      "Loss:  0.09401820600032806\n",
      "Loss:  0.09625527262687683\n",
      "14 **********\n",
      "Epoch:  788.1875462532043  fold:  1  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.6857666969299316\n",
      "Eval Loss:  0.35973310470581055\n",
      "Eval Loss:  0.08513201773166656\n",
      "[[ 814  225]\n",
      " [ 474 1919]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.70      1039\n",
      "           1       0.90      0.80      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.79      0.77      3432\n",
      "weighted avg       0.82      0.80      0.80      3432\n",
      "\n",
      "acc:  0.7963286713286714\n",
      "pre:  0.8950559701492538\n",
      "rec:  0.8019222732971166\n",
      "ma F1:  0.7727733360587005\n",
      "mi F1:  0.7963286713286712\n",
      "we F1:  0.8016366156564748\n",
      "update!  Acc:  0.7963286713286714\n",
      "Eval Loss:  0.3859899640083313\n",
      "Eval Loss:  0.2680470943450928\n",
      "Eval Loss:  0.2457675337791443\n",
      "Eval Loss:  0.3755934238433838\n",
      "Eval Loss:  0.24726352095603943\n",
      "Eval Loss:  0.3478137254714966\n",
      "Eval Loss:  0.32654616236686707\n",
      "Eval Loss:  0.2870674729347229\n",
      "Eval Loss:  0.2513015866279602\n",
      "Eval Loss:  0.339151531457901\n",
      "Eval Loss:  0.24318385124206543\n",
      "Eval Loss:  0.3115368187427521\n",
      "Eval Loss:  0.35442763566970825\n",
      "Eval Loss:  0.30813080072402954\n",
      "Eval Loss:  0.21339857578277588\n",
      "Eval Loss:  0.425883948802948\n",
      "Eval Loss:  0.3226701617240906\n",
      "Eval Loss:  0.31877318024635315\n",
      "Eval Loss:  0.3585534989833832\n",
      "Eval Loss:  0.29066553711891174\n",
      "Eval Loss:  0.30747124552726746\n",
      "Eval Loss:  0.31863558292388916\n",
      "Eval Loss:  0.28064876794815063\n",
      "Eval Loss:  0.24058452248573303\n",
      "Eval Loss:  0.2811586260795593\n",
      "Eval Loss:  0.3887555003166199\n",
      "Eval Loss:  0.294118195772171\n",
      "Eval Loss:  0.3077041804790497\n",
      "[[17802  1323]\n",
      " [ 2435  7899]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     19125\n",
      "           1       0.86      0.76      0.81     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.87      0.85      0.86     29459\n",
      "weighted avg       0.87      0.87      0.87     29459\n",
      "\n",
      "acc:  0.8724328728062731\n",
      "pre:  0.8565387117761873\n",
      "rec:  0.7643700406425392\n",
      "ma F1:  0.8561805609244499\n",
      "mi F1:  0.8724328728062731\n",
      "we F1:  0.8706079136209164\n",
      "29459 461\n",
      "Loss:  0.06717158854007721\n",
      "Loss:  0.08762364089488983\n",
      "Loss:  0.05439452826976776\n",
      "15 **********\n",
      "Epoch:  868.712239742279  fold:  1  kers:  32\n",
      "epoch:  16\n",
      "29459 461\n",
      "Loss:  0.08921642601490021\n",
      "Loss:  0.0894603580236435\n",
      "Loss:  0.10858873277902603\n",
      "16 **********\n",
      "Epoch:  910.0596849918365  fold:  1  kers:  32\n",
      "epoch:  17\n",
      "29459 461\n",
      "Loss:  0.08037056773900986\n",
      "Loss:  0.06316613405942917\n",
      "Loss:  0.0567697249352932\n",
      "17 **********\n",
      "Epoch:  951.3203625679016  fold:  1  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.5443150997161865\n",
      "Eval Loss:  0.6357541680335999\n",
      "Eval Loss:  0.09315615147352219\n",
      "[[ 906  133]\n",
      " [ 817 1576]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.87      0.66      1039\n",
      "           1       0.92      0.66      0.77      2393\n",
      "\n",
      "    accuracy                           0.72      3432\n",
      "   macro avg       0.72      0.77      0.71      3432\n",
      "weighted avg       0.80      0.72      0.73      3432\n",
      "\n",
      "acc:  0.7231934731934732\n",
      "pre:  0.9221767115272089\n",
      "rec:  0.6585875470121186\n",
      "ma F1:  0.7122259995036067\n",
      "mi F1:  0.7231934731934732\n",
      "we F1:  0.7343901179753668\n",
      "Eval Loss:  0.4165707230567932\n",
      "Eval Loss:  0.3267258107662201\n",
      "Eval Loss:  0.24686118960380554\n",
      "Eval Loss:  0.37201499938964844\n",
      "Eval Loss:  0.3215073347091675\n",
      "Eval Loss:  0.4124465584754944\n",
      "Eval Loss:  0.35566192865371704\n",
      "Eval Loss:  0.3383355140686035\n",
      "Eval Loss:  0.3187449276447296\n",
      "Eval Loss:  0.4144497215747833\n",
      "Eval Loss:  0.27198290824890137\n",
      "Eval Loss:  0.34846609830856323\n",
      "Eval Loss:  0.43312200903892517\n",
      "Eval Loss:  0.4061066210269928\n",
      "Eval Loss:  0.17959696054458618\n",
      "Eval Loss:  0.46810004115104675\n",
      "Eval Loss:  0.3417568802833557\n",
      "Eval Loss:  0.42394599318504333\n",
      "Eval Loss:  0.4516812860965729\n",
      "Eval Loss:  0.4301067888736725\n",
      "Eval Loss:  0.3571263253688812\n",
      "Eval Loss:  0.3552747964859009\n",
      "Eval Loss:  0.3083411455154419\n",
      "Eval Loss:  0.30594682693481445\n",
      "Eval Loss:  0.36420702934265137\n",
      "Eval Loss:  0.42275094985961914\n",
      "Eval Loss:  0.30176109075546265\n",
      "Eval Loss:  0.3881381154060364\n",
      "[[18478   647]\n",
      " [ 3557  6777]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     19125\n",
      "           1       0.91      0.66      0.76     10334\n",
      "\n",
      "    accuracy                           0.86     29459\n",
      "   macro avg       0.88      0.81      0.83     29459\n",
      "weighted avg       0.86      0.86      0.85     29459\n",
      "\n",
      "acc:  0.8572931871414509\n",
      "pre:  0.9128502155172413\n",
      "rec:  0.6557964002322431\n",
      "ma F1:  0.8305618152527048\n",
      "mi F1:  0.8572931871414509\n",
      "we F1:  0.8506451833643162\n",
      "29459 461\n",
      "Loss:  0.07816893607378006\n",
      "Loss:  0.0722942054271698\n",
      "Loss:  0.0640607550740242\n",
      "18 **********\n",
      "Epoch:  1031.9278345108032  fold:  1  kers:  32\n",
      "epoch:  19\n",
      "29459 461\n",
      "Loss:  0.10389716923236847\n",
      "Loss:  0.09386252611875534\n",
      "Loss:  0.08375566452741623\n",
      "19 **********\n",
      "Epoch:  1073.2204265594482  fold:  1  kers:  32\n",
      "epoch:  20\n",
      "29459 461\n",
      "Loss:  0.06536050140857697\n",
      "Loss:  0.06313643604516983\n",
      "Loss:  0.060135774314403534\n",
      "20 **********\n",
      "Epoch:  1114.395332813263  fold:  1  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.6788195371627808\n",
      "Eval Loss:  0.6046776175498962\n",
      "Eval Loss:  0.08558744192123413\n",
      "[[ 878  161]\n",
      " [ 705 1688]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.85      0.67      1039\n",
      "           1       0.91      0.71      0.80      2393\n",
      "\n",
      "    accuracy                           0.75      3432\n",
      "   macro avg       0.73      0.78      0.73      3432\n",
      "weighted avg       0.80      0.75      0.76      3432\n",
      "\n",
      "acc:  0.7476689976689976\n",
      "pre:  0.9129259058950784\n",
      "rec:  0.705390722941914\n",
      "ma F1:  0.7327843931826985\n",
      "mi F1:  0.7476689976689976\n",
      "we F1:  0.7576655715462158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3760507106781006\n",
      "Eval Loss:  0.297394722700119\n",
      "Eval Loss:  0.21832089126110077\n",
      "Eval Loss:  0.33867427706718445\n",
      "Eval Loss:  0.26875510811805725\n",
      "Eval Loss:  0.3632810413837433\n",
      "Eval Loss:  0.31356653571128845\n",
      "Eval Loss:  0.3129763901233673\n",
      "Eval Loss:  0.2513965666294098\n",
      "Eval Loss:  0.34970253705978394\n",
      "Eval Loss:  0.2532345652580261\n",
      "Eval Loss:  0.3057517111301422\n",
      "Eval Loss:  0.37003931403160095\n",
      "Eval Loss:  0.32469043135643005\n",
      "Eval Loss:  0.17161668837070465\n",
      "Eval Loss:  0.41932836174964905\n",
      "Eval Loss:  0.316793829202652\n",
      "Eval Loss:  0.33050552010536194\n",
      "Eval Loss:  0.399507999420166\n",
      "Eval Loss:  0.37513870000839233\n",
      "Eval Loss:  0.30118101835250854\n",
      "Eval Loss:  0.3261043131351471\n",
      "Eval Loss:  0.2652098536491394\n",
      "Eval Loss:  0.25217726826667786\n",
      "Eval Loss:  0.3129238486289978\n",
      "Eval Loss:  0.3698321580886841\n",
      "Eval Loss:  0.2835485339164734\n",
      "Eval Loss:  0.3203723728656769\n",
      "[[18324   801]\n",
      " [ 2884  7450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     19125\n",
      "           1       0.90      0.72      0.80     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.88      0.84      0.86     29459\n",
      "weighted avg       0.88      0.87      0.87     29459\n",
      "\n",
      "acc:  0.8749108931056723\n",
      "pre:  0.9029208580778088\n",
      "rec:  0.7209212308883298\n",
      "ma F1:  0.8551787136148599\n",
      "mi F1:  0.8749108931056723\n",
      "we F1:  0.8711310393371086\n",
      "29459 461\n",
      "Loss:  0.06634555011987686\n",
      "Loss:  0.06756557524204254\n",
      "Loss:  0.1175401508808136\n",
      "21 **********\n",
      "Epoch:  1194.651743888855  fold:  1  kers:  32\n",
      "epoch:  22\n",
      "29459 461\n",
      "Loss:  0.057390667498111725\n",
      "Loss:  0.08905284106731415\n",
      "Loss:  0.08651752769947052\n",
      "22 **********\n",
      "Epoch:  1235.8565707206726  fold:  1  kers:  32\n",
      "epoch:  23\n",
      "29459 461\n",
      "Loss:  0.08660659939050674\n",
      "Loss:  0.086599200963974\n",
      "Loss:  0.05802399292588234\n",
      "23 **********\n",
      "Epoch:  1277.0783517360687  fold:  1  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.5419671535491943\n",
      "Eval Loss:  0.8096008896827698\n",
      "Eval Loss:  0.12324447184801102\n",
      "[[ 950   89]\n",
      " [ 901 1492]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.91      0.66      1039\n",
      "           1       0.94      0.62      0.75      2393\n",
      "\n",
      "    accuracy                           0.71      3432\n",
      "   macro avg       0.73      0.77      0.70      3432\n",
      "weighted avg       0.81      0.71      0.72      3432\n",
      "\n",
      "acc:  0.7115384615384616\n",
      "pre:  0.9437065148640101\n",
      "rec:  0.6234851650647723\n",
      "ma F1:  0.7041600855387005\n",
      "mi F1:  0.7115384615384616\n",
      "we F1:  0.7225924122982511\n",
      "Eval Loss:  0.417864054441452\n",
      "Eval Loss:  0.35072413086891174\n",
      "Eval Loss:  0.2593739330768585\n",
      "Eval Loss:  0.3451966345310211\n",
      "Eval Loss:  0.3351205885410309\n",
      "Eval Loss:  0.46306344866752625\n",
      "Eval Loss:  0.35051214694976807\n",
      "Eval Loss:  0.33886414766311646\n",
      "Eval Loss:  0.35851019620895386\n",
      "Eval Loss:  0.41761547327041626\n",
      "Eval Loss:  0.2945205271244049\n",
      "Eval Loss:  0.3666837215423584\n",
      "Eval Loss:  0.4412824511528015\n",
      "Eval Loss:  0.42999568581581116\n",
      "Eval Loss:  0.17908138036727905\n",
      "Eval Loss:  0.46185067296028137\n",
      "Eval Loss:  0.3228214681148529\n",
      "Eval Loss:  0.4598553776741028\n",
      "Eval Loss:  0.4492596685886383\n",
      "Eval Loss:  0.4530022442340851\n",
      "Eval Loss:  0.35801568627357483\n",
      "Eval Loss:  0.3524363338947296\n",
      "Eval Loss:  0.29765942692756653\n",
      "Eval Loss:  0.3162238299846649\n",
      "Eval Loss:  0.38400208950042725\n",
      "Eval Loss:  0.40868130326271057\n",
      "Eval Loss:  0.2789003849029541\n",
      "Eval Loss:  0.4028858244419098\n",
      "[[18669   456]\n",
      " [ 3806  6528]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90     19125\n",
      "           1       0.93      0.63      0.75     10334\n",
      "\n",
      "    accuracy                           0.86     29459\n",
      "   macro avg       0.88      0.80      0.83     29459\n",
      "weighted avg       0.87      0.86      0.85     29459\n",
      "\n",
      "acc:  0.8553243490953528\n",
      "pre:  0.9347079037800687\n",
      "rec:  0.6317011805689956\n",
      "ma F1:  0.825722877819432\n",
      "mi F1:  0.8553243490953528\n",
      "we F1:  0.8471565763604599\n",
      "29459 461\n",
      "Loss:  0.08534904569387436\n",
      "Loss:  0.0867386981844902\n",
      "Loss:  0.05065413936972618\n",
      "24 **********\n",
      "Epoch:  1357.632964849472  fold:  1  kers:  32\n",
      "epoch:  25\n",
      "29459 461\n",
      "Loss:  0.06900045275688171\n",
      "Loss:  0.06507416069507599\n",
      "Loss:  0.060390301048755646\n",
      "25 **********\n",
      "Epoch:  1398.8497595787048  fold:  1  kers:  32\n",
      "epoch:  26\n",
      "29459 461\n",
      "Loss:  0.06978622078895569\n",
      "Loss:  0.0759870633482933\n",
      "Loss:  0.050224669277668\n",
      "26 **********\n",
      "Epoch:  1440.0755302906036  fold:  1  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.868394672870636\n",
      "Eval Loss:  0.5236287713050842\n",
      "Eval Loss:  0.11692680418491364\n",
      "[[ 844  195]\n",
      " [ 605 1788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.81      0.68      1039\n",
      "           1       0.90      0.75      0.82      2393\n",
      "\n",
      "    accuracy                           0.77      3432\n",
      "   macro avg       0.74      0.78      0.75      3432\n",
      "weighted avg       0.81      0.77      0.78      3432\n",
      "\n",
      "acc:  0.7668997668997669\n",
      "pre:  0.9016641452344932\n",
      "rec:  0.7471792728792311\n",
      "ma F1:  0.7478206175749631\n",
      "mi F1:  0.7668997668997669\n",
      "we F1:  0.7751862618395651\n",
      "Eval Loss:  0.3398889899253845\n",
      "Eval Loss:  0.2673801779747009\n",
      "Eval Loss:  0.2011634111404419\n",
      "Eval Loss:  0.2976764440536499\n",
      "Eval Loss:  0.2525833547115326\n",
      "Eval Loss:  0.3316737115383148\n",
      "Eval Loss:  0.2699192762374878\n",
      "Eval Loss:  0.27300533652305603\n",
      "Eval Loss:  0.25083285570144653\n",
      "Eval Loss:  0.3120318353176117\n",
      "Eval Loss:  0.24211685359477997\n",
      "Eval Loss:  0.29106423258781433\n",
      "Eval Loss:  0.3388463854789734\n",
      "Eval Loss:  0.27484527230262756\n",
      "Eval Loss:  0.17042696475982666\n",
      "Eval Loss:  0.375013142824173\n",
      "Eval Loss:  0.29712849855422974\n",
      "Eval Loss:  0.3041444718837738\n",
      "Eval Loss:  0.32764193415641785\n",
      "Eval Loss:  0.30834099650382996\n",
      "Eval Loss:  0.2696708142757416\n",
      "Eval Loss:  0.29688823223114014\n",
      "Eval Loss:  0.24861308932304382\n",
      "Eval Loss:  0.21377050876617432\n",
      "Eval Loss:  0.2919785976409912\n",
      "Eval Loss:  0.3289329409599304\n",
      "Eval Loss:  0.26443442702293396\n",
      "Eval Loss:  0.3147079050540924\n",
      "[[18172   953]\n",
      " [ 2514  7820]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     19125\n",
      "           1       0.89      0.76      0.82     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.88      0.85      0.87     29459\n",
      "weighted avg       0.88      0.88      0.88     29459\n",
      "\n",
      "acc:  0.8823110085203164\n",
      "pre:  0.8913712527071698\n",
      "rec:  0.7567253725566092\n",
      "ma F1:  0.8657308462129766\n",
      "mi F1:  0.8823110085203164\n",
      "we F1:  0.8798108507380754\n",
      "29459 461\n",
      "Loss:  0.08179286122322083\n",
      "Loss:  0.07404520362615585\n",
      "Loss:  0.08106174319982529\n",
      "27 **********\n",
      "Epoch:  1526.6091568470001  fold:  1  kers:  32\n",
      "epoch:  28\n",
      "29459 461\n",
      "Loss:  0.07343385368585587\n",
      "Loss:  0.10670621693134308\n",
      "Loss:  0.08447092026472092\n",
      "28 **********\n",
      "Epoch:  1567.9017491340637  fold:  1  kers:  32\n",
      "epoch:  29\n",
      "29459 461\n",
      "Loss:  0.0736057236790657\n",
      "Loss:  0.07828281819820404\n",
      "Loss:  0.07695081830024719\n",
      "29 **********\n",
      "Epoch:  1609.0597009658813  fold:  1  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.685620129108429\n",
      "Eval Loss:  0.595709502696991\n",
      "Eval Loss:  0.07816027104854584\n",
      "[[ 887  152]\n",
      " [ 652 1741]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69      1039\n",
      "           1       0.92      0.73      0.81      2393\n",
      "\n",
      "    accuracy                           0.77      3432\n",
      "   macro avg       0.75      0.79      0.75      3432\n",
      "weighted avg       0.82      0.77      0.77      3432\n",
      "\n",
      "acc:  0.7657342657342657\n",
      "pre:  0.9197041732699419\n",
      "rec:  0.727538654408692\n",
      "ma F1:  0.7502714197124382\n",
      "mi F1:  0.7657342657342657\n",
      "we F1:  0.7747874542716356\n",
      "Eval Loss:  0.3512781262397766\n",
      "Eval Loss:  0.2661249339580536\n",
      "Eval Loss:  0.20629499852657318\n",
      "Eval Loss:  0.2938891649246216\n",
      "Eval Loss:  0.25061917304992676\n",
      "Eval Loss:  0.36639946699142456\n",
      "Eval Loss:  0.291667103767395\n",
      "Eval Loss:  0.24942032992839813\n",
      "Eval Loss:  0.2435215413570404\n",
      "Eval Loss:  0.3171311020851135\n",
      "Eval Loss:  0.23716062307357788\n",
      "Eval Loss:  0.2955613434314728\n",
      "Eval Loss:  0.3618432581424713\n",
      "Eval Loss:  0.29781341552734375\n",
      "Eval Loss:  0.15760788321495056\n",
      "Eval Loss:  0.38683345913887024\n",
      "Eval Loss:  0.27382731437683105\n",
      "Eval Loss:  0.3442951440811157\n",
      "Eval Loss:  0.3540031611919403\n",
      "Eval Loss:  0.3362499177455902\n",
      "Eval Loss:  0.28886017203330994\n",
      "Eval Loss:  0.3143128454685211\n",
      "Eval Loss:  0.25913745164871216\n",
      "Eval Loss:  0.23837262392044067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2793484628200531\n",
      "Eval Loss:  0.35404297709465027\n",
      "Eval Loss:  0.251167893409729\n",
      "Eval Loss:  0.3189544081687927\n",
      "[[18366   759]\n",
      " [ 2684  7650]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     19125\n",
      "           1       0.91      0.74      0.82     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.89      0.85      0.87     29459\n",
      "weighted avg       0.89      0.88      0.88     29459\n",
      "\n",
      "acc:  0.8831257001255983\n",
      "pre:  0.9097395647520514\n",
      "rec:  0.7402748209792916\n",
      "ma F1:  0.8653023457734945\n",
      "mi F1:  0.8831257001255983\n",
      "we F1:  0.8799239497403987\n",
      "29459 461\n",
      "Loss:  0.051721975207328796\n",
      "Loss:  0.057479556649923325\n",
      "Loss:  0.08728871494531631\n",
      "30 **********\n",
      "Epoch:  1689.470698595047  fold:  1  kers:  32\n",
      "epoch:  31\n",
      "29459 461\n",
      "Loss:  0.052650101482868195\n",
      "Loss:  0.09732477366924286\n",
      "Loss:  0.08255162090063095\n",
      "31 **********\n",
      "Epoch:  1730.6336369514465  fold:  1  kers:  32\n",
      "epoch:  32\n",
      "29459 461\n",
      "Loss:  0.08836319297552109\n",
      "Loss:  0.07739710062742233\n",
      "Loss:  0.0421021431684494\n",
      "32 **********\n",
      "Epoch:  1771.890324831009  fold:  1  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  1.1167855262756348\n",
      "Eval Loss:  0.35933059453964233\n",
      "Eval Loss:  0.0836833193898201\n",
      "[[ 777  262]\n",
      " [ 494 1899]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67      1039\n",
      "           1       0.88      0.79      0.83      2393\n",
      "\n",
      "    accuracy                           0.78      3432\n",
      "   macro avg       0.75      0.77      0.75      3432\n",
      "weighted avg       0.80      0.78      0.79      3432\n",
      "\n",
      "acc:  0.7797202797202797\n",
      "pre:  0.8787598334104582\n",
      "rec:  0.7935645633096532\n",
      "ma F1:  0.7533596837944665\n",
      "mi F1:  0.7797202797202797\n",
      "we F1:  0.7851709555266869\n",
      "Eval Loss:  0.3049320578575134\n",
      "Eval Loss:  0.2508714497089386\n",
      "Eval Loss:  0.19737470149993896\n",
      "Eval Loss:  0.2610952854156494\n",
      "Eval Loss:  0.20809897780418396\n",
      "Eval Loss:  0.3304741084575653\n",
      "Eval Loss:  0.28413498401641846\n",
      "Eval Loss:  0.24691303074359894\n",
      "Eval Loss:  0.19619831442832947\n",
      "Eval Loss:  0.2888442277908325\n",
      "Eval Loss:  0.21567928791046143\n",
      "Eval Loss:  0.2745501697063446\n",
      "Eval Loss:  0.34056657552719116\n",
      "Eval Loss:  0.23044836521148682\n",
      "Eval Loss:  0.16023513674736023\n",
      "Eval Loss:  0.3688836097717285\n",
      "Eval Loss:  0.2532528340816498\n",
      "Eval Loss:  0.3123242259025574\n",
      "Eval Loss:  0.30555811524391174\n",
      "Eval Loss:  0.3010006546974182\n",
      "Eval Loss:  0.26524481177330017\n",
      "Eval Loss:  0.28802958130836487\n",
      "Eval Loss:  0.24625131487846375\n",
      "Eval Loss:  0.2007172703742981\n",
      "Eval Loss:  0.2546711564064026\n",
      "Eval Loss:  0.3094562292098999\n",
      "Eval Loss:  0.25168943405151367\n",
      "Eval Loss:  0.2856440246105194\n",
      "[[18040  1085]\n",
      " [ 2050  8284]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     19125\n",
      "           1       0.88      0.80      0.84     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.89      0.87      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8935809090600496\n",
      "pre:  0.8841925498986017\n",
      "rec:  0.8016257015676408\n",
      "ma F1:  0.8804716377618576\n",
      "mi F1:  0.8935809090600496\n",
      "we F1:  0.8922842252959294\n",
      "29459 461\n",
      "Loss:  0.07833342999219894\n",
      "Loss:  0.05876120552420616\n",
      "Loss:  0.04475346952676773\n",
      "33 **********\n",
      "Epoch:  1855.2993063926697  fold:  1  kers:  32\n",
      "epoch:  34\n",
      "29459 461\n",
      "Loss:  0.08390116691589355\n",
      "Loss:  0.08046621829271317\n",
      "Loss:  0.0690605491399765\n",
      "34 **********\n",
      "Epoch:  1896.6038663387299  fold:  1  kers:  32\n",
      "epoch:  35\n",
      "29459 461\n",
      "Loss:  0.0708278939127922\n",
      "Loss:  0.0754573866724968\n",
      "Loss:  0.07229602336883545\n",
      "35 **********\n",
      "Epoch:  1937.7109541893005  fold:  1  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.975378155708313\n",
      "Eval Loss:  0.5119057893753052\n",
      "Eval Loss:  0.06495468318462372\n",
      "[[ 832  207]\n",
      " [ 636 1757]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.66      1039\n",
      "           1       0.89      0.73      0.81      2393\n",
      "\n",
      "    accuracy                           0.75      3432\n",
      "   macro avg       0.73      0.77      0.74      3432\n",
      "weighted avg       0.80      0.75      0.76      3432\n",
      "\n",
      "acc:  0.7543706293706294\n",
      "pre:  0.8946028513238289\n",
      "rec:  0.7342248223986627\n",
      "ma F1:  0.7351298851167156\n",
      "mi F1:  0.7543706293706294\n",
      "we F1:  0.7632941745435255\n",
      "Eval Loss:  0.32165661454200745\n",
      "Eval Loss:  0.25541242957115173\n",
      "Eval Loss:  0.20329749584197998\n",
      "Eval Loss:  0.2551014721393585\n",
      "Eval Loss:  0.23762039840221405\n",
      "Eval Loss:  0.34978875517845154\n",
      "Eval Loss:  0.29114437103271484\n",
      "Eval Loss:  0.24175947904586792\n",
      "Eval Loss:  0.22213521599769592\n",
      "Eval Loss:  0.3114849328994751\n",
      "Eval Loss:  0.21034245193004608\n",
      "Eval Loss:  0.27774807810783386\n",
      "Eval Loss:  0.3979067802429199\n",
      "Eval Loss:  0.27385246753692627\n",
      "Eval Loss:  0.1484520584344864\n",
      "Eval Loss:  0.39368048310279846\n",
      "Eval Loss:  0.2378954440355301\n",
      "Eval Loss:  0.34257882833480835\n",
      "Eval Loss:  0.34480708837509155\n",
      "Eval Loss:  0.3107663094997406\n",
      "Eval Loss:  0.2571465075016022\n",
      "Eval Loss:  0.3095513582229614\n",
      "Eval Loss:  0.2700527012348175\n",
      "Eval Loss:  0.2556694746017456\n",
      "Eval Loss:  0.2596192955970764\n",
      "Eval Loss:  0.30860355496406555\n",
      "Eval Loss:  0.23680074512958527\n",
      "Eval Loss:  0.2886890172958374\n",
      "[[18341   784]\n",
      " [ 2378  7956]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     19125\n",
      "           1       0.91      0.77      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.90      0.86      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8926643810041074\n",
      "pre:  0.9102974828375286\n",
      "rec:  0.7698858138184633\n",
      "ma F1:  0.8774325484362275\n",
      "mi F1:  0.8926643810041074\n",
      "we F1:  0.8903264377096248\n",
      "29459 461\n",
      "Loss:  0.10023598372936249\n",
      "Loss:  0.06978417932987213\n",
      "Loss:  0.052243422716856\n",
      "36 **********\n",
      "Epoch:  2020.866613149643  fold:  1  kers:  32\n",
      "epoch:  37\n",
      "29459 461\n",
      "Loss:  0.057408593595027924\n",
      "Loss:  0.06455078721046448\n",
      "Loss:  0.04867776110768318\n",
      "37 **********\n",
      "Epoch:  2062.2539517879486  fold:  1  kers:  32\n",
      "epoch:  38\n",
      "29459 461\n",
      "Loss:  0.04239782691001892\n",
      "Loss:  0.05886268988251686\n",
      "Loss:  0.08346445113420486\n",
      "38 **********\n",
      "Epoch:  2103.5076479911804  fold:  1  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  1.20980703830719\n",
      "Eval Loss:  0.28860485553741455\n",
      "Eval Loss:  0.06686970591545105\n",
      "[[ 727  312]\n",
      " [ 396 1997]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      1039\n",
      "           1       0.86      0.83      0.85      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.76      0.77      0.76      3432\n",
      "weighted avg       0.80      0.79      0.80      3432\n",
      "\n",
      "acc:  0.7937062937062938\n",
      "pre:  0.8648765699436985\n",
      "rec:  0.8345173422482239\n",
      "ma F1:  0.7609756078366872\n",
      "mi F1:  0.7937062937062938\n",
      "we F1:  0.7958711579685352\n",
      "Eval Loss:  0.2816382944583893\n",
      "Eval Loss:  0.2655240297317505\n",
      "Eval Loss:  0.2213183045387268\n",
      "Eval Loss:  0.24872903525829315\n",
      "Eval Loss:  0.2028837651014328\n",
      "Eval Loss:  0.3120017945766449\n",
      "Eval Loss:  0.28245580196380615\n",
      "Eval Loss:  0.21474193036556244\n",
      "Eval Loss:  0.2019621580839157\n",
      "Eval Loss:  0.2634766697883606\n",
      "Eval Loss:  0.19561541080474854\n",
      "Eval Loss:  0.2703135311603546\n",
      "Eval Loss:  0.3471747934818268\n",
      "Eval Loss:  0.2347889244556427\n",
      "Eval Loss:  0.16029714047908783\n",
      "Eval Loss:  0.3620896339416504\n",
      "Eval Loss:  0.22268278896808624\n",
      "Eval Loss:  0.31997236609458923\n",
      "Eval Loss:  0.3023800253868103\n",
      "Eval Loss:  0.2720889747142792\n",
      "Eval Loss:  0.23375293612480164\n",
      "Eval Loss:  0.2970779836177826\n",
      "Eval Loss:  0.24556367099285126\n",
      "Eval Loss:  0.21633882820606232\n",
      "Eval Loss:  0.22235150635242462\n",
      "Eval Loss:  0.29632529616355896\n",
      "Eval Loss:  0.2520069479942322\n",
      "Eval Loss:  0.26232221722602844\n",
      "[[18019  1106]\n",
      " [ 1864  8470]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     19125\n",
      "           1       0.88      0.82      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.8991819138463627\n",
      "pre:  0.8845029239766082\n",
      "rec:  0.8196245403522353\n",
      "ma F1:  0.8873452506129922\n",
      "mi F1:  0.8991819138463627\n",
      "we F1:  0.8982423190478608\n",
      "29459 461\n",
      "Loss:  0.046533141285181046\n",
      "Loss:  0.06440272182226181\n",
      "Loss:  0.07552097737789154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 **********\n",
      "Epoch:  2183.9894559383392  fold:  1  kers:  32\n",
      "epoch:  40\n",
      "29459 461\n",
      "Loss:  0.08279301971197128\n",
      "Loss:  0.07180146127939224\n",
      "Loss:  0.0759023055434227\n",
      "40 **********\n",
      "Epoch:  2225.1972744464874  fold:  1  kers:  32\n",
      "epoch:  41\n",
      "29459 461\n",
      "Loss:  0.06484287977218628\n",
      "Loss:  0.09830949455499649\n",
      "Loss:  0.05778810754418373\n",
      "41 **********\n",
      "Epoch:  2266.451967716217  fold:  1  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  1.0934982299804688\n",
      "Eval Loss:  0.3943730890750885\n",
      "Eval Loss:  0.0843258872628212\n",
      "[[ 786  253]\n",
      " [ 501 1892]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68      1039\n",
      "           1       0.88      0.79      0.83      2393\n",
      "\n",
      "    accuracy                           0.78      3432\n",
      "   macro avg       0.75      0.77      0.75      3432\n",
      "weighted avg       0.80      0.78      0.79      3432\n",
      "\n",
      "acc:  0.7803030303030303\n",
      "pre:  0.882051282051282\n",
      "rec:  0.790639364814041\n",
      "ma F1:  0.7548429295067125\n",
      "mi F1:  0.7803030303030304\n",
      "we F1:  0.7860119859969604\n",
      "Eval Loss:  0.30680039525032043\n",
      "Eval Loss:  0.2676396667957306\n",
      "Eval Loss:  0.23218129575252533\n",
      "Eval Loss:  0.24124157428741455\n",
      "Eval Loss:  0.23215365409851074\n",
      "Eval Loss:  0.343408465385437\n",
      "Eval Loss:  0.2960047125816345\n",
      "Eval Loss:  0.21056202054023743\n",
      "Eval Loss:  0.22424381971359253\n",
      "Eval Loss:  0.26072877645492554\n",
      "Eval Loss:  0.2125277817249298\n",
      "Eval Loss:  0.2690117359161377\n",
      "Eval Loss:  0.3845215439796448\n",
      "Eval Loss:  0.2643362283706665\n",
      "Eval Loss:  0.1539609134197235\n",
      "Eval Loss:  0.391838937997818\n",
      "Eval Loss:  0.20748473703861237\n",
      "Eval Loss:  0.3556521534919739\n",
      "Eval Loss:  0.3211424648761749\n",
      "Eval Loss:  0.28020864725112915\n",
      "Eval Loss:  0.2148316651582718\n",
      "Eval Loss:  0.30367156863212585\n",
      "Eval Loss:  0.2564401924610138\n",
      "Eval Loss:  0.23176215589046478\n",
      "Eval Loss:  0.23181237280368805\n",
      "Eval Loss:  0.2973424792289734\n",
      "Eval Loss:  0.2403186410665512\n",
      "Eval Loss:  0.261845201253891\n",
      "[[18288   837]\n",
      " [ 2102  8232]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     19125\n",
      "           1       0.91      0.80      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9002342238365185\n",
      "pre:  0.9077075752563678\n",
      "rec:  0.7965937681439907\n",
      "ma F1:  0.8870758795627098\n",
      "mi F1:  0.9002342238365185\n",
      "we F1:  0.8985789627479775\n",
      "29459 461\n",
      "Loss:  0.05708509311079979\n",
      "Loss:  0.0684460774064064\n",
      "Loss:  0.05935021862387657\n",
      "42 **********\n",
      "Epoch:  2346.885903596878  fold:  1  kers:  32\n",
      "epoch:  43\n",
      "29459 461\n",
      "Loss:  0.06741533428430557\n",
      "Loss:  0.051979776471853256\n",
      "Loss:  0.06204703450202942\n",
      "43 **********\n",
      "Epoch:  2388.266261100769  fold:  1  kers:  32\n",
      "epoch:  44\n",
      "29459 461\n",
      "Loss:  0.0885784700512886\n",
      "Loss:  0.059427689760923386\n",
      "Loss:  0.05060306191444397\n",
      "44 **********\n",
      "Epoch:  2429.531925201416  fold:  1  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.9791476726531982\n",
      "Eval Loss:  0.38177528977394104\n",
      "Eval Loss:  0.07551175355911255\n",
      "[[ 783  256]\n",
      " [ 489 1904]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68      1039\n",
      "           1       0.88      0.80      0.84      2393\n",
      "\n",
      "    accuracy                           0.78      3432\n",
      "   macro avg       0.75      0.77      0.76      3432\n",
      "weighted avg       0.80      0.78      0.79      3432\n",
      "\n",
      "acc:  0.7829254079254079\n",
      "pre:  0.8814814814814815\n",
      "rec:  0.795653990806519\n",
      "ma F1:  0.7570001776281143\n",
      "mi F1:  0.7829254079254079\n",
      "we F1:  0.7883139705117321\n",
      "Eval Loss:  0.28569236397743225\n",
      "Eval Loss:  0.2672940194606781\n",
      "Eval Loss:  0.22469402849674225\n",
      "Eval Loss:  0.2286870926618576\n",
      "Eval Loss:  0.2175232619047165\n",
      "Eval Loss:  0.33126795291900635\n",
      "Eval Loss:  0.2928031384944916\n",
      "Eval Loss:  0.1953631341457367\n",
      "Eval Loss:  0.21832752227783203\n",
      "Eval Loss:  0.2627655863761902\n",
      "Eval Loss:  0.197890967130661\n",
      "Eval Loss:  0.27685168385505676\n",
      "Eval Loss:  0.3624076247215271\n",
      "Eval Loss:  0.26864832639694214\n",
      "Eval Loss:  0.1517910212278366\n",
      "Eval Loss:  0.3550606667995453\n",
      "Eval Loss:  0.1950952559709549\n",
      "Eval Loss:  0.32631975412368774\n",
      "Eval Loss:  0.316752552986145\n",
      "Eval Loss:  0.2948923408985138\n",
      "Eval Loss:  0.18771804869174957\n",
      "Eval Loss:  0.30612072348594666\n",
      "Eval Loss:  0.23945540189743042\n",
      "Eval Loss:  0.24152705073356628\n",
      "Eval Loss:  0.218467116355896\n",
      "Eval Loss:  0.2954438328742981\n",
      "Eval Loss:  0.21951185166835785\n",
      "Eval Loss:  0.2583119571208954\n",
      "[[18159   966]\n",
      " [ 1956  8378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     19125\n",
      "           1       0.90      0.81      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9008112970569265\n",
      "pre:  0.8966181506849316\n",
      "rec:  0.8107218889103929\n",
      "ma F1:  0.8885222339606502\n",
      "mi F1:  0.9008112970569265\n",
      "we F1:  0.8995674393260898\n",
      "29459 461\n",
      "Loss:  0.056330740451812744\n",
      "Loss:  0.08132792264223099\n",
      "Loss:  0.08810633420944214\n",
      "45 **********\n",
      "Epoch:  2510.1463782787323  fold:  1  kers:  32\n",
      "epoch:  46\n",
      "29459 461\n",
      "Loss:  0.09977202117443085\n",
      "Loss:  0.032372523099184036\n",
      "Loss:  0.0701000764966011\n",
      "46 **********\n",
      "Epoch:  2551.402069091797  fold:  1  kers:  32\n",
      "epoch:  47\n",
      "29459 461\n",
      "Loss:  0.06907554715871811\n",
      "Loss:  0.047842688858509064\n",
      "Loss:  0.07149793207645416\n",
      "47 **********\n",
      "Epoch:  2592.696655511856  fold:  1  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  1.3660780191421509\n",
      "Eval Loss:  0.25034892559051514\n",
      "Eval Loss:  0.07474410533905029\n",
      "[[ 737  302]\n",
      " [ 327 2066]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      1039\n",
      "           1       0.87      0.86      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.78      0.79      0.78      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8167249417249417\n",
      "pre:  0.8724662162162162\n",
      "rec:  0.8633514417049728\n",
      "ma F1:  0.7843941846811093\n",
      "mi F1:  0.8167249417249417\n",
      "we F1:  0.8173331199989038\n",
      "update!  Acc:  0.8167249417249417\n",
      "Eval Loss:  0.29108726978302\n",
      "Eval Loss:  0.27449971437454224\n",
      "Eval Loss:  0.23326461017131805\n",
      "Eval Loss:  0.26809442043304443\n",
      "Eval Loss:  0.21852099895477295\n",
      "Eval Loss:  0.3230266273021698\n",
      "Eval Loss:  0.30132174491882324\n",
      "Eval Loss:  0.20046420395374298\n",
      "Eval Loss:  0.2227613776922226\n",
      "Eval Loss:  0.2599966526031494\n",
      "Eval Loss:  0.19156533479690552\n",
      "Eval Loss:  0.2635292112827301\n",
      "Eval Loss:  0.38494873046875\n",
      "Eval Loss:  0.27291300892829895\n",
      "Eval Loss:  0.1596890240907669\n",
      "Eval Loss:  0.4031068682670593\n",
      "Eval Loss:  0.19257117807865143\n",
      "Eval Loss:  0.369017094373703\n",
      "Eval Loss:  0.31079068779945374\n",
      "Eval Loss:  0.24796858429908752\n",
      "Eval Loss:  0.222427636384964\n",
      "Eval Loss:  0.2987339198589325\n",
      "Eval Loss:  0.2744196355342865\n",
      "Eval Loss:  0.2583308815956116\n",
      "Eval Loss:  0.22075991332530975\n",
      "Eval Loss:  0.31414681673049927\n",
      "Eval Loss:  0.2497551292181015\n",
      "Eval Loss:  0.25220051407814026\n",
      "[[18071  1054]\n",
      " [ 1842  8492]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     19125\n",
      "           1       0.89      0.82      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9016938796293154\n",
      "pre:  0.8895872616802849\n",
      "rec:  0.8217534352622411\n",
      "ma F1:  0.8900709137245729\n",
      "mi F1:  0.9016938796293154\n",
      "we F1:  0.90073773628106\n",
      "29459 461\n",
      "Loss:  0.055264756083488464\n",
      "Loss:  0.04725472629070282\n",
      "Loss:  0.032057587057352066\n",
      "48 **********\n",
      "Epoch:  2673.540495634079  fold:  1  kers:  32\n",
      "epoch:  49\n",
      "29459 461\n",
      "Loss:  0.07679907977581024\n",
      "Loss:  0.04978910833597183\n",
      "Loss:  0.06622574478387833\n",
      "49 **********\n",
      "Epoch:  2714.872981071472  fold:  1  kers:  32\n",
      "epoch:  50\n",
      "29459 461\n",
      "Loss:  0.030112789943814278\n",
      "Loss:  0.09030990302562714\n",
      "Loss:  0.06611117720603943\n",
      "50 **********\n",
      "Epoch:  2756.277274608612  fold:  1  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  1.0957894325256348\n",
      "Eval Loss:  0.3463439643383026\n",
      "Eval Loss:  0.07637359201908112\n",
      "[[ 783  256]\n",
      " [ 437 1956]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69      1039\n",
      "           1       0.88      0.82      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.79      0.77      3432\n",
      "weighted avg       0.81      0.80      0.80      3432\n",
      "\n",
      "acc:  0.7980769230769231\n",
      "pre:  0.8842676311030742\n",
      "rec:  0.8173840367739239\n",
      "ma F1:  0.7713692461424659\n",
      "mi F1:  0.7980769230769231\n",
      "we F1:  0.8021980565169374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2999522387981415\n",
      "Eval Loss:  0.26653480529785156\n",
      "Eval Loss:  0.22912287712097168\n",
      "Eval Loss:  0.2462732046842575\n",
      "Eval Loss:  0.2194596827030182\n",
      "Eval Loss:  0.3289782404899597\n",
      "Eval Loss:  0.29457908868789673\n",
      "Eval Loss:  0.1907748430967331\n",
      "Eval Loss:  0.21482323110103607\n",
      "Eval Loss:  0.2625410854816437\n",
      "Eval Loss:  0.20609663426876068\n",
      "Eval Loss:  0.2609752118587494\n",
      "Eval Loss:  0.37658748030662537\n",
      "Eval Loss:  0.2581849694252014\n",
      "Eval Loss:  0.15123684704303741\n",
      "Eval Loss:  0.3915177285671234\n",
      "Eval Loss:  0.18718750774860382\n",
      "Eval Loss:  0.3511122763156891\n",
      "Eval Loss:  0.2932293117046356\n",
      "Eval Loss:  0.2571936547756195\n",
      "Eval Loss:  0.19204828143119812\n",
      "Eval Loss:  0.31177836656570435\n",
      "Eval Loss:  0.2552923858165741\n",
      "Eval Loss:  0.23221763968467712\n",
      "Eval Loss:  0.2183927744626999\n",
      "Eval Loss:  0.3090292513370514\n",
      "Eval Loss:  0.2393968105316162\n",
      "Eval Loss:  0.24290531873703003\n",
      "[[18185   940]\n",
      " [ 1895  8439]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     19125\n",
      "           1       0.90      0.82      0.86     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9037645541260735\n",
      "pre:  0.8997760955325728\n",
      "rec:  0.8166247338881363\n",
      "ma F1:  0.8919370339709611\n",
      "mi F1:  0.9037645541260735\n",
      "we F1:  0.9026055882171743\n",
      "29459 461\n",
      "Loss:  0.058854177594184875\n",
      "Loss:  0.07031930983066559\n",
      "Loss:  0.06910812109708786\n",
      "51 **********\n",
      "Epoch:  2837.2378022670746  fold:  1  kers:  32\n",
      "epoch:  52\n",
      "29459 461\n",
      "Loss:  0.08122490346431732\n",
      "Loss:  0.03825250640511513\n",
      "Loss:  0.062447477132081985\n",
      "52 **********\n",
      "Epoch:  2878.658052921295  fold:  1  kers:  32\n",
      "epoch:  53\n",
      "29459 461\n",
      "Loss:  0.06839922070503235\n",
      "Loss:  0.07711054384708405\n",
      "Loss:  0.06504923105239868\n",
      "53 **********\n",
      "Epoch:  2920.0513756275177  fold:  1  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  1.1563142538070679\n",
      "Eval Loss:  0.27521729469299316\n",
      "Eval Loss:  0.0710042417049408\n",
      "[[ 712  327]\n",
      " [ 309 2084]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69      1039\n",
      "           1       0.86      0.87      0.87      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.78      0.78      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8146853146853147\n",
      "pre:  0.8643716300290336\n",
      "rec:  0.8708733806936899\n",
      "ma F1:  0.7794362303258612\n",
      "mi F1:  0.8146853146853147\n",
      "we F1:  0.8142228631412404\n",
      "Eval Loss:  0.27373993396759033\n",
      "Eval Loss:  0.2599613070487976\n",
      "Eval Loss:  0.22695618867874146\n",
      "Eval Loss:  0.24023079872131348\n",
      "Eval Loss:  0.20064488053321838\n",
      "Eval Loss:  0.31228771805763245\n",
      "Eval Loss:  0.2933731973171234\n",
      "Eval Loss:  0.19747228920459747\n",
      "Eval Loss:  0.19324441254138947\n",
      "Eval Loss:  0.26132985949516296\n",
      "Eval Loss:  0.18364746868610382\n",
      "Eval Loss:  0.2719514071941376\n",
      "Eval Loss:  0.3627244830131531\n",
      "Eval Loss:  0.24821525812149048\n",
      "Eval Loss:  0.15747393667697906\n",
      "Eval Loss:  0.3523705303668976\n",
      "Eval Loss:  0.19025704264640808\n",
      "Eval Loss:  0.32993319630622864\n",
      "Eval Loss:  0.2742340564727783\n",
      "Eval Loss:  0.24003762006759644\n",
      "Eval Loss:  0.2042984664440155\n",
      "Eval Loss:  0.28963226079940796\n",
      "Eval Loss:  0.24848031997680664\n",
      "Eval Loss:  0.21921488642692566\n",
      "Eval Loss:  0.20700609683990479\n",
      "Eval Loss:  0.305205762386322\n",
      "Eval Loss:  0.23995383083820343\n",
      "Eval Loss:  0.23123717308044434\n",
      "[[17936  1189]\n",
      " [ 1676  8658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     19125\n",
      "           1       0.88      0.84      0.86     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.89      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9027461896194712\n",
      "pre:  0.8792525642327612\n",
      "rec:  0.8378169150377395\n",
      "ma F1:  0.8920372444182534\n",
      "mi F1:  0.9027461896194712\n",
      "we F1:  0.9021840796482496\n",
      "29459 461\n",
      "Loss:  0.05185398459434509\n",
      "Loss:  0.06283090263605118\n",
      "Loss:  0.07087412476539612\n",
      "54 **********\n",
      "Epoch:  3001.029855489731  fold:  1  kers:  32\n",
      "epoch:  55\n",
      "29459 461\n",
      "Loss:  0.0721222311258316\n",
      "Loss:  0.06586811691522598\n",
      "Loss:  0.07131264358758926\n",
      "55 **********\n",
      "Epoch:  3042.3862767219543  fold:  1  kers:  32\n",
      "epoch:  56\n",
      "29459 461\n",
      "Loss:  0.07736846804618835\n",
      "Loss:  0.08173689991235733\n",
      "Loss:  0.06846541166305542\n",
      "56 **********\n",
      "Epoch:  3083.824479818344  fold:  1  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  1.0052844285964966\n",
      "Eval Loss:  0.3995499014854431\n",
      "Eval Loss:  0.06544283032417297\n",
      "[[ 820  219]\n",
      " [ 496 1897]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.70      1039\n",
      "           1       0.90      0.79      0.84      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.76      0.79      0.77      3432\n",
      "weighted avg       0.81      0.79      0.80      3432\n",
      "\n",
      "acc:  0.7916666666666666\n",
      "pre:  0.8965028355387523\n",
      "rec:  0.7927287923109068\n",
      "ma F1:  0.7689094563880023\n",
      "mi F1:  0.7916666666666666\n",
      "we F1:  0.7975197281775208\n",
      "Eval Loss:  0.3453996181488037\n",
      "Eval Loss:  0.2990487515926361\n",
      "Eval Loss:  0.2460605800151825\n",
      "Eval Loss:  0.28597375750541687\n",
      "Eval Loss:  0.2717703580856323\n",
      "Eval Loss:  0.3556572496891022\n",
      "Eval Loss:  0.28565284609794617\n",
      "Eval Loss:  0.20219726860523224\n",
      "Eval Loss:  0.22527675330638885\n",
      "Eval Loss:  0.28705117106437683\n",
      "Eval Loss:  0.2081562876701355\n",
      "Eval Loss:  0.28292545676231384\n",
      "Eval Loss:  0.42311668395996094\n",
      "Eval Loss:  0.30371618270874023\n",
      "Eval Loss:  0.14236104488372803\n",
      "Eval Loss:  0.42037585377693176\n",
      "Eval Loss:  0.173919215798378\n",
      "Eval Loss:  0.3964119553565979\n",
      "Eval Loss:  0.3216123580932617\n",
      "Eval Loss:  0.30062568187713623\n",
      "Eval Loss:  0.2166648507118225\n",
      "Eval Loss:  0.3135536015033722\n",
      "Eval Loss:  0.2794187366962433\n",
      "Eval Loss:  0.26977500319480896\n",
      "Eval Loss:  0.2302825152873993\n",
      "Eval Loss:  0.30612432956695557\n",
      "Eval Loss:  0.24464227259159088\n",
      "Eval Loss:  0.2691614329814911\n",
      "[[18377   748]\n",
      " [ 2214  8120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     19125\n",
      "           1       0.92      0.79      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.87      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.89945347771479\n",
      "pre:  0.9156517816869644\n",
      "rec:  0.7857557576930521\n",
      "ma F1:  0.8855828601590194\n",
      "mi F1:  0.8994534777147901\n",
      "we F1:  0.8974709949872128\n",
      "29459 461\n",
      "Loss:  0.04196815565228462\n",
      "Loss:  0.05085393041372299\n",
      "Loss:  0.07945338636636734\n",
      "57 **********\n",
      "Epoch:  3164.6563515663147  fold:  1  kers:  32\n",
      "epoch:  58\n",
      "29459 461\n",
      "Loss:  0.08027821034193039\n",
      "Loss:  0.08607345074415207\n",
      "Loss:  0.07484744489192963\n",
      "58 **********\n",
      "Epoch:  3206.012773036957  fold:  1  kers:  32\n",
      "epoch:  59\n",
      "29459 461\n",
      "Loss:  0.08693378418684006\n",
      "Loss:  0.04837794601917267\n",
      "Loss:  0.06783873587846756\n",
      "59 **********\n",
      "Epoch:  3247.3003783226013  fold:  1  kers:  32\n",
      "Eval Loss:  1.1773195266723633\n",
      "Eval Loss:  0.2842721939086914\n",
      "Eval Loss:  0.058378301560878754\n",
      "[[ 746  293]\n",
      " [ 312 2081]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71      1039\n",
      "           1       0.88      0.87      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.79      0.79      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8237179487179487\n",
      "pre:  0.8765796124684078\n",
      "rec:  0.8696197241955704\n",
      "ma F1:  0.7922892033421234\n",
      "mi F1:  0.8237179487179487\n",
      "we F1:  0.8241652492139342\n",
      "update!  Acc:  0.8237179487179487\n",
      "Epoch:  3251.424351453781  fold:  1  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29797 3094\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29797 466\n",
      "Loss:  0.16780012845993042\n",
      "Loss:  0.16621814668178558\n",
      "Loss:  0.16050569713115692\n",
      "0 **********\n",
      "Epoch:  54.23199439048767  fold:  2  kers:  32\n",
      "epoch:  1\n",
      "29797 466\n",
      "Loss:  0.13921968638896942\n",
      "Loss:  0.14302383363246918\n",
      "Loss:  0.12654513120651245\n",
      "1 **********\n",
      "Epoch:  96.19579243659973  fold:  2  kers:  32\n",
      "epoch:  2\n",
      "29797 466\n",
      "Loss:  0.11403615772724152\n",
      "Loss:  0.10887525230646133\n",
      "Loss:  0.10047423839569092\n",
      "2 **********\n",
      "Epoch:  138.08279490470886  fold:  2  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.8752854466438293\n",
      "Eval Loss:  0.2906520366668701\n",
      "Eval Loss:  0.5589473247528076\n",
      "[[1066  364]\n",
      " [ 489 1175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.71      1430\n",
      "           1       0.76      0.71      0.73      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.72      0.73      0.72      3094\n",
      "weighted avg       0.73      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7243051066580478\n",
      "pre:  0.7634827810266407\n",
      "rec:  0.7061298076923077\n",
      "ma F1:  0.7239625121130682\n",
      "mi F1:  0.7243051066580477\n",
      "we F1:  0.7246979903105474\n",
      "update!  Acc:  0.7243051066580478\n",
      "Eval Loss:  0.4517526924610138\n",
      "Eval Loss:  0.4588148891925812\n",
      "Eval Loss:  0.3577461838722229\n",
      "Eval Loss:  0.34741753339767456\n",
      "Eval Loss:  0.39151936769485474\n",
      "Eval Loss:  0.3662191331386566\n",
      "Eval Loss:  0.46312907338142395\n",
      "Eval Loss:  0.43829575181007385\n",
      "Eval Loss:  0.4467400312423706\n",
      "Eval Loss:  0.35164543986320496\n",
      "Eval Loss:  0.3507079482078552\n",
      "Eval Loss:  0.45316052436828613\n",
      "Eval Loss:  0.3824661076068878\n",
      "Eval Loss:  0.5223718881607056\n",
      "Eval Loss:  0.3823499083518982\n",
      "Eval Loss:  0.40086960792541504\n",
      "Eval Loss:  0.44065237045288086\n",
      "Eval Loss:  0.42903152108192444\n",
      "Eval Loss:  0.37824341654777527\n",
      "Eval Loss:  0.3489046096801758\n",
      "Eval Loss:  0.39389851689338684\n",
      "Eval Loss:  0.40551087260246277\n",
      "Eval Loss:  0.46584951877593994\n",
      "Eval Loss:  0.3840944170951843\n",
      "Eval Loss:  0.40203312039375305\n",
      "Eval Loss:  0.4975571036338806\n",
      "Eval Loss:  0.45216262340545654\n",
      "Eval Loss:  0.37261635065078735\n",
      "Eval Loss:  0.42698320746421814\n",
      "[[15488  3246]\n",
      " [ 2298  8765]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85     18734\n",
      "           1       0.73      0.79      0.76     11063\n",
      "\n",
      "    accuracy                           0.81     29797\n",
      "   macro avg       0.80      0.81      0.80     29797\n",
      "weighted avg       0.82      0.81      0.82     29797\n",
      "\n",
      "acc:  0.8139410007718898\n",
      "pre:  0.7297477312463575\n",
      "rec:  0.7922805748892705\n",
      "ma F1:  0.8039611684146659\n",
      "mi F1:  0.8139410007718898\n",
      "we F1:  0.8153482417468486\n",
      "29797 466\n",
      "Loss:  0.11010389775037766\n",
      "Loss:  0.09581823647022247\n",
      "Loss:  0.07828985899686813\n",
      "3 **********\n",
      "Epoch:  219.18394660949707  fold:  2  kers:  32\n",
      "epoch:  4\n",
      "29797 466\n",
      "Loss:  0.09165403246879578\n",
      "Loss:  0.07969838380813599\n",
      "Loss:  0.09943892061710358\n",
      "4 **********\n",
      "Epoch:  260.9442880153656  fold:  2  kers:  32\n",
      "epoch:  5\n",
      "29797 466\n",
      "Loss:  0.05400533974170685\n",
      "Loss:  0.0714697539806366\n",
      "Loss:  0.06986595690250397\n",
      "5 **********\n",
      "Epoch:  302.75250124931335  fold:  2  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.7115498781204224\n",
      "Eval Loss:  0.22809673845767975\n",
      "Eval Loss:  0.4620642066001892\n",
      "[[1151  279]\n",
      " [ 532 1132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74      1430\n",
      "           1       0.80      0.68      0.74      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.74      0.74      0.74      3094\n",
      "weighted avg       0.75      0.74      0.74      3094\n",
      "\n",
      "acc:  0.737879767291532\n",
      "pre:  0.8022678951098512\n",
      "rec:  0.6802884615384616\n",
      "ma F1:  0.7378698821360201\n",
      "mi F1:  0.737879767291532\n",
      "we F1:  0.7377481386418222\n",
      "update!  Acc:  0.737879767291532\n",
      "Eval Loss:  0.3686077892780304\n",
      "Eval Loss:  0.3964688181877136\n",
      "Eval Loss:  0.30344972014427185\n",
      "Eval Loss:  0.29978376626968384\n",
      "Eval Loss:  0.3478983938694\n",
      "Eval Loss:  0.3146911859512329\n",
      "Eval Loss:  0.36827191710472107\n",
      "Eval Loss:  0.3383971154689789\n",
      "Eval Loss:  0.3238006830215454\n",
      "Eval Loss:  0.26781362295150757\n",
      "Eval Loss:  0.2602076232433319\n",
      "Eval Loss:  0.2962822914123535\n",
      "Eval Loss:  0.3798511326313019\n",
      "Eval Loss:  0.4897361993789673\n",
      "Eval Loss:  0.30842676758766174\n",
      "Eval Loss:  0.34624454379081726\n",
      "Eval Loss:  0.31292790174484253\n",
      "Eval Loss:  0.3154709041118622\n",
      "Eval Loss:  0.36258262395858765\n",
      "Eval Loss:  0.2582486569881439\n",
      "Eval Loss:  0.30349600315093994\n",
      "Eval Loss:  0.33248794078826904\n",
      "Eval Loss:  0.4144704341888428\n",
      "Eval Loss:  0.25533586740493774\n",
      "Eval Loss:  0.3077000379562378\n",
      "Eval Loss:  0.3880123496055603\n",
      "Eval Loss:  0.35217785835266113\n",
      "Eval Loss:  0.28226950764656067\n",
      "Eval Loss:  0.34291714429855347\n",
      "[[16775  1959]\n",
      " [ 2211  8852]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89     18734\n",
      "           1       0.82      0.80      0.81     11063\n",
      "\n",
      "    accuracy                           0.86     29797\n",
      "   macro avg       0.85      0.85      0.85     29797\n",
      "weighted avg       0.86      0.86      0.86     29797\n",
      "\n",
      "acc:  0.860053025472363\n",
      "pre:  0.8187956710757561\n",
      "rec:  0.8001446262315828\n",
      "ma F1:  0.8494056410613917\n",
      "mi F1:  0.860053025472363\n",
      "we F1:  0.8597143733366108\n",
      "29797 466\n",
      "Loss:  0.07633722573518753\n",
      "Loss:  0.07798025012016296\n",
      "Loss:  0.08181081712245941\n",
      "6 **********\n",
      "Epoch:  383.78084802627563  fold:  2  kers:  32\n",
      "epoch:  7\n",
      "29797 466\n",
      "Loss:  0.0781308114528656\n",
      "Loss:  0.1171991229057312\n",
      "Loss:  0.09716124087572098\n",
      "7 **********\n",
      "Epoch:  425.57410192489624  fold:  2  kers:  32\n",
      "epoch:  8\n",
      "29797 466\n",
      "Loss:  0.08571796864271164\n",
      "Loss:  0.07376009970903397\n",
      "Loss:  0.07636990398168564\n",
      "8 **********\n",
      "Epoch:  467.31848549842834  fold:  2  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.7183538675308228\n",
      "Eval Loss:  0.3126019537448883\n",
      "Eval Loss:  0.3525627851486206\n",
      "[[1157  273]\n",
      " [ 521 1143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74      1430\n",
      "           1       0.81      0.69      0.74      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.75      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7433742727860375\n",
      "pre:  0.8072033898305084\n",
      "rec:  0.6868990384615384\n",
      "ma F1:  0.7433690183690183\n",
      "mi F1:  0.7433742727860376\n",
      "we F1:  0.7432811945416987\n",
      "update!  Acc:  0.7433742727860375\n",
      "Eval Loss:  0.32207149267196655\n",
      "Eval Loss:  0.3606443405151367\n",
      "Eval Loss:  0.30522215366363525\n",
      "Eval Loss:  0.29367074370384216\n",
      "Eval Loss:  0.3451384902000427\n",
      "Eval Loss:  0.30249887704849243\n",
      "Eval Loss:  0.3401143252849579\n",
      "Eval Loss:  0.2821916937828064\n",
      "Eval Loss:  0.29358819127082825\n",
      "Eval Loss:  0.24285449087619781\n",
      "Eval Loss:  0.23277968168258667\n",
      "Eval Loss:  0.2531721889972687\n",
      "Eval Loss:  0.3442285358905792\n",
      "Eval Loss:  0.44716206192970276\n",
      "Eval Loss:  0.27739930152893066\n",
      "Eval Loss:  0.3250485360622406\n",
      "Eval Loss:  0.27679017186164856\n",
      "Eval Loss:  0.27256256341934204\n",
      "Eval Loss:  0.34410569071769714\n",
      "Eval Loss:  0.24142056703567505\n",
      "Eval Loss:  0.2799781858921051\n",
      "Eval Loss:  0.3262721300125122\n",
      "Eval Loss:  0.422771692276001\n",
      "Eval Loss:  0.2328578531742096\n",
      "Eval Loss:  0.27252864837646484\n",
      "Eval Loss:  0.34649211168289185\n",
      "Eval Loss:  0.32548874616622925\n",
      "Eval Loss:  0.25338563323020935\n",
      "Eval Loss:  0.30095306038856506\n",
      "[[16719  2015]\n",
      " [ 1788  9275]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90     18734\n",
      "           1       0.82      0.84      0.83     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.86      0.87      0.86     29797\n",
      "weighted avg       0.87      0.87      0.87     29797\n",
      "\n",
      "acc:  0.8723697016478169\n",
      "pre:  0.8215234720992028\n",
      "rec:  0.8383801862062732\n",
      "ma F1:  0.8638738022521677\n",
      "mi F1:  0.8723697016478169\n",
      "we F1:  0.8726287786444333\n",
      "29797 466\n",
      "Loss:  0.10755288600921631\n",
      "Loss:  0.10826157033443451\n",
      "Loss:  0.05609957128763199\n",
      "9 **********\n",
      "Epoch:  548.6031467914581  fold:  2  kers:  32\n",
      "epoch:  10\n",
      "29797 466\n",
      "Loss:  0.07264906913042068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.058786820620298386\n",
      "Loss:  0.06862811744213104\n",
      "10 **********\n",
      "Epoch:  590.3993918895721  fold:  2  kers:  32\n",
      "epoch:  11\n",
      "29797 466\n",
      "Loss:  0.08652985095977783\n",
      "Loss:  0.08098133653402328\n",
      "Loss:  0.06546799093484879\n",
      "11 **********\n",
      "Epoch:  632.1976320743561  fold:  2  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.9280005097389221\n",
      "Eval Loss:  0.26545450091362\n",
      "Eval Loss:  0.5686084628105164\n",
      "[[1257  173]\n",
      " [ 664 1000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75      1430\n",
      "           1       0.85      0.60      0.70      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.75      0.74      0.73      3094\n",
      "weighted avg       0.76      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7294764059469941\n",
      "pre:  0.8525149190110827\n",
      "rec:  0.6009615384615384\n",
      "ma F1:  0.7275969262801407\n",
      "mi F1:  0.7294764059469941\n",
      "we F1:  0.7258856490737449\n",
      "Eval Loss:  0.3363189399242401\n",
      "Eval Loss:  0.37013497948646545\n",
      "Eval Loss:  0.3070741891860962\n",
      "Eval Loss:  0.22053463757038116\n",
      "Eval Loss:  0.33035749197006226\n",
      "Eval Loss:  0.33994340896606445\n",
      "Eval Loss:  0.3973453938961029\n",
      "Eval Loss:  0.3332805633544922\n",
      "Eval Loss:  0.2694462835788727\n",
      "Eval Loss:  0.20222428441047668\n",
      "Eval Loss:  0.21129156649112701\n",
      "Eval Loss:  0.2500211000442505\n",
      "Eval Loss:  0.3509507477283478\n",
      "Eval Loss:  0.4073978662490845\n",
      "Eval Loss:  0.2797633707523346\n",
      "Eval Loss:  0.32500579953193665\n",
      "Eval Loss:  0.2579247057437897\n",
      "Eval Loss:  0.33357521891593933\n",
      "Eval Loss:  0.29348689317703247\n",
      "Eval Loss:  0.2132996916770935\n",
      "Eval Loss:  0.27330029010772705\n",
      "Eval Loss:  0.30113619565963745\n",
      "Eval Loss:  0.4037450850009918\n",
      "Eval Loss:  0.27178284525871277\n",
      "Eval Loss:  0.2988104820251465\n",
      "Eval Loss:  0.3605233430862427\n",
      "Eval Loss:  0.3157816529273987\n",
      "Eval Loss:  0.26032769680023193\n",
      "Eval Loss:  0.3512169122695923\n",
      "[[17636  1098]\n",
      " [ 2541  8522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91     18734\n",
      "           1       0.89      0.77      0.82     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.88      0.86      0.87     29797\n",
      "weighted avg       0.88      0.88      0.88     29797\n",
      "\n",
      "acc:  0.8778736114373931\n",
      "pre:  0.8858627858627859\n",
      "rec:  0.7703154659676399\n",
      "ma F1:  0.8652686465859402\n",
      "mi F1:  0.8778736114373931\n",
      "we F1:  0.8758778944875745\n",
      "29797 466\n",
      "Loss:  0.05621887370944023\n",
      "Loss:  0.08797422796487808\n",
      "Loss:  0.09835052490234375\n",
      "12 **********\n",
      "Epoch:  713.3127465248108  fold:  2  kers:  32\n",
      "epoch:  13\n",
      "29797 466\n",
      "Loss:  0.08996481448411942\n",
      "Loss:  0.06839057803153992\n",
      "Loss:  0.06598743796348572\n",
      "13 **********\n",
      "Epoch:  755.1000158786774  fold:  2  kers:  32\n",
      "epoch:  14\n",
      "29797 466\n",
      "Loss:  0.06738666445016861\n",
      "Loss:  0.07620500773191452\n",
      "Loss:  0.12132241576910019\n",
      "14 **********\n",
      "Epoch:  796.9680695533752  fold:  2  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.8013601899147034\n",
      "Eval Loss:  0.414290189743042\n",
      "Eval Loss:  0.4969518780708313\n",
      "[[1215  215]\n",
      " [ 596 1068]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.85      0.75      1430\n",
      "           1       0.83      0.64      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.74      3094\n",
      "\n",
      "acc:  0.737879767291532\n",
      "pre:  0.8324240062353858\n",
      "rec:  0.6418269230769231\n",
      "ma F1:  0.7372867381332263\n",
      "mi F1:  0.737879767291532\n",
      "we F1:  0.7363427325342907\n",
      "Eval Loss:  0.2848559319972992\n",
      "Eval Loss:  0.3374425768852234\n",
      "Eval Loss:  0.2944166958332062\n",
      "Eval Loss:  0.20894382894039154\n",
      "Eval Loss:  0.3314969837665558\n",
      "Eval Loss:  0.30965834856033325\n",
      "Eval Loss:  0.39309290051460266\n",
      "Eval Loss:  0.29999515414237976\n",
      "Eval Loss:  0.24081915616989136\n",
      "Eval Loss:  0.1904934197664261\n",
      "Eval Loss:  0.19615361094474792\n",
      "Eval Loss:  0.23262670636177063\n",
      "Eval Loss:  0.3409406542778015\n",
      "Eval Loss:  0.3890235126018524\n",
      "Eval Loss:  0.2515294551849365\n",
      "Eval Loss:  0.287239670753479\n",
      "Eval Loss:  0.22424258291721344\n",
      "Eval Loss:  0.29447489976882935\n",
      "Eval Loss:  0.2553178369998932\n",
      "Eval Loss:  0.20012882351875305\n",
      "Eval Loss:  0.23136550188064575\n",
      "Eval Loss:  0.28866615891456604\n",
      "Eval Loss:  0.3635328412055969\n",
      "Eval Loss:  0.24495001137256622\n",
      "Eval Loss:  0.2818683981895447\n",
      "Eval Loss:  0.3276253938674927\n",
      "Eval Loss:  0.3056902587413788\n",
      "Eval Loss:  0.23482002317905426\n",
      "Eval Loss:  0.31248071789741516\n",
      "[[17477  1257]\n",
      " [ 2119  8944]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18734\n",
      "           1       0.88      0.81      0.84     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.88      0.87      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8867000033560426\n",
      "pre:  0.87677678658955\n",
      "rec:  0.8084606345475911\n",
      "ma F1:  0.8765783932138961\n",
      "mi F1:  0.8867000033560426\n",
      "we F1:  0.8856775226408743\n",
      "29797 466\n",
      "Loss:  0.08443727344274521\n",
      "Loss:  0.08409908413887024\n",
      "Loss:  0.08151769638061523\n",
      "15 **********\n",
      "Epoch:  878.0781972408295  fold:  2  kers:  32\n",
      "epoch:  16\n",
      "29797 466\n",
      "Loss:  0.07579632103443146\n",
      "Loss:  0.060664620250463486\n",
      "Loss:  0.05813142657279968\n",
      "16 **********\n",
      "Epoch:  919.9691894054413  fold:  2  kers:  32\n",
      "epoch:  17\n",
      "29797 466\n",
      "Loss:  0.1121341809630394\n",
      "Loss:  0.08431922644376755\n",
      "Loss:  0.09680131077766418\n",
      "17 **********\n",
      "Epoch:  961.7684268951416  fold:  2  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.791563868522644\n",
      "Eval Loss:  0.46736663579940796\n",
      "Eval Loss:  0.6346361637115479\n",
      "[[1231  199]\n",
      " [ 624 1040]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      1430\n",
      "           1       0.84      0.62      0.72      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.75      0.74      0.73      3094\n",
      "weighted avg       0.76      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7340012928248222\n",
      "pre:  0.8393866020984665\n",
      "rec:  0.625\n",
      "ma F1:  0.7329837238651455\n",
      "mi F1:  0.7340012928248222\n",
      "we F1:  0.7317370686998873\n",
      "Eval Loss:  0.24784688651561737\n",
      "Eval Loss:  0.30174940824508667\n",
      "Eval Loss:  0.2519632577896118\n",
      "Eval Loss:  0.19137153029441833\n",
      "Eval Loss:  0.3324001729488373\n",
      "Eval Loss:  0.28795793652534485\n",
      "Eval Loss:  0.379919171333313\n",
      "Eval Loss:  0.26736515760421753\n",
      "Eval Loss:  0.2036016434431076\n",
      "Eval Loss:  0.18109022080898285\n",
      "Eval Loss:  0.19383104145526886\n",
      "Eval Loss:  0.22860966622829437\n",
      "Eval Loss:  0.34972044825553894\n",
      "Eval Loss:  0.3568989932537079\n",
      "Eval Loss:  0.2524389326572418\n",
      "Eval Loss:  0.28869637846946716\n",
      "Eval Loss:  0.20801611244678497\n",
      "Eval Loss:  0.25667649507522583\n",
      "Eval Loss:  0.2493683248758316\n",
      "Eval Loss:  0.18793608248233795\n",
      "Eval Loss:  0.20922896265983582\n",
      "Eval Loss:  0.27879616618156433\n",
      "Eval Loss:  0.34897422790527344\n",
      "Eval Loss:  0.23309370875358582\n",
      "Eval Loss:  0.2647065818309784\n",
      "Eval Loss:  0.32407522201538086\n",
      "Eval Loss:  0.28839340806007385\n",
      "Eval Loss:  0.21758876740932465\n",
      "Eval Loss:  0.2850486636161804\n",
      "[[17615  1119]\n",
      " [ 2059  9004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18734\n",
      "           1       0.89      0.81      0.85     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.89      0.88      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8933449676141894\n",
      "pre:  0.8894596463498963\n",
      "rec:  0.8138841182319443\n",
      "ma F1:  0.8836260506986718\n",
      "mi F1:  0.8933449676141894\n",
      "we F1:  0.8922840244135637\n",
      "29797 466\n",
      "Loss:  0.08032070845365524\n",
      "Loss:  0.04337947815656662\n",
      "Loss:  0.058989714831113815\n",
      "18 **********\n",
      "Epoch:  1043.0550825595856  fold:  2  kers:  32\n",
      "epoch:  19\n",
      "29797 466\n",
      "Loss:  0.07726754248142242\n",
      "Loss:  0.08258401602506638\n",
      "Loss:  0.06967979669570923\n",
      "19 **********\n",
      "Epoch:  1084.8982026576996  fold:  2  kers:  32\n",
      "epoch:  20\n",
      "29797 466\n",
      "Loss:  0.04497283697128296\n",
      "Loss:  0.07157231867313385\n",
      "Loss:  0.06405968219041824\n",
      "20 **********\n",
      "Epoch:  1126.706416130066  fold:  2  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.8017869591712952\n",
      "Eval Loss:  0.38527461886405945\n",
      "Eval Loss:  0.8674334287643433\n",
      "[[1228  202]\n",
      " [ 650 1014]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74      1430\n",
      "           1       0.83      0.61      0.70      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.74      0.73      0.72      3094\n",
      "weighted avg       0.75      0.72      0.72      3094\n",
      "\n",
      "acc:  0.724628312863607\n",
      "pre:  0.8338815789473685\n",
      "rec:  0.609375\n",
      "ma F1:  0.7233046150745668\n",
      "mi F1:  0.724628312863607\n",
      "we F1:  0.7218572072117844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.28213995695114136\n",
      "Eval Loss:  0.32784005999565125\n",
      "Eval Loss:  0.24980321526527405\n",
      "Eval Loss:  0.18154308199882507\n",
      "Eval Loss:  0.30656492710113525\n",
      "Eval Loss:  0.3060915172100067\n",
      "Eval Loss:  0.41567206382751465\n",
      "Eval Loss:  0.2831990718841553\n",
      "Eval Loss:  0.21537676453590393\n",
      "Eval Loss:  0.19863981008529663\n",
      "Eval Loss:  0.20987568795681\n",
      "Eval Loss:  0.22626669704914093\n",
      "Eval Loss:  0.343146413564682\n",
      "Eval Loss:  0.3513580858707428\n",
      "Eval Loss:  0.24589881300926208\n",
      "Eval Loss:  0.30316850543022156\n",
      "Eval Loss:  0.20892123878002167\n",
      "Eval Loss:  0.28214144706726074\n",
      "Eval Loss:  0.23946577310562134\n",
      "Eval Loss:  0.1696806252002716\n",
      "Eval Loss:  0.20710305869579315\n",
      "Eval Loss:  0.26649999618530273\n",
      "Eval Loss:  0.3484063744544983\n",
      "Eval Loss:  0.22685179114341736\n",
      "Eval Loss:  0.28291234374046326\n",
      "Eval Loss:  0.32299289107322693\n",
      "Eval Loss:  0.298893004655838\n",
      "Eval Loss:  0.23309387266635895\n",
      "Eval Loss:  0.3152591586112976\n",
      "[[17829   905]\n",
      " [ 2300  8763]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18734\n",
      "           1       0.91      0.79      0.85     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.90      0.87      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8924388361244421\n",
      "pre:  0.9063922217625155\n",
      "rec:  0.7920997920997921\n",
      "ma F1:  0.8814657105777427\n",
      "mi F1:  0.8924388361244421\n",
      "we F1:  0.8907503836495198\n",
      "29797 466\n",
      "Loss:  0.08876848965883255\n",
      "Loss:  0.09122628718614578\n",
      "Loss:  0.04540950804948807\n",
      "21 **********\n",
      "Epoch:  1208.2065012454987  fold:  2  kers:  32\n",
      "epoch:  22\n",
      "29797 466\n",
      "Loss:  0.08034196496009827\n",
      "Loss:  0.08045487105846405\n",
      "Loss:  0.06408517062664032\n",
      "22 **********\n",
      "Epoch:  1250.101482629776  fold:  2  kers:  32\n",
      "epoch:  23\n",
      "29797 466\n",
      "Loss:  0.03917625546455383\n",
      "Loss:  0.056673623621463776\n",
      "Loss:  0.07121963798999786\n",
      "23 **********\n",
      "Epoch:  1292.059296131134  fold:  2  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.8753654956817627\n",
      "Eval Loss:  0.5211808085441589\n",
      "Eval Loss:  0.8219239115715027\n",
      "[[1210  220]\n",
      " [ 638 1026]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.85      0.74      1430\n",
      "           1       0.82      0.62      0.71      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.74      0.73      0.72      3094\n",
      "weighted avg       0.75      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7226890756302521\n",
      "pre:  0.8234349919743178\n",
      "rec:  0.6165865384615384\n",
      "ma F1:  0.7217048363661522\n",
      "mi F1:  0.7226890756302521\n",
      "we F1:  0.7204531407802862\n",
      "Eval Loss:  0.24792075157165527\n",
      "Eval Loss:  0.2817765474319458\n",
      "Eval Loss:  0.23804813623428345\n",
      "Eval Loss:  0.1806715726852417\n",
      "Eval Loss:  0.29712384939193726\n",
      "Eval Loss:  0.2799161672592163\n",
      "Eval Loss:  0.3804575800895691\n",
      "Eval Loss:  0.24990667402744293\n",
      "Eval Loss:  0.18673987686634064\n",
      "Eval Loss:  0.1801297813653946\n",
      "Eval Loss:  0.1843808889389038\n",
      "Eval Loss:  0.21204635500907898\n",
      "Eval Loss:  0.3118807077407837\n",
      "Eval Loss:  0.3324706256389618\n",
      "Eval Loss:  0.2339564561843872\n",
      "Eval Loss:  0.2864944636821747\n",
      "Eval Loss:  0.19544363021850586\n",
      "Eval Loss:  0.24389594793319702\n",
      "Eval Loss:  0.22864888608455658\n",
      "Eval Loss:  0.16444775462150574\n",
      "Eval Loss:  0.18755388259887695\n",
      "Eval Loss:  0.2631939947605133\n",
      "Eval Loss:  0.3599015176296234\n",
      "Eval Loss:  0.1943298578262329\n",
      "Eval Loss:  0.26104745268821716\n",
      "Eval Loss:  0.2898247241973877\n",
      "Eval Loss:  0.28391557931900024\n",
      "Eval Loss:  0.23178428411483765\n",
      "Eval Loss:  0.28084298968315125\n",
      "[[17765   969]\n",
      " [ 2058  9005]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18734\n",
      "           1       0.90      0.81      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.88      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.8984125918716649\n",
      "pre:  0.9028474032484459\n",
      "rec:  0.8139745096266835\n",
      "ma F1:  0.8888017584506038\n",
      "mi F1:  0.8984125918716649\n",
      "we F1:  0.8972178204566494\n",
      "29797 466\n",
      "Loss:  0.0684274435043335\n",
      "Loss:  0.06836440414190292\n",
      "Loss:  0.06840497255325317\n",
      "24 **********\n",
      "Epoch:  1373.1983473300934  fold:  2  kers:  32\n",
      "epoch:  25\n",
      "29797 466\n",
      "Loss:  0.05681465566158295\n",
      "Loss:  0.057631950825452805\n",
      "Loss:  0.03934905678033829\n",
      "25 **********\n",
      "Epoch:  1415.1003096103668  fold:  2  kers:  32\n",
      "epoch:  26\n",
      "29797 466\n",
      "Loss:  0.0712929517030716\n",
      "Loss:  0.0633029118180275\n",
      "Loss:  0.07657330483198166\n",
      "26 **********\n",
      "Epoch:  1456.8676319122314  fold:  2  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.7642965316772461\n",
      "Eval Loss:  0.35537371039390564\n",
      "Eval Loss:  0.537243664264679\n",
      "[[1232  198]\n",
      " [ 618 1046]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75      1430\n",
      "           1       0.84      0.63      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.73      3094\n",
      "\n",
      "acc:  0.7362637362637363\n",
      "pre:  0.8408360128617364\n",
      "rec:  0.6286057692307693\n",
      "ma F1:  0.735307142617506\n",
      "mi F1:  0.7362637362637363\n",
      "we F1:  0.7341036860948292\n",
      "Eval Loss:  0.2398572415113449\n",
      "Eval Loss:  0.26733145117759705\n",
      "Eval Loss:  0.1918783038854599\n",
      "Eval Loss:  0.18946081399917603\n",
      "Eval Loss:  0.29819145798683167\n",
      "Eval Loss:  0.25026604533195496\n",
      "Eval Loss:  0.36040329933166504\n",
      "Eval Loss:  0.22324317693710327\n",
      "Eval Loss:  0.16811932623386383\n",
      "Eval Loss:  0.1712069809436798\n",
      "Eval Loss:  0.1689024716615677\n",
      "Eval Loss:  0.20934198796749115\n",
      "Eval Loss:  0.3280198872089386\n",
      "Eval Loss:  0.3249083459377289\n",
      "Eval Loss:  0.22227831184864044\n",
      "Eval Loss:  0.2747041881084442\n",
      "Eval Loss:  0.17767579853534698\n",
      "Eval Loss:  0.21116848289966583\n",
      "Eval Loss:  0.21591800451278687\n",
      "Eval Loss:  0.16521739959716797\n",
      "Eval Loss:  0.18513546884059906\n",
      "Eval Loss:  0.27271178364753723\n",
      "Eval Loss:  0.3439847230911255\n",
      "Eval Loss:  0.17892564833164215\n",
      "Eval Loss:  0.2408311665058136\n",
      "Eval Loss:  0.25348541140556335\n",
      "Eval Loss:  0.2557106912136078\n",
      "Eval Loss:  0.19804129004478455\n",
      "Eval Loss:  0.2810709476470947\n",
      "[[17784   950]\n",
      " [ 1896  9167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     18734\n",
      "           1       0.91      0.83      0.87     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.89      0.90     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9044870288955263\n",
      "pre:  0.9060986458436295\n",
      "rec:  0.8286179155744373\n",
      "ma F1:  0.8957701893288925\n",
      "mi F1:  0.9044870288955262\n",
      "we F1:  0.9035300682096686\n",
      "29797 466\n",
      "Loss:  0.06955748051404953\n",
      "Loss:  0.053225331008434296\n",
      "Loss:  0.056238677352666855\n",
      "27 **********\n",
      "Epoch:  1538.1024267673492  fold:  2  kers:  32\n",
      "epoch:  28\n",
      "29797 466\n",
      "Loss:  0.07880991697311401\n",
      "Loss:  0.06181801110506058\n",
      "Loss:  0.10177095234394073\n",
      "28 **********\n",
      "Epoch:  1579.9186189174652  fold:  2  kers:  32\n",
      "epoch:  29\n",
      "29797 466\n",
      "Loss:  0.06277792155742645\n",
      "Loss:  0.04781287536025047\n",
      "Loss:  0.06964705139398575\n",
      "29 **********\n",
      "Epoch:  1621.717856168747  fold:  2  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.7268782258033752\n",
      "Eval Loss:  0.3684731721878052\n",
      "Eval Loss:  0.563439667224884\n",
      "[[1234  196]\n",
      " [ 610 1054]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75      1430\n",
      "           1       0.84      0.63      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.76      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7394957983193278\n",
      "pre:  0.8432\n",
      "rec:  0.6334134615384616\n",
      "ma F1:  0.7386111075007473\n",
      "mi F1:  0.7394957983193278\n",
      "we F1:  0.7374610094365928\n",
      "Eval Loss:  0.2728522717952728\n",
      "Eval Loss:  0.2527593672275543\n",
      "Eval Loss:  0.21541854739189148\n",
      "Eval Loss:  0.17105452716350555\n",
      "Eval Loss:  0.27317923307418823\n",
      "Eval Loss:  0.2481469213962555\n",
      "Eval Loss:  0.3685065507888794\n",
      "Eval Loss:  0.24363546073436737\n",
      "Eval Loss:  0.17749400436878204\n",
      "Eval Loss:  0.1804254949092865\n",
      "Eval Loss:  0.17509959638118744\n",
      "Eval Loss:  0.2261747270822525\n",
      "Eval Loss:  0.31725332140922546\n",
      "Eval Loss:  0.3213597536087036\n",
      "Eval Loss:  0.21435654163360596\n",
      "Eval Loss:  0.2848009765148163\n",
      "Eval Loss:  0.1831386685371399\n",
      "Eval Loss:  0.22811491787433624\n",
      "Eval Loss:  0.2053689956665039\n",
      "Eval Loss:  0.16172727942466736\n",
      "Eval Loss:  0.18237236142158508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.27266576886177063\n",
      "Eval Loss:  0.33822986483573914\n",
      "Eval Loss:  0.17834517359733582\n",
      "Eval Loss:  0.2544955313205719\n",
      "Eval Loss:  0.2602953016757965\n",
      "Eval Loss:  0.2604372501373291\n",
      "Eval Loss:  0.22267207503318787\n",
      "Eval Loss:  0.2668401896953583\n",
      "[[17880   854]\n",
      " [ 2038  9025]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     18734\n",
      "           1       0.91      0.82      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.89      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9029432493204014\n",
      "pre:  0.9135540034416438\n",
      "rec:  0.815782337521468\n",
      "ma F1:  0.8935414115614062\n",
      "mi F1:  0.9029432493204014\n",
      "we F1:  0.9016861317702433\n",
      "29797 466\n",
      "Loss:  0.08159134536981583\n",
      "Loss:  0.04771272838115692\n",
      "Loss:  0.058190058916807175\n",
      "30 **********\n",
      "Epoch:  1702.8279838562012  fold:  2  kers:  32\n",
      "epoch:  31\n",
      "29797 466\n",
      "Loss:  0.06676841527223587\n",
      "Loss:  0.059405338019132614\n",
      "Loss:  0.04507819563150406\n",
      "31 **********\n",
      "Epoch:  1744.6501603126526  fold:  2  kers:  32\n",
      "epoch:  32\n",
      "29797 466\n",
      "Loss:  0.07783181965351105\n",
      "Loss:  0.07125844061374664\n",
      "Loss:  0.09021857380867004\n",
      "32 **********\n",
      "Epoch:  1786.447402715683  fold:  2  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.8763086199760437\n",
      "Eval Loss:  0.30722659826278687\n",
      "Eval Loss:  0.9120306968688965\n",
      "[[1256  174]\n",
      " [ 704  960]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74      1430\n",
      "           1       0.85      0.58      0.69      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.74      0.73      0.71      3094\n",
      "weighted avg       0.75      0.72      0.71      3094\n",
      "\n",
      "acc:  0.7162249515190692\n",
      "pre:  0.8465608465608465\n",
      "rec:  0.5769230769230769\n",
      "ma F1:  0.7136036907947312\n",
      "mi F1:  0.7162249515190693\n",
      "we F1:  0.7115314779248153\n",
      "Eval Loss:  0.30527785420417786\n",
      "Eval Loss:  0.27688881754875183\n",
      "Eval Loss:  0.24670138955116272\n",
      "Eval Loss:  0.1542053520679474\n",
      "Eval Loss:  0.2815326452255249\n",
      "Eval Loss:  0.25629499554634094\n",
      "Eval Loss:  0.3993498682975769\n",
      "Eval Loss:  0.2680642604827881\n",
      "Eval Loss:  0.19975435733795166\n",
      "Eval Loss:  0.1757829636335373\n",
      "Eval Loss:  0.18302878737449646\n",
      "Eval Loss:  0.24724024534225464\n",
      "Eval Loss:  0.31651902198791504\n",
      "Eval Loss:  0.3477012813091278\n",
      "Eval Loss:  0.23515096306800842\n",
      "Eval Loss:  0.29988402128219604\n",
      "Eval Loss:  0.2035626471042633\n",
      "Eval Loss:  0.26901859045028687\n",
      "Eval Loss:  0.22826367616653442\n",
      "Eval Loss:  0.16009533405303955\n",
      "Eval Loss:  0.20459245145320892\n",
      "Eval Loss:  0.28070327639579773\n",
      "Eval Loss:  0.3872458040714264\n",
      "Eval Loss:  0.17661680281162262\n",
      "Eval Loss:  0.2560909688472748\n",
      "Eval Loss:  0.28666701912879944\n",
      "Eval Loss:  0.27027615904808044\n",
      "Eval Loss:  0.23851996660232544\n",
      "Eval Loss:  0.28508564829826355\n",
      "[[17988   746]\n",
      " [ 2235  8828]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18734\n",
      "           1       0.92      0.80      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.88      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.89995637144679\n",
      "pre:  0.9220806350532693\n",
      "rec:  0.7979752327578414\n",
      "ma F1:  0.8895152219778841\n",
      "mi F1:  0.89995637144679\n",
      "we F1:  0.8982591147263532\n",
      "29797 466\n",
      "Loss:  0.07184691727161407\n",
      "Loss:  0.0614028200507164\n",
      "Loss:  0.04721873998641968\n",
      "33 **********\n",
      "Epoch:  1867.5585281848907  fold:  2  kers:  32\n",
      "epoch:  34\n",
      "29797 466\n",
      "Loss:  0.08524343371391296\n",
      "Loss:  0.06047048419713974\n",
      "Loss:  0.0435866080224514\n",
      "34 **********\n",
      "Epoch:  1909.2729923725128  fold:  2  kers:  32\n",
      "epoch:  35\n",
      "29797 466\n",
      "Loss:  0.048930224031209946\n",
      "Loss:  0.08093105256557465\n",
      "Loss:  0.032330483198165894\n",
      "35 **********\n",
      "Epoch:  1950.9575362205505  fold:  2  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.7762317061424255\n",
      "Eval Loss:  0.20681121945381165\n",
      "Eval Loss:  0.8306406140327454\n",
      "[[1283  147]\n",
      " [ 723  941]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75      1430\n",
      "           1       0.86      0.57      0.68      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.75      0.73      0.72      3094\n",
      "weighted avg       0.76      0.72      0.71      3094\n",
      "\n",
      "acc:  0.7188106011635423\n",
      "pre:  0.8648897058823529\n",
      "rec:  0.5655048076923077\n",
      "ma F1:  0.7153324410482713\n",
      "mi F1:  0.7188106011635425\n",
      "we F1:  0.7129526472851913\n",
      "Eval Loss:  0.34134504199028015\n",
      "Eval Loss:  0.30106833577156067\n",
      "Eval Loss:  0.22730666399002075\n",
      "Eval Loss:  0.14492401480674744\n",
      "Eval Loss:  0.29358357191085815\n",
      "Eval Loss:  0.27102425694465637\n",
      "Eval Loss:  0.40022459626197815\n",
      "Eval Loss:  0.2643105387687683\n",
      "Eval Loss:  0.22951585054397583\n",
      "Eval Loss:  0.180137500166893\n",
      "Eval Loss:  0.17544269561767578\n",
      "Eval Loss:  0.277284175157547\n",
      "Eval Loss:  0.34013670682907104\n",
      "Eval Loss:  0.38044700026512146\n",
      "Eval Loss:  0.26300790905952454\n",
      "Eval Loss:  0.328933447599411\n",
      "Eval Loss:  0.2400118112564087\n",
      "Eval Loss:  0.2863505482673645\n",
      "Eval Loss:  0.23844939470291138\n",
      "Eval Loss:  0.18647874891757965\n",
      "Eval Loss:  0.22689154744148254\n",
      "Eval Loss:  0.29775482416152954\n",
      "Eval Loss:  0.3869940936565399\n",
      "Eval Loss:  0.1903897225856781\n",
      "Eval Loss:  0.281063973903656\n",
      "Eval Loss:  0.28740525245666504\n",
      "Eval Loss:  0.27031847834587097\n",
      "Eval Loss:  0.2481558471918106\n",
      "Eval Loss:  0.301590234041214\n",
      "[[18094   640]\n",
      " [ 2474  8589]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18734\n",
      "           1       0.93      0.78      0.85     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.87      0.88     29797\n",
      "weighted avg       0.90      0.90      0.89     29797\n",
      "\n",
      "acc:  0.8954928348491459\n",
      "pre:  0.9306533752302525\n",
      "rec:  0.7763716894151677\n",
      "ma F1:  0.8836539497736386\n",
      "mi F1:  0.8954928348491459\n",
      "we F1:  0.8932085092070122\n",
      "29797 466\n",
      "Loss:  0.03772241994738579\n",
      "Loss:  0.0931924432516098\n",
      "Loss:  0.05558854714035988\n",
      "36 **********\n",
      "Epoch:  2031.823317527771  fold:  2  kers:  32\n",
      "epoch:  37\n",
      "29797 466\n",
      "Loss:  0.05044647678732872\n",
      "Loss:  0.04711270332336426\n",
      "Loss:  0.07904870808124542\n",
      "37 **********\n",
      "Epoch:  2073.549749135971  fold:  2  kers:  32\n",
      "epoch:  38\n",
      "29797 466\n",
      "Loss:  0.0809234082698822\n",
      "Loss:  0.06554369628429413\n",
      "Loss:  0.06370176374912262\n",
      "38 **********\n",
      "Epoch:  2115.3799040317535  fold:  2  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.6030773520469666\n",
      "Eval Loss:  0.24051393568515778\n",
      "Eval Loss:  0.7926554083824158\n",
      "[[1264  166]\n",
      " [ 665  999]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.75      1430\n",
      "           1       0.86      0.60      0.71      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.76      0.74      0.73      3094\n",
      "weighted avg       0.76      0.73      0.73      3094\n",
      "\n",
      "acc:  0.731415643180349\n",
      "pre:  0.8575107296137339\n",
      "rec:  0.6003605769230769\n",
      "ma F1:  0.7294307848653385\n",
      "mi F1:  0.731415643180349\n",
      "we F1:  0.7276781175230274\n",
      "Eval Loss:  0.3826389014720917\n",
      "Eval Loss:  0.3643213212490082\n",
      "Eval Loss:  0.2555171549320221\n",
      "Eval Loss:  0.15926958620548248\n",
      "Eval Loss:  0.33064162731170654\n",
      "Eval Loss:  0.31880664825439453\n",
      "Eval Loss:  0.46587756276130676\n",
      "Eval Loss:  0.304390549659729\n",
      "Eval Loss:  0.2666202187538147\n",
      "Eval Loss:  0.1940445899963379\n",
      "Eval Loss:  0.17321406304836273\n",
      "Eval Loss:  0.29004037380218506\n",
      "Eval Loss:  0.3516870141029358\n",
      "Eval Loss:  0.4143608510494232\n",
      "Eval Loss:  0.27020329236984253\n",
      "Eval Loss:  0.34043997526168823\n",
      "Eval Loss:  0.267873078584671\n",
      "Eval Loss:  0.30976295471191406\n",
      "Eval Loss:  0.24446777999401093\n",
      "Eval Loss:  0.1926993727684021\n",
      "Eval Loss:  0.25158825516700745\n",
      "Eval Loss:  0.3037424087524414\n",
      "Eval Loss:  0.3945944607257843\n",
      "Eval Loss:  0.20367473363876343\n",
      "Eval Loss:  0.3032618761062622\n",
      "Eval Loss:  0.34365588426589966\n",
      "Eval Loss:  0.28611284494400024\n",
      "Eval Loss:  0.27128612995147705\n",
      "Eval Loss:  0.35109034180641174\n",
      "[[18125   609]\n",
      " [ 2677  8386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     18734\n",
      "           1       0.93      0.76      0.84     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.90      0.86      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8897204416552001\n",
      "pre:  0.932295719844358\n",
      "rec:  0.7580222362831058\n",
      "ma F1:  0.876530484198011\n",
      "mi F1:  0.8897204416552001\n",
      "we F1:  0.8869196579996435\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06423918157815933\n",
      "Loss:  0.0563604012131691\n",
      "Loss:  0.07463410496711731\n",
      "39 **********\n",
      "Epoch:  2196.329461336136  fold:  2  kers:  32\n",
      "epoch:  40\n",
      "29797 466\n",
      "Loss:  0.0480244904756546\n",
      "Loss:  0.059457261115312576\n",
      "Loss:  0.07958855479955673\n",
      "40 **********\n",
      "Epoch:  2238.117727994919  fold:  2  kers:  32\n",
      "epoch:  41\n",
      "29797 466\n",
      "Loss:  0.06707935035228729\n",
      "Loss:  0.08210781216621399\n",
      "Loss:  0.044755034148693085\n",
      "41 **********\n",
      "Epoch:  2279.85413312912  fold:  2  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.5471214652061462\n",
      "Eval Loss:  0.2170039266347885\n",
      "Eval Loss:  0.8154953718185425\n",
      "[[1232  198]\n",
      " [ 587 1077]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76      1430\n",
      "           1       0.84      0.65      0.73      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.75      0.75      3094\n",
      "weighted avg       0.77      0.75      0.74      3094\n",
      "\n",
      "acc:  0.7462831286360698\n",
      "pre:  0.8447058823529412\n",
      "rec:  0.6472355769230769\n",
      "ma F1:  0.7456447718988259\n",
      "mi F1:  0.7462831286360698\n",
      "we F1:  0.744681059147116\n",
      "update!  Acc:  0.7462831286360698\n",
      "Eval Loss:  0.3173868954181671\n",
      "Eval Loss:  0.29077884554862976\n",
      "Eval Loss:  0.22530201077461243\n",
      "Eval Loss:  0.16205701231956482\n",
      "Eval Loss:  0.285532146692276\n",
      "Eval Loss:  0.23249150812625885\n",
      "Eval Loss:  0.3412962257862091\n",
      "Eval Loss:  0.24585627019405365\n",
      "Eval Loss:  0.23523859679698944\n",
      "Eval Loss:  0.16869589686393738\n",
      "Eval Loss:  0.12752901017665863\n",
      "Eval Loss:  0.2537797689437866\n",
      "Eval Loss:  0.333156019449234\n",
      "Eval Loss:  0.39043092727661133\n",
      "Eval Loss:  0.2313430905342102\n",
      "Eval Loss:  0.2932369112968445\n",
      "Eval Loss:  0.21159259974956512\n",
      "Eval Loss:  0.23336215317249298\n",
      "Eval Loss:  0.2200574278831482\n",
      "Eval Loss:  0.19373758137226105\n",
      "Eval Loss:  0.1919618397951126\n",
      "Eval Loss:  0.2776140868663788\n",
      "Eval Loss:  0.37934643030166626\n",
      "Eval Loss:  0.17092323303222656\n",
      "Eval Loss:  0.2443496435880661\n",
      "Eval Loss:  0.2642994821071625\n",
      "Eval Loss:  0.2562773525714874\n",
      "Eval Loss:  0.22542518377304077\n",
      "Eval Loss:  0.29735350608825684\n",
      "[[17892   842]\n",
      " [ 2026  9037]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18734\n",
      "           1       0.91      0.82      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.89      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9037486995335101\n",
      "pre:  0.9147687012855552\n",
      "rec:  0.8168670342583386\n",
      "ma F1:  0.8944248853243821\n",
      "mi F1:  0.9037486995335101\n",
      "we F1:  0.9025020144941416\n",
      "29797 466\n",
      "Loss:  0.05673487111926079\n",
      "Loss:  0.04471179097890854\n",
      "Loss:  0.049272648990154266\n",
      "42 **********\n",
      "Epoch:  2360.9921867847443  fold:  2  kers:  32\n",
      "epoch:  43\n",
      "29797 466\n",
      "Loss:  0.0768340602517128\n",
      "Loss:  0.08341357111930847\n",
      "Loss:  0.036571186035871506\n",
      "43 **********\n",
      "Epoch:  2402.819349527359  fold:  2  kers:  32\n",
      "epoch:  44\n",
      "29797 466\n",
      "Loss:  0.07702914625406265\n",
      "Loss:  0.07179837673902512\n",
      "Loss:  0.07240895181894302\n",
      "44 **********\n",
      "Epoch:  2444.6155948638916  fold:  2  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.6776116490364075\n",
      "Eval Loss:  0.151655912399292\n",
      "Eval Loss:  1.6932497024536133\n",
      "[[1276  154]\n",
      " [ 796  868]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.89      0.73      1430\n",
      "           1       0.85      0.52      0.65      1664\n",
      "\n",
      "    accuracy                           0.69      3094\n",
      "   macro avg       0.73      0.71      0.69      3094\n",
      "weighted avg       0.74      0.69      0.68      3094\n",
      "\n",
      "acc:  0.6929541047188106\n",
      "pre:  0.8493150684931506\n",
      "rec:  0.5216346153846154\n",
      "ma F1:  0.6875203319622061\n",
      "mi F1:  0.6929541047188106\n",
      "we F1:  0.6844039034694475\n",
      "Eval Loss:  0.39581361413002014\n",
      "Eval Loss:  0.3540154993534088\n",
      "Eval Loss:  0.25613486766815186\n",
      "Eval Loss:  0.16067729890346527\n",
      "Eval Loss:  0.3325575590133667\n",
      "Eval Loss:  0.31560224294662476\n",
      "Eval Loss:  0.4567323625087738\n",
      "Eval Loss:  0.2906711995601654\n",
      "Eval Loss:  0.28752008080482483\n",
      "Eval Loss:  0.19991259276866913\n",
      "Eval Loss:  0.16809715330600739\n",
      "Eval Loss:  0.310431569814682\n",
      "Eval Loss:  0.3429640233516693\n",
      "Eval Loss:  0.4119247794151306\n",
      "Eval Loss:  0.2806451916694641\n",
      "Eval Loss:  0.3396695852279663\n",
      "Eval Loss:  0.2858875095844269\n",
      "Eval Loss:  0.3237220346927643\n",
      "Eval Loss:  0.27407923340797424\n",
      "Eval Loss:  0.19741664826869965\n",
      "Eval Loss:  0.2576674818992615\n",
      "Eval Loss:  0.3119073808193207\n",
      "Eval Loss:  0.42497149109840393\n",
      "Eval Loss:  0.2073334902524948\n",
      "Eval Loss:  0.3039921820163727\n",
      "Eval Loss:  0.3385440707206726\n",
      "Eval Loss:  0.3056262731552124\n",
      "Eval Loss:  0.27095338702201843\n",
      "Eval Loss:  0.38060781359672546\n",
      "[[18147   587]\n",
      " [ 2721  8342]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     18734\n",
      "           1       0.93      0.75      0.83     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.90      0.86      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8889821122931839\n",
      "pre:  0.9342591555605331\n",
      "rec:  0.7540450149145801\n",
      "ma F1:  0.8755013393671189\n",
      "mi F1:  0.8889821122931838\n",
      "we F1:  0.8860481021530286\n",
      "29797 466\n",
      "Loss:  0.01932494342327118\n",
      "Loss:  0.09254549443721771\n",
      "Loss:  0.041621752083301544\n",
      "45 **********\n",
      "Epoch:  2525.6389548778534  fold:  2  kers:  32\n",
      "epoch:  46\n",
      "29797 466\n",
      "Loss:  0.04350370913743973\n",
      "Loss:  0.03922275826334953\n",
      "Loss:  0.04196558892726898\n",
      "46 **********\n",
      "Epoch:  2567.384336709976  fold:  2  kers:  32\n",
      "epoch:  47\n",
      "29797 466\n",
      "Loss:  0.07887212187051773\n",
      "Loss:  0.06601043045520782\n",
      "Loss:  0.0489095002412796\n",
      "47 **********\n",
      "Epoch:  2609.2224695682526  fold:  2  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.698013424873352\n",
      "Eval Loss:  0.22922803461551666\n",
      "Eval Loss:  1.2206307649612427\n",
      "[[1249  181]\n",
      " [ 703  961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74      1430\n",
      "           1       0.84      0.58      0.68      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.74      0.73      0.71      3094\n",
      "weighted avg       0.75      0.71      0.71      3094\n",
      "\n",
      "acc:  0.7142857142857143\n",
      "pre:  0.841506129597198\n",
      "rec:  0.5775240384615384\n",
      "ma F1:  0.7117885008596515\n",
      "mi F1:  0.7142857142857143\n",
      "we F1:  0.7097595149509756\n",
      "Eval Loss:  0.32054460048675537\n",
      "Eval Loss:  0.27858585119247437\n",
      "Eval Loss:  0.23986080288887024\n",
      "Eval Loss:  0.14991702139377594\n",
      "Eval Loss:  0.25454869866371155\n",
      "Eval Loss:  0.20429280400276184\n",
      "Eval Loss:  0.3264557719230652\n",
      "Eval Loss:  0.24591627717018127\n",
      "Eval Loss:  0.21536239981651306\n",
      "Eval Loss:  0.17924627661705017\n",
      "Eval Loss:  0.14235055446624756\n",
      "Eval Loss:  0.25876203179359436\n",
      "Eval Loss:  0.3179706037044525\n",
      "Eval Loss:  0.3817175626754761\n",
      "Eval Loss:  0.23670533299446106\n",
      "Eval Loss:  0.30069682002067566\n",
      "Eval Loss:  0.20809154212474823\n",
      "Eval Loss:  0.25910288095474243\n",
      "Eval Loss:  0.21017228066921234\n",
      "Eval Loss:  0.15011173486709595\n",
      "Eval Loss:  0.20654058456420898\n",
      "Eval Loss:  0.2674601972103119\n",
      "Eval Loss:  0.3999468982219696\n",
      "Eval Loss:  0.17662730813026428\n",
      "Eval Loss:  0.23049597442150116\n",
      "Eval Loss:  0.26184073090553284\n",
      "Eval Loss:  0.24559839069843292\n",
      "Eval Loss:  0.2459850013256073\n",
      "Eval Loss:  0.28661829233169556\n",
      "[[18035   699]\n",
      " [ 2140  8923]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     18734\n",
      "           1       0.93      0.81      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.88      0.89     29797\n",
      "weighted avg       0.91      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9047219518743498\n",
      "pre:  0.9273539804614426\n",
      "rec:  0.8065624152580674\n",
      "ma F1:  0.8948928309215681\n",
      "mi F1:  0.9047219518743498\n",
      "we F1:  0.9031675441380727\n",
      "29797 466\n",
      "Loss:  0.041497811675071716\n",
      "Loss:  0.06616611033678055\n",
      "Loss:  0.03898829594254494\n",
      "48 **********\n",
      "Epoch:  2690.045365333557  fold:  2  kers:  32\n",
      "epoch:  49\n",
      "29797 466\n",
      "Loss:  0.05745100602507591\n",
      "Loss:  0.04394299536943436\n",
      "Loss:  0.056467656046152115\n",
      "49 **********\n",
      "Epoch:  2731.7857604026794  fold:  2  kers:  32\n",
      "epoch:  50\n",
      "29797 466\n",
      "Loss:  0.07000713050365448\n",
      "Loss:  0.0700053796172142\n",
      "Loss:  0.058377914130687714\n",
      "50 **********\n",
      "Epoch:  2773.5510878562927  fold:  2  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.5378772616386414\n",
      "Eval Loss:  0.16597247123718262\n",
      "Eval Loss:  0.7354071140289307\n",
      "[[1274  156]\n",
      " [ 661 1003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.89      0.76      1430\n",
      "           1       0.87      0.60      0.71      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.76      0.75      0.73      3094\n",
      "weighted avg       0.77      0.74      0.73      3094\n",
      "\n",
      "acc:  0.7359405300581772\n",
      "pre:  0.8654012079378774\n",
      "rec:  0.6027644230769231\n",
      "ma F1:  0.7338990535713064\n",
      "mi F1:  0.7359405300581772\n",
      "we F1:  0.7321363026564438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2962251901626587\n",
      "Eval Loss:  0.2739062011241913\n",
      "Eval Loss:  0.22992680966854095\n",
      "Eval Loss:  0.1558467149734497\n",
      "Eval Loss:  0.2575419545173645\n",
      "Eval Loss:  0.21384580433368683\n",
      "Eval Loss:  0.32079195976257324\n",
      "Eval Loss:  0.25265663862228394\n",
      "Eval Loss:  0.19805186986923218\n",
      "Eval Loss:  0.17074595391750336\n",
      "Eval Loss:  0.13005276024341583\n",
      "Eval Loss:  0.2385290414094925\n",
      "Eval Loss:  0.3127734661102295\n",
      "Eval Loss:  0.3629400432109833\n",
      "Eval Loss:  0.25430530309677124\n",
      "Eval Loss:  0.30678021907806396\n",
      "Eval Loss:  0.20735390484333038\n",
      "Eval Loss:  0.26614072918891907\n",
      "Eval Loss:  0.21234305202960968\n",
      "Eval Loss:  0.16430702805519104\n",
      "Eval Loss:  0.19963164627552032\n",
      "Eval Loss:  0.2645293176174164\n",
      "Eval Loss:  0.4029664695262909\n",
      "Eval Loss:  0.18843665719032288\n",
      "Eval Loss:  0.2359585016965866\n",
      "Eval Loss:  0.2418816089630127\n",
      "Eval Loss:  0.2246345579624176\n",
      "Eval Loss:  0.23466856777668\n",
      "Eval Loss:  0.274077445268631\n",
      "[[18124   610]\n",
      " [ 2186  8877]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     18734\n",
      "           1       0.94      0.80      0.86     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.88      0.90     29797\n",
      "weighted avg       0.91      0.91      0.90     29797\n",
      "\n",
      "acc:  0.9061650501728362\n",
      "pre:  0.9357014862443344\n",
      "rec:  0.8024044111000632\n",
      "ma F1:  0.8961650453129055\n",
      "mi F1:  0.9061650501728362\n",
      "we F1:  0.9044607128029595\n",
      "29797 466\n",
      "Loss:  0.040651462972164154\n",
      "Loss:  0.06209899112582207\n",
      "Loss:  0.06447558104991913\n",
      "51 **********\n",
      "Epoch:  2854.547520160675  fold:  2  kers:  32\n",
      "epoch:  52\n",
      "29797 466\n",
      "Loss:  0.07620850205421448\n",
      "Loss:  0.02881859615445137\n",
      "Loss:  0.047102149575948715\n",
      "52 **********\n",
      "Epoch:  2896.3018774986267  fold:  2  kers:  32\n",
      "epoch:  53\n",
      "29797 466\n",
      "Loss:  0.06714366376399994\n",
      "Loss:  0.05092006176710129\n",
      "Loss:  0.07473554462194443\n",
      "53 **********\n",
      "Epoch:  2938.0233228206635  fold:  2  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.4847496747970581\n",
      "Eval Loss:  0.17372827231884003\n",
      "Eval Loss:  0.7547350525856018\n",
      "[[1254  176]\n",
      " [ 588 1076]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77      1430\n",
      "           1       0.86      0.65      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.77      0.76      0.75      3094\n",
      "weighted avg       0.78      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7530704589528119\n",
      "pre:  0.8594249201277955\n",
      "rec:  0.6466346153846154\n",
      "ma F1:  0.7522504619987189\n",
      "mi F1:  0.7530704589528119\n",
      "we F1:  0.7511724884747987\n",
      "update!  Acc:  0.7530704589528119\n",
      "Eval Loss:  0.28547078371047974\n",
      "Eval Loss:  0.3029588758945465\n",
      "Eval Loss:  0.24482621252536774\n",
      "Eval Loss:  0.1453789472579956\n",
      "Eval Loss:  0.2627526521682739\n",
      "Eval Loss:  0.22745557129383087\n",
      "Eval Loss:  0.3498533070087433\n",
      "Eval Loss:  0.2428983449935913\n",
      "Eval Loss:  0.23129664361476898\n",
      "Eval Loss:  0.17819803953170776\n",
      "Eval Loss:  0.12149691581726074\n",
      "Eval Loss:  0.2641959488391876\n",
      "Eval Loss:  0.3115234673023224\n",
      "Eval Loss:  0.3760870695114136\n",
      "Eval Loss:  0.23632843792438507\n",
      "Eval Loss:  0.28391727805137634\n",
      "Eval Loss:  0.21245764195919037\n",
      "Eval Loss:  0.27429816126823425\n",
      "Eval Loss:  0.18664252758026123\n",
      "Eval Loss:  0.18247631192207336\n",
      "Eval Loss:  0.20230340957641602\n",
      "Eval Loss:  0.26476845145225525\n",
      "Eval Loss:  0.3421248197555542\n",
      "Eval Loss:  0.18559546768665314\n",
      "Eval Loss:  0.27693793177604675\n",
      "Eval Loss:  0.24331088364124298\n",
      "Eval Loss:  0.21538284420967102\n",
      "Eval Loss:  0.23541423678398132\n",
      "Eval Loss:  0.2916390001773834\n",
      "[[18032   702]\n",
      " [ 2124  8939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     18734\n",
      "           1       0.93      0.81      0.86     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.89      0.90     29797\n",
      "weighted avg       0.91      0.91      0.90     29797\n",
      "\n",
      "acc:  0.9051582374064503\n",
      "pre:  0.9271859765584483\n",
      "rec:  0.8080086775738949\n",
      "ma F1:  0.8954190707710845\n",
      "mi F1:  0.9051582374064503\n",
      "we F1:  0.9036351872628794\n",
      "29797 466\n",
      "Loss:  0.049321699887514114\n",
      "Loss:  0.04970986023545265\n",
      "Loss:  0.04711606726050377\n",
      "54 **********\n",
      "Epoch:  3018.793360233307  fold:  2  kers:  32\n",
      "epoch:  55\n",
      "29797 466\n",
      "Loss:  0.04989643022418022\n",
      "Loss:  0.05404932424426079\n",
      "Loss:  0.05871773883700371\n",
      "55 **********\n",
      "Epoch:  3060.464938879013  fold:  2  kers:  32\n",
      "epoch:  56\n",
      "29797 466\n",
      "Loss:  0.050424590706825256\n",
      "Loss:  0.06016051396727562\n",
      "Loss:  0.06921882927417755\n",
      "56 **********\n",
      "Epoch:  3102.1953604221344  fold:  2  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.5391274094581604\n",
      "Eval Loss:  0.1593644618988037\n",
      "Eval Loss:  0.8932161927223206\n",
      "[[1274  156]\n",
      " [ 668  996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.89      0.76      1430\n",
      "           1       0.86      0.60      0.71      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.76      0.74      0.73      3094\n",
      "weighted avg       0.77      0.73      0.73      3094\n",
      "\n",
      "acc:  0.733678086619263\n",
      "pre:  0.8645833333333334\n",
      "rec:  0.5985576923076923\n",
      "ma F1:  0.7315105009166397\n",
      "mi F1:  0.7336780866192631\n",
      "we F1:  0.7296859863324171\n",
      "Eval Loss:  0.35415202379226685\n",
      "Eval Loss:  0.3144818842411041\n",
      "Eval Loss:  0.2465575933456421\n",
      "Eval Loss:  0.15154846012592316\n",
      "Eval Loss:  0.29881197214126587\n",
      "Eval Loss:  0.2539787292480469\n",
      "Eval Loss:  0.39620453119277954\n",
      "Eval Loss:  0.2488907277584076\n",
      "Eval Loss:  0.25137028098106384\n",
      "Eval Loss:  0.18028345704078674\n",
      "Eval Loss:  0.14529068768024445\n",
      "Eval Loss:  0.2741861939430237\n",
      "Eval Loss:  0.3255486488342285\n",
      "Eval Loss:  0.3778627812862396\n",
      "Eval Loss:  0.24320265650749207\n",
      "Eval Loss:  0.29481539130210876\n",
      "Eval Loss:  0.24744851887226105\n",
      "Eval Loss:  0.294087290763855\n",
      "Eval Loss:  0.2211025357246399\n",
      "Eval Loss:  0.21306061744689941\n",
      "Eval Loss:  0.22212864458560944\n",
      "Eval Loss:  0.27438321709632874\n",
      "Eval Loss:  0.3715693950653076\n",
      "Eval Loss:  0.20264479517936707\n",
      "Eval Loss:  0.2847791910171509\n",
      "Eval Loss:  0.28365465998649597\n",
      "Eval Loss:  0.24597850441932678\n",
      "Eval Loss:  0.25070104002952576\n",
      "Eval Loss:  0.33263474702835083\n",
      "[[18164   570]\n",
      " [ 2431  8632]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18734\n",
      "           1       0.94      0.78      0.85     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.87      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.899285162935866\n",
      "pre:  0.9380569441425777\n",
      "rec:  0.7802585193889542\n",
      "ma F1:  0.8878035735874426\n",
      "mi F1:  0.899285162935866\n",
      "we F1:  0.8970435307728974\n",
      "29797 466\n",
      "Loss:  0.061359185725450516\n",
      "Loss:  0.07006091624498367\n",
      "Loss:  0.09329540282487869\n",
      "57 **********\n",
      "Epoch:  3183.100037574768  fold:  2  kers:  32\n",
      "epoch:  58\n",
      "29797 466\n",
      "Loss:  0.050151098519563675\n",
      "Loss:  0.04477488994598389\n",
      "Loss:  0.06475339829921722\n",
      "58 **********\n",
      "Epoch:  3224.812507390976  fold:  2  kers:  32\n",
      "epoch:  59\n",
      "29797 466\n",
      "Loss:  0.06658831238746643\n",
      "Loss:  0.07880302518606186\n",
      "Loss:  0.055992431938648224\n",
      "59 **********\n",
      "Epoch:  3266.445189476013  fold:  2  kers:  32\n",
      "Eval Loss:  0.676792323589325\n",
      "Eval Loss:  0.16004785895347595\n",
      "Eval Loss:  0.9214809536933899\n",
      "[[1273  157]\n",
      " [ 706  958]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.89      0.75      1430\n",
      "           1       0.86      0.58      0.69      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.75      0.73      0.72      3094\n",
      "weighted avg       0.76      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7210730446024564\n",
      "pre:  0.8591928251121076\n",
      "rec:  0.5757211538461539\n",
      "ma F1:  0.7181516108271704\n",
      "mi F1:  0.7210730446024564\n",
      "we F1:  0.715981402879815\n",
      "update!  Acc:  0.7530704589528119\n",
      "Epoch:  3270.133328437805  fold:  2  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.16904552280902863\n",
      "Loss:  0.1678466647863388\n",
      "Loss:  0.16154809296131134\n",
      "0 **********\n",
      "Epoch:  53.648555517196655  fold:  3  kers:  32\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.15176954865455627\n",
      "Loss:  0.13773959875106812\n",
      "Loss:  0.11924781650304794\n",
      "1 **********\n",
      "Epoch:  95.00298142433167  fold:  3  kers:  32\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.13498981297016144\n",
      "Loss:  0.11560997366905212\n",
      "Loss:  0.09939704090356827\n",
      "2 **********\n",
      "Epoch:  136.3374617099762  fold:  3  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.6072984337806702\n",
      "Eval Loss:  0.6111474633216858\n",
      "Eval Loss:  0.3992127478122711\n",
      "[[1127  409]\n",
      " [ 337 1558]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      1536\n",
      "           1       0.79      0.82      0.81      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.78      0.78      3431\n",
      "weighted avg       0.78      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7825706791023025\n",
      "pre:  0.7920691408235893\n",
      "rec:  0.8221635883905013\n",
      "ma F1:  0.7790845848437771\n",
      "mi F1:  0.7825706791023025\n",
      "we F1:  0.7819883153282565\n",
      "update!  Acc:  0.7825706791023025\n",
      "Eval Loss:  0.3889365494251251\n",
      "Eval Loss:  0.4625382721424103\n",
      "Eval Loss:  0.40720266103744507\n",
      "Eval Loss:  0.48954254388809204\n",
      "Eval Loss:  0.39103963971138\n",
      "Eval Loss:  0.4917234182357788\n",
      "Eval Loss:  0.32861462235450745\n",
      "Eval Loss:  0.5147278308868408\n",
      "Eval Loss:  0.32978305220603943\n",
      "Eval Loss:  0.46404093503952026\n",
      "Eval Loss:  0.3479548394680023\n",
      "Eval Loss:  0.38549232482910156\n",
      "Eval Loss:  0.3620888292789459\n",
      "Eval Loss:  0.4386719763278961\n",
      "Eval Loss:  0.4033522307872772\n",
      "Eval Loss:  0.45024895668029785\n",
      "Eval Loss:  0.35262227058410645\n",
      "Eval Loss:  0.4578592777252197\n",
      "Eval Loss:  0.4739378094673157\n",
      "Eval Loss:  0.43192219734191895\n",
      "Eval Loss:  0.4900662899017334\n",
      "Eval Loss:  0.4141538739204407\n",
      "Eval Loss:  0.39282166957855225\n",
      "Eval Loss:  0.37102800607681274\n",
      "Eval Loss:  0.3945629298686981\n",
      "Eval Loss:  0.40079745650291443\n",
      "Eval Loss:  0.49151813983917236\n",
      "Eval Loss:  0.4044259190559387\n",
      "[[14824  3804]\n",
      " [ 1928  8904]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84     18628\n",
      "           1       0.70      0.82      0.76     10832\n",
      "\n",
      "    accuracy                           0.81     29460\n",
      "   macro avg       0.79      0.81      0.80     29460\n",
      "weighted avg       0.82      0.81      0.81     29460\n",
      "\n",
      "acc:  0.8054310930074677\n",
      "pre:  0.7006610009442871\n",
      "rec:  0.8220088626292467\n",
      "ma F1:  0.7972435693932078\n",
      "mi F1:  0.8054310930074677\n",
      "we F1:  0.8080256528555002\n",
      "29460 461\n",
      "Loss:  0.09521093219518661\n",
      "Loss:  0.08857367932796478\n",
      "Loss:  0.08707503974437714\n",
      "3 **********\n",
      "Epoch:  217.1643466949463  fold:  3  kers:  32\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.10788175463676453\n",
      "Loss:  0.11806055158376694\n",
      "Loss:  0.0802900567650795\n",
      "4 **********\n",
      "Epoch:  258.59955739974976  fold:  3  kers:  32\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.10290396958589554\n",
      "Loss:  0.09286098182201385\n",
      "Loss:  0.08496762812137604\n",
      "5 **********\n",
      "Epoch:  300.07166934013367  fold:  3  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.8846369385719299\n",
      "Eval Loss:  0.5827562212944031\n",
      "Eval Loss:  0.5345843434333801\n",
      "[[1349  187]\n",
      " [ 592 1303]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78      1536\n",
      "           1       0.87      0.69      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.78      0.77      3431\n",
      "weighted avg       0.79      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7729524919848441\n",
      "pre:  0.874496644295302\n",
      "rec:  0.687598944591029\n",
      "ma F1:  0.7729116723571527\n",
      "mi F1:  0.7729524919848441\n",
      "we F1:  0.7725931017845176\n",
      "Eval Loss:  0.29276373982429504\n",
      "Eval Loss:  0.3722648024559021\n",
      "Eval Loss:  0.34388622641563416\n",
      "Eval Loss:  0.4489266872406006\n",
      "Eval Loss:  0.38153859972953796\n",
      "Eval Loss:  0.4249889850616455\n",
      "Eval Loss:  0.23288539052009583\n",
      "Eval Loss:  0.4506068527698517\n",
      "Eval Loss:  0.252485454082489\n",
      "Eval Loss:  0.45683062076568604\n",
      "Eval Loss:  0.29290786385536194\n",
      "Eval Loss:  0.35852909088134766\n",
      "Eval Loss:  0.3446742296218872\n",
      "Eval Loss:  0.32544222474098206\n",
      "Eval Loss:  0.3904053270816803\n",
      "Eval Loss:  0.387876033782959\n",
      "Eval Loss:  0.33400464057922363\n",
      "Eval Loss:  0.35528844594955444\n",
      "Eval Loss:  0.4490780830383301\n",
      "Eval Loss:  0.35419243574142456\n",
      "Eval Loss:  0.43936237692832947\n",
      "Eval Loss:  0.332326740026474\n",
      "Eval Loss:  0.361870676279068\n",
      "Eval Loss:  0.2886815667152405\n",
      "Eval Loss:  0.3812943696975708\n",
      "Eval Loss:  0.3150772452354431\n",
      "Eval Loss:  0.4223826825618744\n",
      "Eval Loss:  0.4232702851295471\n",
      "[[17213  1415]\n",
      " [ 2977  7855]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89     18628\n",
      "           1       0.85      0.73      0.78     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.85      0.82      0.83     29460\n",
      "weighted avg       0.85      0.85      0.85     29460\n",
      "\n",
      "acc:  0.8509164969450101\n",
      "pre:  0.8473570658036678\n",
      "rec:  0.7251661742983752\n",
      "ma F1:  0.8341854450489427\n",
      "mi F1:  0.8509164969450101\n",
      "we F1:  0.8481238165579982\n",
      "29460 461\n",
      "Loss:  0.09484612196683884\n",
      "Loss:  0.11684747785329819\n",
      "Loss:  0.09267739206552505\n",
      "6 **********\n",
      "Epoch:  380.7619204521179  fold:  3  kers:  32\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.12491077184677124\n",
      "Loss:  0.114153653383255\n",
      "Loss:  0.07054933905601501\n",
      "7 **********\n",
      "Epoch:  422.24400544166565  fold:  3  kers:  32\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.0744205042719841\n",
      "Loss:  0.09619402140378952\n",
      "Loss:  0.07502737641334534\n",
      "8 **********\n",
      "Epoch:  463.63832545280457  fold:  3  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  1.0300670862197876\n",
      "Eval Loss:  0.7136303186416626\n",
      "Eval Loss:  0.6505118608474731\n",
      "[[1414  122]\n",
      " [ 720 1175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.92      0.77      1536\n",
      "           1       0.91      0.62      0.74      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.77      0.75      3431\n",
      "weighted avg       0.80      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7545904983969688\n",
      "pre:  0.9059367771781033\n",
      "rec:  0.6200527704485488\n",
      "ma F1:  0.7533938729657932\n",
      "mi F1:  0.7545904983969688\n",
      "we F1:  0.7515964314185463\n",
      "Eval Loss:  0.33952099084854126\n",
      "Eval Loss:  0.37770530581474304\n",
      "Eval Loss:  0.37329086661338806\n",
      "Eval Loss:  0.4611194133758545\n",
      "Eval Loss:  0.44239258766174316\n",
      "Eval Loss:  0.4242696762084961\n",
      "Eval Loss:  0.2337048351764679\n",
      "Eval Loss:  0.4796144366264343\n",
      "Eval Loss:  0.28050532937049866\n",
      "Eval Loss:  0.5073758363723755\n",
      "Eval Loss:  0.29939329624176025\n",
      "Eval Loss:  0.38661670684814453\n",
      "Eval Loss:  0.3867446482181549\n",
      "Eval Loss:  0.31408312916755676\n",
      "Eval Loss:  0.43827304244041443\n",
      "Eval Loss:  0.39812684059143066\n",
      "Eval Loss:  0.3539797365665436\n",
      "Eval Loss:  0.3739375174045563\n",
      "Eval Loss:  0.5055649280548096\n",
      "Eval Loss:  0.3863251805305481\n",
      "Eval Loss:  0.4682835340499878\n",
      "Eval Loss:  0.345525324344635\n",
      "Eval Loss:  0.39955398440361023\n",
      "Eval Loss:  0.31348246335983276\n",
      "Eval Loss:  0.43479353189468384\n",
      "Eval Loss:  0.29744240641593933\n",
      "Eval Loss:  0.43556883931159973\n",
      "Eval Loss:  0.48505493998527527\n",
      "[[17860   768]\n",
      " [ 3653  7179]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18628\n",
      "           1       0.90      0.66      0.76     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.87      0.81      0.83     29460\n",
      "weighted avg       0.86      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8499321113374066\n",
      "pre:  0.903359758399396\n",
      "rec:  0.662758493353028\n",
      "ma F1:  0.8272203428226752\n",
      "mi F1:  0.8499321113374066\n",
      "we F1:  0.8437975310392135\n",
      "29460 461\n",
      "Loss:  0.08965863287448883\n",
      "Loss:  0.09085846692323685\n",
      "Loss:  0.09733935445547104\n",
      "9 **********\n",
      "Epoch:  544.42631483078  fold:  3  kers:  32\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.09715661406517029\n",
      "Loss:  0.11844658106565475\n",
      "Loss:  0.09554900974035263\n",
      "10 **********\n",
      "Epoch:  585.731871843338  fold:  3  kers:  32\n",
      "epoch:  11\n",
      "29460 461\n",
      "Loss:  0.11170066893100739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06195200979709625\n",
      "Loss:  0.11600379645824432\n",
      "11 **********\n",
      "Epoch:  627.1062457561493  fold:  3  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.6819725036621094\n",
      "Eval Loss:  0.3935692608356476\n",
      "Eval Loss:  0.643991231918335\n",
      "[[1318  218]\n",
      " [ 551 1344]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.77      1536\n",
      "           1       0.86      0.71      0.78      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.78      0.78      3431\n",
      "weighted avg       0.79      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7758670941416497\n",
      "pre:  0.8604353393085787\n",
      "rec:  0.7092348284960422\n",
      "ma F1:  0.7758542224442352\n",
      "mi F1:  0.7758670941416497\n",
      "we F1:  0.7760319508816121\n",
      "Eval Loss:  0.2592524588108063\n",
      "Eval Loss:  0.3034704625606537\n",
      "Eval Loss:  0.3143666982650757\n",
      "Eval Loss:  0.3546384871006012\n",
      "Eval Loss:  0.36798423528671265\n",
      "Eval Loss:  0.3513020873069763\n",
      "Eval Loss:  0.17360690236091614\n",
      "Eval Loss:  0.3995211124420166\n",
      "Eval Loss:  0.18714211881160736\n",
      "Eval Loss:  0.39442527294158936\n",
      "Eval Loss:  0.2618110775947571\n",
      "Eval Loss:  0.3119797706604004\n",
      "Eval Loss:  0.299750953912735\n",
      "Eval Loss:  0.26376861333847046\n",
      "Eval Loss:  0.3376293182373047\n",
      "Eval Loss:  0.3221369683742523\n",
      "Eval Loss:  0.298348069190979\n",
      "Eval Loss:  0.3326961100101471\n",
      "Eval Loss:  0.42709705233573914\n",
      "Eval Loss:  0.3321055471897125\n",
      "Eval Loss:  0.3257092237472534\n",
      "Eval Loss:  0.29399535059928894\n",
      "Eval Loss:  0.3393847644329071\n",
      "Eval Loss:  0.2516936659812927\n",
      "Eval Loss:  0.32851043343544006\n",
      "Eval Loss:  0.21540316939353943\n",
      "Eval Loss:  0.3323971629142761\n",
      "Eval Loss:  0.4506823420524597\n",
      "[[17473  1155]\n",
      " [ 2531  8301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     18628\n",
      "           1       0.88      0.77      0.82     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.85      0.86     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8748811948404617\n",
      "pre:  0.8778553299492385\n",
      "rec:  0.7663404726735599\n",
      "ma F1:  0.8614515585222822\n",
      "mi F1:  0.8748811948404617\n",
      "we F1:  0.8728664565528673\n",
      "29460 461\n",
      "Loss:  0.08461357653141022\n",
      "Loss:  0.05269626900553703\n",
      "Loss:  0.09652741253376007\n",
      "12 **********\n",
      "Epoch:  707.8433706760406  fold:  3  kers:  32\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.07148916274309158\n",
      "Loss:  0.0881059393286705\n",
      "Loss:  0.1044851541519165\n",
      "13 **********\n",
      "Epoch:  749.2696053981781  fold:  3  kers:  32\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.08446364849805832\n",
      "Loss:  0.10942001640796661\n",
      "Loss:  0.0823715403676033\n",
      "14 **********\n",
      "Epoch:  790.596107006073  fold:  3  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.7533808946609497\n",
      "Eval Loss:  0.39270129799842834\n",
      "Eval Loss:  0.691624104976654\n",
      "[[1346  190]\n",
      " [ 581 1314]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78      1536\n",
      "           1       0.87      0.69      0.77      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.79      0.78      0.78      3431\n",
      "weighted avg       0.80      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7752841737102886\n",
      "pre:  0.8736702127659575\n",
      "rec:  0.6934036939313984\n",
      "ma F1:  0.7752646244665903\n",
      "mi F1:  0.7752841737102886\n",
      "we F1:  0.7750453063888508\n",
      "Eval Loss:  0.2661457359790802\n",
      "Eval Loss:  0.3113851249217987\n",
      "Eval Loss:  0.2854316532611847\n",
      "Eval Loss:  0.37026751041412354\n",
      "Eval Loss:  0.37363606691360474\n",
      "Eval Loss:  0.3408696949481964\n",
      "Eval Loss:  0.16489556431770325\n",
      "Eval Loss:  0.4043024182319641\n",
      "Eval Loss:  0.1873241811990738\n",
      "Eval Loss:  0.40721651911735535\n",
      "Eval Loss:  0.254619836807251\n",
      "Eval Loss:  0.32939451932907104\n",
      "Eval Loss:  0.31373536586761475\n",
      "Eval Loss:  0.24762706458568573\n",
      "Eval Loss:  0.3557639718055725\n",
      "Eval Loss:  0.3316272795200348\n",
      "Eval Loss:  0.29677194356918335\n",
      "Eval Loss:  0.32542669773101807\n",
      "Eval Loss:  0.4321236312389374\n",
      "Eval Loss:  0.33297184109687805\n",
      "Eval Loss:  0.3314513564109802\n",
      "Eval Loss:  0.3063828647136688\n",
      "Eval Loss:  0.3447358012199402\n",
      "Eval Loss:  0.2525787651538849\n",
      "Eval Loss:  0.33600354194641113\n",
      "Eval Loss:  0.19230850040912628\n",
      "Eval Loss:  0.3432997465133667\n",
      "Eval Loss:  0.44767501950263977\n",
      "[[17655   973]\n",
      " [ 2669  8163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18628\n",
      "           1       0.89      0.75      0.82     10832\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.88      0.85      0.86     29460\n",
      "weighted avg       0.88      0.88      0.87     29460\n",
      "\n",
      "acc:  0.8763747454175153\n",
      "pre:  0.8934982486865148\n",
      "rec:  0.7536004431314623\n",
      "ma F1:  0.8620542405741978\n",
      "mi F1:  0.8763747454175153\n",
      "we F1:  0.8738160037177399\n",
      "29460 461\n",
      "Loss:  0.08310502767562866\n",
      "Loss:  0.08556169271469116\n",
      "Loss:  0.05823015794157982\n",
      "15 **********\n",
      "Epoch:  871.2723948955536  fold:  3  kers:  32\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.06787100434303284\n",
      "Loss:  0.08632083237171173\n",
      "Loss:  0.09779761731624603\n",
      "16 **********\n",
      "Epoch:  912.5151200294495  fold:  3  kers:  32\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.05723332241177559\n",
      "Loss:  0.07572470605373383\n",
      "Loss:  0.06636922061443329\n",
      "17 **********\n",
      "Epoch:  953.7219414710999  fold:  3  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.7503587603569031\n",
      "Eval Loss:  0.39464154839515686\n",
      "Eval Loss:  0.7518905997276306\n",
      "[[1342  194]\n",
      " [ 595 1300]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77      1536\n",
      "           1       0.87      0.69      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.78      0.77      3431\n",
      "weighted avg       0.79      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7700378898280384\n",
      "pre:  0.8701472556894244\n",
      "rec:  0.6860158311345647\n",
      "ma F1:  0.770003424809709\n",
      "mi F1:  0.7700378898280384\n",
      "we F1:  0.7697088309625592\n",
      "Eval Loss:  0.29187527298927307\n",
      "Eval Loss:  0.32012879848480225\n",
      "Eval Loss:  0.2977239787578583\n",
      "Eval Loss:  0.3674841821193695\n",
      "Eval Loss:  0.374327152967453\n",
      "Eval Loss:  0.3449990749359131\n",
      "Eval Loss:  0.16264349222183228\n",
      "Eval Loss:  0.40282249450683594\n",
      "Eval Loss:  0.19742168486118317\n",
      "Eval Loss:  0.3835911154747009\n",
      "Eval Loss:  0.2559773623943329\n",
      "Eval Loss:  0.3291017711162567\n",
      "Eval Loss:  0.33610469102859497\n",
      "Eval Loss:  0.23778386414051056\n",
      "Eval Loss:  0.3639169931411743\n",
      "Eval Loss:  0.3418641686439514\n",
      "Eval Loss:  0.2841531038284302\n",
      "Eval Loss:  0.3272359371185303\n",
      "Eval Loss:  0.41323187947273254\n",
      "Eval Loss:  0.3233537971973419\n",
      "Eval Loss:  0.3577103614807129\n",
      "Eval Loss:  0.3099980354309082\n",
      "Eval Loss:  0.3581150770187378\n",
      "Eval Loss:  0.2505272924900055\n",
      "Eval Loss:  0.34633147716522217\n",
      "Eval Loss:  0.2103549838066101\n",
      "Eval Loss:  0.34133264422416687\n",
      "Eval Loss:  0.4413747489452362\n",
      "[[17748   880]\n",
      " [ 2850  7982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18628\n",
      "           1       0.90      0.74      0.81     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.84      0.86     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.873387644263408\n",
      "pre:  0.9006996163394267\n",
      "rec:  0.736890694239291\n",
      "ma F1:  0.8577561112699829\n",
      "mi F1:  0.873387644263408\n",
      "we F1:  0.8702344474584677\n",
      "29460 461\n",
      "Loss:  0.08149177581071854\n",
      "Loss:  0.056835874915122986\n",
      "Loss:  0.06793317943811417\n",
      "18 **********\n",
      "Epoch:  1034.4710347652435  fold:  3  kers:  32\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.0968058630824089\n",
      "Loss:  0.08225100487470627\n",
      "Loss:  0.0879882276058197\n",
      "19 **********\n",
      "Epoch:  1075.7696108818054  fold:  3  kers:  32\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.09100504219532013\n",
      "Loss:  0.07078983634710312\n",
      "Loss:  0.08325665444135666\n",
      "20 **********\n",
      "Epoch:  1117.0622026920319  fold:  3  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.5218325853347778\n",
      "Eval Loss:  0.28287214040756226\n",
      "Eval Loss:  0.7525589466094971\n",
      "[[1256  280]\n",
      " [ 488 1407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77      1536\n",
      "           1       0.83      0.74      0.79      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.78      0.78      3431\n",
      "weighted avg       0.78      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7761585543573303\n",
      "pre:  0.8340248962655602\n",
      "rec:  0.7424802110817942\n",
      "ma F1:  0.775724149201291\n",
      "mi F1:  0.7761585543573302\n",
      "we F1:  0.776756940267636\n",
      "Eval Loss:  0.24389763176441193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.26553091406822205\n",
      "Eval Loss:  0.28015536069869995\n",
      "Eval Loss:  0.3100005090236664\n",
      "Eval Loss:  0.34773606061935425\n",
      "Eval Loss:  0.32195523381233215\n",
      "Eval Loss:  0.13851667940616608\n",
      "Eval Loss:  0.35875001549720764\n",
      "Eval Loss:  0.15209926664829254\n",
      "Eval Loss:  0.3279167711734772\n",
      "Eval Loss:  0.26459288597106934\n",
      "Eval Loss:  0.27609366178512573\n",
      "Eval Loss:  0.2938447594642639\n",
      "Eval Loss:  0.25143370032310486\n",
      "Eval Loss:  0.29933232069015503\n",
      "Eval Loss:  0.2964143753051758\n",
      "Eval Loss:  0.26578059792518616\n",
      "Eval Loss:  0.31424933671951294\n",
      "Eval Loss:  0.37760505080223083\n",
      "Eval Loss:  0.29563358426094055\n",
      "Eval Loss:  0.28229373693466187\n",
      "Eval Loss:  0.2869720757007599\n",
      "Eval Loss:  0.3251742422580719\n",
      "Eval Loss:  0.24650906026363373\n",
      "Eval Loss:  0.2852979898452759\n",
      "Eval Loss:  0.1779453605413437\n",
      "Eval Loss:  0.2945995628833771\n",
      "Eval Loss:  0.4143313467502594\n",
      "[[17269  1359]\n",
      " [ 1991  8841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     18628\n",
      "           1       0.87      0.82      0.84     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.88      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8862864901561439\n",
      "pre:  0.866764705882353\n",
      "rec:  0.8161927621861153\n",
      "ma F1:  0.8761502039524072\n",
      "mi F1:  0.8862864901561439\n",
      "we F1:  0.8855263889600401\n",
      "29460 461\n",
      "Loss:  0.08412063866853714\n",
      "Loss:  0.08296778053045273\n",
      "Loss:  0.07696083933115005\n",
      "21 **********\n",
      "Epoch:  1197.3854353427887  fold:  3  kers:  32\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.07231107354164124\n",
      "Loss:  0.06415723264217377\n",
      "Loss:  0.07029473781585693\n",
      "22 **********\n",
      "Epoch:  1238.6122028827667  fold:  3  kers:  32\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.06931711733341217\n",
      "Loss:  0.04260771721601486\n",
      "Loss:  0.08799305558204651\n",
      "23 **********\n",
      "Epoch:  1279.7671627998352  fold:  3  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.8924557566642761\n",
      "Eval Loss:  0.3928944170475006\n",
      "Eval Loss:  0.8920583724975586\n",
      "[[1373  163]\n",
      " [ 654 1241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      1536\n",
      "           1       0.88      0.65      0.75      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.77      0.76      3431\n",
      "weighted avg       0.79      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7618770037889828\n",
      "pre:  0.8839031339031339\n",
      "rec:  0.6548812664907652\n",
      "ma F1:  0.7615240230052958\n",
      "mi F1:  0.7618770037889828\n",
      "we F1:  0.7605640222375412\n",
      "Eval Loss:  0.34839189052581787\n",
      "Eval Loss:  0.3336983323097229\n",
      "Eval Loss:  0.3149314224720001\n",
      "Eval Loss:  0.43372803926467896\n",
      "Eval Loss:  0.4146480858325958\n",
      "Eval Loss:  0.358969509601593\n",
      "Eval Loss:  0.16685952246189117\n",
      "Eval Loss:  0.4418397545814514\n",
      "Eval Loss:  0.22836825251579285\n",
      "Eval Loss:  0.39944589138031006\n",
      "Eval Loss:  0.26338985562324524\n",
      "Eval Loss:  0.3698745369911194\n",
      "Eval Loss:  0.39115384221076965\n",
      "Eval Loss:  0.25358301401138306\n",
      "Eval Loss:  0.38225263357162476\n",
      "Eval Loss:  0.39344149827957153\n",
      "Eval Loss:  0.3115246593952179\n",
      "Eval Loss:  0.3328869342803955\n",
      "Eval Loss:  0.43221426010131836\n",
      "Eval Loss:  0.3312721848487854\n",
      "Eval Loss:  0.40930283069610596\n",
      "Eval Loss:  0.3422759473323822\n",
      "Eval Loss:  0.3774183392524719\n",
      "Eval Loss:  0.2743285596370697\n",
      "Eval Loss:  0.386901319026947\n",
      "Eval Loss:  0.22701509296894073\n",
      "Eval Loss:  0.3732357621192932\n",
      "Eval Loss:  0.4791969954967499\n",
      "[[18062   566]\n",
      " [ 3442  7390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     18628\n",
      "           1       0.93      0.68      0.79     10832\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.88      0.83      0.84     29460\n",
      "weighted avg       0.87      0.86      0.86     29460\n",
      "\n",
      "acc:  0.8639511201629327\n",
      "pre:  0.9288587229763701\n",
      "rec:  0.6822378138847858\n",
      "ma F1:  0.8434009582302184\n",
      "mi F1:  0.8639511201629326\n",
      "we F1:  0.8584130517860131\n",
      "29460 461\n",
      "Loss:  0.05129716917872429\n",
      "Loss:  0.0464494563639164\n",
      "Loss:  0.04166652262210846\n",
      "24 **********\n",
      "Epoch:  1360.3836104869843  fold:  3  kers:  32\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.10513484477996826\n",
      "Loss:  0.0774068534374237\n",
      "Loss:  0.06029621884226799\n",
      "25 **********\n",
      "Epoch:  1401.7400324344635  fold:  3  kers:  32\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.0852256491780281\n",
      "Loss:  0.09107093513011932\n",
      "Loss:  0.06981605291366577\n",
      "26 **********\n",
      "Epoch:  1443.0665335655212  fold:  3  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.5684234499931335\n",
      "Eval Loss:  0.25935062766075134\n",
      "Eval Loss:  0.9396767020225525\n",
      "[[1290  246]\n",
      " [ 564 1331]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1536\n",
      "           1       0.84      0.70      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7639172252987467\n",
      "pre:  0.844007609384908\n",
      "rec:  0.7023746701846966\n",
      "ma F1:  0.7638835080135393\n",
      "mi F1:  0.7639172252987467\n",
      "we F1:  0.7641787398523058\n",
      "Eval Loss:  0.27489638328552246\n",
      "Eval Loss:  0.26111793518066406\n",
      "Eval Loss:  0.28202953934669495\n",
      "Eval Loss:  0.350800484418869\n",
      "Eval Loss:  0.3663492202758789\n",
      "Eval Loss:  0.30028098821640015\n",
      "Eval Loss:  0.1285019963979721\n",
      "Eval Loss:  0.38992705941200256\n",
      "Eval Loss:  0.16110855340957642\n",
      "Eval Loss:  0.3108329772949219\n",
      "Eval Loss:  0.2332989126443863\n",
      "Eval Loss:  0.2912582457065582\n",
      "Eval Loss:  0.32886865735054016\n",
      "Eval Loss:  0.2169273942708969\n",
      "Eval Loss:  0.29912567138671875\n",
      "Eval Loss:  0.31377679109573364\n",
      "Eval Loss:  0.2712301015853882\n",
      "Eval Loss:  0.28955286741256714\n",
      "Eval Loss:  0.3480479419231415\n",
      "Eval Loss:  0.2899061441421509\n",
      "Eval Loss:  0.30503660440444946\n",
      "Eval Loss:  0.29999497532844543\n",
      "Eval Loss:  0.3289739489555359\n",
      "Eval Loss:  0.2458695024251938\n",
      "Eval Loss:  0.31552284955978394\n",
      "Eval Loss:  0.1763397455215454\n",
      "Eval Loss:  0.31044065952301025\n",
      "Eval Loss:  0.42088618874549866\n",
      "[[17717   911]\n",
      " [ 2477  8355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18628\n",
      "           1       0.90      0.77      0.83     10832\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.86      0.87     29460\n",
      "weighted avg       0.89      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8849966055668703\n",
      "pre:  0.9016835743578675\n",
      "rec:  0.7713257016248154\n",
      "ma F1:  0.872077953979342\n",
      "mi F1:  0.8849966055668703\n",
      "we F1:  0.8828356775187963\n",
      "29460 461\n",
      "Loss:  0.07457906752824783\n",
      "Loss:  0.03856322541832924\n",
      "Loss:  0.0612400621175766\n",
      "27 **********\n",
      "Epoch:  1523.7268640995026  fold:  3  kers:  32\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.05797765776515007\n",
      "Loss:  0.04574482887983322\n",
      "Loss:  0.06145525723695755\n",
      "28 **********\n",
      "Epoch:  1564.9925282001495  fold:  3  kers:  32\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.08018054813146591\n",
      "Loss:  0.07109113782644272\n",
      "Loss:  0.05370810627937317\n",
      "29 **********\n",
      "Epoch:  1606.3389763832092  fold:  3  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.6164796352386475\n",
      "Eval Loss:  0.26273295283317566\n",
      "Eval Loss:  1.0231159925460815\n",
      "[[1301  235]\n",
      " [ 597 1298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1536\n",
      "           1       0.85      0.68      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7575051005537744\n",
      "pre:  0.8467058056099152\n",
      "rec:  0.6849604221635884\n",
      "ma F1:  0.7575049151562147\n",
      "mi F1:  0.7575051005537744\n",
      "we F1:  0.7574827292482288\n",
      "Eval Loss:  0.27614906430244446\n",
      "Eval Loss:  0.2516665458679199\n",
      "Eval Loss:  0.2712653577327728\n",
      "Eval Loss:  0.35625141859054565\n",
      "Eval Loss:  0.387832909822464\n",
      "Eval Loss:  0.28447115421295166\n",
      "Eval Loss:  0.13508203625679016\n",
      "Eval Loss:  0.3986719846725464\n",
      "Eval Loss:  0.17570629715919495\n",
      "Eval Loss:  0.3122502863407135\n",
      "Eval Loss:  0.23050931096076965\n",
      "Eval Loss:  0.30266815423965454\n",
      "Eval Loss:  0.32973337173461914\n",
      "Eval Loss:  0.2294762283563614\n",
      "Eval Loss:  0.28916671872138977\n",
      "Eval Loss:  0.32414764165878296\n",
      "Eval Loss:  0.27049490809440613\n",
      "Eval Loss:  0.2829171121120453\n",
      "Eval Loss:  0.35267090797424316\n",
      "Eval Loss:  0.2947635054588318\n",
      "Eval Loss:  0.2910553216934204\n",
      "Eval Loss:  0.29682573676109314\n",
      "Eval Loss:  0.31229981780052185\n",
      "Eval Loss:  0.25184881687164307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.32465580105781555\n",
      "Eval Loss:  0.18087412416934967\n",
      "Eval Loss:  0.32313796877861023\n",
      "Eval Loss:  0.4299989640712738\n",
      "[[17892   736]\n",
      " [ 2669  8163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     18628\n",
      "           1       0.92      0.75      0.83     10832\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.86      0.87     29460\n",
      "weighted avg       0.89      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8844195519348269\n",
      "pre:  0.9172940779862906\n",
      "rec:  0.7536004431314623\n",
      "ma F1:  0.8702711463053907\n",
      "mi F1:  0.8844195519348269\n",
      "we F1:  0.8816084852186484\n",
      "29460 461\n",
      "Loss:  0.050472185015678406\n",
      "Loss:  0.0492902509868145\n",
      "Loss:  0.10286328941583633\n",
      "30 **********\n",
      "Epoch:  1686.7170615196228  fold:  3  kers:  32\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.05410153046250343\n",
      "Loss:  0.06721286475658417\n",
      "Loss:  0.06773002445697784\n",
      "31 **********\n",
      "Epoch:  1728.0605175495148  fold:  3  kers:  32\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.11771427094936371\n",
      "Loss:  0.07578989118337631\n",
      "Loss:  0.08497658371925354\n",
      "32 **********\n",
      "Epoch:  1769.2065014839172  fold:  3  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.46691596508026123\n",
      "Eval Loss:  0.2682136595249176\n",
      "Eval Loss:  1.1206533908843994\n",
      "[[1280  256]\n",
      " [ 566 1329]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.76      1536\n",
      "           1       0.84      0.70      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.76041970271058\n",
      "pre:  0.8384858044164037\n",
      "rec:  0.7013192612137203\n",
      "ma F1:  0.7603708273007198\n",
      "mi F1:  0.76041970271058\n",
      "we F1:  0.7607289144872462\n",
      "Eval Loss:  0.2682536840438843\n",
      "Eval Loss:  0.24383120238780975\n",
      "Eval Loss:  0.275956392288208\n",
      "Eval Loss:  0.3361714482307434\n",
      "Eval Loss:  0.380889356136322\n",
      "Eval Loss:  0.27851441502571106\n",
      "Eval Loss:  0.12992839515209198\n",
      "Eval Loss:  0.4049933850765228\n",
      "Eval Loss:  0.1437090039253235\n",
      "Eval Loss:  0.2563033401966095\n",
      "Eval Loss:  0.2326647788286209\n",
      "Eval Loss:  0.265790194272995\n",
      "Eval Loss:  0.31985971331596375\n",
      "Eval Loss:  0.20883841812610626\n",
      "Eval Loss:  0.2654173970222473\n",
      "Eval Loss:  0.3397454023361206\n",
      "Eval Loss:  0.26665496826171875\n",
      "Eval Loss:  0.2717595398426056\n",
      "Eval Loss:  0.3338438868522644\n",
      "Eval Loss:  0.2608312964439392\n",
      "Eval Loss:  0.30088531970977783\n",
      "Eval Loss:  0.28165552020072937\n",
      "Eval Loss:  0.30202800035476685\n",
      "Eval Loss:  0.24568644165992737\n",
      "Eval Loss:  0.3172336220741272\n",
      "Eval Loss:  0.17976120114326477\n",
      "Eval Loss:  0.3072827458381653\n",
      "Eval Loss:  0.4039374887943268\n",
      "[[17713   915]\n",
      " [ 2305  8527]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     18628\n",
      "           1       0.90      0.79      0.84     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8906992532247114\n",
      "pre:  0.9030925651345054\n",
      "rec:  0.7872045790251108\n",
      "ma F1:  0.8789277474595557\n",
      "mi F1:  0.8906992532247114\n",
      "we F1:  0.8889180216752268\n",
      "29460 461\n",
      "Loss:  0.07250771671533585\n",
      "Loss:  0.0643288865685463\n",
      "Loss:  0.0743839293718338\n",
      "33 **********\n",
      "Epoch:  1849.684319972992  fold:  3  kers:  32\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.08702123165130615\n",
      "Loss:  0.0851743295788765\n",
      "Loss:  0.0753278061747551\n",
      "34 **********\n",
      "Epoch:  1890.9230561256409  fold:  3  kers:  32\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.08858508616685867\n",
      "Loss:  0.05809420719742775\n",
      "Loss:  0.06063099578022957\n",
      "35 **********\n",
      "Epoch:  1932.1398508548737  fold:  3  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.42178452014923096\n",
      "Eval Loss:  0.18137937784194946\n",
      "Eval Loss:  1.0701290369033813\n",
      "[[1228  308]\n",
      " [ 503 1392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75      1536\n",
      "           1       0.82      0.73      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7636257650830661\n",
      "pre:  0.8188235294117647\n",
      "rec:  0.7345646437994723\n",
      "ma F1:  0.7630844628695179\n",
      "mi F1:  0.7636257650830661\n",
      "we F1:  0.7642693866174681\n",
      "Eval Loss:  0.20029038190841675\n",
      "Eval Loss:  0.20013287663459778\n",
      "Eval Loss:  0.2588908076286316\n",
      "Eval Loss:  0.28915250301361084\n",
      "Eval Loss:  0.3615979850292206\n",
      "Eval Loss:  0.2799853980541229\n",
      "Eval Loss:  0.1245044469833374\n",
      "Eval Loss:  0.33554691076278687\n",
      "Eval Loss:  0.1311335414648056\n",
      "Eval Loss:  0.2684122920036316\n",
      "Eval Loss:  0.23106878995895386\n",
      "Eval Loss:  0.2222054898738861\n",
      "Eval Loss:  0.24734653532505035\n",
      "Eval Loss:  0.21761633455753326\n",
      "Eval Loss:  0.23756086826324463\n",
      "Eval Loss:  0.2925764322280884\n",
      "Eval Loss:  0.24973264336585999\n",
      "Eval Loss:  0.2440817654132843\n",
      "Eval Loss:  0.28611961007118225\n",
      "Eval Loss:  0.257367879152298\n",
      "Eval Loss:  0.24188998341560364\n",
      "Eval Loss:  0.2685779929161072\n",
      "Eval Loss:  0.2722278833389282\n",
      "Eval Loss:  0.22336211800575256\n",
      "Eval Loss:  0.2560897469520569\n",
      "Eval Loss:  0.16712525486946106\n",
      "Eval Loss:  0.2736338973045349\n",
      "Eval Loss:  0.3789094388484955\n",
      "[[17408  1220]\n",
      " [ 1750  9082]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18628\n",
      "           1       0.88      0.84      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.8991853360488798\n",
      "pre:  0.881576392933411\n",
      "rec:  0.8384416543574594\n",
      "ma F1:  0.8904338078480961\n",
      "mi F1:  0.8991853360488798\n",
      "we F1:  0.8986282486183712\n",
      "29460 461\n",
      "Loss:  0.03510269150137901\n",
      "Loss:  0.046340327709913254\n",
      "Loss:  0.09100569784641266\n",
      "36 **********\n",
      "Epoch:  2012.5259146690369  fold:  3  kers:  32\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.06898292899131775\n",
      "Loss:  0.0556827113032341\n",
      "Loss:  0.06407230347394943\n",
      "37 **********\n",
      "Epoch:  2053.7068054676056  fold:  3  kers:  32\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.06344348937273026\n",
      "Loss:  0.04056721180677414\n",
      "Loss:  0.10141962766647339\n",
      "38 **********\n",
      "Epoch:  2094.908640384674  fold:  3  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.32435959577560425\n",
      "Eval Loss:  0.1828596442937851\n",
      "Eval Loss:  1.2141900062561035\n",
      "[[1216  320]\n",
      " [ 500 1395]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75      1536\n",
      "           1       0.81      0.74      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7610026231419411\n",
      "pre:  0.8134110787172012\n",
      "rec:  0.7361477572559367\n",
      "ma F1:  0.7603503320351763\n",
      "mi F1:  0.7610026231419411\n",
      "we F1:  0.7616585583331013\n",
      "Eval Loss:  0.2134205400943756\n",
      "Eval Loss:  0.20635288953781128\n",
      "Eval Loss:  0.2764616310596466\n",
      "Eval Loss:  0.29077646136283875\n",
      "Eval Loss:  0.3534759283065796\n",
      "Eval Loss:  0.2788678705692291\n",
      "Eval Loss:  0.1335553526878357\n",
      "Eval Loss:  0.3669191896915436\n",
      "Eval Loss:  0.1207464262843132\n",
      "Eval Loss:  0.2476891428232193\n",
      "Eval Loss:  0.22868067026138306\n",
      "Eval Loss:  0.22277867794036865\n",
      "Eval Loss:  0.2532404661178589\n",
      "Eval Loss:  0.22356493771076202\n",
      "Eval Loss:  0.23263214528560638\n",
      "Eval Loss:  0.2975592017173767\n",
      "Eval Loss:  0.2708888053894043\n",
      "Eval Loss:  0.24630674719810486\n",
      "Eval Loss:  0.29028984904289246\n",
      "Eval Loss:  0.23923639953136444\n",
      "Eval Loss:  0.2619272768497467\n",
      "Eval Loss:  0.2615051865577698\n",
      "Eval Loss:  0.2804173231124878\n",
      "Eval Loss:  0.23110142350196838\n",
      "Eval Loss:  0.26422882080078125\n",
      "Eval Loss:  0.17895366251468658\n",
      "Eval Loss:  0.28224509954452515\n",
      "Eval Loss:  0.37666597962379456\n",
      "[[17216  1412]\n",
      " [ 1620  9212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     18628\n",
      "           1       0.87      0.85      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.89      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.8970807875084861\n",
      "pre:  0.8670933734939759\n",
      "rec:  0.8504431314623339\n",
      "ma F1:  0.888878259743821\n",
      "mi F1:  0.8970807875084861\n",
      "we F1:  0.896867628366176\n",
      "29460 461\n",
      "Loss:  0.051939357072114944\n",
      "Loss:  0.049706727266311646\n",
      "Loss:  0.06278464943170547\n",
      "39 **********\n",
      "Epoch:  2175.2328696250916  fold:  3  kers:  32\n",
      "epoch:  40\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05368327349424362\n",
      "Loss:  0.06060541793704033\n",
      "Loss:  0.07841479778289795\n",
      "40 **********\n",
      "Epoch:  2216.534437417984  fold:  3  kers:  32\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.053685955703258514\n",
      "Loss:  0.0546320341527462\n",
      "Loss:  0.0768289864063263\n",
      "41 **********\n",
      "Epoch:  2257.723307132721  fold:  3  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.3932299017906189\n",
      "Eval Loss:  0.14887186884880066\n",
      "Eval Loss:  1.3060412406921387\n",
      "[[1222  314]\n",
      " [ 527 1368]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.74      1536\n",
      "           1       0.81      0.72      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.76      3431\n",
      "\n",
      "acc:  0.7548819586126494\n",
      "pre:  0.8133174791914387\n",
      "rec:  0.7218997361477573\n",
      "ma F1:  0.7544373000341689\n",
      "mi F1:  0.7548819586126494\n",
      "we F1:  0.7555306728401585\n",
      "Eval Loss:  0.1971152126789093\n",
      "Eval Loss:  0.18170024454593658\n",
      "Eval Loss:  0.274678111076355\n",
      "Eval Loss:  0.2984482944011688\n",
      "Eval Loss:  0.3695412278175354\n",
      "Eval Loss:  0.25274673104286194\n",
      "Eval Loss:  0.126997172832489\n",
      "Eval Loss:  0.3417135179042816\n",
      "Eval Loss:  0.1331915259361267\n",
      "Eval Loss:  0.24618211388587952\n",
      "Eval Loss:  0.23172691464424133\n",
      "Eval Loss:  0.23876729607582092\n",
      "Eval Loss:  0.2407626360654831\n",
      "Eval Loss:  0.21425579488277435\n",
      "Eval Loss:  0.20829850435256958\n",
      "Eval Loss:  0.27509188652038574\n",
      "Eval Loss:  0.2586211562156677\n",
      "Eval Loss:  0.23159006237983704\n",
      "Eval Loss:  0.29797452688217163\n",
      "Eval Loss:  0.2442791908979416\n",
      "Eval Loss:  0.23911917209625244\n",
      "Eval Loss:  0.2603810131549835\n",
      "Eval Loss:  0.28852736949920654\n",
      "Eval Loss:  0.22466522455215454\n",
      "Eval Loss:  0.2524247467517853\n",
      "Eval Loss:  0.17036229372024536\n",
      "Eval Loss:  0.27441126108169556\n",
      "Eval Loss:  0.34665217995643616\n",
      "[[17471  1157]\n",
      " [ 1714  9118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     18628\n",
      "           1       0.89      0.84      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9025458248472505\n",
      "pre:  0.887396593673966\n",
      "rec:  0.8417651403249631\n",
      "ma F1:  0.8940262530352445\n",
      "mi F1:  0.9025458248472505\n",
      "we F1:  0.9019777174009093\n",
      "29460 461\n",
      "Loss:  0.061039771884679794\n",
      "Loss:  0.04447190463542938\n",
      "Loss:  0.10980784893035889\n",
      "42 **********\n",
      "Epoch:  2338.098400115967  fold:  3  kers:  32\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.07134757936000824\n",
      "Loss:  0.07289725542068481\n",
      "Loss:  0.06126972287893295\n",
      "43 **********\n",
      "Epoch:  2379.353093624115  fold:  3  kers:  32\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.06440139561891556\n",
      "Loss:  0.08061861991882324\n",
      "Loss:  0.07516762614250183\n",
      "44 **********\n",
      "Epoch:  2420.581856250763  fold:  3  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.4241916835308075\n",
      "Eval Loss:  0.1507163643836975\n",
      "Eval Loss:  1.3913246393203735\n",
      "[[1217  319]\n",
      " [ 520 1375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74      1536\n",
      "           1       0.81      0.73      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7554648790440105\n",
      "pre:  0.8116883116883117\n",
      "rec:  0.7255936675461742\n",
      "ma F1:  0.7549451991040621\n",
      "mi F1:  0.7554648790440105\n",
      "we F1:  0.7561259908663497\n",
      "Eval Loss:  0.1802971065044403\n",
      "Eval Loss:  0.18046234548091888\n",
      "Eval Loss:  0.29765868186950684\n",
      "Eval Loss:  0.29620590806007385\n",
      "Eval Loss:  0.34756582975387573\n",
      "Eval Loss:  0.25715652108192444\n",
      "Eval Loss:  0.12034264206886292\n",
      "Eval Loss:  0.3378658592700958\n",
      "Eval Loss:  0.13164012134075165\n",
      "Eval Loss:  0.24934837222099304\n",
      "Eval Loss:  0.23551402986049652\n",
      "Eval Loss:  0.21133027970790863\n",
      "Eval Loss:  0.23997095227241516\n",
      "Eval Loss:  0.22304967045783997\n",
      "Eval Loss:  0.21822313964366913\n",
      "Eval Loss:  0.2769498825073242\n",
      "Eval Loss:  0.24982695281505585\n",
      "Eval Loss:  0.22328919172286987\n",
      "Eval Loss:  0.27600646018981934\n",
      "Eval Loss:  0.2405121773481369\n",
      "Eval Loss:  0.24434882402420044\n",
      "Eval Loss:  0.2671494483947754\n",
      "Eval Loss:  0.2707922160625458\n",
      "Eval Loss:  0.22765478491783142\n",
      "Eval Loss:  0.2353029102087021\n",
      "Eval Loss:  0.15375550091266632\n",
      "Eval Loss:  0.28967228531837463\n",
      "Eval Loss:  0.35306915640830994\n",
      "[[17524  1104]\n",
      " [ 1720  9112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18628\n",
      "           1       0.89      0.84      0.87     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.90     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9041412084181941\n",
      "pre:  0.8919342208300705\n",
      "rec:  0.8412112259970458\n",
      "ma F1:  0.8956317601532666\n",
      "mi F1:  0.9041412084181941\n",
      "we F1:  0.903518072406402\n",
      "29460 461\n",
      "Loss:  0.08825178444385529\n",
      "Loss:  0.05202389508485794\n",
      "Loss:  0.06734112650156021\n",
      "45 **********\n",
      "Epoch:  2501.0347414016724  fold:  3  kers:  32\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.06047089770436287\n",
      "Loss:  0.04891246557235718\n",
      "Loss:  0.06953074783086777\n",
      "46 **********\n",
      "Epoch:  2542.1827199459076  fold:  3  kers:  32\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.10159391909837723\n",
      "Loss:  0.06902787834405899\n",
      "Loss:  0.051143620163202286\n",
      "47 **********\n",
      "Epoch:  2584.2103469371796  fold:  3  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.4305228590965271\n",
      "Eval Loss:  0.17673596739768982\n",
      "Eval Loss:  1.4042707681655884\n",
      "[[1250  286]\n",
      " [ 562 1333]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75      1536\n",
      "           1       0.82      0.70      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7528417371028855\n",
      "pre:  0.8233477455219271\n",
      "rec:  0.7034300791556728\n",
      "ma F1:  0.7526970119181917\n",
      "mi F1:  0.7528417371028855\n",
      "we F1:  0.7533229919339153\n",
      "Eval Loss:  0.19795124232769012\n",
      "Eval Loss:  0.16481776535511017\n",
      "Eval Loss:  0.2818000912666321\n",
      "Eval Loss:  0.2990259528160095\n",
      "Eval Loss:  0.3170042634010315\n",
      "Eval Loss:  0.2622869908809662\n",
      "Eval Loss:  0.11958334594964981\n",
      "Eval Loss:  0.31923478841781616\n",
      "Eval Loss:  0.13421231508255005\n",
      "Eval Loss:  0.2444954365491867\n",
      "Eval Loss:  0.22089633345603943\n",
      "Eval Loss:  0.21869319677352905\n",
      "Eval Loss:  0.23929032683372498\n",
      "Eval Loss:  0.21743138134479523\n",
      "Eval Loss:  0.21648021042346954\n",
      "Eval Loss:  0.2568179666996002\n",
      "Eval Loss:  0.2298472672700882\n",
      "Eval Loss:  0.22387854754924774\n",
      "Eval Loss:  0.28743886947631836\n",
      "Eval Loss:  0.2277737557888031\n",
      "Eval Loss:  0.24054451286792755\n",
      "Eval Loss:  0.24184691905975342\n",
      "Eval Loss:  0.279779314994812\n",
      "Eval Loss:  0.2258319854736328\n",
      "Eval Loss:  0.2456817626953125\n",
      "Eval Loss:  0.16031087934970856\n",
      "Eval Loss:  0.29773062467575073\n",
      "Eval Loss:  0.3393913209438324\n",
      "[[17688   940]\n",
      " [ 1782  9050]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.91      0.84      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9076035302104548\n",
      "pre:  0.9059059059059059\n",
      "rec:  0.8354874446085672\n",
      "ma F1:  0.8989127821899227\n",
      "mi F1:  0.9076035302104548\n",
      "we F1:  0.9067563885302873\n",
      "29460 461\n",
      "Loss:  0.06351785361766815\n",
      "Loss:  0.05384116619825363\n",
      "Loss:  0.04637674242258072\n",
      "48 **********\n",
      "Epoch:  2664.436837911606  fold:  3  kers:  32\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.09085499495267868\n",
      "Loss:  0.07006651908159256\n",
      "Loss:  0.09073203057050705\n",
      "49 **********\n",
      "Epoch:  2705.605759859085  fold:  3  kers:  32\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.07504510879516602\n",
      "Loss:  0.06938135623931885\n",
      "Loss:  0.03830506280064583\n",
      "50 **********\n",
      "Epoch:  2746.812581539154  fold:  3  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.37150847911834717\n",
      "Eval Loss:  0.14431920647621155\n",
      "Eval Loss:  1.4412232637405396\n",
      "[[1218  318]\n",
      " [ 540 1355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74      1536\n",
      "           1       0.81      0.72      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7499271349460799\n",
      "pre:  0.8099222952779438\n",
      "rec:  0.7150395778364116\n",
      "ma F1:  0.749527779819811\n",
      "mi F1:  0.7499271349460799\n",
      "we F1:  0.7505742651506906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.16939370334148407\n",
      "Eval Loss:  0.16333161294460297\n",
      "Eval Loss:  0.2800101041793823\n",
      "Eval Loss:  0.2697129547595978\n",
      "Eval Loss:  0.3317655920982361\n",
      "Eval Loss:  0.24790097773075104\n",
      "Eval Loss:  0.11411910504102707\n",
      "Eval Loss:  0.3239801824092865\n",
      "Eval Loss:  0.12962403893470764\n",
      "Eval Loss:  0.22934985160827637\n",
      "Eval Loss:  0.23980437219142914\n",
      "Eval Loss:  0.19987665116786957\n",
      "Eval Loss:  0.22768069803714752\n",
      "Eval Loss:  0.21439775824546814\n",
      "Eval Loss:  0.20355090498924255\n",
      "Eval Loss:  0.2515035569667816\n",
      "Eval Loss:  0.23696237802505493\n",
      "Eval Loss:  0.21930387616157532\n",
      "Eval Loss:  0.2750624418258667\n",
      "Eval Loss:  0.2233630269765854\n",
      "Eval Loss:  0.23612689971923828\n",
      "Eval Loss:  0.25104182958602905\n",
      "Eval Loss:  0.25736841559410095\n",
      "Eval Loss:  0.22433613240718842\n",
      "Eval Loss:  0.21072779595851898\n",
      "Eval Loss:  0.16228508949279785\n",
      "Eval Loss:  0.2736198604106903\n",
      "Eval Loss:  0.32562679052352905\n",
      "[[17522  1106]\n",
      " [ 1600  9232]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18628\n",
      "           1       0.89      0.85      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9081466395112017\n",
      "pre:  0.8930160572644612\n",
      "rec:  0.8522895125553914\n",
      "ma F1:  0.9002477453099631\n",
      "mi F1:  0.9081466395112018\n",
      "we F1:  0.907675945453854\n",
      "29460 461\n",
      "Loss:  0.056229449808597565\n",
      "Loss:  0.04368353635072708\n",
      "Loss:  0.05983990058302879\n",
      "51 **********\n",
      "Epoch:  2827.18966960907  fold:  3  kers:  32\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.03906151279807091\n",
      "Loss:  0.08651433885097504\n",
      "Loss:  0.10088802874088287\n",
      "52 **********\n",
      "Epoch:  2868.4084589481354  fold:  3  kers:  32\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.06665612012147903\n",
      "Loss:  0.08943559974431992\n",
      "Loss:  0.04843214899301529\n",
      "53 **********\n",
      "Epoch:  2909.7140164375305  fold:  3  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.4768976867198944\n",
      "Eval Loss:  0.15152376890182495\n",
      "Eval Loss:  1.457719326019287\n",
      "[[1242  294]\n",
      " [ 596 1299]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74      1536\n",
      "           1       0.82      0.69      0.74      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7406004080443019\n",
      "pre:  0.815442561205273\n",
      "rec:  0.6854881266490765\n",
      "ma F1:  0.7405287941245249\n",
      "mi F1:  0.7406004080443019\n",
      "we F1:  0.740979836180665\n",
      "Eval Loss:  0.17643320560455322\n",
      "Eval Loss:  0.1688361018896103\n",
      "Eval Loss:  0.27620765566825867\n",
      "Eval Loss:  0.2720262408256531\n",
      "Eval Loss:  0.3161270022392273\n",
      "Eval Loss:  0.29840704798698425\n",
      "Eval Loss:  0.13041773438453674\n",
      "Eval Loss:  0.32609814405441284\n",
      "Eval Loss:  0.13469994068145752\n",
      "Eval Loss:  0.24194331467151642\n",
      "Eval Loss:  0.2531304359436035\n",
      "Eval Loss:  0.22553382813930511\n",
      "Eval Loss:  0.216572105884552\n",
      "Eval Loss:  0.2161269336938858\n",
      "Eval Loss:  0.2084263414144516\n",
      "Eval Loss:  0.23974820971488953\n",
      "Eval Loss:  0.24464385211467743\n",
      "Eval Loss:  0.22109773755073547\n",
      "Eval Loss:  0.2557523548603058\n",
      "Eval Loss:  0.23841583728790283\n",
      "Eval Loss:  0.25824931263923645\n",
      "Eval Loss:  0.26529544591903687\n",
      "Eval Loss:  0.2610156238079071\n",
      "Eval Loss:  0.22607918083667755\n",
      "Eval Loss:  0.2388443648815155\n",
      "Eval Loss:  0.15376617014408112\n",
      "Eval Loss:  0.27177694439888\n",
      "Eval Loss:  0.3359159827232361\n",
      "[[17691   937]\n",
      " [ 1765  9067]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.91      0.84      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9082824168363883\n",
      "pre:  0.9063374650139944\n",
      "rec:  0.8370568685376661\n",
      "ma F1:  0.8996860845882728\n",
      "mi F1:  0.9082824168363883\n",
      "we F1:  0.907457073248559\n",
      "29460 461\n",
      "Loss:  0.03724959120154381\n",
      "Loss:  0.05068089812994003\n",
      "Loss:  0.04209912568330765\n",
      "54 **********\n",
      "Epoch:  2990.1050667762756  fold:  3  kers:  32\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.055390723049640656\n",
      "Loss:  0.059735655784606934\n",
      "Loss:  0.039289556443691254\n",
      "55 **********\n",
      "Epoch:  3031.3966612815857  fold:  3  kers:  32\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.056609634310007095\n",
      "Loss:  0.07788816839456558\n",
      "Loss:  0.05652347952127457\n",
      "56 **********\n",
      "Epoch:  3072.6992268562317  fold:  3  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.4179903268814087\n",
      "Eval Loss:  0.1415153592824936\n",
      "Eval Loss:  1.425148844718933\n",
      "[[1224  312]\n",
      " [ 570 1325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74      1536\n",
      "           1       0.81      0.70      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7429320897697465\n",
      "pre:  0.8094074526573\n",
      "rec:  0.6992084432717678\n",
      "ma F1:  0.7427091304214747\n",
      "mi F1:  0.7429320897697465\n",
      "we F1:  0.7435016294910741\n",
      "Eval Loss:  0.18020476400852203\n",
      "Eval Loss:  0.20606158673763275\n",
      "Eval Loss:  0.26362746953964233\n",
      "Eval Loss:  0.2664776146411896\n",
      "Eval Loss:  0.3025180995464325\n",
      "Eval Loss:  0.32733023166656494\n",
      "Eval Loss:  0.1373487412929535\n",
      "Eval Loss:  0.33237528800964355\n",
      "Eval Loss:  0.12950025498867035\n",
      "Eval Loss:  0.23610498011112213\n",
      "Eval Loss:  0.266891211271286\n",
      "Eval Loss:  0.23116517066955566\n",
      "Eval Loss:  0.22595004737377167\n",
      "Eval Loss:  0.22500044107437134\n",
      "Eval Loss:  0.21316511929035187\n",
      "Eval Loss:  0.23692388832569122\n",
      "Eval Loss:  0.2675451636314392\n",
      "Eval Loss:  0.22224806249141693\n",
      "Eval Loss:  0.24459128081798553\n",
      "Eval Loss:  0.24765020608901978\n",
      "Eval Loss:  0.28266608715057373\n",
      "Eval Loss:  0.2795880436897278\n",
      "Eval Loss:  0.2629580795764923\n",
      "Eval Loss:  0.2245088368654251\n",
      "Eval Loss:  0.25630030035972595\n",
      "Eval Loss:  0.160240039229393\n",
      "Eval Loss:  0.27380162477493286\n",
      "Eval Loss:  0.2973476052284241\n",
      "[[17650   978]\n",
      " [ 1697  9135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.90      0.84      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9091989137813985\n",
      "pre:  0.9032927914565411\n",
      "rec:  0.8433345642540621\n",
      "ma F1:  0.9009217375643379\n",
      "mi F1:  0.9091989137813985\n",
      "we F1:  0.9084999954372921\n",
      "29460 461\n",
      "Loss:  0.06444012373685837\n",
      "Loss:  0.053711775690317154\n",
      "Loss:  0.06010113283991814\n",
      "57 **********\n",
      "Epoch:  3153.1192009449005  fold:  3  kers:  32\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.03970195725560188\n",
      "Loss:  0.05242243409156799\n",
      "Loss:  0.07553818076848984\n",
      "58 **********\n",
      "Epoch:  3194.3569388389587  fold:  3  kers:  32\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.051361169666051865\n",
      "Loss:  0.06488464772701263\n",
      "Loss:  0.07175450772047043\n",
      "59 **********\n",
      "Epoch:  3235.6305813789368  fold:  3  kers:  32\n",
      "Eval Loss:  0.38987496495246887\n",
      "Eval Loss:  0.12099310755729675\n",
      "Eval Loss:  1.4637911319732666\n",
      "[[1216  320]\n",
      " [ 550 1345]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74      1536\n",
      "           1       0.81      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.75      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7464296123579132\n",
      "pre:  0.8078078078078078\n",
      "rec:  0.7097625329815304\n",
      "ma F1:  0.7460706483642872\n",
      "mi F1:  0.7464296123579132\n",
      "we F1:  0.7470696256798818\n",
      "update!  Acc:  0.7825706791023025\n",
      "Epoch:  3239.746576309204  fold:  3  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29520 3371\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29520 462\n",
      "Loss:  0.17105409502983093\n",
      "Loss:  0.16800877451896667\n",
      "Loss:  0.1615012139081955\n",
      "0 **********\n",
      "Epoch:  53.84403133392334  fold:  4  kers:  32\n",
      "epoch:  1\n",
      "29520 462\n",
      "Loss:  0.15815486013889313\n",
      "Loss:  0.13305622339248657\n",
      "Loss:  0.1341150552034378\n",
      "1 **********\n",
      "Epoch:  95.41089010238647  fold:  4  kers:  32\n",
      "epoch:  2\n",
      "29520 462\n",
      "Loss:  0.1281859427690506\n",
      "Loss:  0.14745904505252838\n",
      "Loss:  0.10709347575902939\n",
      "2 **********\n",
      "Epoch:  136.9498233795166  fold:  4  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.4875001311302185\n",
      "Eval Loss:  0.4362165927886963\n",
      "Eval Loss:  0.11744699627161026\n",
      "[[2638  499]\n",
      " [ 130  104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89      3137\n",
      "           1       0.17      0.44      0.25       234\n",
      "\n",
      "    accuracy                           0.81      3371\n",
      "   macro avg       0.56      0.64      0.57      3371\n",
      "weighted avg       0.90      0.81      0.85      3371\n",
      "\n",
      "acc:  0.8134084841293385\n",
      "pre:  0.1724709784411277\n",
      "rec:  0.4444444444444444\n",
      "ma F1:  0.5709933363480112\n",
      "mi F1:  0.8134084841293385\n",
      "we F1:  0.8487088746310392\n",
      "update!  Acc:  0.8134084841293385\n",
      "Eval Loss:  0.3980652391910553\n",
      "Eval Loss:  0.45556846261024475\n",
      "Eval Loss:  0.43102383613586426\n",
      "Eval Loss:  0.47034257650375366\n",
      "Eval Loss:  0.5083228349685669\n",
      "Eval Loss:  0.3955388367176056\n",
      "Eval Loss:  0.4093581736087799\n",
      "Eval Loss:  0.5232833623886108\n",
      "Eval Loss:  0.38841941952705383\n",
      "Eval Loss:  0.40142330527305603\n",
      "Eval Loss:  0.49685049057006836\n",
      "Eval Loss:  0.4169253706932068\n",
      "Eval Loss:  0.4302883744239807\n",
      "Eval Loss:  0.43641677498817444\n",
      "Eval Loss:  0.3753988444805145\n",
      "Eval Loss:  0.41134679317474365\n",
      "Eval Loss:  0.5184087753295898\n",
      "Eval Loss:  0.47321584820747375\n",
      "Eval Loss:  0.3980041444301605\n",
      "Eval Loss:  0.4528442621231079\n",
      "Eval Loss:  0.49037763476371765\n",
      "Eval Loss:  0.47069820761680603\n",
      "Eval Loss:  0.5028035044670105\n",
      "Eval Loss:  0.4178607165813446\n",
      "Eval Loss:  0.38930293917655945\n",
      "Eval Loss:  0.3804488480091095\n",
      "Eval Loss:  0.4654924273490906\n",
      "Eval Loss:  0.4599896967411041\n",
      "[[13886  3141]\n",
      " [ 2543  9950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83     17027\n",
      "           1       0.76      0.80      0.78     12493\n",
      "\n",
      "    accuracy                           0.81     29520\n",
      "   macro avg       0.80      0.81      0.80     29520\n",
      "weighted avg       0.81      0.81      0.81     29520\n",
      "\n",
      "acc:  0.8074525745257453\n",
      "pre:  0.7600641662210679\n",
      "rec:  0.7964460097654686\n",
      "ma F1:  0.8039675532501931\n",
      "mi F1:  0.8074525745257454\n",
      "we F1:  0.8079820569248256\n",
      "29520 462\n",
      "Loss:  0.10933781415224075\n",
      "Loss:  0.11376350373029709\n",
      "Loss:  0.11134389042854309\n",
      "3 **********\n",
      "Epoch:  217.68595170974731  fold:  4  kers:  32\n",
      "epoch:  4\n",
      "29520 462\n",
      "Loss:  0.09395073354244232\n",
      "Loss:  0.09621696919202805\n",
      "Loss:  0.10255856066942215\n",
      "4 **********\n",
      "Epoch:  258.92568492889404  fold:  4  kers:  32\n",
      "epoch:  5\n",
      "29520 462\n",
      "Loss:  0.11717597395181656\n",
      "Loss:  0.09351754188537598\n",
      "Loss:  0.10822171717882156\n",
      "5 **********\n",
      "Epoch:  300.3180103302002  fold:  4  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.1289079636335373\n",
      "Eval Loss:  0.2281544804573059\n",
      "Eval Loss:  0.07523927837610245\n",
      "[[2987  150]\n",
      " [ 193   41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      3137\n",
      "           1       0.21      0.18      0.19       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.58      0.56      0.57      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.8982497775140907\n",
      "pre:  0.21465968586387435\n",
      "rec:  0.1752136752136752\n",
      "ma F1:  0.5693216251198913\n",
      "mi F1:  0.8982497775140907\n",
      "we F1:  0.8934487216576921\n",
      "update!  Acc:  0.8982497775140907\n",
      "Eval Loss:  0.3463604152202606\n",
      "Eval Loss:  0.43395471572875977\n",
      "Eval Loss:  0.39336568117141724\n",
      "Eval Loss:  0.4552508592605591\n",
      "Eval Loss:  0.5074781775474548\n",
      "Eval Loss:  0.38932064175605774\n",
      "Eval Loss:  0.3933422863483429\n",
      "Eval Loss:  0.5117743015289307\n",
      "Eval Loss:  0.3924107253551483\n",
      "Eval Loss:  0.38132911920547485\n",
      "Eval Loss:  0.5210022926330566\n",
      "Eval Loss:  0.43222668766975403\n",
      "Eval Loss:  0.4307037889957428\n",
      "Eval Loss:  0.42531514167785645\n",
      "Eval Loss:  0.36172476410865784\n",
      "Eval Loss:  0.40679308772087097\n",
      "Eval Loss:  0.48323294520378113\n",
      "Eval Loss:  0.4633564054965973\n",
      "Eval Loss:  0.3624521791934967\n",
      "Eval Loss:  0.43916743993759155\n",
      "Eval Loss:  0.4870419204235077\n",
      "Eval Loss:  0.524142861366272\n",
      "Eval Loss:  0.45331642031669617\n",
      "Eval Loss:  0.3825606107711792\n",
      "Eval Loss:  0.37057146430015564\n",
      "Eval Loss:  0.38120585680007935\n",
      "Eval Loss:  0.42211320996284485\n",
      "Eval Loss:  0.4358383119106293\n",
      "[[15470  1557]\n",
      " [ 3551  8942]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86     17027\n",
      "           1       0.85      0.72      0.78     12493\n",
      "\n",
      "    accuracy                           0.83     29520\n",
      "   macro avg       0.83      0.81      0.82     29520\n",
      "weighted avg       0.83      0.83      0.82     29520\n",
      "\n",
      "acc:  0.8269647696476965\n",
      "pre:  0.8517001619201828\n",
      "rec:  0.7157608260625951\n",
      "ma F1:  0.8180679066741908\n",
      "mi F1:  0.8269647696476964\n",
      "we F1:  0.8242471923239878\n",
      "29520 462\n",
      "Loss:  0.11605041474103928\n",
      "Loss:  0.07492287456989288\n",
      "Loss:  0.11441145837306976\n",
      "6 **********\n",
      "Epoch:  380.7469599246979  fold:  4  kers:  32\n",
      "epoch:  7\n",
      "29520 462\n",
      "Loss:  0.13657501339912415\n",
      "Loss:  0.10435745865106583\n",
      "Loss:  0.09073817729949951\n",
      "7 **********\n",
      "Epoch:  421.99866104125977  fold:  4  kers:  32\n",
      "epoch:  8\n",
      "29520 462\n",
      "Loss:  0.118559829890728\n",
      "Loss:  0.10189443826675415\n",
      "Loss:  0.06063787639141083\n",
      "8 **********\n",
      "Epoch:  463.3151886463165  fold:  4  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.08596620708703995\n",
      "Eval Loss:  0.13014692068099976\n",
      "Eval Loss:  0.05337899550795555\n",
      "[[3072   65]\n",
      " [ 208   26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.29      0.11      0.16       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.61      0.55      0.56      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9190151290418274\n",
      "pre:  0.2857142857142857\n",
      "rec:  0.1111111111111111\n",
      "ma F1:  0.5587283777466105\n",
      "mi F1:  0.9190151290418275\n",
      "we F1:  0.9021008134032141\n",
      "update!  Acc:  0.9190151290418274\n",
      "Eval Loss:  0.3365086615085602\n",
      "Eval Loss:  0.41993167996406555\n",
      "Eval Loss:  0.3803099989891052\n",
      "Eval Loss:  0.44662830233573914\n",
      "Eval Loss:  0.5110820531845093\n",
      "Eval Loss:  0.3765527606010437\n",
      "Eval Loss:  0.35979577898979187\n",
      "Eval Loss:  0.48547083139419556\n",
      "Eval Loss:  0.40351995825767517\n",
      "Eval Loss:  0.3577719032764435\n",
      "Eval Loss:  0.48269712924957275\n",
      "Eval Loss:  0.42320308089256287\n",
      "Eval Loss:  0.39691266417503357\n",
      "Eval Loss:  0.40313583612442017\n",
      "Eval Loss:  0.34881919622421265\n",
      "Eval Loss:  0.3924562335014343\n",
      "Eval Loss:  0.44790488481521606\n",
      "Eval Loss:  0.45495834946632385\n",
      "Eval Loss:  0.36446264386177063\n",
      "Eval Loss:  0.4077271819114685\n",
      "Eval Loss:  0.47073206305503845\n",
      "Eval Loss:  0.49744707345962524\n",
      "Eval Loss:  0.4565008580684662\n",
      "Eval Loss:  0.39461418986320496\n",
      "Eval Loss:  0.3706057369709015\n",
      "Eval Loss:  0.38012421131134033\n",
      "Eval Loss:  0.39627593755722046\n",
      "Eval Loss:  0.4408845603466034\n",
      "[[15918  1109]\n",
      " [ 3649  8844]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87     17027\n",
      "           1       0.89      0.71      0.79     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.85      0.82      0.83     29520\n",
      "weighted avg       0.85      0.84      0.84     29520\n",
      "\n",
      "acc:  0.8388211382113822\n",
      "pre:  0.8885763086506581\n",
      "rec:  0.7079164332025935\n",
      "ma F1:  0.8290016386926591\n",
      "mi F1:  0.8388211382113823\n",
      "we F1:  0.835295335443845\n",
      "29520 462\n",
      "Loss:  0.08285285532474518\n",
      "Loss:  0.10198941826820374\n",
      "Loss:  0.09096525609493256\n",
      "9 **********\n",
      "Epoch:  543.8069703578949  fold:  4  kers:  32\n",
      "epoch:  10\n",
      "29520 462\n",
      "Loss:  0.06861269474029541\n",
      "Loss:  0.08920029550790787\n",
      "Loss:  0.08630155026912689\n",
      "10 **********\n",
      "Epoch:  585.1324739456177  fold:  4  kers:  32\n",
      "epoch:  11\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.11845779418945312\n",
      "Loss:  0.08825506269931793\n",
      "Loss:  0.10292281210422516\n",
      "11 **********\n",
      "Epoch:  626.5367674827576  fold:  4  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.08541650325059891\n",
      "Eval Loss:  0.12327109277248383\n",
      "Eval Loss:  0.057266585528850555\n",
      "[[3056   81]\n",
      " [ 199   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      3137\n",
      "           1       0.30      0.15      0.20       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.62      0.56      0.58      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9169385938890537\n",
      "pre:  0.3017241379310345\n",
      "rec:  0.14957264957264957\n",
      "ma F1:  0.5780976220275345\n",
      "mi F1:  0.9169385938890537\n",
      "we F1:  0.9037034946902257\n",
      "Eval Loss:  0.3009827435016632\n",
      "Eval Loss:  0.37869900465011597\n",
      "Eval Loss:  0.32237523794174194\n",
      "Eval Loss:  0.3899585008621216\n",
      "Eval Loss:  0.44665443897247314\n",
      "Eval Loss:  0.3082095682621002\n",
      "Eval Loss:  0.3372248411178589\n",
      "Eval Loss:  0.39191973209381104\n",
      "Eval Loss:  0.3540536165237427\n",
      "Eval Loss:  0.3040822744369507\n",
      "Eval Loss:  0.43009865283966064\n",
      "Eval Loss:  0.3723009526729584\n",
      "Eval Loss:  0.3112933039665222\n",
      "Eval Loss:  0.3441287875175476\n",
      "Eval Loss:  0.30474191904067993\n",
      "Eval Loss:  0.36126798391342163\n",
      "Eval Loss:  0.3816206455230713\n",
      "Eval Loss:  0.424818754196167\n",
      "Eval Loss:  0.3124566674232483\n",
      "Eval Loss:  0.34110012650489807\n",
      "Eval Loss:  0.38675037026405334\n",
      "Eval Loss:  0.4098151624202728\n",
      "Eval Loss:  0.4098661541938782\n",
      "Eval Loss:  0.3448145091533661\n",
      "Eval Loss:  0.36706674098968506\n",
      "Eval Loss:  0.33472758531570435\n",
      "Eval Loss:  0.3398694097995758\n",
      "Eval Loss:  0.3743099272251129\n",
      "[[15736  1291]\n",
      " [ 2930  9563]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88     17027\n",
      "           1       0.88      0.77      0.82     12493\n",
      "\n",
      "    accuracy                           0.86     29520\n",
      "   macro avg       0.86      0.84      0.85     29520\n",
      "weighted avg       0.86      0.86      0.86     29520\n",
      "\n",
      "acc:  0.8570121951219513\n",
      "pre:  0.8810576745900129\n",
      "rec:  0.7654686624509726\n",
      "ma F1:  0.8504737058177667\n",
      "mi F1:  0.8570121951219513\n",
      "we F1:  0.8552761536559609\n",
      "29520 462\n",
      "Loss:  0.08841820806264877\n",
      "Loss:  0.07202313095331192\n",
      "Loss:  0.0691433697938919\n",
      "12 **********\n",
      "Epoch:  707.3696370124817  fold:  4  kers:  32\n",
      "epoch:  13\n",
      "29520 462\n",
      "Loss:  0.07862120866775513\n",
      "Loss:  0.06565052270889282\n",
      "Loss:  0.0500323511660099\n",
      "13 **********\n",
      "Epoch:  748.8218021392822  fold:  4  kers:  32\n",
      "epoch:  14\n",
      "29520 462\n",
      "Loss:  0.077751524746418\n",
      "Loss:  0.06528376042842865\n",
      "Loss:  0.08824102580547333\n",
      "14 **********\n",
      "Epoch:  790.3238337039948  fold:  4  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.0751134604215622\n",
      "Eval Loss:  0.09493227303028107\n",
      "Eval Loss:  0.03353169187903404\n",
      "[[3102   35]\n",
      " [ 217   17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.33      0.07      0.12       234\n",
      "\n",
      "    accuracy                           0.93      3371\n",
      "   macro avg       0.63      0.53      0.54      3371\n",
      "weighted avg       0.89      0.93      0.90      3371\n",
      "\n",
      "acc:  0.9252447345001483\n",
      "pre:  0.3269230769230769\n",
      "rec:  0.07264957264957266\n",
      "ma F1:  0.5399238308160242\n",
      "mi F1:  0.9252447345001484\n",
      "we F1:  0.9025126747041968\n",
      "update!  Acc:  0.9252447345001483\n",
      "Eval Loss:  0.34225496649742126\n",
      "Eval Loss:  0.4252561330795288\n",
      "Eval Loss:  0.3879852592945099\n",
      "Eval Loss:  0.4586102366447449\n",
      "Eval Loss:  0.47122371196746826\n",
      "Eval Loss:  0.364202618598938\n",
      "Eval Loss:  0.3857850432395935\n",
      "Eval Loss:  0.444957971572876\n",
      "Eval Loss:  0.417380154132843\n",
      "Eval Loss:  0.3292205333709717\n",
      "Eval Loss:  0.5003790259361267\n",
      "Eval Loss:  0.444296270608902\n",
      "Eval Loss:  0.3918580114841461\n",
      "Eval Loss:  0.38007038831710815\n",
      "Eval Loss:  0.348829984664917\n",
      "Eval Loss:  0.3667340576648712\n",
      "Eval Loss:  0.38684576749801636\n",
      "Eval Loss:  0.48902589082717896\n",
      "Eval Loss:  0.3624688386917114\n",
      "Eval Loss:  0.3702911138534546\n",
      "Eval Loss:  0.46516457200050354\n",
      "Eval Loss:  0.47285884618759155\n",
      "Eval Loss:  0.43756580352783203\n",
      "Eval Loss:  0.44736534357070923\n",
      "Eval Loss:  0.40375471115112305\n",
      "Eval Loss:  0.41007640957832336\n",
      "Eval Loss:  0.41512951254844666\n",
      "Eval Loss:  0.4306597411632538\n",
      "[[16337   690]\n",
      " [ 3923  8570]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88     17027\n",
      "           1       0.93      0.69      0.79     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.87      0.82      0.83     29520\n",
      "weighted avg       0.86      0.84      0.84     29520\n",
      "\n",
      "acc:  0.8437330623306233\n",
      "pre:  0.9254859611231101\n",
      "rec:  0.6859841511246297\n",
      "ma F1:  0.8321106277810495\n",
      "mi F1:  0.8437330623306233\n",
      "we F1:  0.8388952445246786\n",
      "29520 462\n",
      "Loss:  0.08227675408124924\n",
      "Loss:  0.09222867339849472\n",
      "Loss:  0.08031780272722244\n",
      "15 **********\n",
      "Epoch:  870.7477967739105  fold:  4  kers:  32\n",
      "epoch:  16\n",
      "29520 462\n",
      "Loss:  0.07275139540433884\n",
      "Loss:  0.13670620322227478\n",
      "Loss:  0.07471229881048203\n",
      "16 **********\n",
      "Epoch:  912.1421167850494  fold:  4  kers:  32\n",
      "epoch:  17\n",
      "29520 462\n",
      "Loss:  0.07437700778245926\n",
      "Loss:  0.08869052678346634\n",
      "Loss:  0.11528744548559189\n",
      "17 **********\n",
      "Epoch:  953.457647562027  fold:  4  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.08503967523574829\n",
      "Eval Loss:  0.11689852923154831\n",
      "Eval Loss:  0.05590532720088959\n",
      "[[3062   75]\n",
      " [ 198   36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.32      0.15      0.21       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.63      0.56      0.58      3371\n",
      "weighted avg       0.90      0.92      0.91      3371\n",
      "\n",
      "acc:  0.9190151290418274\n",
      "pre:  0.32432432432432434\n",
      "rec:  0.15384615384615385\n",
      "ma F1:  0.5830096988398094\n",
      "mi F1:  0.9190151290418275\n",
      "we F1:  0.9053572744764445\n",
      "Eval Loss:  0.2890295684337616\n",
      "Eval Loss:  0.35958752036094666\n",
      "Eval Loss:  0.310482919216156\n",
      "Eval Loss:  0.38498029112815857\n",
      "Eval Loss:  0.3884258270263672\n",
      "Eval Loss:  0.30596616864204407\n",
      "Eval Loss:  0.3418629467487335\n",
      "Eval Loss:  0.34507957100868225\n",
      "Eval Loss:  0.34659716486930847\n",
      "Eval Loss:  0.2851511538028717\n",
      "Eval Loss:  0.42326340079307556\n",
      "Eval Loss:  0.3859400749206543\n",
      "Eval Loss:  0.28809499740600586\n",
      "Eval Loss:  0.3210228681564331\n",
      "Eval Loss:  0.28802311420440674\n",
      "Eval Loss:  0.3316618502140045\n",
      "Eval Loss:  0.3269374370574951\n",
      "Eval Loss:  0.4017949402332306\n",
      "Eval Loss:  0.2890576422214508\n",
      "Eval Loss:  0.3027579188346863\n",
      "Eval Loss:  0.36796000599861145\n",
      "Eval Loss:  0.3686996102333069\n",
      "Eval Loss:  0.38234415650367737\n",
      "Eval Loss:  0.3477913439273834\n",
      "Eval Loss:  0.3647610545158386\n",
      "Eval Loss:  0.35742226243019104\n",
      "Eval Loss:  0.35310423374176025\n",
      "Eval Loss:  0.3499302864074707\n",
      "[[15989  1038]\n",
      " [ 2926  9567]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     17027\n",
      "           1       0.90      0.77      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.87      0.85      0.86     29520\n",
      "weighted avg       0.87      0.87      0.86     29520\n",
      "\n",
      "acc:  0.8657181571815719\n",
      "pre:  0.9021216407355022\n",
      "rec:  0.7657888417513807\n",
      "ma F1:  0.8590473055995165\n",
      "mi F1:  0.8657181571815719\n",
      "we F1:  0.8637569974514377\n",
      "29520 462\n",
      "Loss:  0.06489093601703644\n",
      "Loss:  0.06598711758852005\n",
      "Loss:  0.1028139665722847\n",
      "18 **********\n",
      "Epoch:  1033.930480003357  fold:  4  kers:  32\n",
      "epoch:  19\n",
      "29520 462\n",
      "Loss:  0.06104865297675133\n",
      "Loss:  0.09967826306819916\n",
      "Loss:  0.07287897169589996\n",
      "19 **********\n",
      "Epoch:  1075.2460100650787  fold:  4  kers:  32\n",
      "epoch:  20\n",
      "29520 462\n",
      "Loss:  0.09832625091075897\n",
      "Loss:  0.06718917936086655\n",
      "Loss:  0.07191459089517593\n",
      "20 **********\n",
      "Epoch:  1116.6084153652191  fold:  4  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.09544309973716736\n",
      "Eval Loss:  0.12177906930446625\n",
      "Eval Loss:  0.03623446822166443\n",
      "[[3092   45]\n",
      " [ 210   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      3137\n",
      "           1       0.35      0.10      0.16       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.64      0.54      0.56      3371\n",
      "weighted avg       0.90      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9243547908632453\n",
      "pre:  0.34782608695652173\n",
      "rec:  0.10256410256410256\n",
      "ma F1:  0.5594067094238543\n",
      "mi F1:  0.9243547908632453\n",
      "we F1:  0.9047275309422872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3085287809371948\n",
      "Eval Loss:  0.366730272769928\n",
      "Eval Loss:  0.3541630208492279\n",
      "Eval Loss:  0.4079812467098236\n",
      "Eval Loss:  0.39756396412849426\n",
      "Eval Loss:  0.3225066363811493\n",
      "Eval Loss:  0.35621005296707153\n",
      "Eval Loss:  0.37417811155319214\n",
      "Eval Loss:  0.37621980905532837\n",
      "Eval Loss:  0.30302855372428894\n",
      "Eval Loss:  0.45010361075401306\n",
      "Eval Loss:  0.39845284819602966\n",
      "Eval Loss:  0.3273170292377472\n",
      "Eval Loss:  0.35255029797554016\n",
      "Eval Loss:  0.304979145526886\n",
      "Eval Loss:  0.34069591760635376\n",
      "Eval Loss:  0.33345022797584534\n",
      "Eval Loss:  0.4134252369403839\n",
      "Eval Loss:  0.31128183007240295\n",
      "Eval Loss:  0.3012080192565918\n",
      "Eval Loss:  0.4024941623210907\n",
      "Eval Loss:  0.3874945342540741\n",
      "Eval Loss:  0.378745436668396\n",
      "Eval Loss:  0.3891508877277374\n",
      "Eval Loss:  0.37541550397872925\n",
      "Eval Loss:  0.3688471019268036\n",
      "Eval Loss:  0.37380462884902954\n",
      "Eval Loss:  0.37686991691589355\n",
      "[[16247   780]\n",
      " [ 3412  9081]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     17027\n",
      "           1       0.92      0.73      0.81     12493\n",
      "\n",
      "    accuracy                           0.86     29520\n",
      "   macro avg       0.87      0.84      0.85     29520\n",
      "weighted avg       0.87      0.86      0.85     29520\n",
      "\n",
      "acc:  0.8579945799457994\n",
      "pre:  0.9209005171889261\n",
      "rec:  0.726887056751781\n",
      "ma F1:  0.849102508977783\n",
      "mi F1:  0.8579945799457994\n",
      "we F1:  0.8547286113736785\n",
      "29520 462\n",
      "Loss:  0.06525347381830215\n",
      "Loss:  0.0950264260172844\n",
      "Loss:  0.09762891381978989\n",
      "21 **********\n",
      "Epoch:  1197.109172821045  fold:  4  kers:  32\n",
      "epoch:  22\n",
      "29520 462\n",
      "Loss:  0.07413773238658905\n",
      "Loss:  0.07720915228128433\n",
      "Loss:  0.05457492172718048\n",
      "22 **********\n",
      "Epoch:  1238.5633327960968  fold:  4  kers:  32\n",
      "epoch:  23\n",
      "29520 462\n",
      "Loss:  0.08184656500816345\n",
      "Loss:  0.07561445981264114\n",
      "Loss:  0.10704058408737183\n",
      "23 **********\n",
      "Epoch:  1280.0364422798157  fold:  4  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.10753116756677628\n",
      "Eval Loss:  0.13588032126426697\n",
      "Eval Loss:  0.05091092735528946\n",
      "[[3032  105]\n",
      " [ 187   47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.31      0.20      0.24       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.63      0.58      0.60      3371\n",
      "weighted avg       0.90      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9133788193414417\n",
      "pre:  0.3092105263157895\n",
      "rec:  0.20085470085470086\n",
      "ma F1:  0.5987912363822523\n",
      "mi F1:  0.9133788193414417\n",
      "we F1:  0.904736882389129\n",
      "Eval Loss:  0.2921398878097534\n",
      "Eval Loss:  0.34656694531440735\n",
      "Eval Loss:  0.3134462833404541\n",
      "Eval Loss:  0.38289254903793335\n",
      "Eval Loss:  0.35374391078948975\n",
      "Eval Loss:  0.30019792914390564\n",
      "Eval Loss:  0.3271966278553009\n",
      "Eval Loss:  0.3404216170310974\n",
      "Eval Loss:  0.3598686456680298\n",
      "Eval Loss:  0.2805725336074829\n",
      "Eval Loss:  0.416207879781723\n",
      "Eval Loss:  0.3685009777545929\n",
      "Eval Loss:  0.2763299345970154\n",
      "Eval Loss:  0.31836459040641785\n",
      "Eval Loss:  0.27282074093818665\n",
      "Eval Loss:  0.331767737865448\n",
      "Eval Loss:  0.2933504581451416\n",
      "Eval Loss:  0.38206687569618225\n",
      "Eval Loss:  0.28088951110839844\n",
      "Eval Loss:  0.26662498712539673\n",
      "Eval Loss:  0.3504983186721802\n",
      "Eval Loss:  0.3481839597225189\n",
      "Eval Loss:  0.37407028675079346\n",
      "Eval Loss:  0.33913829922676086\n",
      "Eval Loss:  0.3579142987728119\n",
      "Eval Loss:  0.3470849394798279\n",
      "Eval Loss:  0.3493404686450958\n",
      "Eval Loss:  0.338400661945343\n",
      "[[16020  1007]\n",
      " [ 2869  9624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     17027\n",
      "           1       0.91      0.77      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.88      0.86      0.86     29520\n",
      "weighted avg       0.87      0.87      0.87     29520\n",
      "\n",
      "acc:  0.8686991869918699\n",
      "pre:  0.9052770200357445\n",
      "rec:  0.770351396782198\n",
      "ma F1:  0.8622317321978232\n",
      "mi F1:  0.8686991869918699\n",
      "we F1:  0.8668163851115517\n",
      "29520 462\n",
      "Loss:  0.08555091172456741\n",
      "Loss:  0.06076711416244507\n",
      "Loss:  0.09243220090866089\n",
      "24 **********\n",
      "Epoch:  1360.9500958919525  fold:  4  kers:  32\n",
      "epoch:  25\n",
      "29520 462\n",
      "Loss:  0.08337345719337463\n",
      "Loss:  0.08797158300876617\n",
      "Loss:  0.07077304273843765\n",
      "25 **********\n",
      "Epoch:  1402.4082448482513  fold:  4  kers:  32\n",
      "epoch:  26\n",
      "29520 462\n",
      "Loss:  0.079098179936409\n",
      "Loss:  0.06330045312643051\n",
      "Loss:  0.09152881056070328\n",
      "26 **********\n",
      "Epoch:  1443.841460943222  fold:  4  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.07621824741363525\n",
      "Eval Loss:  0.09619342535734177\n",
      "Eval Loss:  0.027438245713710785\n",
      "[[3096   41]\n",
      " [ 214   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      3137\n",
      "           1       0.33      0.09      0.14       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.63      0.54      0.55      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9243547908632453\n",
      "pre:  0.32786885245901637\n",
      "rec:  0.08547008547008547\n",
      "ma F1:  0.5480199698716786\n",
      "mi F1:  0.9243547908632453\n",
      "we F1:  0.9031890158204817\n",
      "Eval Loss:  0.3140158951282501\n",
      "Eval Loss:  0.37342777848243713\n",
      "Eval Loss:  0.3796917498111725\n",
      "Eval Loss:  0.41155174374580383\n",
      "Eval Loss:  0.39317354559898376\n",
      "Eval Loss:  0.32866525650024414\n",
      "Eval Loss:  0.37031713128089905\n",
      "Eval Loss:  0.39929789304733276\n",
      "Eval Loss:  0.38296934962272644\n",
      "Eval Loss:  0.2812938690185547\n",
      "Eval Loss:  0.4514549672603607\n",
      "Eval Loss:  0.39575761556625366\n",
      "Eval Loss:  0.35002681612968445\n",
      "Eval Loss:  0.36187681555747986\n",
      "Eval Loss:  0.3114067018032074\n",
      "Eval Loss:  0.34501388669013977\n",
      "Eval Loss:  0.3215043246746063\n",
      "Eval Loss:  0.4370471239089966\n",
      "Eval Loss:  0.2946794629096985\n",
      "Eval Loss:  0.32493796944618225\n",
      "Eval Loss:  0.4001268744468689\n",
      "Eval Loss:  0.4154645800590515\n",
      "Eval Loss:  0.3945857584476471\n",
      "Eval Loss:  0.4009358882904053\n",
      "Eval Loss:  0.3801223039627075\n",
      "Eval Loss:  0.3902047872543335\n",
      "Eval Loss:  0.37440282106399536\n",
      "Eval Loss:  0.37970688939094543\n",
      "[[16428   599]\n",
      " [ 3651  8842]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89     17027\n",
      "           1       0.94      0.71      0.81     12493\n",
      "\n",
      "    accuracy                           0.86     29520\n",
      "   macro avg       0.88      0.84      0.85     29520\n",
      "weighted avg       0.87      0.86      0.85     29520\n",
      "\n",
      "acc:  0.856029810298103\n",
      "pre:  0.9365533312149137\n",
      "rec:  0.7077563435523894\n",
      "ma F1:  0.8458500799458886\n",
      "mi F1:  0.856029810298103\n",
      "we F1:  0.8519343005386832\n",
      "29520 462\n",
      "Loss:  0.08083236962556839\n",
      "Loss:  0.07851379364728928\n",
      "Loss:  0.0759955570101738\n",
      "27 **********\n",
      "Epoch:  1524.509770154953  fold:  4  kers:  32\n",
      "epoch:  28\n",
      "29520 462\n",
      "Loss:  0.07651717215776443\n",
      "Loss:  0.0774056613445282\n",
      "Loss:  0.05551030486822128\n",
      "28 **********\n",
      "Epoch:  1565.7854073047638  fold:  4  kers:  32\n",
      "epoch:  29\n",
      "29520 462\n",
      "Loss:  0.08554859459400177\n",
      "Loss:  0.0830458551645279\n",
      "Loss:  0.06366166472434998\n",
      "29 **********\n",
      "Epoch:  1607.104927778244  fold:  4  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.11248832941055298\n",
      "Eval Loss:  0.1592797487974167\n",
      "Eval Loss:  0.04572710394859314\n",
      "[[3042   95]\n",
      " [ 183   51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      3137\n",
      "           1       0.35      0.22      0.27       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.65      0.59      0.61      3371\n",
      "weighted avg       0.90      0.92      0.91      3371\n",
      "\n",
      "acc:  0.9175318896469891\n",
      "pre:  0.3493150684931507\n",
      "rec:  0.21794871794871795\n",
      "ma F1:  0.6123620509935638\n",
      "mi F1:  0.9175318896469891\n",
      "we F1:  0.9085533052934279\n",
      "Eval Loss:  0.2772045433521271\n",
      "Eval Loss:  0.3178686201572418\n",
      "Eval Loss:  0.2960645854473114\n",
      "Eval Loss:  0.3469260334968567\n",
      "Eval Loss:  0.3191065192222595\n",
      "Eval Loss:  0.29313796758651733\n",
      "Eval Loss:  0.3172720670700073\n",
      "Eval Loss:  0.2987147271633148\n",
      "Eval Loss:  0.3113289773464203\n",
      "Eval Loss:  0.23794136941432953\n",
      "Eval Loss:  0.37330561876296997\n",
      "Eval Loss:  0.33852386474609375\n",
      "Eval Loss:  0.24200358986854553\n",
      "Eval Loss:  0.29795578122138977\n",
      "Eval Loss:  0.2500038146972656\n",
      "Eval Loss:  0.3195510804653168\n",
      "Eval Loss:  0.27381253242492676\n",
      "Eval Loss:  0.31553804874420166\n",
      "Eval Loss:  0.2653718888759613\n",
      "Eval Loss:  0.2629755735397339\n",
      "Eval Loss:  0.31649520993232727\n",
      "Eval Loss:  0.312673419713974\n",
      "Eval Loss:  0.3507295548915863\n",
      "Eval Loss:  0.30855613946914673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3407445251941681\n",
      "Eval Loss:  0.3125542402267456\n",
      "Eval Loss:  0.3295973837375641\n",
      "Eval Loss:  0.28812235593795776\n",
      "[[15987  1040]\n",
      " [ 2545  9948]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     17027\n",
      "           1       0.91      0.80      0.85     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.88      0.87      0.87     29520\n",
      "weighted avg       0.88      0.88      0.88     29520\n",
      "\n",
      "acc:  0.8785569105691057\n",
      "pre:  0.9053512923188933\n",
      "rec:  0.7962859201152646\n",
      "ma F1:  0.8732525048038807\n",
      "mi F1:  0.8785569105691057\n",
      "we F1:  0.8772349813297178\n",
      "29520 462\n",
      "Loss:  0.09128892421722412\n",
      "Loss:  0.06797478348016739\n",
      "Loss:  0.06465742737054825\n",
      "30 **********\n",
      "Epoch:  1687.6465759277344  fold:  4  kers:  32\n",
      "epoch:  31\n",
      "29520 462\n",
      "Loss:  0.05838118866086006\n",
      "Loss:  0.07266875356435776\n",
      "Loss:  0.0586426742374897\n",
      "31 **********\n",
      "Epoch:  1729.2493379116058  fold:  4  kers:  32\n",
      "epoch:  32\n",
      "29520 462\n",
      "Loss:  0.062038566917181015\n",
      "Loss:  0.06712590903043747\n",
      "Loss:  0.11206748336553574\n",
      "32 **********\n",
      "Epoch:  1770.724442243576  fold:  4  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.09679430723190308\n",
      "Eval Loss:  0.14633400738239288\n",
      "Eval Loss:  0.04882586747407913\n",
      "[[3034  103]\n",
      " [ 193   41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.28      0.18      0.22       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.61      0.57      0.59      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9121922278255711\n",
      "pre:  0.2847222222222222\n",
      "rec:  0.1752136752136752\n",
      "ma F1:  0.5852097945121201\n",
      "mi F1:  0.9121922278255711\n",
      "we F1:  0.9023598125237966\n",
      "Eval Loss:  0.2738553285598755\n",
      "Eval Loss:  0.2927033007144928\n",
      "Eval Loss:  0.2695924639701843\n",
      "Eval Loss:  0.3212343156337738\n",
      "Eval Loss:  0.30489397048950195\n",
      "Eval Loss:  0.29573115706443787\n",
      "Eval Loss:  0.2918262481689453\n",
      "Eval Loss:  0.2984744608402252\n",
      "Eval Loss:  0.307847261428833\n",
      "Eval Loss:  0.24878907203674316\n",
      "Eval Loss:  0.34542107582092285\n",
      "Eval Loss:  0.31786710023880005\n",
      "Eval Loss:  0.2334100902080536\n",
      "Eval Loss:  0.2868365943431854\n",
      "Eval Loss:  0.2401396930217743\n",
      "Eval Loss:  0.3204919993877411\n",
      "Eval Loss:  0.2845606505870819\n",
      "Eval Loss:  0.2858842611312866\n",
      "Eval Loss:  0.25181594491004944\n",
      "Eval Loss:  0.24670928716659546\n",
      "Eval Loss:  0.2974007725715637\n",
      "Eval Loss:  0.2933320701122284\n",
      "Eval Loss:  0.3579671084880829\n",
      "Eval Loss:  0.28726744651794434\n",
      "Eval Loss:  0.3516201674938202\n",
      "Eval Loss:  0.3130994439125061\n",
      "Eval Loss:  0.3135298192501068\n",
      "Eval Loss:  0.2908172905445099\n",
      "[[15811  1216]\n",
      " [ 2266 10227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     17027\n",
      "           1       0.89      0.82      0.85     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.88      0.87      0.88     29520\n",
      "weighted avg       0.88      0.88      0.88     29520\n",
      "\n",
      "acc:  0.8820460704607046\n",
      "pre:  0.8937341606222144\n",
      "rec:  0.8186184263187385\n",
      "ma F1:  0.8776688839640439\n",
      "mi F1:  0.8820460704607046\n",
      "we F1:  0.881222996352271\n",
      "29520 462\n",
      "Loss:  0.05613655224442482\n",
      "Loss:  0.07810548692941666\n",
      "Loss:  0.0833340659737587\n",
      "33 **********\n",
      "Epoch:  1851.428655385971  fold:  4  kers:  32\n",
      "epoch:  34\n",
      "29520 462\n",
      "Loss:  0.06598159670829773\n",
      "Loss:  0.08375025540590286\n",
      "Loss:  0.08712846785783768\n",
      "34 **********\n",
      "Epoch:  1892.8838126659393  fold:  4  kers:  32\n",
      "epoch:  35\n",
      "29520 462\n",
      "Loss:  0.05405157431960106\n",
      "Loss:  0.04855988174676895\n",
      "Loss:  0.08341272920370102\n",
      "35 **********\n",
      "Epoch:  1934.3070554733276  fold:  4  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.15834923088550568\n",
      "Eval Loss:  0.1857205331325531\n",
      "Eval Loss:  0.08055354654788971\n",
      "[[2967  170]\n",
      " [ 167   67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      3137\n",
      "           1       0.28      0.29      0.28       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.61      0.62      0.62      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.9000296647878968\n",
      "pre:  0.28270042194092826\n",
      "rec:  0.2863247863247863\n",
      "ma F1:  0.6153808130371972\n",
      "mi F1:  0.9000296647878968\n",
      "we F1:  0.9003241291172941\n",
      "Eval Loss:  0.28220614790916443\n",
      "Eval Loss:  0.301115483045578\n",
      "Eval Loss:  0.2598145008087158\n",
      "Eval Loss:  0.3117885887622833\n",
      "Eval Loss:  0.3005640208721161\n",
      "Eval Loss:  0.27970242500305176\n",
      "Eval Loss:  0.30106469988822937\n",
      "Eval Loss:  0.2871852219104767\n",
      "Eval Loss:  0.2958914637565613\n",
      "Eval Loss:  0.23155613243579865\n",
      "Eval Loss:  0.35404038429260254\n",
      "Eval Loss:  0.30721279978752136\n",
      "Eval Loss:  0.22335253655910492\n",
      "Eval Loss:  0.2707107365131378\n",
      "Eval Loss:  0.23580047488212585\n",
      "Eval Loss:  0.3109179735183716\n",
      "Eval Loss:  0.27314117550849915\n",
      "Eval Loss:  0.2852197289466858\n",
      "Eval Loss:  0.24430659413337708\n",
      "Eval Loss:  0.2590004503726959\n",
      "Eval Loss:  0.2852398157119751\n",
      "Eval Loss:  0.29518985748291016\n",
      "Eval Loss:  0.35763296484947205\n",
      "Eval Loss:  0.2832825183868408\n",
      "Eval Loss:  0.3398240804672241\n",
      "Eval Loss:  0.2947877049446106\n",
      "Eval Loss:  0.3176117539405823\n",
      "Eval Loss:  0.24888771772384644\n",
      "[[15718  1309]\n",
      " [ 2080 10413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     17027\n",
      "           1       0.89      0.83      0.86     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.88      0.88     29520\n",
      "weighted avg       0.89      0.89      0.88     29520\n",
      "\n",
      "acc:  0.8851964769647697\n",
      "pre:  0.8883296365807882\n",
      "rec:  0.8335067637877211\n",
      "ma F1:  0.8813651396121044\n",
      "mi F1:  0.8851964769647697\n",
      "we F1:  0.8846396511214323\n",
      "29520 462\n",
      "Loss:  0.06704797595739365\n",
      "Loss:  0.09710913896560669\n",
      "Loss:  0.07367151975631714\n",
      "36 **********\n",
      "Epoch:  2014.991322517395  fold:  4  kers:  32\n",
      "epoch:  37\n",
      "29520 462\n",
      "Loss:  0.07715415209531784\n",
      "Loss:  0.07522961497306824\n",
      "Loss:  0.0835847407579422\n",
      "37 **********\n",
      "Epoch:  2056.556186914444  fold:  4  kers:  32\n",
      "epoch:  38\n",
      "29520 462\n",
      "Loss:  0.09891235083341599\n",
      "Loss:  0.04282768443226814\n",
      "Loss:  0.10564058274030685\n",
      "38 **********\n",
      "Epoch:  2098.143988609314  fold:  4  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.12441346794366837\n",
      "Eval Loss:  0.23112015426158905\n",
      "Eval Loss:  0.09153735637664795\n",
      "[[2921  216]\n",
      " [ 186   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3137\n",
      "           1       0.18      0.21      0.19       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.56      0.57      0.56      3371\n",
      "weighted avg       0.89      0.88      0.88      3371\n",
      "\n",
      "acc:  0.8807475526549985\n",
      "pre:  0.18181818181818182\n",
      "rec:  0.20512820512820512\n",
      "ma F1:  0.5641946389015383\n",
      "mi F1:  0.8807475526549985\n",
      "we F1:  0.8840530129448015\n",
      "Eval Loss:  0.30047911405563354\n",
      "Eval Loss:  0.292356014251709\n",
      "Eval Loss:  0.2661188840866089\n",
      "Eval Loss:  0.30638575553894043\n",
      "Eval Loss:  0.3080137372016907\n",
      "Eval Loss:  0.2967994213104248\n",
      "Eval Loss:  0.29456663131713867\n",
      "Eval Loss:  0.30279120802879333\n",
      "Eval Loss:  0.32261019945144653\n",
      "Eval Loss:  0.2635382413864136\n",
      "Eval Loss:  0.33290788531303406\n",
      "Eval Loss:  0.3151152431964874\n",
      "Eval Loss:  0.21819886565208435\n",
      "Eval Loss:  0.27994248270988464\n",
      "Eval Loss:  0.24132472276687622\n",
      "Eval Loss:  0.3207578659057617\n",
      "Eval Loss:  0.28258898854255676\n",
      "Eval Loss:  0.2586538791656494\n",
      "Eval Loss:  0.26229190826416016\n",
      "Eval Loss:  0.2581615447998047\n",
      "Eval Loss:  0.28098034858703613\n",
      "Eval Loss:  0.2853892147541046\n",
      "Eval Loss:  0.3789218068122864\n",
      "Eval Loss:  0.26862645149230957\n",
      "Eval Loss:  0.345400869846344\n",
      "Eval Loss:  0.307290256023407\n",
      "Eval Loss:  0.31045764684677124\n",
      "Eval Loss:  0.27181681990623474\n",
      "[[15597  1430]\n",
      " [ 1986 10507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90     17027\n",
      "           1       0.88      0.84      0.86     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.88      0.88      0.88     29520\n",
      "weighted avg       0.88      0.88      0.88     29520\n",
      "\n",
      "acc:  0.8842818428184281\n",
      "pre:  0.8802044064672866\n",
      "rec:  0.8410309773473145\n",
      "ma F1:  0.8807360610122288\n",
      "mi F1:  0.8842818428184281\n",
      "we F1:  0.8838945236270241\n",
      "29520 462\n",
      "Loss:  0.07063375413417816\n",
      "Loss:  0.10585632920265198\n",
      "Loss:  0.06128989905118942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 **********\n",
      "Epoch:  2178.6267943382263  fold:  4  kers:  32\n",
      "epoch:  40\n",
      "29520 462\n",
      "Loss:  0.09992983192205429\n",
      "Loss:  0.05251723900437355\n",
      "Loss:  0.043723709881305695\n",
      "40 **********\n",
      "Epoch:  2220.0081486701965  fold:  4  kers:  32\n",
      "epoch:  41\n",
      "29520 462\n",
      "Loss:  0.06935929507017136\n",
      "Loss:  0.054319512099027634\n",
      "Loss:  0.07978855073451996\n",
      "41 **********\n",
      "Epoch:  2261.2827887535095  fold:  4  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.13739676773548126\n",
      "Eval Loss:  0.1695435494184494\n",
      "Eval Loss:  0.06516790390014648\n",
      "[[3020  117]\n",
      " [ 186   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.29      0.21      0.24       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.62      0.58      0.60      3371\n",
      "weighted avg       0.90      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9101156926727973\n",
      "pre:  0.2909090909090909\n",
      "rec:  0.20512820512820512\n",
      "ma F1:  0.5964161546859423\n",
      "mi F1:  0.9101156926727973\n",
      "we F1:  0.9028326280290919\n",
      "Eval Loss:  0.27182233333587646\n",
      "Eval Loss:  0.293214350938797\n",
      "Eval Loss:  0.2690756618976593\n",
      "Eval Loss:  0.28684890270233154\n",
      "Eval Loss:  0.3009510040283203\n",
      "Eval Loss:  0.27687546610832214\n",
      "Eval Loss:  0.28425896167755127\n",
      "Eval Loss:  0.27796661853790283\n",
      "Eval Loss:  0.31282615661621094\n",
      "Eval Loss:  0.23687508702278137\n",
      "Eval Loss:  0.3408733010292053\n",
      "Eval Loss:  0.30399638414382935\n",
      "Eval Loss:  0.21550284326076508\n",
      "Eval Loss:  0.2697664499282837\n",
      "Eval Loss:  0.2318865954875946\n",
      "Eval Loss:  0.33099034428596497\n",
      "Eval Loss:  0.2850698232650757\n",
      "Eval Loss:  0.25277820229530334\n",
      "Eval Loss:  0.24880170822143555\n",
      "Eval Loss:  0.24894796311855316\n",
      "Eval Loss:  0.2810652554035187\n",
      "Eval Loss:  0.27821433544158936\n",
      "Eval Loss:  0.3474682569503784\n",
      "Eval Loss:  0.26802894473075867\n",
      "Eval Loss:  0.3432888686656952\n",
      "Eval Loss:  0.30339550971984863\n",
      "Eval Loss:  0.3161369264125824\n",
      "Eval Loss:  0.2595670819282532\n",
      "[[15806  1221]\n",
      " [ 2081 10412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     17027\n",
      "           1       0.90      0.83      0.86     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.88      0.88     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8881436314363144\n",
      "pre:  0.8950399724920485\n",
      "rec:  0.8334267189626191\n",
      "ma F1:  0.8842799824037739\n",
      "mi F1:  0.8881436314363144\n",
      "we F1:  0.8875276251018716\n",
      "29520 462\n",
      "Loss:  0.07710065692663193\n",
      "Loss:  0.09288781136274338\n",
      "Loss:  0.09296111017465591\n",
      "42 **********\n",
      "Epoch:  2341.8433859348297  fold:  4  kers:  32\n",
      "epoch:  43\n",
      "29520 462\n",
      "Loss:  0.08291704952716827\n",
      "Loss:  0.09313276410102844\n",
      "Loss:  0.06507708132266998\n",
      "43 **********\n",
      "Epoch:  2383.2416954040527  fold:  4  kers:  32\n",
      "epoch:  44\n",
      "29520 462\n",
      "Loss:  0.09861376136541367\n",
      "Loss:  0.1009874939918518\n",
      "Loss:  0.059397339820861816\n",
      "44 **********\n",
      "Epoch:  2424.6868798732758  fold:  4  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.1134064644575119\n",
      "Eval Loss:  0.1709415763616562\n",
      "Eval Loss:  0.1357535719871521\n",
      "[[2936  201]\n",
      " [ 179   55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.21      0.24      0.22       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.58      0.59      0.58      3371\n",
      "weighted avg       0.89      0.89      0.89      3371\n",
      "\n",
      "acc:  0.8872738059922871\n",
      "pre:  0.21484375\n",
      "rec:  0.23504273504273504\n",
      "ma F1:  0.5818546228472196\n",
      "mi F1:  0.8872738059922871\n",
      "we F1:  0.8896060593866612\n",
      "Eval Loss:  0.27285924553871155\n",
      "Eval Loss:  0.2811175584793091\n",
      "Eval Loss:  0.23858419060707092\n",
      "Eval Loss:  0.25816473364830017\n",
      "Eval Loss:  0.2825269103050232\n",
      "Eval Loss:  0.2661712169647217\n",
      "Eval Loss:  0.28181588649749756\n",
      "Eval Loss:  0.2711237668991089\n",
      "Eval Loss:  0.2717779874801636\n",
      "Eval Loss:  0.23518796265125275\n",
      "Eval Loss:  0.3294442892074585\n",
      "Eval Loss:  0.27062854170799255\n",
      "Eval Loss:  0.19638647139072418\n",
      "Eval Loss:  0.25284579396247864\n",
      "Eval Loss:  0.21834741532802582\n",
      "Eval Loss:  0.3261215090751648\n",
      "Eval Loss:  0.28863900899887085\n",
      "Eval Loss:  0.2423977255821228\n",
      "Eval Loss:  0.2307223379611969\n",
      "Eval Loss:  0.2650580406188965\n",
      "Eval Loss:  0.2648893892765045\n",
      "Eval Loss:  0.26354727149009705\n",
      "Eval Loss:  0.33635592460632324\n",
      "Eval Loss:  0.2509574592113495\n",
      "Eval Loss:  0.3487468361854553\n",
      "Eval Loss:  0.2923528552055359\n",
      "Eval Loss:  0.29979291558265686\n",
      "Eval Loss:  0.2298353910446167\n",
      "[[15644  1383]\n",
      " [ 1801 10692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17027\n",
      "           1       0.89      0.86      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8921409214092141\n",
      "pre:  0.8854658385093168\n",
      "rec:  0.8558392699911951\n",
      "ma F1:  0.889017851589885\n",
      "mi F1:  0.8921409214092141\n",
      "we F1:  0.8918773020262416\n",
      "29520 462\n",
      "Loss:  0.07549478113651276\n",
      "Loss:  0.06584445387125015\n",
      "Loss:  0.06309175491333008\n",
      "45 **********\n",
      "Epoch:  2505.3003351688385  fold:  4  kers:  32\n",
      "epoch:  46\n",
      "29520 462\n",
      "Loss:  0.10834208875894547\n",
      "Loss:  0.0824013277888298\n",
      "Loss:  0.08692625164985657\n",
      "46 **********\n",
      "Epoch:  2546.6777007579803  fold:  4  kers:  32\n",
      "epoch:  47\n",
      "29520 462\n",
      "Loss:  0.05951660871505737\n",
      "Loss:  0.08121271431446075\n",
      "Loss:  0.08370719850063324\n",
      "47 **********\n",
      "Epoch:  2588.183721780777  fold:  4  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.09328402578830719\n",
      "Eval Loss:  0.19956602156162262\n",
      "Eval Loss:  0.12994617223739624\n",
      "[[2917  220]\n",
      " [ 179   55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3137\n",
      "           1       0.20      0.24      0.22       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.57      0.58      0.58      3371\n",
      "weighted avg       0.89      0.88      0.89      3371\n",
      "\n",
      "acc:  0.8816374962919015\n",
      "pre:  0.2\n",
      "rec:  0.23504273504273504\n",
      "ma F1:  0.5760479506221559\n",
      "mi F1:  0.8816374962919015\n",
      "we F1:  0.8860152640670446\n",
      "Eval Loss:  0.2787073850631714\n",
      "Eval Loss:  0.27617305517196655\n",
      "Eval Loss:  0.2528129816055298\n",
      "Eval Loss:  0.25897055864334106\n",
      "Eval Loss:  0.2821287214756012\n",
      "Eval Loss:  0.26191356778144836\n",
      "Eval Loss:  0.2903561592102051\n",
      "Eval Loss:  0.2908279299736023\n",
      "Eval Loss:  0.28177493810653687\n",
      "Eval Loss:  0.240973100066185\n",
      "Eval Loss:  0.3238970637321472\n",
      "Eval Loss:  0.28879213333129883\n",
      "Eval Loss:  0.1946764439344406\n",
      "Eval Loss:  0.2438916563987732\n",
      "Eval Loss:  0.21408267319202423\n",
      "Eval Loss:  0.33303302526474\n",
      "Eval Loss:  0.2784549295902252\n",
      "Eval Loss:  0.2353944629430771\n",
      "Eval Loss:  0.23855963349342346\n",
      "Eval Loss:  0.27167394757270813\n",
      "Eval Loss:  0.26438578963279724\n",
      "Eval Loss:  0.260711133480072\n",
      "Eval Loss:  0.3451184630393982\n",
      "Eval Loss:  0.24537727236747742\n",
      "Eval Loss:  0.3441994786262512\n",
      "Eval Loss:  0.2986387014389038\n",
      "Eval Loss:  0.30165570974349976\n",
      "Eval Loss:  0.2350381761789322\n",
      "[[15638  1389]\n",
      " [ 1815 10678]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17027\n",
      "           1       0.88      0.85      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8914634146341464\n",
      "pre:  0.8848926825225822\n",
      "rec:  0.8547186424397663\n",
      "ma F1:  0.888310270033329\n",
      "mi F1:  0.8914634146341464\n",
      "we F1:  0.8911926001986727\n",
      "29520 462\n",
      "Loss:  0.06324165314435959\n",
      "Loss:  0.047256290912628174\n",
      "Loss:  0.0771806389093399\n",
      "48 **********\n",
      "Epoch:  2668.6874713897705  fold:  4  kers:  32\n",
      "epoch:  49\n",
      "29520 462\n",
      "Loss:  0.06977706402540207\n",
      "Loss:  0.0869193747639656\n",
      "Loss:  0.05692923814058304\n",
      "49 **********\n",
      "Epoch:  2710.1545968055725  fold:  4  kers:  32\n",
      "epoch:  50\n",
      "29520 462\n",
      "Loss:  0.06819280982017517\n",
      "Loss:  0.07427164912223816\n",
      "Loss:  0.10662654042243958\n",
      "50 **********\n",
      "Epoch:  2751.545924425125  fold:  4  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.09435614198446274\n",
      "Eval Loss:  0.1725751757621765\n",
      "Eval Loss:  0.09861063212156296\n",
      "[[2984  153]\n",
      " [ 173   61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      3137\n",
      "           1       0.29      0.26      0.27       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.62      0.61      0.61      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.9032927914565411\n",
      "pre:  0.2850467289719626\n",
      "rec:  0.2606837606837607\n",
      "ma F1:  0.6102630339552408\n",
      "mi F1:  0.9032927914565411\n",
      "we F1:  0.9012877982475003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.26149559020996094\n",
      "Eval Loss:  0.2498345971107483\n",
      "Eval Loss:  0.2675129771232605\n",
      "Eval Loss:  0.2595739960670471\n",
      "Eval Loss:  0.27020564675331116\n",
      "Eval Loss:  0.24500565230846405\n",
      "Eval Loss:  0.27836889028549194\n",
      "Eval Loss:  0.2906850278377533\n",
      "Eval Loss:  0.27555206418037415\n",
      "Eval Loss:  0.23800493776798248\n",
      "Eval Loss:  0.3169560432434082\n",
      "Eval Loss:  0.2791133224964142\n",
      "Eval Loss:  0.18893100321292877\n",
      "Eval Loss:  0.23223061859607697\n",
      "Eval Loss:  0.20103342831134796\n",
      "Eval Loss:  0.33843061327934265\n",
      "Eval Loss:  0.2589419484138489\n",
      "Eval Loss:  0.24019739031791687\n",
      "Eval Loss:  0.21637649834156036\n",
      "Eval Loss:  0.2612464725971222\n",
      "Eval Loss:  0.26505306363105774\n",
      "Eval Loss:  0.24780036509037018\n",
      "Eval Loss:  0.3231631815433502\n",
      "Eval Loss:  0.23414510488510132\n",
      "Eval Loss:  0.3322698473930359\n",
      "Eval Loss:  0.2869073748588562\n",
      "Eval Loss:  0.2797865867614746\n",
      "Eval Loss:  0.24179185926914215\n",
      "[[15738  1289]\n",
      " [ 1832 10661]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17027\n",
      "           1       0.89      0.85      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8942750677506776\n",
      "pre:  0.8921338912133892\n",
      "rec:  0.8533578804130313\n",
      "ma F1:  0.8910525242170687\n",
      "mi F1:  0.8942750677506776\n",
      "we F1:  0.8939304072939609\n",
      "29520 462\n",
      "Loss:  0.07082723081111908\n",
      "Loss:  0.11261425912380219\n",
      "Loss:  0.05317189544439316\n",
      "51 **********\n",
      "Epoch:  2832.151402235031  fold:  4  kers:  32\n",
      "epoch:  52\n",
      "29520 462\n",
      "Loss:  0.05966949090361595\n",
      "Loss:  0.07116150856018066\n",
      "Loss:  0.1293286234140396\n",
      "52 **********\n",
      "Epoch:  2873.414073944092  fold:  4  kers:  32\n",
      "epoch:  53\n",
      "29520 462\n",
      "Loss:  0.07283175736665726\n",
      "Loss:  0.06726665049791336\n",
      "Loss:  0.09779208898544312\n",
      "53 **********\n",
      "Epoch:  2914.725615501404  fold:  4  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.11476904153823853\n",
      "Eval Loss:  0.1820036917924881\n",
      "Eval Loss:  0.14757180213928223\n",
      "[[2931  206]\n",
      " [ 170   64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      3137\n",
      "           1       0.24      0.27      0.25       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.59      0.60      0.60      3371\n",
      "weighted avg       0.90      0.89      0.89      3371\n",
      "\n",
      "acc:  0.8884603975081579\n",
      "pre:  0.23703703703703705\n",
      "rec:  0.27350427350427353\n",
      "ma F1:  0.5968462622839026\n",
      "mi F1:  0.8884603975081579\n",
      "we F1:  0.8921221027289716\n",
      "Eval Loss:  0.26982566714286804\n",
      "Eval Loss:  0.255084365606308\n",
      "Eval Loss:  0.2616284489631653\n",
      "Eval Loss:  0.2462872862815857\n",
      "Eval Loss:  0.2733449935913086\n",
      "Eval Loss:  0.2383381575345993\n",
      "Eval Loss:  0.2733543813228607\n",
      "Eval Loss:  0.28262820839881897\n",
      "Eval Loss:  0.25892725586891174\n",
      "Eval Loss:  0.22470800578594208\n",
      "Eval Loss:  0.3281744122505188\n",
      "Eval Loss:  0.26980024576187134\n",
      "Eval Loss:  0.1920878291130066\n",
      "Eval Loss:  0.227199986577034\n",
      "Eval Loss:  0.19590382277965546\n",
      "Eval Loss:  0.32454538345336914\n",
      "Eval Loss:  0.2606217861175537\n",
      "Eval Loss:  0.2494291216135025\n",
      "Eval Loss:  0.21464429795742035\n",
      "Eval Loss:  0.2588769197463989\n",
      "Eval Loss:  0.2584719955921173\n",
      "Eval Loss:  0.25439736247062683\n",
      "Eval Loss:  0.30251941084861755\n",
      "Eval Loss:  0.239922896027565\n",
      "Eval Loss:  0.3100731372833252\n",
      "Eval Loss:  0.27879592776298523\n",
      "Eval Loss:  0.29012149572372437\n",
      "Eval Loss:  0.22403232753276825\n",
      "[[15860  1167]\n",
      " [ 1884 10609]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     17027\n",
      "           1       0.90      0.85      0.87     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.89      0.89     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.8966463414634146\n",
      "pre:  0.9009001358695652\n",
      "rec:  0.8491955495077244\n",
      "ma F1:  0.8932692655101079\n",
      "mi F1:  0.8966463414634146\n",
      "we F1:  0.8961852172092686\n",
      "29520 462\n",
      "Loss:  0.09547016769647598\n",
      "Loss:  0.07454563677310944\n",
      "Loss:  0.05869152769446373\n",
      "54 **********\n",
      "Epoch:  2998.8995518684387  fold:  4  kers:  32\n",
      "epoch:  55\n",
      "29520 462\n",
      "Loss:  0.03664856031537056\n",
      "Loss:  0.044027380645275116\n",
      "Loss:  0.06618370115756989\n",
      "55 **********\n",
      "Epoch:  3040.422527551651  fold:  4  kers:  32\n",
      "epoch:  56\n",
      "29520 462\n",
      "Loss:  0.059647124260663986\n",
      "Loss:  0.05709753930568695\n",
      "Loss:  0.06128887087106705\n",
      "56 **********\n",
      "Epoch:  3081.752021074295  fold:  4  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.07285357266664505\n",
      "Eval Loss:  0.1810908019542694\n",
      "Eval Loss:  0.1139632910490036\n",
      "[[2963  174]\n",
      " [ 174   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.26      0.26      0.26       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.60      0.60      0.60      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.8967665381192524\n",
      "pre:  0.2564102564102564\n",
      "rec:  0.2564102564102564\n",
      "ma F1:  0.6004716248579812\n",
      "mi F1:  0.8967665381192524\n",
      "we F1:  0.8967665381192524\n",
      "Eval Loss:  0.2832278311252594\n",
      "Eval Loss:  0.2579532563686371\n",
      "Eval Loss:  0.2523351013660431\n",
      "Eval Loss:  0.23338700830936432\n",
      "Eval Loss:  0.2870084345340729\n",
      "Eval Loss:  0.25444918870925903\n",
      "Eval Loss:  0.25548434257507324\n",
      "Eval Loss:  0.2945907711982727\n",
      "Eval Loss:  0.2577921748161316\n",
      "Eval Loss:  0.25053706765174866\n",
      "Eval Loss:  0.3006737232208252\n",
      "Eval Loss:  0.2610599398612976\n",
      "Eval Loss:  0.18902504444122314\n",
      "Eval Loss:  0.23448050022125244\n",
      "Eval Loss:  0.21830075979232788\n",
      "Eval Loss:  0.3535148799419403\n",
      "Eval Loss:  0.2983621656894684\n",
      "Eval Loss:  0.24224048852920532\n",
      "Eval Loss:  0.22199329733848572\n",
      "Eval Loss:  0.2671240270137787\n",
      "Eval Loss:  0.2622261047363281\n",
      "Eval Loss:  0.2313801497220993\n",
      "Eval Loss:  0.3303122818470001\n",
      "Eval Loss:  0.21534158289432526\n",
      "Eval Loss:  0.3558327257633209\n",
      "Eval Loss:  0.2894083261489868\n",
      "Eval Loss:  0.3025844693183899\n",
      "Eval Loss:  0.23999260365962982\n",
      "[[15433  1594]\n",
      " [ 1507 10986]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     17027\n",
      "           1       0.87      0.88      0.88     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.90      0.89      0.90     29520\n",
      "\n",
      "acc:  0.8949525745257453\n",
      "pre:  0.8732909379968203\n",
      "rec:  0.8793724485711999\n",
      "ma F1:  0.8925133252760213\n",
      "mi F1:  0.8949525745257452\n",
      "we F1:  0.8950002953903115\n",
      "29520 462\n",
      "Loss:  0.06024278327822685\n",
      "Loss:  0.0747913345694542\n",
      "Loss:  0.08550690114498138\n",
      "57 **********\n",
      "Epoch:  3162.3126180171967  fold:  4  kers:  32\n",
      "epoch:  58\n",
      "29520 462\n",
      "Loss:  0.08047685772180557\n",
      "Loss:  0.08596950769424438\n",
      "Loss:  0.0625038594007492\n",
      "58 **********\n",
      "Epoch:  3203.601220846176  fold:  4  kers:  32\n",
      "epoch:  59\n",
      "29520 462\n",
      "Loss:  0.08233270794153214\n",
      "Loss:  0.05539573356509209\n",
      "Loss:  0.06312225013971329\n",
      "59 **********\n",
      "Epoch:  3244.9576423168182  fold:  4  kers:  32\n",
      "Eval Loss:  0.08807028084993362\n",
      "Eval Loss:  0.2051357626914978\n",
      "Eval Loss:  0.15610714256763458\n",
      "[[2878  259]\n",
      " [ 174   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3137\n",
      "           1       0.19      0.26      0.22       234\n",
      "\n",
      "    accuracy                           0.87      3371\n",
      "   macro avg       0.57      0.59      0.57      3371\n",
      "weighted avg       0.89      0.87      0.88      3371\n",
      "\n",
      "acc:  0.8715514684070009\n",
      "pre:  0.18808777429467086\n",
      "rec:  0.2564102564102564\n",
      "ma F1:  0.5735176771948832\n",
      "mi F1:  0.8715514684070009\n",
      "we F1:  0.880541132087991\n",
      "update!  Acc:  0.9252447345001483\n",
      "Epoch:  3248.9499673843384  fold:  4  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29673 3218\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29673 464\n",
      "Loss:  0.1667521595954895\n",
      "Loss:  0.1632513552904129\n",
      "Loss:  0.15775544941425323\n",
      "0 **********\n",
      "Epoch:  54.16317868232727  fold:  5  kers:  32\n",
      "epoch:  1\n",
      "29673 464\n",
      "Loss:  0.16955061256885529\n",
      "Loss:  0.14703749120235443\n",
      "Loss:  0.13087667524814606\n",
      "1 **********\n",
      "Epoch:  95.73502373695374  fold:  5  kers:  32\n",
      "epoch:  2\n",
      "29673 464\n",
      "Loss:  0.12958940863609314\n",
      "Loss:  0.1053016409277916\n",
      "Loss:  0.11740674823522568\n",
      "2 **********\n",
      "Epoch:  137.2430398464203  fold:  5  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.17405350506305695\n",
      "Eval Loss:  0.37598490715026855\n",
      "Eval Loss:  0.35026729106903076\n",
      "[[2714  383]\n",
      " [  42   79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      3097\n",
      "           1       0.17      0.65      0.27       121\n",
      "\n",
      "    accuracy                           0.87      3218\n",
      "   macro avg       0.58      0.76      0.60      3218\n",
      "weighted avg       0.95      0.87      0.90      3218\n",
      "\n",
      "acc:  0.867930391547545\n",
      "pre:  0.170995670995671\n",
      "rec:  0.6528925619834711\n",
      "ma F1:  0.5991998356533235\n",
      "mi F1:  0.867930391547545\n",
      "we F1:  0.902707287016209\n",
      "update!  Acc:  0.867930391547545\n",
      "Eval Loss:  0.47237640619277954\n",
      "Eval Loss:  0.3688526451587677\n",
      "Eval Loss:  0.4895368814468384\n",
      "Eval Loss:  0.38883906602859497\n",
      "Eval Loss:  0.4054582417011261\n",
      "Eval Loss:  0.38893812894821167\n",
      "Eval Loss:  0.41741466522216797\n",
      "Eval Loss:  0.32686060667037964\n",
      "Eval Loss:  0.3948242664337158\n",
      "Eval Loss:  0.4923798441886902\n",
      "Eval Loss:  0.4386707544326782\n",
      "Eval Loss:  0.3913898766040802\n",
      "Eval Loss:  0.35774654150009155\n",
      "Eval Loss:  0.40612828731536865\n",
      "Eval Loss:  0.41099175810813904\n",
      "Eval Loss:  0.4250190258026123\n",
      "Eval Loss:  0.40262332558631897\n",
      "Eval Loss:  0.46291568875312805\n",
      "Eval Loss:  0.4971170127391815\n",
      "Eval Loss:  0.39429834485054016\n",
      "Eval Loss:  0.42462706565856934\n",
      "Eval Loss:  0.4709979295730591\n",
      "Eval Loss:  0.4388938546180725\n",
      "Eval Loss:  0.44218942523002625\n",
      "Eval Loss:  0.45682257413864136\n",
      "Eval Loss:  0.36623677611351013\n",
      "Eval Loss:  0.46732422709465027\n",
      "Eval Loss:  0.46217721700668335\n",
      "Eval Loss:  0.3681108355522156\n",
      "[[14386  2681]\n",
      " [ 2918  9688]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84     17067\n",
      "           1       0.78      0.77      0.78     12606\n",
      "\n",
      "    accuracy                           0.81     29673\n",
      "   macro avg       0.81      0.81      0.81     29673\n",
      "weighted avg       0.81      0.81      0.81     29673\n",
      "\n",
      "acc:  0.8113099450679069\n",
      "pre:  0.7832484436898698\n",
      "rec:  0.7685229255909884\n",
      "ma F1:  0.806458430150496\n",
      "mi F1:  0.8113099450679069\n",
      "we F1:  0.8110652007010642\n",
      "29673 464\n",
      "Loss:  0.07717482000589371\n",
      "Loss:  0.12590505182743073\n",
      "Loss:  0.09080978482961655\n",
      "3 **********\n",
      "Epoch:  217.86347723007202  fold:  5  kers:  32\n",
      "epoch:  4\n",
      "29673 464\n",
      "Loss:  0.13741347193717957\n",
      "Loss:  0.10800834000110626\n",
      "Loss:  0.08302712440490723\n",
      "4 **********\n",
      "Epoch:  259.40839433670044  fold:  5  kers:  32\n",
      "epoch:  5\n",
      "29673 464\n",
      "Loss:  0.07785025984048843\n",
      "Loss:  0.1073317602276802\n",
      "Loss:  0.07543128728866577\n",
      "5 **********\n",
      "Epoch:  300.97226095199585  fold:  5  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.1217094361782074\n",
      "Eval Loss:  0.24449098110198975\n",
      "Eval Loss:  0.18379800021648407\n",
      "[[2951  146]\n",
      " [  51   70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      3097\n",
      "           1       0.32      0.58      0.42       121\n",
      "\n",
      "    accuracy                           0.94      3218\n",
      "   macro avg       0.65      0.77      0.69      3218\n",
      "weighted avg       0.96      0.94      0.95      3218\n",
      "\n",
      "acc:  0.9387818520820386\n",
      "pre:  0.32407407407407407\n",
      "rec:  0.5785123966942148\n",
      "ma F1:  0.6915649449756563\n",
      "mi F1:  0.9387818520820385\n",
      "we F1:  0.9469337459296976\n",
      "update!  Acc:  0.9387818520820386\n",
      "Eval Loss:  0.49290910363197327\n",
      "Eval Loss:  0.3082895874977112\n",
      "Eval Loss:  0.4629504680633545\n",
      "Eval Loss:  0.3734178841114044\n",
      "Eval Loss:  0.4195941090583801\n",
      "Eval Loss:  0.3656463325023651\n",
      "Eval Loss:  0.43405693769454956\n",
      "Eval Loss:  0.33139684796333313\n",
      "Eval Loss:  0.40955615043640137\n",
      "Eval Loss:  0.4325973689556122\n",
      "Eval Loss:  0.40272051095962524\n",
      "Eval Loss:  0.36137038469314575\n",
      "Eval Loss:  0.30489519238471985\n",
      "Eval Loss:  0.43264055252075195\n",
      "Eval Loss:  0.42060717940330505\n",
      "Eval Loss:  0.4347935914993286\n",
      "Eval Loss:  0.44249334931373596\n",
      "Eval Loss:  0.5419644713401794\n",
      "Eval Loss:  0.4677690267562866\n",
      "Eval Loss:  0.37181028723716736\n",
      "Eval Loss:  0.4257725775241852\n",
      "Eval Loss:  0.5100666880607605\n",
      "Eval Loss:  0.4819154739379883\n",
      "Eval Loss:  0.4501907229423523\n",
      "Eval Loss:  0.5088417530059814\n",
      "Eval Loss:  0.3797672390937805\n",
      "Eval Loss:  0.464108943939209\n",
      "Eval Loss:  0.4604994058609009\n",
      "Eval Loss:  0.3161391615867615\n",
      "[[15971  1096]\n",
      " [ 4111  8495]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86     17067\n",
      "           1       0.89      0.67      0.77     12606\n",
      "\n",
      "    accuracy                           0.82     29673\n",
      "   macro avg       0.84      0.80      0.81     29673\n",
      "weighted avg       0.83      0.82      0.82     29673\n",
      "\n",
      "acc:  0.8245206079600984\n",
      "pre:  0.8857262016473777\n",
      "rec:  0.6738854513723623\n",
      "ma F1:  0.8126267349620451\n",
      "mi F1:  0.8245206079600984\n",
      "we F1:  0.8197239216185882\n",
      "29673 464\n",
      "Loss:  0.08908170461654663\n",
      "Loss:  0.10799141228199005\n",
      "Loss:  0.09153907746076584\n",
      "6 **********\n",
      "Epoch:  381.8061275482178  fold:  5  kers:  32\n",
      "epoch:  7\n",
      "29673 464\n",
      "Loss:  0.1252368986606598\n",
      "Loss:  0.08004780858755112\n",
      "Loss:  0.08205546438694\n",
      "7 **********\n",
      "Epoch:  423.51361060142517  fold:  5  kers:  32\n",
      "epoch:  8\n",
      "29673 464\n",
      "Loss:  0.13101203739643097\n",
      "Loss:  0.09612147510051727\n",
      "Loss:  0.057619858533144\n",
      "8 **********\n",
      "Epoch:  465.114378452301  fold:  5  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.12262767553329468\n",
      "Eval Loss:  0.20199398696422577\n",
      "Eval Loss:  0.15728329122066498\n",
      "[[2978  119]\n",
      " [  43   78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      3097\n",
      "           1       0.40      0.64      0.49       121\n",
      "\n",
      "    accuracy                           0.95      3218\n",
      "   macro avg       0.69      0.80      0.73      3218\n",
      "weighted avg       0.96      0.95      0.96      3218\n",
      "\n",
      "acc:  0.949658172778123\n",
      "pre:  0.39593908629441626\n",
      "rec:  0.6446280991735537\n",
      "ma F1:  0.7320433980768164\n",
      "mi F1:  0.949658172778123\n",
      "we F1:  0.955361180666847\n",
      "update!  Acc:  0.949658172778123\n",
      "Eval Loss:  0.4472108781337738\n",
      "Eval Loss:  0.29175448417663574\n",
      "Eval Loss:  0.42868560552597046\n",
      "Eval Loss:  0.34688568115234375\n",
      "Eval Loss:  0.39289724826812744\n",
      "Eval Loss:  0.3243606686592102\n",
      "Eval Loss:  0.3739933371543884\n",
      "Eval Loss:  0.3072737455368042\n",
      "Eval Loss:  0.36719682812690735\n",
      "Eval Loss:  0.37937718629837036\n",
      "Eval Loss:  0.3511882424354553\n",
      "Eval Loss:  0.32325562834739685\n",
      "Eval Loss:  0.28544050455093384\n",
      "Eval Loss:  0.3860519230365753\n",
      "Eval Loss:  0.3844982087612152\n",
      "Eval Loss:  0.40234845876693726\n",
      "Eval Loss:  0.39601534605026245\n",
      "Eval Loss:  0.49687156081199646\n",
      "Eval Loss:  0.4310090243816376\n",
      "Eval Loss:  0.34591782093048096\n",
      "Eval Loss:  0.39275258779525757\n",
      "Eval Loss:  0.4519549608230591\n",
      "Eval Loss:  0.4371701776981354\n",
      "Eval Loss:  0.3844347894191742\n",
      "Eval Loss:  0.4674986004829407\n",
      "Eval Loss:  0.3371483385562897\n",
      "Eval Loss:  0.3966580927371979\n",
      "Eval Loss:  0.4221661686897278\n",
      "Eval Loss:  0.2938246726989746\n",
      "[[15893  1174]\n",
      " [ 3624  8982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87     17067\n",
      "           1       0.88      0.71      0.79     12606\n",
      "\n",
      "    accuracy                           0.84     29673\n",
      "   macro avg       0.85      0.82      0.83     29673\n",
      "weighted avg       0.84      0.84      0.84     29673\n",
      "\n",
      "acc:  0.8383041822532269\n",
      "pre:  0.8844033083891296\n",
      "rec:  0.7125178486435031\n",
      "ma F1:  0.8290299286892558\n",
      "mi F1:  0.8383041822532269\n",
      "we F1:  0.8350163915960529\n",
      "29673 464\n",
      "Loss:  0.0843934491276741\n",
      "Loss:  0.11037470400333405\n",
      "Loss:  0.11640593409538269\n",
      "9 **********\n",
      "Epoch:  545.8963837623596  fold:  5  kers:  32\n",
      "epoch:  10\n",
      "29673 464\n",
      "Loss:  0.09885551780462265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0957554280757904\n",
      "Loss:  0.08865028619766235\n",
      "10 **********\n",
      "Epoch:  587.5709545612335  fold:  5  kers:  32\n",
      "epoch:  11\n",
      "29673 464\n",
      "Loss:  0.10464833676815033\n",
      "Loss:  0.0972057431936264\n",
      "Loss:  0.10574229806661606\n",
      "11 **********\n",
      "Epoch:  629.3362834453583  fold:  5  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.1084481030702591\n",
      "Eval Loss:  0.1633380800485611\n",
      "Eval Loss:  0.14396147429943085\n",
      "[[2999   98]\n",
      " [  50   71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      3097\n",
      "           1       0.42      0.59      0.49       121\n",
      "\n",
      "    accuracy                           0.95      3218\n",
      "   macro avg       0.70      0.78      0.73      3218\n",
      "weighted avg       0.96      0.95      0.96      3218\n",
      "\n",
      "acc:  0.9540087010565569\n",
      "pre:  0.42011834319526625\n",
      "rec:  0.5867768595041323\n",
      "ma F1:  0.7327872347588001\n",
      "mi F1:  0.9540087010565569\n",
      "we F1:  0.9576352824712742\n",
      "update!  Acc:  0.9540087010565569\n",
      "Eval Loss:  0.43606579303741455\n",
      "Eval Loss:  0.2943873703479767\n",
      "Eval Loss:  0.43142881989479065\n",
      "Eval Loss:  0.34916678071022034\n",
      "Eval Loss:  0.41605401039123535\n",
      "Eval Loss:  0.34463366866111755\n",
      "Eval Loss:  0.398011714220047\n",
      "Eval Loss:  0.3019499182701111\n",
      "Eval Loss:  0.3905476927757263\n",
      "Eval Loss:  0.37817418575286865\n",
      "Eval Loss:  0.3534594178199768\n",
      "Eval Loss:  0.33364441990852356\n",
      "Eval Loss:  0.2851802110671997\n",
      "Eval Loss:  0.39154037833213806\n",
      "Eval Loss:  0.40207022428512573\n",
      "Eval Loss:  0.4147518575191498\n",
      "Eval Loss:  0.41282209753990173\n",
      "Eval Loss:  0.5400287508964539\n",
      "Eval Loss:  0.42436715960502625\n",
      "Eval Loss:  0.37175145745277405\n",
      "Eval Loss:  0.4049147069454193\n",
      "Eval Loss:  0.4827384650707245\n",
      "Eval Loss:  0.4607172906398773\n",
      "Eval Loss:  0.399922639131546\n",
      "Eval Loss:  0.49847275018692017\n",
      "Eval Loss:  0.34887686371803284\n",
      "Eval Loss:  0.44854846596717834\n",
      "Eval Loss:  0.4418017268180847\n",
      "Eval Loss:  0.28810030221939087\n",
      "[[16134   933]\n",
      " [ 3926  8680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87     17067\n",
      "           1       0.90      0.69      0.78     12606\n",
      "\n",
      "    accuracy                           0.84     29673\n",
      "   macro avg       0.85      0.82      0.83     29673\n",
      "weighted avg       0.85      0.84      0.83     29673\n",
      "\n",
      "acc:  0.8362484413439828\n",
      "pre:  0.9029439300946634\n",
      "rec:  0.6885610026971284\n",
      "ma F1:  0.8252190930278152\n",
      "mi F1:  0.8362484413439828\n",
      "we F1:  0.831819833950598\n",
      "29673 464\n",
      "Loss:  0.05906014144420624\n",
      "Loss:  0.08898181468248367\n",
      "Loss:  0.06671342253684998\n",
      "12 **********\n",
      "Epoch:  710.1851086616516  fold:  5  kers:  32\n",
      "epoch:  13\n",
      "29673 464\n",
      "Loss:  0.07872666418552399\n",
      "Loss:  0.09679372608661652\n",
      "Loss:  0.11034636199474335\n",
      "13 **********\n",
      "Epoch:  751.7250399589539  fold:  5  kers:  32\n",
      "epoch:  14\n",
      "29673 464\n",
      "Loss:  0.09419534355401993\n",
      "Loss:  0.08746001869440079\n",
      "Loss:  0.11749875545501709\n",
      "14 **********\n",
      "Epoch:  793.2061276435852  fold:  5  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.12341433763504028\n",
      "Eval Loss:  0.17895916104316711\n",
      "Eval Loss:  0.14581477642059326\n",
      "[[2991  106]\n",
      " [  30   91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.46      0.75      0.57       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.73      0.86      0.78      3218\n",
      "weighted avg       0.97      0.96      0.96      3218\n",
      "\n",
      "acc:  0.9577377252952144\n",
      "pre:  0.4619289340101523\n",
      "rec:  0.7520661157024794\n",
      "ma F1:  0.775048778632389\n",
      "mi F1:  0.9577377252952144\n",
      "we F1:  0.9625254356215504\n",
      "update!  Acc:  0.9577377252952144\n",
      "Eval Loss:  0.3721979856491089\n",
      "Eval Loss:  0.28643834590911865\n",
      "Eval Loss:  0.3901849389076233\n",
      "Eval Loss:  0.32538068294525146\n",
      "Eval Loss:  0.35855114459991455\n",
      "Eval Loss:  0.2886247932910919\n",
      "Eval Loss:  0.2921271026134491\n",
      "Eval Loss:  0.2537286877632141\n",
      "Eval Loss:  0.31005561351776123\n",
      "Eval Loss:  0.3105793297290802\n",
      "Eval Loss:  0.27470284700393677\n",
      "Eval Loss:  0.27941977977752686\n",
      "Eval Loss:  0.26455432176589966\n",
      "Eval Loss:  0.3136283755302429\n",
      "Eval Loss:  0.3019886016845703\n",
      "Eval Loss:  0.3539269268512726\n",
      "Eval Loss:  0.35572826862335205\n",
      "Eval Loss:  0.4189314544200897\n",
      "Eval Loss:  0.40013664960861206\n",
      "Eval Loss:  0.3408464789390564\n",
      "Eval Loss:  0.35901474952697754\n",
      "Eval Loss:  0.40241506695747375\n",
      "Eval Loss:  0.3496556580066681\n",
      "Eval Loss:  0.31000828742980957\n",
      "Eval Loss:  0.42457684874534607\n",
      "Eval Loss:  0.30616670846939087\n",
      "Eval Loss:  0.3233153820037842\n",
      "Eval Loss:  0.3595978915691376\n",
      "Eval Loss:  0.24341616034507751\n",
      "[[15665  1402]\n",
      " [ 2837  9769]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88     17067\n",
      "           1       0.87      0.77      0.82     12606\n",
      "\n",
      "    accuracy                           0.86     29673\n",
      "   macro avg       0.86      0.85      0.85     29673\n",
      "weighted avg       0.86      0.86      0.86     29673\n",
      "\n",
      "acc:  0.8571428571428571\n",
      "pre:  0.8744964640587235\n",
      "rec:  0.7749484372521022\n",
      "ma F1:  0.8512708280791328\n",
      "mi F1:  0.8571428571428571\n",
      "we F1:  0.8557136913174765\n",
      "29673 464\n",
      "Loss:  0.10514006018638611\n",
      "Loss:  0.11233651638031006\n",
      "Loss:  0.10499301552772522\n",
      "15 **********\n",
      "Epoch:  873.9462454319  fold:  5  kers:  32\n",
      "epoch:  16\n",
      "29673 464\n",
      "Loss:  0.08472079783678055\n",
      "Loss:  0.0642223134636879\n",
      "Loss:  0.08894842118024826\n",
      "16 **********\n",
      "Epoch:  915.4901652336121  fold:  5  kers:  32\n",
      "epoch:  17\n",
      "29673 464\n",
      "Loss:  0.10803741961717606\n",
      "Loss:  0.06984212249517441\n",
      "Loss:  0.0825473964214325\n",
      "17 **********\n",
      "Epoch:  957.0889382362366  fold:  5  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.1045791357755661\n",
      "Eval Loss:  0.12950801849365234\n",
      "Eval Loss:  0.12226489186286926\n",
      "[[3036   61]\n",
      " [  46   75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.55      0.62      0.58       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.80      0.78      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9667495338719702\n",
      "pre:  0.5514705882352942\n",
      "rec:  0.6198347107438017\n",
      "ma F1:  0.7831704348165589\n",
      "mi F1:  0.96674953387197\n",
      "we F1:  0.9676795191762022\n",
      "update!  Acc:  0.9667495338719702\n",
      "Eval Loss:  0.41209670901298523\n",
      "Eval Loss:  0.28873634338378906\n",
      "Eval Loss:  0.42197734117507935\n",
      "Eval Loss:  0.33958104252815247\n",
      "Eval Loss:  0.40719491243362427\n",
      "Eval Loss:  0.32203593850135803\n",
      "Eval Loss:  0.38186657428741455\n",
      "Eval Loss:  0.27938783168792725\n",
      "Eval Loss:  0.36780866980552673\n",
      "Eval Loss:  0.35281500220298767\n",
      "Eval Loss:  0.31226280331611633\n",
      "Eval Loss:  0.3138185739517212\n",
      "Eval Loss:  0.25832024216651917\n",
      "Eval Loss:  0.3512275516986847\n",
      "Eval Loss:  0.3650546371936798\n",
      "Eval Loss:  0.3919549584388733\n",
      "Eval Loss:  0.410648375749588\n",
      "Eval Loss:  0.5291467905044556\n",
      "Eval Loss:  0.40764346718788147\n",
      "Eval Loss:  0.36531853675842285\n",
      "Eval Loss:  0.37781283259391785\n",
      "Eval Loss:  0.4473770558834076\n",
      "Eval Loss:  0.40572798252105713\n",
      "Eval Loss:  0.36212947964668274\n",
      "Eval Loss:  0.4664878845214844\n",
      "Eval Loss:  0.32563865184783936\n",
      "Eval Loss:  0.3975009024143219\n",
      "Eval Loss:  0.4206201136112213\n",
      "Eval Loss:  0.25737860798835754\n",
      "[[16256   811]\n",
      " [ 3748  8858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88     17067\n",
      "           1       0.92      0.70      0.80     12606\n",
      "\n",
      "    accuracy                           0.85     29673\n",
      "   macro avg       0.86      0.83      0.84     29673\n",
      "weighted avg       0.86      0.85      0.84     29673\n",
      "\n",
      "acc:  0.8463586425369864\n",
      "pre:  0.9161236942806908\n",
      "rec:  0.702681262890687\n",
      "ma F1:  0.8361754307663509\n",
      "mi F1:  0.8463586425369864\n",
      "we F1:  0.8423159157229345\n",
      "29673 464\n",
      "Loss:  0.1158231794834137\n",
      "Loss:  0.10092958807945251\n",
      "Loss:  0.07309923321008682\n",
      "18 **********\n",
      "Epoch:  1037.8699464797974  fold:  5  kers:  32\n",
      "epoch:  19\n",
      "29673 464\n",
      "Loss:  0.07717529684305191\n",
      "Loss:  0.09609076380729675\n",
      "Loss:  0.10527340322732925\n",
      "19 **********\n",
      "Epoch:  1079.4707143306732  fold:  5  kers:  32\n",
      "epoch:  20\n",
      "29673 464\n",
      "Loss:  0.08341418951749802\n",
      "Loss:  0.09813088178634644\n",
      "Loss:  0.05768772214651108\n",
      "20 **********\n",
      "Epoch:  1121.1482770442963  fold:  5  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.11512593179941177\n",
      "Eval Loss:  0.1797836720943451\n",
      "Eval Loss:  0.15393929183483124\n",
      "[[2995  102]\n",
      " [  26   95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.48      0.79      0.60       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.74      0.88      0.79      3218\n",
      "weighted avg       0.97      0.96      0.96      3218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc:  0.9602237414543194\n",
      "pre:  0.48223350253807107\n",
      "rec:  0.7851239669421488\n",
      "ma F1:  0.7882812034187191\n",
      "mi F1:  0.9602237414543194\n",
      "we F1:  0.9647298217614594\n",
      "Eval Loss:  0.3572812080383301\n",
      "Eval Loss:  0.279135525226593\n",
      "Eval Loss:  0.3485376536846161\n",
      "Eval Loss:  0.3097371459007263\n",
      "Eval Loss:  0.33599382638931274\n",
      "Eval Loss:  0.28725680708885193\n",
      "Eval Loss:  0.2528509199619293\n",
      "Eval Loss:  0.2322043627500534\n",
      "Eval Loss:  0.27587080001831055\n",
      "Eval Loss:  0.28500017523765564\n",
      "Eval Loss:  0.26039132475852966\n",
      "Eval Loss:  0.2734539806842804\n",
      "Eval Loss:  0.25539594888687134\n",
      "Eval Loss:  0.2679072618484497\n",
      "Eval Loss:  0.2691010534763336\n",
      "Eval Loss:  0.3213508427143097\n",
      "Eval Loss:  0.35593077540397644\n",
      "Eval Loss:  0.39471957087516785\n",
      "Eval Loss:  0.38571611046791077\n",
      "Eval Loss:  0.34156882762908936\n",
      "Eval Loss:  0.34246575832366943\n",
      "Eval Loss:  0.3694496750831604\n",
      "Eval Loss:  0.31969377398490906\n",
      "Eval Loss:  0.3274345397949219\n",
      "Eval Loss:  0.40074819326400757\n",
      "Eval Loss:  0.2937000095844269\n",
      "Eval Loss:  0.30378955602645874\n",
      "Eval Loss:  0.3264840245246887\n",
      "Eval Loss:  0.21719680726528168\n",
      "[[15478  1589]\n",
      " [ 2389 10217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89     17067\n",
      "           1       0.87      0.81      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.87      0.86      0.86     29673\n",
      "weighted avg       0.87      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8659387321807704\n",
      "pre:  0.8654074199559546\n",
      "rec:  0.8104870696493733\n",
      "ma F1:  0.86158774054313\n",
      "mi F1:  0.8659387321807704\n",
      "we F1:  0.8652771101868316\n",
      "29673 464\n",
      "Loss:  0.07909051328897476\n",
      "Loss:  0.06688115000724792\n",
      "Loss:  0.07667995244264603\n",
      "21 **********\n",
      "Epoch:  1201.7038881778717  fold:  5  kers:  32\n",
      "epoch:  22\n",
      "29673 464\n",
      "Loss:  0.0952165424823761\n",
      "Loss:  0.08718807995319366\n",
      "Loss:  0.11249896138906479\n",
      "22 **********\n",
      "Epoch:  1243.2627675533295  fold:  5  kers:  32\n",
      "epoch:  23\n",
      "29673 464\n",
      "Loss:  0.08069277554750443\n",
      "Loss:  0.07463967055082321\n",
      "Loss:  0.07552273571491241\n",
      "23 **********\n",
      "Epoch:  1284.7618081569672  fold:  5  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.11115051060914993\n",
      "Eval Loss:  0.16622282564640045\n",
      "Eval Loss:  0.1125081330537796\n",
      "[[3022   75]\n",
      " [  22   99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.57      0.82      0.67       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.90      0.83      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9698570540708514\n",
      "pre:  0.5689655172413793\n",
      "rec:  0.8181818181818182\n",
      "ma F1:  0.8276954838139872\n",
      "mi F1:  0.9698570540708514\n",
      "we F1:  0.9724347356389711\n",
      "update!  Acc:  0.9698570540708514\n",
      "Eval Loss:  0.33223283290863037\n",
      "Eval Loss:  0.3014298379421234\n",
      "Eval Loss:  0.3265705108642578\n",
      "Eval Loss:  0.32521897554397583\n",
      "Eval Loss:  0.3348320722579956\n",
      "Eval Loss:  0.2734870910644531\n",
      "Eval Loss:  0.24364835023880005\n",
      "Eval Loss:  0.23857246339321136\n",
      "Eval Loss:  0.28603339195251465\n",
      "Eval Loss:  0.29241666197776794\n",
      "Eval Loss:  0.25646960735321045\n",
      "Eval Loss:  0.2746111750602722\n",
      "Eval Loss:  0.2408502995967865\n",
      "Eval Loss:  0.27565911412239075\n",
      "Eval Loss:  0.25953152775764465\n",
      "Eval Loss:  0.3095550835132599\n",
      "Eval Loss:  0.332544207572937\n",
      "Eval Loss:  0.40349018573760986\n",
      "Eval Loss:  0.36915984749794006\n",
      "Eval Loss:  0.3062950670719147\n",
      "Eval Loss:  0.3352758288383484\n",
      "Eval Loss:  0.3656134605407715\n",
      "Eval Loss:  0.29863545298576355\n",
      "Eval Loss:  0.294119656085968\n",
      "Eval Loss:  0.39476335048675537\n",
      "Eval Loss:  0.297779381275177\n",
      "Eval Loss:  0.2753620445728302\n",
      "Eval Loss:  0.3248084485530853\n",
      "Eval Loss:  0.21929974853992462\n",
      "[[15673  1394]\n",
      " [ 2481 10125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     17067\n",
      "           1       0.88      0.80      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.87      0.86      0.86     29673\n",
      "weighted avg       0.87      0.87      0.87     29673\n",
      "\n",
      "acc:  0.869409901257035\n",
      "pre:  0.8789825505686257\n",
      "rec:  0.8031889576392194\n",
      "ma F1:  0.8646793238784034\n",
      "mi F1:  0.869409901257035\n",
      "we F1:  0.8684830559775519\n",
      "29673 464\n",
      "Loss:  0.07722126692533493\n",
      "Loss:  0.07896244525909424\n",
      "Loss:  0.10697788000106812\n",
      "24 **********\n",
      "Epoch:  1365.3184161186218  fold:  5  kers:  32\n",
      "epoch:  25\n",
      "29673 464\n",
      "Loss:  0.10397721081972122\n",
      "Loss:  0.06590922921895981\n",
      "Loss:  0.11048013716936111\n",
      "25 **********\n",
      "Epoch:  1406.782549381256  fold:  5  kers:  32\n",
      "epoch:  26\n",
      "29673 464\n",
      "Loss:  0.0886935442686081\n",
      "Loss:  0.09886117279529572\n",
      "Loss:  0.071771040558815\n",
      "26 **********\n",
      "Epoch:  1448.2307250499725  fold:  5  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.10046906024217606\n",
      "Eval Loss:  0.14672020077705383\n",
      "Eval Loss:  0.11694993078708649\n",
      "[[3029   68]\n",
      " [  37   84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.55      0.69      0.62       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.84      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9673710379117464\n",
      "pre:  0.5526315789473685\n",
      "rec:  0.6942148760330579\n",
      "ma F1:  0.7991737290779966\n",
      "mi F1:  0.9673710379117464\n",
      "we F1:  0.96914153589947\n",
      "Eval Loss:  0.3473692238330841\n",
      "Eval Loss:  0.2728593945503235\n",
      "Eval Loss:  0.3363597095012665\n",
      "Eval Loss:  0.32048189640045166\n",
      "Eval Loss:  0.34289881587028503\n",
      "Eval Loss:  0.28329771757125854\n",
      "Eval Loss:  0.26344582438468933\n",
      "Eval Loss:  0.23305124044418335\n",
      "Eval Loss:  0.2959271967411041\n",
      "Eval Loss:  0.29897981882095337\n",
      "Eval Loss:  0.2493615299463272\n",
      "Eval Loss:  0.27610424160957336\n",
      "Eval Loss:  0.2243904173374176\n",
      "Eval Loss:  0.2741719186306\n",
      "Eval Loss:  0.306633859872818\n",
      "Eval Loss:  0.34563639760017395\n",
      "Eval Loss:  0.35650837421417236\n",
      "Eval Loss:  0.45022857189178467\n",
      "Eval Loss:  0.3653182089328766\n",
      "Eval Loss:  0.3069521486759186\n",
      "Eval Loss:  0.3510277569293976\n",
      "Eval Loss:  0.3808037340641022\n",
      "Eval Loss:  0.3130471706390381\n",
      "Eval Loss:  0.3127903938293457\n",
      "Eval Loss:  0.41543036699295044\n",
      "Eval Loss:  0.2891698479652405\n",
      "Eval Loss:  0.31081289052963257\n",
      "Eval Loss:  0.32312557101249695\n",
      "Eval Loss:  0.23016181588172913\n",
      "[[16032  1035]\n",
      " [ 2849  9757]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     17067\n",
      "           1       0.90      0.77      0.83     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.86      0.86     29673\n",
      "weighted avg       0.87      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8691065952212449\n",
      "pre:  0.9040956263899185\n",
      "rec:  0.7739965095986039\n",
      "ma F1:  0.8629789762045572\n",
      "mi F1:  0.8691065952212448\n",
      "we F1:  0.867335200656102\n",
      "29673 464\n",
      "Loss:  0.0971415787935257\n",
      "Loss:  0.10130534321069717\n",
      "Loss:  0.06979355961084366\n",
      "27 **********\n",
      "Epoch:  1528.9987680912018  fold:  5  kers:  32\n",
      "epoch:  28\n",
      "29673 464\n",
      "Loss:  0.09744994342327118\n",
      "Loss:  0.08918983489274979\n",
      "Loss:  0.054172419011592865\n",
      "28 **********\n",
      "Epoch:  1570.5895624160767  fold:  5  kers:  32\n",
      "epoch:  29\n",
      "29673 464\n",
      "Loss:  0.0695737823843956\n",
      "Loss:  0.06526109576225281\n",
      "Loss:  0.046326324343681335\n",
      "29 **********\n",
      "Epoch:  1612.2212479114532  fold:  5  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.09927236288785934\n",
      "Eval Loss:  0.11634314805269241\n",
      "Eval Loss:  0.09462559968233109\n",
      "[[3043   54]\n",
      " [  30   91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.63      0.75      0.68       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.81      0.87      0.84      3218\n",
      "weighted avg       0.98      0.97      0.98      3218\n",
      "\n",
      "acc:  0.9738968303293971\n",
      "pre:  0.6275862068965518\n",
      "rec:  0.7520661157024794\n",
      "ma F1:  0.8352981318775057\n",
      "mi F1:  0.9738968303293971\n",
      "we F1:  0.9750236490159977\n",
      "update!  Acc:  0.9738968303293971\n",
      "Eval Loss:  0.3199129104614258\n",
      "Eval Loss:  0.2740350365638733\n",
      "Eval Loss:  0.32518675923347473\n",
      "Eval Loss:  0.3210260272026062\n",
      "Eval Loss:  0.32638314366340637\n",
      "Eval Loss:  0.27790510654449463\n",
      "Eval Loss:  0.22631040215492249\n",
      "Eval Loss:  0.21513959765434265\n",
      "Eval Loss:  0.25658562779426575\n",
      "Eval Loss:  0.2829574644565582\n",
      "Eval Loss:  0.23837991058826447\n",
      "Eval Loss:  0.27110591530799866\n",
      "Eval Loss:  0.23547129333019257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.25959745049476624\n",
      "Eval Loss:  0.26676180958747864\n",
      "Eval Loss:  0.3265629708766937\n",
      "Eval Loss:  0.3462204933166504\n",
      "Eval Loss:  0.4271092414855957\n",
      "Eval Loss:  0.36334481835365295\n",
      "Eval Loss:  0.2880401313304901\n",
      "Eval Loss:  0.3284943699836731\n",
      "Eval Loss:  0.34726983308792114\n",
      "Eval Loss:  0.2919248938560486\n",
      "Eval Loss:  0.2969985902309418\n",
      "Eval Loss:  0.41961848735809326\n",
      "Eval Loss:  0.29106655716896057\n",
      "Eval Loss:  0.2800256907939911\n",
      "Eval Loss:  0.2987341284751892\n",
      "Eval Loss:  0.22556062042713165\n",
      "[[15867  1200]\n",
      " [ 2534 10072]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89     17067\n",
      "           1       0.89      0.80      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.86      0.87     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8741616958177467\n",
      "pre:  0.893541518807665\n",
      "rec:  0.7989846105029351\n",
      "ma F1:  0.869171873398433\n",
      "mi F1:  0.8741616958177467\n",
      "we F1:  0.8730130464463294\n",
      "29673 464\n",
      "Loss:  0.06622836738824844\n",
      "Loss:  0.09550930559635162\n",
      "Loss:  0.0755748301744461\n",
      "30 **********\n",
      "Epoch:  1693.197732925415  fold:  5  kers:  32\n",
      "epoch:  31\n",
      "29673 464\n",
      "Loss:  0.07498291879892349\n",
      "Loss:  0.08367517590522766\n",
      "Loss:  0.10053473711013794\n",
      "31 **********\n",
      "Epoch:  1734.9550824165344  fold:  5  kers:  32\n",
      "epoch:  32\n",
      "29673 464\n",
      "Loss:  0.08025704324245453\n",
      "Loss:  0.07000561058521271\n",
      "Loss:  0.107660673558712\n",
      "32 **********\n",
      "Epoch:  1776.4371676445007  fold:  5  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.08899961411952972\n",
      "Eval Loss:  0.09069519490003586\n",
      "Eval Loss:  0.07839146256446838\n",
      "[[3049   48]\n",
      " [  35   86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.64      0.71      0.67       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.82      0.85      0.83      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9742075823492853\n",
      "pre:  0.6417910447761194\n",
      "rec:  0.7107438016528925\n",
      "ma F1:  0.8305407780326173\n",
      "mi F1:  0.9742075823492853\n",
      "we F1:  0.9748379125740968\n",
      "update!  Acc:  0.9742075823492853\n",
      "Eval Loss:  0.3130667209625244\n",
      "Eval Loss:  0.27325764298439026\n",
      "Eval Loss:  0.3312794864177704\n",
      "Eval Loss:  0.31371650099754333\n",
      "Eval Loss:  0.3252054452896118\n",
      "Eval Loss:  0.2765200138092041\n",
      "Eval Loss:  0.2441590130329132\n",
      "Eval Loss:  0.23110640048980713\n",
      "Eval Loss:  0.2595598101615906\n",
      "Eval Loss:  0.30654212832450867\n",
      "Eval Loss:  0.2345278561115265\n",
      "Eval Loss:  0.268842875957489\n",
      "Eval Loss:  0.23097150027751923\n",
      "Eval Loss:  0.26931095123291016\n",
      "Eval Loss:  0.29238346219062805\n",
      "Eval Loss:  0.3159116804599762\n",
      "Eval Loss:  0.3500250577926636\n",
      "Eval Loss:  0.4368167519569397\n",
      "Eval Loss:  0.3470394015312195\n",
      "Eval Loss:  0.2889914810657501\n",
      "Eval Loss:  0.32315534353256226\n",
      "Eval Loss:  0.3485809564590454\n",
      "Eval Loss:  0.29513123631477356\n",
      "Eval Loss:  0.28798148036003113\n",
      "Eval Loss:  0.4024367332458496\n",
      "Eval Loss:  0.2847738564014435\n",
      "Eval Loss:  0.2895936369895935\n",
      "Eval Loss:  0.3115962743759155\n",
      "Eval Loss:  0.2235109955072403\n",
      "[[16058  1009]\n",
      " [ 2726  9880]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.90     17067\n",
      "           1       0.91      0.78      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.86      0.87     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8741279951471034\n",
      "pre:  0.9073376802277527\n",
      "rec:  0.7837537680469617\n",
      "ma F1:  0.8684244059982269\n",
      "mi F1:  0.8741279951471034\n",
      "we F1:  0.8725428441971811\n",
      "29673 464\n",
      "Loss:  0.05541544407606125\n",
      "Loss:  0.08775835484266281\n",
      "Loss:  0.050369102507829666\n",
      "33 **********\n",
      "Epoch:  1857.200223684311  fold:  5  kers:  32\n",
      "epoch:  34\n",
      "29673 464\n",
      "Loss:  0.07450830191373825\n",
      "Loss:  0.10583765059709549\n",
      "Loss:  0.11673614382743835\n",
      "34 **********\n",
      "Epoch:  1898.7521226406097  fold:  5  kers:  32\n",
      "epoch:  35\n",
      "29673 464\n",
      "Loss:  0.07899398356676102\n",
      "Loss:  0.048209283500909805\n",
      "Loss:  0.0703907459974289\n",
      "35 **********\n",
      "Epoch:  1940.418714761734  fold:  5  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.0927257388830185\n",
      "Eval Loss:  0.10165942460298538\n",
      "Eval Loss:  0.07092124968767166\n",
      "[[3045   52]\n",
      " [  28   93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.64      0.77      0.70       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.82      0.88      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9751398384089497\n",
      "pre:  0.6413793103448275\n",
      "rec:  0.768595041322314\n",
      "ma F1:  0.8431410779785768\n",
      "mi F1:  0.9751398384089497\n",
      "we F1:  0.9762129990628552\n",
      "update!  Acc:  0.9751398384089497\n",
      "Eval Loss:  0.2960774302482605\n",
      "Eval Loss:  0.27672216296195984\n",
      "Eval Loss:  0.3001697063446045\n",
      "Eval Loss:  0.2847967743873596\n",
      "Eval Loss:  0.2884564995765686\n",
      "Eval Loss:  0.27226874232292175\n",
      "Eval Loss:  0.20908577740192413\n",
      "Eval Loss:  0.2127259224653244\n",
      "Eval Loss:  0.2225678712129593\n",
      "Eval Loss:  0.2709626853466034\n",
      "Eval Loss:  0.21918241679668427\n",
      "Eval Loss:  0.24992568790912628\n",
      "Eval Loss:  0.22234541177749634\n",
      "Eval Loss:  0.23626135289669037\n",
      "Eval Loss:  0.2541291415691376\n",
      "Eval Loss:  0.29954245686531067\n",
      "Eval Loss:  0.3349013328552246\n",
      "Eval Loss:  0.37692588567733765\n",
      "Eval Loss:  0.34882989525794983\n",
      "Eval Loss:  0.26767420768737793\n",
      "Eval Loss:  0.2986144423484802\n",
      "Eval Loss:  0.31631284952163696\n",
      "Eval Loss:  0.26560962200164795\n",
      "Eval Loss:  0.2805020809173584\n",
      "Eval Loss:  0.3849097788333893\n",
      "Eval Loss:  0.2781863510608673\n",
      "Eval Loss:  0.27390891313552856\n",
      "Eval Loss:  0.2849106192588806\n",
      "Eval Loss:  0.20676100254058838\n",
      "[[15794  1273]\n",
      " [ 2233 10373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     17067\n",
      "           1       0.89      0.82      0.86     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.88      0.87      0.88     29673\n",
      "weighted avg       0.88      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8818454487244296\n",
      "pre:  0.8906920831186673\n",
      "rec:  0.8228621291448517\n",
      "ma F1:  0.8777657429948441\n",
      "mi F1:  0.8818454487244296\n",
      "we F1:  0.8811229773168661\n",
      "29673 464\n",
      "Loss:  0.06740205734968185\n",
      "Loss:  0.07456322014331818\n",
      "Loss:  0.06868831813335419\n",
      "36 **********\n",
      "Epoch:  2020.9124908447266  fold:  5  kers:  32\n",
      "epoch:  37\n",
      "29673 464\n",
      "Loss:  0.06516415625810623\n",
      "Loss:  0.09679968655109406\n",
      "Loss:  0.0635886937379837\n",
      "37 **********\n",
      "Epoch:  2062.4284851551056  fold:  5  kers:  32\n",
      "epoch:  38\n",
      "29673 464\n",
      "Loss:  0.07014946639537811\n",
      "Loss:  0.06052833050489426\n",
      "Loss:  0.05720020458102226\n",
      "38 **********\n",
      "Epoch:  2104.034239768982  fold:  5  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.09461785852909088\n",
      "Eval Loss:  0.09200593829154968\n",
      "Eval Loss:  0.08613766729831696\n",
      "[[3031   66]\n",
      " [  27   94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.59      0.78      0.67       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.79      0.88      0.83      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n",
      "\n",
      "acc:  0.971100062150404\n",
      "pre:  0.5875\n",
      "rec:  0.7768595041322314\n",
      "ma F1:  0.8269647394850119\n",
      "mi F1:  0.971100062150404\n",
      "we F1:  0.9730140143410577\n",
      "Eval Loss:  0.2828490436077118\n",
      "Eval Loss:  0.2831348776817322\n",
      "Eval Loss:  0.27828118205070496\n",
      "Eval Loss:  0.28819990158081055\n",
      "Eval Loss:  0.25536060333251953\n",
      "Eval Loss:  0.27545276284217834\n",
      "Eval Loss:  0.19729648530483246\n",
      "Eval Loss:  0.19293546676635742\n",
      "Eval Loss:  0.20259860157966614\n",
      "Eval Loss:  0.2627992630004883\n",
      "Eval Loss:  0.2123921811580658\n",
      "Eval Loss:  0.23257027566432953\n",
      "Eval Loss:  0.231115460395813\n",
      "Eval Loss:  0.22593607008457184\n",
      "Eval Loss:  0.24020427465438843\n",
      "Eval Loss:  0.2879255712032318\n",
      "Eval Loss:  0.30936741828918457\n",
      "Eval Loss:  0.3430333435535431\n",
      "Eval Loss:  0.3406416177749634\n",
      "Eval Loss:  0.2537462115287781\n",
      "Eval Loss:  0.28614097833633423\n",
      "Eval Loss:  0.30668288469314575\n",
      "Eval Loss:  0.26321500539779663\n",
      "Eval Loss:  0.26432257890701294\n",
      "Eval Loss:  0.3753814399242401\n",
      "Eval Loss:  0.2712402045726776\n",
      "Eval Loss:  0.2698427140712738\n",
      "Eval Loss:  0.2684970200061798\n",
      "Eval Loss:  0.2110472172498703\n",
      "[[15622  1445]\n",
      " [ 1910 10696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90     17067\n",
      "           1       0.88      0.85      0.86     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.88      0.88     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8869342499915749\n",
      "pre:  0.8809817972160449\n",
      "rec:  0.8484848484848485\n",
      "ma F1:  0.8837299455051145\n",
      "mi F1:  0.8869342499915749\n",
      "we F1:  0.8866317730150819\n",
      "29673 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05774485692381859\n",
      "Loss:  0.09987516701221466\n",
      "Loss:  0.05640237033367157\n",
      "39 **********\n",
      "Epoch:  2184.6457011699677  fold:  5  kers:  32\n",
      "epoch:  40\n",
      "29673 464\n",
      "Loss:  0.06666210293769836\n",
      "Loss:  0.08957972377538681\n",
      "Loss:  0.0860263854265213\n",
      "40 **********\n",
      "Epoch:  2226.221535682678  fold:  5  kers:  32\n",
      "epoch:  41\n",
      "29673 464\n",
      "Loss:  0.06147018074989319\n",
      "Loss:  0.07487582415342331\n",
      "Loss:  0.07403172552585602\n",
      "41 **********\n",
      "Epoch:  2267.814325094223  fold:  5  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.09002029895782471\n",
      "Eval Loss:  0.08049864321947098\n",
      "Eval Loss:  0.06317497789859772\n",
      "[[3054   43]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.67      0.73      0.70       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.83      0.86      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9763828464885022\n",
      "pre:  0.6717557251908397\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.8430614591675394\n",
      "mi F1:  0.9763828464885022\n",
      "we F1:  0.9768323454342909\n",
      "update!  Acc:  0.9763828464885022\n",
      "Eval Loss:  0.2892071008682251\n",
      "Eval Loss:  0.2626687288284302\n",
      "Eval Loss:  0.2882375121116638\n",
      "Eval Loss:  0.2766475975513458\n",
      "Eval Loss:  0.29297634959220886\n",
      "Eval Loss:  0.27721381187438965\n",
      "Eval Loss:  0.22982178628444672\n",
      "Eval Loss:  0.20285387337207794\n",
      "Eval Loss:  0.21744151413440704\n",
      "Eval Loss:  0.27261295914649963\n",
      "Eval Loss:  0.21816609799861908\n",
      "Eval Loss:  0.2334294319152832\n",
      "Eval Loss:  0.2141595482826233\n",
      "Eval Loss:  0.23266951739788055\n",
      "Eval Loss:  0.2646321654319763\n",
      "Eval Loss:  0.2912180721759796\n",
      "Eval Loss:  0.32458558678627014\n",
      "Eval Loss:  0.36627858877182007\n",
      "Eval Loss:  0.34239310026168823\n",
      "Eval Loss:  0.24690629541873932\n",
      "Eval Loss:  0.28308582305908203\n",
      "Eval Loss:  0.3207450211048126\n",
      "Eval Loss:  0.27172428369522095\n",
      "Eval Loss:  0.27591845393180847\n",
      "Eval Loss:  0.36993396282196045\n",
      "Eval Loss:  0.27167075872421265\n",
      "Eval Loss:  0.27920159697532654\n",
      "Eval Loss:  0.2800722122192383\n",
      "Eval Loss:  0.2071690857410431\n",
      "[[15869  1198]\n",
      " [ 2204 10402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     17067\n",
      "           1       0.90      0.83      0.86     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.88      0.88     29673\n",
      "weighted avg       0.89      0.89      0.88     29673\n",
      "\n",
      "acc:  0.8853503184713376\n",
      "pre:  0.8967241379310344\n",
      "rec:  0.8251626209741393\n",
      "ma F1:  0.8813217920682798\n",
      "mi F1:  0.8853503184713376\n",
      "we F1:  0.8846090165577696\n",
      "29673 464\n",
      "Loss:  0.07223556190729141\n",
      "Loss:  0.07446229457855225\n",
      "Loss:  0.0624103769659996\n",
      "42 **********\n",
      "Epoch:  2350.7046933174133  fold:  5  kers:  32\n",
      "epoch:  43\n",
      "29673 464\n",
      "Loss:  0.0706845074892044\n",
      "Loss:  0.07642447203397751\n",
      "Loss:  0.08100593090057373\n",
      "43 **********\n",
      "Epoch:  2392.3623094558716  fold:  5  kers:  32\n",
      "epoch:  44\n",
      "29673 464\n",
      "Loss:  0.08423271030187607\n",
      "Loss:  0.06672312319278717\n",
      "Loss:  0.059282414615154266\n",
      "44 **********\n",
      "Epoch:  2434.051839828491  fold:  5  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.09222853928804398\n",
      "Eval Loss:  0.098828986287117\n",
      "Eval Loss:  0.061795201152563095\n",
      "[[3029   68]\n",
      " [  23   98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.59      0.81      0.68       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.79      0.89      0.83      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9717215661901802\n",
      "pre:  0.5903614457831325\n",
      "rec:  0.8099173553719008\n",
      "ma F1:  0.8340638374671272\n",
      "mi F1:  0.9717215661901802\n",
      "we F1:  0.9738350420661737\n",
      "Eval Loss:  0.2816069424152374\n",
      "Eval Loss:  0.2831043601036072\n",
      "Eval Loss:  0.25670602917671204\n",
      "Eval Loss:  0.28353333473205566\n",
      "Eval Loss:  0.24641311168670654\n",
      "Eval Loss:  0.28178873658180237\n",
      "Eval Loss:  0.18850970268249512\n",
      "Eval Loss:  0.21034005284309387\n",
      "Eval Loss:  0.20114372670650482\n",
      "Eval Loss:  0.270774781703949\n",
      "Eval Loss:  0.2194477617740631\n",
      "Eval Loss:  0.22707276046276093\n",
      "Eval Loss:  0.22493331134319305\n",
      "Eval Loss:  0.22422415018081665\n",
      "Eval Loss:  0.22900812327861786\n",
      "Eval Loss:  0.27266356348991394\n",
      "Eval Loss:  0.28274309635162354\n",
      "Eval Loss:  0.2924862802028656\n",
      "Eval Loss:  0.341286301612854\n",
      "Eval Loss:  0.24223527312278748\n",
      "Eval Loss:  0.2685491442680359\n",
      "Eval Loss:  0.3016843795776367\n",
      "Eval Loss:  0.25354406237602234\n",
      "Eval Loss:  0.2614341974258423\n",
      "Eval Loss:  0.3553465008735657\n",
      "Eval Loss:  0.2814337909221649\n",
      "Eval Loss:  0.2568169832229614\n",
      "Eval Loss:  0.2704235315322876\n",
      "Eval Loss:  0.20825371146202087\n",
      "[[15461  1606]\n",
      " [ 1662 10944]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90     17067\n",
      "           1       0.87      0.87      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8898662083375459\n",
      "pre:  0.8720318725099602\n",
      "rec:  0.8681580199904807\n",
      "ma F1:  0.8872535652462823\n",
      "mi F1:  0.8898662083375459\n",
      "we F1:  0.8898338178099588\n",
      "29673 464\n",
      "Loss:  0.08571143448352814\n",
      "Loss:  0.09885209798812866\n",
      "Loss:  0.0635872632265091\n",
      "45 **********\n",
      "Epoch:  2514.7251358032227  fold:  5  kers:  32\n",
      "epoch:  46\n",
      "29673 464\n",
      "Loss:  0.05706409737467766\n",
      "Loss:  0.10622262209653854\n",
      "Loss:  0.0549040324985981\n",
      "46 **********\n",
      "Epoch:  2556.438602209091  fold:  5  kers:  32\n",
      "epoch:  47\n",
      "29673 464\n",
      "Loss:  0.05943325161933899\n",
      "Loss:  0.08419138938188553\n",
      "Loss:  0.05416130647063255\n",
      "47 **********\n",
      "Epoch:  2598.175008058548  fold:  5  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.08298995345830917\n",
      "Eval Loss:  0.07812799513339996\n",
      "Eval Loss:  0.049211177974939346\n",
      "[[3057   40]\n",
      " [  37   84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.68      0.69      0.69       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.83      0.84      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9760720944686141\n",
      "pre:  0.6774193548387096\n",
      "rec:  0.6942148760330579\n",
      "ma F1:  0.836638438285991\n",
      "mi F1:  0.9760720944686141\n",
      "we F1:  0.9762127944243986\n",
      "Eval Loss:  0.27674081921577454\n",
      "Eval Loss:  0.2579818367958069\n",
      "Eval Loss:  0.269535630941391\n",
      "Eval Loss:  0.3023882806301117\n",
      "Eval Loss:  0.2550812363624573\n",
      "Eval Loss:  0.2791092097759247\n",
      "Eval Loss:  0.21743358671665192\n",
      "Eval Loss:  0.2159859985113144\n",
      "Eval Loss:  0.1995142698287964\n",
      "Eval Loss:  0.26791492104530334\n",
      "Eval Loss:  0.20700478553771973\n",
      "Eval Loss:  0.22407789528369904\n",
      "Eval Loss:  0.20384617149829865\n",
      "Eval Loss:  0.2252638041973114\n",
      "Eval Loss:  0.249226376414299\n",
      "Eval Loss:  0.2756292223930359\n",
      "Eval Loss:  0.3061882555484772\n",
      "Eval Loss:  0.33840876817703247\n",
      "Eval Loss:  0.3474034368991852\n",
      "Eval Loss:  0.2433317005634308\n",
      "Eval Loss:  0.27637919783592224\n",
      "Eval Loss:  0.2955104410648346\n",
      "Eval Loss:  0.2527692914009094\n",
      "Eval Loss:  0.2716487646102905\n",
      "Eval Loss:  0.3649553656578064\n",
      "Eval Loss:  0.26833054423332214\n",
      "Eval Loss:  0.25213462114334106\n",
      "Eval Loss:  0.28129738569259644\n",
      "Eval Loss:  0.18862546980381012\n",
      "[[15946  1121]\n",
      " [ 2098 10508]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     17067\n",
      "           1       0.90      0.83      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.88      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8915175411990699\n",
      "pre:  0.9036030613122367\n",
      "rec:  0.8335713152467079\n",
      "ma F1:  0.8877474513217732\n",
      "mi F1:  0.8915175411990699\n",
      "we F1:  0.8908402006676027\n",
      "29673 464\n",
      "Loss:  0.08481892943382263\n",
      "Loss:  0.07255373150110245\n",
      "Loss:  0.07273175567388535\n",
      "48 **********\n",
      "Epoch:  2678.9829440116882  fold:  5  kers:  32\n",
      "epoch:  49\n",
      "29673 464\n",
      "Loss:  0.0591767318546772\n",
      "Loss:  0.04443937540054321\n",
      "Loss:  0.08308031409978867\n",
      "49 **********\n",
      "Epoch:  2720.591690301895  fold:  5  kers:  32\n",
      "epoch:  50\n",
      "29673 464\n",
      "Loss:  0.07589910924434662\n",
      "Loss:  0.064368337392807\n",
      "Loss:  0.08344539999961853\n",
      "50 **********\n",
      "Epoch:  2762.1874718666077  fold:  5  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.08290314674377441\n",
      "Eval Loss:  0.06058194860816002\n",
      "Eval Loss:  0.036309078335762024\n",
      "[[3065   32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [  31   90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.74      0.74      0.74       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.87      0.87      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9804226227470478\n",
      "pre:  0.7377049180327869\n",
      "rec:  0.743801652892562\n",
      "ma F1:  0.8652839825131122\n",
      "mi F1:  0.9804226227470478\n",
      "we F1:  0.980461324810992\n",
      "update!  Acc:  0.9804226227470478\n",
      "Eval Loss:  0.2765670418739319\n",
      "Eval Loss:  0.2886659801006317\n",
      "Eval Loss:  0.2612667679786682\n",
      "Eval Loss:  0.2781524360179901\n",
      "Eval Loss:  0.2368774712085724\n",
      "Eval Loss:  0.3182971179485321\n",
      "Eval Loss:  0.22022667527198792\n",
      "Eval Loss:  0.2289344221353531\n",
      "Eval Loss:  0.19988076388835907\n",
      "Eval Loss:  0.2876666486263275\n",
      "Eval Loss:  0.23237554728984833\n",
      "Eval Loss:  0.22924895584583282\n",
      "Eval Loss:  0.23299522697925568\n",
      "Eval Loss:  0.24153119325637817\n",
      "Eval Loss:  0.22813038527965546\n",
      "Eval Loss:  0.27948394417762756\n",
      "Eval Loss:  0.32202473282814026\n",
      "Eval Loss:  0.34940794110298157\n",
      "Eval Loss:  0.35191628336906433\n",
      "Eval Loss:  0.24350813031196594\n",
      "Eval Loss:  0.2877004146575928\n",
      "Eval Loss:  0.3056245446205139\n",
      "Eval Loss:  0.26663947105407715\n",
      "Eval Loss:  0.290999174118042\n",
      "Eval Loss:  0.3614048957824707\n",
      "Eval Loss:  0.283724308013916\n",
      "Eval Loss:  0.2648126184940338\n",
      "Eval Loss:  0.3105369806289673\n",
      "Eval Loss:  0.18540190160274506\n",
      "[[15572  1495]\n",
      " [ 1914 10692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     17067\n",
      "           1       0.88      0.85      0.86     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.88      0.88      0.88     29673\n",
      "weighted avg       0.88      0.89      0.88     29673\n",
      "\n",
      "acc:  0.8851144137768342\n",
      "pre:  0.8773283006482318\n",
      "rec:  0.8481675392670157\n",
      "ma F1:  0.8819207415019141\n",
      "mi F1:  0.8851144137768342\n",
      "we F1:  0.8848402029810981\n",
      "29673 464\n",
      "Loss:  0.08698081970214844\n",
      "Loss:  0.05714832991361618\n",
      "Loss:  0.0735650509595871\n",
      "51 **********\n",
      "Epoch:  2842.7390933036804  fold:  5  kers:  32\n",
      "epoch:  52\n",
      "29673 464\n",
      "Loss:  0.05393827334046364\n",
      "Loss:  0.055393461138010025\n",
      "Loss:  0.055892691016197205\n",
      "52 **********\n",
      "Epoch:  2884.257082462311  fold:  5  kers:  32\n",
      "epoch:  53\n",
      "29673 464\n",
      "Loss:  0.05279625207185745\n",
      "Loss:  0.09573926031589508\n",
      "Loss:  0.05514419823884964\n",
      "53 **********\n",
      "Epoch:  2925.7820534706116  fold:  5  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.08400003612041473\n",
      "Eval Loss:  0.08850666135549545\n",
      "Eval Loss:  0.05319192260503769\n",
      "[[3043   54]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.62      0.74      0.67       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.81      0.86      0.83      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9732753262896209\n",
      "pre:  0.6223776223776224\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.8301542646163514\n",
      "mi F1:  0.9732753262896209\n",
      "we F1:  0.9743412245146758\n",
      "Eval Loss:  0.2501062750816345\n",
      "Eval Loss:  0.26796120405197144\n",
      "Eval Loss:  0.25356897711753845\n",
      "Eval Loss:  0.2721233665943146\n",
      "Eval Loss:  0.24816711246967316\n",
      "Eval Loss:  0.29080820083618164\n",
      "Eval Loss:  0.20149165391921997\n",
      "Eval Loss:  0.21054138243198395\n",
      "Eval Loss:  0.19410066306591034\n",
      "Eval Loss:  0.26616084575653076\n",
      "Eval Loss:  0.20379754900932312\n",
      "Eval Loss:  0.21225666999816895\n",
      "Eval Loss:  0.20265857875347137\n",
      "Eval Loss:  0.20260220766067505\n",
      "Eval Loss:  0.23162738978862762\n",
      "Eval Loss:  0.26803600788116455\n",
      "Eval Loss:  0.272474467754364\n",
      "Eval Loss:  0.30458351969718933\n",
      "Eval Loss:  0.34275349974632263\n",
      "Eval Loss:  0.2172727733850479\n",
      "Eval Loss:  0.2526269555091858\n",
      "Eval Loss:  0.29876673221588135\n",
      "Eval Loss:  0.2398357093334198\n",
      "Eval Loss:  0.2433699667453766\n",
      "Eval Loss:  0.35184478759765625\n",
      "Eval Loss:  0.2642706334590912\n",
      "Eval Loss:  0.23400001227855682\n",
      "Eval Loss:  0.27347543835639954\n",
      "Eval Loss:  0.18441908061504364\n",
      "[[15807  1260]\n",
      " [ 1820 10786]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     17067\n",
      "           1       0.90      0.86      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.8962019344184949\n",
      "pre:  0.8954009629752615\n",
      "rec:  0.855624305886086\n",
      "ma F1:  0.8931423448647404\n",
      "mi F1:  0.8962019344184949\n",
      "we F1:  0.8958606935999125\n",
      "29673 464\n",
      "Loss:  0.06557071954011917\n",
      "Loss:  0.03783562034368515\n",
      "Loss:  0.05803806334733963\n",
      "54 **********\n",
      "Epoch:  3006.625893354416  fold:  5  kers:  32\n",
      "epoch:  55\n",
      "29673 464\n",
      "Loss:  0.06596260517835617\n",
      "Loss:  0.08981915563344955\n",
      "Loss:  0.10752318054437637\n",
      "55 **********\n",
      "Epoch:  3048.368282556534  fold:  5  kers:  32\n",
      "epoch:  56\n",
      "29673 464\n",
      "Loss:  0.03758883848786354\n",
      "Loss:  0.07956758886575699\n",
      "Loss:  0.07761090993881226\n",
      "56 **********\n",
      "Epoch:  3090.0239040851593  fold:  5  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.07486909627914429\n",
      "Eval Loss:  0.08142754435539246\n",
      "Eval Loss:  0.036709729582071304\n",
      "[[3055   42]\n",
      " [  36   85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.67      0.70      0.69       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.83      0.84      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9757613424487259\n",
      "pre:  0.6692913385826772\n",
      "rec:  0.7024793388429752\n",
      "ma F1:  0.8364394144754675\n",
      "mi F1:  0.9757613424487259\n",
      "we F1:  0.9760428008890758\n",
      "Eval Loss:  0.26163968443870544\n",
      "Eval Loss:  0.2548734247684479\n",
      "Eval Loss:  0.25206080079078674\n",
      "Eval Loss:  0.26160305738449097\n",
      "Eval Loss:  0.2485826313495636\n",
      "Eval Loss:  0.2841285765171051\n",
      "Eval Loss:  0.21519750356674194\n",
      "Eval Loss:  0.2213190793991089\n",
      "Eval Loss:  0.19396580755710602\n",
      "Eval Loss:  0.25046437978744507\n",
      "Eval Loss:  0.2134372889995575\n",
      "Eval Loss:  0.21153441071510315\n",
      "Eval Loss:  0.1880703866481781\n",
      "Eval Loss:  0.22926181554794312\n",
      "Eval Loss:  0.2152515947818756\n",
      "Eval Loss:  0.2697952091693878\n",
      "Eval Loss:  0.2680814862251282\n",
      "Eval Loss:  0.2938857972621918\n",
      "Eval Loss:  0.34570619463920593\n",
      "Eval Loss:  0.21196842193603516\n",
      "Eval Loss:  0.24494992196559906\n",
      "Eval Loss:  0.2946074604988098\n",
      "Eval Loss:  0.2528936266899109\n",
      "Eval Loss:  0.2508511245250702\n",
      "Eval Loss:  0.34726518392562866\n",
      "Eval Loss:  0.2888932526111603\n",
      "Eval Loss:  0.2244398295879364\n",
      "Eval Loss:  0.25785031914711\n",
      "Eval Loss:  0.1787906289100647\n",
      "[[15845  1222]\n",
      " [ 1805 10801]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     17067\n",
      "           1       0.90      0.86      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.8979880699625923\n",
      "pre:  0.8983614738418032\n",
      "rec:  0.8568142154529589\n",
      "ma F1:  0.8949526963664706\n",
      "mi F1:  0.8979880699625923\n",
      "we F1:  0.8976372327685916\n",
      "29673 464\n",
      "Loss:  0.0735003724694252\n",
      "Loss:  0.09046485275030136\n",
      "Loss:  0.055553168058395386\n",
      "57 **********\n",
      "Epoch:  3170.4747948646545  fold:  5  kers:  32\n",
      "epoch:  58\n",
      "29673 464\n",
      "Loss:  0.0646069273352623\n",
      "Loss:  0.09220989793539047\n",
      "Loss:  0.060833629220724106\n",
      "58 **********\n",
      "Epoch:  3211.9718396663666  fold:  5  kers:  32\n",
      "epoch:  59\n",
      "29673 464\n",
      "Loss:  0.0545223131775856\n",
      "Loss:  0.04976094514131546\n",
      "Loss:  0.08944903314113617\n",
      "59 **********\n",
      "Epoch:  3253.4978079795837  fold:  5  kers:  32\n",
      "Eval Loss:  0.07550662755966187\n",
      "Eval Loss:  0.07070934772491455\n",
      "Eval Loss:  0.032751064747571945\n",
      "[[3064   33]\n",
      " [  31   90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.73      0.74      0.74       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.87      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9801118707271598\n",
      "pre:  0.7317073170731707\n",
      "rec:  0.743801652892562\n",
      "ma F1:  0.8636845003600626\n",
      "mi F1:  0.9801118707271598\n",
      "we F1:  0.9801901675465055\n",
      "update!  Acc:  0.9804226227470478\n",
      "Epoch:  3257.3165974617004  fold:  5  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29479 3412\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29479 461\n",
      "Loss:  0.16897626221179962\n",
      "Loss:  0.16309186816215515\n",
      "Loss:  0.1630631536245346\n",
      "0 **********\n",
      "Epoch:  54.089375495910645  fold:  6  kers:  32\n",
      "epoch:  1\n",
      "29479 461\n",
      "Loss:  0.1661711037158966\n",
      "Loss:  0.15643464028835297\n",
      "Loss:  0.14717592298984528\n",
      "1 **********\n",
      "Epoch:  95.58043670654297  fold:  6  kers:  32\n",
      "epoch:  2\n",
      "29479 461\n",
      "Loss:  0.13759566843509674\n",
      "Loss:  0.12227923423051834\n",
      "Loss:  0.11651173233985901\n",
      "2 **********\n",
      "Epoch:  137.04955673217773  fold:  6  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.16174215078353882\n",
      "Eval Loss:  0.25149843096733093\n",
      "Eval Loss:  0.6006743907928467\n",
      "[[1667  565]\n",
      " [  72 1108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.75      0.84      2232\n",
      "           1       0.66      0.94      0.78      1180\n",
      "\n",
      "    accuracy                           0.81      3412\n",
      "   macro avg       0.81      0.84      0.81      3412\n",
      "weighted avg       0.86      0.81      0.82      3412\n",
      "\n",
      "acc:  0.813305978898007\n",
      "pre:  0.6622833233711894\n",
      "rec:  0.9389830508474576\n",
      "ma F1:  0.8081566294294695\n",
      "mi F1:  0.813305978898007\n",
      "we F1:  0.8178473550840337\n",
      "update!  Acc:  0.813305978898007\n",
      "Eval Loss:  0.5492469668388367\n",
      "Eval Loss:  0.5075386166572571\n",
      "Eval Loss:  0.5097500681877136\n",
      "Eval Loss:  0.4559996426105499\n",
      "Eval Loss:  0.44518184661865234\n",
      "Eval Loss:  0.49219468235969543\n",
      "Eval Loss:  0.4435849189758301\n",
      "Eval Loss:  0.4861072301864624\n",
      "Eval Loss:  0.45158398151397705\n",
      "Eval Loss:  0.4549275040626526\n",
      "Eval Loss:  0.41393882036209106\n",
      "Eval Loss:  0.5304620862007141\n",
      "Eval Loss:  0.41784927248954773\n",
      "Eval Loss:  0.4308554232120514\n",
      "Eval Loss:  0.4155196249485016\n",
      "Eval Loss:  0.38509848713874817\n",
      "Eval Loss:  0.45479270815849304\n",
      "Eval Loss:  0.4901793599128723\n",
      "Eval Loss:  0.5100123286247253\n",
      "Eval Loss:  0.4649304449558258\n",
      "Eval Loss:  0.3961159288883209\n",
      "Eval Loss:  0.37009456753730774\n",
      "Eval Loss:  0.46533188223838806\n",
      "Eval Loss:  0.557056725025177\n",
      "Eval Loss:  0.48362332582473755\n",
      "Eval Loss:  0.4839138984680176\n",
      "Eval Loss:  0.399452805519104\n",
      "Eval Loss:  0.3801092207431793\n",
      "[[14141  3791]\n",
      " [ 2389  9158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82     17932\n",
      "           1       0.71      0.79      0.75     11547\n",
      "\n",
      "    accuracy                           0.79     29479\n",
      "   macro avg       0.78      0.79      0.78     29479\n",
      "weighted avg       0.80      0.79      0.79     29479\n",
      "\n",
      "acc:  0.7903592387801486\n",
      "pre:  0.7072360800061781\n",
      "rec:  0.7931064345717502\n",
      "ma F1:  0.7841929785231689\n",
      "mi F1:  0.7903592387801486\n",
      "we F1:  0.7920941568777375\n",
      "29479 461\n",
      "Loss:  0.10478729754686356\n",
      "Loss:  0.10342027992010117\n",
      "Loss:  0.12024307250976562\n",
      "3 **********\n",
      "Epoch:  217.61414337158203  fold:  6  kers:  32\n",
      "epoch:  4\n",
      "29479 461\n",
      "Loss:  0.10233020782470703\n",
      "Loss:  0.1363437920808792\n",
      "Loss:  0.11126216500997543\n",
      "4 **********\n",
      "Epoch:  258.9416425228119  fold:  6  kers:  32\n",
      "epoch:  5\n",
      "29479 461\n",
      "Loss:  0.07409687340259552\n",
      "Loss:  0.08031933754682541\n",
      "Loss:  0.11425939202308655\n",
      "5 **********\n",
      "Epoch:  300.32499146461487  fold:  6  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.1066010445356369\n",
      "Eval Loss:  0.1942903995513916\n",
      "Eval Loss:  0.5529496669769287\n",
      "[[1874  358]\n",
      " [ 100 1080]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89      2232\n",
      "           1       0.75      0.92      0.83      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.85      0.88      0.86      3412\n",
      "weighted avg       0.88      0.87      0.87      3412\n",
      "\n",
      "acc:  0.865767878077374\n",
      "pre:  0.7510431154381085\n",
      "rec:  0.9152542372881356\n",
      "ma F1:  0.8580826183410726\n",
      "mi F1:  0.865767878077374\n",
      "we F1:  0.8682651035332501\n",
      "update!  Acc:  0.865767878077374\n",
      "Eval Loss:  0.4206141233444214\n",
      "Eval Loss:  0.4352738559246063\n",
      "Eval Loss:  0.4389688968658447\n",
      "Eval Loss:  0.35445472598075867\n",
      "Eval Loss:  0.48733019828796387\n",
      "Eval Loss:  0.43568310141563416\n",
      "Eval Loss:  0.4280628263950348\n",
      "Eval Loss:  0.3797299265861511\n",
      "Eval Loss:  0.37638819217681885\n",
      "Eval Loss:  0.38138049840927124\n",
      "Eval Loss:  0.30486059188842773\n",
      "Eval Loss:  0.4715175926685333\n",
      "Eval Loss:  0.3624208867549896\n",
      "Eval Loss:  0.36800459027290344\n",
      "Eval Loss:  0.39703869819641113\n",
      "Eval Loss:  0.3576086759567261\n",
      "Eval Loss:  0.45749759674072266\n",
      "Eval Loss:  0.4382484555244446\n",
      "Eval Loss:  0.473136842250824\n",
      "Eval Loss:  0.3631511926651001\n",
      "Eval Loss:  0.32775819301605225\n",
      "Eval Loss:  0.3325464129447937\n",
      "Eval Loss:  0.45339763164520264\n",
      "Eval Loss:  0.4590974450111389\n",
      "Eval Loss:  0.4807182550430298\n",
      "Eval Loss:  0.3845366835594177\n",
      "Eval Loss:  0.34478941559791565\n",
      "Eval Loss:  0.2764006555080414\n",
      "[[15952  1980]\n",
      " [ 2589  8958]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87     17932\n",
      "           1       0.82      0.78      0.80     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.84      0.83      0.84     29479\n",
      "weighted avg       0.84      0.85      0.84     29479\n",
      "\n",
      "acc:  0.8450083110010516\n",
      "pre:  0.8189797037849699\n",
      "rec:  0.7757859184203689\n",
      "ma F1:  0.8357635585093908\n",
      "mi F1:  0.8450083110010516\n",
      "we F1:  0.8442033275484605\n",
      "29479 461\n",
      "Loss:  0.1225118562579155\n",
      "Loss:  0.10448303818702698\n",
      "Loss:  0.11598225682973862\n",
      "6 **********\n",
      "Epoch:  381.04217004776  fold:  6  kers:  32\n",
      "epoch:  7\n",
      "29479 461\n",
      "Loss:  0.12432308495044708\n",
      "Loss:  0.06519666314125061\n",
      "Loss:  0.12595553696155548\n",
      "7 **********\n",
      "Epoch:  422.55018615722656  fold:  6  kers:  32\n",
      "epoch:  8\n",
      "29479 461\n",
      "Loss:  0.1350485235452652\n",
      "Loss:  0.1240258738398552\n",
      "Loss:  0.08849120140075684\n",
      "8 **********\n",
      "Epoch:  464.0701696872711  fold:  6  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.08234193921089172\n",
      "Eval Loss:  0.18750236928462982\n",
      "Eval Loss:  0.5590944886207581\n",
      "[[1929  303]\n",
      " [ 119 1061]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      2232\n",
      "           1       0.78      0.90      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.86      0.88      0.87      3412\n",
      "weighted avg       0.89      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8763188745603752\n",
      "pre:  0.7778592375366569\n",
      "rec:  0.8991525423728813\n",
      "ma F1:  0.8677606830071123\n",
      "mi F1:  0.876318874560375\n",
      "we F1:  0.8781330534149838\n",
      "update!  Acc:  0.8763188745603752\n",
      "Eval Loss:  0.41033935546875\n",
      "Eval Loss:  0.39832136034965515\n",
      "Eval Loss:  0.38758236169815063\n",
      "Eval Loss:  0.3372969925403595\n",
      "Eval Loss:  0.4999788701534271\n",
      "Eval Loss:  0.41509702801704407\n",
      "Eval Loss:  0.4257323741912842\n",
      "Eval Loss:  0.40645313262939453\n",
      "Eval Loss:  0.35799938440322876\n",
      "Eval Loss:  0.3498574495315552\n",
      "Eval Loss:  0.2905209958553314\n",
      "Eval Loss:  0.44069811701774597\n",
      "Eval Loss:  0.35826998949050903\n",
      "Eval Loss:  0.353995144367218\n",
      "Eval Loss:  0.36824744939804077\n",
      "Eval Loss:  0.31971749663352966\n",
      "Eval Loss:  0.4093545079231262\n",
      "Eval Loss:  0.40245136618614197\n",
      "Eval Loss:  0.4457169771194458\n",
      "Eval Loss:  0.33203384280204773\n",
      "Eval Loss:  0.30701038241386414\n",
      "Eval Loss:  0.31562894582748413\n",
      "Eval Loss:  0.42540833353996277\n",
      "Eval Loss:  0.38008302450180054\n",
      "Eval Loss:  0.4825093746185303\n",
      "Eval Loss:  0.36703819036483765\n",
      "Eval Loss:  0.35191619396209717\n",
      "Eval Loss:  0.26111146807670593\n",
      "[[16543  1389]\n",
      " [ 2818  8729]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89     17932\n",
      "           1       0.86      0.76      0.81     11547\n",
      "\n",
      "    accuracy                           0.86     29479\n",
      "   macro avg       0.86      0.84      0.85     29479\n",
      "weighted avg       0.86      0.86      0.86     29479\n",
      "\n",
      "acc:  0.8572882390854507\n",
      "pre:  0.8627199051195888\n",
      "rec:  0.7559539274270374\n",
      "ma F1:  0.8465032287868237\n",
      "mi F1:  0.8572882390854507\n",
      "we F1:  0.8553159099688986\n",
      "29479 461\n",
      "Loss:  0.060449887067079544\n",
      "Loss:  0.07414649426937103\n",
      "Loss:  0.09875550866127014\n",
      "9 **********\n",
      "Epoch:  544.6696634292603  fold:  6  kers:  32\n",
      "epoch:  10\n",
      "29479 461\n",
      "Loss:  0.09779330343008041\n",
      "Loss:  0.1077314093708992\n",
      "Loss:  0.09685048460960388\n",
      "10 **********\n",
      "Epoch:  586.0968954563141  fold:  6  kers:  32\n",
      "epoch:  11\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09346535056829453\n",
      "Loss:  0.08117004483938217\n",
      "Loss:  0.13495700061321259\n",
      "11 **********\n",
      "Epoch:  627.4692740440369  fold:  6  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.05920136719942093\n",
      "Eval Loss:  0.19355201721191406\n",
      "Eval Loss:  0.491693377494812\n",
      "[[1971  261]\n",
      " [ 125 1055]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91      2232\n",
      "           1       0.80      0.89      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.87      0.89      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8868698710433763\n",
      "pre:  0.8016717325227963\n",
      "rec:  0.8940677966101694\n",
      "ma F1:  0.8780829363950898\n",
      "mi F1:  0.8868698710433763\n",
      "we F1:  0.8881744814278381\n",
      "update!  Acc:  0.8868698710433763\n",
      "Eval Loss:  0.3981528878211975\n",
      "Eval Loss:  0.39983856678009033\n",
      "Eval Loss:  0.3704363703727722\n",
      "Eval Loss:  0.33356764912605286\n",
      "Eval Loss:  0.505452036857605\n",
      "Eval Loss:  0.3980896770954132\n",
      "Eval Loss:  0.40235090255737305\n",
      "Eval Loss:  0.41187331080436707\n",
      "Eval Loss:  0.3390766680240631\n",
      "Eval Loss:  0.3438538908958435\n",
      "Eval Loss:  0.3015998899936676\n",
      "Eval Loss:  0.43824511766433716\n",
      "Eval Loss:  0.3653421700000763\n",
      "Eval Loss:  0.34219011664390564\n",
      "Eval Loss:  0.35183924436569214\n",
      "Eval Loss:  0.325592577457428\n",
      "Eval Loss:  0.3928290605545044\n",
      "Eval Loss:  0.39206573367118835\n",
      "Eval Loss:  0.43769311904907227\n",
      "Eval Loss:  0.34114375710487366\n",
      "Eval Loss:  0.320004403591156\n",
      "Eval Loss:  0.3043927848339081\n",
      "Eval Loss:  0.4177055358886719\n",
      "Eval Loss:  0.3763238489627838\n",
      "Eval Loss:  0.4771760106086731\n",
      "Eval Loss:  0.3539462685585022\n",
      "Eval Loss:  0.34194520115852356\n",
      "Eval Loss:  0.26364678144454956\n",
      "[[16806  1126]\n",
      " [ 2998  8549]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     17932\n",
      "           1       0.88      0.74      0.81     11547\n",
      "\n",
      "    accuracy                           0.86     29479\n",
      "   macro avg       0.87      0.84      0.85     29479\n",
      "weighted avg       0.86      0.86      0.86     29479\n",
      "\n",
      "acc:  0.8601038027070118\n",
      "pre:  0.8836175710594315\n",
      "rec:  0.7403654628907942\n",
      "ma F1:  0.8481938974892296\n",
      "mi F1:  0.8601038027070118\n",
      "we F1:  0.8574036279985597\n",
      "29479 461\n",
      "Loss:  0.07527610659599304\n",
      "Loss:  0.12831896543502808\n",
      "Loss:  0.08985582739114761\n",
      "12 **********\n",
      "Epoch:  707.9141805171967  fold:  6  kers:  32\n",
      "epoch:  13\n",
      "29479 461\n",
      "Loss:  0.1164366826415062\n",
      "Loss:  0.09564411640167236\n",
      "Loss:  0.0874059647321701\n",
      "13 **********\n",
      "Epoch:  749.2476632595062  fold:  6  kers:  32\n",
      "epoch:  14\n",
      "29479 461\n",
      "Loss:  0.06809081137180328\n",
      "Loss:  0.06049381569027901\n",
      "Loss:  0.0682908296585083\n",
      "14 **********\n",
      "Epoch:  790.5083405971527  fold:  6  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.1015826165676117\n",
      "Eval Loss:  0.13795071840286255\n",
      "Eval Loss:  0.657945990562439\n",
      "[[1834  398]\n",
      " [  84 1096]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88      2232\n",
      "           1       0.73      0.93      0.82      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.84      0.88      0.85      3412\n",
      "weighted avg       0.88      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8587338804220399\n",
      "pre:  0.7336010709504686\n",
      "rec:  0.9288135593220339\n",
      "ma F1:  0.8518005605067991\n",
      "mi F1:  0.8587338804220398\n",
      "we F1:  0.8616838295458686\n",
      "Eval Loss:  0.401664137840271\n",
      "Eval Loss:  0.3788827657699585\n",
      "Eval Loss:  0.3224336802959442\n",
      "Eval Loss:  0.3086329698562622\n",
      "Eval Loss:  0.4340486228466034\n",
      "Eval Loss:  0.38945865631103516\n",
      "Eval Loss:  0.36848604679107666\n",
      "Eval Loss:  0.3490232527256012\n",
      "Eval Loss:  0.3335050046443939\n",
      "Eval Loss:  0.3054440915584564\n",
      "Eval Loss:  0.26470550894737244\n",
      "Eval Loss:  0.4274173676967621\n",
      "Eval Loss:  0.3432466983795166\n",
      "Eval Loss:  0.3438873887062073\n",
      "Eval Loss:  0.32954514026641846\n",
      "Eval Loss:  0.2899630665779114\n",
      "Eval Loss:  0.3252374529838562\n",
      "Eval Loss:  0.3819497227668762\n",
      "Eval Loss:  0.41930171847343445\n",
      "Eval Loss:  0.2577161490917206\n",
      "Eval Loss:  0.28600791096687317\n",
      "Eval Loss:  0.2937854528427124\n",
      "Eval Loss:  0.39252039790153503\n",
      "Eval Loss:  0.3290472626686096\n",
      "Eval Loss:  0.4484783113002777\n",
      "Eval Loss:  0.32740435004234314\n",
      "Eval Loss:  0.26229068636894226\n",
      "Eval Loss:  0.22240111231803894\n",
      "[[15982  1950]\n",
      " [ 1973  9574]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     17932\n",
      "           1       0.83      0.83      0.83     11547\n",
      "\n",
      "    accuracy                           0.87     29479\n",
      "   macro avg       0.86      0.86      0.86     29479\n",
      "weighted avg       0.87      0.87      0.87     29479\n",
      "\n",
      "acc:  0.8669222158146477\n",
      "pre:  0.8307879208608122\n",
      "rec:  0.8291331081666233\n",
      "ma F1:  0.8603221693454668\n",
      "mi F1:  0.8669222158146476\n",
      "we F1:  0.8668985265092808\n",
      "29479 461\n",
      "Loss:  0.0910901427268982\n",
      "Loss:  0.07657118141651154\n",
      "Loss:  0.08591948449611664\n",
      "15 **********\n",
      "Epoch:  870.8305752277374  fold:  6  kers:  32\n",
      "epoch:  16\n",
      "29479 461\n",
      "Loss:  0.07540129870176315\n",
      "Loss:  0.07415570318698883\n",
      "Loss:  0.051535941660404205\n",
      "16 **********\n",
      "Epoch:  912.2737646102905  fold:  6  kers:  32\n",
      "epoch:  17\n",
      "29479 461\n",
      "Loss:  0.0712624341249466\n",
      "Loss:  0.07597316801548004\n",
      "Loss:  0.11314140260219574\n",
      "17 **********\n",
      "Epoch:  953.6820478439331  fold:  6  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.09691305458545685\n",
      "Eval Loss:  0.13596969842910767\n",
      "Eval Loss:  0.5580386519432068\n",
      "[[1892  340]\n",
      " [  99 1081]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90      2232\n",
      "           1       0.76      0.92      0.83      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.88      0.86      3412\n",
      "weighted avg       0.88      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8713364595545134\n",
      "pre:  0.7607318789584799\n",
      "rec:  0.9161016949152543\n",
      "ma F1:  0.8636321136618159\n",
      "mi F1:  0.8713364595545134\n",
      "we F1:  0.8736259137593718\n",
      "Eval Loss:  0.3903612494468689\n",
      "Eval Loss:  0.35810205340385437\n",
      "Eval Loss:  0.3174988031387329\n",
      "Eval Loss:  0.29167506098747253\n",
      "Eval Loss:  0.4293312430381775\n",
      "Eval Loss:  0.3657096028327942\n",
      "Eval Loss:  0.3394930362701416\n",
      "Eval Loss:  0.32409363985061646\n",
      "Eval Loss:  0.3202948570251465\n",
      "Eval Loss:  0.2851570248603821\n",
      "Eval Loss:  0.2624031901359558\n",
      "Eval Loss:  0.4273988604545593\n",
      "Eval Loss:  0.32588139176368713\n",
      "Eval Loss:  0.3319036066532135\n",
      "Eval Loss:  0.29976722598075867\n",
      "Eval Loss:  0.2927112877368927\n",
      "Eval Loss:  0.30336907505989075\n",
      "Eval Loss:  0.3573892414569855\n",
      "Eval Loss:  0.41307806968688965\n",
      "Eval Loss:  0.2552172541618347\n",
      "Eval Loss:  0.2836897373199463\n",
      "Eval Loss:  0.28983595967292786\n",
      "Eval Loss:  0.38992586731910706\n",
      "Eval Loss:  0.31910353899002075\n",
      "Eval Loss:  0.4279918670654297\n",
      "Eval Loss:  0.3064865171909332\n",
      "Eval Loss:  0.23907573521137238\n",
      "Eval Loss:  0.2171415090560913\n",
      "[[16192  1740]\n",
      " [ 1957  9590]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90     17932\n",
      "           1       0.85      0.83      0.84     11547\n",
      "\n",
      "    accuracy                           0.87     29479\n",
      "   macro avg       0.87      0.87      0.87     29479\n",
      "weighted avg       0.87      0.87      0.87     29479\n",
      "\n",
      "acc:  0.8745886902540791\n",
      "pre:  0.8464254192409533\n",
      "rec:  0.8305187494587338\n",
      "ma F1:  0.8679663711242624\n",
      "mi F1:  0.8745886902540791\n",
      "we F1:  0.8743710223881038\n",
      "29479 461\n",
      "Loss:  0.06885021924972534\n",
      "Loss:  0.08419767767190933\n",
      "Loss:  0.10976523905992508\n",
      "18 **********\n",
      "Epoch:  1033.9444420337677  fold:  6  kers:  32\n",
      "epoch:  19\n",
      "29479 461\n",
      "Loss:  0.09911108016967773\n",
      "Loss:  0.07806729525327682\n",
      "Loss:  0.0703815445303917\n",
      "19 **********\n",
      "Epoch:  1075.2420208454132  fold:  6  kers:  32\n",
      "epoch:  20\n",
      "29479 461\n",
      "Loss:  0.08022050559520721\n",
      "Loss:  0.07858444005250931\n",
      "Loss:  0.06352724879980087\n",
      "20 **********\n",
      "Epoch:  1116.578495502472  fold:  6  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.0776321068406105\n",
      "Eval Loss:  0.16937322914600372\n",
      "Eval Loss:  0.5125898718833923\n",
      "[[1952  280]\n",
      " [ 108 1072]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91      2232\n",
      "           1       0.79      0.91      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.87      0.89      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8862837045720985\n",
      "pre:  0.7928994082840237\n",
      "rec:  0.9084745762711864\n",
      "ma F1:  0.8781803539116826\n",
      "mi F1:  0.8862837045720985\n",
      "we F1:  0.8878675412920889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3716256320476532\n",
      "Eval Loss:  0.3609042465686798\n",
      "Eval Loss:  0.30730926990509033\n",
      "Eval Loss:  0.3039967119693756\n",
      "Eval Loss:  0.4195915162563324\n",
      "Eval Loss:  0.3432331681251526\n",
      "Eval Loss:  0.34957996010780334\n",
      "Eval Loss:  0.31686902046203613\n",
      "Eval Loss:  0.29827991127967834\n",
      "Eval Loss:  0.27327480912208557\n",
      "Eval Loss:  0.2640744149684906\n",
      "Eval Loss:  0.42530086636543274\n",
      "Eval Loss:  0.3359622061252594\n",
      "Eval Loss:  0.3213958144187927\n",
      "Eval Loss:  0.3155386447906494\n",
      "Eval Loss:  0.30435147881507874\n",
      "Eval Loss:  0.31817883253097534\n",
      "Eval Loss:  0.3511807322502136\n",
      "Eval Loss:  0.40342485904693604\n",
      "Eval Loss:  0.2523225247859955\n",
      "Eval Loss:  0.2833596467971802\n",
      "Eval Loss:  0.2754899561405182\n",
      "Eval Loss:  0.3783782124519348\n",
      "Eval Loss:  0.3082304298877716\n",
      "Eval Loss:  0.4030250310897827\n",
      "Eval Loss:  0.29073527455329895\n",
      "Eval Loss:  0.24909280240535736\n",
      "Eval Loss:  0.20961764454841614\n",
      "[[16537  1395]\n",
      " [ 2191  9356]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     17932\n",
      "           1       0.87      0.81      0.84     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.88      0.87      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8783540825672512\n",
      "pre:  0.8702446284066598\n",
      "rec:  0.8102537455616178\n",
      "ma F1:  0.8706803082992722\n",
      "mi F1:  0.8783540825672512\n",
      "we F1:  0.8775034594900599\n",
      "29479 461\n",
      "Loss:  0.10705531388521194\n",
      "Loss:  0.08967498689889908\n",
      "Loss:  0.07287995517253876\n",
      "21 **********\n",
      "Epoch:  1197.039359331131  fold:  6  kers:  32\n",
      "epoch:  22\n",
      "29479 461\n",
      "Loss:  0.0424799770116806\n",
      "Loss:  0.11210726201534271\n",
      "Loss:  0.09011665731668472\n",
      "22 **********\n",
      "Epoch:  1238.2890660762787  fold:  6  kers:  32\n",
      "epoch:  23\n",
      "29479 461\n",
      "Loss:  0.05586748570203781\n",
      "Loss:  0.10762756317853928\n",
      "Loss:  0.0857706293463707\n",
      "23 **********\n",
      "Epoch:  1279.5647032260895  fold:  6  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.07138357311487198\n",
      "Eval Loss:  0.14821195602416992\n",
      "Eval Loss:  0.5038011074066162\n",
      "[[1955  277]\n",
      " [ 102 1078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      2232\n",
      "           1       0.80      0.91      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.87      0.89      0.88      3412\n",
      "weighted avg       0.90      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8889214536928488\n",
      "pre:  0.7955719557195572\n",
      "rec:  0.9135593220338983\n",
      "ma F1:  0.8810637551315852\n",
      "mi F1:  0.8889214536928488\n",
      "we F1:  0.8904894095060998\n",
      "update!  Acc:  0.8889214536928488\n",
      "Eval Loss:  0.3908291459083557\n",
      "Eval Loss:  0.3652735948562622\n",
      "Eval Loss:  0.3100285232067108\n",
      "Eval Loss:  0.3054543435573578\n",
      "Eval Loss:  0.42798927426338196\n",
      "Eval Loss:  0.32631710171699524\n",
      "Eval Loss:  0.35142040252685547\n",
      "Eval Loss:  0.3125884532928467\n",
      "Eval Loss:  0.2982877790927887\n",
      "Eval Loss:  0.2705693244934082\n",
      "Eval Loss:  0.2578800916671753\n",
      "Eval Loss:  0.39325034618377686\n",
      "Eval Loss:  0.3324061632156372\n",
      "Eval Loss:  0.3103612959384918\n",
      "Eval Loss:  0.31081560254096985\n",
      "Eval Loss:  0.2828945219516754\n",
      "Eval Loss:  0.26505759358406067\n",
      "Eval Loss:  0.3594157099723816\n",
      "Eval Loss:  0.3886670768260956\n",
      "Eval Loss:  0.25085994601249695\n",
      "Eval Loss:  0.28749844431877136\n",
      "Eval Loss:  0.2541309893131256\n",
      "Eval Loss:  0.346207857131958\n",
      "Eval Loss:  0.3010908365249634\n",
      "Eval Loss:  0.4116525650024414\n",
      "Eval Loss:  0.2806502878665924\n",
      "Eval Loss:  0.26008808612823486\n",
      "Eval Loss:  0.2040928602218628\n",
      "[[16544  1388]\n",
      " [ 2138  9409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90     17932\n",
      "           1       0.87      0.81      0.84     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.88      0.87      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8803894297635605\n",
      "pre:  0.8714457719736964\n",
      "rec:  0.8148436823417338\n",
      "ma F1:  0.8729464058236878\n",
      "mi F1:  0.8803894297635605\n",
      "we F1:  0.8796070516339314\n",
      "29479 461\n",
      "Loss:  0.0705384686589241\n",
      "Loss:  0.11101524531841278\n",
      "Loss:  0.050594184547662735\n",
      "24 **********\n",
      "Epoch:  1359.9657270908356  fold:  6  kers:  32\n",
      "epoch:  25\n",
      "29479 461\n",
      "Loss:  0.07354383915662766\n",
      "Loss:  0.060969043523073196\n",
      "Loss:  0.05745972320437431\n",
      "25 **********\n",
      "Epoch:  1401.2942237854004  fold:  6  kers:  32\n",
      "epoch:  26\n",
      "29479 461\n",
      "Loss:  0.08273404836654663\n",
      "Loss:  0.06322310864925385\n",
      "Loss:  0.11169742792844772\n",
      "26 **********\n",
      "Epoch:  1442.598783493042  fold:  6  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.07152888178825378\n",
      "Eval Loss:  0.1847798079252243\n",
      "Eval Loss:  0.42835763096809387\n",
      "[[1996  236]\n",
      " [ 133 1047]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92      2232\n",
      "           1       0.82      0.89      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.89      0.88      3412\n",
      "weighted avg       0.90      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8918522860492379\n",
      "pre:  0.8160561184723305\n",
      "rec:  0.8872881355932203\n",
      "ma F1:  0.882784541645149\n",
      "mi F1:  0.8918522860492379\n",
      "we F1:  0.8928364564113257\n",
      "update!  Acc:  0.8918522860492379\n",
      "Eval Loss:  0.3725750148296356\n",
      "Eval Loss:  0.35633015632629395\n",
      "Eval Loss:  0.30341142416000366\n",
      "Eval Loss:  0.29856157302856445\n",
      "Eval Loss:  0.39751946926116943\n",
      "Eval Loss:  0.3144567608833313\n",
      "Eval Loss:  0.3403126001358032\n",
      "Eval Loss:  0.29387181997299194\n",
      "Eval Loss:  0.27130869030952454\n",
      "Eval Loss:  0.25885021686553955\n",
      "Eval Loss:  0.2578708827495575\n",
      "Eval Loss:  0.41879716515541077\n",
      "Eval Loss:  0.318880170583725\n",
      "Eval Loss:  0.3137272894382477\n",
      "Eval Loss:  0.28791287541389465\n",
      "Eval Loss:  0.295807808637619\n",
      "Eval Loss:  0.3087041974067688\n",
      "Eval Loss:  0.3533436357975006\n",
      "Eval Loss:  0.40028220415115356\n",
      "Eval Loss:  0.2578495740890503\n",
      "Eval Loss:  0.2829301357269287\n",
      "Eval Loss:  0.26034754514694214\n",
      "Eval Loss:  0.35349708795547485\n",
      "Eval Loss:  0.31703683733940125\n",
      "Eval Loss:  0.3969687521457672\n",
      "Eval Loss:  0.28039419651031494\n",
      "Eval Loss:  0.22246238589286804\n",
      "Eval Loss:  0.20815277099609375\n",
      "[[16659  1273]\n",
      " [ 2196  9351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     17932\n",
      "           1       0.88      0.81      0.84     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.88      0.87      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8823230096000543\n",
      "pre:  0.8801769578313253\n",
      "rec:  0.8098207326578332\n",
      "ma F1:  0.8746173649783233\n",
      "mi F1:  0.8823230096000543\n",
      "we F1:  0.8813497871060946\n",
      "29479 461\n",
      "Loss:  0.06994911283254623\n",
      "Loss:  0.08471975475549698\n",
      "Loss:  0.09353764355182648\n",
      "27 **********\n",
      "Epoch:  1523.2311890125275  fold:  6  kers:  32\n",
      "epoch:  28\n",
      "29479 461\n",
      "Loss:  0.07461383938789368\n",
      "Loss:  0.08352868258953094\n",
      "Loss:  0.07012855261564255\n",
      "28 **********\n",
      "Epoch:  1564.6115462779999  fold:  6  kers:  32\n",
      "epoch:  29\n",
      "29479 461\n",
      "Loss:  0.07573579251766205\n",
      "Loss:  0.06900883466005325\n",
      "Loss:  0.1065351590514183\n",
      "29 **********\n",
      "Epoch:  1606.0736849308014  fold:  6  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.07748576998710632\n",
      "Eval Loss:  0.1436307579278946\n",
      "Eval Loss:  0.4888211786746979\n",
      "[[1950  282]\n",
      " [  89 1091]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      2232\n",
      "           1       0.79      0.92      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.90      0.88      3412\n",
      "weighted avg       0.90      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8912661195779601\n",
      "pre:  0.7946103423160962\n",
      "rec:  0.9245762711864407\n",
      "ma F1:  0.883907932445593\n",
      "mi F1:  0.89126611957796\n",
      "we F1:  0.8929193560349414\n",
      "Eval Loss:  0.3942685127258301\n",
      "Eval Loss:  0.3734531104564667\n",
      "Eval Loss:  0.27433228492736816\n",
      "Eval Loss:  0.28578874468803406\n",
      "Eval Loss:  0.39102792739868164\n",
      "Eval Loss:  0.33187025785446167\n",
      "Eval Loss:  0.3226495385169983\n",
      "Eval Loss:  0.27257880568504333\n",
      "Eval Loss:  0.27521517872810364\n",
      "Eval Loss:  0.24396266043186188\n",
      "Eval Loss:  0.2355090081691742\n",
      "Eval Loss:  0.398349791765213\n",
      "Eval Loss:  0.31640511751174927\n",
      "Eval Loss:  0.3127671778202057\n",
      "Eval Loss:  0.29425251483917236\n",
      "Eval Loss:  0.2707624137401581\n",
      "Eval Loss:  0.23549656569957733\n",
      "Eval Loss:  0.3582393527030945\n",
      "Eval Loss:  0.3904201090335846\n",
      "Eval Loss:  0.2301723062992096\n",
      "Eval Loss:  0.2893829345703125\n",
      "Eval Loss:  0.25603845715522766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.31935974955558777\n",
      "Eval Loss:  0.30382823944091797\n",
      "Eval Loss:  0.39195436239242554\n",
      "Eval Loss:  0.2850910425186157\n",
      "Eval Loss:  0.1951388120651245\n",
      "Eval Loss:  0.16895082592964172\n",
      "[[16225  1707]\n",
      " [ 1712  9835]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     17932\n",
      "           1       0.85      0.85      0.85     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.88      0.88      0.88     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8840191322636453\n",
      "pre:  0.8521053543579968\n",
      "rec:  0.851736381744176\n",
      "ma F1:  0.8783008751723982\n",
      "mi F1:  0.8840191322636453\n",
      "we F1:  0.8840146578840746\n",
      "29479 461\n",
      "Loss:  0.10198096185922623\n",
      "Loss:  0.11984986066818237\n",
      "Loss:  0.046582963317632675\n",
      "30 **********\n",
      "Epoch:  1686.5076205730438  fold:  6  kers:  32\n",
      "epoch:  31\n",
      "29479 461\n",
      "Loss:  0.08031132817268372\n",
      "Loss:  0.10089179873466492\n",
      "Loss:  0.07114998251199722\n",
      "31 **********\n",
      "Epoch:  1727.8480849266052  fold:  6  kers:  32\n",
      "epoch:  32\n",
      "29479 461\n",
      "Loss:  0.09060419350862503\n",
      "Loss:  0.05434514582157135\n",
      "Loss:  0.08660832047462463\n",
      "32 **********\n",
      "Epoch:  1769.2224581241608  fold:  6  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.05409649387001991\n",
      "Eval Loss:  0.16777338087558746\n",
      "Eval Loss:  0.4170090854167938\n",
      "[[2021  211]\n",
      " [ 130 1050]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92      2232\n",
      "           1       0.83      0.89      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.90      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.9000586166471278\n",
      "pre:  0.8326724821570183\n",
      "rec:  0.8898305084745762\n",
      "ma F1:  0.8912512806219479\n",
      "mi F1:  0.9000586166471278\n",
      "we F1:  0.9007933171806392\n",
      "update!  Acc:  0.9000586166471278\n",
      "Eval Loss:  0.36009976267814636\n",
      "Eval Loss:  0.35783255100250244\n",
      "Eval Loss:  0.27782732248306274\n",
      "Eval Loss:  0.2775193452835083\n",
      "Eval Loss:  0.38799914717674255\n",
      "Eval Loss:  0.29012587666511536\n",
      "Eval Loss:  0.3205001950263977\n",
      "Eval Loss:  0.2642914354801178\n",
      "Eval Loss:  0.24846559762954712\n",
      "Eval Loss:  0.22850702702999115\n",
      "Eval Loss:  0.2341860979795456\n",
      "Eval Loss:  0.4089431166648865\n",
      "Eval Loss:  0.3109281063079834\n",
      "Eval Loss:  0.29624661803245544\n",
      "Eval Loss:  0.26772862672805786\n",
      "Eval Loss:  0.2808162569999695\n",
      "Eval Loss:  0.2826496660709381\n",
      "Eval Loss:  0.33474308252334595\n",
      "Eval Loss:  0.3987258970737457\n",
      "Eval Loss:  0.23822516202926636\n",
      "Eval Loss:  0.2810760736465454\n",
      "Eval Loss:  0.24474751949310303\n",
      "Eval Loss:  0.31809499859809875\n",
      "Eval Loss:  0.2966342866420746\n",
      "Eval Loss:  0.3511894643306732\n",
      "Eval Loss:  0.2571737766265869\n",
      "Eval Loss:  0.20528081059455872\n",
      "Eval Loss:  0.18937940895557404\n",
      "[[16696  1236]\n",
      " [ 1989  9558]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     17932\n",
      "           1       0.89      0.83      0.86     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.89      0.88      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8906000881983785\n",
      "pre:  0.8854919399666481\n",
      "rec:  0.8277474668745128\n",
      "ma F1:  0.8837863618033082\n",
      "mi F1:  0.8906000881983785\n",
      "we F1:  0.8898812963833761\n",
      "29479 461\n",
      "Loss:  0.08583702892065048\n",
      "Loss:  0.06444262713193893\n",
      "Loss:  0.08193744719028473\n",
      "33 **********\n",
      "Epoch:  1849.5975513458252  fold:  6  kers:  32\n",
      "epoch:  34\n",
      "29479 461\n",
      "Loss:  0.0681229755282402\n",
      "Loss:  0.04964517056941986\n",
      "Loss:  0.09478721767663956\n",
      "34 **********\n",
      "Epoch:  1890.873188495636  fold:  6  kers:  32\n",
      "epoch:  35\n",
      "29479 461\n",
      "Loss:  0.06223747879266739\n",
      "Loss:  0.096498504281044\n",
      "Loss:  0.07672922313213348\n",
      "35 **********\n",
      "Epoch:  1932.147828578949  fold:  6  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.05112539976835251\n",
      "Eval Loss:  0.13329002261161804\n",
      "Eval Loss:  0.4663228392601013\n",
      "[[1979  253]\n",
      " [ 108 1072]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      2232\n",
      "           1       0.81      0.91      0.86      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.90      0.89      3412\n",
      "weighted avg       0.90      0.89      0.90      3412\n",
      "\n",
      "acc:  0.8941969519343493\n",
      "pre:  0.8090566037735849\n",
      "rec:  0.9084745762711864\n",
      "ma F1:  0.8861520302760999\n",
      "mi F1:  0.8941969519343493\n",
      "we F1:  0.8954830750219417\n",
      "Eval Loss:  0.39217692613601685\n",
      "Eval Loss:  0.36484280228614807\n",
      "Eval Loss:  0.2533551752567291\n",
      "Eval Loss:  0.3142790198326111\n",
      "Eval Loss:  0.396450400352478\n",
      "Eval Loss:  0.28713545203208923\n",
      "Eval Loss:  0.3375532925128937\n",
      "Eval Loss:  0.2767982482910156\n",
      "Eval Loss:  0.2461088001728058\n",
      "Eval Loss:  0.22160275280475616\n",
      "Eval Loss:  0.22627951204776764\n",
      "Eval Loss:  0.3478415310382843\n",
      "Eval Loss:  0.3116406798362732\n",
      "Eval Loss:  0.2959487736225128\n",
      "Eval Loss:  0.2627931833267212\n",
      "Eval Loss:  0.24786202609539032\n",
      "Eval Loss:  0.21930423378944397\n",
      "Eval Loss:  0.34814026951789856\n",
      "Eval Loss:  0.4054242968559265\n",
      "Eval Loss:  0.22844332456588745\n",
      "Eval Loss:  0.2808242738246918\n",
      "Eval Loss:  0.2289705127477646\n",
      "Eval Loss:  0.28955399990081787\n",
      "Eval Loss:  0.294440895318985\n",
      "Eval Loss:  0.3648201823234558\n",
      "Eval Loss:  0.24834579229354858\n",
      "Eval Loss:  0.19519658386707306\n",
      "Eval Loss:  0.16400732100009918\n",
      "[[16578  1354]\n",
      " [ 1828  9719]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17932\n",
      "           1       0.88      0.84      0.86     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.89      0.88      0.89     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8920587536890668\n",
      "pre:  0.8777205815948704\n",
      "rec:  0.8416904823763748\n",
      "ma F1:  0.8858806468728446\n",
      "mi F1:  0.8920587536890668\n",
      "we F1:  0.8916318076866044\n",
      "29479 461\n",
      "Loss:  0.05694475397467613\n",
      "Loss:  0.06733469665050507\n",
      "Loss:  0.07974329590797424\n",
      "36 **********\n",
      "Epoch:  2012.555834054947  fold:  6  kers:  32\n",
      "epoch:  37\n",
      "29479 461\n",
      "Loss:  0.09302830696105957\n",
      "Loss:  0.07226309180259705\n",
      "Loss:  0.0588630735874176\n",
      "37 **********\n",
      "Epoch:  2054.036921977997  fold:  6  kers:  32\n",
      "epoch:  38\n",
      "29479 461\n",
      "Loss:  0.07110889256000519\n",
      "Loss:  0.057255059480667114\n",
      "Loss:  0.041359324008226395\n",
      "38 **********\n",
      "Epoch:  2095.3723995685577  fold:  6  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.07711204141378403\n",
      "Eval Loss:  0.09526024013757706\n",
      "Eval Loss:  0.5263076424598694\n",
      "[[1925  307]\n",
      " [  92 1088]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.91      2232\n",
      "           1       0.78      0.92      0.85      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.89      0.88      3412\n",
      "weighted avg       0.89      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8830597889800703\n",
      "pre:  0.7799283154121864\n",
      "rec:  0.9220338983050848\n",
      "ma F1:  0.875572047791942\n",
      "mi F1:  0.8830597889800703\n",
      "we F1:  0.8849831633593388\n",
      "Eval Loss:  0.40655025839805603\n",
      "Eval Loss:  0.3768380880355835\n",
      "Eval Loss:  0.26437658071517944\n",
      "Eval Loss:  0.30662569403648376\n",
      "Eval Loss:  0.3764554560184479\n",
      "Eval Loss:  0.3128308057785034\n",
      "Eval Loss:  0.3271096348762512\n",
      "Eval Loss:  0.25742822885513306\n",
      "Eval Loss:  0.24678750336170197\n",
      "Eval Loss:  0.21057888865470886\n",
      "Eval Loss:  0.21113936603069305\n",
      "Eval Loss:  0.3567248582839966\n",
      "Eval Loss:  0.313727468252182\n",
      "Eval Loss:  0.28852415084838867\n",
      "Eval Loss:  0.2592388093471527\n",
      "Eval Loss:  0.22784297168254852\n",
      "Eval Loss:  0.20947691798210144\n",
      "Eval Loss:  0.34373006224632263\n",
      "Eval Loss:  0.39816781878471375\n",
      "Eval Loss:  0.21091701090335846\n",
      "Eval Loss:  0.27337172627449036\n",
      "Eval Loss:  0.22672602534294128\n",
      "Eval Loss:  0.28282833099365234\n",
      "Eval Loss:  0.2966865301132202\n",
      "Eval Loss:  0.3426082134246826\n",
      "Eval Loss:  0.26174813508987427\n",
      "Eval Loss:  0.18908706307411194\n",
      "Eval Loss:  0.16130560636520386\n",
      "[[16135  1797]\n",
      " [ 1451 10096]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91     17932\n",
      "           1       0.85      0.87      0.86     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.88      0.89      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8898198717731266\n",
      "pre:  0.8489027158832927\n",
      "rec:  0.8743396553217286\n",
      "ma F1:  0.8849934283189007\n",
      "mi F1:  0.8898198717731266\n",
      "we F1:  0.890096399250385\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0767388716340065\n",
      "Loss:  0.07744638621807098\n",
      "Loss:  0.05861646309494972\n",
      "39 **********\n",
      "Epoch:  2175.586921930313  fold:  6  kers:  32\n",
      "epoch:  40\n",
      "29479 461\n",
      "Loss:  0.04923854023218155\n",
      "Loss:  0.04587269574403763\n",
      "Loss:  0.04251469299197197\n",
      "40 **********\n",
      "Epoch:  2216.795738220215  fold:  6  kers:  32\n",
      "epoch:  41\n",
      "29479 461\n",
      "Loss:  0.07861869037151337\n",
      "Loss:  0.05724984034895897\n",
      "Loss:  0.05119781196117401\n",
      "41 **********\n",
      "Epoch:  2257.9796204566956  fold:  6  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.04244110360741615\n",
      "Eval Loss:  0.18242283165454865\n",
      "Eval Loss:  0.46213671565055847\n",
      "[[2047  185]\n",
      " [ 154 1026]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      2232\n",
      "           1       0.85      0.87      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.9006447831184057\n",
      "pre:  0.847233691164327\n",
      "rec:  0.8694915254237288\n",
      "ma F1:  0.890873201756757\n",
      "mi F1:  0.9006447831184057\n",
      "we F1:  0.9009414716808063\n",
      "update!  Acc:  0.9006447831184057\n",
      "Eval Loss:  0.344530314207077\n",
      "Eval Loss:  0.3503059148788452\n",
      "Eval Loss:  0.23887822031974792\n",
      "Eval Loss:  0.30046969652175903\n",
      "Eval Loss:  0.36536020040512085\n",
      "Eval Loss:  0.26856866478919983\n",
      "Eval Loss:  0.3152981698513031\n",
      "Eval Loss:  0.2639388144016266\n",
      "Eval Loss:  0.21486397087574005\n",
      "Eval Loss:  0.1899564415216446\n",
      "Eval Loss:  0.21372152864933014\n",
      "Eval Loss:  0.36401161551475525\n",
      "Eval Loss:  0.31095224618911743\n",
      "Eval Loss:  0.26129743456840515\n",
      "Eval Loss:  0.2615315020084381\n",
      "Eval Loss:  0.2504567503929138\n",
      "Eval Loss:  0.23764607310295105\n",
      "Eval Loss:  0.3127817213535309\n",
      "Eval Loss:  0.40187281370162964\n",
      "Eval Loss:  0.21642032265663147\n",
      "Eval Loss:  0.2766913175582886\n",
      "Eval Loss:  0.22575074434280396\n",
      "Eval Loss:  0.2783109247684479\n",
      "Eval Loss:  0.27736058831214905\n",
      "Eval Loss:  0.3156941831111908\n",
      "Eval Loss:  0.23476265370845795\n",
      "Eval Loss:  0.17514783143997192\n",
      "Eval Loss:  0.16786707937717438\n",
      "[[16811  1121]\n",
      " [ 1937  9610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17932\n",
      "           1       0.90      0.83      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.88      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8962651378947726\n",
      "pre:  0.895536296710465\n",
      "rec:  0.832250801073872\n",
      "ma F1:  0.8896824262812445\n",
      "mi F1:  0.8962651378947726\n",
      "we F1:  0.895519200847607\n",
      "29479 461\n",
      "Loss:  0.05629637464880943\n",
      "Loss:  0.061266809701919556\n",
      "Loss:  0.053666647523641586\n",
      "42 **********\n",
      "Epoch:  2338.6060423851013  fold:  6  kers:  32\n",
      "epoch:  43\n",
      "29479 461\n",
      "Loss:  0.05535358563065529\n",
      "Loss:  0.07724829018115997\n",
      "Loss:  0.07927339524030685\n",
      "43 **********\n",
      "Epoch:  2379.9345383644104  fold:  6  kers:  32\n",
      "epoch:  44\n",
      "29479 461\n",
      "Loss:  0.07346433401107788\n",
      "Loss:  0.06667228788137436\n",
      "Loss:  0.09929146617650986\n",
      "44 **********\n",
      "Epoch:  2421.3547883033752  fold:  6  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.05866298824548721\n",
      "Eval Loss:  0.09846141189336777\n",
      "Eval Loss:  0.4440624713897705\n",
      "[[1950  282]\n",
      " [  88 1092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      2232\n",
      "           1       0.79      0.93      0.86      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.90      0.88      3412\n",
      "weighted avg       0.90      0.89      0.89      3412\n",
      "\n",
      "acc:  0.891559202813599\n",
      "pre:  0.7947598253275109\n",
      "rec:  0.9254237288135593\n",
      "ma F1:  0.8842390776098108\n",
      "mi F1:  0.891559202813599\n",
      "we F1:  0.8932143360181851\n",
      "Eval Loss:  0.3768131732940674\n",
      "Eval Loss:  0.37443971633911133\n",
      "Eval Loss:  0.25607722997665405\n",
      "Eval Loss:  0.26213139295578003\n",
      "Eval Loss:  0.34208422899246216\n",
      "Eval Loss:  0.303539514541626\n",
      "Eval Loss:  0.29757797718048096\n",
      "Eval Loss:  0.2328721582889557\n",
      "Eval Loss:  0.23107457160949707\n",
      "Eval Loss:  0.19585317373275757\n",
      "Eval Loss:  0.20126360654830933\n",
      "Eval Loss:  0.36900192499160767\n",
      "Eval Loss:  0.2811793088912964\n",
      "Eval Loss:  0.2558342218399048\n",
      "Eval Loss:  0.22897084057331085\n",
      "Eval Loss:  0.222056046128273\n",
      "Eval Loss:  0.21262651681900024\n",
      "Eval Loss:  0.31269946694374084\n",
      "Eval Loss:  0.3980512320995331\n",
      "Eval Loss:  0.19634699821472168\n",
      "Eval Loss:  0.2560415267944336\n",
      "Eval Loss:  0.22275863587856293\n",
      "Eval Loss:  0.2561763525009155\n",
      "Eval Loss:  0.2968316078186035\n",
      "Eval Loss:  0.3123457729816437\n",
      "Eval Loss:  0.24727556109428406\n",
      "Eval Loss:  0.13756626844406128\n",
      "Eval Loss:  0.14770756661891937\n",
      "[[16406  1526]\n",
      " [ 1447 10100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92     17932\n",
      "           1       0.87      0.87      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.89      0.89      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8991485464228773\n",
      "pre:  0.8687424737656976\n",
      "rec:  0.8746860656447563\n",
      "ma F1:  0.894312317926046\n",
      "mi F1:  0.8991485464228773\n",
      "we F1:  0.8992091334909472\n",
      "29479 461\n",
      "Loss:  0.0691421702504158\n",
      "Loss:  0.05637511610984802\n",
      "Loss:  0.05093880370259285\n",
      "45 **********\n",
      "Epoch:  2502.4389867782593  fold:  6  kers:  32\n",
      "epoch:  46\n",
      "29479 461\n",
      "Loss:  0.03730342909693718\n",
      "Loss:  0.06381013989448547\n",
      "Loss:  0.08584803342819214\n",
      "46 **********\n",
      "Epoch:  2544.8505861759186  fold:  6  kers:  32\n",
      "epoch:  47\n",
      "29479 461\n",
      "Loss:  0.0814882218837738\n",
      "Loss:  0.09040069580078125\n",
      "Loss:  0.06745342910289764\n",
      "47 **********\n",
      "Epoch:  2587.748885154724  fold:  6  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.04894082620739937\n",
      "Eval Loss:  0.12433061003684998\n",
      "Eval Loss:  0.43555617332458496\n",
      "[[2006  226]\n",
      " [ 112 1068]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      2232\n",
      "           1       0.83      0.91      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.90      0.89      3412\n",
      "weighted avg       0.91      0.90      0.90      3412\n",
      "\n",
      "acc:  0.9009378663540446\n",
      "pre:  0.8253477588871716\n",
      "rec:  0.9050847457627119\n",
      "ma F1:  0.8928389968314145\n",
      "mi F1:  0.9009378663540446\n",
      "we F1:  0.9019221639292896\n",
      "update!  Acc:  0.9009378663540446\n",
      "Eval Loss:  0.3587930500507355\n",
      "Eval Loss:  0.3808886706829071\n",
      "Eval Loss:  0.2552880048751831\n",
      "Eval Loss:  0.27901309728622437\n",
      "Eval Loss:  0.35531118512153625\n",
      "Eval Loss:  0.2942850589752197\n",
      "Eval Loss:  0.2994294762611389\n",
      "Eval Loss:  0.21801936626434326\n",
      "Eval Loss:  0.21907703578472137\n",
      "Eval Loss:  0.19530828297138214\n",
      "Eval Loss:  0.2138826996088028\n",
      "Eval Loss:  0.3671097755432129\n",
      "Eval Loss:  0.2914856970310211\n",
      "Eval Loss:  0.2592763900756836\n",
      "Eval Loss:  0.23454689979553223\n",
      "Eval Loss:  0.22420796751976013\n",
      "Eval Loss:  0.21453917026519775\n",
      "Eval Loss:  0.30387330055236816\n",
      "Eval Loss:  0.39738327264785767\n",
      "Eval Loss:  0.1868867576122284\n",
      "Eval Loss:  0.2533896565437317\n",
      "Eval Loss:  0.21488125622272491\n",
      "Eval Loss:  0.2546986937522888\n",
      "Eval Loss:  0.2995556890964508\n",
      "Eval Loss:  0.30411285161972046\n",
      "Eval Loss:  0.23921872675418854\n",
      "Eval Loss:  0.1375764012336731\n",
      "Eval Loss:  0.14062263071537018\n",
      "[[16546  1386]\n",
      " [ 1503 10044]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     17932\n",
      "           1       0.88      0.87      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9019980324977103\n",
      "pre:  0.878740157480315\n",
      "rec:  0.8698363211223694\n",
      "ma F1:  0.8969865966928425\n",
      "mi F1:  0.9019980324977103\n",
      "we F1:  0.9019078544003295\n",
      "29479 461\n",
      "Loss:  0.093328557908535\n",
      "Loss:  0.0631994903087616\n",
      "Loss:  0.07830435037612915\n",
      "48 **********\n",
      "Epoch:  2670.0278871059418  fold:  6  kers:  32\n",
      "epoch:  49\n",
      "29479 461\n",
      "Loss:  0.08376942574977875\n",
      "Loss:  0.0775497555732727\n",
      "Loss:  0.05791573226451874\n",
      "49 **********\n",
      "Epoch:  2711.8361008167267  fold:  6  kers:  32\n",
      "epoch:  50\n",
      "29479 461\n",
      "Loss:  0.06264909356832504\n",
      "Loss:  0.06980010122060776\n",
      "Loss:  0.07520700246095657\n",
      "50 **********\n",
      "Epoch:  2753.4578127861023  fold:  6  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.04969847947359085\n",
      "Eval Loss:  0.10356119275093079\n",
      "Eval Loss:  0.4653167128562927\n",
      "[[1988  244]\n",
      " [ 102 1078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      2232\n",
      "           1       0.82      0.91      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.88      0.90      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8985932004689332\n",
      "pre:  0.8154311649016641\n",
      "rec:  0.9135593220338983\n",
      "ma F1:  0.8908275508237555\n",
      "mi F1:  0.8985932004689332\n",
      "we F1:  0.899804983160818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.35535356402397156\n",
      "Eval Loss:  0.3708459138870239\n",
      "Eval Loss:  0.24571563303470612\n",
      "Eval Loss:  0.2690436840057373\n",
      "Eval Loss:  0.3385618329048157\n",
      "Eval Loss:  0.28693658113479614\n",
      "Eval Loss:  0.29317450523376465\n",
      "Eval Loss:  0.22646547853946686\n",
      "Eval Loss:  0.22942492365837097\n",
      "Eval Loss:  0.1876170039176941\n",
      "Eval Loss:  0.20208105444908142\n",
      "Eval Loss:  0.3578822612762451\n",
      "Eval Loss:  0.27001214027404785\n",
      "Eval Loss:  0.25843071937561035\n",
      "Eval Loss:  0.2165878266096115\n",
      "Eval Loss:  0.22149521112442017\n",
      "Eval Loss:  0.2046496421098709\n",
      "Eval Loss:  0.2973864674568176\n",
      "Eval Loss:  0.40212464332580566\n",
      "Eval Loss:  0.1815083920955658\n",
      "Eval Loss:  0.2383165806531906\n",
      "Eval Loss:  0.21466758847236633\n",
      "Eval Loss:  0.24037079513072968\n",
      "Eval Loss:  0.31284716725349426\n",
      "Eval Loss:  0.2889324128627777\n",
      "Eval Loss:  0.23003193736076355\n",
      "Eval Loss:  0.13058628141880035\n",
      "Eval Loss:  0.1404457986354828\n",
      "[[16470  1462]\n",
      " [ 1400 10147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     17932\n",
      "           1       0.87      0.88      0.88     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9029139387360494\n",
      "pre:  0.8740632268067878\n",
      "rec:  0.8787563869403309\n",
      "ma F1:  0.8982319278748614\n",
      "mi F1:  0.9029139387360494\n",
      "we F1:  0.9029598480628555\n",
      "29479 461\n",
      "Loss:  0.05001304671168327\n",
      "Loss:  0.05004499480128288\n",
      "Loss:  0.06352220475673676\n",
      "51 **********\n",
      "Epoch:  2834.065284729004  fold:  6  kers:  32\n",
      "epoch:  52\n",
      "29479 461\n",
      "Loss:  0.06196422874927521\n",
      "Loss:  0.0856490433216095\n",
      "Loss:  0.06913160532712936\n",
      "52 **********\n",
      "Epoch:  2875.460602283478  fold:  6  kers:  32\n",
      "epoch:  53\n",
      "29479 461\n",
      "Loss:  0.07172369956970215\n",
      "Loss:  0.040123555809259415\n",
      "Loss:  0.061549630016088486\n",
      "53 **********\n",
      "Epoch:  2916.91974902153  fold:  6  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.024968989193439484\n",
      "Eval Loss:  0.10490527749061584\n",
      "Eval Loss:  0.4044576585292816\n",
      "[[2055  177]\n",
      " [ 148 1032]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      2232\n",
      "           1       0.85      0.87      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.90      0.90      3412\n",
      "weighted avg       0.91      0.90      0.91      3412\n",
      "\n",
      "acc:  0.9047479484173505\n",
      "pre:  0.8535980148883374\n",
      "rec:  0.8745762711864407\n",
      "ma F1:  0.8953395471446308\n",
      "mi F1:  0.9047479484173505\n",
      "we F1:  0.905014657739842\n",
      "update!  Acc:  0.9047479484173505\n",
      "Eval Loss:  0.32547271251678467\n",
      "Eval Loss:  0.3634132146835327\n",
      "Eval Loss:  0.27095505595207214\n",
      "Eval Loss:  0.26339784264564514\n",
      "Eval Loss:  0.31547805666923523\n",
      "Eval Loss:  0.2552019953727722\n",
      "Eval Loss:  0.33031773567199707\n",
      "Eval Loss:  0.22295303642749786\n",
      "Eval Loss:  0.24617603421211243\n",
      "Eval Loss:  0.17937488853931427\n",
      "Eval Loss:  0.2081427276134491\n",
      "Eval Loss:  0.3720362186431885\n",
      "Eval Loss:  0.30005359649658203\n",
      "Eval Loss:  0.2491609901189804\n",
      "Eval Loss:  0.19885286688804626\n",
      "Eval Loss:  0.21313300728797913\n",
      "Eval Loss:  0.21437281370162964\n",
      "Eval Loss:  0.3006398677825928\n",
      "Eval Loss:  0.4052955210208893\n",
      "Eval Loss:  0.20653414726257324\n",
      "Eval Loss:  0.2674964368343353\n",
      "Eval Loss:  0.20998463034629822\n",
      "Eval Loss:  0.2379588633775711\n",
      "Eval Loss:  0.3220714330673218\n",
      "Eval Loss:  0.2886132001876831\n",
      "Eval Loss:  0.2287677377462387\n",
      "Eval Loss:  0.15017391741275787\n",
      "Eval Loss:  0.1530628353357315\n",
      "[[16766  1166]\n",
      " [ 1621  9926]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     17932\n",
      "           1       0.89      0.86      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9054581227314359\n",
      "pre:  0.8948791922106022\n",
      "rec:  0.8596172165930545\n",
      "ma F1:  0.9000785807217166\n",
      "mi F1:  0.9054581227314359\n",
      "we F1:  0.9051002730802046\n",
      "29479 461\n",
      "Loss:  0.03563471883535385\n",
      "Loss:  0.0635581761598587\n",
      "Loss:  0.07092119753360748\n",
      "54 **********\n",
      "Epoch:  2997.6788153648376  fold:  6  kers:  32\n",
      "epoch:  55\n",
      "29479 461\n",
      "Loss:  0.07237501442432404\n",
      "Loss:  0.049981407821178436\n",
      "Loss:  0.07393142580986023\n",
      "55 **********\n",
      "Epoch:  3039.271605014801  fold:  6  kers:  32\n",
      "epoch:  56\n",
      "29479 461\n",
      "Loss:  0.03359409421682358\n",
      "Loss:  0.05467195436358452\n",
      "Loss:  0.06810463219881058\n",
      "56 **********\n",
      "Epoch:  3080.6479728221893  fold:  6  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.016218937933444977\n",
      "Eval Loss:  0.14902305603027344\n",
      "Eval Loss:  0.40260568261146545\n",
      "[[2067  165]\n",
      " [ 166 1014]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      2232\n",
      "           1       0.86      0.86      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.902989449003517\n",
      "pre:  0.8600508905852418\n",
      "rec:  0.8593220338983051\n",
      "ma F1:  0.8927770844498708\n",
      "mi F1:  0.902989449003517\n",
      "we F1:  0.9029797506516142\n",
      "Eval Loss:  0.2940480709075928\n",
      "Eval Loss:  0.3427862823009491\n",
      "Eval Loss:  0.23049874603748322\n",
      "Eval Loss:  0.2759231626987457\n",
      "Eval Loss:  0.3283383250236511\n",
      "Eval Loss:  0.24334470927715302\n",
      "Eval Loss:  0.2912713289260864\n",
      "Eval Loss:  0.22882716357707977\n",
      "Eval Loss:  0.22170965373516083\n",
      "Eval Loss:  0.1754002869129181\n",
      "Eval Loss:  0.20022331178188324\n",
      "Eval Loss:  0.3654773533344269\n",
      "Eval Loss:  0.3002915382385254\n",
      "Eval Loss:  0.23889261484146118\n",
      "Eval Loss:  0.2261440008878708\n",
      "Eval Loss:  0.22262579202651978\n",
      "Eval Loss:  0.22099173069000244\n",
      "Eval Loss:  0.27124616503715515\n",
      "Eval Loss:  0.4084072411060333\n",
      "Eval Loss:  0.19782356917858124\n",
      "Eval Loss:  0.22794188559055328\n",
      "Eval Loss:  0.20451387763023376\n",
      "Eval Loss:  0.22908423840999603\n",
      "Eval Loss:  0.33848053216934204\n",
      "Eval Loss:  0.29848578572273254\n",
      "Eval Loss:  0.22448453307151794\n",
      "Eval Loss:  0.14529059827327728\n",
      "Eval Loss:  0.14596866071224213\n",
      "[[16937   995]\n",
      " [ 1748  9799]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     17932\n",
      "           1       0.91      0.85      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.906950710675396\n",
      "pre:  0.9078191587919214\n",
      "rec:  0.8486186888369274\n",
      "ma F1:  0.9011553458686742\n",
      "mi F1:  0.906950710675396\n",
      "we F1:  0.9063393475905737\n",
      "29479 461\n",
      "Loss:  0.06136848032474518\n",
      "Loss:  0.0414687842130661\n",
      "Loss:  0.059593990445137024\n",
      "57 **********\n",
      "Epoch:  3161.1666820049286  fold:  6  kers:  32\n",
      "epoch:  58\n",
      "29479 461\n",
      "Loss:  0.03899171203374863\n",
      "Loss:  0.08542189747095108\n",
      "Loss:  0.07810709625482559\n",
      "58 **********\n",
      "Epoch:  3202.489193916321  fold:  6  kers:  32\n",
      "epoch:  59\n",
      "29479 461\n",
      "Loss:  0.06926604360342026\n",
      "Loss:  0.09883204847574234\n",
      "Loss:  0.061697252094745636\n",
      "59 **********\n",
      "Epoch:  3243.857583284378  fold:  6  kers:  32\n",
      "Eval Loss:  0.052993327379226685\n",
      "Eval Loss:  0.08514886349439621\n",
      "Eval Loss:  0.42663881182670593\n",
      "[[2005  227]\n",
      " [ 109 1071]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      2232\n",
      "           1       0.83      0.91      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.90      0.89      3412\n",
      "weighted avg       0.91      0.90      0.90      3412\n",
      "\n",
      "acc:  0.9015240328253223\n",
      "pre:  0.825115562403698\n",
      "rec:  0.9076271186440678\n",
      "ma F1:  0.8935471542115485\n",
      "mi F1:  0.9015240328253223\n",
      "we F1:  0.9025318183461204\n",
      "update!  Acc:  0.9047479484173505\n",
      "Epoch:  3247.968591451645  fold:  6  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.1711326241493225\n",
      "Loss:  0.16954593360424042\n",
      "Loss:  0.15177062153816223\n",
      "0 **********\n",
      "Epoch:  54.08239483833313  fold:  7  kers:  32\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.1457124799489975\n",
      "Loss:  0.1329369843006134\n",
      "Loss:  0.11573135107755661\n",
      "1 **********\n",
      "Epoch:  95.73602151870728  fold:  7  kers:  32\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.10479021072387695\n",
      "Loss:  0.1169360876083374\n",
      "Loss:  0.11007556319236755\n",
      "2 **********\n",
      "Epoch:  137.3268165588379  fold:  7  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.8217025995254517\n",
      "Eval Loss:  0.14486488699913025\n",
      "Eval Loss:  2.0186686515808105\n",
      "[[1688  439]\n",
      " [ 654  650]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.76      2127\n",
      "           1       0.60      0.50      0.54      1304\n",
      "\n",
      "    accuracy                           0.68      3431\n",
      "   macro avg       0.66      0.65      0.65      3431\n",
      "weighted avg       0.67      0.68      0.67      3431\n",
      "\n",
      "acc:  0.6814339842611483\n",
      "pre:  0.5968778696051423\n",
      "rec:  0.49846625766871167\n",
      "ma F1:  0.6493387095220761\n",
      "mi F1:  0.6814339842611483\n",
      "we F1:  0.6747861190695293\n",
      "update!  Acc:  0.6814339842611483\n",
      "Eval Loss:  0.45047178864479065\n",
      "Eval Loss:  0.414061576128006\n",
      "Eval Loss:  0.41262295842170715\n",
      "Eval Loss:  0.47568589448928833\n",
      "Eval Loss:  0.4279395043849945\n",
      "Eval Loss:  0.4076595902442932\n",
      "Eval Loss:  0.3402467966079712\n",
      "Eval Loss:  0.3742155134677887\n",
      "Eval Loss:  0.4342934191226959\n",
      "Eval Loss:  0.4973030686378479\n",
      "Eval Loss:  0.4878646433353424\n",
      "Eval Loss:  0.4545687139034271\n",
      "Eval Loss:  0.39577215909957886\n",
      "Eval Loss:  0.3664894104003906\n",
      "Eval Loss:  0.4004864990711212\n",
      "Eval Loss:  0.3637826144695282\n",
      "Eval Loss:  0.39090362191200256\n",
      "Eval Loss:  0.46355074644088745\n",
      "Eval Loss:  0.3383845388889313\n",
      "Eval Loss:  0.5584797859191895\n",
      "Eval Loss:  0.3282249867916107\n",
      "Eval Loss:  0.421597421169281\n",
      "Eval Loss:  0.3635532855987549\n",
      "Eval Loss:  0.42730721831321716\n",
      "Eval Loss:  0.398353636264801\n",
      "Eval Loss:  0.5287749767303467\n",
      "Eval Loss:  0.2875822186470032\n",
      "Eval Loss:  0.40589553117752075\n",
      "[[15551  2486]\n",
      " [ 2867  8556]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85     18037\n",
      "           1       0.77      0.75      0.76     11423\n",
      "\n",
      "    accuracy                           0.82     29460\n",
      "   macro avg       0.81      0.81      0.81     29460\n",
      "weighted avg       0.82      0.82      0.82     29460\n",
      "\n",
      "acc:  0.818295994568907\n",
      "pre:  0.7748596268791885\n",
      "rec:  0.7490151448831305\n",
      "ma F1:  0.8074398301287822\n",
      "mi F1:  0.818295994568907\n",
      "we F1:  0.8177046866844627\n",
      "29460 461\n",
      "Loss:  0.1077282577753067\n",
      "Loss:  0.09365111589431763\n",
      "Loss:  0.09428241848945618\n",
      "3 **********\n",
      "Epoch:  218.37211751937866  fold:  7  kers:  32\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.11298437416553497\n",
      "Loss:  0.11214281618595123\n",
      "Loss:  0.08107957243919373\n",
      "4 **********\n",
      "Epoch:  259.99283242225647  fold:  7  kers:  32\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.09372144937515259\n",
      "Loss:  0.08790213614702225\n",
      "Loss:  0.07245998084545135\n",
      "5 **********\n",
      "Epoch:  301.5168056488037  fold:  7  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.6940032243728638\n",
      "Eval Loss:  0.11310723423957825\n",
      "Eval Loss:  2.4114787578582764\n",
      "[[1881  246]\n",
      " [ 745  559]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79      2127\n",
      "           1       0.69      0.43      0.53      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.71      0.66      0.66      3431\n",
      "weighted avg       0.71      0.71      0.69      3431\n",
      "\n",
      "acc:  0.7111629262605654\n",
      "pre:  0.6944099378881987\n",
      "rec:  0.42868098159509205\n",
      "ma F1:  0.6608045808107819\n",
      "mi F1:  0.7111629262605655\n",
      "we F1:  0.6921547459432871\n",
      "update!  Acc:  0.7111629262605654\n",
      "Eval Loss:  0.40632811188697815\n",
      "Eval Loss:  0.36399465799331665\n",
      "Eval Loss:  0.36941075325012207\n",
      "Eval Loss:  0.49332353472709656\n",
      "Eval Loss:  0.37799787521362305\n",
      "Eval Loss:  0.3637593388557434\n",
      "Eval Loss:  0.23887231945991516\n",
      "Eval Loss:  0.3117610812187195\n",
      "Eval Loss:  0.35426145792007446\n",
      "Eval Loss:  0.45633065700531006\n",
      "Eval Loss:  0.4904415011405945\n",
      "Eval Loss:  0.3780842423439026\n",
      "Eval Loss:  0.34402453899383545\n",
      "Eval Loss:  0.2864370048046112\n",
      "Eval Loss:  0.31707319617271423\n",
      "Eval Loss:  0.3075885474681854\n",
      "Eval Loss:  0.3759859502315521\n",
      "Eval Loss:  0.3991380035877228\n",
      "Eval Loss:  0.2652277946472168\n",
      "Eval Loss:  0.4557756185531616\n",
      "Eval Loss:  0.22297586500644684\n",
      "Eval Loss:  0.3778004050254822\n",
      "Eval Loss:  0.2430121898651123\n",
      "Eval Loss:  0.3523740768432617\n",
      "Eval Loss:  0.25840213894844055\n",
      "Eval Loss:  0.4693749248981476\n",
      "Eval Loss:  0.24449250102043152\n",
      "Eval Loss:  0.4021010100841522\n",
      "[[16495  1542]\n",
      " [ 2751  8672]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88     18037\n",
      "           1       0.85      0.76      0.80     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.85      0.84      0.84     29460\n",
      "weighted avg       0.85      0.85      0.85     29460\n",
      "\n",
      "acc:  0.8542769857433808\n",
      "pre:  0.8490307421186607\n",
      "rec:  0.759170095421518\n",
      "ma F1:  0.8432217779361866\n",
      "mi F1:  0.8542769857433808\n",
      "we F1:  0.8525684664746991\n",
      "29460 461\n",
      "Loss:  0.1108555719256401\n",
      "Loss:  0.07323983311653137\n",
      "Loss:  0.1045318990945816\n",
      "6 **********\n",
      "Epoch:  382.0474829673767  fold:  7  kers:  32\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.08484897762537003\n",
      "Loss:  0.08937014639377594\n",
      "Loss:  0.07556667178869247\n",
      "7 **********\n",
      "Epoch:  423.42484855651855  fold:  7  kers:  32\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.07502873241901398\n",
      "Loss:  0.0872465968132019\n",
      "Loss:  0.0657711997628212\n",
      "8 **********\n",
      "Epoch:  464.80620288848877  fold:  7  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.8799371719360352\n",
      "Eval Loss:  0.0615733377635479\n",
      "Eval Loss:  3.1535727977752686\n",
      "[[2035   92]\n",
      " [ 914  390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80      2127\n",
      "           1       0.81      0.30      0.44      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.75      0.63      0.62      3431\n",
      "weighted avg       0.74      0.71      0.66      3431\n",
      "\n",
      "acc:  0.706791023025357\n",
      "pre:  0.8091286307053942\n",
      "rec:  0.299079754601227\n",
      "ma F1:  0.6192712869644561\n",
      "mi F1:  0.706791023025357\n",
      "we F1:  0.6630577567383901\n",
      "Eval Loss:  0.4675329923629761\n",
      "Eval Loss:  0.4186556339263916\n",
      "Eval Loss:  0.36241379380226135\n",
      "Eval Loss:  0.5759239196777344\n",
      "Eval Loss:  0.42430397868156433\n",
      "Eval Loss:  0.3767336905002594\n",
      "Eval Loss:  0.29186946153640747\n",
      "Eval Loss:  0.3096867799758911\n",
      "Eval Loss:  0.37443941831588745\n",
      "Eval Loss:  0.48391732573509216\n",
      "Eval Loss:  0.48271092772483826\n",
      "Eval Loss:  0.4414813816547394\n",
      "Eval Loss:  0.37994760274887085\n",
      "Eval Loss:  0.30631840229034424\n",
      "Eval Loss:  0.3440430462360382\n",
      "Eval Loss:  0.3126882314682007\n",
      "Eval Loss:  0.3776857852935791\n",
      "Eval Loss:  0.49573174118995667\n",
      "Eval Loss:  0.28531160950660706\n",
      "Eval Loss:  0.5198532342910767\n",
      "Eval Loss:  0.2557867467403412\n",
      "Eval Loss:  0.3749931752681732\n",
      "Eval Loss:  0.29427370429039\n",
      "Eval Loss:  0.3676241934299469\n",
      "Eval Loss:  0.36289191246032715\n",
      "Eval Loss:  0.509548544883728\n",
      "Eval Loss:  0.28606075048446655\n",
      "Eval Loss:  0.39465320110321045\n",
      "[[17225   812]\n",
      " [ 3621  7802]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     18037\n",
      "           1       0.91      0.68      0.78     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.87      0.82      0.83     29460\n",
      "weighted avg       0.86      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8495247793618466\n",
      "pre:  0.9057348502437892\n",
      "rec:  0.683007966383612\n",
      "ma F1:  0.8323753012793935\n",
      "mi F1:  0.8495247793618466\n",
      "we F1:  0.8444125132116173\n",
      "29460 461\n",
      "Loss:  0.10369838029146194\n",
      "Loss:  0.08422045409679413\n",
      "Loss:  0.09406590461730957\n",
      "9 **********\n",
      "Epoch:  545.4186615943909  fold:  7  kers:  32\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.08566530048847198\n",
      "Loss:  0.10503799468278885\n",
      "Loss:  0.0845300555229187\n",
      "10 **********\n",
      "Epoch:  589.3332433700562  fold:  7  kers:  32\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.10826316475868225\n",
      "Loss:  0.09623073786497116\n",
      "Loss:  0.07790961116552353\n",
      "11 **********\n",
      "Epoch:  630.8612055778503  fold:  7  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.9588589072227478\n",
      "Eval Loss:  0.040319450199604034\n",
      "Eval Loss:  3.438859224319458\n",
      "[[2062   65]\n",
      " [ 952  352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80      2127\n",
      "           1       0.84      0.27      0.41      1304\n",
      "\n",
      "    accuracy                           0.70      3431\n",
      "   macro avg       0.76      0.62      0.61      3431\n",
      "weighted avg       0.74      0.70      0.65      3431\n",
      "\n",
      "acc:  0.7035849606528709\n",
      "pre:  0.8441247002398081\n",
      "rec:  0.26993865030674846\n",
      "ma F1:  0.6056215309334299\n",
      "mi F1:  0.7035849606528709\n",
      "we F1:  0.6527700120206228\n",
      "Eval Loss:  0.5033964514732361\n",
      "Eval Loss:  0.43580085039138794\n",
      "Eval Loss:  0.36972105503082275\n",
      "Eval Loss:  0.5873017907142639\n",
      "Eval Loss:  0.4187915623188019\n",
      "Eval Loss:  0.37443819642066956\n",
      "Eval Loss:  0.29980042576789856\n",
      "Eval Loss:  0.32076677680015564\n",
      "Eval Loss:  0.37119388580322266\n",
      "Eval Loss:  0.501285195350647\n",
      "Eval Loss:  0.4963271915912628\n",
      "Eval Loss:  0.4256768226623535\n",
      "Eval Loss:  0.4175589382648468\n",
      "Eval Loss:  0.28813162446022034\n",
      "Eval Loss:  0.351421058177948\n",
      "Eval Loss:  0.3074646294116974\n",
      "Eval Loss:  0.36517563462257385\n",
      "Eval Loss:  0.5315626859664917\n",
      "Eval Loss:  0.3069840371608734\n",
      "Eval Loss:  0.5094554424285889\n",
      "Eval Loss:  0.26104676723480225\n",
      "Eval Loss:  0.3594704866409302\n",
      "Eval Loss:  0.2868458032608032\n",
      "Eval Loss:  0.37672626972198486\n",
      "Eval Loss:  0.3971559703350067\n",
      "Eval Loss:  0.5239371061325073\n",
      "Eval Loss:  0.3248138129711151\n",
      "Eval Loss:  0.3932819366455078\n",
      "[[17386   651]\n",
      " [ 3754  7669]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89     18037\n",
      "           1       0.92      0.67      0.78     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.87      0.82      0.83     29460\n",
      "weighted avg       0.86      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8504752206381534\n",
      "pre:  0.9217548076923077\n",
      "rec:  0.6713647903352885\n",
      "ma F1:  0.8322222626762008\n",
      "mi F1:  0.8504752206381534\n",
      "we F1:  0.844646371347638\n",
      "29460 461\n",
      "Loss:  0.07508436590433121\n",
      "Loss:  0.08967282623052597\n",
      "Loss:  0.08232744038105011\n",
      "12 **********\n",
      "Epoch:  711.7997922897339  fold:  7  kers:  32\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.09298557788133621\n",
      "Loss:  0.06413806974887848\n",
      "Loss:  0.10352562367916107\n",
      "13 **********\n",
      "Epoch:  753.337728023529  fold:  7  kers:  32\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.04490639269351959\n",
      "Loss:  0.0774850845336914\n",
      "Loss:  0.059260133653879166\n",
      "14 **********\n",
      "Epoch:  794.8437497615814  fold:  7  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.7276360988616943\n",
      "Eval Loss:  0.08551423251628876\n",
      "Eval Loss:  2.774172067642212\n",
      "[[2012  115]\n",
      " [ 790  514]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82      2127\n",
      "           1       0.82      0.39      0.53      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.77      0.67      0.67      3431\n",
      "weighted avg       0.76      0.74      0.71      3431\n",
      "\n",
      "acc:  0.7362285048090935\n",
      "pre:  0.8171701112877583\n",
      "rec:  0.3941717791411043\n",
      "ma F1:  0.6741043038776072\n",
      "mi F1:  0.7362285048090936\n",
      "we F1:  0.7082352901036508\n",
      "update!  Acc:  0.7362285048090935\n",
      "Eval Loss:  0.3964325785636902\n",
      "Eval Loss:  0.3625580668449402\n",
      "Eval Loss:  0.29748016595840454\n",
      "Eval Loss:  0.464850515127182\n",
      "Eval Loss:  0.30715829133987427\n",
      "Eval Loss:  0.31077146530151367\n",
      "Eval Loss:  0.2271033525466919\n",
      "Eval Loss:  0.27527374029159546\n",
      "Eval Loss:  0.3145564794540405\n",
      "Eval Loss:  0.4159272015094757\n",
      "Eval Loss:  0.42095595598220825\n",
      "Eval Loss:  0.3362671136856079\n",
      "Eval Loss:  0.305154412984848\n",
      "Eval Loss:  0.23555564880371094\n",
      "Eval Loss:  0.2964233160018921\n",
      "Eval Loss:  0.26578328013420105\n",
      "Eval Loss:  0.30872586369514465\n",
      "Eval Loss:  0.4046478867530823\n",
      "Eval Loss:  0.26234138011932373\n",
      "Eval Loss:  0.40744253993034363\n",
      "Eval Loss:  0.21562930941581726\n",
      "Eval Loss:  0.3259703516960144\n",
      "Eval Loss:  0.22793200612068176\n",
      "Eval Loss:  0.2815820872783661\n",
      "Eval Loss:  0.23719368875026703\n",
      "Eval Loss:  0.4223880171775818\n",
      "Eval Loss:  0.2437485158443451\n",
      "Eval Loss:  0.3388496935367584\n",
      "[[17118   919]\n",
      " [ 2858  8565]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18037\n",
      "           1       0.90      0.75      0.82     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.85      0.86     29460\n",
      "weighted avg       0.87      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8717922606924644\n",
      "pre:  0.9030999578237031\n",
      "rec:  0.7498030289766261\n",
      "ma F1:  0.8599910294186577\n",
      "mi F1:  0.8717922606924644\n",
      "we F1:  0.869116873408481\n",
      "29460 461\n",
      "Loss:  0.10606664419174194\n",
      "Loss:  0.08880890905857086\n",
      "Loss:  0.11760043352842331\n",
      "15 **********\n",
      "Epoch:  875.6816053390503  fold:  7  kers:  32\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.04153481125831604\n",
      "Loss:  0.08288591355085373\n",
      "Loss:  0.052621595561504364\n",
      "16 **********\n",
      "Epoch:  917.1208057403564  fold:  7  kers:  32\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.04149191081523895\n",
      "Loss:  0.07939978688955307\n",
      "Loss:  0.05897032842040062\n",
      "17 **********\n",
      "Epoch:  958.5699787139893  fold:  7  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.825920045375824\n",
      "Eval Loss:  0.05659698694944382\n",
      "Eval Loss:  2.9904332160949707\n",
      "[[2039   88]\n",
      " [ 854  450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81      2127\n",
      "           1       0.84      0.35      0.49      1304\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.77      0.65      0.65      3431\n",
      "weighted avg       0.75      0.73      0.69      3431\n",
      "\n",
      "acc:  0.7254444768289129\n",
      "pre:  0.8364312267657993\n",
      "rec:  0.3450920245398773\n",
      "ma F1:  0.6504749730718818\n",
      "mi F1:  0.7254444768289129\n",
      "we F1:  0.689304363626971\n",
      "Eval Loss:  0.4357261657714844\n",
      "Eval Loss:  0.3814074695110321\n",
      "Eval Loss:  0.29617610573768616\n",
      "Eval Loss:  0.4955558776855469\n",
      "Eval Loss:  0.31590792536735535\n",
      "Eval Loss:  0.320701539516449\n",
      "Eval Loss:  0.26369357109069824\n",
      "Eval Loss:  0.2754625380039215\n",
      "Eval Loss:  0.3207797408103943\n",
      "Eval Loss:  0.4423808753490448\n",
      "Eval Loss:  0.4387652277946472\n",
      "Eval Loss:  0.34326809644699097\n",
      "Eval Loss:  0.32205140590667725\n",
      "Eval Loss:  0.25374042987823486\n",
      "Eval Loss:  0.3185003697872162\n",
      "Eval Loss:  0.28379297256469727\n",
      "Eval Loss:  0.30886998772621155\n",
      "Eval Loss:  0.47262629866600037\n",
      "Eval Loss:  0.2744731307029724\n",
      "Eval Loss:  0.4344823360443115\n",
      "Eval Loss:  0.23818427324295044\n",
      "Eval Loss:  0.3271966874599457\n",
      "Eval Loss:  0.23725441098213196\n",
      "Eval Loss:  0.28646671772003174\n",
      "Eval Loss:  0.25922220945358276\n",
      "Eval Loss:  0.4608613848686218\n",
      "Eval Loss:  0.2778727412223816\n",
      "Eval Loss:  0.3574427366256714\n",
      "[[17323   714]\n",
      " [ 3247  8176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     18037\n",
      "           1       0.92      0.72      0.81     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.84      0.85     29460\n",
      "weighted avg       0.87      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8655465037338764\n",
      "pre:  0.9196850393700787\n",
      "rec:  0.7157489276022061\n",
      "ma F1:  0.8512018742869599\n",
      "mi F1:  0.8655465037338764\n",
      "we F1:  0.8615741689367802\n",
      "29460 461\n",
      "Loss:  0.0781564861536026\n",
      "Loss:  0.06965544819831848\n",
      "Loss:  0.06346265226602554\n",
      "18 **********\n",
      "Epoch:  1039.2462675571442  fold:  7  kers:  32\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.0858093872666359\n",
      "Loss:  0.06332217901945114\n",
      "Loss:  0.07051453739404678\n",
      "19 **********\n",
      "Epoch:  1080.7293496131897  fold:  7  kers:  32\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.07738946378231049\n",
      "Loss:  0.07831422984600067\n",
      "Loss:  0.08046571165323257\n",
      "20 **********\n",
      "Epoch:  1122.2124321460724  fold:  7  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.829125165939331\n",
      "Eval Loss:  0.06403438746929169\n",
      "Eval Loss:  3.0266294479370117\n",
      "[[2041   86]\n",
      " [ 804  500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      2127\n",
      "           1       0.85      0.38      0.53      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.79      0.67      0.68      3431\n",
      "weighted avg       0.77      0.74      0.71      3431\n",
      "\n",
      "acc:  0.7406004080443019\n",
      "pre:  0.8532423208191127\n",
      "rec:  0.3834355828220859\n",
      "ma F1:  0.6750490577924206\n",
      "mi F1:  0.7406004080443019\n",
      "we F1:  0.7100579878750282\n",
      "update!  Acc:  0.7406004080443019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.39178434014320374\n",
      "Eval Loss:  0.36540505290031433\n",
      "Eval Loss:  0.28626856207847595\n",
      "Eval Loss:  0.4677894711494446\n",
      "Eval Loss:  0.31538641452789307\n",
      "Eval Loss:  0.2914792001247406\n",
      "Eval Loss:  0.2548995018005371\n",
      "Eval Loss:  0.2712671756744385\n",
      "Eval Loss:  0.31877458095550537\n",
      "Eval Loss:  0.43032920360565186\n",
      "Eval Loss:  0.4284517467021942\n",
      "Eval Loss:  0.33096736669540405\n",
      "Eval Loss:  0.30087539553642273\n",
      "Eval Loss:  0.2520870566368103\n",
      "Eval Loss:  0.28320810198783875\n",
      "Eval Loss:  0.2625994384288788\n",
      "Eval Loss:  0.30478253960609436\n",
      "Eval Loss:  0.3954246938228607\n",
      "Eval Loss:  0.25357919931411743\n",
      "Eval Loss:  0.41334718465805054\n",
      "Eval Loss:  0.22279228270053864\n",
      "Eval Loss:  0.3189375400543213\n",
      "Eval Loss:  0.24514923989772797\n",
      "Eval Loss:  0.2760888636112213\n",
      "Eval Loss:  0.2517653703689575\n",
      "Eval Loss:  0.4039498269557953\n",
      "Eval Loss:  0.23888924717903137\n",
      "Eval Loss:  0.3370826244354248\n",
      "[[17183   854]\n",
      " [ 2883  8540]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18037\n",
      "           1       0.91      0.75      0.82     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.85      0.86     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8731500339443313\n",
      "pre:  0.9090909090909091\n",
      "rec:  0.7476144620502495\n",
      "ma F1:  0.8612034959571755\n",
      "mi F1:  0.8731500339443313\n",
      "we F1:  0.8703455070930136\n",
      "29460 461\n",
      "Loss:  0.0572516992688179\n",
      "Loss:  0.09698721021413803\n",
      "Loss:  0.06023639068007469\n",
      "21 **********\n",
      "Epoch:  1203.1849284172058  fold:  7  kers:  32\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.10039929300546646\n",
      "Loss:  0.06201634928584099\n",
      "Loss:  0.060238756239414215\n",
      "22 **********\n",
      "Epoch:  1244.7388217449188  fold:  7  kers:  32\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.07102108001708984\n",
      "Loss:  0.05018666386604309\n",
      "Loss:  0.05822998657822609\n",
      "23 **********\n",
      "Epoch:  1286.243845462799  fold:  7  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.6923000812530518\n",
      "Eval Loss:  0.10208597034215927\n",
      "Eval Loss:  2.8181304931640625\n",
      "[[2006  121]\n",
      " [ 735  569]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.94      0.82      2127\n",
      "           1       0.82      0.44      0.57      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.69      0.70      3431\n",
      "weighted avg       0.77      0.75      0.73      3431\n",
      "\n",
      "acc:  0.750510055377441\n",
      "pre:  0.8246376811594203\n",
      "rec:  0.4363496932515337\n",
      "ma F1:  0.6974349507025596\n",
      "mi F1:  0.750510055377441\n",
      "we F1:  0.7278321748830936\n",
      "update!  Acc:  0.750510055377441\n",
      "Eval Loss:  0.36718934774398804\n",
      "Eval Loss:  0.31801944971084595\n",
      "Eval Loss:  0.28512853384017944\n",
      "Eval Loss:  0.4156859517097473\n",
      "Eval Loss:  0.28027212619781494\n",
      "Eval Loss:  0.2756834626197815\n",
      "Eval Loss:  0.22528445720672607\n",
      "Eval Loss:  0.2746327221393585\n",
      "Eval Loss:  0.31539157032966614\n",
      "Eval Loss:  0.40332910418510437\n",
      "Eval Loss:  0.39969125390052795\n",
      "Eval Loss:  0.3061823844909668\n",
      "Eval Loss:  0.2694546580314636\n",
      "Eval Loss:  0.2229691594839096\n",
      "Eval Loss:  0.262533575296402\n",
      "Eval Loss:  0.2603178918361664\n",
      "Eval Loss:  0.28722018003463745\n",
      "Eval Loss:  0.3221924304962158\n",
      "Eval Loss:  0.23572580516338348\n",
      "Eval Loss:  0.380149781703949\n",
      "Eval Loss:  0.1997917890548706\n",
      "Eval Loss:  0.3085298240184784\n",
      "Eval Loss:  0.23638324439525604\n",
      "Eval Loss:  0.2241334617137909\n",
      "Eval Loss:  0.1816241443157196\n",
      "Eval Loss:  0.3605610728263855\n",
      "Eval Loss:  0.21591398119926453\n",
      "Eval Loss:  0.33744168281555176\n",
      "[[16884  1153]\n",
      " [ 2318  9105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18037\n",
      "           1       0.89      0.80      0.84     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.88      0.87      0.87     29460\n",
      "weighted avg       0.88      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8821792260692465\n",
      "pre:  0.8875999220120881\n",
      "rec:  0.7970760745863609\n",
      "ma F1:  0.8733485878094547\n",
      "mi F1:  0.8821792260692465\n",
      "we F1:  0.8808567304306479\n",
      "29460 461\n",
      "Loss:  0.07991991937160492\n",
      "Loss:  0.08701278269290924\n",
      "Loss:  0.08469610661268234\n",
      "24 **********\n",
      "Epoch:  1367.0807042121887  fold:  7  kers:  32\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.05017486587166786\n",
      "Loss:  0.0886293426156044\n",
      "Loss:  0.09050935506820679\n",
      "25 **********\n",
      "Epoch:  1408.4979634284973  fold:  7  kers:  32\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.08246129751205444\n",
      "Loss:  0.08819574862718582\n",
      "Loss:  0.06360360234975815\n",
      "26 **********\n",
      "Epoch:  1449.9800479412079  fold:  7  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.6708117127418518\n",
      "Eval Loss:  0.17698943614959717\n",
      "Eval Loss:  2.4074039459228516\n",
      "[[1969  158]\n",
      " [ 686  618]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82      2127\n",
      "           1       0.80      0.47      0.59      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.70      0.71      3431\n",
      "weighted avg       0.76      0.75      0.74      3431\n",
      "\n",
      "acc:  0.7540075779656077\n",
      "pre:  0.7963917525773195\n",
      "rec:  0.47392638036809814\n",
      "ma F1:  0.7088677894669112\n",
      "mi F1:  0.7540075779656077\n",
      "we F1:  0.7363659729861023\n",
      "update!  Acc:  0.7540075779656077\n",
      "Eval Loss:  0.34959763288497925\n",
      "Eval Loss:  0.3119896948337555\n",
      "Eval Loss:  0.25019556283950806\n",
      "Eval Loss:  0.39183369278907776\n",
      "Eval Loss:  0.24477867782115936\n",
      "Eval Loss:  0.27476173639297485\n",
      "Eval Loss:  0.20147652924060822\n",
      "Eval Loss:  0.26594072580337524\n",
      "Eval Loss:  0.3161991536617279\n",
      "Eval Loss:  0.36656898260116577\n",
      "Eval Loss:  0.36743324995040894\n",
      "Eval Loss:  0.28467026352882385\n",
      "Eval Loss:  0.2706237733364105\n",
      "Eval Loss:  0.2108590006828308\n",
      "Eval Loss:  0.24838948249816895\n",
      "Eval Loss:  0.25992679595947266\n",
      "Eval Loss:  0.26900622248649597\n",
      "Eval Loss:  0.3030272126197815\n",
      "Eval Loss:  0.2319197952747345\n",
      "Eval Loss:  0.35171452164649963\n",
      "Eval Loss:  0.19275492429733276\n",
      "Eval Loss:  0.3010820150375366\n",
      "Eval Loss:  0.23076704144477844\n",
      "Eval Loss:  0.21187444031238556\n",
      "Eval Loss:  0.14548565447330475\n",
      "Eval Loss:  0.34538745880126953\n",
      "Eval Loss:  0.22072480618953705\n",
      "Eval Loss:  0.31822463870048523\n",
      "[[16860  1177]\n",
      " [ 2138  9285]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18037\n",
      "           1       0.89      0.81      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8874745417515275\n",
      "pre:  0.8874976103995412\n",
      "rec:  0.8128337564562724\n",
      "ma F1:  0.8795082324455878\n",
      "mi F1:  0.8874745417515275\n",
      "we F1:  0.8864638984191171\n",
      "29460 461\n",
      "Loss:  0.05951344594359398\n",
      "Loss:  0.042685896158218384\n",
      "Loss:  0.08343636989593506\n",
      "27 **********\n",
      "Epoch:  1530.7740213871002  fold:  7  kers:  32\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.09732218086719513\n",
      "Loss:  0.0651811808347702\n",
      "Loss:  0.10397592931985855\n",
      "28 **********\n",
      "Epoch:  1572.3767838478088  fold:  7  kers:  32\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.0786157175898552\n",
      "Loss:  0.04143349453806877\n",
      "Loss:  0.07489127665758133\n",
      "29 **********\n",
      "Epoch:  1613.9785497188568  fold:  7  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.8163115382194519\n",
      "Eval Loss:  0.07096925377845764\n",
      "Eval Loss:  2.8751637935638428\n",
      "[[2041   86]\n",
      " [ 770  534]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83      2127\n",
      "           1       0.86      0.41      0.56      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.79      0.68      0.69      3431\n",
      "weighted avg       0.78      0.75      0.72      3431\n",
      "\n",
      "acc:  0.750510055377441\n",
      "pre:  0.8612903225806452\n",
      "rec:  0.40950920245398775\n",
      "ma F1:  0.6908720104345865\n",
      "mi F1:  0.750510055377441\n",
      "we F1:  0.7234414271485673\n",
      "Eval Loss:  0.3973938524723053\n",
      "Eval Loss:  0.3256228268146515\n",
      "Eval Loss:  0.2660030126571655\n",
      "Eval Loss:  0.4256090223789215\n",
      "Eval Loss:  0.26804685592651367\n",
      "Eval Loss:  0.2753679156303406\n",
      "Eval Loss:  0.23007477819919586\n",
      "Eval Loss:  0.265289306640625\n",
      "Eval Loss:  0.3096555471420288\n",
      "Eval Loss:  0.3921740651130676\n",
      "Eval Loss:  0.40035954117774963\n",
      "Eval Loss:  0.30892303586006165\n",
      "Eval Loss:  0.291706383228302\n",
      "Eval Loss:  0.22757087647914886\n",
      "Eval Loss:  0.26640981435775757\n",
      "Eval Loss:  0.26141369342803955\n",
      "Eval Loss:  0.2780269682407379\n",
      "Eval Loss:  0.35587337613105774\n",
      "Eval Loss:  0.24031297862529755\n",
      "Eval Loss:  0.38472601771354675\n",
      "Eval Loss:  0.2057868391275406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2922600209712982\n",
      "Eval Loss:  0.23413021862506866\n",
      "Eval Loss:  0.2286500632762909\n",
      "Eval Loss:  0.17826707661151886\n",
      "Eval Loss:  0.3923184275627136\n",
      "Eval Loss:  0.24702048301696777\n",
      "Eval Loss:  0.3366047143936157\n",
      "[[17137   900]\n",
      " [ 2580  8843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18037\n",
      "           1       0.91      0.77      0.84     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.86      0.87     29460\n",
      "weighted avg       0.88      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8818737270875764\n",
      "pre:  0.9076259878887406\n",
      "rec:  0.774139893197934\n",
      "ma F1:  0.8717048546308963\n",
      "mi F1:  0.8818737270875764\n",
      "we F1:  0.8798139603010775\n",
      "29460 461\n",
      "Loss:  0.08345909416675568\n",
      "Loss:  0.07203108817338943\n",
      "Loss:  0.08463302999734879\n",
      "30 **********\n",
      "Epoch:  1694.7017121315002  fold:  7  kers:  32\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.053751930594444275\n",
      "Loss:  0.07434514909982681\n",
      "Loss:  0.09751009941101074\n",
      "31 **********\n",
      "Epoch:  1736.1538774967194  fold:  7  kers:  32\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.0903000459074974\n",
      "Loss:  0.03708617016673088\n",
      "Loss:  0.06155247986316681\n",
      "32 **********\n",
      "Epoch:  1777.5621602535248  fold:  7  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.6296504735946655\n",
      "Eval Loss:  0.15914861857891083\n",
      "Eval Loss:  2.2999179363250732\n",
      "[[1984  143]\n",
      " [ 672  632]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      2127\n",
      "           1       0.82      0.48      0.61      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.71      0.72      3431\n",
      "weighted avg       0.77      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7624599242203439\n",
      "pre:  0.8154838709677419\n",
      "rec:  0.48466257668711654\n",
      "ma F1:  0.7187947292484195\n",
      "mi F1:  0.7624599242203439\n",
      "we F1:  0.7453749477853233\n",
      "update!  Acc:  0.7624599242203439\n",
      "Eval Loss:  0.3379310667514801\n",
      "Eval Loss:  0.28359153866767883\n",
      "Eval Loss:  0.2543354332447052\n",
      "Eval Loss:  0.3618447184562683\n",
      "Eval Loss:  0.23281629383563995\n",
      "Eval Loss:  0.2546188533306122\n",
      "Eval Loss:  0.18585331737995148\n",
      "Eval Loss:  0.2507294714450836\n",
      "Eval Loss:  0.29944366216659546\n",
      "Eval Loss:  0.3588196337223053\n",
      "Eval Loss:  0.3572329878807068\n",
      "Eval Loss:  0.28301024436950684\n",
      "Eval Loss:  0.256254643201828\n",
      "Eval Loss:  0.20835748314857483\n",
      "Eval Loss:  0.23151689767837524\n",
      "Eval Loss:  0.24978549778461456\n",
      "Eval Loss:  0.24881410598754883\n",
      "Eval Loss:  0.29587504267692566\n",
      "Eval Loss:  0.2334679812192917\n",
      "Eval Loss:  0.3400978446006775\n",
      "Eval Loss:  0.1827842891216278\n",
      "Eval Loss:  0.29216814041137695\n",
      "Eval Loss:  0.22440193593502045\n",
      "Eval Loss:  0.18484124541282654\n",
      "Eval Loss:  0.1474398970603943\n",
      "Eval Loss:  0.33196431398391724\n",
      "Eval Loss:  0.1967494785785675\n",
      "Eval Loss:  0.316270649433136\n",
      "[[16899  1138]\n",
      " [ 2037  9386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     18037\n",
      "           1       0.89      0.82      0.86     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.88      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8922267481330618\n",
      "pre:  0.8918662105663246\n",
      "rec:  0.8216755668388339\n",
      "ma F1:  0.8847299138592182\n",
      "mi F1:  0.8922267481330619\n",
      "we F1:  0.8913296825118473\n",
      "29460 461\n",
      "Loss:  0.05117371305823326\n",
      "Loss:  0.06375602632761002\n",
      "Loss:  0.0824819877743721\n",
      "33 **********\n",
      "Epoch:  1858.4349234104156  fold:  7  kers:  32\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.05092455446720123\n",
      "Loss:  0.06956816464662552\n",
      "Loss:  0.08267556875944138\n",
      "34 **********\n",
      "Epoch:  1899.9708642959595  fold:  7  kers:  32\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.07410451024770737\n",
      "Loss:  0.050267208367586136\n",
      "Loss:  0.07710584253072739\n",
      "35 **********\n",
      "Epoch:  1941.5177762508392  fold:  7  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.7644585371017456\n",
      "Eval Loss:  0.13162861764431\n",
      "Eval Loss:  2.5328686237335205\n",
      "[[2009  118]\n",
      " [ 716  588]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83      2127\n",
      "           1       0.83      0.45      0.59      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.79      0.70      0.71      3431\n",
      "weighted avg       0.77      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7569221801224133\n",
      "pre:  0.8328611898016998\n",
      "rec:  0.450920245398773\n",
      "ma F1:  0.7065933727898019\n",
      "mi F1:  0.7569221801224133\n",
      "we F1:  0.7357422879444389\n",
      "Eval Loss:  0.3642699718475342\n",
      "Eval Loss:  0.2765212953090668\n",
      "Eval Loss:  0.2561662793159485\n",
      "Eval Loss:  0.37564435601234436\n",
      "Eval Loss:  0.2261570245027542\n",
      "Eval Loss:  0.2575872838497162\n",
      "Eval Loss:  0.2069714516401291\n",
      "Eval Loss:  0.24744866788387299\n",
      "Eval Loss:  0.3068227767944336\n",
      "Eval Loss:  0.35572537779808044\n",
      "Eval Loss:  0.36549195647239685\n",
      "Eval Loss:  0.2819395065307617\n",
      "Eval Loss:  0.2622932195663452\n",
      "Eval Loss:  0.1986856460571289\n",
      "Eval Loss:  0.23733001947402954\n",
      "Eval Loss:  0.24789373576641083\n",
      "Eval Loss:  0.2597588002681732\n",
      "Eval Loss:  0.32240355014801025\n",
      "Eval Loss:  0.23648643493652344\n",
      "Eval Loss:  0.33895692229270935\n",
      "Eval Loss:  0.1964709758758545\n",
      "Eval Loss:  0.2930004298686981\n",
      "Eval Loss:  0.2264414131641388\n",
      "Eval Loss:  0.1997905820608139\n",
      "Eval Loss:  0.14146585762500763\n",
      "Eval Loss:  0.3441808521747589\n",
      "Eval Loss:  0.2380986511707306\n",
      "Eval Loss:  0.3103153109550476\n",
      "[[17014  1023]\n",
      " [ 2257  9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18037\n",
      "           1       0.90      0.80      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8886625933469111\n",
      "pre:  0.8995976052605751\n",
      "rec:  0.8024161778867198\n",
      "ma F1:  0.8801578313800268\n",
      "mi F1:  0.8886625933469111\n",
      "we F1:  0.8873253257287745\n",
      "29460 461\n",
      "Loss:  0.08801894634962082\n",
      "Loss:  0.08240415155887604\n",
      "Loss:  0.059821657836437225\n",
      "36 **********\n",
      "Epoch:  2022.271856546402  fold:  7  kers:  32\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.061977315694093704\n",
      "Loss:  0.04953305795788765\n",
      "Loss:  0.06736139953136444\n",
      "37 **********\n",
      "Epoch:  2063.865642786026  fold:  7  kers:  32\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.05768788605928421\n",
      "Loss:  0.061470773071050644\n",
      "Loss:  0.05653474107384682\n",
      "38 **********\n",
      "Epoch:  2105.390613555908  fold:  7  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.8135733008384705\n",
      "Eval Loss:  0.10748607665300369\n",
      "Eval Loss:  2.640024185180664\n",
      "[[2012  115]\n",
      " [ 748  556]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82      2127\n",
      "           1       0.83      0.43      0.56      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.69      0.69      3431\n",
      "weighted avg       0.77      0.75      0.72      3431\n",
      "\n",
      "acc:  0.7484698338676771\n",
      "pre:  0.8286140089418778\n",
      "rec:  0.4263803680981595\n",
      "ma F1:  0.6932235095435318\n",
      "mi F1:  0.7484698338676772\n",
      "we F1:  0.7244513425921386\n",
      "Eval Loss:  0.36768582463264465\n",
      "Eval Loss:  0.30203112959861755\n",
      "Eval Loss:  0.2625873386859894\n",
      "Eval Loss:  0.38530057668685913\n",
      "Eval Loss:  0.2390964925289154\n",
      "Eval Loss:  0.2568153738975525\n",
      "Eval Loss:  0.2215525209903717\n",
      "Eval Loss:  0.2399439662694931\n",
      "Eval Loss:  0.30274730920791626\n",
      "Eval Loss:  0.36740824580192566\n",
      "Eval Loss:  0.3732515275478363\n",
      "Eval Loss:  0.29155728220939636\n",
      "Eval Loss:  0.2614908814430237\n",
      "Eval Loss:  0.2005884051322937\n",
      "Eval Loss:  0.24770542979240417\n",
      "Eval Loss:  0.24826784431934357\n",
      "Eval Loss:  0.2665693759918213\n",
      "Eval Loss:  0.34522753953933716\n",
      "Eval Loss:  0.2403101623058319\n",
      "Eval Loss:  0.342597097158432\n",
      "Eval Loss:  0.20828506350517273\n",
      "Eval Loss:  0.30118733644485474\n",
      "Eval Loss:  0.23677179217338562\n",
      "Eval Loss:  0.21023917198181152\n",
      "Eval Loss:  0.14715361595153809\n",
      "Eval Loss:  0.3486890494823456\n",
      "Eval Loss:  0.23333147168159485\n",
      "Eval Loss:  0.297353595495224\n",
      "[[17144   893]\n",
      " [ 2387  9036]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18037\n",
      "           1       0.91      0.79      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8886625933469111\n",
      "pre:  0.9100614361969986\n",
      "rec:  0.7910356298695614\n",
      "ma F1:  0.879538033054127\n",
      "mi F1:  0.8886625933469111\n",
      "we F1:  0.8869812794498442\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08013294637203217\n",
      "Loss:  0.06324027478694916\n",
      "Loss:  0.06352387368679047\n",
      "39 **********\n",
      "Epoch:  2186.312245607376  fold:  7  kers:  32\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.07085995376110077\n",
      "Loss:  0.07494685053825378\n",
      "Loss:  0.04478207975625992\n",
      "40 **********\n",
      "Epoch:  2227.8721227645874  fold:  7  kers:  32\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.06319631636142731\n",
      "Loss:  0.08240891993045807\n",
      "Loss:  0.06675117462873459\n",
      "41 **********\n",
      "Epoch:  2269.392106771469  fold:  7  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.7130804061889648\n",
      "Eval Loss:  0.16841652989387512\n",
      "Eval Loss:  2.278496503829956\n",
      "[[1959  168]\n",
      " [ 672  632]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82      2127\n",
      "           1       0.79      0.48      0.60      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.70      0.71      3431\n",
      "weighted avg       0.76      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7551734188283299\n",
      "pre:  0.79\n",
      "rec:  0.48466257668711654\n",
      "ma F1:  0.7121078447825315\n",
      "mi F1:  0.7551734188283299\n",
      "we F1:  0.7388169385577329\n",
      "Eval Loss:  0.3255191445350647\n",
      "Eval Loss:  0.25166139006614685\n",
      "Eval Loss:  0.26775938272476196\n",
      "Eval Loss:  0.3329322636127472\n",
      "Eval Loss:  0.19275839626789093\n",
      "Eval Loss:  0.2410605251789093\n",
      "Eval Loss:  0.19326549768447876\n",
      "Eval Loss:  0.25638365745544434\n",
      "Eval Loss:  0.2933218777179718\n",
      "Eval Loss:  0.3528195917606354\n",
      "Eval Loss:  0.3644622564315796\n",
      "Eval Loss:  0.27771955728530884\n",
      "Eval Loss:  0.2293192744255066\n",
      "Eval Loss:  0.21163223683834076\n",
      "Eval Loss:  0.22774720191955566\n",
      "Eval Loss:  0.23132625222206116\n",
      "Eval Loss:  0.2573932707309723\n",
      "Eval Loss:  0.2749987840652466\n",
      "Eval Loss:  0.2124406099319458\n",
      "Eval Loss:  0.3022122085094452\n",
      "Eval Loss:  0.20354358851909637\n",
      "Eval Loss:  0.291215717792511\n",
      "Eval Loss:  0.2164418250322342\n",
      "Eval Loss:  0.17819201946258545\n",
      "Eval Loss:  0.1349847912788391\n",
      "Eval Loss:  0.296756386756897\n",
      "Eval Loss:  0.20081359148025513\n",
      "Eval Loss:  0.29958808422088623\n",
      "[[16822  1215]\n",
      " [ 1875  9548]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     18037\n",
      "           1       0.89      0.84      0.86     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.89      0.88      0.89     29460\n",
      "weighted avg       0.89      0.90      0.89     29460\n",
      "\n",
      "acc:  0.895112016293279\n",
      "pre:  0.8871132583852086\n",
      "rec:  0.8358574805217543\n",
      "ma F1:  0.8883023614439159\n",
      "mi F1:  0.895112016293279\n",
      "we F1:  0.8944941482426083\n",
      "29460 461\n",
      "Loss:  0.08693321794271469\n",
      "Loss:  0.062496937811374664\n",
      "Loss:  0.06362669169902802\n",
      "42 **********\n",
      "Epoch:  2350.4224483966827  fold:  7  kers:  32\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.08431857079267502\n",
      "Loss:  0.06864508986473083\n",
      "Loss:  0.06504646688699722\n",
      "43 **********\n",
      "Epoch:  2391.950410604477  fold:  7  kers:  32\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.07418068498373032\n",
      "Loss:  0.062962107360363\n",
      "Loss:  0.0625467374920845\n",
      "44 **********\n",
      "Epoch:  2433.4544377326965  fold:  7  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.6803262233734131\n",
      "Eval Loss:  0.12744610011577606\n",
      "Eval Loss:  2.3641598224639893\n",
      "[[1998  129]\n",
      " [ 705  599]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83      2127\n",
      "           1       0.82      0.46      0.59      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.70      0.71      3431\n",
      "weighted avg       0.77      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7569221801224133\n",
      "pre:  0.8228021978021978\n",
      "rec:  0.4593558282208589\n",
      "ma F1:  0.708448060840221\n",
      "mi F1:  0.7569221801224133\n",
      "we F1:  0.7369642868368217\n",
      "Eval Loss:  0.3358037769794464\n",
      "Eval Loss:  0.24743115901947021\n",
      "Eval Loss:  0.2653053402900696\n",
      "Eval Loss:  0.34578222036361694\n",
      "Eval Loss:  0.1959289312362671\n",
      "Eval Loss:  0.2390802949666977\n",
      "Eval Loss:  0.1965223252773285\n",
      "Eval Loss:  0.24046380817890167\n",
      "Eval Loss:  0.2891483008861542\n",
      "Eval Loss:  0.35622942447662354\n",
      "Eval Loss:  0.36718684434890747\n",
      "Eval Loss:  0.27627742290496826\n",
      "Eval Loss:  0.23699480295181274\n",
      "Eval Loss:  0.2222258746623993\n",
      "Eval Loss:  0.22481119632720947\n",
      "Eval Loss:  0.22425220906734467\n",
      "Eval Loss:  0.254293829202652\n",
      "Eval Loss:  0.2977994382381439\n",
      "Eval Loss:  0.2250634878873825\n",
      "Eval Loss:  0.2950311601161957\n",
      "Eval Loss:  0.20871973037719727\n",
      "Eval Loss:  0.2904278337955475\n",
      "Eval Loss:  0.2146342247724533\n",
      "Eval Loss:  0.17938607931137085\n",
      "Eval Loss:  0.1382908970117569\n",
      "Eval Loss:  0.31534522771835327\n",
      "Eval Loss:  0.20975783467292786\n",
      "Eval Loss:  0.3087383210659027\n",
      "[[16953  1084]\n",
      " [ 1993  9430]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     18037\n",
      "           1       0.90      0.83      0.86     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.89     29460\n",
      "\n",
      "acc:  0.8955532926001358\n",
      "pre:  0.8968993722655507\n",
      "rec:  0.8255274446292568\n",
      "ma F1:  0.8882671527198855\n",
      "mi F1:  0.8955532926001358\n",
      "we F1:  0.8946729122796324\n",
      "29460 461\n",
      "Loss:  0.0644584447145462\n",
      "Loss:  0.09487859904766083\n",
      "Loss:  0.07907740026712418\n",
      "45 **********\n",
      "Epoch:  2514.4249391555786  fold:  7  kers:  32\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.05670159310102463\n",
      "Loss:  0.06954134255647659\n",
      "Loss:  0.06278517842292786\n",
      "46 **********\n",
      "Epoch:  2556.0087521076202  fold:  7  kers:  32\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.0928041860461235\n",
      "Loss:  0.07706468552350998\n",
      "Loss:  0.08121870458126068\n",
      "47 **********\n",
      "Epoch:  2597.6085228919983  fold:  7  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.6035148501396179\n",
      "Eval Loss:  0.2067594826221466\n",
      "Eval Loss:  2.17685604095459\n",
      "[[1958  169]\n",
      " [ 643  661]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83      2127\n",
      "           1       0.80      0.51      0.62      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.71      0.72      3431\n",
      "weighted avg       0.77      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7633343048673856\n",
      "pre:  0.7963855421686747\n",
      "rec:  0.5069018404907976\n",
      "ma F1:  0.7238755496775278\n",
      "mi F1:  0.7633343048673855\n",
      "we F1:  0.7489137574811153\n",
      "update!  Acc:  0.7633343048673856\n",
      "Eval Loss:  0.3159351348876953\n",
      "Eval Loss:  0.24462541937828064\n",
      "Eval Loss:  0.26980358362197876\n",
      "Eval Loss:  0.33620351552963257\n",
      "Eval Loss:  0.18716345727443695\n",
      "Eval Loss:  0.2463226169347763\n",
      "Eval Loss:  0.1765524297952652\n",
      "Eval Loss:  0.2542242407798767\n",
      "Eval Loss:  0.2911987006664276\n",
      "Eval Loss:  0.3527376055717468\n",
      "Eval Loss:  0.3603682518005371\n",
      "Eval Loss:  0.25874778628349304\n",
      "Eval Loss:  0.2407284826040268\n",
      "Eval Loss:  0.22042419016361237\n",
      "Eval Loss:  0.21966302394866943\n",
      "Eval Loss:  0.22801151871681213\n",
      "Eval Loss:  0.26491326093673706\n",
      "Eval Loss:  0.2879791557788849\n",
      "Eval Loss:  0.22995403409004211\n",
      "Eval Loss:  0.27874794602394104\n",
      "Eval Loss:  0.2133634239435196\n",
      "Eval Loss:  0.2992156744003296\n",
      "Eval Loss:  0.20747286081314087\n",
      "Eval Loss:  0.1653391420841217\n",
      "Eval Loss:  0.1303131878376007\n",
      "Eval Loss:  0.28918880224227905\n",
      "Eval Loss:  0.1908678114414215\n",
      "Eval Loss:  0.29844939708709717\n",
      "[[16723  1314]\n",
      " [ 1698  9725]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18037\n",
      "           1       0.88      0.85      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.89      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.8977596741344196\n",
      "pre:  0.8809674789383096\n",
      "rec:  0.8513525343605007\n",
      "ma F1:  0.8916456262209165\n",
      "mi F1:  0.8977596741344196\n",
      "we F1:  0.8974241790788628\n",
      "29460 461\n",
      "Loss:  0.05550232529640198\n",
      "Loss:  0.05936110019683838\n",
      "Loss:  0.04979752376675606\n",
      "48 **********\n",
      "Epoch:  2678.3795578479767  fold:  7  kers:  32\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.06344781070947647\n",
      "Loss:  0.06407837569713593\n",
      "Loss:  0.07970348745584488\n",
      "49 **********\n",
      "Epoch:  2719.798810482025  fold:  7  kers:  32\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.05630619451403618\n",
      "Loss:  0.07920552790164948\n",
      "Loss:  0.054447680711746216\n",
      "50 **********\n",
      "Epoch:  2761.286880016327  fold:  7  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.5694985389709473\n",
      "Eval Loss:  0.35504162311553955\n",
      "Eval Loss:  1.791494369506836\n",
      "[[1864  263]\n",
      " [ 553  751]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      2127\n",
      "           1       0.74      0.58      0.65      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.73      0.73      3431\n",
      "weighted avg       0.76      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7621684640046633\n",
      "pre:  0.7406311637080868\n",
      "rec:  0.575920245398773\n",
      "ma F1:  0.7341974626013197\n",
      "mi F1:  0.7621684640046633\n",
      "we F1:  0.7548804223092728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2858791649341583\n",
      "Eval Loss:  0.24184256792068481\n",
      "Eval Loss:  0.2634320557117462\n",
      "Eval Loss:  0.33060702681541443\n",
      "Eval Loss:  0.18354609608650208\n",
      "Eval Loss:  0.22905056178569794\n",
      "Eval Loss:  0.1824273318052292\n",
      "Eval Loss:  0.2577097415924072\n",
      "Eval Loss:  0.2794937789440155\n",
      "Eval Loss:  0.32758551836013794\n",
      "Eval Loss:  0.3460196256637573\n",
      "Eval Loss:  0.2612093985080719\n",
      "Eval Loss:  0.23194169998168945\n",
      "Eval Loss:  0.22635021805763245\n",
      "Eval Loss:  0.21598681807518005\n",
      "Eval Loss:  0.24033324420452118\n",
      "Eval Loss:  0.2564241588115692\n",
      "Eval Loss:  0.2678477466106415\n",
      "Eval Loss:  0.23400601744651794\n",
      "Eval Loss:  0.2589833736419678\n",
      "Eval Loss:  0.21310636401176453\n",
      "Eval Loss:  0.2967177927494049\n",
      "Eval Loss:  0.21168841421604156\n",
      "Eval Loss:  0.17495502531528473\n",
      "Eval Loss:  0.13890190422534943\n",
      "Eval Loss:  0.278775155544281\n",
      "Eval Loss:  0.1813036948442459\n",
      "Eval Loss:  0.2802686095237732\n",
      "[[16539  1498]\n",
      " [ 1471  9952]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     18037\n",
      "           1       0.87      0.87      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.89      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.8992192803801765\n",
      "pre:  0.8691703056768559\n",
      "rec:  0.8712247220520003\n",
      "ma F1:  0.8939158053865298\n",
      "mi F1:  0.8992192803801765\n",
      "we F1:  0.8992410192331943\n",
      "29460 461\n",
      "Loss:  0.05624532699584961\n",
      "Loss:  0.08542513102293015\n",
      "Loss:  0.09670307487249374\n",
      "51 **********\n",
      "Epoch:  2842.100800037384  fold:  7  kers:  32\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.05470796674489975\n",
      "Loss:  0.04703034460544586\n",
      "Loss:  0.05848893150687218\n",
      "52 **********\n",
      "Epoch:  2883.6896002292633  fold:  7  kers:  32\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.07564651966094971\n",
      "Loss:  0.04456494376063347\n",
      "Loss:  0.04381062462925911\n",
      "53 **********\n",
      "Epoch:  2925.206592321396  fold:  7  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.7318321466445923\n",
      "Eval Loss:  0.10121610760688782\n",
      "Eval Loss:  2.525562047958374\n",
      "[[2007  120]\n",
      " [ 721  583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83      2127\n",
      "           1       0.83      0.45      0.58      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.70      0.70      3431\n",
      "weighted avg       0.77      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7548819586126494\n",
      "pre:  0.829302987197724\n",
      "rec:  0.4470858895705521\n",
      "ma F1:  0.7038715679467897\n",
      "mi F1:  0.7548819586126494\n",
      "we F1:  0.7333529945746006\n",
      "Eval Loss:  0.3213644027709961\n",
      "Eval Loss:  0.2511364817619324\n",
      "Eval Loss:  0.24480053782463074\n",
      "Eval Loss:  0.36006706953048706\n",
      "Eval Loss:  0.1831800937652588\n",
      "Eval Loss:  0.22388887405395508\n",
      "Eval Loss:  0.17970174551010132\n",
      "Eval Loss:  0.23434515297412872\n",
      "Eval Loss:  0.2545393407344818\n",
      "Eval Loss:  0.3501192331314087\n",
      "Eval Loss:  0.36119887232780457\n",
      "Eval Loss:  0.2747901976108551\n",
      "Eval Loss:  0.21895991265773773\n",
      "Eval Loss:  0.1981232911348343\n",
      "Eval Loss:  0.218190535902977\n",
      "Eval Loss:  0.2224455624818802\n",
      "Eval Loss:  0.2628476917743683\n",
      "Eval Loss:  0.2981702983379364\n",
      "Eval Loss:  0.22669103741645813\n",
      "Eval Loss:  0.2799426317214966\n",
      "Eval Loss:  0.19951553642749786\n",
      "Eval Loss:  0.2864799201488495\n",
      "Eval Loss:  0.2065688669681549\n",
      "Eval Loss:  0.18917298316955566\n",
      "Eval Loss:  0.1444007158279419\n",
      "Eval Loss:  0.3080512285232544\n",
      "Eval Loss:  0.1817079782485962\n",
      "Eval Loss:  0.25711363554000854\n",
      "[[17115   922]\n",
      " [ 2025  9398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18037\n",
      "           1       0.91      0.82      0.86     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.8999660556687034\n",
      "pre:  0.9106589147286822\n",
      "rec:  0.8227260789634947\n",
      "ma F1:  0.892596342479169\n",
      "mi F1:  0.8999660556687034\n",
      "we F1:  0.8989126937860993\n",
      "29460 461\n",
      "Loss:  0.0963490828871727\n",
      "Loss:  0.06434406340122223\n",
      "Loss:  0.033928267657756805\n",
      "54 **********\n",
      "Epoch:  3005.9397282600403  fold:  7  kers:  32\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.08539154380559921\n",
      "Loss:  0.07947798073291779\n",
      "Loss:  0.07874225080013275\n",
      "55 **********\n",
      "Epoch:  3047.363968372345  fold:  7  kers:  32\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.07942560315132141\n",
      "Loss:  0.05162227526307106\n",
      "Loss:  0.05115266144275665\n",
      "56 **********\n",
      "Epoch:  3088.8520374298096  fold:  7  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.5752413272857666\n",
      "Eval Loss:  0.14082273840904236\n",
      "Eval Loss:  2.194009304046631\n",
      "[[1993  134]\n",
      " [ 647  657]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.84      2127\n",
      "           1       0.83      0.50      0.63      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.72      0.73      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.772369571553483\n",
      "pre:  0.8305941845764855\n",
      "rec:  0.5038343558282209\n",
      "ma F1:  0.7316864701785796\n",
      "mi F1:  0.772369571553483\n",
      "we F1:  0.7567479914596765\n",
      "update!  Acc:  0.772369571553483\n",
      "Eval Loss:  0.3013112545013428\n",
      "Eval Loss:  0.2601333260536194\n",
      "Eval Loss:  0.26106101274490356\n",
      "Eval Loss:  0.34068015217781067\n",
      "Eval Loss:  0.18779398500919342\n",
      "Eval Loss:  0.22734622657299042\n",
      "Eval Loss:  0.1672912985086441\n",
      "Eval Loss:  0.23223896324634552\n",
      "Eval Loss:  0.2606235146522522\n",
      "Eval Loss:  0.34390074014663696\n",
      "Eval Loss:  0.35667359828948975\n",
      "Eval Loss:  0.2561419606208801\n",
      "Eval Loss:  0.2215769737958908\n",
      "Eval Loss:  0.19310949742794037\n",
      "Eval Loss:  0.1975487619638443\n",
      "Eval Loss:  0.2241961658000946\n",
      "Eval Loss:  0.2724776864051819\n",
      "Eval Loss:  0.28645578026771545\n",
      "Eval Loss:  0.24935314059257507\n",
      "Eval Loss:  0.27676528692245483\n",
      "Eval Loss:  0.2004546970129013\n",
      "Eval Loss:  0.2942521274089813\n",
      "Eval Loss:  0.19750601053237915\n",
      "Eval Loss:  0.1574554145336151\n",
      "Eval Loss:  0.1366037279367447\n",
      "Eval Loss:  0.2779543995857239\n",
      "Eval Loss:  0.16653911769390106\n",
      "Eval Loss:  0.28306058049201965\n",
      "[[16869  1168]\n",
      " [ 1736  9687]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     18037\n",
      "           1       0.89      0.85      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.90     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9014256619144603\n",
      "pre:  0.8923998157531091\n",
      "rec:  0.8480259126324083\n",
      "ma F1:  0.895196934848598\n",
      "mi F1:  0.9014256619144603\n",
      "we F1:  0.9009330530348433\n",
      "29460 461\n",
      "Loss:  0.07223370671272278\n",
      "Loss:  0.08519212901592255\n",
      "Loss:  0.07813546061515808\n",
      "57 **********\n",
      "Epoch:  3169.872405767441  fold:  7  kers:  32\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.09431848675012589\n",
      "Loss:  0.05576809495687485\n",
      "Loss:  0.043198004364967346\n",
      "58 **********\n",
      "Epoch:  3211.2796907424927  fold:  7  kers:  32\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.08462730795145035\n",
      "Loss:  0.04922252893447876\n",
      "Loss:  0.06041695177555084\n",
      "59 **********\n",
      "Epoch:  3252.7747416496277  fold:  7  kers:  32\n",
      "Eval Loss:  0.7382644414901733\n",
      "Eval Loss:  0.13311637938022614\n",
      "Eval Loss:  2.3353347778320312\n",
      "[[1985  142]\n",
      " [ 677  627]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      2127\n",
      "           1       0.82      0.48      0.60      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.71      0.72      3431\n",
      "weighted avg       0.77      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7612940833576217\n",
      "pre:  0.8153446033810143\n",
      "rec:  0.4808282208588957\n",
      "ma F1:  0.7169517457245695\n",
      "mi F1:  0.7612940833576217\n",
      "we F1:  0.74382490026949\n",
      "update!  Acc:  0.772369571553483\n",
      "Epoch:  3256.8737819194794  fold:  7  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29817 3074\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29817 466\n",
      "Loss:  0.17328748106956482\n",
      "Loss:  0.16733957827091217\n",
      "Loss:  0.15674114227294922\n",
      "0 **********\n",
      "Epoch:  54.465370416641235  fold:  8  kers:  32\n",
      "epoch:  1\n",
      "29817 466\n",
      "Loss:  0.1297791749238968\n",
      "Loss:  0.1225755512714386\n",
      "Loss:  0.11262357980012894\n",
      "1 **********\n",
      "Epoch:  96.67251682281494  fold:  8  kers:  32\n",
      "epoch:  2\n",
      "29817 466\n",
      "Loss:  0.11420325934886932\n",
      "Loss:  0.09987316280603409\n",
      "Loss:  0.11244233697652817\n",
      "2 **********\n",
      "Epoch:  138.78990387916565  fold:  8  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.29717111587524414\n",
      "Eval Loss:  0.9540808200836182\n",
      "Eval Loss:  0.23537397384643555\n",
      "[[1890  183]\n",
      " [ 383  618]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      2073\n",
      "           1       0.77      0.62      0.69      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.80      0.76      0.78      3074\n",
      "weighted avg       0.81      0.82      0.81      3074\n",
      "\n",
      "acc:  0.8158750813272609\n",
      "pre:  0.7715355805243446\n",
      "rec:  0.6173826173826173\n",
      "ma F1:  0.7778349259630222\n",
      "mi F1:  0.8158750813272609\n",
      "we F1:  0.8098939248234499\n",
      "update!  Acc:  0.8158750813272609\n",
      "Eval Loss:  0.45191285014152527\n",
      "Eval Loss:  0.4231925308704376\n",
      "Eval Loss:  0.40725839138031006\n",
      "Eval Loss:  0.36414989829063416\n",
      "Eval Loss:  0.4531886577606201\n",
      "Eval Loss:  0.4068681001663208\n",
      "Eval Loss:  0.3714611828327179\n",
      "Eval Loss:  0.4192965626716614\n",
      "Eval Loss:  0.4951098561286926\n",
      "Eval Loss:  0.3715590834617615\n",
      "Eval Loss:  0.41888439655303955\n",
      "Eval Loss:  0.5055367350578308\n",
      "Eval Loss:  0.47539180517196655\n",
      "Eval Loss:  0.4201788306236267\n",
      "Eval Loss:  0.4447493255138397\n",
      "Eval Loss:  0.47860482335090637\n",
      "Eval Loss:  0.40367382764816284\n",
      "Eval Loss:  0.3851297199726105\n",
      "Eval Loss:  0.3798964023590088\n",
      "Eval Loss:  0.4793815612792969\n",
      "Eval Loss:  0.4249618351459503\n",
      "Eval Loss:  0.4816143214702606\n",
      "Eval Loss:  0.45330914855003357\n",
      "Eval Loss:  0.38756048679351807\n",
      "Eval Loss:  0.4255897104740143\n",
      "Eval Loss:  0.3369307816028595\n",
      "Eval Loss:  0.43605098128318787\n",
      "Eval Loss:  0.36599457263946533\n",
      "Eval Loss:  0.45296749472618103\n",
      "[[15759  2332]\n",
      " [ 3112  8614]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85     18091\n",
      "           1       0.79      0.73      0.76     11726\n",
      "\n",
      "    accuracy                           0.82     29817\n",
      "   macro avg       0.81      0.80      0.81     29817\n",
      "weighted avg       0.82      0.82      0.82     29817\n",
      "\n",
      "acc:  0.8174195928497167\n",
      "pre:  0.7869541384980815\n",
      "rec:  0.7346068565580761\n",
      "ma F1:  0.8062968129888459\n",
      "mi F1:  0.8174195928497167\n",
      "we F1:  0.8162053495618959\n",
      "29817 466\n",
      "Loss:  0.10079705715179443\n",
      "Loss:  0.10437856614589691\n",
      "Loss:  0.10385292023420334\n",
      "3 **********\n",
      "Epoch:  220.36678338050842  fold:  8  kers:  32\n",
      "epoch:  4\n",
      "29817 466\n",
      "Loss:  0.07553016394376755\n",
      "Loss:  0.08746392279863358\n",
      "Loss:  0.10090290009975433\n",
      "4 **********\n",
      "Epoch:  262.5300476551056  fold:  8  kers:  32\n",
      "epoch:  5\n",
      "29817 466\n",
      "Loss:  0.09142395853996277\n",
      "Loss:  0.10203296691179276\n",
      "Loss:  0.0984201654791832\n",
      "5 **********\n",
      "Epoch:  306.06265091896057  fold:  8  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.3432401716709137\n",
      "Eval Loss:  1.078125\n",
      "Eval Loss:  0.2759127914905548\n",
      "[[1898  175]\n",
      " [ 321  680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.88      2073\n",
      "           1       0.80      0.68      0.73      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.83      0.80      0.81      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8386467143786597\n",
      "pre:  0.7953216374269005\n",
      "rec:  0.6793206793206793\n",
      "ma F1:  0.8085973904939421\n",
      "mi F1:  0.8386467143786597\n",
      "we F1:  0.8350447428785212\n",
      "update!  Acc:  0.8386467143786597\n",
      "Eval Loss:  0.3892260491847992\n",
      "Eval Loss:  0.3836168944835663\n",
      "Eval Loss:  0.3277818262577057\n",
      "Eval Loss:  0.30021393299102783\n",
      "Eval Loss:  0.3827545642852783\n",
      "Eval Loss:  0.3271630108356476\n",
      "Eval Loss:  0.34312769770622253\n",
      "Eval Loss:  0.33828017115592957\n",
      "Eval Loss:  0.3915831744670868\n",
      "Eval Loss:  0.2831723690032959\n",
      "Eval Loss:  0.33488816022872925\n",
      "Eval Loss:  0.42635318636894226\n",
      "Eval Loss:  0.39568695425987244\n",
      "Eval Loss:  0.3465239107608795\n",
      "Eval Loss:  0.3093203604221344\n",
      "Eval Loss:  0.3299148976802826\n",
      "Eval Loss:  0.36202770471572876\n",
      "Eval Loss:  0.3694888651371002\n",
      "Eval Loss:  0.3686208128929138\n",
      "Eval Loss:  0.39830315113067627\n",
      "Eval Loss:  0.3444339334964752\n",
      "Eval Loss:  0.4128758907318115\n",
      "Eval Loss:  0.3923787474632263\n",
      "Eval Loss:  0.2850337028503418\n",
      "Eval Loss:  0.3416963517665863\n",
      "Eval Loss:  0.33462125062942505\n",
      "Eval Loss:  0.3122624456882477\n",
      "Eval Loss:  0.3249439597129822\n",
      "Eval Loss:  0.3642127215862274\n",
      "[[15945  2146]\n",
      " [ 2374  9352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88     18091\n",
      "           1       0.81      0.80      0.81     11726\n",
      "\n",
      "    accuracy                           0.85     29817\n",
      "   macro avg       0.84      0.84      0.84     29817\n",
      "weighted avg       0.85      0.85      0.85     29817\n",
      "\n",
      "acc:  0.8484086259516384\n",
      "pre:  0.8133588450165247\n",
      "rec:  0.797543919495139\n",
      "ma F1:  0.8406160159919425\n",
      "mi F1:  0.8484086259516384\n",
      "we F1:  0.8481391408809862\n",
      "29817 466\n",
      "Loss:  0.11051212251186371\n",
      "Loss:  0.10588762164115906\n",
      "Loss:  0.09545840322971344\n",
      "6 **********\n",
      "Epoch:  387.6445174217224  fold:  8  kers:  32\n",
      "epoch:  7\n",
      "29817 466\n",
      "Loss:  0.11529632657766342\n",
      "Loss:  0.08438773453235626\n",
      "Loss:  0.08401221036911011\n",
      "7 **********\n",
      "Epoch:  429.5245382785797  fold:  8  kers:  32\n",
      "epoch:  8\n",
      "29817 466\n",
      "Loss:  0.10002235323190689\n",
      "Loss:  0.1097414642572403\n",
      "Loss:  0.06983625143766403\n",
      "8 **********\n",
      "Epoch:  471.64092779159546  fold:  8  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.2873101830482483\n",
      "Eval Loss:  1.6124347448349\n",
      "Eval Loss:  0.16673408448696136\n",
      "[[1967  106]\n",
      " [ 463  538]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87      2073\n",
      "           1       0.84      0.54      0.65      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.82      0.74      0.76      3074\n",
      "weighted avg       0.82      0.81      0.80      3074\n",
      "\n",
      "acc:  0.8148991541964866\n",
      "pre:  0.8354037267080745\n",
      "rec:  0.5374625374625375\n",
      "ma F1:  0.7638715695784033\n",
      "mi F1:  0.8148991541964866\n",
      "we F1:  0.8021511851911292\n",
      "Eval Loss:  0.3847103416919708\n",
      "Eval Loss:  0.3479960560798645\n",
      "Eval Loss:  0.3469378650188446\n",
      "Eval Loss:  0.33617860078811646\n",
      "Eval Loss:  0.34272754192352295\n",
      "Eval Loss:  0.3424883782863617\n",
      "Eval Loss:  0.36240705847740173\n",
      "Eval Loss:  0.3480982184410095\n",
      "Eval Loss:  0.42423108220100403\n",
      "Eval Loss:  0.31240683794021606\n",
      "Eval Loss:  0.3700728714466095\n",
      "Eval Loss:  0.44267767667770386\n",
      "Eval Loss:  0.4021661579608917\n",
      "Eval Loss:  0.39773285388946533\n",
      "Eval Loss:  0.3347870707511902\n",
      "Eval Loss:  0.329507052898407\n",
      "Eval Loss:  0.3496401607990265\n",
      "Eval Loss:  0.3685199022293091\n",
      "Eval Loss:  0.3687845468521118\n",
      "Eval Loss:  0.4187452793121338\n",
      "Eval Loss:  0.29752156138420105\n",
      "Eval Loss:  0.42643603682518005\n",
      "Eval Loss:  0.4122934341430664\n",
      "Eval Loss:  0.26476654410362244\n",
      "Eval Loss:  0.35104626417160034\n",
      "Eval Loss:  0.38024622201919556\n",
      "Eval Loss:  0.2918547987937927\n",
      "Eval Loss:  0.35439372062683105\n",
      "Eval Loss:  0.3475310802459717\n",
      "[[16901  1190]\n",
      " [ 3084  8642]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     18091\n",
      "           1       0.88      0.74      0.80     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.86      0.84      0.84     29817\n",
      "weighted avg       0.86      0.86      0.85     29817\n",
      "\n",
      "acc:  0.8566589529463058\n",
      "pre:  0.878966639544345\n",
      "rec:  0.7369947126044687\n",
      "ma F1:  0.8447474731349407\n",
      "mi F1:  0.8566589529463058\n",
      "we F1:  0.8539273458797451\n",
      "29817 466\n",
      "Loss:  0.064162977039814\n",
      "Loss:  0.07697644829750061\n",
      "Loss:  0.07379458099603653\n",
      "9 **********\n",
      "Epoch:  552.9794449806213  fold:  8  kers:  32\n",
      "epoch:  10\n",
      "29817 466\n",
      "Loss:  0.06510018557310104\n",
      "Loss:  0.12857511639595032\n",
      "Loss:  0.08132629841566086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 **********\n",
      "Epoch:  594.8923783302307  fold:  8  kers:  32\n",
      "epoch:  11\n",
      "29817 466\n",
      "Loss:  0.0928303524851799\n",
      "Loss:  0.07674864679574966\n",
      "Loss:  0.07617046684026718\n",
      "11 **********\n",
      "Epoch:  636.5539836883545  fold:  8  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.32926735281944275\n",
      "Eval Loss:  1.4956414699554443\n",
      "Eval Loss:  0.21012981235980988\n",
      "[[1910  163]\n",
      " [ 386  615]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      2073\n",
      "           1       0.79      0.61      0.69      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.81      0.77      0.78      3074\n",
      "weighted avg       0.82      0.82      0.81      3074\n",
      "\n",
      "acc:  0.8214053350683149\n",
      "pre:  0.7904884318766067\n",
      "rec:  0.6143856143856143\n",
      "ma F1:  0.7828708087062883\n",
      "mi F1:  0.8214053350683149\n",
      "we F1:  0.8147696598723828\n",
      "Eval Loss:  0.3322938084602356\n",
      "Eval Loss:  0.31653451919555664\n",
      "Eval Loss:  0.2965908646583557\n",
      "Eval Loss:  0.31655895709991455\n",
      "Eval Loss:  0.3353702425956726\n",
      "Eval Loss:  0.3075982630252838\n",
      "Eval Loss:  0.31324782967567444\n",
      "Eval Loss:  0.3081073760986328\n",
      "Eval Loss:  0.3807932138442993\n",
      "Eval Loss:  0.25730377435684204\n",
      "Eval Loss:  0.30289551615715027\n",
      "Eval Loss:  0.3695380985736847\n",
      "Eval Loss:  0.3377574682235718\n",
      "Eval Loss:  0.34438949823379517\n",
      "Eval Loss:  0.28528866171836853\n",
      "Eval Loss:  0.24777980148792267\n",
      "Eval Loss:  0.3186870515346527\n",
      "Eval Loss:  0.3443197011947632\n",
      "Eval Loss:  0.34600597620010376\n",
      "Eval Loss:  0.3783489465713501\n",
      "Eval Loss:  0.26108720898628235\n",
      "Eval Loss:  0.37976884841918945\n",
      "Eval Loss:  0.3822059631347656\n",
      "Eval Loss:  0.22201873362064362\n",
      "Eval Loss:  0.32074615359306335\n",
      "Eval Loss:  0.36692118644714355\n",
      "Eval Loss:  0.24473878741264343\n",
      "Eval Loss:  0.33963871002197266\n",
      "Eval Loss:  0.30344998836517334\n",
      "[[16530  1561]\n",
      " [ 2380  9346]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89     18091\n",
      "           1       0.86      0.80      0.83     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.87      0.86      0.86     29817\n",
      "weighted avg       0.87      0.87      0.87     29817\n",
      "\n",
      "acc:  0.8678270785122582\n",
      "pre:  0.8568809021729165\n",
      "rec:  0.7970322360566263\n",
      "ma F1:  0.859681544680154\n",
      "mi F1:  0.8678270785122582\n",
      "we F1:  0.8668984604431472\n",
      "29817 466\n",
      "Loss:  0.10762900114059448\n",
      "Loss:  0.11159615963697433\n",
      "Loss:  0.0646728053689003\n",
      "12 **********\n",
      "Epoch:  717.4227573871613  fold:  8  kers:  32\n",
      "epoch:  13\n",
      "29817 466\n",
      "Loss:  0.1008995994925499\n",
      "Loss:  0.09905315190553665\n",
      "Loss:  0.11216630786657333\n",
      "13 **********\n",
      "Epoch:  759.1581649780273  fold:  8  kers:  32\n",
      "epoch:  14\n",
      "29817 466\n",
      "Loss:  0.07061320543289185\n",
      "Loss:  0.07287672162055969\n",
      "Loss:  0.0768924355506897\n",
      "14 **********\n",
      "Epoch:  804.6914184093475  fold:  8  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.27587419748306274\n",
      "Eval Loss:  1.8867095708847046\n",
      "Eval Loss:  0.14022387564182281\n",
      "[[1981   92]\n",
      " [ 499  502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87      2073\n",
      "           1       0.85      0.50      0.63      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.82      0.73      0.75      3074\n",
      "weighted avg       0.81      0.81      0.79      3074\n",
      "\n",
      "acc:  0.8077423552374756\n",
      "pre:  0.8451178451178452\n",
      "rec:  0.5014985014985015\n",
      "ma F1:  0.7498312800750753\n",
      "mi F1:  0.8077423552374756\n",
      "we F1:  0.7918060417884581\n",
      "Eval Loss:  0.36040380597114563\n",
      "Eval Loss:  0.3191865384578705\n",
      "Eval Loss:  0.32289156317710876\n",
      "Eval Loss:  0.3498031198978424\n",
      "Eval Loss:  0.3332298696041107\n",
      "Eval Loss:  0.3402572572231293\n",
      "Eval Loss:  0.3591039180755615\n",
      "Eval Loss:  0.337217777967453\n",
      "Eval Loss:  0.410996675491333\n",
      "Eval Loss:  0.29316893219947815\n",
      "Eval Loss:  0.34796884655952454\n",
      "Eval Loss:  0.39485886693000793\n",
      "Eval Loss:  0.38888028264045715\n",
      "Eval Loss:  0.403760701417923\n",
      "Eval Loss:  0.33847832679748535\n",
      "Eval Loss:  0.29835739731788635\n",
      "Eval Loss:  0.33783936500549316\n",
      "Eval Loss:  0.3563675582408905\n",
      "Eval Loss:  0.35245662927627563\n",
      "Eval Loss:  0.3927924931049347\n",
      "Eval Loss:  0.24087263643741608\n",
      "Eval Loss:  0.41512107849121094\n",
      "Eval Loss:  0.3928801119327545\n",
      "Eval Loss:  0.2338341921567917\n",
      "Eval Loss:  0.3511514365673065\n",
      "Eval Loss:  0.4033021628856659\n",
      "Eval Loss:  0.27336838841438293\n",
      "Eval Loss:  0.367592453956604\n",
      "Eval Loss:  0.3054603636264801\n",
      "[[17197   894]\n",
      " [ 3217  8509]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18091\n",
      "           1       0.90      0.73      0.81     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.87      0.84      0.85     29817\n",
      "weighted avg       0.87      0.86      0.86     29817\n",
      "\n",
      "acc:  0.8621256330281383\n",
      "pre:  0.904923960438158\n",
      "rec:  0.7256523963841037\n",
      "ma F1:  0.8493339677945833\n",
      "mi F1:  0.8621256330281384\n",
      "we F1:  0.8587053938088074\n",
      "29817 466\n",
      "Loss:  0.10411030054092407\n",
      "Loss:  0.09748416393995285\n",
      "Loss:  0.08112216740846634\n",
      "15 **********\n",
      "Epoch:  885.7686338424683  fold:  8  kers:  32\n",
      "epoch:  16\n",
      "29817 466\n",
      "Loss:  0.10782752931118011\n",
      "Loss:  0.0940207839012146\n",
      "Loss:  0.08656725287437439\n",
      "16 **********\n",
      "Epoch:  927.6366872787476  fold:  8  kers:  32\n",
      "epoch:  17\n",
      "29817 466\n",
      "Loss:  0.06803188472986221\n",
      "Loss:  0.08583655953407288\n",
      "Loss:  0.064000204205513\n",
      "17 **********\n",
      "Epoch:  969.5865225791931  fold:  8  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.21231789886951447\n",
      "Eval Loss:  2.0921168327331543\n",
      "Eval Loss:  0.11084097623825073\n",
      "[[2021   52]\n",
      " [ 584  417]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86      2073\n",
      "           1       0.89      0.42      0.57      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.83      0.70      0.72      3074\n",
      "weighted avg       0.81      0.79      0.77      3074\n",
      "\n",
      "acc:  0.7931034482758621\n",
      "pre:  0.8891257995735607\n",
      "rec:  0.4165834165834166\n",
      "ma F1:  0.7156957011107136\n",
      "mi F1:  0.7931034482758621\n",
      "we F1:  0.7674295570714611\n",
      "Eval Loss:  0.38488224148750305\n",
      "Eval Loss:  0.33322131633758545\n",
      "Eval Loss:  0.375081866979599\n",
      "Eval Loss:  0.40197500586509705\n",
      "Eval Loss:  0.35167762637138367\n",
      "Eval Loss:  0.3805471360683441\n",
      "Eval Loss:  0.4049525260925293\n",
      "Eval Loss:  0.3712765574455261\n",
      "Eval Loss:  0.4562799632549286\n",
      "Eval Loss:  0.35178348422050476\n",
      "Eval Loss:  0.39614543318748474\n",
      "Eval Loss:  0.41821417212486267\n",
      "Eval Loss:  0.4254942238330841\n",
      "Eval Loss:  0.4348197281360626\n",
      "Eval Loss:  0.3803766667842865\n",
      "Eval Loss:  0.34461912512779236\n",
      "Eval Loss:  0.3540191650390625\n",
      "Eval Loss:  0.3815971910953522\n",
      "Eval Loss:  0.3662242889404297\n",
      "Eval Loss:  0.43715372681617737\n",
      "Eval Loss:  0.2628946900367737\n",
      "Eval Loss:  0.44907882809638977\n",
      "Eval Loss:  0.40809768438339233\n",
      "Eval Loss:  0.26201871037483215\n",
      "Eval Loss:  0.40388214588165283\n",
      "Eval Loss:  0.4328727424144745\n",
      "Eval Loss:  0.31196558475494385\n",
      "Eval Loss:  0.3926983177661896\n",
      "Eval Loss:  0.3435499370098114\n",
      "[[17478   613]\n",
      " [ 3851  7875]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     18091\n",
      "           1       0.93      0.67      0.78     11726\n",
      "\n",
      "    accuracy                           0.85     29817\n",
      "   macro avg       0.87      0.82      0.83     29817\n",
      "weighted avg       0.86      0.85      0.84     29817\n",
      "\n",
      "acc:  0.8502867491699366\n",
      "pre:  0.9277803958529689\n",
      "rec:  0.6715845130479277\n",
      "ma F1:  0.8329604736172271\n",
      "mi F1:  0.8502867491699367\n",
      "we F1:  0.8444445664937236\n",
      "29817 466\n",
      "Loss:  0.05935870110988617\n",
      "Loss:  0.07157936692237854\n",
      "Loss:  0.07858078181743622\n",
      "18 **********\n",
      "Epoch:  1050.670719385147  fold:  8  kers:  32\n",
      "epoch:  19\n",
      "29817 466\n",
      "Loss:  0.06301853805780411\n",
      "Loss:  0.09755095839500427\n",
      "Loss:  0.07743675261735916\n",
      "19 **********\n",
      "Epoch:  1092.4849169254303  fold:  8  kers:  32\n",
      "epoch:  20\n",
      "29817 466\n",
      "Loss:  0.09541218727827072\n",
      "Loss:  0.06741389632225037\n",
      "Loss:  0.07661125808954239\n",
      "20 **********\n",
      "Epoch:  1134.2691941261292  fold:  8  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.30918020009994507\n",
      "Eval Loss:  1.8388020992279053\n",
      "Eval Loss:  0.12584039568901062\n",
      "[[1919  154]\n",
      " [ 475  526]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      2073\n",
      "           1       0.77      0.53      0.63      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.79      0.73      0.74      3074\n",
      "weighted avg       0.79      0.80      0.78      3074\n",
      "\n",
      "acc:  0.7953806115810019\n",
      "pre:  0.7735294117647059\n",
      "rec:  0.5254745254745254\n",
      "ma F1:  0.7425037891060986\n",
      "mi F1:  0.7953806115810019\n",
      "we F1:  0.78319578745003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.314534068107605\n",
      "Eval Loss:  0.29543474316596985\n",
      "Eval Loss:  0.2915131747722626\n",
      "Eval Loss:  0.3354550302028656\n",
      "Eval Loss:  0.3269769549369812\n",
      "Eval Loss:  0.3042224049568176\n",
      "Eval Loss:  0.336342453956604\n",
      "Eval Loss:  0.31057125329971313\n",
      "Eval Loss:  0.3817562460899353\n",
      "Eval Loss:  0.286896288394928\n",
      "Eval Loss:  0.32657745480537415\n",
      "Eval Loss:  0.35565653443336487\n",
      "Eval Loss:  0.3582260310649872\n",
      "Eval Loss:  0.3730546534061432\n",
      "Eval Loss:  0.30511757731437683\n",
      "Eval Loss:  0.2677699327468872\n",
      "Eval Loss:  0.3225760757923126\n",
      "Eval Loss:  0.33955246210098267\n",
      "Eval Loss:  0.3409830927848816\n",
      "Eval Loss:  0.36014795303344727\n",
      "Eval Loss:  0.20830073952674866\n",
      "Eval Loss:  0.3881836533546448\n",
      "Eval Loss:  0.3514789044857025\n",
      "Eval Loss:  0.20315277576446533\n",
      "Eval Loss:  0.3294191062450409\n",
      "Eval Loss:  0.3933559060096741\n",
      "Eval Loss:  0.24976643919944763\n",
      "Eval Loss:  0.3631143271923065\n",
      "Eval Loss:  0.27735278010368347\n",
      "[[17201   890]\n",
      " [ 2974  8752]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     18091\n",
      "           1       0.91      0.75      0.82     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.88      0.85      0.86     29817\n",
      "weighted avg       0.87      0.87      0.87     29817\n",
      "\n",
      "acc:  0.8704094979374183\n",
      "pre:  0.9076954988591579\n",
      "rec:  0.7463755756438684\n",
      "ma F1:  0.8590957408370181\n",
      "mi F1:  0.8704094979374183\n",
      "we F1:  0.8676188872382546\n",
      "29817 466\n",
      "Loss:  0.06401701271533966\n",
      "Loss:  0.07746057212352753\n",
      "Loss:  0.08372177183628082\n",
      "21 **********\n",
      "Epoch:  1215.3075160980225  fold:  8  kers:  32\n",
      "epoch:  22\n",
      "29817 466\n",
      "Loss:  0.1047479584813118\n",
      "Loss:  0.11454378068447113\n",
      "Loss:  0.08951502293348312\n",
      "22 **********\n",
      "Epoch:  1256.962138414383  fold:  8  kers:  32\n",
      "epoch:  23\n",
      "29817 466\n",
      "Loss:  0.09266716241836548\n",
      "Loss:  0.07446673512458801\n",
      "Loss:  0.09244874119758606\n",
      "23 **********\n",
      "Epoch:  1298.7055246829987  fold:  8  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.34576547145843506\n",
      "Eval Loss:  1.7093610763549805\n",
      "Eval Loss:  0.12745924293994904\n",
      "[[1850  223]\n",
      " [ 454  547]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.85      2073\n",
      "           1       0.71      0.55      0.62      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.76      0.72      0.73      3074\n",
      "weighted avg       0.77      0.78      0.77      3074\n",
      "\n",
      "acc:  0.7797657774886142\n",
      "pre:  0.7103896103896103\n",
      "rec:  0.5464535464535465\n",
      "ma F1:  0.7315289730583112\n",
      "mi F1:  0.7797657774886142\n",
      "we F1:  0.771214202796826\n",
      "Eval Loss:  0.2827363908290863\n",
      "Eval Loss:  0.2806848883628845\n",
      "Eval Loss:  0.2691205143928528\n",
      "Eval Loss:  0.3324444890022278\n",
      "Eval Loss:  0.3150414824485779\n",
      "Eval Loss:  0.3002888262271881\n",
      "Eval Loss:  0.29346251487731934\n",
      "Eval Loss:  0.28781312704086304\n",
      "Eval Loss:  0.35291093587875366\n",
      "Eval Loss:  0.2641943395137787\n",
      "Eval Loss:  0.30003222823143005\n",
      "Eval Loss:  0.324674516916275\n",
      "Eval Loss:  0.30311375856399536\n",
      "Eval Loss:  0.3531486690044403\n",
      "Eval Loss:  0.27689915895462036\n",
      "Eval Loss:  0.22760668396949768\n",
      "Eval Loss:  0.30331137776374817\n",
      "Eval Loss:  0.31881314516067505\n",
      "Eval Loss:  0.3209938406944275\n",
      "Eval Loss:  0.3596373200416565\n",
      "Eval Loss:  0.195982426404953\n",
      "Eval Loss:  0.36062490940093994\n",
      "Eval Loss:  0.34199732542037964\n",
      "Eval Loss:  0.18547210097312927\n",
      "Eval Loss:  0.30379486083984375\n",
      "Eval Loss:  0.3740871548652649\n",
      "Eval Loss:  0.23427660763263702\n",
      "Eval Loss:  0.34134748578071594\n",
      "Eval Loss:  0.264478474855423\n",
      "[[17130   961]\n",
      " [ 2718  9008]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18091\n",
      "           1       0.90      0.77      0.83     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.88      0.86      0.87     29817\n",
      "weighted avg       0.88      0.88      0.87     29817\n",
      "\n",
      "acc:  0.8766140121407251\n",
      "pre:  0.9036011636071822\n",
      "rec:  0.7682074023537439\n",
      "ma F1:  0.8667251509942869\n",
      "mi F1:  0.8766140121407251\n",
      "we F1:  0.8744747940867614\n",
      "29817 466\n",
      "Loss:  0.04374900087714195\n",
      "Loss:  0.08909288793802261\n",
      "Loss:  0.08833268284797668\n",
      "24 **********\n",
      "Epoch:  1379.7378611564636  fold:  8  kers:  32\n",
      "epoch:  25\n",
      "29817 466\n",
      "Loss:  0.05850892886519432\n",
      "Loss:  0.0765196681022644\n",
      "Loss:  0.05974891036748886\n",
      "25 **********\n",
      "Epoch:  1421.5859682559967  fold:  8  kers:  32\n",
      "epoch:  26\n",
      "29817 466\n",
      "Loss:  0.05081336572766304\n",
      "Loss:  0.07771005481481552\n",
      "Loss:  0.0862022340297699\n",
      "26 **********\n",
      "Epoch:  1463.5248317718506  fold:  8  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.4623108208179474\n",
      "Eval Loss:  1.5097126960754395\n",
      "Eval Loss:  0.13208800554275513\n",
      "[[1768  305]\n",
      " [ 385  616]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      2073\n",
      "           1       0.67      0.62      0.64      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.75      0.73      0.74      3074\n",
      "weighted avg       0.77      0.78      0.77      3074\n",
      "\n",
      "acc:  0.7755367599219258\n",
      "pre:  0.6688382193268186\n",
      "rec:  0.6153846153846154\n",
      "ma F1:  0.7388619974559156\n",
      "mi F1:  0.7755367599219257\n",
      "we F1:  0.7729899014173418\n",
      "Eval Loss:  0.26967984437942505\n",
      "Eval Loss:  0.2861006259918213\n",
      "Eval Loss:  0.24267327785491943\n",
      "Eval Loss:  0.3237605094909668\n",
      "Eval Loss:  0.3015950918197632\n",
      "Eval Loss:  0.28698989748954773\n",
      "Eval Loss:  0.2775852084159851\n",
      "Eval Loss:  0.2657976746559143\n",
      "Eval Loss:  0.3327016234397888\n",
      "Eval Loss:  0.2474551647901535\n",
      "Eval Loss:  0.2579866349697113\n",
      "Eval Loss:  0.2996519207954407\n",
      "Eval Loss:  0.2829984128475189\n",
      "Eval Loss:  0.3336920440196991\n",
      "Eval Loss:  0.25415992736816406\n",
      "Eval Loss:  0.21021097898483276\n",
      "Eval Loss:  0.30794546008110046\n",
      "Eval Loss:  0.30814722180366516\n",
      "Eval Loss:  0.3029515743255615\n",
      "Eval Loss:  0.33117198944091797\n",
      "Eval Loss:  0.1883242279291153\n",
      "Eval Loss:  0.33831924200057983\n",
      "Eval Loss:  0.31628137826919556\n",
      "Eval Loss:  0.17452707886695862\n",
      "Eval Loss:  0.2615809142589569\n",
      "Eval Loss:  0.3284662067890167\n",
      "Eval Loss:  0.2229728400707245\n",
      "Eval Loss:  0.322480171918869\n",
      "Eval Loss:  0.26434698700904846\n",
      "[[16928  1163]\n",
      " [ 2332  9394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18091\n",
      "           1       0.89      0.80      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.88      0.87      0.87     29817\n",
      "weighted avg       0.88      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8827849884294194\n",
      "pre:  0.8898361276877901\n",
      "rec:  0.801125703564728\n",
      "ma F1:  0.8747910909807697\n",
      "mi F1:  0.8827849884294194\n",
      "we F1:  0.8815446292420726\n",
      "29817 466\n",
      "Loss:  0.08766381442546844\n",
      "Loss:  0.0949111133813858\n",
      "Loss:  0.05244696885347366\n",
      "27 **********\n",
      "Epoch:  1545.0049707889557  fold:  8  kers:  32\n",
      "epoch:  28\n",
      "29817 466\n",
      "Loss:  0.05193208158016205\n",
      "Loss:  0.07649547606706619\n",
      "Loss:  0.09777761995792389\n",
      "28 **********\n",
      "Epoch:  1586.8331303596497  fold:  8  kers:  32\n",
      "epoch:  29\n",
      "29817 466\n",
      "Loss:  0.058951057493686676\n",
      "Loss:  0.09646330028772354\n",
      "Loss:  0.060990460216999054\n",
      "29 **********\n",
      "Epoch:  1628.6742556095123  fold:  8  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.3858998119831085\n",
      "Eval Loss:  1.7360957860946655\n",
      "Eval Loss:  0.11066905409097672\n",
      "[[1837  236]\n",
      " [ 450  551]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84      2073\n",
      "           1       0.70      0.55      0.62      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.75      0.72      0.73      3074\n",
      "weighted avg       0.77      0.78      0.77      3074\n",
      "\n",
      "acc:  0.7768379960962914\n",
      "pre:  0.7001270648030495\n",
      "rec:  0.5504495504495505\n",
      "ma F1:  0.7294958233277917\n",
      "mi F1:  0.7768379960962913\n",
      "we F1:  0.7689599051379252\n",
      "Eval Loss:  0.28225094079971313\n",
      "Eval Loss:  0.27222973108291626\n",
      "Eval Loss:  0.2776532471179962\n",
      "Eval Loss:  0.35063832998275757\n",
      "Eval Loss:  0.3132052719593048\n",
      "Eval Loss:  0.31732437014579773\n",
      "Eval Loss:  0.292492151260376\n",
      "Eval Loss:  0.286801278591156\n",
      "Eval Loss:  0.3622467517852783\n",
      "Eval Loss:  0.2803862392902374\n",
      "Eval Loss:  0.2793707549571991\n",
      "Eval Loss:  0.3292173743247986\n",
      "Eval Loss:  0.31978949904441833\n",
      "Eval Loss:  0.3679414987564087\n",
      "Eval Loss:  0.26118049025535583\n",
      "Eval Loss:  0.24131256341934204\n",
      "Eval Loss:  0.305635005235672\n",
      "Eval Loss:  0.30746373534202576\n",
      "Eval Loss:  0.29913657903671265\n",
      "Eval Loss:  0.37077876925468445\n",
      "Eval Loss:  0.18840362131595612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.37913575768470764\n",
      "Eval Loss:  0.32300975918769836\n",
      "Eval Loss:  0.1898490935564041\n",
      "Eval Loss:  0.29256579279899597\n",
      "Eval Loss:  0.3568466007709503\n",
      "Eval Loss:  0.24400007724761963\n",
      "Eval Loss:  0.34414929151535034\n",
      "Eval Loss:  0.2808898687362671\n",
      "[[17276   815]\n",
      " [ 2801  8925]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91     18091\n",
      "           1       0.92      0.76      0.83     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.86      0.87     29817\n",
      "weighted avg       0.88      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8787269007613107\n",
      "pre:  0.9163244353182751\n",
      "rec:  0.7611291147876513\n",
      "ma F1:  0.8684042575857043\n",
      "mi F1:  0.8787269007613108\n",
      "we F1:  0.8762720128021735\n",
      "29817 466\n",
      "Loss:  0.07764188945293427\n",
      "Loss:  0.054106105118989944\n",
      "Loss:  0.10535553842782974\n",
      "30 **********\n",
      "Epoch:  1709.6786661148071  fold:  8  kers:  32\n",
      "epoch:  31\n",
      "29817 466\n",
      "Loss:  0.07082843780517578\n",
      "Loss:  0.06771472841501236\n",
      "Loss:  0.07142149657011032\n",
      "31 **********\n",
      "Epoch:  1751.4888744354248  fold:  8  kers:  32\n",
      "epoch:  32\n",
      "29817 466\n",
      "Loss:  0.059174180030822754\n",
      "Loss:  0.09287123382091522\n",
      "Loss:  0.08730055391788483\n",
      "32 **********\n",
      "Epoch:  1793.3918342590332  fold:  8  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.4033281207084656\n",
      "Eval Loss:  1.551347255706787\n",
      "Eval Loss:  0.12815415859222412\n",
      "[[1826  247]\n",
      " [ 403  598]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85      2073\n",
      "           1       0.71      0.60      0.65      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.76      0.74      0.75      3074\n",
      "weighted avg       0.78      0.79      0.78      3074\n",
      "\n",
      "acc:  0.7885491216655823\n",
      "pre:  0.7076923076923077\n",
      "rec:  0.5974025974025974\n",
      "ma F1:  0.7483974044172051\n",
      "mi F1:  0.7885491216655823\n",
      "we F1:  0.7834484149141596\n",
      "Eval Loss:  0.28726252913475037\n",
      "Eval Loss:  0.2666688859462738\n",
      "Eval Loss:  0.2550943195819855\n",
      "Eval Loss:  0.3188687860965729\n",
      "Eval Loss:  0.3119906485080719\n",
      "Eval Loss:  0.2774113714694977\n",
      "Eval Loss:  0.27392134070396423\n",
      "Eval Loss:  0.2682267725467682\n",
      "Eval Loss:  0.3355439007282257\n",
      "Eval Loss:  0.24264216423034668\n",
      "Eval Loss:  0.25253909826278687\n",
      "Eval Loss:  0.3029565215110779\n",
      "Eval Loss:  0.2897452116012573\n",
      "Eval Loss:  0.33013054728507996\n",
      "Eval Loss:  0.2637474834918976\n",
      "Eval Loss:  0.19503135979175568\n",
      "Eval Loss:  0.2855779230594635\n",
      "Eval Loss:  0.29456257820129395\n",
      "Eval Loss:  0.2980705499649048\n",
      "Eval Loss:  0.33157870173454285\n",
      "Eval Loss:  0.18321363627910614\n",
      "Eval Loss:  0.3601987063884735\n",
      "Eval Loss:  0.2897786498069763\n",
      "Eval Loss:  0.17643272876739502\n",
      "Eval Loss:  0.2549053728580475\n",
      "Eval Loss:  0.32990989089012146\n",
      "Eval Loss:  0.23393532633781433\n",
      "Eval Loss:  0.32206836342811584\n",
      "Eval Loss:  0.24930283427238464\n",
      "[[17097   994]\n",
      " [ 2440  9286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18091\n",
      "           1       0.90      0.79      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.87      0.88     29817\n",
      "weighted avg       0.89      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8848308012207801\n",
      "pre:  0.903307392996109\n",
      "rec:  0.7919154016714992\n",
      "ma F1:  0.8763449116252793\n",
      "mi F1:  0.8848308012207801\n",
      "we F1:  0.8832598632672409\n",
      "29817 466\n",
      "Loss:  0.08653955906629562\n",
      "Loss:  0.06684853136539459\n",
      "Loss:  0.08596660941839218\n",
      "33 **********\n",
      "Epoch:  1874.355354309082  fold:  8  kers:  32\n",
      "epoch:  34\n",
      "29817 466\n",
      "Loss:  0.05247829481959343\n",
      "Loss:  0.0722719058394432\n",
      "Loss:  0.06019223481416702\n",
      "34 **********\n",
      "Epoch:  1916.1655623912811  fold:  8  kers:  32\n",
      "epoch:  35\n",
      "29817 466\n",
      "Loss:  0.07566017657518387\n",
      "Loss:  0.05777105316519737\n",
      "Loss:  0.05122615024447441\n",
      "35 **********\n",
      "Epoch:  1957.9368743896484  fold:  8  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.4553180932998657\n",
      "Eval Loss:  1.520761251449585\n",
      "Eval Loss:  0.13063329458236694\n",
      "[[1733  340]\n",
      " [ 379  622]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      2073\n",
      "           1       0.65      0.62      0.63      1001\n",
      "\n",
      "    accuracy                           0.77      3074\n",
      "   macro avg       0.73      0.73      0.73      3074\n",
      "weighted avg       0.76      0.77      0.76      3074\n",
      "\n",
      "acc:  0.7661027976577749\n",
      "pre:  0.6465696465696466\n",
      "rec:  0.6213786213786214\n",
      "ma F1:  0.7309599149376975\n",
      "mi F1:  0.7661027976577749\n",
      "we F1:  0.7648691591104456\n",
      "Eval Loss:  0.2603906989097595\n",
      "Eval Loss:  0.27862659096717834\n",
      "Eval Loss:  0.23796986043453217\n",
      "Eval Loss:  0.32478052377700806\n",
      "Eval Loss:  0.29601728916168213\n",
      "Eval Loss:  0.2902188301086426\n",
      "Eval Loss:  0.25652673840522766\n",
      "Eval Loss:  0.261752188205719\n",
      "Eval Loss:  0.31772878766059875\n",
      "Eval Loss:  0.25251126289367676\n",
      "Eval Loss:  0.2440112680196762\n",
      "Eval Loss:  0.2894815504550934\n",
      "Eval Loss:  0.2617056965827942\n",
      "Eval Loss:  0.3161261975765228\n",
      "Eval Loss:  0.2534506618976593\n",
      "Eval Loss:  0.18657487630844116\n",
      "Eval Loss:  0.29452553391456604\n",
      "Eval Loss:  0.2993956208229065\n",
      "Eval Loss:  0.28259921073913574\n",
      "Eval Loss:  0.3263380825519562\n",
      "Eval Loss:  0.17652826011180878\n",
      "Eval Loss:  0.3449289798736572\n",
      "Eval Loss:  0.3015498220920563\n",
      "Eval Loss:  0.1720590591430664\n",
      "Eval Loss:  0.24631312489509583\n",
      "Eval Loss:  0.32330289483070374\n",
      "Eval Loss:  0.22094717621803284\n",
      "Eval Loss:  0.2885662913322449\n",
      "Eval Loss:  0.26095959544181824\n",
      "[[16977  1114]\n",
      " [ 2228  9498]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18091\n",
      "           1       0.90      0.81      0.85     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.89      0.87      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8879162893651272\n",
      "pre:  0.8950245005653976\n",
      "rec:  0.8099948831656149\n",
      "ma F1:  0.8803910031246855\n",
      "mi F1:  0.8879162893651272\n",
      "we F1:  0.8867953950113564\n",
      "29817 466\n",
      "Loss:  0.07171978056430817\n",
      "Loss:  0.07774890214204788\n",
      "Loss:  0.06878675520420074\n",
      "36 **********\n",
      "Epoch:  2039.0091032981873  fold:  8  kers:  32\n",
      "epoch:  37\n",
      "29817 466\n",
      "Loss:  0.07204484939575195\n",
      "Loss:  0.07603461295366287\n",
      "Loss:  0.07311311364173889\n",
      "37 **********\n",
      "Epoch:  2080.834271669388  fold:  8  kers:  32\n",
      "epoch:  38\n",
      "29817 466\n",
      "Loss:  0.08157674968242645\n",
      "Loss:  0.07624327391386032\n",
      "Loss:  0.07332432270050049\n",
      "38 **********\n",
      "Epoch:  2122.7053170204163  fold:  8  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.33337634801864624\n",
      "Eval Loss:  1.6271384954452515\n",
      "Eval Loss:  0.10529055446386337\n",
      "[[1872  201]\n",
      " [ 460  541]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      2073\n",
      "           1       0.73      0.54      0.62      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.77      0.72      0.74      3074\n",
      "weighted avg       0.78      0.78      0.78      3074\n",
      "\n",
      "acc:  0.7849707221860768\n",
      "pre:  0.72911051212938\n",
      "rec:  0.5404595404595405\n",
      "ma F1:  0.7353560178772492\n",
      "mi F1:  0.7849707221860768\n",
      "we F1:  0.7753161704084762\n",
      "Eval Loss:  0.30262428522109985\n",
      "Eval Loss:  0.27822697162628174\n",
      "Eval Loss:  0.2881039083003998\n",
      "Eval Loss:  0.3410077691078186\n",
      "Eval Loss:  0.3294079899787903\n",
      "Eval Loss:  0.3048359751701355\n",
      "Eval Loss:  0.31147170066833496\n",
      "Eval Loss:  0.2817666530609131\n",
      "Eval Loss:  0.3672373294830322\n",
      "Eval Loss:  0.27867889404296875\n",
      "Eval Loss:  0.27994734048843384\n",
      "Eval Loss:  0.31915196776390076\n",
      "Eval Loss:  0.32126671075820923\n",
      "Eval Loss:  0.3620415925979614\n",
      "Eval Loss:  0.28001654148101807\n",
      "Eval Loss:  0.22564640641212463\n",
      "Eval Loss:  0.29919910430908203\n",
      "Eval Loss:  0.3165953457355499\n",
      "Eval Loss:  0.31132808327674866\n",
      "Eval Loss:  0.36642348766326904\n",
      "Eval Loss:  0.187604159116745\n",
      "Eval Loss:  0.39506763219833374\n",
      "Eval Loss:  0.304642915725708\n",
      "Eval Loss:  0.20987874269485474\n",
      "Eval Loss:  0.29289522767066956\n",
      "Eval Loss:  0.3551259934902191\n",
      "Eval Loss:  0.24249178171157837\n",
      "Eval Loss:  0.3418115973472595\n",
      "Eval Loss:  0.2649402618408203\n",
      "[[17341   750]\n",
      " [ 2867  8859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18091\n",
      "           1       0.92      0.76      0.83     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.86      0.87     29817\n",
      "weighted avg       0.88      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8786933628466982\n",
      "pre:  0.9219481735872619\n",
      "rec:  0.7555005969640116\n",
      "ma F1:  0.8680126308459654\n",
      "mi F1:  0.8786933628466982\n",
      "we F1:  0.8760275871280527\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07459578663110733\n",
      "Loss:  0.0901440903544426\n",
      "Loss:  0.09781581908464432\n",
      "39 **********\n",
      "Epoch:  2203.9071996212006  fold:  8  kers:  32\n",
      "epoch:  40\n",
      "29817 466\n",
      "Loss:  0.08023726940155029\n",
      "Loss:  0.047051191329956055\n",
      "Loss:  0.06608673185110092\n",
      "40 **********\n",
      "Epoch:  2245.6675407886505  fold:  8  kers:  32\n",
      "epoch:  41\n",
      "29817 466\n",
      "Loss:  0.0643988847732544\n",
      "Loss:  0.07891172915697098\n",
      "Loss:  0.07526230812072754\n",
      "41 **********\n",
      "Epoch:  2287.4947035312653  fold:  8  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.5973829627037048\n",
      "Eval Loss:  1.3315566778182983\n",
      "Eval Loss:  0.14028960466384888\n",
      "[[1662  411]\n",
      " [ 328  673]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      2073\n",
      "           1       0.62      0.67      0.65      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.73      0.74      0.73      3074\n",
      "weighted avg       0.77      0.76      0.76      3074\n",
      "\n",
      "acc:  0.7595966167859467\n",
      "pre:  0.6208487084870848\n",
      "rec:  0.6723276723276723\n",
      "ma F1:  0.7318391213684234\n",
      "mi F1:  0.7595966167859467\n",
      "we F1:  0.7619261133680038\n",
      "Eval Loss:  0.24516454339027405\n",
      "Eval Loss:  0.28389468789100647\n",
      "Eval Loss:  0.22705556452274323\n",
      "Eval Loss:  0.30880460143089294\n",
      "Eval Loss:  0.2888396978378296\n",
      "Eval Loss:  0.2780154049396515\n",
      "Eval Loss:  0.2269137054681778\n",
      "Eval Loss:  0.23249435424804688\n",
      "Eval Loss:  0.3179091811180115\n",
      "Eval Loss:  0.23655268549919128\n",
      "Eval Loss:  0.21853873133659363\n",
      "Eval Loss:  0.276212215423584\n",
      "Eval Loss:  0.2374291718006134\n",
      "Eval Loss:  0.3082839846611023\n",
      "Eval Loss:  0.2546761631965637\n",
      "Eval Loss:  0.18200288712978363\n",
      "Eval Loss:  0.2768028676509857\n",
      "Eval Loss:  0.306903213262558\n",
      "Eval Loss:  0.2758275866508484\n",
      "Eval Loss:  0.30802589654922485\n",
      "Eval Loss:  0.1773950606584549\n",
      "Eval Loss:  0.317849338054657\n",
      "Eval Loss:  0.2973152995109558\n",
      "Eval Loss:  0.15384086966514587\n",
      "Eval Loss:  0.2382182776927948\n",
      "Eval Loss:  0.2941845655441284\n",
      "Eval Loss:  0.20929501950740814\n",
      "Eval Loss:  0.2756863832473755\n",
      "Eval Loss:  0.25634896755218506\n",
      "[[16695  1396]\n",
      " [ 1806  9920]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     18091\n",
      "           1       0.88      0.85      0.86     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.89      0.88      0.89     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.892611597410873\n",
      "pre:  0.8766348533050548\n",
      "rec:  0.8459832850076753\n",
      "ma F1:  0.8867654513476217\n",
      "mi F1:  0.892611597410873\n",
      "we F1:  0.8922578084978201\n",
      "29817 466\n",
      "Loss:  0.06275694072246552\n",
      "Loss:  0.050479136407375336\n",
      "Loss:  0.03710464760661125\n",
      "42 **********\n",
      "Epoch:  2368.3904049396515  fold:  8  kers:  32\n",
      "epoch:  43\n",
      "29817 466\n",
      "Loss:  0.07602604478597641\n",
      "Loss:  0.07215452939271927\n",
      "Loss:  0.07074122130870819\n",
      "43 **********\n",
      "Epoch:  2410.2873809337616  fold:  8  kers:  32\n",
      "epoch:  44\n",
      "29817 466\n",
      "Loss:  0.06097164377570152\n",
      "Loss:  0.06865889579057693\n",
      "Loss:  0.07390154898166656\n",
      "44 **********\n",
      "Epoch:  2451.993866443634  fold:  8  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.46501871943473816\n",
      "Eval Loss:  1.305935263633728\n",
      "Eval Loss:  0.11120495945215225\n",
      "[[1806  267]\n",
      " [ 372  629]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      2073\n",
      "           1       0.70      0.63      0.66      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.77      0.75      0.76      3074\n",
      "weighted avg       0.79      0.79      0.79      3074\n",
      "\n",
      "acc:  0.7921275211450879\n",
      "pre:  0.7020089285714286\n",
      "rec:  0.6283716283716284\n",
      "ma F1:  0.7564173867366257\n",
      "mi F1:  0.7921275211450879\n",
      "we F1:  0.7889418252123024\n",
      "Eval Loss:  0.2632034718990326\n",
      "Eval Loss:  0.2689289152622223\n",
      "Eval Loss:  0.24550622701644897\n",
      "Eval Loss:  0.30594393610954285\n",
      "Eval Loss:  0.3091060221195221\n",
      "Eval Loss:  0.2730178236961365\n",
      "Eval Loss:  0.26729318499565125\n",
      "Eval Loss:  0.2466389536857605\n",
      "Eval Loss:  0.33671221137046814\n",
      "Eval Loss:  0.239816352725029\n",
      "Eval Loss:  0.22171057760715485\n",
      "Eval Loss:  0.2854282259941101\n",
      "Eval Loss:  0.2863563895225525\n",
      "Eval Loss:  0.3191884458065033\n",
      "Eval Loss:  0.2506011426448822\n",
      "Eval Loss:  0.18945248425006866\n",
      "Eval Loss:  0.26525622606277466\n",
      "Eval Loss:  0.2705436050891876\n",
      "Eval Loss:  0.2985078692436218\n",
      "Eval Loss:  0.2991335391998291\n",
      "Eval Loss:  0.16683140397071838\n",
      "Eval Loss:  0.34696751832962036\n",
      "Eval Loss:  0.26597750186920166\n",
      "Eval Loss:  0.1732122004032135\n",
      "Eval Loss:  0.2396819293498993\n",
      "Eval Loss:  0.29577937722206116\n",
      "Eval Loss:  0.21515876054763794\n",
      "Eval Loss:  0.2900291681289673\n",
      "Eval Loss:  0.24763688445091248\n",
      "[[17095   996]\n",
      " [ 2237  9489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18091\n",
      "           1       0.91      0.81      0.85     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.89      0.88      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8915719220578865\n",
      "pre:  0.9050071530758226\n",
      "rec:  0.8092273580078458\n",
      "ma F1:  0.8840253853354268\n",
      "mi F1:  0.8915719220578865\n",
      "we F1:  0.8903406241256524\n",
      "29817 466\n",
      "Loss:  0.07550571113824844\n",
      "Loss:  0.050710324198007584\n",
      "Loss:  0.04471374303102493\n",
      "45 **********\n",
      "Epoch:  2533.14488530159  fold:  8  kers:  32\n",
      "epoch:  46\n",
      "29817 466\n",
      "Loss:  0.04323311895132065\n",
      "Loss:  0.07202402502298355\n",
      "Loss:  0.07311733067035675\n",
      "46 **********\n",
      "Epoch:  2574.9451191425323  fold:  8  kers:  32\n",
      "epoch:  47\n",
      "29817 466\n",
      "Loss:  0.08397705107927322\n",
      "Loss:  0.09477690607309341\n",
      "Loss:  0.06595335155725479\n",
      "47 **********\n",
      "Epoch:  2616.7902343273163  fold:  8  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.568148136138916\n",
      "Eval Loss:  1.203536868095398\n",
      "Eval Loss:  0.11729225516319275\n",
      "[[1705  368]\n",
      " [ 344  657]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      2073\n",
      "           1       0.64      0.66      0.65      1001\n",
      "\n",
      "    accuracy                           0.77      3074\n",
      "   macro avg       0.74      0.74      0.74      3074\n",
      "weighted avg       0.77      0.77      0.77      3074\n",
      "\n",
      "acc:  0.7683799609629147\n",
      "pre:  0.6409756097560976\n",
      "rec:  0.6563436563436563\n",
      "ma F1:  0.7379184622230269\n",
      "mi F1:  0.7683799609629147\n",
      "we F1:  0.7690775525371106\n",
      "Eval Loss:  0.2365400642156601\n",
      "Eval Loss:  0.26595109701156616\n",
      "Eval Loss:  0.21287597715854645\n",
      "Eval Loss:  0.29438021779060364\n",
      "Eval Loss:  0.278804212808609\n",
      "Eval Loss:  0.2689633369445801\n",
      "Eval Loss:  0.2544984221458435\n",
      "Eval Loss:  0.2196374237537384\n",
      "Eval Loss:  0.31483447551727295\n",
      "Eval Loss:  0.23388521373271942\n",
      "Eval Loss:  0.20217175781726837\n",
      "Eval Loss:  0.26522061228752136\n",
      "Eval Loss:  0.25701770186424255\n",
      "Eval Loss:  0.29127684235572815\n",
      "Eval Loss:  0.23797829449176788\n",
      "Eval Loss:  0.18366476893424988\n",
      "Eval Loss:  0.25113365054130554\n",
      "Eval Loss:  0.271653413772583\n",
      "Eval Loss:  0.2720646262168884\n",
      "Eval Loss:  0.2907971143722534\n",
      "Eval Loss:  0.1552751511335373\n",
      "Eval Loss:  0.3076695203781128\n",
      "Eval Loss:  0.27536553144454956\n",
      "Eval Loss:  0.14650800824165344\n",
      "Eval Loss:  0.22464944422245026\n",
      "Eval Loss:  0.2823072671890259\n",
      "Eval Loss:  0.194349005818367\n",
      "Eval Loss:  0.2598590552806854\n",
      "Eval Loss:  0.24778176844120026\n",
      "[[16923  1168]\n",
      " [ 1882  9844]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18091\n",
      "           1       0.89      0.84      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8977093604319684\n",
      "pre:  0.8939338903014893\n",
      "rec:  0.839501961453181\n",
      "ma F1:  0.8915992625028255\n",
      "mi F1:  0.8977093604319685\n",
      "we F1:  0.8970930855454861\n",
      "29817 466\n",
      "Loss:  0.07187734544277191\n",
      "Loss:  0.0814613476395607\n",
      "Loss:  0.06417792290449142\n",
      "48 **********\n",
      "Epoch:  2697.867450237274  fold:  8  kers:  32\n",
      "epoch:  49\n",
      "29817 466\n",
      "Loss:  0.05733660236001015\n",
      "Loss:  0.06846977025270462\n",
      "Loss:  0.052879687398672104\n",
      "49 **********\n",
      "Epoch:  2739.7205436229706  fold:  8  kers:  32\n",
      "epoch:  50\n",
      "29817 466\n",
      "Loss:  0.08889295160770416\n",
      "Loss:  0.06144338473677635\n",
      "Loss:  0.06109093874692917\n",
      "50 **********\n",
      "Epoch:  2781.5227732658386  fold:  8  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  1.05093252658844\n",
      "Eval Loss:  1.1469199657440186\n",
      "Eval Loss:  0.1650165468454361\n",
      "[[1424  649]\n",
      " [ 261  740]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76      2073\n",
      "           1       0.53      0.74      0.62      1001\n",
      "\n",
      "    accuracy                           0.70      3074\n",
      "   macro avg       0.69      0.71      0.69      3074\n",
      "weighted avg       0.74      0.70      0.71      3074\n",
      "\n",
      "acc:  0.7039687703318153\n",
      "pre:  0.5327573794096472\n",
      "rec:  0.7392607392607392\n",
      "ma F1:  0.6885483910474948\n",
      "mi F1:  0.7039687703318153\n",
      "we F1:  0.7127160030252601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24353215098381042\n",
      "Eval Loss:  0.31863918900489807\n",
      "Eval Loss:  0.22442340850830078\n",
      "Eval Loss:  0.3253971040248871\n",
      "Eval Loss:  0.300420343875885\n",
      "Eval Loss:  0.29564738273620605\n",
      "Eval Loss:  0.2419927716255188\n",
      "Eval Loss:  0.22778552770614624\n",
      "Eval Loss:  0.3115166127681732\n",
      "Eval Loss:  0.2551736533641815\n",
      "Eval Loss:  0.22065380215644836\n",
      "Eval Loss:  0.279628723859787\n",
      "Eval Loss:  0.23207050561904907\n",
      "Eval Loss:  0.29070883989334106\n",
      "Eval Loss:  0.3060038387775421\n",
      "Eval Loss:  0.1835346817970276\n",
      "Eval Loss:  0.30794671177864075\n",
      "Eval Loss:  0.3162427842617035\n",
      "Eval Loss:  0.29959341883659363\n",
      "Eval Loss:  0.2858184278011322\n",
      "Eval Loss:  0.20542196929454803\n",
      "Eval Loss:  0.3211917281150818\n",
      "Eval Loss:  0.3023045063018799\n",
      "Eval Loss:  0.15560351312160492\n",
      "Eval Loss:  0.2140769511461258\n",
      "Eval Loss:  0.31844574213027954\n",
      "Eval Loss:  0.22125564515590668\n",
      "Eval Loss:  0.2715292274951935\n",
      "Eval Loss:  0.26439109444618225\n",
      "[[16136  1955]\n",
      " [ 1386 10340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91     18091\n",
      "           1       0.84      0.88      0.86     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.88      0.89      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8879498272797397\n",
      "pre:  0.8409922732818219\n",
      "rec:  0.8818011257035647\n",
      "ma F1:  0.8835496554027146\n",
      "mi F1:  0.8879498272797397\n",
      "we F1:  0.888381797224189\n",
      "29817 466\n",
      "Loss:  0.052154768258333206\n",
      "Loss:  0.07955872267484665\n",
      "Loss:  0.057693831622600555\n",
      "51 **********\n",
      "Epoch:  2862.5650823116302  fold:  8  kers:  32\n",
      "epoch:  52\n",
      "29817 466\n",
      "Loss:  0.06977943331003189\n",
      "Loss:  0.06861159205436707\n",
      "Loss:  0.10371918231248856\n",
      "52 **********\n",
      "Epoch:  2904.3104634284973  fold:  8  kers:  32\n",
      "epoch:  53\n",
      "29817 466\n",
      "Loss:  0.092955082654953\n",
      "Loss:  0.06741353869438171\n",
      "Loss:  0.08677907288074493\n",
      "53 **********\n",
      "Epoch:  2946.0039834976196  fold:  8  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.5785211324691772\n",
      "Eval Loss:  1.1971768140792847\n",
      "Eval Loss:  0.09852903336286545\n",
      "[[1766  307]\n",
      " [ 365  636]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      2073\n",
      "           1       0.67      0.64      0.65      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.75      0.74      0.75      3074\n",
      "weighted avg       0.78      0.78      0.78      3074\n",
      "\n",
      "acc:  0.7813923227065712\n",
      "pre:  0.6744432661717922\n",
      "rec:  0.6353646353646354\n",
      "ma F1:  0.747236611810034\n",
      "mi F1:  0.7813923227065712\n",
      "we F1:  0.7796391977225011\n",
      "Eval Loss:  0.24556434154510498\n",
      "Eval Loss:  0.27140751481056213\n",
      "Eval Loss:  0.21849960088729858\n",
      "Eval Loss:  0.2929350733757019\n",
      "Eval Loss:  0.2843579947948456\n",
      "Eval Loss:  0.26178860664367676\n",
      "Eval Loss:  0.278725802898407\n",
      "Eval Loss:  0.22132664918899536\n",
      "Eval Loss:  0.3084012269973755\n",
      "Eval Loss:  0.22234517335891724\n",
      "Eval Loss:  0.1993061751127243\n",
      "Eval Loss:  0.2637607753276825\n",
      "Eval Loss:  0.2507966458797455\n",
      "Eval Loss:  0.27193909883499146\n",
      "Eval Loss:  0.22611184418201447\n",
      "Eval Loss:  0.17517097294330597\n",
      "Eval Loss:  0.26187193393707275\n",
      "Eval Loss:  0.277538537979126\n",
      "Eval Loss:  0.2833068370819092\n",
      "Eval Loss:  0.26818907260894775\n",
      "Eval Loss:  0.1531345546245575\n",
      "Eval Loss:  0.32696446776390076\n",
      "Eval Loss:  0.26523253321647644\n",
      "Eval Loss:  0.1509951949119568\n",
      "Eval Loss:  0.21484336256980896\n",
      "Eval Loss:  0.269415944814682\n",
      "Eval Loss:  0.18969221413135529\n",
      "Eval Loss:  0.2661762833595276\n",
      "Eval Loss:  0.23929089307785034\n",
      "[[17063  1028]\n",
      " [ 1983  9743]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18091\n",
      "           1       0.90      0.83      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8990173391018547\n",
      "pre:  0.9045585368118095\n",
      "rec:  0.8308886235715504\n",
      "ma F1:  0.8925408812081588\n",
      "mi F1:  0.8990173391018547\n",
      "we F1:  0.8981723913848494\n",
      "29817 466\n",
      "Loss:  0.05529584363102913\n",
      "Loss:  0.0598958320915699\n",
      "Loss:  0.08268777281045914\n",
      "54 **********\n",
      "Epoch:  3027.120096921921  fold:  8  kers:  32\n",
      "epoch:  55\n",
      "29817 466\n",
      "Loss:  0.08052733540534973\n",
      "Loss:  0.09331568330526352\n",
      "Loss:  0.04821891710162163\n",
      "55 **********\n",
      "Epoch:  3068.9203305244446  fold:  8  kers:  32\n",
      "epoch:  56\n",
      "29817 466\n",
      "Loss:  0.05249718949198723\n",
      "Loss:  0.06383147835731506\n",
      "Loss:  0.04726889356970787\n",
      "56 **********\n",
      "Epoch:  3110.811322450638  fold:  8  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.6577195525169373\n",
      "Eval Loss:  1.0819474458694458\n",
      "Eval Loss:  0.09946620464324951\n",
      "[[1644  429]\n",
      " [ 322  679]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81      2073\n",
      "           1       0.61      0.68      0.64      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.72      0.74      0.73      3074\n",
      "weighted avg       0.76      0.76      0.76      3074\n",
      "\n",
      "acc:  0.7556929082628497\n",
      "pre:  0.6128158844765343\n",
      "rec:  0.6783216783216783\n",
      "ma F1:  0.7289849759064391\n",
      "mi F1:  0.7556929082628498\n",
      "we F1:  0.7586543059438197\n",
      "Eval Loss:  0.23309892416000366\n",
      "Eval Loss:  0.2605360150337219\n",
      "Eval Loss:  0.21607212722301483\n",
      "Eval Loss:  0.27767637372016907\n",
      "Eval Loss:  0.28242310881614685\n",
      "Eval Loss:  0.25322216749191284\n",
      "Eval Loss:  0.2633289694786072\n",
      "Eval Loss:  0.22760064899921417\n",
      "Eval Loss:  0.2957877218723297\n",
      "Eval Loss:  0.23266065120697021\n",
      "Eval Loss:  0.19791078567504883\n",
      "Eval Loss:  0.26033252477645874\n",
      "Eval Loss:  0.2445986270904541\n",
      "Eval Loss:  0.26622313261032104\n",
      "Eval Loss:  0.22996442019939423\n",
      "Eval Loss:  0.17601066827774048\n",
      "Eval Loss:  0.26992863416671753\n",
      "Eval Loss:  0.2565980553627014\n",
      "Eval Loss:  0.260081946849823\n",
      "Eval Loss:  0.2616249918937683\n",
      "Eval Loss:  0.15294471383094788\n",
      "Eval Loss:  0.2952709496021271\n",
      "Eval Loss:  0.27312496304512024\n",
      "Eval Loss:  0.14033690094947815\n",
      "Eval Loss:  0.20558589696884155\n",
      "Eval Loss:  0.2717343866825104\n",
      "Eval Loss:  0.18838897347450256\n",
      "Eval Loss:  0.25118279457092285\n",
      "Eval Loss:  0.24579937756061554\n",
      "[[16900  1191]\n",
      " [ 1808  9918]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     18091\n",
      "           1       0.89      0.85      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8994197940772043\n",
      "pre:  0.8927896300297057\n",
      "rec:  0.8458127238615043\n",
      "ma F1:  0.8935848704440607\n",
      "mi F1:  0.8994197940772043\n",
      "we F1:  0.8989041613241752\n",
      "29817 466\n",
      "Loss:  0.0744573175907135\n",
      "Loss:  0.08388587087392807\n",
      "Loss:  0.07092037796974182\n",
      "57 **********\n",
      "Epoch:  3191.908485174179  fold:  8  kers:  32\n",
      "epoch:  58\n",
      "29817 466\n",
      "Loss:  0.036327920854091644\n",
      "Loss:  0.07717864960432053\n",
      "Loss:  0.05181829258799553\n",
      "58 **********\n",
      "Epoch:  3233.9410984516144  fold:  8  kers:  32\n",
      "epoch:  59\n",
      "29817 466\n",
      "Loss:  0.06727367639541626\n",
      "Loss:  0.03601966053247452\n",
      "Loss:  0.04959326609969139\n",
      "59 **********\n",
      "Epoch:  3275.7124106884003  fold:  8  kers:  32\n",
      "Eval Loss:  0.623852550983429\n",
      "Eval Loss:  1.1342195272445679\n",
      "Eval Loss:  0.08986743539571762\n",
      "[[1685  388]\n",
      " [ 365  636]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      2073\n",
      "           1       0.62      0.64      0.63      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.72      0.72      0.72      3074\n",
      "weighted avg       0.76      0.76      0.76      3074\n",
      "\n",
      "acc:  0.7550422901756669\n",
      "pre:  0.62109375\n",
      "rec:  0.6353646353646354\n",
      "ma F1:  0.7227570718911975\n",
      "mi F1:  0.7550422901756669\n",
      "we F1:  0.7557501643611223\n",
      "update!  Acc:  0.8386467143786597\n",
      "Epoch:  3279.3716266155243  fold:  8  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29483 3408\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29483 461\n",
      "Loss:  0.17100244760513306\n",
      "Loss:  0.16744323074817657\n",
      "Loss:  0.1530085802078247\n",
      "0 **********\n",
      "Epoch:  53.74629259109497  fold:  9  kers:  32\n",
      "epoch:  1\n",
      "29483 461\n",
      "Loss:  0.14174099266529083\n",
      "Loss:  0.13724751770496368\n",
      "Loss:  0.129305899143219\n",
      "1 **********\n",
      "Epoch:  95.22039937973022  fold:  9  kers:  32\n",
      "epoch:  2\n",
      "29483 461\n",
      "Loss:  0.1164548322558403\n",
      "Loss:  0.10925540328025818\n",
      "Loss:  0.1491689383983612\n",
      "2 **********\n",
      "Epoch:  136.5289487838745  fold:  9  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.2608794867992401\n",
      "Eval Loss:  0.744112491607666\n",
      "Eval Loss:  0.36103397607803345\n",
      "[[1369  373]\n",
      " [ 255 1411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81      1742\n",
      "           1       0.79      0.85      0.82      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.82      0.82      0.82      3408\n",
      "weighted avg       0.82      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8157276995305164\n",
      "pre:  0.7909192825112108\n",
      "rec:  0.8469387755102041\n",
      "ma F1:  0.8156997080782248\n",
      "mi F1:  0.8157276995305164\n",
      "we F1:  0.8156490568788397\n",
      "update!  Acc:  0.8157276995305164\n",
      "Eval Loss:  0.44254070520401\n",
      "Eval Loss:  0.5010161399841309\n",
      "Eval Loss:  0.4945589005947113\n",
      "Eval Loss:  0.5374055504798889\n",
      "Eval Loss:  0.41302555799484253\n",
      "Eval Loss:  0.48320743441581726\n",
      "Eval Loss:  0.3937394917011261\n",
      "Eval Loss:  0.44496703147888184\n",
      "Eval Loss:  0.4183084964752197\n",
      "Eval Loss:  0.31411176919937134\n",
      "Eval Loss:  0.4137928783893585\n",
      "Eval Loss:  0.43352192640304565\n",
      "Eval Loss:  0.4637887179851532\n",
      "Eval Loss:  0.4804645776748657\n",
      "Eval Loss:  0.4160139560699463\n",
      "Eval Loss:  0.4681878089904785\n",
      "Eval Loss:  0.4514836370944977\n",
      "Eval Loss:  0.4066377878189087\n",
      "Eval Loss:  0.4067572355270386\n",
      "Eval Loss:  0.47966739535331726\n",
      "Eval Loss:  0.4706175625324249\n",
      "Eval Loss:  0.42052504420280457\n",
      "Eval Loss:  0.4794900417327881\n",
      "Eval Loss:  0.4145474135875702\n",
      "Eval Loss:  0.3869314193725586\n",
      "Eval Loss:  0.5064754486083984\n",
      "Eval Loss:  0.4615119695663452\n",
      "Eval Loss:  0.4955999255180359\n",
      "[[14484  3938]\n",
      " [ 2214  8847]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.82     18422\n",
      "           1       0.69      0.80      0.74     11061\n",
      "\n",
      "    accuracy                           0.79     29483\n",
      "   macro avg       0.78      0.79      0.78     29483\n",
      "weighted avg       0.80      0.79      0.79     29483\n",
      "\n",
      "acc:  0.7913373808635484\n",
      "pre:  0.6919827923347673\n",
      "rec:  0.7998372660699756\n",
      "ma F1:  0.7834201979787923\n",
      "mi F1:  0.7913373808635483\n",
      "we F1:  0.7937587438746041\n",
      "29483 461\n",
      "Loss:  0.1255231648683548\n",
      "Loss:  0.12206502258777618\n",
      "Loss:  0.0974414125084877\n",
      "3 **********\n",
      "Epoch:  217.1184687614441  fold:  9  kers:  32\n",
      "epoch:  4\n",
      "29483 461\n",
      "Loss:  0.1082376018166542\n",
      "Loss:  0.12884202599525452\n",
      "Loss:  0.1359827220439911\n",
      "4 **********\n",
      "Epoch:  258.4040791988373  fold:  9  kers:  32\n",
      "epoch:  5\n",
      "29483 461\n",
      "Loss:  0.12136296927928925\n",
      "Loss:  0.11227147281169891\n",
      "Loss:  0.08949435502290726\n",
      "5 **********\n",
      "Epoch:  299.65578055381775  fold:  9  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.10247737914323807\n",
      "Eval Loss:  1.4928737878799438\n",
      "Eval Loss:  0.27682045102119446\n",
      "[[1631  111]\n",
      " [ 495 1171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.84      1742\n",
      "           1       0.91      0.70      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.84      0.82      0.82      3408\n",
      "weighted avg       0.84      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8221830985915493\n",
      "pre:  0.9134165366614665\n",
      "rec:  0.7028811524609844\n",
      "ma F1:  0.8188833963116634\n",
      "mi F1:  0.8221830985915493\n",
      "we F1:  0.819428564514427\n",
      "update!  Acc:  0.8221830985915493\n",
      "Eval Loss:  0.3402903378009796\n",
      "Eval Loss:  0.4142075181007385\n",
      "Eval Loss:  0.4260266423225403\n",
      "Eval Loss:  0.533589780330658\n",
      "Eval Loss:  0.3707258701324463\n",
      "Eval Loss:  0.47554829716682434\n",
      "Eval Loss:  0.33680105209350586\n",
      "Eval Loss:  0.4144746661186218\n",
      "Eval Loss:  0.33031344413757324\n",
      "Eval Loss:  0.26026451587677\n",
      "Eval Loss:  0.36605870723724365\n",
      "Eval Loss:  0.32780131697654724\n",
      "Eval Loss:  0.3700241148471832\n",
      "Eval Loss:  0.4713219702243805\n",
      "Eval Loss:  0.330763041973114\n",
      "Eval Loss:  0.4142893850803375\n",
      "Eval Loss:  0.3929998278617859\n",
      "Eval Loss:  0.33625879883766174\n",
      "Eval Loss:  0.3444100618362427\n",
      "Eval Loss:  0.4206937849521637\n",
      "Eval Loss:  0.41997647285461426\n",
      "Eval Loss:  0.43171221017837524\n",
      "Eval Loss:  0.4297669529914856\n",
      "Eval Loss:  0.3221781551837921\n",
      "Eval Loss:  0.32408004999160767\n",
      "Eval Loss:  0.4447733461856842\n",
      "Eval Loss:  0.3846298158168793\n",
      "Eval Loss:  0.4659583866596222\n",
      "[[17151  1271]\n",
      " [ 3446  7615]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88     18422\n",
      "           1       0.86      0.69      0.76     11061\n",
      "\n",
      "    accuracy                           0.84     29483\n",
      "   macro avg       0.84      0.81      0.82     29483\n",
      "weighted avg       0.84      0.84      0.84     29483\n",
      "\n",
      "acc:  0.8400094969982702\n",
      "pre:  0.8569660139545352\n",
      "rec:  0.6884549317421571\n",
      "ma F1:  0.8213167569679221\n",
      "mi F1:  0.8400094969982702\n",
      "we F1:  0.8357459997702912\n",
      "29483 461\n",
      "Loss:  0.09990298748016357\n",
      "Loss:  0.10386430472135544\n",
      "Loss:  0.06238185614347458\n",
      "6 **********\n",
      "Epoch:  380.3240900039673  fold:  9  kers:  32\n",
      "epoch:  7\n",
      "29483 461\n",
      "Loss:  0.09184729307889938\n",
      "Loss:  0.11153393983840942\n",
      "Loss:  0.056986089795827866\n",
      "7 **********\n",
      "Epoch:  421.6216688156128  fold:  9  kers:  32\n",
      "epoch:  8\n",
      "29483 461\n",
      "Loss:  0.11529378592967987\n",
      "Loss:  0.059845004230737686\n",
      "Loss:  0.06829722225666046\n",
      "8 **********\n",
      "Epoch:  463.0419194698334  fold:  9  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.08762572705745697\n",
      "Eval Loss:  1.2120168209075928\n",
      "Eval Loss:  0.1928427815437317\n",
      "[[1567  175]\n",
      " [ 395 1271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1742\n",
      "           1       0.88      0.76      0.82      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.84      0.83      0.83      3408\n",
      "weighted avg       0.84      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8327464788732394\n",
      "pre:  0.8789764868603043\n",
      "rec:  0.762905162064826\n",
      "ma F1:  0.8314751786438062\n",
      "mi F1:  0.8327464788732394\n",
      "we F1:  0.8318015935675795\n",
      "update!  Acc:  0.8327464788732394\n",
      "Eval Loss:  0.32555267214775085\n",
      "Eval Loss:  0.3246295750141144\n",
      "Eval Loss:  0.3498031198978424\n",
      "Eval Loss:  0.3832321763038635\n",
      "Eval Loss:  0.30652159452438354\n",
      "Eval Loss:  0.43830764293670654\n",
      "Eval Loss:  0.2841149866580963\n",
      "Eval Loss:  0.3620121479034424\n",
      "Eval Loss:  0.33403152227401733\n",
      "Eval Loss:  0.23727336525917053\n",
      "Eval Loss:  0.2813258171081543\n",
      "Eval Loss:  0.3466106355190277\n",
      "Eval Loss:  0.2738600969314575\n",
      "Eval Loss:  0.35901033878326416\n",
      "Eval Loss:  0.25505495071411133\n",
      "Eval Loss:  0.3426032066345215\n",
      "Eval Loss:  0.320697546005249\n",
      "Eval Loss:  0.32603031396865845\n",
      "Eval Loss:  0.31335973739624023\n",
      "Eval Loss:  0.32298600673675537\n",
      "Eval Loss:  0.322185754776001\n",
      "Eval Loss:  0.3640170991420746\n",
      "Eval Loss:  0.35894283652305603\n",
      "Eval Loss:  0.2556389272212982\n",
      "Eval Loss:  0.27009931206703186\n",
      "Eval Loss:  0.32405564188957214\n",
      "Eval Loss:  0.2858860194683075\n",
      "Eval Loss:  0.3218075931072235\n",
      "[[16589  1833]\n",
      " [ 2178  8883]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89     18422\n",
      "           1       0.83      0.80      0.82     11061\n",
      "\n",
      "    accuracy                           0.86     29483\n",
      "   macro avg       0.86      0.85      0.85     29483\n",
      "weighted avg       0.86      0.86      0.86     29483\n",
      "\n",
      "acc:  0.863955499779534\n",
      "pre:  0.8289473684210527\n",
      "rec:  0.8030919446704637\n",
      "ma F1:  0.8539801887167463\n",
      "mi F1:  0.863955499779534\n",
      "we F1:  0.8635089020223756\n",
      "29483 461\n",
      "Loss:  0.07991372793912888\n",
      "Loss:  0.10128898918628693\n",
      "Loss:  0.07831688970327377\n",
      "9 **********\n",
      "Epoch:  543.6833004951477  fold:  9  kers:  32\n",
      "epoch:  10\n",
      "29483 461\n",
      "Loss:  0.12788313627243042\n",
      "Loss:  0.08356655389070511\n",
      "Loss:  0.06719504296779633\n",
      "10 **********\n",
      "Epoch:  585.202287197113  fold:  9  kers:  32\n",
      "epoch:  11\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06861656904220581\n",
      "Loss:  0.07136593759059906\n",
      "Loss:  0.13298776745796204\n",
      "11 **********\n",
      "Epoch:  626.739226102829  fold:  9  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.0792195200920105\n",
      "Eval Loss:  1.2939902544021606\n",
      "Eval Loss:  0.21372048556804657\n",
      "[[1627  115]\n",
      " [ 454 1212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85      1742\n",
      "           1       0.91      0.73      0.81      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8330399061032864\n",
      "pre:  0.9133383571966842\n",
      "rec:  0.7274909963985594\n",
      "ma F1:  0.8305268750285675\n",
      "mi F1:  0.8330399061032864\n",
      "we F1:  0.8309870927675521\n",
      "update!  Acc:  0.8330399061032864\n",
      "Eval Loss:  0.26725566387176514\n",
      "Eval Loss:  0.3301151692867279\n",
      "Eval Loss:  0.36599263548851013\n",
      "Eval Loss:  0.3878526985645294\n",
      "Eval Loss:  0.34502506256103516\n",
      "Eval Loss:  0.44874054193496704\n",
      "Eval Loss:  0.32699263095855713\n",
      "Eval Loss:  0.3929300010204315\n",
      "Eval Loss:  0.3139234781265259\n",
      "Eval Loss:  0.22428977489471436\n",
      "Eval Loss:  0.29522281885147095\n",
      "Eval Loss:  0.2984018921852112\n",
      "Eval Loss:  0.262617290019989\n",
      "Eval Loss:  0.36550524830818176\n",
      "Eval Loss:  0.2613758444786072\n",
      "Eval Loss:  0.35918372869491577\n",
      "Eval Loss:  0.3201158940792084\n",
      "Eval Loss:  0.3026094436645508\n",
      "Eval Loss:  0.3052457273006439\n",
      "Eval Loss:  0.33188948035240173\n",
      "Eval Loss:  0.33677685260772705\n",
      "Eval Loss:  0.41648274660110474\n",
      "Eval Loss:  0.36978456377983093\n",
      "Eval Loss:  0.2535153329372406\n",
      "Eval Loss:  0.29689449071884155\n",
      "Eval Loss:  0.33747929334640503\n",
      "Eval Loss:  0.29414933919906616\n",
      "Eval Loss:  0.38121628761291504\n",
      "[[17350  1072]\n",
      " [ 2794  8267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     18422\n",
      "           1       0.89      0.75      0.81     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.87      0.84      0.86     29483\n",
      "weighted avg       0.87      0.87      0.87     29483\n",
      "\n",
      "acc:  0.8688735881694536\n",
      "pre:  0.8852125495235036\n",
      "rec:  0.7474007775065545\n",
      "ma F1:  0.8551232290354298\n",
      "mi F1:  0.8688735881694536\n",
      "we F1:  0.8662667271732201\n",
      "29483 461\n",
      "Loss:  0.11130336672067642\n",
      "Loss:  0.15604549646377563\n",
      "Loss:  0.08456622809171677\n",
      "12 **********\n",
      "Epoch:  707.3417115211487  fold:  9  kers:  32\n",
      "epoch:  13\n",
      "29483 461\n",
      "Loss:  0.07867202162742615\n",
      "Loss:  0.05976235494017601\n",
      "Loss:  0.07698438316583633\n",
      "13 **********\n",
      "Epoch:  748.5475356578827  fold:  9  kers:  32\n",
      "epoch:  14\n",
      "29483 461\n",
      "Loss:  0.05497162044048309\n",
      "Loss:  0.08696788549423218\n",
      "Loss:  0.08246567845344543\n",
      "14 **********\n",
      "Epoch:  789.864063501358  fold:  9  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.07245577871799469\n",
      "Eval Loss:  1.1973811388015747\n",
      "Eval Loss:  0.18000070750713348\n",
      "[[1613  129]\n",
      " [ 427 1239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85      1742\n",
      "           1       0.91      0.74      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8368544600938967\n",
      "pre:  0.9057017543859649\n",
      "rec:  0.7436974789915967\n",
      "ma F1:  0.8348657049821746\n",
      "mi F1:  0.8368544600938966\n",
      "we F1:  0.835269837036963\n",
      "update!  Acc:  0.8368544600938967\n",
      "Eval Loss:  0.25789326429367065\n",
      "Eval Loss:  0.2836751937866211\n",
      "Eval Loss:  0.3672615885734558\n",
      "Eval Loss:  0.35008904337882996\n",
      "Eval Loss:  0.3250666558742523\n",
      "Eval Loss:  0.41269585490226746\n",
      "Eval Loss:  0.32226166129112244\n",
      "Eval Loss:  0.3490982949733734\n",
      "Eval Loss:  0.2953367829322815\n",
      "Eval Loss:  0.21724718809127808\n",
      "Eval Loss:  0.26463016867637634\n",
      "Eval Loss:  0.27753913402557373\n",
      "Eval Loss:  0.2250637412071228\n",
      "Eval Loss:  0.3270512819290161\n",
      "Eval Loss:  0.23393481969833374\n",
      "Eval Loss:  0.3198186159133911\n",
      "Eval Loss:  0.28729212284088135\n",
      "Eval Loss:  0.29279688000679016\n",
      "Eval Loss:  0.2910034954547882\n",
      "Eval Loss:  0.28493455052375793\n",
      "Eval Loss:  0.27505189180374146\n",
      "Eval Loss:  0.3751777112483978\n",
      "Eval Loss:  0.3268013000488281\n",
      "Eval Loss:  0.23305700719356537\n",
      "Eval Loss:  0.26831790804862976\n",
      "Eval Loss:  0.2675713300704956\n",
      "Eval Loss:  0.2635081112384796\n",
      "Eval Loss:  0.32529014348983765\n",
      "[[17150  1272]\n",
      " [ 2305  8756]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     18422\n",
      "           1       0.87      0.79      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.88      0.86      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8786758470983278\n",
      "pre:  0.8731551655364979\n",
      "rec:  0.7916101618298527\n",
      "ma F1:  0.867974125797297\n",
      "mi F1:  0.8786758470983278\n",
      "we F1:  0.8773588494685965\n",
      "29483 461\n",
      "Loss:  0.09413759410381317\n",
      "Loss:  0.07297861576080322\n",
      "Loss:  0.06344199180603027\n",
      "15 **********\n",
      "Epoch:  870.4156847000122  fold:  9  kers:  32\n",
      "epoch:  16\n",
      "29483 461\n",
      "Loss:  0.048491042107343674\n",
      "Loss:  0.07872873544692993\n",
      "Loss:  0.06970079988241196\n",
      "16 **********\n",
      "Epoch:  911.7900578975677  fold:  9  kers:  32\n",
      "epoch:  17\n",
      "29483 461\n",
      "Loss:  0.06430912017822266\n",
      "Loss:  0.06457319855690002\n",
      "Loss:  0.06707711517810822\n",
      "17 **********\n",
      "Epoch:  953.1095781326294  fold:  9  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.07434117048978806\n",
      "Eval Loss:  1.2051515579223633\n",
      "Eval Loss:  0.1702600121498108\n",
      "[[1617  125]\n",
      " [ 407 1259]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      1742\n",
      "           1       0.91      0.76      0.83      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8438967136150235\n",
      "pre:  0.9096820809248555\n",
      "rec:  0.7557022809123649\n",
      "ma F1:  0.8421549149856786\n",
      "mi F1:  0.8438967136150235\n",
      "we F1:  0.8425246822924668\n",
      "update!  Acc:  0.8438967136150235\n",
      "Eval Loss:  0.2349880486726761\n",
      "Eval Loss:  0.28144651651382446\n",
      "Eval Loss:  0.3515835702419281\n",
      "Eval Loss:  0.34733596444129944\n",
      "Eval Loss:  0.3244771361351013\n",
      "Eval Loss:  0.38453415036201477\n",
      "Eval Loss:  0.32761168479919434\n",
      "Eval Loss:  0.35560545325279236\n",
      "Eval Loss:  0.2733078598976135\n",
      "Eval Loss:  0.20954056084156036\n",
      "Eval Loss:  0.2642388343811035\n",
      "Eval Loss:  0.2741939425468445\n",
      "Eval Loss:  0.20387345552444458\n",
      "Eval Loss:  0.31648194789886475\n",
      "Eval Loss:  0.21410568058490753\n",
      "Eval Loss:  0.3238677382469177\n",
      "Eval Loss:  0.29605668783187866\n",
      "Eval Loss:  0.2833127975463867\n",
      "Eval Loss:  0.2972864806652069\n",
      "Eval Loss:  0.2989034652709961\n",
      "Eval Loss:  0.2690839171409607\n",
      "Eval Loss:  0.3681139349937439\n",
      "Eval Loss:  0.3415883183479309\n",
      "Eval Loss:  0.21855229139328003\n",
      "Eval Loss:  0.2732110321521759\n",
      "Eval Loss:  0.26269081234931946\n",
      "Eval Loss:  0.2546358108520508\n",
      "Eval Loss:  0.31708335876464844\n",
      "[[17231  1191]\n",
      " [ 2349  8712]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18422\n",
      "           1       0.88      0.79      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.88      0.86      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8799308075840315\n",
      "pre:  0.8797334141169343\n",
      "rec:  0.7876322213181448\n",
      "ma F1:  0.8689930518223259\n",
      "mi F1:  0.8799308075840315\n",
      "we F1:  0.8784440226125495\n",
      "29483 461\n",
      "Loss:  0.08343388885259628\n",
      "Loss:  0.0866459384560585\n",
      "Loss:  0.0774269700050354\n",
      "18 **********\n",
      "Epoch:  1033.5185806751251  fold:  9  kers:  32\n",
      "epoch:  19\n",
      "29483 461\n",
      "Loss:  0.09247083961963654\n",
      "Loss:  0.0748133659362793\n",
      "Loss:  0.09061349928379059\n",
      "19 **********\n",
      "Epoch:  1077.6695301532745  fold:  9  kers:  32\n",
      "epoch:  20\n",
      "29483 461\n",
      "Loss:  0.08839881420135498\n",
      "Loss:  0.08378148823976517\n",
      "Loss:  0.07370686531066895\n",
      "20 **********\n",
      "Epoch:  1118.966111421585  fold:  9  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.06610028445720673\n",
      "Eval Loss:  1.2909424304962158\n",
      "Eval Loss:  0.15919102728366852\n",
      "[[1608  134]\n",
      " [ 396 1270]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86      1742\n",
      "           1       0.90      0.76      0.83      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8444835680751174\n",
      "pre:  0.9045584045584045\n",
      "rec:  0.7623049219687875\n",
      "ma F1:  0.8429386568256956\n",
      "mi F1:  0.8444835680751174\n",
      "we F1:  0.8432860333196485\n",
      "update!  Acc:  0.8444835680751174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24287769198417664\n",
      "Eval Loss:  0.2720305323600769\n",
      "Eval Loss:  0.33580252528190613\n",
      "Eval Loss:  0.3454536199569702\n",
      "Eval Loss:  0.31943103671073914\n",
      "Eval Loss:  0.38489019870758057\n",
      "Eval Loss:  0.3268057703971863\n",
      "Eval Loss:  0.3566177189350128\n",
      "Eval Loss:  0.27015602588653564\n",
      "Eval Loss:  0.20238560438156128\n",
      "Eval Loss:  0.2602103352546692\n",
      "Eval Loss:  0.2742222547531128\n",
      "Eval Loss:  0.198820561170578\n",
      "Eval Loss:  0.31936901807785034\n",
      "Eval Loss:  0.21287332475185394\n",
      "Eval Loss:  0.3267948627471924\n",
      "Eval Loss:  0.29407647252082825\n",
      "Eval Loss:  0.2787580192089081\n",
      "Eval Loss:  0.294613778591156\n",
      "Eval Loss:  0.27758902311325073\n",
      "Eval Loss:  0.2631283700466156\n",
      "Eval Loss:  0.3551968038082123\n",
      "Eval Loss:  0.33748629689216614\n",
      "Eval Loss:  0.20647791028022766\n",
      "Eval Loss:  0.25506868958473206\n",
      "Eval Loss:  0.25398483872413635\n",
      "Eval Loss:  0.2299633026123047\n",
      "Eval Loss:  0.296487420797348\n",
      "[[17148  1274]\n",
      " [ 2135  8926]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18422\n",
      "           1       0.88      0.81      0.84     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.88      0.87      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8843740460604416\n",
      "pre:  0.8750980392156863\n",
      "rec:  0.8069794774432691\n",
      "ma F1:  0.8746235291224336\n",
      "mi F1:  0.8843740460604416\n",
      "we F1:  0.8833529812241944\n",
      "29483 461\n",
      "Loss:  0.08593778312206268\n",
      "Loss:  0.08556636422872543\n",
      "Loss:  0.06932981312274933\n",
      "21 **********\n",
      "Epoch:  1199.250447511673  fold:  9  kers:  32\n",
      "epoch:  22\n",
      "29483 461\n",
      "Loss:  0.0804932713508606\n",
      "Loss:  0.08042318373918533\n",
      "Loss:  0.078398197889328\n",
      "22 **********\n",
      "Epoch:  1240.5071353912354  fold:  9  kers:  32\n",
      "epoch:  23\n",
      "29483 461\n",
      "Loss:  0.07987534254789352\n",
      "Loss:  0.08891968429088593\n",
      "Loss:  0.05990384891629219\n",
      "23 **********\n",
      "Epoch:  1281.7628259658813  fold:  9  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.059782348573207855\n",
      "Eval Loss:  1.3604438304901123\n",
      "Eval Loss:  0.17857283353805542\n",
      "[[1660   82]\n",
      " [ 456 1210]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86      1742\n",
      "           1       0.94      0.73      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.86      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8421361502347418\n",
      "pre:  0.9365325077399381\n",
      "rec:  0.7262905162064826\n",
      "ma F1:  0.8393349295528797\n",
      "mi F1:  0.8421361502347418\n",
      "we F1:  0.839808024601372\n",
      "Eval Loss:  0.23415981233119965\n",
      "Eval Loss:  0.2814187705516815\n",
      "Eval Loss:  0.3536895215511322\n",
      "Eval Loss:  0.34780463576316833\n",
      "Eval Loss:  0.3313797116279602\n",
      "Eval Loss:  0.393456369638443\n",
      "Eval Loss:  0.31992170214653015\n",
      "Eval Loss:  0.3465058207511902\n",
      "Eval Loss:  0.26181918382644653\n",
      "Eval Loss:  0.21205005049705505\n",
      "Eval Loss:  0.2718289792537689\n",
      "Eval Loss:  0.2581245005130768\n",
      "Eval Loss:  0.1965751051902771\n",
      "Eval Loss:  0.31690484285354614\n",
      "Eval Loss:  0.21143993735313416\n",
      "Eval Loss:  0.3426869213581085\n",
      "Eval Loss:  0.28390663862228394\n",
      "Eval Loss:  0.28315988183021545\n",
      "Eval Loss:  0.28654584288597107\n",
      "Eval Loss:  0.26059144735336304\n",
      "Eval Loss:  0.2810910940170288\n",
      "Eval Loss:  0.36750537157058716\n",
      "Eval Loss:  0.3276512920856476\n",
      "Eval Loss:  0.21934165060520172\n",
      "Eval Loss:  0.2530558109283447\n",
      "Eval Loss:  0.2578994035720825\n",
      "Eval Loss:  0.24229036271572113\n",
      "Eval Loss:  0.35388848185539246\n",
      "[[17502   920]\n",
      " [ 2549  8512]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18422\n",
      "           1       0.90      0.77      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.89      0.86      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8823389750025439\n",
      "pre:  0.9024597116200169\n",
      "rec:  0.7695506735376548\n",
      "ma F1:  0.8702777777999738\n",
      "mi F1:  0.8823389750025439\n",
      "we F1:  0.8801534699699536\n",
      "29483 461\n",
      "Loss:  0.04741105064749718\n",
      "Loss:  0.09841694682836533\n",
      "Loss:  0.05055483803153038\n",
      "24 **********\n",
      "Epoch:  1362.0361912250519  fold:  9  kers:  32\n",
      "epoch:  25\n",
      "29483 461\n",
      "Loss:  0.05014289915561676\n",
      "Loss:  0.06683723628520966\n",
      "Loss:  0.09299467504024506\n",
      "25 **********\n",
      "Epoch:  1403.4813754558563  fold:  9  kers:  32\n",
      "epoch:  26\n",
      "29483 461\n",
      "Loss:  0.07496549189090729\n",
      "Loss:  0.10661108791828156\n",
      "Loss:  0.06656286120414734\n",
      "26 **********\n",
      "Epoch:  1444.7111353874207  fold:  9  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.05108196288347244\n",
      "Eval Loss:  1.3490409851074219\n",
      "Eval Loss:  0.1632242649793625\n",
      "[[1649   93]\n",
      " [ 441 1225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86      1742\n",
      "           1       0.93      0.74      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.86      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8433098591549296\n",
      "pre:  0.9294385432473444\n",
      "rec:  0.7352941176470589\n",
      "ma F1:  0.8408463790179497\n",
      "mi F1:  0.8433098591549296\n",
      "we F1:  0.8412879462123138\n",
      "Eval Loss:  0.23599591851234436\n",
      "Eval Loss:  0.24436894059181213\n",
      "Eval Loss:  0.36121225357055664\n",
      "Eval Loss:  0.33352506160736084\n",
      "Eval Loss:  0.3071218729019165\n",
      "Eval Loss:  0.3668920695781708\n",
      "Eval Loss:  0.2742489278316498\n",
      "Eval Loss:  0.31319761276245117\n",
      "Eval Loss:  0.2603119909763336\n",
      "Eval Loss:  0.20977258682250977\n",
      "Eval Loss:  0.23832820355892181\n",
      "Eval Loss:  0.2686162292957306\n",
      "Eval Loss:  0.18104326725006104\n",
      "Eval Loss:  0.2811901569366455\n",
      "Eval Loss:  0.19067862629890442\n",
      "Eval Loss:  0.3011797070503235\n",
      "Eval Loss:  0.27444684505462646\n",
      "Eval Loss:  0.28570637106895447\n",
      "Eval Loss:  0.25753453373908997\n",
      "Eval Loss:  0.22306357324123383\n",
      "Eval Loss:  0.25244951248168945\n",
      "Eval Loss:  0.35244831442832947\n",
      "Eval Loss:  0.2990912199020386\n",
      "Eval Loss:  0.2108311504125595\n",
      "Eval Loss:  0.22124354541301727\n",
      "Eval Loss:  0.23255445063114166\n",
      "Eval Loss:  0.2167138308286667\n",
      "Eval Loss:  0.3119727075099945\n",
      "[[17240  1182]\n",
      " [ 2131  8930]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     18422\n",
      "           1       0.88      0.81      0.84     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.887630159753078\n",
      "pre:  0.8831091772151899\n",
      "rec:  0.807341108398879\n",
      "ma F1:  0.8779326986565956\n",
      "mi F1:  0.887630159753078\n",
      "we F1:  0.8865227120297854\n",
      "29483 461\n",
      "Loss:  0.0644354596734047\n",
      "Loss:  0.07012341916561127\n",
      "Loss:  0.06416299939155579\n",
      "27 **********\n",
      "Epoch:  1525.0892207622528  fold:  9  kers:  32\n",
      "epoch:  28\n",
      "29483 461\n",
      "Loss:  0.06799710541963577\n",
      "Loss:  0.07623840123414993\n",
      "Loss:  0.09031736850738525\n",
      "28 **********\n",
      "Epoch:  1566.3608684539795  fold:  9  kers:  32\n",
      "epoch:  29\n",
      "29483 461\n",
      "Loss:  0.09311667084693909\n",
      "Loss:  0.04469102993607521\n",
      "Loss:  0.04626699537038803\n",
      "29 **********\n",
      "Epoch:  1607.6025965213776  fold:  9  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.06018509715795517\n",
      "Eval Loss:  1.0450037717819214\n",
      "Eval Loss:  0.14103958010673523\n",
      "[[1608  134]\n",
      " [ 351 1315]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87      1742\n",
      "           1       0.91      0.79      0.84      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.86      0.86      0.86      3408\n",
      "weighted avg       0.86      0.86      0.86      3408\n",
      "\n",
      "acc:  0.85768779342723\n",
      "pre:  0.9075224292615597\n",
      "rec:  0.7893157262905162\n",
      "ma F1:  0.8566280511579232\n",
      "mi F1:  0.85768779342723\n",
      "we F1:  0.8569029331117366\n",
      "update!  Acc:  0.85768779342723\n",
      "Eval Loss:  0.23971331119537354\n",
      "Eval Loss:  0.225411057472229\n",
      "Eval Loss:  0.3255327641963959\n",
      "Eval Loss:  0.29883164167404175\n",
      "Eval Loss:  0.2984098494052887\n",
      "Eval Loss:  0.37574127316474915\n",
      "Eval Loss:  0.26203247904777527\n",
      "Eval Loss:  0.31608206033706665\n",
      "Eval Loss:  0.23931239545345306\n",
      "Eval Loss:  0.19766302406787872\n",
      "Eval Loss:  0.2087806761264801\n",
      "Eval Loss:  0.2672114372253418\n",
      "Eval Loss:  0.17059043049812317\n",
      "Eval Loss:  0.2550511360168457\n",
      "Eval Loss:  0.1880311220884323\n",
      "Eval Loss:  0.30384892225265503\n",
      "Eval Loss:  0.22233344614505768\n",
      "Eval Loss:  0.28871867060661316\n",
      "Eval Loss:  0.28287237882614136\n",
      "Eval Loss:  0.21849334239959717\n",
      "Eval Loss:  0.24238555133342743\n",
      "Eval Loss:  0.31081637740135193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2962559461593628\n",
      "Eval Loss:  0.19728252291679382\n",
      "Eval Loss:  0.21827788650989532\n",
      "Eval Loss:  0.21805121004581451\n",
      "Eval Loss:  0.19999255239963531\n",
      "Eval Loss:  0.26490068435668945\n",
      "[[17037  1385]\n",
      " [ 1816  9245]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     18422\n",
      "           1       0.87      0.84      0.85     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.88      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8914289590611539\n",
      "pre:  0.8697083725305739\n",
      "rec:  0.8358195461531507\n",
      "ma F1:  0.8832760112377738\n",
      "mi F1:  0.8914289590611539\n",
      "we F1:  0.8909779939030588\n",
      "29483 461\n",
      "Loss:  0.09823168069124222\n",
      "Loss:  0.06851007044315338\n",
      "Loss:  0.04262284189462662\n",
      "30 **********\n",
      "Epoch:  1688.2359993457794  fold:  9  kers:  32\n",
      "epoch:  31\n",
      "29483 461\n",
      "Loss:  0.06478475034236908\n",
      "Loss:  0.08555382490158081\n",
      "Loss:  0.05377001315355301\n",
      "31 **********\n",
      "Epoch:  1729.5874338150024  fold:  9  kers:  32\n",
      "epoch:  32\n",
      "29483 461\n",
      "Loss:  0.08573493361473083\n",
      "Loss:  0.057624876499176025\n",
      "Loss:  0.08546338230371475\n",
      "32 **********\n",
      "Epoch:  1770.9727778434753  fold:  9  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.053301166743040085\n",
      "Eval Loss:  1.0703481435775757\n",
      "Eval Loss:  0.1449374407529831\n",
      "[[1631  111]\n",
      " [ 370 1296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87      1742\n",
      "           1       0.92      0.78      0.84      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.87      0.86      0.86      3408\n",
      "weighted avg       0.87      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8588615023474179\n",
      "pre:  0.9211087420042644\n",
      "rec:  0.7779111644657863\n",
      "ma F1:  0.8574844428115256\n",
      "mi F1:  0.8588615023474179\n",
      "we F1:  0.8577968503480267\n",
      "update!  Acc:  0.8588615023474179\n",
      "Eval Loss:  0.23628059029579163\n",
      "Eval Loss:  0.21864548325538635\n",
      "Eval Loss:  0.32988592982292175\n",
      "Eval Loss:  0.2931375503540039\n",
      "Eval Loss:  0.2953086495399475\n",
      "Eval Loss:  0.37036624550819397\n",
      "Eval Loss:  0.252027690410614\n",
      "Eval Loss:  0.32187148928642273\n",
      "Eval Loss:  0.23584520816802979\n",
      "Eval Loss:  0.1912839710712433\n",
      "Eval Loss:  0.20669056475162506\n",
      "Eval Loss:  0.2604733109474182\n",
      "Eval Loss:  0.16700685024261475\n",
      "Eval Loss:  0.24768181145191193\n",
      "Eval Loss:  0.1890997737646103\n",
      "Eval Loss:  0.30601766705513\n",
      "Eval Loss:  0.2364756166934967\n",
      "Eval Loss:  0.2835356295108795\n",
      "Eval Loss:  0.25300735235214233\n",
      "Eval Loss:  0.21315045654773712\n",
      "Eval Loss:  0.25497502088546753\n",
      "Eval Loss:  0.31107741594314575\n",
      "Eval Loss:  0.29727447032928467\n",
      "Eval Loss:  0.18815864622592926\n",
      "Eval Loss:  0.21777500212192535\n",
      "Eval Loss:  0.22058001160621643\n",
      "Eval Loss:  0.21998685598373413\n",
      "Eval Loss:  0.26927027106285095\n",
      "[[17067  1355]\n",
      " [ 1780  9281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18422\n",
      "           1       0.87      0.84      0.86     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.88      0.89     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8936675372248414\n",
      "pre:  0.8726024821361414\n",
      "rec:  0.8390742247536389\n",
      "ma F1:  0.8856959052118334\n",
      "mi F1:  0.8936675372248414\n",
      "we F1:  0.8932324044730396\n",
      "29483 461\n",
      "Loss:  0.08152644336223602\n",
      "Loss:  0.061211083084344864\n",
      "Loss:  0.08408503979444504\n",
      "33 **********\n",
      "Epoch:  1851.466553926468  fold:  9  kers:  32\n",
      "epoch:  34\n",
      "29483 461\n",
      "Loss:  0.06225759536027908\n",
      "Loss:  0.059694427996873856\n",
      "Loss:  0.059000805020332336\n",
      "34 **********\n",
      "Epoch:  1892.8479084968567  fold:  9  kers:  32\n",
      "epoch:  35\n",
      "29483 461\n",
      "Loss:  0.05697209760546684\n",
      "Loss:  0.060642410069704056\n",
      "Loss:  0.05015679448843002\n",
      "35 **********\n",
      "Epoch:  1934.1953537464142  fold:  9  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.04804137349128723\n",
      "Eval Loss:  1.0479978322982788\n",
      "Eval Loss:  0.12661707401275635\n",
      "[[1628  114]\n",
      " [ 335 1331]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      1742\n",
      "           1       0.92      0.80      0.86      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.88      0.87      0.87      3408\n",
      "weighted avg       0.87      0.87      0.87      3408\n",
      "\n",
      "acc:  0.8682511737089202\n",
      "pre:  0.9211072664359862\n",
      "rec:  0.7989195678271308\n",
      "ma F1:  0.8672429162811337\n",
      "mi F1:  0.8682511737089202\n",
      "we F1:  0.8675009215488501\n",
      "update!  Acc:  0.8682511737089202\n",
      "Eval Loss:  0.25810134410858154\n",
      "Eval Loss:  0.21423622965812683\n",
      "Eval Loss:  0.3009624779224396\n",
      "Eval Loss:  0.2935291826725006\n",
      "Eval Loss:  0.2771250903606415\n",
      "Eval Loss:  0.36736539006233215\n",
      "Eval Loss:  0.23970182240009308\n",
      "Eval Loss:  0.3199828863143921\n",
      "Eval Loss:  0.24743562936782837\n",
      "Eval Loss:  0.18751537799835205\n",
      "Eval Loss:  0.2025296986103058\n",
      "Eval Loss:  0.29038846492767334\n",
      "Eval Loss:  0.17383790016174316\n",
      "Eval Loss:  0.23690228164196014\n",
      "Eval Loss:  0.18171779811382294\n",
      "Eval Loss:  0.30221885442733765\n",
      "Eval Loss:  0.20765334367752075\n",
      "Eval Loss:  0.30615055561065674\n",
      "Eval Loss:  0.25626805424690247\n",
      "Eval Loss:  0.1863616555929184\n",
      "Eval Loss:  0.2341247946023941\n",
      "Eval Loss:  0.29966726899147034\n",
      "Eval Loss:  0.2745988965034485\n",
      "Eval Loss:  0.18252010643482208\n",
      "Eval Loss:  0.21557925641536713\n",
      "Eval Loss:  0.2090969681739807\n",
      "Eval Loss:  0.201337993144989\n",
      "Eval Loss:  0.24151301383972168\n",
      "[[16907  1515]\n",
      " [ 1590  9471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     18422\n",
      "           1       0.86      0.86      0.86     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.89      0.89     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8946850727537903\n",
      "pre:  0.8620972146368104\n",
      "rec:  0.8562516951451045\n",
      "ma F1:  0.8875307379007973\n",
      "mi F1:  0.8946850727537903\n",
      "we F1:  0.8946129136475539\n",
      "29483 461\n",
      "Loss:  0.08390799164772034\n",
      "Loss:  0.0873914286494255\n",
      "Loss:  0.052626486867666245\n",
      "36 **********\n",
      "Epoch:  2014.6272957324982  fold:  9  kers:  32\n",
      "epoch:  37\n",
      "29483 461\n",
      "Loss:  0.060577817261219025\n",
      "Loss:  0.06580408662557602\n",
      "Loss:  0.06476143002510071\n",
      "37 **********\n",
      "Epoch:  2055.847081899643  fold:  9  kers:  32\n",
      "epoch:  38\n",
      "29483 461\n",
      "Loss:  0.05462134629487991\n",
      "Loss:  0.06251294910907745\n",
      "Loss:  0.07972721010446548\n",
      "38 **********\n",
      "Epoch:  2097.0678658485413  fold:  9  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.04434170946478844\n",
      "Eval Loss:  0.9630504846572876\n",
      "Eval Loss:  0.14819394052028656\n",
      "[[1640  102]\n",
      " [ 351 1315]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      1742\n",
      "           1       0.93      0.79      0.85      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.88      0.87      0.87      3408\n",
      "weighted avg       0.87      0.87      0.87      3408\n",
      "\n",
      "acc:  0.8670774647887324\n",
      "pre:  0.9280169371912491\n",
      "rec:  0.7893157262905162\n",
      "ma F1:  0.8658575378454769\n",
      "mi F1:  0.8670774647887324\n",
      "we F1:  0.8661428130691304\n",
      "Eval Loss:  0.236587256193161\n",
      "Eval Loss:  0.2168014496564865\n",
      "Eval Loss:  0.3035558760166168\n",
      "Eval Loss:  0.26238635182380676\n",
      "Eval Loss:  0.28842246532440186\n",
      "Eval Loss:  0.3382290005683899\n",
      "Eval Loss:  0.2642561197280884\n",
      "Eval Loss:  0.3249239921569824\n",
      "Eval Loss:  0.22117669880390167\n",
      "Eval Loss:  0.1906747817993164\n",
      "Eval Loss:  0.2071061134338379\n",
      "Eval Loss:  0.2591765820980072\n",
      "Eval Loss:  0.16228368878364563\n",
      "Eval Loss:  0.2404269427061081\n",
      "Eval Loss:  0.19121934473514557\n",
      "Eval Loss:  0.30893030762672424\n",
      "Eval Loss:  0.1967647671699524\n",
      "Eval Loss:  0.2660435736179352\n",
      "Eval Loss:  0.25116685032844543\n",
      "Eval Loss:  0.19691382348537445\n",
      "Eval Loss:  0.24130190908908844\n",
      "Eval Loss:  0.29946979880332947\n",
      "Eval Loss:  0.27272456884384155\n",
      "Eval Loss:  0.18817138671875\n",
      "Eval Loss:  0.2155475914478302\n",
      "Eval Loss:  0.2172640860080719\n",
      "Eval Loss:  0.1872621476650238\n",
      "Eval Loss:  0.26900961995124817\n",
      "[[17347  1075]\n",
      " [ 1961  9100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18422\n",
      "           1       0.89      0.82      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8970254044703727\n",
      "pre:  0.8943488943488943\n",
      "rec:  0.8227104240122954\n",
      "ma F1:  0.888284375451335\n",
      "mi F1:  0.8970254044703727\n",
      "we F1:  0.8960863294478353\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04934817552566528\n",
      "Loss:  0.08686873316764832\n",
      "Loss:  0.04378635808825493\n",
      "39 **********\n",
      "Epoch:  2177.561641931534  fold:  9  kers:  32\n",
      "epoch:  40\n",
      "29483 461\n",
      "Loss:  0.0662636011838913\n",
      "Loss:  0.08530723303556442\n",
      "Loss:  0.07061951607465744\n",
      "40 **********\n",
      "Epoch:  2218.862212896347  fold:  9  kers:  32\n",
      "epoch:  41\n",
      "29483 461\n",
      "Loss:  0.05597013235092163\n",
      "Loss:  0.07549560070037842\n",
      "Loss:  0.05486278980970383\n",
      "41 **********\n",
      "Epoch:  2260.1777431964874  fold:  9  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.03745904937386513\n",
      "Eval Loss:  1.2327972650527954\n",
      "Eval Loss:  0.13189786672592163\n",
      "[[1649   93]\n",
      " [ 396 1270]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87      1742\n",
      "           1       0.93      0.76      0.84      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.87      0.85      0.85      3408\n",
      "weighted avg       0.87      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8565140845070423\n",
      "pre:  0.9317681584739546\n",
      "rec:  0.7623049219687875\n",
      "ma F1:  0.854717311913888\n",
      "mi F1:  0.8565140845070423\n",
      "we F1:  0.8550776145974757\n",
      "Eval Loss:  0.2597860097885132\n",
      "Eval Loss:  0.231822207570076\n",
      "Eval Loss:  0.29031431674957275\n",
      "Eval Loss:  0.2721250653266907\n",
      "Eval Loss:  0.2743314206600189\n",
      "Eval Loss:  0.32676151394844055\n",
      "Eval Loss:  0.2354855239391327\n",
      "Eval Loss:  0.3184734582901001\n",
      "Eval Loss:  0.24243298172950745\n",
      "Eval Loss:  0.16670919954776764\n",
      "Eval Loss:  0.20291021466255188\n",
      "Eval Loss:  0.2606622278690338\n",
      "Eval Loss:  0.16451671719551086\n",
      "Eval Loss:  0.24309119582176208\n",
      "Eval Loss:  0.1730789840221405\n",
      "Eval Loss:  0.30501607060432434\n",
      "Eval Loss:  0.20758002996444702\n",
      "Eval Loss:  0.26868030428886414\n",
      "Eval Loss:  0.23266556859016418\n",
      "Eval Loss:  0.1768082231283188\n",
      "Eval Loss:  0.2577742338180542\n",
      "Eval Loss:  0.3186831474304199\n",
      "Eval Loss:  0.23566070199012756\n",
      "Eval Loss:  0.17500361800193787\n",
      "Eval Loss:  0.20703741908073425\n",
      "Eval Loss:  0.20764152705669403\n",
      "Eval Loss:  0.1955646127462387\n",
      "Eval Loss:  0.25790920853614807\n",
      "[[17302  1120]\n",
      " [ 1813  9248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     18422\n",
      "           1       0.89      0.84      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.89      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9005189431197639\n",
      "pre:  0.8919753086419753\n",
      "rec:  0.836090769369858\n",
      "ma F1:  0.892496582583822\n",
      "mi F1:  0.9005189431197639\n",
      "we F1:  0.8998286655121892\n",
      "29483 461\n",
      "Loss:  0.05878907069563866\n",
      "Loss:  0.07038932293653488\n",
      "Loss:  0.08615383505821228\n",
      "42 **********\n",
      "Epoch:  2340.446121931076  fold:  9  kers:  32\n",
      "epoch:  43\n",
      "29483 461\n",
      "Loss:  0.06598759442567825\n",
      "Loss:  0.06923514604568481\n",
      "Loss:  0.0358775332570076\n",
      "43 **********\n",
      "Epoch:  2381.8145112991333  fold:  9  kers:  32\n",
      "epoch:  44\n",
      "29483 461\n",
      "Loss:  0.07439245283603668\n",
      "Loss:  0.05490538105368614\n",
      "Loss:  0.10946133732795715\n",
      "44 **********\n",
      "Epoch:  2423.0981273651123  fold:  9  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.037680551409721375\n",
      "Eval Loss:  1.165984869003296\n",
      "Eval Loss:  0.14778266847133636\n",
      "[[1680   62]\n",
      " [ 450 1216]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87      1742\n",
      "           1       0.95      0.73      0.83      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.87      0.85      0.85      3408\n",
      "weighted avg       0.87      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8497652582159625\n",
      "pre:  0.9514866979655712\n",
      "rec:  0.7298919567827131\n",
      "ma F1:  0.8469277757815308\n",
      "mi F1:  0.8497652582159625\n",
      "we F1:  0.8473925358354464\n",
      "Eval Loss:  0.23504571616649628\n",
      "Eval Loss:  0.22877269983291626\n",
      "Eval Loss:  0.31736382842063904\n",
      "Eval Loss:  0.276911199092865\n",
      "Eval Loss:  0.2772962152957916\n",
      "Eval Loss:  0.2932129204273224\n",
      "Eval Loss:  0.2576427757740021\n",
      "Eval Loss:  0.31463709473609924\n",
      "Eval Loss:  0.23475773632526398\n",
      "Eval Loss:  0.171578049659729\n",
      "Eval Loss:  0.21230050921440125\n",
      "Eval Loss:  0.24379600584506989\n",
      "Eval Loss:  0.1710694432258606\n",
      "Eval Loss:  0.23870226740837097\n",
      "Eval Loss:  0.18383775651454926\n",
      "Eval Loss:  0.3078990876674652\n",
      "Eval Loss:  0.200691357254982\n",
      "Eval Loss:  0.2618386149406433\n",
      "Eval Loss:  0.22426176071166992\n",
      "Eval Loss:  0.2017708718776703\n",
      "Eval Loss:  0.26170727610588074\n",
      "Eval Loss:  0.30150383710861206\n",
      "Eval Loss:  0.25811365246772766\n",
      "Eval Loss:  0.1882256120443344\n",
      "Eval Loss:  0.2019108235836029\n",
      "Eval Loss:  0.2204732894897461\n",
      "Eval Loss:  0.18141795694828033\n",
      "Eval Loss:  0.2892778813838959\n",
      "[[17590   832]\n",
      " [ 2154  8907]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18422\n",
      "           1       0.91      0.81      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8987212970186209\n",
      "pre:  0.9145702844234521\n",
      "rec:  0.8052617304041226\n",
      "ma F1:  0.8891025666219229\n",
      "mi F1:  0.8987212970186209\n",
      "we F1:  0.8972568306378269\n",
      "29483 461\n",
      "Loss:  0.11322067677974701\n",
      "Loss:  0.04465998709201813\n",
      "Loss:  0.04393976181745529\n",
      "45 **********\n",
      "Epoch:  2503.537050008774  fold:  9  kers:  32\n",
      "epoch:  46\n",
      "29483 461\n",
      "Loss:  0.06814049929380417\n",
      "Loss:  0.07944800704717636\n",
      "Loss:  0.08011732995510101\n",
      "46 **********\n",
      "Epoch:  2544.8126876354218  fold:  9  kers:  32\n",
      "epoch:  47\n",
      "29483 461\n",
      "Loss:  0.07299923896789551\n",
      "Loss:  0.060761887580156326\n",
      "Loss:  0.0774955227971077\n",
      "47 **********\n",
      "Epoch:  2586.1840686798096  fold:  9  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.0367853119969368\n",
      "Eval Loss:  1.1569390296936035\n",
      "Eval Loss:  0.14877478778362274\n",
      "[[1666   76]\n",
      " [ 400 1266]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      1742\n",
      "           1       0.94      0.76      0.84      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.87      0.86      0.86      3408\n",
      "weighted avg       0.87      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8603286384976526\n",
      "pre:  0.9433681073025335\n",
      "rec:  0.7599039615846338\n",
      "ma F1:  0.8583776595744681\n",
      "mi F1:  0.8603286384976526\n",
      "we F1:  0.8587483455698732\n",
      "Eval Loss:  0.23697781562805176\n",
      "Eval Loss:  0.2201751172542572\n",
      "Eval Loss:  0.29228293895721436\n",
      "Eval Loss:  0.2629089057445526\n",
      "Eval Loss:  0.2703280746936798\n",
      "Eval Loss:  0.3049340546131134\n",
      "Eval Loss:  0.24858175218105316\n",
      "Eval Loss:  0.30447134375572205\n",
      "Eval Loss:  0.22912465035915375\n",
      "Eval Loss:  0.17286279797554016\n",
      "Eval Loss:  0.19493523240089417\n",
      "Eval Loss:  0.24827593564987183\n",
      "Eval Loss:  0.16108636558055878\n",
      "Eval Loss:  0.23161520063877106\n",
      "Eval Loss:  0.17162232100963593\n",
      "Eval Loss:  0.2932986617088318\n",
      "Eval Loss:  0.18313539028167725\n",
      "Eval Loss:  0.2492438405752182\n",
      "Eval Loss:  0.21842972934246063\n",
      "Eval Loss:  0.17858058214187622\n",
      "Eval Loss:  0.2513052225112915\n",
      "Eval Loss:  0.30138254165649414\n",
      "Eval Loss:  0.24257583916187286\n",
      "Eval Loss:  0.16564913094043732\n",
      "Eval Loss:  0.21081039309501648\n",
      "Eval Loss:  0.19376471638679504\n",
      "Eval Loss:  0.17432014644145966\n",
      "Eval Loss:  0.2603148818016052\n",
      "[[17440   982]\n",
      " [ 1872  9189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18422\n",
      "           1       0.90      0.83      0.87     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.89      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.903198453345996\n",
      "pre:  0.9034509881034313\n",
      "rec:  0.8307567127746135\n",
      "ma F1:  0.8949727750582159\n",
      "mi F1:  0.903198453345996\n",
      "we F1:  0.9023111846905452\n",
      "29483 461\n",
      "Loss:  0.06653660535812378\n",
      "Loss:  0.0922762006521225\n",
      "Loss:  0.05805302411317825\n",
      "48 **********\n",
      "Epoch:  2666.463418006897  fold:  9  kers:  32\n",
      "epoch:  49\n",
      "29483 461\n",
      "Loss:  0.04843224212527275\n",
      "Loss:  0.09398401528596878\n",
      "Loss:  0.06960245221853256\n",
      "49 **********\n",
      "Epoch:  2707.705146074295  fold:  9  kers:  32\n",
      "epoch:  50\n",
      "29483 461\n",
      "Loss:  0.0594751201570034\n",
      "Loss:  0.08169858902692795\n",
      "Loss:  0.094646155834198\n",
      "50 **********\n",
      "Epoch:  2748.9488685131073  fold:  9  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.03843718022108078\n",
      "Eval Loss:  0.9702443480491638\n",
      "Eval Loss:  0.13409487903118134\n",
      "[[1635  107]\n",
      " [ 326 1340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      1742\n",
      "           1       0.93      0.80      0.86      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.88      0.87      0.87      3408\n",
      "weighted avg       0.88      0.87      0.87      3408\n",
      "\n",
      "acc:  0.8729460093896714\n",
      "pre:  0.9260539046302695\n",
      "rec:  0.8043217286914766\n",
      "ma F1:  0.8719868307262351\n",
      "mi F1:  0.8729460093896714\n",
      "we F1:  0.872233941161561\n",
      "update!  Acc:  0.8729460093896714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2524928152561188\n",
      "Eval Loss:  0.20529226958751678\n",
      "Eval Loss:  0.28700578212738037\n",
      "Eval Loss:  0.25154685974121094\n",
      "Eval Loss:  0.2607329487800598\n",
      "Eval Loss:  0.3005107641220093\n",
      "Eval Loss:  0.24172599613666534\n",
      "Eval Loss:  0.29108288884162903\n",
      "Eval Loss:  0.21082749962806702\n",
      "Eval Loss:  0.17771318554878235\n",
      "Eval Loss:  0.1787668764591217\n",
      "Eval Loss:  0.24180404841899872\n",
      "Eval Loss:  0.1558290719985962\n",
      "Eval Loss:  0.21565525233745575\n",
      "Eval Loss:  0.16773611307144165\n",
      "Eval Loss:  0.30417609214782715\n",
      "Eval Loss:  0.17638644576072693\n",
      "Eval Loss:  0.25182899832725525\n",
      "Eval Loss:  0.22114714980125427\n",
      "Eval Loss:  0.18680548667907715\n",
      "Eval Loss:  0.22998645901679993\n",
      "Eval Loss:  0.2665373980998993\n",
      "Eval Loss:  0.25686898827552795\n",
      "Eval Loss:  0.16266094148159027\n",
      "Eval Loss:  0.20713727176189423\n",
      "Eval Loss:  0.17629411816596985\n",
      "Eval Loss:  0.18082968890666962\n",
      "Eval Loss:  0.25206735730171204\n",
      "[[17260  1162]\n",
      " [ 1626  9435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18422\n",
      "           1       0.89      0.85      0.87     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.90      0.89      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9054370315096836\n",
      "pre:  0.8903463244314429\n",
      "rec:  0.8529970165446162\n",
      "ma F1:  0.8982711524870235\n",
      "mi F1:  0.9054370315096835\n",
      "we F1:  0.9050121154884038\n",
      "29483 461\n",
      "Loss:  0.06248088181018829\n",
      "Loss:  0.044781871140003204\n",
      "Loss:  0.07679450511932373\n",
      "51 **********\n",
      "Epoch:  2829.562324523926  fold:  9  kers:  32\n",
      "epoch:  52\n",
      "29483 461\n",
      "Loss:  0.07201037555932999\n",
      "Loss:  0.044552288949489594\n",
      "Loss:  0.03238402679562569\n",
      "52 **********\n",
      "Epoch:  2870.8838396072388  fold:  9  kers:  32\n",
      "epoch:  53\n",
      "29483 461\n",
      "Loss:  0.061816565692424774\n",
      "Loss:  0.06859590113162994\n",
      "Loss:  0.05685516819357872\n",
      "53 **********\n",
      "Epoch:  2912.251230955124  fold:  9  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.033940307796001434\n",
      "Eval Loss:  1.0068997144699097\n",
      "Eval Loss:  0.11391272395849228\n",
      "[[1659   83]\n",
      " [ 357 1309]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1742\n",
      "           1       0.94      0.79      0.86      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.88      0.87      0.87      3408\n",
      "weighted avg       0.88      0.87      0.87      3408\n",
      "\n",
      "acc:  0.8708920187793427\n",
      "pre:  0.9403735632183908\n",
      "rec:  0.7857142857142857\n",
      "ma F1:  0.8695157764155892\n",
      "mi F1:  0.8708920187793427\n",
      "we F1:  0.8698146176145757\n",
      "Eval Loss:  0.26566082239151\n",
      "Eval Loss:  0.17854224145412445\n",
      "Eval Loss:  0.2966686189174652\n",
      "Eval Loss:  0.2580660283565521\n",
      "Eval Loss:  0.24488136172294617\n",
      "Eval Loss:  0.28696557879447937\n",
      "Eval Loss:  0.23031261563301086\n",
      "Eval Loss:  0.2757955491542816\n",
      "Eval Loss:  0.2323240339756012\n",
      "Eval Loss:  0.17809920012950897\n",
      "Eval Loss:  0.17648981511592865\n",
      "Eval Loss:  0.25124117732048035\n",
      "Eval Loss:  0.16642731428146362\n",
      "Eval Loss:  0.19908732175827026\n",
      "Eval Loss:  0.17048002779483795\n",
      "Eval Loss:  0.28958383202552795\n",
      "Eval Loss:  0.17693789303302765\n",
      "Eval Loss:  0.2742674946784973\n",
      "Eval Loss:  0.21677324175834656\n",
      "Eval Loss:  0.16459010541439056\n",
      "Eval Loss:  0.2355184704065323\n",
      "Eval Loss:  0.2786186933517456\n",
      "Eval Loss:  0.25101494789123535\n",
      "Eval Loss:  0.16654600203037262\n",
      "Eval Loss:  0.20939745008945465\n",
      "Eval Loss:  0.17199872434139252\n",
      "Eval Loss:  0.19281908869743347\n",
      "Eval Loss:  0.24610580503940582\n",
      "[[17099  1323]\n",
      " [ 1458  9603]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     18422\n",
      "           1       0.88      0.87      0.87     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.90      0.90      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9056744564664383\n",
      "pre:  0.8789126853377265\n",
      "rec:  0.8681855166802278\n",
      "ma F1:  0.8991556613257181\n",
      "mi F1:  0.9056744564664383\n",
      "we F1:  0.9055570555400779\n",
      "29483 461\n",
      "Loss:  0.05397461727261543\n",
      "Loss:  0.042353011667728424\n",
      "Loss:  0.06864237040281296\n",
      "54 **********\n",
      "Epoch:  2992.762959241867  fold:  9  kers:  32\n",
      "epoch:  55\n",
      "29483 461\n",
      "Loss:  0.053352225571870804\n",
      "Loss:  0.051384761929512024\n",
      "Loss:  0.049086667597293854\n",
      "55 **********\n",
      "Epoch:  3034.0435836315155  fold:  9  kers:  32\n",
      "epoch:  56\n",
      "29483 461\n",
      "Loss:  0.06429754197597504\n",
      "Loss:  0.06340966373682022\n",
      "Loss:  0.03835277631878853\n",
      "56 **********\n",
      "Epoch:  3075.550602197647  fold:  9  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.03899040073156357\n",
      "Eval Loss:  0.9839977622032166\n",
      "Eval Loss:  0.10638340562582016\n",
      "[[1614  128]\n",
      " [ 300 1366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      1742\n",
      "           1       0.91      0.82      0.86      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.88      0.87      0.87      3408\n",
      "weighted avg       0.88      0.87      0.87      3408\n",
      "\n",
      "acc:  0.8744131455399061\n",
      "pre:  0.9143239625167336\n",
      "rec:  0.8199279711884754\n",
      "ma F1:  0.8737445641636428\n",
      "mi F1:  0.8744131455399061\n",
      "we F1:  0.8739494520047557\n",
      "update!  Acc:  0.8744131455399061\n",
      "Eval Loss:  0.2724486291408539\n",
      "Eval Loss:  0.16511975228786469\n",
      "Eval Loss:  0.26461219787597656\n",
      "Eval Loss:  0.2365400642156601\n",
      "Eval Loss:  0.233761265873909\n",
      "Eval Loss:  0.2832663357257843\n",
      "Eval Loss:  0.21882019937038422\n",
      "Eval Loss:  0.27707231044769287\n",
      "Eval Loss:  0.20937275886535645\n",
      "Eval Loss:  0.1754046082496643\n",
      "Eval Loss:  0.17649374902248383\n",
      "Eval Loss:  0.24751245975494385\n",
      "Eval Loss:  0.15980342030525208\n",
      "Eval Loss:  0.21232610940933228\n",
      "Eval Loss:  0.16530093550682068\n",
      "Eval Loss:  0.2898734509944916\n",
      "Eval Loss:  0.1757245510816574\n",
      "Eval Loss:  0.24762850999832153\n",
      "Eval Loss:  0.19963635504245758\n",
      "Eval Loss:  0.16829708218574524\n",
      "Eval Loss:  0.21876420080661774\n",
      "Eval Loss:  0.26426321268081665\n",
      "Eval Loss:  0.24568721652030945\n",
      "Eval Loss:  0.16485393047332764\n",
      "Eval Loss:  0.20884506404399872\n",
      "Eval Loss:  0.17274583876132965\n",
      "Eval Loss:  0.19908395409584045\n",
      "Eval Loss:  0.22470197081565857\n",
      "[[17003  1419]\n",
      " [ 1270  9791]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     18422\n",
      "           1       0.87      0.89      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.90      0.90      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9087948987552149\n",
      "pre:  0.8734165923282783\n",
      "rec:  0.8851821715938885\n",
      "ma F1:  0.9029901429314011\n",
      "mi F1:  0.9087948987552149\n",
      "we F1:  0.9089148250749248\n",
      "29483 461\n",
      "Loss:  0.06921956688165665\n",
      "Loss:  0.07692024111747742\n",
      "Loss:  0.07201072573661804\n",
      "57 **********\n",
      "Epoch:  3156.080281972885  fold:  9  kers:  32\n",
      "epoch:  58\n",
      "29483 461\n",
      "Loss:  0.06703852117061615\n",
      "Loss:  0.08531054854393005\n",
      "Loss:  0.09570740908384323\n",
      "58 **********\n",
      "Epoch:  3197.559375524521  fold:  9  kers:  32\n",
      "epoch:  59\n",
      "29483 461\n",
      "Loss:  0.06330710649490356\n",
      "Loss:  0.09695391356945038\n",
      "Loss:  0.04416341334581375\n",
      "59 **********\n",
      "Epoch:  3238.9217805862427  fold:  9  kers:  32\n",
      "Eval Loss:  0.028069229796528816\n",
      "Eval Loss:  1.2441349029541016\n",
      "Eval Loss:  0.14324018359184265\n",
      "[[1661   81]\n",
      " [ 394 1272]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87      1742\n",
      "           1       0.94      0.76      0.84      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.87      0.86      0.86      3408\n",
      "weighted avg       0.87      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8606220657276995\n",
      "pre:  0.9401330376940134\n",
      "rec:  0.7635054021608644\n",
      "ma F1:  0.8587821856536204\n",
      "mi F1:  0.8606220657276995\n",
      "we F1:  0.859141648084546\n",
      "update!  Acc:  0.8744131455399061\n",
      "Epoch:  3242.9799299240112  fold:  9  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0BElEQVR4nO3dd3wUdfoH8M+TBoReQkBaKKFZaAGRKiL9BPVOhbsfYkU8ELHcHeqpeOqJnqjnyYGgeOApqGdD6SDSBCG0UAMhBAiEEHoJSQh5fn/sbJhsZndndmd3dnee9+vFK7NTv99smGfmW4mZIYQQwn6irE6AEEIIa0gAEEIIm5IAIIQQNiUBQAghbEoCgBBC2FSM1Qkwok6dOpyUlGR1MoQQIqxs3rz5JDMnuK4PqwCQlJSE1NRUq5MhhBBhhYgOaa2XIiAhhLApCQBCCGFTEgCEEMKmJAAIIYRNSQAQQgibkgAghBA2JQFACCFsSgKAhp1Hz2HbkbNWJ0MIIQIqrDqCBctv/rUWAJA1eYjFKRFCiMCRNwAhhLApCQBCCGFTEgCEEMKmJAAIIYRNSQAQQgibkgAghBA2JQFACCFsyhYBIC37LKYsTbc6GUIIEVJsEQCGfrAO//opA8xsdVKEECJk2CIAOF0oLLY6CUIIETJsFQBe+m6n1UkQQoiQYasA8N22Y1YnQQghQoauAEBEA4konYgyiGiixvbWRLSeiAqJ6FnV+lZEtE317zwRTVC2TSKio6ptg03LlRcH8i7i8Kn8YF1OCCFCktfRQIkoGsBUAP0AZAPYRETzmXm3arfTAMYDuFN9LDOnA2ivOs9RAN+qdnmXmd/2I/0+6TtlFQAZ7VMIYW963gC6AMhg5kxmLgIwD8Aw9Q7MfIKZNwG44uE8fQEcYOZDPqfWBE/M3Vq6nDRxAX4/cwOOnyuwMEVCCGENPQGgAYAjqs/ZyjqjhgOY67JuHBGlEdEsIqqpdRARjSaiVCJKzcvL8+GyZf2wvWw9wC8HTuHVH3e72VsIISKXngBAGusMNagnojgAQwF8pVo9DUBzOIqIcgBM0TqWmWcwcwozpyQkJBi5bKnbWtf16TghhIhkegJANoBGqs8NARhtTjMIwBZmznWuYOZcZr7KzCUAZsJR1BQQfdt4DgBsLJ4JIURE0BMANgFIJqKmypP8cADzDV5nBFyKf4iovurjXQAC1kj/910aB+rUQggRtry2AmLmYiIaB2AJgGgAs5h5FxGNUbZPJ6J6AFIBVANQojT1bMvM54koHo4WRI+5nPotImoPR3FSlsZ20xBplWIJIYS96ZoUnpkXAljosm66avk4HEVDWsfmA6itsX6koZQGkAwRJISwI1v1BBZCCHGNbQJAszqV3W7LOHExiCkRQojQYJsAEBfjPqv7JQAIIWzINgHglaHXe9w+9IO12HbkbHASI4QQIcA2AaBlYlWP29Oyz+GVH3YFKTVCCGE92wSAmpXjrE6CEEKEFNsEACGEEGVJABBCCJuSACCEEDZlqwDwTL+WVidBCCFChq0CQOemtaxOghBChAxbBYAuSRIAhBDCyVYBICoqdEYF/WLTYSRNXIBzlz3NoimEEIFjqwAQSmatzQIA5Jy7bG1ChBC2JQFAZevhszh5sdDqZAghRFBIAHCRmXdJc/30VQdw8KT2tlD3+H8347NfD1mdDCFEiJEA4OKxT1NLl9Oyz4KZce7yFUxetBcjZmywMGW+W7TzOF74NmAzbgohwpTtAkCl2GiP28/kX6uUHfrBOkxflQnnnPH5RcVYsSfX1IrbSJqN7OTFQhQVl1idDCGETrYLAHteHWho/zcX7y1dPl9QjIdnp2LsZ1v8TodV0xSfuVSESfN3BeRGnfLackz4Yqvp5xVCBIbtAoAZsk5dwpr9eX7dRH158s8+k4+dR8/5fE0AeGPRHvznlyz8sP2YX+dxZ+GO4wE5rxDCfLoCABENJKJ0Isogooka21sT0XoiKiSiZ122ZRHRDiLaRkSpqvW1iGgZEe1Xftb0PzvBkX3mMkZ+vBH/WLLX+85eEDluyk/O8/7k3OPNlfjNv9b6db3iEkfkiaCSJyGEj7wGACKKBjAVwCAAbQGMIKK2LrudBjAewNtuTtOHmdszc4pq3UQAK5g5GcAK5XNYcddiyKgPV2Xi+22BeSIXQgh39LwBdAGQwcyZzFwEYB6AYeodmPkEM28CYKR2dBiA2crybAB3Gjg2qFjn8/Kpi4VYsSfX2LktehTnSKp9FkL4RE8AaADgiOpztrJOLwawlIg2E9Fo1fpEZs4BAOVnXa2DiWg0EaUSUWpeXp6By5rnxAXtzmGn84vKfH7gk014eHYqLhUWez2nVZXAhNAZDmPm6ky8sXCP1ckQwrb0BACtO4aRx8fuzNwRjiKksUTUy8CxYOYZzJzCzCkJCQlGDjXNjNWZmuu3Hj5b5nOW0lHsqvJ0vXhnDlbvsyZouXPucpH3nYLk9YV78KGb360QIvD0BIBsAI1UnxsC0F1gzczHlJ8nAHwLR5ESAOQSUX0AUH6e0HvOcDHmv1tw/6yNOHI63+qkAAD+8NEGLN/j+DWfvhQ6gUAIYQ09AWATgGQiakpEcQCGA5iv5+REVJmIqjqXAfQH4OySOh/AKGV5FIDvjSQ8mPwtLu/51krTz+mLdRmnSpevXHXfhDX3fAH2Hj8fjCQJISwU420HZi4monEAlgCIBjCLmXcR0Rhl+3QiqgcgFUA1ACVENAGOFkN1AHxLjgLvGACfM/Ni5dSTAXxJRA8DOAzgHlNzZoFIqVbt+sYKMANZk4dYnRQhRAB5DQAAwMwLASx0WTddtXwcjqIhV+cBtHNzzlMA+upOqYlaJlbBvtyLuvf31goov6gYlwqvln7WU81qtBK42MMTu9mkgZAQ1li+OxclzOh/fb2gXM+WPYG/frybqee7a+ov6Pz6clPP6Wrc5zLEghCR7pE5qRj96eagXc+WAaBqxVjTzvXT3lyk514AAFzU0fzTV4t3mTvEQiCf8pMmLkDu+YLAXUAIYQpbBgCjvtly1O22LzYdcbvNV5cKi5GWfRYAUFh8FX3e/rnM9i2Hz5h+TbPtyPZvzCIhzHKh4Iquvjl2ZNsA4G1YaL2W7Crf85eIsC7jpK7jtZ7En5i7FUM/WIfsM/l4c1F6uYlo7v73L9ivvHW4ulhYrOvma1VHNCGC7cZJS9HptWVWJyMk2TYAjOjSOGDnPph3CX/46FfNbVdL3Je9vLM0HTdNWoLtR84CcASCWesOau6rnrdA7dHZqbjjg7UoLL6qud2JIjAClJQwPl57EAVXPOdd2E/BFZmnQottA0CNePPqAVxdKCh/c161Lw+frDuI5s8vxPfbrhUpqe/D7/+UgfMF115VT1003lnLWTzkrYw/EscC+iHtGF79cTemLE23OilChAVdzUAj0ZjezfHOsn1Bu96oWRtLlxfJmPkBkV/kePK/UCDlvULb2fwixMVEIT7Otre+Mmz7BhAXE8CsGyhdWb7b/eihekchtVLu+QIcyNPfp0IIK7X/2zIMfG+N1ckIGbYNAKFiisZbiLNYyFMpzVKNZqHTVx1AoZ9TPWrVHZSUMDZlndbc/+a/r0DfKavKrf/14Cm0fGERzsiYQyLEHA6RsblCgQQACyzedRx7j2u34tHro7UHy5XjT16kf4aypbtzNd8+Fu7IKbfuk1+ycM/09ViZrn+8vplrDqLoagm2Kc1Z9dp97DySJi7APjetnIQQ5pEAEAD+PoU7eaunnbP+kM/nTss+h0fmpHrfEUDGCUcRz7Gzl32+nl4LdjgGmtV6w/EmVOu156zPwr9/ziizrqSEMWVpOk5e1J5rQohgkAAQAA9+siko19mmNBcNF5uyThueMc0X/rZwPXOpyGNzXb3Sj19ASQnjpe934a3FZVsmbcg8hX/9lIG//C/N7+sI4SsJACHJvDb6RoptXJWYcBNUu2f6ejw8W99bB+C4gT73zQ7T0+HJ2fwidHh1Gd5aor84TcuO7HMY8N5qTFt1QHN7sZKnoiAO8ieEK1sHgHrVKlqdBI/8aas/fq5j8DijbyPqKSMfnq3/2CKTir2ciksYj85JxdyNh3HkTPAq7Zwd7Jbs1C6CWr47F+k66m+OKsVl2016S2Nm/LD9WFBHhdVSfLXE8jQI89g6AKz5Sx+rk6BJbxHGt1vdj1G01EPzUr1Wpudh+5GzmLvxsNd975+l3fPZV+8t32/4mEA1my0qLsG4z7cgM+8iHpmTigHvrfb7nEZTumBHDp6YuxXT3bxRBEvK68vR7pWlll2fmSUAmcjWASA2OrSzb+QmodVqRk859voDp7D50LXB5VyDz7Cp63Rdf0OmdjNRAHjgk43o9Gowx2LxHEFX78tD0sQF5cZTKrhyFVdLyt9cth4+gx/TcvDMV9u9XvnY2cvIu1CoeywovZxTeOaed19pfO/09Xj8v4EdSvhs/hVcKtI31MY7y/ZhT465M8v97cfdaPHCIlPqaISNewKHMl9qALSGoh76wVqvx42YuQEAsOKZ3mieUMXjvq4lUnqLqH5Oz9O1X7A4m7qmHjqD5MSqpetbv7gYzepUdnvc1sNnPZ73bH4Ruk3+yZQ0+mKjm74aVigsvor3V+zHjNUHsPfVQX6fr/hqCf6xNB2frMsCAJQwI9rEujK7Cu1HYJvzt1njrmP6n77+tzkb/d9dZejJKu+Cb00YXQdrY+bSYKJu2WRFT+hMl5FXjdAagsI1B+cLrmDYB2uRGaK9p3/YfszUtxeNFyqfLNmViw9XZZpzMlFKAkCE8DdYTPv5APblXiw39LSrCwVXMGLGBhw+pa9iNr+wfHHB3xfuKfP5t9N+QdPnHDOOqieuDxVmjpy6cu8JbM8+h3cDOA6VP53onpi71e1ItlYqNiuSiDJsHwCaJbh/5beKszjHiifgJV46YC3bnYv1mafw7nJ9N7Cxn28pt+7ombIdyra4KVohg6/4ZnYEC9ZvPhDDcjs77gnhja4AQEQDiSidiDKIaKLG9tZEtJ6IConoWdX6RkS0koj2ENEuInpStW0SER0lom3Kv8HmZMmY8bclW3FZj5yjWuq5oRUWX0V+UTGCccsKlykEvKUzVHsMC/0uFhRjmQkt3dx54dsd+GhN5Bc5eQ0ARBQNYCqAQQDaAhhBRG1ddjsNYDyAt13WFwN4hpnbAOgKYKzLse8yc3vl30JfMxGpTugoY2/118Vo+9IS066p96n7QkExuvx9hWnXtcKUpfuQqqPi1MzA52y6G+ox6MSFAgz+55qgDP/hi6e/3IZH56Ti0Cnf62w8+ezXw3htwR7vO4Y5PW8AXQBkMHMmMxcBmAdgmHoHZj7BzJsAXHFZn8PMW5TlCwD2AGhgSspFQHi62b3w7c7S5b3HzW3eBwDPfbOjzGejRWBfb8k2tP/Ji4X43fT1ho5xmr/9mE89lF1bRAXipcqMN5yvUrOxO+c8Pt3g+3hTvtp86LTXwHxIqYOSmb78oycANACgnvk8Gz7cxIkoCUAHAOoapnFElEZEs4ioppvjRhNRKhGl5uWZ35wwHMbc1yNYzaLNmGzFXUsbdx3OmL0PS5F3odBrM00jDp3K99i7efzcrfgi9YiSPvM6J+UXFWPlXv3Dd1y5WoIXv9vpc4ssNTOn0vQnCP122nqfA7MwRk8A0HpIMfT1ElEVAF8DmMDMzkfHaQCaA2gPIAfAFK1jmXkGM6cwc0pCQoKRy9qKnongzfDy/F1+n+NqCePF73Z631HR951VaP3iYq/n9GZBWg7yi4p1B/1pPzt63bp7Sj+p3HQnfr0DLV5YpOucpdwk4flvduDB/2wq10nNnWW7c/HphkOYZOB72XXsHI5ojInv6XecfSYfSRMX6L5GqQDVG4XqY9vGg6eRHcShS/ylpyNYNoBGqs8NARzTewEiioXj5v8ZM3/jXM/Muap9ZgL4Ue85zWS0pUmoCtX/EFoYrKtowfndXC1hXDWQQ61vdPuRsxj7+Rb8rlNDROn8ys9e1jeZjfNNQMspN8M9u8vNQaVoQ6tjn+Z52Hk+/b+fIe87OghmTR6ia/+5Gw97bR5slVBrmHDvh443F72/W6vpeQPYBCCZiJoSURyA4QDm6zk5Odq4fQxgDzO/47KtvurjXQD0PxKKcswqggjGfLpHTuurWDRyU5u9Pkt1XHnOG6qZlZp6Uueuiauz45vRG1iwiiz/qwrQz32zAzNWe28R43xL0PM26s9Ah2Ywcv1fM0/h683G6pfChdcAwMzFAMYBWAJHJe6XzLyLiMYQ0RgAIKJ6RJQN4GkAfyWibCKqBqA7gJEAbtNo7vkWEe0gojQAfQA8ZX72vGtSO96Ky5ruDQOzgXlyNIRafXgKFFdcRqX8r5c3ijLjHRl461uQloOccwW69tUzSqiT29uPcmPae/xCmfMZiRNmBAm9eVZbqVRwz9vkefDAtftPoulzC5FmcLY4PZbsOo4pS9O97vfHz8r3T3HnvhkbNMeBYuaADlW+7chZU+tltOgaC0hpornQZd101fJxOIqGXK2Fm79dZh6pP5mB06GxZt2z8CL7jLWB4vqXl6B6pVhseuF2/HLgpNc3l3dUPW/13iCLr7JmRzZ3th45430nRYnzDcDNdmeLqH2vDUJczLXntOwzl3Eu/wp2HTuHjk2u/e368kD9/bajGNY+sI3yiopLwMylHd52Hj2H8fMcQ5VvPHgaNzWs4dN53T3BP/apYzC8Z/q38nj8IjfDfRsx4L3VOHjyEva/bn4XpuPnCnDn1HW4s/11eG94B9PP7ySDwYmwVFRcgrwLhfj818N4/tsd3g/wgbd6Cn9KMZzHeusJPGd9Fh7p2az088/peWj3N8dwzHd3bIDb2yQauq56zud1GSe9BgBfWxepszV/+zFUrRiDD37KcFsk5isrqwD25ZrX49p1atCLhY4W9TuOBrZxh+2HghDhTevm77wpbDl8BoXFrgPPBSFRbugZAG67S/m5s9/AuxrzI+gd8uFy0VWUlDAOn8o3VPQBOAYJ9IX693zmUhEe+k+q15v/oh05WOzjk/mJCwXoGNQhx32Tln0Wj8xOxRcuxWQpry1HymvLg54eeQMQEaeEgWe+3I6vt2RjeOdGmPzbmwJyHaNl7bdNWaU61hjnfABlru/mJOr1RcUlaPPSYjzQLQm/v7lxmf3S/Gw6XFLCKLpagoqx0X6dx+lxg8FJbcWeE+V+R8fPFSDzZGiNizT0A8f8Gsv35OK+zo297B148gYgwsbuY+dxNt9708y5Gw+X9grerXNCEmebfyOYgck+Vr7rnULT3wpd5xvQVxpNVfeqKpm3HNZff+H0+sI9aP3i4tK8OCvl12eaM6LrG4vcD8Wg57cy4L3V+P1M/0Y23aTqkZxzzni919Gzl9HtjRWa/S6SJi7w6fduJgkAImwMfn8N7v73L36fR+vJ+c3Fvt3I/Z2i0Vlc9eAnG/HS9+VbQnsqslIHB7dvA87reKlrWJiW43G7lnlKz+0LBY7y6uNKy6HMPH19BrylSc/4/55Oce7yFfcbdZqpav6adVK7g9c7Hob2/l9qNo6dK9AMwADw2QbtFlM/Kb3BD+j8XfpKAoAIK5knLyH3vLEmilsD9JRV5NL3Iv248eKGoqslOHOpCCvT8zBnfflKZ+ayT6GunPe/xRrDeB88eQk3TVpaul+g6j/uieBhG9Rza5+4oP139/4K4/NXe73ursCNdKomdQAi7NxscBTS+2ZsKF02syOVa7HR8j3G/9Ou2X8SHTxUXq7PPOX2BrvzqHbxFpduL1vG789EMZ74M4uaWcxsDeTu9/TkvG1Yf+AUftp7Aiue6W3iFa0jbwAAaleOszoJIoC8lbe7G64hopBjti8zuYZSd6G1wM3vf97Gwz6XgQeyNVf/d1e73TZv0xGcuFCIzq/ra7GjfuAwMpxG6qHg1A1IAADQun5V7zuJiNXJguZ3webuCflqCWPAu6vLFHWYQT0gmruK8v0nLuLuf//isbLXmcYn521zs9W8Z/83Fu7Bj2n6hjlzHYb6O2WeB7eIcOfUdeVWF5eU+DbInkkkAAB4f3gHDO/cyPuOIuz429QxXP2YdqzME7+7CtevUo8gPfcCDmu0UjHi1MXCMr1zz13WP6aUt8reixq9vAMxCNyHqzMx7nPf3pImfLGtzOfxc7fiuW/SyoxSq1UprZW3YJI6AAC1q1TAiC6NMW+T+1EdRWTYkHkalVqZ0249FGgNacDMGDd3m67jJ37jey9qdTGM61uUnuG59ThyOh993v7Z7bVvf2cV/vNg53LbD2h0ugvmMM3ztzveJJqH4JzjavIGIGxnZbr5EwtZxXmj8SbYwybrGZBNjy82HUGxl2Dy7dajOOXSCayvqtOdU483V5qSJiPMCoSBIgFAEdpfkxD6/XrQ+zzHZrjsYaTK/TqHqTDLP5b4FnAO5F0MyKikrkJs2oJSUgQkRIT5/NfynYvO5vvfKcoIs254gZz/4B9L9mLqSkdT3kBN4OIt9Xpyd6mwGJUrBOZWLW8ACqsnqBAikgS6yElrbCSjnDf/QLo26qvv59DqIGgWCQBCCMNu/rvnprMnLxq7Qf/lf2mG9tc7ZaZeRnuX66V+gwm16SsBCQClaleuYHUShAgbuefN7Tznbl7lYL2YnzAhP//+OcPttkuFxZp5sbrkQQKAonGETA0pRCTRO2pqKHhrsfuK6JlrDgYxJfpJABBChKyP1nq/ca7Yc8Lv6/zpf+Xn/DWDGQ/4U1dmBKw5qQQAIURYM6M+QD03gpm8zZ2t57Z+sbDY55nSvNEVAIhoIBGlE1EGEU3U2N6aiNYTUSERPavnWCKqRUTLiGi/8lNmZxdC2MrPOjslqudyNpPXAEBE0QCmAhgEoC2AEUTU1mW30wDGA3jbwLETAaxg5mQAK5TPQgghXCzYkYOlGnM++EvPG0AXABnMnMnMRQDmARim3oGZTzDzJgCuvU08HTsMwGxleTaAO33LghBCRL6sU+bPu6AnADQAoG6jla2s08PTsYnMnAMAys+6Os8phBDCBHoCgFb3Bb1V0v4c6zgB0WgiSiWi1Ly8yBnESwghjAhEQyA9ASAbgHqw/IYA9A1B6PnYXCKqDwDKT822XMw8g5lTmDklISFB52WFECKynLxg/sx1egLAJgDJRNSUiOIADAcwX+f5PR07H8AoZXkUgO/1J1sIIewlED0BvA4xx8zFRDQOwBIA0QBmMfMuIhqjbJ9ORPUApAKoBqCEiCYAaMvM57WOVU49GcCXRPQwgMMA7jE5b4b1TK6DNftPWp0MIYQoJxCjRugaY5SZFwJY6LJuumr5OBzFO7qOVdafAtDXSGIDrUJM5MwUJYQQ3khPYJVQHK1PCCEA4Ey+/0Ngu5IAoCL3fyFEqNoYgJneJACodGgso1EIIexDAoDKY72aYdlTvaxOhhBClFMSgFpgCQAqUVGE5MSqVidDCCHKCUQrIAkAQghhUxIAhBAiDASilaIEACGECANSBBQkW1/sJ30ChBAhhQMwGIQEAA01K8fh4BtDrE6GEEKUsmo0UNvq3zbR6iQIIUTASADwYNLQ661OghBCBIwEAA+uq1HJ6iQIIQQAqQQWQggbk0rgoFv9pz5WJ0EIIeQNwAqNa8dbnQQhhAgICQBCCGFTEgCEECIMBGJOYAkAQggRBmQ4aCGEsCmpBLbIoz2bWp0EIYQwna4AQEQDiSidiDKIaKLGdiKi95XtaUTUUVnfioi2qf6dJ6IJyrZJRHRUtW2wqTkz0XOD2uCxXs2sToYQQpjKawAgomgAUwEMAtAWwAgiauuy2yAAycq/0QCmAQAzpzNze2ZuD6ATgHwA36qOe9e5nZkX+puZQImKItzR7jqrkyGEEKbS8wbQBUAGM2cycxGAeQCGuewzDMAcdtgAoAYR1XfZpy+AA8x8yO9UCyGEzbBFlcANABxRfc5W1hndZziAuS7rxilFRrOIqKbWxYloNBGlElFqXl6ejuQGRiAqYIQQQi+rmoFqTY3imhaP+xBRHIChAL5SbZ8GoDmA9gByAEzRujgzz2DmFGZOSUhI0JFcIYSIQBa1AsoG0Ej1uSGAYwb3GQRgCzPnOlcwcy4zX2XmEgAz4ShqEkIIocGqN4BNAJKJqKnyJD8cwHyXfeYDuF9pDdQVwDlmzlFtHwGX4h+XOoK7AOw0nHohhLCJQNQBxOi4aDERjQOwBEA0gFnMvIuIxijbpwNYCGAwgAw4Wvo86DyeiOIB9APwmMup3yKi9nAEtiyN7UIIIQLIawAAAKWJ5kKXddNVywxgrJtj8wHU1lg/0lBKQ8ych7rg/lkbrU6GEEL4THoC+6hrs3IxTQghAkYGg7NQTHTZhk5EwBt331huv9horQZRQggReiQA6NS6XlX8dUibMuu6NZe3ACFEcMhgcBYiIjzSsxl6JtdxfLY4PUIIe+EAFALpqgQW13w4shOyz1xGTLR27CQQAlNaJ4SwsxJ5A7BefFwMWiZWdbs9oWqFIKZGCGEXVo0FJAyoUkFeqoQQ5pM6gDBQuUK01UkQQghdJACYrGJsNPa9NsjqZAghhFcSAAIgLkZ+rUIIc8mk8CEmOsp9Y9BOTTSnNxBCCJ9IK6AQ07BmfGm/AFeDbqgX5NQIIYQxEgD8NLJrEwBAxVjHr7JW5TgAwKhuSVYlSQghdJE2iybp0aIObmudiN+0c0xzEOumo5gQQoQKCQB+6tUyAf3aJuLFIW3RuHa81ckRQkSouAA8VEoA8FPF2GjMvD9F176vDL0e1SrF4Kkvtgc4VUKIiBOAAciknCKIRnVLQtv61T3uM6JLI4/bhRA2Ja2AIt/EQW2QNXkI2jX0HCiEEMJfEgBCTPVKsQCAGvFxFqdECBHpJACEkLs7NrA6CUKIEBWI+QB0BQAiGkhE6USUQUQTNbYTEb2vbE8joo6qbVlEtIOIthFRqmp9LSJaRkT7lZ8R23VWPTQEuanIefmOtvj7XdemmKxfvaLHc379+C0AgJd+09b/BAohQp4lPYGJKBrAVACDALQFMIKIXO86gwAkK/9GA5jmsr0PM7dnZnVzmYkAVjBzMoAVyueItPyp3vhwZCeP+zzYvSkqxl4bSfTlO67H7W3qut2/U5NayJo8BA9IhzMhbMGq+QC6AMhg5kxmLgIwD8Awl32GAZjDDhsA1CCi+l7OOwzAbGV5NoA79Sc7PNyX0ghP92uJxrXjMeB6Y0NDVIqLxtD2xouE9vxtoOFjhBD2pKcfQAMAR1SfswHcrGOfBgBy4Gi8tJSIGMCHzDxD2SeRmXMAgJlziEjzcZeIRsPxVoHGjRvrSG7oePN3N/l1fIdGNQwfUylO5iMQQuij5w1Aq9Ta9V3E0z7dmbkjHMVEY4mol4H0gZlnMHMKM6ckJCQYOTQkVasYq3vfRrXiMcNL0ZFWnUK9ap7rD4QQAtAXALIBqHsnNQRwTO8+zOz8eQLAt3AUKQFArrOYSPl5wmjiw1G96hXx4xM9dO9P7mqNPQhEawEhhLWsGg56E4BkImpKRHEAhgOY77LPfAD3K62BugI4pxTrVCaiqgBARJUB9AewU3XMKGV5FIDv/cxL2Lihgf5OXre2SsD/ddVX9PXfh11L5uB2uGohhPAaAJi5GMA4AEsA7AHwJTPvIqIxRDRG2W0hgEwAGQBmAvijsj4RwFoi2g5gI4AFzLxY2TYZQD8i2g+gn/LZNv40oBUa1Kjkdb/Y6Ci8dueNbrcTEb4f2x3bX+6PHi43+w3P9cWnGkHBqUtSLQBAfFw0siYP0ZXuuzo0wM/P3qprXyFEaNM1GBwzL4TjJq9eN121zADGahyXCaCdm3OeAtDXSGIjydg+LTC2Twvkni9AwZWrXvf/aswtuGf6es1t7XyoLAaATx7sjOtfXmLomPs6N0JSnco+XU+PO9pdhx+2u5YwCiECQXoCWyyxWkU0qe39htpZeVrXo1eyo7LcU4sg58Q1ejRLcKTvlma10bVZbd3H+eKeTg0Den4hxDUSAMLItpf66drv9btuxJo/9ykdV8gdrTolrTHHnxvUBoD7Xsxm6t5C6iyECBYJAGFE7wBxcTFRaFSr/OQ0q//UBwvH9wRQtt2uc3nXKwMw5+Eu5Y6L13iT+PrxWzD+tha60mNEdFQQoowQAoAEAFtpXDsedatVAKD99F+5Qgxiox034FaJVUvXO4uLWtW7tq5Tk1p4un+rwCU2TDjnghYiHMlfr81479Xn2CO+wrWn/jb1q+GrMbeUFgWp3X9LE9zSrDayJg+x5c2wTyv34zXp4WsFvhBmsN//WFHKU2GL67hTnZNqlRnV1Olvw27A3NFdAQBLJnju5G1GD+VX77zBp+PcXVtPU1xP3BXL/fHW5rqOr6e8kQlhBQkAYSb1r7dj4wvGWs82S6iMvwxsDaDs075WMZA/Fb1Nalf2+ET7UI8kAOUHrLvOy9DX6lFRR3ZtUro8+e4bsXhCT7fHrf5THwBAjfhYJLq50cZGE+aP6+7x+r4YF4D6EWFvgZglUAJAmKlTpQLqVjX2JP3TM7ficQ9PpMGqdh3dqzmyJg8p1zy1dyvPYzx9NKpzuXV9W9fF8C6NPY6tVFkpxooiwpje2vlnADc1rOE54RrG9032uD0+TlcXG599+dgtuvarbaC5rwhtzw0uXwTrLwkANhPsNjZdm3nuv3BDg2p4vHfZp2Wtm9bKZ2/Fxucdbz57Xx2IGfenlNvHk0E31tfs7fyklxu5Ow2VoqO4aP9+o0aGeO/XNhEA8M697TSL47RM+z/PgwmGgia1y7dYE+VVrWj+Q4UEAFGG8+Z7k5+vm++P6ICdrwzAvNHaT6r1qlVEz+Q6+PGJnmjscgOY/0QP/GlA2RZGTetURl2lHL9ibLRmc9Gbm5YNNnrurXd39K3j2Z0dGuCx3s3w7AB9LaE2Pt+3XJ6eMFhM9Ez/ltj5ygBDae7StBb6tU3EoBuMzUcRTJViZQhzqwT2PVWEnJgoR8yvW1W7TLxJ7cr48YkeaJlYFXPWHzJ8/ntTGmL7kbPo1rw2qlRw/+e14Xn39RgNalTC2D4t0LFxTdSsrG/47PrVK+Lff+iITq8tL13nfLpWh4qHezRFwZWrqBQbjdP5RbrOrSUuJkqzVVTzhMo4kHepzLp1E28rDV5qNzaojvTjFwxd1/k7NfLeMVN5W0qauMDQtQAgsVoF5J4vNHycUc/2b4m3l+4L+HVEWRIAbKZ6fCym3NMOPZLrlPb6Hdah7MxjRkYrdfWHm5vgDzc3KbPu68e7YfOh04bPdUtz78NO1KlSATXiY/HXIWVnKf3Pg9fqDdQV2y/qmEM5a/IQ9H93FfblXtSfWMX343qU9qVw8tTSqGFN64s/xvdNxvsr9mtucz4wqPVqmYDV+/IMX2f7y/3R7pWluvZtXCseh0/no1blOJy+5HugDpT2jWpg25GzVifDb1IEZEO/7dQQidUqIi4mCmmT+uPVYb41rdSrU5OaGN1LX7NIo+JiorDtpf4YclN91Kochz/e2hzLnuqFW1vV9WteBF/b91eMiUKFGP1FGn8Z1Aqdk2oiioDrr6uGGz0E32hVJNMqD171p1vx/ODWpZ8XPem+hZTa0/1aur3u3R3LT0s656HyvcXV3NVPVK8Uq3sMqsUTemL6/3XCvSmNvO9sge/Gmt9yzAoSAGyuWsXYkBh+4YFuSZj7aFe/zkFE+PPA1khW9WJWthg+l7u3jw6Na7g9JmvyEMRojKXkTqW4aFSIicZXY7oh840hWDC+J37QOVlQs4Qq6Nv6WpD65/D2aFK7Mu6/JQkAUCEmCm3qV9M89uvHy9fLaN20b2pYHU/3a+k1LQffGFzms6c/J71/avFxMRgYhHqL+l6aIEc6CQDCrY3P98UvE28LyrUmDb1eV5FPsNzaqi4+e6T8XApzHuqi2eFNaxA9dx7oloRX77wBPXQOfNeibhXN9erJfoa1dzypxyrpeKa/+xt3pya1MLTddV6vO7ZPC10z0qn3mftoV/znwbJvCO0a1cAbdzvmtPjsEd+CvGvg1VOU91jvZj5dKxR888duQbmOBADhVt1qFXGdnz1lrRSrlF83ruU9D86bqXoEVa3htKtWjC0zJhIAfPD7Dlj6VPmg0DKx7I2blVrp+LhojOzaxKfpPr2JjiJkTR7itcjt/REd8PXj3Tz2rPaUOndzVd/S3DFkeNbkIaVB8YvRXTGii2NWu1b1qmJ0r7I35rs7NihT1JPx+qDSZWfTV+cQ512a1sILg9vgwW5JHlLnoFVJ70qrfuZWL/1SvFn0ZE9U9dAAQo92PvRN8YUEABGxalaOw4cjO2l2JHP16cM3I2vyEGx/ub/h6/zmpus0J8n5akw3zbeFYAyrrUenJjXL9Kw2ov/1+otnXPPbu+W1G+wLg9vg0Z7NyrSSUhejdWpSE1mTh5TWUdSKj8OjvZohSqMs6Y5215XOcufkvBG7Bh0nrf4ko5RitM8fuRkfj0ox3AO3Tf1q2PHKAEPHqD3YPUmzWJYC0ItHAoCIaAOur2do8hszVa9U/m3BF+ymt9jtytOxmf5+17XpR41MQqQlsbp2U+PuLeqUznMdE02lb0KjezXDhNu1O+bd2ioBD3Vv6vGNpUVClXJzYC95qhfeva+dZsu2J/sma/5t9GldFzsm9Ue3FnXQt01iucnY27rUrYzvm4y0SeUfHNb8uQ/mPNQFXZoa+z06v+4hN9U3dJwvJAAI4Uadyo4bWK+W/hUJGOWs3F3z5z74VlUW7PokHYgmpI2VeSTiYqJQU7k5tqhbpbQIx51fJt6GX136dnwx+ha8d197zVZRzhZN6iw9P7gNJtyuXXcREx2Fl+5oiwSN/ivO4qjerRLK1ZdcV6MS7urQsEydR71qFTGiS2M85aGCu6pqiJES5Y7cul5VLH2qF74cU7YSPS6aNIckaVQrHr1aJuiu+HY19fcdfTvQAOkHIIQbjWvHY8UzvdGkVjx6/+NnrzOsmeWjUSlgBqKiSHNin2BQ37OWP90bADB34+Fy+zkH/9OqK7quRiXc2aF8M1KzfDiyE6pWjEG35nVKh/lwturRGpRw8I31sHDHcaz+cx/dQ2kAQHLdKth17Dw+HNlJc/pWb3U5j9/aAhsyN3q9Tmw04cpVRstyrdgCR1cAIKKBAP4JIBrAR8w82WU7KdsHA8gH8AAzbyGiRgDmAKgHoATADGb+p3LMJACPAnD2KHlemXxeiJDRPMHxRLnOhNZQ96Y0woIdx/F/XsrdiciyegLndWvEew92S5/q5XMzSt97aFwzQKMeIrFaRbx9Tzv0alm+hdW797XH84MLy938P3vkZhzIu4iXvt+leZ037r4J93ZupGvubi29WyYga/IQtHtlKc5dvuJ2v/2vD0Za9tkyfTJaJlYp7ZBYNwBDh3sNAEQUDWAqgH4AsgFsIqL5zLxbtdsgAMnKv5sBTFN+FgN4RgkGVQFsJqJlqmPfZea3zcuOEKGrbrWKujtnaTEycJxRv+vUEJsPnUFyYhW8ftcN6NnCe7GXGU+qgWgJ9btO2mMlVYiJ1iw2696iDlKSamLN/pOYOKh1ue2V4qLRrbn3Jrs/PtED5z3c4NVZdTf0hevItEuf6g1mRsGVEs1Waf7S8wbQBUAGM2cCABHNAzAMgDoADAMwhx21VRuIqAYR1WfmHAA5AMDMF4hoD4AGLscKITwIxE3S1YgujUvL+V2H8rCDCjHRpWMm+crIECrtG9UEAHRJqoWNWZ6HSSGigNz8AX2VwA0AHFF9zlbWGdqHiJIAdADwq2r1OCJKI6JZRFRT6+JENJqIUokoNS/P+PgjQoQ7d62AAMdw2nr9bdj1+Ofw9iakyH+BfJsJNr/is8VNgvW8AXifRtbLPkRUBcDXACYw83ll9TQAryr7vQpgCoCHyp2EeQaAGQCQkpISQX82QhijdaP57JGuOHI6X9fxzmEifPVIj6amD4AWKn0igiEUs6onAGQDUI/I1BDAMb37EFEsHDf/z5j5G+cOzJzrXCaimQB+NJRyIQSqV4pFdT9GbzXirzqGX7CjQHTQChY9RUCbACQTUVMiigMwHMB8l33mA7ifHLoCOMfMOUrroI8B7GHmd9QHEJG6l8NdAHb6nAshRFhxjlkUFcavAM55pvUWw6l7i6tHqvU0XHigeX0DYOZiIhoHYAkczUBnMfMuIhqjbJ8OYCEcTUAz4GgG+qByeHcAIwHsIKJtyjpnc8+3iKg9HEVAWQAeMylPQogQ91S/ZERHAfek+DYjWyj49fnbceJ8geZkP1o+HtUZT87bijX7T5bpCPfd2O44fPqS54MDRFc/AOWGvdBl3XTVMgMYq3HcWrgp+mLmkYZSKoSIGFUrxuKFIeFfpKT35g8AtSrH4dOHHSPMrj9wqnR9QtUKmj2cg0GGghAixN2l9KatU8Wam4Qwn3OwtwoWz4dMnpqYhZqUlBROTU21OhlCBBUzo7C4BBVl8vSIUVLCeGfZPtzfrQnqVg38pDREtJmZy3V0kLGAhAhxRCQ3/wgTFUV4dkArq5MhRUBCCGFXEgCEEMKmJAAIIYRNSQAQQgibkgAghBA2JQFACCFsSgKAEELYlAQAIYSwqbDqCUxEeQAO+Xh4HQAnTUxOKJG8hSfJW3gKx7w1YeZy83yGVQDwBxGlanWFjgSSt/AkeQtPkZQ3KQISQgibkgAghBA2ZacAMMPqBASQ5C08Sd7CU8TkzTZ1AEIIIcqy0xuAEEIIFQkAQghhU7YIAEQ0kIjSiSiDiCZanR49iCiLiHYQ0TYiSlXW1SKiZUS0X/lZU7X/c0r+0ologGp9J+U8GUT0PhFpztEc4LzMIqITRLRTtc60vBBRBSL6Qln/KxElWZy3SUR0VPnuthHR4DDNWyMiWklEe4hoFxE9qawP++/OQ94i4rvTjZkj+h+AaAAHADQDEAdgO4C2VqdLR7qzANRxWfcWgInK8kQAbyrLbZV8VQDQVMlvtLJtI4BbABCARQAGWZCXXgA6AtgZiLwA+COA6crycABfWJy3SQCe1dg33PJWH0BHZbkqgH1KHsL+u/OQt4j47vT+s8MbQBcAGcycycxFAOYBGGZxmnw1DMBsZXk2gDtV6+cxcyEzHwSQAaALEdUHUI2Z17Pjr3CO6pigYebVAE67rDYzL+pz/Q9A32C96bjJmzvhlrccZt6iLF8AsAdAA0TAd+chb+6ETd6MsEMAaADgiOpzNjx/0aGCASwlos1ENFpZl8jMOYDjDxhAXWW9uzw2UJZd14cCM/NSegwzFwM4B6B2wFKuzzgiSlOKiJxFJGGbN6X4ogOAXxFh351L3oAI++48sUMA0Iq44dD2tTszdwQwCMBYIurlYV93eQzHvPuSl1DL5zQAzQG0B5ADYIqyPizzRkRVAHwNYAIzn/e0q8a6kM6fRt4i6rvzxg4BIBtAI9XnhgCOWZQW3Zj5mPLzBIBv4SjKylVeOaH8PKHs7i6P2cqy6/pQYGZeSo8hohgA1aG/WMZ0zJzLzFeZuQTATDi+OyAM80ZEsXDcID9j5m+U1RHx3WnlLZK+Oz3sEAA2AUgmoqZEFAdHZcx8i9PkERFVJqKqzmUA/QHshCPdo5TdRgH4XlmeD2C40uqgKYBkABuV1/MLRNRVKXu8X3WM1czMi/pcvwPwk1IeawnnzVFxFxzfHRBmeVPS8jGAPcz8jmpT2H937vIWKd+dblbXQgfjH4DBcNTyHwDwgtXp0ZHeZnC0ONgOYJczzXCUH64AsF/5WUt1zAtK/tKhaukDIAWOP+IDAD6A0vs7yPmZC8fr9BU4nooeNjMvACoC+AqOirmNAJpZnLdPAewAkAbHTaB+mOatBxxFFmkAtin/BkfCd+chbxHx3en9J0NBCCGETdmhCEgIIYQGCQBCCGFTEgCEEMKmJAAIIYRNSQAQQgibkgAghBA2JQFACCFs6v8Bft2InvI//ywAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29871 3020\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29871 467\n",
      "Loss:  0.16805724799633026\n",
      "Loss:  0.16585426032543182\n",
      "Loss:  0.1741877794265747\n",
      "0 **********\n",
      "Epoch:  54.326740741729736  fold:  10  kers:  32\n",
      "epoch:  1\n",
      "29871 467\n",
      "Loss:  0.14024978876113892\n",
      "Loss:  0.14167217910289764\n",
      "Loss:  0.1261066347360611\n",
      "1 **********\n",
      "Epoch:  96.54785013198853  fold:  10  kers:  32\n",
      "epoch:  2\n",
      "29871 467\n",
      "Loss:  0.1174386590719223\n",
      "Loss:  0.10483840107917786\n",
      "Loss:  0.09776780754327774\n",
      "2 **********\n",
      "Epoch:  138.66423964500427  fold:  10  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.39809560775756836\n",
      "Eval Loss:  0.38300350308418274\n",
      "Eval Loss:  0.20338203012943268\n",
      "[[1485  266]\n",
      " [ 142 1127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88      1751\n",
      "           1       0.81      0.89      0.85      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.86      0.87      0.86      3020\n",
      "weighted avg       0.87      0.86      0.87      3020\n",
      "\n",
      "acc:  0.8649006622516556\n",
      "pre:  0.8090452261306532\n",
      "rec:  0.888100866824271\n",
      "ma F1:  0.8629751265424974\n",
      "mi F1:  0.8649006622516556\n",
      "we F1:  0.8655676075810849\n",
      "update!  Acc:  0.8649006622516556\n",
      "Eval Loss:  0.46976208686828613\n",
      "Eval Loss:  0.45067882537841797\n",
      "Eval Loss:  0.42347246408462524\n",
      "Eval Loss:  0.4562720060348511\n",
      "Eval Loss:  0.36678794026374817\n",
      "Eval Loss:  0.390374094247818\n",
      "Eval Loss:  0.48812609910964966\n",
      "Eval Loss:  0.45908671617507935\n",
      "Eval Loss:  0.5071566104888916\n",
      "Eval Loss:  0.42579010128974915\n",
      "Eval Loss:  0.4610646963119507\n",
      "Eval Loss:  0.4690137803554535\n",
      "Eval Loss:  0.34832626581192017\n",
      "Eval Loss:  0.48686161637306213\n",
      "Eval Loss:  0.3519909381866455\n",
      "Eval Loss:  0.4160059094429016\n",
      "Eval Loss:  0.46709713339805603\n",
      "Eval Loss:  0.3527432680130005\n",
      "Eval Loss:  0.4106438159942627\n",
      "Eval Loss:  0.4589231312274933\n",
      "Eval Loss:  0.4080851376056671\n",
      "Eval Loss:  0.45691925287246704\n",
      "Eval Loss:  0.4503146708011627\n",
      "Eval Loss:  0.38989701867103577\n",
      "Eval Loss:  0.43396398425102234\n",
      "Eval Loss:  0.3440617024898529\n",
      "Eval Loss:  0.47371524572372437\n",
      "Eval Loss:  0.45211076736450195\n",
      "Eval Loss:  0.43958500027656555\n",
      "[[15232  3181]\n",
      " [ 2667  8791]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84     18413\n",
      "           1       0.73      0.77      0.75     11458\n",
      "\n",
      "    accuracy                           0.80     29871\n",
      "   macro avg       0.79      0.80      0.79     29871\n",
      "weighted avg       0.81      0.80      0.80     29871\n",
      "\n",
      "acc:  0.8042248334505039\n",
      "pre:  0.7342966922819913\n",
      "rec:  0.7672368650724385\n",
      "ma F1:  0.7946783869714713\n",
      "mi F1:  0.8042248334505039\n",
      "we F1:  0.8049866520330566\n",
      "29871 467\n",
      "Loss:  0.11291874945163727\n",
      "Loss:  0.1049942672252655\n",
      "Loss:  0.0972200483083725\n",
      "3 **********\n",
      "Epoch:  220.19823384284973  fold:  10  kers:  32\n",
      "epoch:  4\n",
      "29871 467\n",
      "Loss:  0.10211659222841263\n",
      "Loss:  0.1068132221698761\n",
      "Loss:  0.09903491288423538\n",
      "4 **********\n",
      "Epoch:  262.54700207710266  fold:  10  kers:  32\n",
      "epoch:  5\n",
      "29871 467\n",
      "Loss:  0.109120212495327\n",
      "Loss:  0.12968523800373077\n",
      "Loss:  0.10148553550243378\n",
      "5 **********\n",
      "Epoch:  304.7940421104431  fold:  10  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.3588014245033264\n",
      "Eval Loss:  0.2645607590675354\n",
      "Eval Loss:  0.1784900426864624\n",
      "[[1570  181]\n",
      " [ 159 1110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      1751\n",
      "           1       0.86      0.87      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.88      0.89      0.88      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8874172185430463\n",
      "pre:  0.8597986057319907\n",
      "rec:  0.8747044917257684\n",
      "ma F1:  0.8847431752873564\n",
      "mi F1:  0.8874172185430463\n",
      "we F1:  0.8875451075683185\n",
      "update!  Acc:  0.8874172185430463\n",
      "Eval Loss:  0.4567653238773346\n",
      "Eval Loss:  0.38960665464401245\n",
      "Eval Loss:  0.3808233141899109\n",
      "Eval Loss:  0.41061174869537354\n",
      "Eval Loss:  0.31686651706695557\n",
      "Eval Loss:  0.3155970871448517\n",
      "Eval Loss:  0.45409128069877625\n",
      "Eval Loss:  0.42169588804244995\n",
      "Eval Loss:  0.48317474126815796\n",
      "Eval Loss:  0.3201090693473816\n",
      "Eval Loss:  0.43709075450897217\n",
      "Eval Loss:  0.3623802959918976\n",
      "Eval Loss:  0.28360626101493835\n",
      "Eval Loss:  0.43007007241249084\n",
      "Eval Loss:  0.2849716544151306\n",
      "Eval Loss:  0.3621727526187897\n",
      "Eval Loss:  0.3903311491012573\n",
      "Eval Loss:  0.3215256333351135\n",
      "Eval Loss:  0.31143757700920105\n",
      "Eval Loss:  0.437662273645401\n",
      "Eval Loss:  0.3567507565021515\n",
      "Eval Loss:  0.4604969918727875\n",
      "Eval Loss:  0.3842715919017792\n",
      "Eval Loss:  0.3291105031967163\n",
      "Eval Loss:  0.42650106549263\n",
      "Eval Loss:  0.26881763339042664\n",
      "Eval Loss:  0.42859238386154175\n",
      "Eval Loss:  0.45298680663108826\n",
      "Eval Loss:  0.4303044378757477\n",
      "[[16590  1823]\n",
      " [ 3024  8434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87     18413\n",
      "           1       0.82      0.74      0.78     11458\n",
      "\n",
      "    accuracy                           0.84     29871\n",
      "   macro avg       0.83      0.82      0.82     29871\n",
      "weighted avg       0.84      0.84      0.84     29871\n",
      "\n",
      "acc:  0.8377355963978441\n",
      "pre:  0.8222677196061227\n",
      "rec:  0.7360795950427649\n",
      "ma F1:  0.8246640853683823\n",
      "mi F1:  0.837735596397844\n",
      "we F1:  0.8358107699208475\n",
      "29871 467\n",
      "Loss:  0.10084670037031174\n",
      "Loss:  0.09901773184537888\n",
      "Loss:  0.08561790734529495\n",
      "6 **********\n",
      "Epoch:  386.238276720047  fold:  10  kers:  32\n",
      "epoch:  7\n",
      "29871 467\n",
      "Loss:  0.08563186228275299\n",
      "Loss:  0.12472233176231384\n",
      "Loss:  0.09008453041315079\n",
      "7 **********\n",
      "Epoch:  428.30579686164856  fold:  10  kers:  32\n",
      "epoch:  8\n",
      "29871 467\n",
      "Loss:  0.07697615027427673\n",
      "Loss:  0.08361683040857315\n",
      "Loss:  0.1317906528711319\n",
      "8 **********\n",
      "Epoch:  470.0761113166809  fold:  10  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.39207738637924194\n",
      "Eval Loss:  0.19432932138442993\n",
      "Eval Loss:  0.12559793889522552\n",
      "[[1613  138]\n",
      " [ 179 1090]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1751\n",
      "           1       0.89      0.86      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.89      0.89      0.89      3020\n",
      "weighted avg       0.89      0.90      0.89      3020\n",
      "\n",
      "acc:  0.8950331125827815\n",
      "pre:  0.8876221498371335\n",
      "rec:  0.8589440504334122\n",
      "ma F1:  0.8917877292434804\n",
      "mi F1:  0.8950331125827815\n",
      "we F1:  0.8947786943860101\n",
      "update!  Acc:  0.8950331125827815\n",
      "Eval Loss:  0.4251573383808136\n",
      "Eval Loss:  0.35779714584350586\n",
      "Eval Loss:  0.3549179136753082\n",
      "Eval Loss:  0.38042446970939636\n",
      "Eval Loss:  0.3065584897994995\n",
      "Eval Loss:  0.2906849682331085\n",
      "Eval Loss:  0.4394854009151459\n",
      "Eval Loss:  0.4206881821155548\n",
      "Eval Loss:  0.4653359353542328\n",
      "Eval Loss:  0.2860456705093384\n",
      "Eval Loss:  0.3787919580936432\n",
      "Eval Loss:  0.31720593571662903\n",
      "Eval Loss:  0.2672668993473053\n",
      "Eval Loss:  0.38468798995018005\n",
      "Eval Loss:  0.2803950011730194\n",
      "Eval Loss:  0.33038783073425293\n",
      "Eval Loss:  0.3680132329463959\n",
      "Eval Loss:  0.2920067608356476\n",
      "Eval Loss:  0.27622953057289124\n",
      "Eval Loss:  0.45510733127593994\n",
      "Eval Loss:  0.3477928042411804\n",
      "Eval Loss:  0.45142343640327454\n",
      "Eval Loss:  0.36614349484443665\n",
      "Eval Loss:  0.31512653827667236\n",
      "Eval Loss:  0.40746009349823\n",
      "Eval Loss:  0.26771995425224304\n",
      "Eval Loss:  0.3849653899669647\n",
      "Eval Loss:  0.4122743606567383\n",
      "Eval Loss:  0.38234496116638184\n",
      "[[17055  1358]\n",
      " [ 3213  8245]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88     18413\n",
      "           1       0.86      0.72      0.78     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.85      0.82      0.83     29871\n",
      "weighted avg       0.85      0.85      0.84     29871\n",
      "\n",
      "acc:  0.8469753272404673\n",
      "pre:  0.8585858585858586\n",
      "rec:  0.7195845697329377\n",
      "ma F1:  0.8323960298452703\n",
      "mi F1:  0.8469753272404673\n",
      "we F1:  0.8439055659841574\n",
      "29871 467\n",
      "Loss:  0.11477434635162354\n",
      "Loss:  0.09069095551967621\n",
      "Loss:  0.08284365385770798\n",
      "9 **********\n",
      "Epoch:  551.2141647338867  fold:  10  kers:  32\n",
      "epoch:  10\n",
      "29871 467\n",
      "Loss:  0.09763560444116592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0824429914355278\n",
      "Loss:  0.09049919247627258\n",
      "10 **********\n",
      "Epoch:  592.999439239502  fold:  10  kers:  32\n",
      "epoch:  11\n",
      "29871 467\n",
      "Loss:  0.08382278680801392\n",
      "Loss:  0.0926850363612175\n",
      "Loss:  0.10255564749240875\n",
      "11 **********\n",
      "Epoch:  634.785712480545  fold:  10  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.37264546751976013\n",
      "Eval Loss:  0.17221428453922272\n",
      "Eval Loss:  0.13393576443195343\n",
      "[[1614  137]\n",
      " [ 149 1120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1751\n",
      "           1       0.89      0.88      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.90      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9052980132450331\n",
      "pre:  0.8910103420843277\n",
      "rec:  0.8825847123719465\n",
      "ma F1:  0.9026943915323887\n",
      "mi F1:  0.9052980132450331\n",
      "we F1:  0.905234767373471\n",
      "update!  Acc:  0.9052980132450331\n",
      "Eval Loss:  0.38459938764572144\n",
      "Eval Loss:  0.3207600712776184\n",
      "Eval Loss:  0.3289516568183899\n",
      "Eval Loss:  0.34970664978027344\n",
      "Eval Loss:  0.2777530550956726\n",
      "Eval Loss:  0.28365862369537354\n",
      "Eval Loss:  0.4094219505786896\n",
      "Eval Loss:  0.3805108666419983\n",
      "Eval Loss:  0.434219092130661\n",
      "Eval Loss:  0.25523513555526733\n",
      "Eval Loss:  0.3199326992034912\n",
      "Eval Loss:  0.28621941804885864\n",
      "Eval Loss:  0.25438305735588074\n",
      "Eval Loss:  0.34678104519844055\n",
      "Eval Loss:  0.2545386254787445\n",
      "Eval Loss:  0.310095876455307\n",
      "Eval Loss:  0.3480323255062103\n",
      "Eval Loss:  0.26404497027397156\n",
      "Eval Loss:  0.2546704113483429\n",
      "Eval Loss:  0.413505494594574\n",
      "Eval Loss:  0.3189998269081116\n",
      "Eval Loss:  0.4079238474369049\n",
      "Eval Loss:  0.3499058783054352\n",
      "Eval Loss:  0.30466747283935547\n",
      "Eval Loss:  0.38909727334976196\n",
      "Eval Loss:  0.2413937747478485\n",
      "Eval Loss:  0.35754460096359253\n",
      "Eval Loss:  0.38865727186203003\n",
      "Eval Loss:  0.3498552441596985\n",
      "[[17000  1413]\n",
      " [ 2837  8621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     18413\n",
      "           1       0.86      0.75      0.80     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.86      0.84      0.85     29871\n",
      "weighted avg       0.86      0.86      0.86     29871\n",
      "\n",
      "acc:  0.8577215359378662\n",
      "pre:  0.8591787921068368\n",
      "rec:  0.7524000698202129\n",
      "ma F1:  0.8455704448166759\n",
      "mi F1:  0.8577215359378662\n",
      "we F1:  0.8556564740263521\n",
      "29871 467\n",
      "Loss:  0.06948467344045639\n",
      "Loss:  0.05985817685723305\n",
      "Loss:  0.07301823049783707\n",
      "12 **********\n",
      "Epoch:  715.7741649150848  fold:  10  kers:  32\n",
      "epoch:  13\n",
      "29871 467\n",
      "Loss:  0.07314573973417282\n",
      "Loss:  0.08376061916351318\n",
      "Loss:  0.07524064183235168\n",
      "13 **********\n",
      "Epoch:  757.5245323181152  fold:  10  kers:  32\n",
      "epoch:  14\n",
      "29871 467\n",
      "Loss:  0.10997834801673889\n",
      "Loss:  0.09761714935302734\n",
      "Loss:  0.06771060079336166\n",
      "14 **********\n",
      "Epoch:  799.4205112457275  fold:  10  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.3773671090602875\n",
      "Eval Loss:  0.15226642787456512\n",
      "Eval Loss:  0.12389397621154785\n",
      "[[1632  119]\n",
      " [ 153 1116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1751\n",
      "           1       0.90      0.88      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.909933774834437\n",
      "pre:  0.9036437246963562\n",
      "rec:  0.8794326241134752\n",
      "ma F1:  0.907225362496928\n",
      "mi F1:  0.909933774834437\n",
      "we F1:  0.9097553135563842\n",
      "update!  Acc:  0.909933774834437\n",
      "Eval Loss:  0.3580709397792816\n",
      "Eval Loss:  0.31406790018081665\n",
      "Eval Loss:  0.3330521881580353\n",
      "Eval Loss:  0.33832547068595886\n",
      "Eval Loss:  0.2676849663257599\n",
      "Eval Loss:  0.28107255697250366\n",
      "Eval Loss:  0.39744284749031067\n",
      "Eval Loss:  0.3754241168498993\n",
      "Eval Loss:  0.44460389018058777\n",
      "Eval Loss:  0.24857546389102936\n",
      "Eval Loss:  0.28898322582244873\n",
      "Eval Loss:  0.28934013843536377\n",
      "Eval Loss:  0.23184582591056824\n",
      "Eval Loss:  0.3495987057685852\n",
      "Eval Loss:  0.2629319429397583\n",
      "Eval Loss:  0.3018277585506439\n",
      "Eval Loss:  0.35219815373420715\n",
      "Eval Loss:  0.25590166449546814\n",
      "Eval Loss:  0.2503604292869568\n",
      "Eval Loss:  0.4152715802192688\n",
      "Eval Loss:  0.31872841715812683\n",
      "Eval Loss:  0.4020451009273529\n",
      "Eval Loss:  0.35936078429222107\n",
      "Eval Loss:  0.3127189576625824\n",
      "Eval Loss:  0.3869673013687134\n",
      "Eval Loss:  0.24182631075382233\n",
      "Eval Loss:  0.33430325984954834\n",
      "Eval Loss:  0.3794911205768585\n",
      "Eval Loss:  0.3297753930091858\n",
      "[[17177  1236]\n",
      " [ 2906  8552]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89     18413\n",
      "           1       0.87      0.75      0.81     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.86      0.84      0.85     29871\n",
      "weighted avg       0.86      0.86      0.86     29871\n",
      "\n",
      "acc:  0.8613370827893274\n",
      "pre:  0.8737229260318757\n",
      "rec:  0.7463780764531331\n",
      "ma F1:  0.8487250306526821\n",
      "mi F1:  0.8613370827893275\n",
      "we F1:  0.8588950970422902\n",
      "29871 467\n",
      "Loss:  0.11330990493297577\n",
      "Loss:  0.11318220943212509\n",
      "Loss:  0.09977715462446213\n",
      "15 **********\n",
      "Epoch:  880.5176739692688  fold:  10  kers:  32\n",
      "epoch:  16\n",
      "29871 467\n",
      "Loss:  0.05555083975195885\n",
      "Loss:  0.11717399209737778\n",
      "Loss:  0.09091232717037201\n",
      "16 **********\n",
      "Epoch:  922.4355940818787  fold:  10  kers:  32\n",
      "epoch:  17\n",
      "29871 467\n",
      "Loss:  0.03753276169300079\n",
      "Loss:  0.07359383255243301\n",
      "Loss:  0.07169217616319656\n",
      "17 **********\n",
      "Epoch:  964.3096315860748  fold:  10  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.3076891303062439\n",
      "Eval Loss:  0.1727338433265686\n",
      "Eval Loss:  0.13738077878952026\n",
      "[[1607  144]\n",
      " [ 133 1136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1751\n",
      "           1       0.89      0.90      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9082781456953642\n",
      "pre:  0.8875\n",
      "rec:  0.8951930654058313\n",
      "ma F1:  0.9059915206495792\n",
      "mi F1:  0.9082781456953642\n",
      "we F1:  0.9083315488280684\n",
      "Eval Loss:  0.31604206562042236\n",
      "Eval Loss:  0.3271859288215637\n",
      "Eval Loss:  0.31516847014427185\n",
      "Eval Loss:  0.3384268283843994\n",
      "Eval Loss:  0.2488885521888733\n",
      "Eval Loss:  0.27983081340789795\n",
      "Eval Loss:  0.3794623911380768\n",
      "Eval Loss:  0.3339627683162689\n",
      "Eval Loss:  0.42088425159454346\n",
      "Eval Loss:  0.24324776232242584\n",
      "Eval Loss:  0.25371477007865906\n",
      "Eval Loss:  0.25649330019950867\n",
      "Eval Loss:  0.2375495731830597\n",
      "Eval Loss:  0.3046191930770874\n",
      "Eval Loss:  0.23587459325790405\n",
      "Eval Loss:  0.28780755400657654\n",
      "Eval Loss:  0.3450358808040619\n",
      "Eval Loss:  0.22691644728183746\n",
      "Eval Loss:  0.2468736171722412\n",
      "Eval Loss:  0.3749605417251587\n",
      "Eval Loss:  0.30839547514915466\n",
      "Eval Loss:  0.38959789276123047\n",
      "Eval Loss:  0.3541242480278015\n",
      "Eval Loss:  0.3128455877304077\n",
      "Eval Loss:  0.36731988191604614\n",
      "Eval Loss:  0.232330784201622\n",
      "Eval Loss:  0.3444325625896454\n",
      "Eval Loss:  0.3472140431404114\n",
      "Eval Loss:  0.3101394474506378\n",
      "[[16809  1604]\n",
      " [ 2277  9181]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90     18413\n",
      "           1       0.85      0.80      0.83     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.87      0.86      0.86     29871\n",
      "weighted avg       0.87      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8700746543470256\n",
      "pre:  0.8512749188687992\n",
      "rec:  0.8012742188863676\n",
      "ma F1:  0.8610110236547217\n",
      "mi F1:  0.8700746543470256\n",
      "we F1:  0.8692749921215509\n",
      "29871 467\n",
      "Loss:  0.09476455301046371\n",
      "Loss:  0.080922931432724\n",
      "Loss:  0.06732744723558426\n",
      "18 **********\n",
      "Epoch:  1045.3519406318665  fold:  10  kers:  32\n",
      "epoch:  19\n",
      "29871 467\n",
      "Loss:  0.10127623379230499\n",
      "Loss:  0.05654311552643776\n",
      "Loss:  0.09215417504310608\n",
      "19 **********\n",
      "Epoch:  1087.1890771389008  fold:  10  kers:  32\n",
      "epoch:  20\n",
      "29871 467\n",
      "Loss:  0.09446552395820618\n",
      "Loss:  0.07030662894248962\n",
      "Loss:  0.06789354234933853\n",
      "20 **********\n",
      "Epoch:  1129.0212259292603  fold:  10  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.4966997504234314\n",
      "Eval Loss:  0.10203531384468079\n",
      "Eval Loss:  0.07933451980352402\n",
      "[[1680   71]\n",
      " [ 222 1047]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1751\n",
      "           1       0.94      0.83      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.91      0.89      0.90      3020\n",
      "weighted avg       0.91      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9029801324503312\n",
      "pre:  0.9364937388193202\n",
      "rec:  0.8250591016548463\n",
      "ma F1:  0.8985218661490042\n",
      "mi F1:  0.9029801324503312\n",
      "we F1:  0.9019166281667602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3488008677959442\n",
      "Eval Loss:  0.30308210849761963\n",
      "Eval Loss:  0.3759908378124237\n",
      "Eval Loss:  0.3200090825557709\n",
      "Eval Loss:  0.2917042672634125\n",
      "Eval Loss:  0.32230594754219055\n",
      "Eval Loss:  0.39556050300598145\n",
      "Eval Loss:  0.3983301818370819\n",
      "Eval Loss:  0.4776456654071808\n",
      "Eval Loss:  0.27568158507347107\n",
      "Eval Loss:  0.2993521988391876\n",
      "Eval Loss:  0.3183556795120239\n",
      "Eval Loss:  0.23520252108573914\n",
      "Eval Loss:  0.38540980219841003\n",
      "Eval Loss:  0.30528876185417175\n",
      "Eval Loss:  0.3055662214756012\n",
      "Eval Loss:  0.378580242395401\n",
      "Eval Loss:  0.26493653655052185\n",
      "Eval Loss:  0.2697613835334778\n",
      "Eval Loss:  0.4209912419319153\n",
      "Eval Loss:  0.36972007155418396\n",
      "Eval Loss:  0.4234163761138916\n",
      "Eval Loss:  0.3828164041042328\n",
      "Eval Loss:  0.34092482924461365\n",
      "Eval Loss:  0.4431034326553345\n",
      "Eval Loss:  0.25299134850502014\n",
      "Eval Loss:  0.35457363724708557\n",
      "Eval Loss:  0.3875666856765747\n",
      "Eval Loss:  0.34836843609809875\n",
      "[[17717   696]\n",
      " [ 3626  7832]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18413\n",
      "           1       0.92      0.68      0.78     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.87      0.82      0.84     29871\n",
      "weighted avg       0.86      0.86      0.85     29871\n",
      "\n",
      "acc:  0.8553111713702253\n",
      "pre:  0.9183864915572233\n",
      "rec:  0.6835398847966486\n",
      "ma F1:  0.8375177369102532\n",
      "mi F1:  0.8553111713702253\n",
      "we F1:  0.8500370425925098\n",
      "29871 467\n",
      "Loss:  0.04539576172828674\n",
      "Loss:  0.061088427901268005\n",
      "Loss:  0.08396592736244202\n",
      "21 **********\n",
      "Epoch:  1210.141327381134  fold:  10  kers:  32\n",
      "epoch:  22\n",
      "29871 467\n",
      "Loss:  0.08207929879426956\n",
      "Loss:  0.058955781161785126\n",
      "Loss:  0.06788522750139236\n",
      "22 **********\n",
      "Epoch:  1252.0752046108246  fold:  10  kers:  32\n",
      "epoch:  23\n",
      "29871 467\n",
      "Loss:  0.0844588354229927\n",
      "Loss:  0.08405162394046783\n",
      "Loss:  0.08099591732025146\n",
      "23 **********\n",
      "Epoch:  1294.1128046512604  fold:  10  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.3845471441745758\n",
      "Eval Loss:  0.13326315581798553\n",
      "Eval Loss:  0.09382770210504532\n",
      "[[1661   90]\n",
      " [ 171 1098]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      1751\n",
      "           1       0.92      0.87      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9135761589403973\n",
      "pre:  0.9242424242424242\n",
      "rec:  0.8652482269503546\n",
      "ma F1:  0.9104644541429359\n",
      "mi F1:  0.9135761589403973\n",
      "we F1:  0.9131284713940487\n",
      "update!  Acc:  0.9135761589403973\n",
      "Eval Loss:  0.29033902287483215\n",
      "Eval Loss:  0.30091145634651184\n",
      "Eval Loss:  0.3332364559173584\n",
      "Eval Loss:  0.3158907890319824\n",
      "Eval Loss:  0.2453290969133377\n",
      "Eval Loss:  0.2679927349090576\n",
      "Eval Loss:  0.372539758682251\n",
      "Eval Loss:  0.3430793285369873\n",
      "Eval Loss:  0.43213629722595215\n",
      "Eval Loss:  0.24661092460155487\n",
      "Eval Loss:  0.24174262583255768\n",
      "Eval Loss:  0.2566010653972626\n",
      "Eval Loss:  0.23355434834957123\n",
      "Eval Loss:  0.3285059332847595\n",
      "Eval Loss:  0.24822576344013214\n",
      "Eval Loss:  0.2651057243347168\n",
      "Eval Loss:  0.34493011236190796\n",
      "Eval Loss:  0.21843849122524261\n",
      "Eval Loss:  0.240217387676239\n",
      "Eval Loss:  0.3824613392353058\n",
      "Eval Loss:  0.3218553066253662\n",
      "Eval Loss:  0.39122867584228516\n",
      "Eval Loss:  0.3475523293018341\n",
      "Eval Loss:  0.31207048892974854\n",
      "Eval Loss:  0.3736148178577423\n",
      "Eval Loss:  0.2225080281496048\n",
      "Eval Loss:  0.323910117149353\n",
      "Eval Loss:  0.3419915735721588\n",
      "Eval Loss:  0.3080476224422455\n",
      "[[17329  1084]\n",
      " [ 2696  8762]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     18413\n",
      "           1       0.89      0.76      0.82     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.88      0.85      0.86     29871\n",
      "weighted avg       0.87      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8734558601988551\n",
      "pre:  0.8899045297582775\n",
      "rec:  0.7647058823529411\n",
      "ma F1:  0.8621141737692022\n",
      "mi F1:  0.8734558601988551\n",
      "we F1:  0.8713217644215\n",
      "29871 467\n",
      "Loss:  0.06293966621160507\n",
      "Loss:  0.0822228342294693\n",
      "Loss:  0.0696716457605362\n",
      "24 **********\n",
      "Epoch:  1381.1939675807953  fold:  10  kers:  32\n",
      "epoch:  25\n",
      "29871 467\n",
      "Loss:  0.08367946743965149\n",
      "Loss:  0.058674611151218414\n",
      "Loss:  0.06304167211055756\n",
      "25 **********\n",
      "Epoch:  1422.9862236976624  fold:  10  kers:  32\n",
      "epoch:  26\n",
      "29871 467\n",
      "Loss:  0.07441039383411407\n",
      "Loss:  0.05572434887290001\n",
      "Loss:  0.08192305266857147\n",
      "26 **********\n",
      "Epoch:  1464.7814712524414  fold:  10  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.4501935839653015\n",
      "Eval Loss:  0.11661571264266968\n",
      "Eval Loss:  0.07860235124826431\n",
      "[[1663   88]\n",
      " [ 190 1079]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1751\n",
      "           1       0.92      0.85      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9079470198675497\n",
      "pre:  0.9245929734361611\n",
      "rec:  0.8502758077226162\n",
      "ma F1:  0.9043709871717067\n",
      "mi F1:  0.9079470198675497\n",
      "we F1:  0.9073224388145086\n",
      "Eval Loss:  0.32605746388435364\n",
      "Eval Loss:  0.2825877070426941\n",
      "Eval Loss:  0.333824098110199\n",
      "Eval Loss:  0.29814592003822327\n",
      "Eval Loss:  0.2596576511859894\n",
      "Eval Loss:  0.26825150847435\n",
      "Eval Loss:  0.34721794724464417\n",
      "Eval Loss:  0.34856706857681274\n",
      "Eval Loss:  0.4296090602874756\n",
      "Eval Loss:  0.24809113144874573\n",
      "Eval Loss:  0.2409699410200119\n",
      "Eval Loss:  0.2693675458431244\n",
      "Eval Loss:  0.22567203640937805\n",
      "Eval Loss:  0.3399023413658142\n",
      "Eval Loss:  0.2651253342628479\n",
      "Eval Loss:  0.2678784430027008\n",
      "Eval Loss:  0.3327873647212982\n",
      "Eval Loss:  0.23617158830165863\n",
      "Eval Loss:  0.25122860074043274\n",
      "Eval Loss:  0.3848399519920349\n",
      "Eval Loss:  0.3261399269104004\n",
      "Eval Loss:  0.3882755935192108\n",
      "Eval Loss:  0.34335222840309143\n",
      "Eval Loss:  0.3107371926307678\n",
      "Eval Loss:  0.37536072731018066\n",
      "Eval Loss:  0.22722801566123962\n",
      "Eval Loss:  0.3123512864112854\n",
      "Eval Loss:  0.3418368101119995\n",
      "Eval Loss:  0.31120720505714417\n",
      "[[17506   907]\n",
      " [ 2932  8526]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18413\n",
      "           1       0.90      0.74      0.82     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.88      0.85      0.86     29871\n",
      "weighted avg       0.87      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8714807003448161\n",
      "pre:  0.9038481925156366\n",
      "rec:  0.7441089195322046\n",
      "ma F1:  0.858711620788752\n",
      "mi F1:  0.8714807003448161\n",
      "we F1:  0.8686012586854587\n",
      "29871 467\n",
      "Loss:  0.08178094029426575\n",
      "Loss:  0.06782624125480652\n",
      "Loss:  0.055162183940410614\n",
      "27 **********\n",
      "Epoch:  1545.729033946991  fold:  10  kers:  32\n",
      "epoch:  28\n",
      "29871 467\n",
      "Loss:  0.09718736261129379\n",
      "Loss:  0.07248498499393463\n",
      "Loss:  0.0815335065126419\n",
      "28 **********\n",
      "Epoch:  1587.6090552806854  fold:  10  kers:  32\n",
      "epoch:  29\n",
      "29871 467\n",
      "Loss:  0.047426559031009674\n",
      "Loss:  0.053633566945791245\n",
      "Loss:  0.08668838441371918\n",
      "29 **********\n",
      "Epoch:  1629.5558984279633  fold:  10  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.3635820150375366\n",
      "Eval Loss:  0.13976378738880157\n",
      "Eval Loss:  0.08571777492761612\n",
      "[[1654   97]\n",
      " [ 160 1109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1751\n",
      "           1       0.92      0.87      0.90      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.92      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9149006622516557\n",
      "pre:  0.9195688225538972\n",
      "rec:  0.8739164696611506\n",
      "ma F1:  0.9120359272953944\n",
      "mi F1:  0.9149006622516557\n",
      "we F1:  0.9145695094035007\n",
      "update!  Acc:  0.9149006622516557\n",
      "Eval Loss:  0.29406213760375977\n",
      "Eval Loss:  0.2726634740829468\n",
      "Eval Loss:  0.31734904646873474\n",
      "Eval Loss:  0.29635512828826904\n",
      "Eval Loss:  0.2399178296327591\n",
      "Eval Loss:  0.24624858796596527\n",
      "Eval Loss:  0.32799723744392395\n",
      "Eval Loss:  0.30907687544822693\n",
      "Eval Loss:  0.40329891443252563\n",
      "Eval Loss:  0.23245351016521454\n",
      "Eval Loss:  0.22431227564811707\n",
      "Eval Loss:  0.24424903094768524\n",
      "Eval Loss:  0.21356526017189026\n",
      "Eval Loss:  0.3205510973930359\n",
      "Eval Loss:  0.23900637030601501\n",
      "Eval Loss:  0.25166183710098267\n",
      "Eval Loss:  0.3264884054660797\n",
      "Eval Loss:  0.21863962709903717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2335316240787506\n",
      "Eval Loss:  0.3631439208984375\n",
      "Eval Loss:  0.2983412444591522\n",
      "Eval Loss:  0.3796190321445465\n",
      "Eval Loss:  0.335499107837677\n",
      "Eval Loss:  0.2957507073879242\n",
      "Eval Loss:  0.3560670018196106\n",
      "Eval Loss:  0.20915214717388153\n",
      "Eval Loss:  0.31775379180908203\n",
      "Eval Loss:  0.3226816952228546\n",
      "Eval Loss:  0.2843100428581238\n",
      "[[17334  1079]\n",
      " [ 2521  8937]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91     18413\n",
      "           1       0.89      0.78      0.83     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.88      0.86      0.87     29871\n",
      "weighted avg       0.88      0.88      0.88     29871\n",
      "\n",
      "acc:  0.8794817716179573\n",
      "pre:  0.8922723642172524\n",
      "rec:  0.7799790539361146\n",
      "ma F1:  0.8691410146519483\n",
      "mi F1:  0.8794817716179572\n",
      "we F1:  0.8777059741254021\n",
      "29871 467\n",
      "Loss:  0.062462322413921356\n",
      "Loss:  0.04553896188735962\n",
      "Loss:  0.08198165893554688\n",
      "30 **********\n",
      "Epoch:  1710.2501378059387  fold:  10  kers:  32\n",
      "epoch:  31\n",
      "29871 467\n",
      "Loss:  0.07273268699645996\n",
      "Loss:  0.06894644349813461\n",
      "Loss:  0.07277027517557144\n",
      "31 **********\n",
      "Epoch:  1755.798351764679  fold:  10  kers:  32\n",
      "epoch:  32\n",
      "29871 467\n",
      "Loss:  0.08040173351764679\n",
      "Loss:  0.10989047586917877\n",
      "Loss:  0.10180602967739105\n",
      "32 **********\n",
      "Epoch:  1797.723252773285  fold:  10  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.44749289751052856\n",
      "Eval Loss:  0.10814321041107178\n",
      "Eval Loss:  0.06153692677617073\n",
      "[[1679   72]\n",
      " [ 190 1079]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      1751\n",
      "           1       0.94      0.85      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.92      0.90      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9132450331125828\n",
      "pre:  0.9374456993918332\n",
      "rec:  0.8502758077226162\n",
      "ma F1:  0.909679923291174\n",
      "mi F1:  0.9132450331125828\n",
      "we F1:  0.9125438948477058\n",
      "Eval Loss:  0.31869587302207947\n",
      "Eval Loss:  0.26662296056747437\n",
      "Eval Loss:  0.3578745424747467\n",
      "Eval Loss:  0.29153233766555786\n",
      "Eval Loss:  0.27430346608161926\n",
      "Eval Loss:  0.28433337807655334\n",
      "Eval Loss:  0.3392903506755829\n",
      "Eval Loss:  0.33389970660209656\n",
      "Eval Loss:  0.45105117559432983\n",
      "Eval Loss:  0.2507261037826538\n",
      "Eval Loss:  0.2423626184463501\n",
      "Eval Loss:  0.28519147634506226\n",
      "Eval Loss:  0.22660090029239655\n",
      "Eval Loss:  0.3607349395751953\n",
      "Eval Loss:  0.27028387784957886\n",
      "Eval Loss:  0.2602670192718506\n",
      "Eval Loss:  0.34753525257110596\n",
      "Eval Loss:  0.23723246157169342\n",
      "Eval Loss:  0.24640966951847076\n",
      "Eval Loss:  0.3894381523132324\n",
      "Eval Loss:  0.3332424759864807\n",
      "Eval Loss:  0.39573201537132263\n",
      "Eval Loss:  0.3495272696018219\n",
      "Eval Loss:  0.31439799070358276\n",
      "Eval Loss:  0.37698906660079956\n",
      "Eval Loss:  0.22414164245128632\n",
      "Eval Loss:  0.3357595205307007\n",
      "Eval Loss:  0.3341715931892395\n",
      "Eval Loss:  0.31056341528892517\n",
      "[[17614   799]\n",
      " [ 3085  8373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     18413\n",
      "           1       0.91      0.73      0.81     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.88      0.84      0.86     29871\n",
      "weighted avg       0.87      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8699742224900405\n",
      "pre:  0.912887047535979\n",
      "rec:  0.7307558038052016\n",
      "ma F1:  0.8562129641591563\n",
      "mi F1:  0.8699742224900405\n",
      "we F1:  0.8665700198556502\n",
      "29871 467\n",
      "Loss:  0.08582337200641632\n",
      "Loss:  0.06796427816152573\n",
      "Loss:  0.056913185864686966\n",
      "33 **********\n",
      "Epoch:  1878.7146978378296  fold:  10  kers:  32\n",
      "epoch:  34\n",
      "29871 467\n",
      "Loss:  0.04673849418759346\n",
      "Loss:  0.09298235923051834\n",
      "Loss:  0.10575969517230988\n",
      "34 **********\n",
      "Epoch:  1920.5937221050262  fold:  10  kers:  32\n",
      "epoch:  35\n",
      "29871 467\n",
      "Loss:  0.06937915086746216\n",
      "Loss:  0.07759101688861847\n",
      "Loss:  0.07709833234548569\n",
      "35 **********\n",
      "Epoch:  1962.5236101150513  fold:  10  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.36919111013412476\n",
      "Eval Loss:  0.1242763102054596\n",
      "Eval Loss:  0.10516195744276047\n",
      "[[1648  103]\n",
      " [ 151 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1751\n",
      "           1       0.92      0.88      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9158940397350993\n",
      "pre:  0.9156429156429157\n",
      "rec:  0.8810086682427108\n",
      "ma F1:  0.9132213360484189\n",
      "mi F1:  0.9158940397350993\n",
      "we F1:  0.9156519835521546\n",
      "update!  Acc:  0.9158940397350993\n",
      "Eval Loss:  0.26158127188682556\n",
      "Eval Loss:  0.2568541169166565\n",
      "Eval Loss:  0.3222167491912842\n",
      "Eval Loss:  0.29532626271247864\n",
      "Eval Loss:  0.2450886070728302\n",
      "Eval Loss:  0.24828097224235535\n",
      "Eval Loss:  0.3048401176929474\n",
      "Eval Loss:  0.27274760603904724\n",
      "Eval Loss:  0.36554309725761414\n",
      "Eval Loss:  0.22696390748023987\n",
      "Eval Loss:  0.21471849083900452\n",
      "Eval Loss:  0.23156435787677765\n",
      "Eval Loss:  0.2248743176460266\n",
      "Eval Loss:  0.30500319600105286\n",
      "Eval Loss:  0.22902822494506836\n",
      "Eval Loss:  0.23375175893306732\n",
      "Eval Loss:  0.31509795784950256\n",
      "Eval Loss:  0.19603893160820007\n",
      "Eval Loss:  0.2198372185230255\n",
      "Eval Loss:  0.35232701897621155\n",
      "Eval Loss:  0.2931463122367859\n",
      "Eval Loss:  0.3466256558895111\n",
      "Eval Loss:  0.33902326226234436\n",
      "Eval Loss:  0.27833500504493713\n",
      "Eval Loss:  0.31382644176483154\n",
      "Eval Loss:  0.2089434564113617\n",
      "Eval Loss:  0.3045041561126709\n",
      "Eval Loss:  0.29735448956489563\n",
      "Eval Loss:  0.2832332253456116\n",
      "[[17206  1207]\n",
      " [ 2220  9238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18413\n",
      "           1       0.88      0.81      0.84     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.88     29871\n",
      "\n",
      "acc:  0.8852733420374276\n",
      "pre:  0.8844423168980373\n",
      "rec:  0.8062489090591727\n",
      "ma F1:  0.8764847412048147\n",
      "mi F1:  0.8852733420374276\n",
      "we F1:  0.8841560161534621\n",
      "29871 467\n",
      "Loss:  0.06583212316036224\n",
      "Loss:  0.05377905070781708\n",
      "Loss:  0.07281415164470673\n",
      "36 **********\n",
      "Epoch:  2043.6816103458405  fold:  10  kers:  32\n",
      "epoch:  37\n",
      "29871 467\n",
      "Loss:  0.07352957874536514\n",
      "Loss:  0.06644447147846222\n",
      "Loss:  0.0713329017162323\n",
      "37 **********\n",
      "Epoch:  2085.5955407619476  fold:  10  kers:  32\n",
      "epoch:  38\n",
      "29871 467\n",
      "Loss:  0.0803375095129013\n",
      "Loss:  0.08102570474147797\n",
      "Loss:  0.03190615028142929\n",
      "38 **********\n",
      "Epoch:  2127.5074768066406  fold:  10  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.37549906969070435\n",
      "Eval Loss:  0.12765872478485107\n",
      "Eval Loss:  0.06896310299634933\n",
      "[[1653   98]\n",
      " [ 156 1113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1751\n",
      "           1       0.92      0.88      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9158940397350993\n",
      "pre:  0.9190751445086706\n",
      "rec:  0.8770685579196218\n",
      "ma F1:  0.9131161652772743\n",
      "mi F1:  0.9158940397350993\n",
      "we F1:  0.9155956754414811\n",
      "Eval Loss:  0.25731563568115234\n",
      "Eval Loss:  0.2629328668117523\n",
      "Eval Loss:  0.32433363795280457\n",
      "Eval Loss:  0.30018025636672974\n",
      "Eval Loss:  0.2489926666021347\n",
      "Eval Loss:  0.2400323748588562\n",
      "Eval Loss:  0.2908978760242462\n",
      "Eval Loss:  0.2862337827682495\n",
      "Eval Loss:  0.3721003532409668\n",
      "Eval Loss:  0.22676712274551392\n",
      "Eval Loss:  0.204789936542511\n",
      "Eval Loss:  0.2154856026172638\n",
      "Eval Loss:  0.22598618268966675\n",
      "Eval Loss:  0.2909155786037445\n",
      "Eval Loss:  0.23533222079277039\n",
      "Eval Loss:  0.23553775250911713\n",
      "Eval Loss:  0.3127819299697876\n",
      "Eval Loss:  0.1964716762304306\n",
      "Eval Loss:  0.21407079696655273\n",
      "Eval Loss:  0.33749231696128845\n",
      "Eval Loss:  0.27791842818260193\n",
      "Eval Loss:  0.3576653301715851\n",
      "Eval Loss:  0.3176082670688629\n",
      "Eval Loss:  0.2683933675289154\n",
      "Eval Loss:  0.309124231338501\n",
      "Eval Loss:  0.2054349035024643\n",
      "Eval Loss:  0.28606119751930237\n",
      "Eval Loss:  0.29549264907836914\n",
      "Eval Loss:  0.2695726156234741\n",
      "[[17253  1160]\n",
      " [ 2230  9228]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     18413\n",
      "           1       0.89      0.81      0.84     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8865120016069097\n",
      "pre:  0.888332691567193\n",
      "rec:  0.805376156397277\n",
      "ma F1:  0.8776837496884315\n",
      "mi F1:  0.8865120016069097\n",
      "we F1:  0.8853349013511126\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.061924923211336136\n",
      "Loss:  0.052797265350818634\n",
      "Loss:  0.0658850446343422\n",
      "39 **********\n",
      "Epoch:  2208.68941283226  fold:  10  kers:  32\n",
      "epoch:  40\n",
      "29871 467\n",
      "Loss:  0.07363011687994003\n",
      "Loss:  0.07924224436283112\n",
      "Loss:  0.07257837057113647\n",
      "40 **********\n",
      "Epoch:  2250.757929801941  fold:  10  kers:  32\n",
      "epoch:  41\n",
      "29871 467\n",
      "Loss:  0.0655307024717331\n",
      "Loss:  0.06345859169960022\n",
      "Loss:  0.073560930788517\n",
      "41 **********\n",
      "Epoch:  2292.730703353882  fold:  10  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.4785183072090149\n",
      "Eval Loss:  0.10381456464529037\n",
      "Eval Loss:  0.14267250895500183\n",
      "[[1624  127]\n",
      " [ 173 1096]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      1751\n",
      "           1       0.90      0.86      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.90      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9006622516556292\n",
      "pre:  0.8961569910057237\n",
      "rec:  0.863672182821119\n",
      "ma F1:  0.897530044281498\n",
      "mi F1:  0.9006622516556292\n",
      "we F1:  0.9003893699525799\n",
      "Eval Loss:  0.25242000818252563\n",
      "Eval Loss:  0.2773447334766388\n",
      "Eval Loss:  0.31984254717826843\n",
      "Eval Loss:  0.30106121301651\n",
      "Eval Loss:  0.2459040731191635\n",
      "Eval Loss:  0.2578616738319397\n",
      "Eval Loss:  0.3095923960208893\n",
      "Eval Loss:  0.276359498500824\n",
      "Eval Loss:  0.35207873582839966\n",
      "Eval Loss:  0.23473002016544342\n",
      "Eval Loss:  0.20758995413780212\n",
      "Eval Loss:  0.21431215107440948\n",
      "Eval Loss:  0.2511533796787262\n",
      "Eval Loss:  0.2795749604701996\n",
      "Eval Loss:  0.23734229803085327\n",
      "Eval Loss:  0.24056962132453918\n",
      "Eval Loss:  0.30840978026390076\n",
      "Eval Loss:  0.19055971503257751\n",
      "Eval Loss:  0.2244545966386795\n",
      "Eval Loss:  0.33953213691711426\n",
      "Eval Loss:  0.27935269474983215\n",
      "Eval Loss:  0.3439551889896393\n",
      "Eval Loss:  0.3266989290714264\n",
      "Eval Loss:  0.31533005833625793\n",
      "Eval Loss:  0.3275015354156494\n",
      "Eval Loss:  0.2035405933856964\n",
      "Eval Loss:  0.3038569986820221\n",
      "Eval Loss:  0.304473340511322\n",
      "Eval Loss:  0.273988276720047\n",
      "[[17101  1312]\n",
      " [ 2047  9411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18413\n",
      "           1       0.88      0.82      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8875497974624218\n",
      "pre:  0.8776461811060338\n",
      "rec:  0.8213475301099669\n",
      "ma F1:  0.8795681111861775\n",
      "mi F1:  0.8875497974624218\n",
      "we F1:  0.8867869184750304\n",
      "29871 467\n",
      "Loss:  0.0801854133605957\n",
      "Loss:  0.08597508072853088\n",
      "Loss:  0.05368317663669586\n",
      "42 **********\n",
      "Epoch:  2373.9435567855835  fold:  10  kers:  32\n",
      "epoch:  43\n",
      "29871 467\n",
      "Loss:  0.05870945006608963\n",
      "Loss:  0.0919141173362732\n",
      "Loss:  0.05508958548307419\n",
      "43 **********\n",
      "Epoch:  2415.88640999794  fold:  10  kers:  32\n",
      "epoch:  44\n",
      "29871 467\n",
      "Loss:  0.056664638221263885\n",
      "Loss:  0.0715339332818985\n",
      "Loss:  0.07753430306911469\n",
      "44 **********\n",
      "Epoch:  2457.811311483383  fold:  10  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.3753623366355896\n",
      "Eval Loss:  0.14917367696762085\n",
      "Eval Loss:  0.06253665685653687\n",
      "[[1610  141]\n",
      " [ 138 1131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1751\n",
      "           1       0.89      0.89      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9076158940397351\n",
      "pre:  0.8891509433962265\n",
      "rec:  0.8912529550827423\n",
      "ma F1:  0.9052318203244443\n",
      "mi F1:  0.9076158940397351\n",
      "we F1:  0.9076308256078893\n",
      "Eval Loss:  0.25100642442703247\n",
      "Eval Loss:  0.272266685962677\n",
      "Eval Loss:  0.32173851132392883\n",
      "Eval Loss:  0.30759483575820923\n",
      "Eval Loss:  0.2405165582895279\n",
      "Eval Loss:  0.2296542227268219\n",
      "Eval Loss:  0.2833854556083679\n",
      "Eval Loss:  0.25847792625427246\n",
      "Eval Loss:  0.3432828187942505\n",
      "Eval Loss:  0.2357371747493744\n",
      "Eval Loss:  0.1971225142478943\n",
      "Eval Loss:  0.21701613068580627\n",
      "Eval Loss:  0.24828845262527466\n",
      "Eval Loss:  0.28698065876960754\n",
      "Eval Loss:  0.22440125048160553\n",
      "Eval Loss:  0.23704716563224792\n",
      "Eval Loss:  0.30175870656967163\n",
      "Eval Loss:  0.19484707713127136\n",
      "Eval Loss:  0.20347809791564941\n",
      "Eval Loss:  0.3236074447631836\n",
      "Eval Loss:  0.2597683370113373\n",
      "Eval Loss:  0.33119121193885803\n",
      "Eval Loss:  0.31632792949676514\n",
      "Eval Loss:  0.2789090871810913\n",
      "Eval Loss:  0.30593952536582947\n",
      "Eval Loss:  0.20578086376190186\n",
      "Eval Loss:  0.2707284092903137\n",
      "Eval Loss:  0.2940429151058197\n",
      "Eval Loss:  0.26459723711013794\n",
      "[[16922  1491]\n",
      " [ 1759  9699]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91     18413\n",
      "           1       0.87      0.85      0.86     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8911988215995447\n",
      "pre:  0.8667560321715818\n",
      "rec:  0.8464828067725606\n",
      "ma F1:  0.884442111201464\n",
      "mi F1:  0.8911988215995447\n",
      "we F1:  0.8909481226674272\n",
      "29871 467\n",
      "Loss:  0.0843510553240776\n",
      "Loss:  0.10256144404411316\n",
      "Loss:  0.08526816964149475\n",
      "45 **********\n",
      "Epoch:  2538.914457798004  fold:  10  kers:  32\n",
      "epoch:  46\n",
      "29871 467\n",
      "Loss:  0.08012200146913528\n",
      "Loss:  0.05361628532409668\n",
      "Loss:  0.11088085919618607\n",
      "46 **********\n",
      "Epoch:  2580.8982021808624  fold:  10  kers:  32\n",
      "epoch:  47\n",
      "29871 467\n",
      "Loss:  0.0698358342051506\n",
      "Loss:  0.06601692736148834\n",
      "Loss:  0.08493422716856003\n",
      "47 **********\n",
      "Epoch:  2622.8280901908875  fold:  10  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.532755434513092\n",
      "Eval Loss:  0.08693784475326538\n",
      "Eval Loss:  0.04357044771313667\n",
      "[[1675   76]\n",
      " [ 202 1067]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      1751\n",
      "           1       0.93      0.84      0.88      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9079470198675497\n",
      "pre:  0.9335083114610674\n",
      "rec:  0.8408195429472025\n",
      "ma F1:  0.9040583557771598\n",
      "mi F1:  0.9079470198675497\n",
      "we F1:  0.9071411454014492\n",
      "Eval Loss:  0.2732933461666107\n",
      "Eval Loss:  0.23037442564964294\n",
      "Eval Loss:  0.314846932888031\n",
      "Eval Loss:  0.2857736349105835\n",
      "Eval Loss:  0.25721728801727295\n",
      "Eval Loss:  0.2443351149559021\n",
      "Eval Loss:  0.2897859513759613\n",
      "Eval Loss:  0.27669012546539307\n",
      "Eval Loss:  0.3652663230895996\n",
      "Eval Loss:  0.22489359974861145\n",
      "Eval Loss:  0.21271666884422302\n",
      "Eval Loss:  0.22036023437976837\n",
      "Eval Loss:  0.2268649935722351\n",
      "Eval Loss:  0.2999165952205658\n",
      "Eval Loss:  0.2442714422941208\n",
      "Eval Loss:  0.2334323525428772\n",
      "Eval Loss:  0.2915059030056\n",
      "Eval Loss:  0.20286963880062103\n",
      "Eval Loss:  0.20193122327327728\n",
      "Eval Loss:  0.3317211866378784\n",
      "Eval Loss:  0.2864077389240265\n",
      "Eval Loss:  0.3279709219932556\n",
      "Eval Loss:  0.3127470314502716\n",
      "Eval Loss:  0.2538159489631653\n",
      "Eval Loss:  0.3107057213783264\n",
      "Eval Loss:  0.20595847070217133\n",
      "Eval Loss:  0.2971363365650177\n",
      "Eval Loss:  0.3054693341255188\n",
      "Eval Loss:  0.27225473523139954\n",
      "[[17588   825]\n",
      " [ 2533  8925]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     18413\n",
      "           1       0.92      0.78      0.84     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8875832747480834\n",
      "pre:  0.9153846153846154\n",
      "rec:  0.7789317507418397\n",
      "ma F1:  0.8772598510788172\n",
      "mi F1:  0.8875832747480834\n",
      "we F1:  0.885547905057779\n",
      "29871 467\n",
      "Loss:  0.05276472866535187\n",
      "Loss:  0.06165122240781784\n",
      "Loss:  0.0797237977385521\n",
      "48 **********\n",
      "Epoch:  2704.1117539405823  fold:  10  kers:  32\n",
      "epoch:  49\n",
      "29871 467\n",
      "Loss:  0.06954535096883774\n",
      "Loss:  0.07639442384243011\n",
      "Loss:  0.04957790672779083\n",
      "49 **********\n",
      "Epoch:  2746.0456314086914  fold:  10  kers:  32\n",
      "epoch:  50\n",
      "29871 467\n",
      "Loss:  0.08113136887550354\n",
      "Loss:  0.06214552000164986\n",
      "Loss:  0.06311523169279099\n",
      "50 **********\n",
      "Epoch:  2787.910692691803  fold:  10  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.40616393089294434\n",
      "Eval Loss:  0.10891977697610855\n",
      "Eval Loss:  0.06739655137062073\n",
      "[[1657   94]\n",
      " [ 166 1103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      1751\n",
      "           1       0.92      0.87      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9139072847682119\n",
      "pre:  0.9214703425229741\n",
      "rec:  0.8691883372734437\n",
      "ma F1:  0.9109092386166469\n",
      "mi F1:  0.9139072847682119\n",
      "we F1:  0.9135176470012215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23313647508621216\n",
      "Eval Loss:  0.2478771209716797\n",
      "Eval Loss:  0.29797083139419556\n",
      "Eval Loss:  0.29927390813827515\n",
      "Eval Loss:  0.2571316063404083\n",
      "Eval Loss:  0.232443705201149\n",
      "Eval Loss:  0.28401294350624084\n",
      "Eval Loss:  0.24784722924232483\n",
      "Eval Loss:  0.34245675802230835\n",
      "Eval Loss:  0.22386384010314941\n",
      "Eval Loss:  0.20089755952358246\n",
      "Eval Loss:  0.20001579821109772\n",
      "Eval Loss:  0.2162935584783554\n",
      "Eval Loss:  0.27653253078460693\n",
      "Eval Loss:  0.22698524594306946\n",
      "Eval Loss:  0.23674878478050232\n",
      "Eval Loss:  0.3048473298549652\n",
      "Eval Loss:  0.19698719680309296\n",
      "Eval Loss:  0.19420413672924042\n",
      "Eval Loss:  0.3195067346096039\n",
      "Eval Loss:  0.263554185628891\n",
      "Eval Loss:  0.31561917066574097\n",
      "Eval Loss:  0.29975640773773193\n",
      "Eval Loss:  0.2676655650138855\n",
      "Eval Loss:  0.3128957748413086\n",
      "Eval Loss:  0.18926092982292175\n",
      "Eval Loss:  0.28007829189300537\n",
      "Eval Loss:  0.29590556025505066\n",
      "Eval Loss:  0.25252193212509155\n",
      "[[17303  1110]\n",
      " [ 2097  9361]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     18413\n",
      "           1       0.89      0.82      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8926383448829969\n",
      "pre:  0.8939929328621908\n",
      "rec:  0.8169837668004888\n",
      "ma F1:  0.8844715997705828\n",
      "mi F1:  0.8926383448829968\n",
      "we F1:  0.8916234144591801\n",
      "29871 467\n",
      "Loss:  0.08164902776479721\n",
      "Loss:  0.08722031116485596\n",
      "Loss:  0.07633150368928909\n",
      "51 **********\n",
      "Epoch:  2869.102602005005  fold:  10  kers:  32\n",
      "epoch:  52\n",
      "29871 467\n",
      "Loss:  0.051321107894182205\n",
      "Loss:  0.08526082336902618\n",
      "Loss:  0.053959280252456665\n",
      "52 **********\n",
      "Epoch:  2911.025508403778  fold:  10  kers:  32\n",
      "epoch:  53\n",
      "29871 467\n",
      "Loss:  0.06573259830474854\n",
      "Loss:  0.0772770419716835\n",
      "Loss:  0.06772667169570923\n",
      "53 **********\n",
      "Epoch:  2952.9404368400574  fold:  10  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.5047253966331482\n",
      "Eval Loss:  0.10304168611764908\n",
      "Eval Loss:  0.0550321526825428\n",
      "[[1666   85]\n",
      " [ 195 1074]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1751\n",
      "           1       0.93      0.85      0.88      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9072847682119205\n",
      "pre:  0.9266609145815358\n",
      "rec:  0.8463356973995272\n",
      "ma F1:  0.9035796840478654\n",
      "mi F1:  0.9072847682119205\n",
      "we F1:  0.9065963235192752\n",
      "Eval Loss:  0.2259601354598999\n",
      "Eval Loss:  0.25064393877983093\n",
      "Eval Loss:  0.302864134311676\n",
      "Eval Loss:  0.28052443265914917\n",
      "Eval Loss:  0.2478559911251068\n",
      "Eval Loss:  0.23918677866458893\n",
      "Eval Loss:  0.26821863651275635\n",
      "Eval Loss:  0.2398027777671814\n",
      "Eval Loss:  0.3358808755874634\n",
      "Eval Loss:  0.2188578099012375\n",
      "Eval Loss:  0.1944829672574997\n",
      "Eval Loss:  0.20210936665534973\n",
      "Eval Loss:  0.2271251082420349\n",
      "Eval Loss:  0.2684377431869507\n",
      "Eval Loss:  0.23151534795761108\n",
      "Eval Loss:  0.22243134677410126\n",
      "Eval Loss:  0.2942273020744324\n",
      "Eval Loss:  0.19231164455413818\n",
      "Eval Loss:  0.19362613558769226\n",
      "Eval Loss:  0.30675023794174194\n",
      "Eval Loss:  0.25134018063545227\n",
      "Eval Loss:  0.3113780915737152\n",
      "Eval Loss:  0.30828672647476196\n",
      "Eval Loss:  0.24612605571746826\n",
      "Eval Loss:  0.2968270778656006\n",
      "Eval Loss:  0.19262057542800903\n",
      "Eval Loss:  0.27893319725990295\n",
      "Eval Loss:  0.28456827998161316\n",
      "Eval Loss:  0.2478092908859253\n",
      "[[17321  1092]\n",
      " [ 2076  9382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     18413\n",
      "           1       0.90      0.82      0.86     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.88      0.89     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8939439590238023\n",
      "pre:  0.8957418369295398\n",
      "rec:  0.8188165473904695\n",
      "ma F1:  0.8858830856240367\n",
      "mi F1:  0.8939439590238023\n",
      "we F1:  0.8929448534153668\n",
      "29871 467\n",
      "Loss:  0.06555449217557907\n",
      "Loss:  0.058218564838171005\n",
      "Loss:  0.07360704988241196\n",
      "54 **********\n",
      "Epoch:  3034.220111131668  fold:  10  kers:  32\n",
      "epoch:  55\n",
      "29871 467\n",
      "Loss:  0.05161936208605766\n",
      "Loss:  0.07123704254627228\n",
      "Loss:  0.09175572544336319\n",
      "55 **********\n",
      "Epoch:  3076.129055261612  fold:  10  kers:  32\n",
      "epoch:  56\n",
      "29871 467\n",
      "Loss:  0.059241753071546555\n",
      "Loss:  0.07780800759792328\n",
      "Loss:  0.05488201230764389\n",
      "56 **********\n",
      "Epoch:  3118.1207780838013  fold:  10  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.48541373014450073\n",
      "Eval Loss:  0.10680797696113586\n",
      "Eval Loss:  0.03475475311279297\n",
      "[[1669   82]\n",
      " [ 185 1084]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93      1751\n",
      "           1       0.93      0.85      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.91158940397351\n",
      "pre:  0.9296740994854202\n",
      "rec:  0.8542159180457053\n",
      "ma F1:  0.9081426378489834\n",
      "mi F1:  0.91158940397351\n",
      "we F1:  0.910982537459277\n",
      "Eval Loss:  0.2287554293870926\n",
      "Eval Loss:  0.23814380168914795\n",
      "Eval Loss:  0.30512574315071106\n",
      "Eval Loss:  0.2794564664363861\n",
      "Eval Loss:  0.2619284987449646\n",
      "Eval Loss:  0.22792841494083405\n",
      "Eval Loss:  0.27133259177207947\n",
      "Eval Loss:  0.25497663021087646\n",
      "Eval Loss:  0.3443581461906433\n",
      "Eval Loss:  0.21349455416202545\n",
      "Eval Loss:  0.20750047266483307\n",
      "Eval Loss:  0.20053556561470032\n",
      "Eval Loss:  0.22040237486362457\n",
      "Eval Loss:  0.26680874824523926\n",
      "Eval Loss:  0.2240723818540573\n",
      "Eval Loss:  0.23204030096530914\n",
      "Eval Loss:  0.29779767990112305\n",
      "Eval Loss:  0.20557576417922974\n",
      "Eval Loss:  0.19090263545513153\n",
      "Eval Loss:  0.330180823802948\n",
      "Eval Loss:  0.2441389411687851\n",
      "Eval Loss:  0.339295893907547\n",
      "Eval Loss:  0.3154227137565613\n",
      "Eval Loss:  0.22565317153930664\n",
      "Eval Loss:  0.2777932584285736\n",
      "Eval Loss:  0.19489620625972748\n",
      "Eval Loss:  0.2744859755039215\n",
      "Eval Loss:  0.29438579082489014\n",
      "Eval Loss:  0.24756819009780884\n",
      "[[17473   940]\n",
      " [ 2181  9277]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18413\n",
      "           1       0.91      0.81      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.88      0.89     29871\n",
      "weighted avg       0.90      0.90      0.89     29871\n",
      "\n",
      "acc:  0.8955173914499013\n",
      "pre:  0.9079964764608006\n",
      "rec:  0.8096526444405655\n",
      "ma F1:  0.8870111021697948\n",
      "mi F1:  0.8955173914499013\n",
      "we F1:  0.89422940889785\n",
      "29871 467\n",
      "Loss:  0.0567617304623127\n",
      "Loss:  0.06007629632949829\n",
      "Loss:  0.06117657572031021\n",
      "57 **********\n",
      "Epoch:  3199.291743516922  fold:  10  kers:  32\n",
      "epoch:  58\n",
      "29871 467\n",
      "Loss:  0.073285311460495\n",
      "Loss:  0.06589831411838531\n",
      "Loss:  0.05672174692153931\n",
      "58 **********\n",
      "Epoch:  3242.8203568458557  fold:  10  kers:  32\n",
      "epoch:  59\n",
      "29871 467\n",
      "Loss:  0.08699734508991241\n",
      "Loss:  0.06608613580465317\n",
      "Loss:  0.0922793298959732\n",
      "59 **********\n",
      "Epoch:  3285.0644047260284  fold:  10  kers:  32\n",
      "Eval Loss:  0.46595335006713867\n",
      "Eval Loss:  0.1158805638551712\n",
      "Eval Loss:  0.04942333698272705\n",
      "[[1637  114]\n",
      " [ 165 1104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1751\n",
      "           1       0.91      0.87      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9076158940397351\n",
      "pre:  0.9064039408866995\n",
      "rec:  0.8699763593380615\n",
      "ma F1:  0.9046457282909124\n",
      "mi F1:  0.9076158940397351\n",
      "we F1:  0.907331694315176\n",
      "update!  Acc:  0.9158940397350993\n",
      "Epoch:  3288.640842437744  fold:  10  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from time import time\n",
    "for kers in [128,64,32]:\n",
    "    print(\"  \")\n",
    "    print(\"kernel:\",kers)\n",
    "    print(\"  \")\n",
    "    for fold in range(1,11):\n",
    "        begin=time()\n",
    "        #train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "        train_dtlist,test_dtlist=getTrainTestList(reclist,opt='kfold',fold = fold)#fold 1-10   \n",
    "        print('*********')\n",
    "\n",
    "        train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "        np.random.shuffle(train_dtlist)\n",
    "        test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "        print(len(train_dtlist),len(test_dtlist))\n",
    "        model = MyLSTM(2,kers).to(device)\n",
    "\n",
    "        #model.features[0]=nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if(m.in_channels!=m.out_channels or m.out_channels!=m.groups or m.bias is not None):\n",
    "                    # don't want to reinitialize downsample layers, code assuming normal conv layers will not have these characteristics\n",
    "                    #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                    print(m,'init')\n",
    "                else:\n",
    "                    print('Not initializing')\n",
    "        criterion=nn.CrossEntropyLoss().to(device)#weight=torch.FloatTensor([1,1.5])\n",
    "        #criterion = CircleLoss(m=0.25, gamma=256)\n",
    "        opt=torch.optim.Adam(model.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001)\n",
    "        loss_list=[]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        epoch_flag=0\n",
    "        best_acc=0\n",
    "        for epoch in range(60):\n",
    "            print('epoch: ', epoch)\n",
    "            if epoch_flag%3==0 and epoch_flag!=0:\n",
    "                model.eval()\n",
    "                prob_file,lab_file,tmp_acc,seg_file=eval(model,test_dtlist,criterion,device)\n",
    "                if tmp_acc>best_acc:\n",
    "                    best_acc=tmp_acc                   \n",
    "                    res_file_name=\"./weights/fold_%.0f_w_%.0f_fs_%.0f.csv\"%(fold,kers,48)\n",
    "                    res_file=pd.DataFrame({\"prob\":prob_file,'label':lab_file,'seg':seg_file})\n",
    "                    res_file.to_csv(res_file_name,index=False)\n",
    "                    torch.save(model.state_dict(), \"./weights/fold_%.0f_w_%.0f_fs_%.0f.pkl\"%(fold,kers,48))\n",
    "                    print(\"update! \",'Acc: ',best_acc)\n",
    "                #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "                _,_,_,_=eval(model,train_dtlist,criterion,device)\n",
    "                model.train()\n",
    "            train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "            #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "            train_loader=DataLoader(train_dataset, batch_size=64, shuffle=True, sampler=None, num_workers=0)\n",
    "\n",
    "            #test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "            print(len(train_dataset),len(train_loader)) #,len(test_dataset)\n",
    "            flag=0\n",
    "            accum_flag=0\n",
    "            for fe, label,seg_id in train_loader:\n",
    "                del seg_id\n",
    "                fe=fe.float().to(device)\n",
    "                #fe=(fe-fe_mean)/fe_std\n",
    "                #fe=torch.stft(fe,100,hop_length=50,onesided=True)\n",
    "\n",
    "                label=label.long().to(device)\n",
    "                pred_prob_no_softmax=model(fe)\n",
    "                loss=criterion(pred_prob_no_softmax,label)/4#/256\n",
    "                del label\n",
    "                del fe\n",
    "                #inp_sp, inp_sn = convert_label_to_similarity(pred_prob_no_softmax,label)\n",
    "                #loss = criterion(inp_sp, inp_sn)/256\n",
    "                \n",
    "                loss_list.append(loss.item())\n",
    "                loss.backward()\n",
    "                accum_flag+=1\n",
    "                if accum_flag%4==0:\n",
    "                    opt.step()\n",
    "                    accum_flag=0\n",
    "                    opt.zero_grad()\n",
    "                flag+=1\n",
    "                if flag%128==0:\n",
    "                    print(\"Loss: \", loss.item())\n",
    "                #print('step')\n",
    "            print(epoch_flag,'*'*10)\n",
    "            epoch_flag+=1\n",
    "            #scheduler.step()\n",
    "            print('Epoch: ', time()-begin,' fold: ',fold,' kers: ',kers)\n",
    "            \n",
    "        model.eval()\n",
    "\n",
    "        prob_file,lab_file,tmp_acc,seg_file=eval(model,test_dtlist,criterion,device)\n",
    "        if tmp_acc>best_acc:\n",
    "            best_acc=tmp_acc                   \n",
    "            res_file_name=\"./weights/fold_%.0f_w_%.0f_fs_%.0f.csv\"%(fold,kers,48)\n",
    "            res_file=pd.DataFrame({\"prob\":prob_file,'label':lab_file,'seg':seg_file})\n",
    "            res_file.to_csv(res_file_name,index=False)\n",
    "            torch.save(model.state_dict(), \"./weights/fold_%.0f_w_%.0f_fs_%.0f.pkl\"%(fold,kers,48))\n",
    "        print(\"update! \",'Acc: ',best_acc)\n",
    "        #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "\n",
    "        print('Epoch: ', time()-begin,' fold: ',fold,' kers: ',kers)\n",
    "        plt.plot(loss_list)\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "        print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blind val ^^^^^^^^^^^^^^^^^^^^\n",
      "  \n",
      "kernel: 128\n",
      "  \n",
      "70 0 []\n",
      "*********\n",
      "32891 0\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "32891 129\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0c76cec02dde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#,len(test_dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mflag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m                 \u001b[0mfe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;31m#fe=(fe-fe_mean)/fe_std\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "print('blind val','^^^^^^^^^^^^^^^^^^^^')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from time import time\n",
    "for kers in [128,64,32]:\n",
    "    print(\"  \")\n",
    "    print(\"kernel:\",kers)\n",
    "    print(\"  \")\n",
    "    for fold in range(1,11):\n",
    "        begin=time()\n",
    "        #train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "        train_dtlist,test_dtlist=getTrainTestList(reclist,opt='blind',fold = fold)#fold 1-10   \n",
    "        print('*********')\n",
    "\n",
    "        train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "        np.random.shuffle(train_dtlist)\n",
    "        test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "        print(len(train_dtlist),len(test_dtlist))\n",
    "        model = MyLSTM(2,kers).to(device)\n",
    "\n",
    "        #model.features[0]=nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if(m.in_channels!=m.out_channels or m.out_channels!=m.groups or m.bias is not None):\n",
    "                    # don't want to reinitialize downsample layers, code assuming normal conv layers will not have these characteristics\n",
    "                    #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                    print(m,'init')\n",
    "                else:\n",
    "                    print('Not initializing')\n",
    "        criterion=nn.CrossEntropyLoss().to(device)#weight=torch.FloatTensor([1,1.5])\n",
    "        #criterion = CircleLoss(m=0.25, gamma=256)\n",
    "        opt=torch.optim.Adam(model.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001)\n",
    "        loss_list=[]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        epoch_flag=0\n",
    "        for epoch in range(60):\n",
    "            print('epoch: ', epoch)\n",
    "            if epoch_flag%3==0 and epoch_flag!=0:\n",
    "                model.eval()\n",
    "                eval(model,test_dtlist,criterion,device)\n",
    "                #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "                eval(model,train_dtlist,criterion,device)\n",
    "                model.train()\n",
    "            train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "            #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "            train_loader=DataLoader(train_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "\n",
    "            #test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "            print(len(train_dataset),len(train_loader)) #,len(test_dataset)\n",
    "            flag=0\n",
    "            for fe, label in train_loader:\n",
    "                fe=fe.float().to(device)\n",
    "                #fe=(fe-fe_mean)/fe_std\n",
    "                #fe=torch.stft(fe,100,hop_length=50,onesided=True)\n",
    "\n",
    "                label=label.long().to(device)\n",
    "                pred_prob_no_softmax=model(fe)\n",
    "                loss=criterion(pred_prob_no_softmax,label)#/256\n",
    "\n",
    "                #inp_sp, inp_sn = convert_label_to_similarity(pred_prob_no_softmax,label)\n",
    "                #loss = criterion(inp_sp, inp_sn)/256\n",
    "\n",
    "                loss_list.append(loss.item())\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "                flag+=1\n",
    "                if flag%4==0:\n",
    "                    print(\"Loss: \", loss.item())\n",
    "\n",
    "                #print('step')\n",
    "            print(epoch_flag,'*'*10)\n",
    "            epoch_flag+=1\n",
    "            #scheduler.step()\n",
    "            \n",
    "        model.eval()\n",
    "        eval(model,test_dtlist,criterion,device)\n",
    "        print('Epoch: ', time()-begin,' fold: ',fold,' kers: ',kers)\n",
    "        plt.plot(loss_list)\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "        print('------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
