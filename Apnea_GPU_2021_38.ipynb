{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import wfdb\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, lfilter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchvision.models.alexnet import alexnet\n",
    "\n",
    "\n",
    "seed=2020\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a01_100'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reclist=glob(\"./seg/*\")\n",
    "dtlist=glob(\"./seg/*/*.npy*\")\n",
    "reclist.sort()\n",
    "dtlist.sort()\n",
    "lab_list=[seg.split('_')[0][-1] for seg in dtlist]#shuffle by idx\n",
    "(dtlist[0].split('_')[1]+'_'+dtlist[0].split('_')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cheb_bandpass_filter(data, lowcut, highcut, signal_freq, filter_order):    # \n",
    "        \"\"\"\n",
    "        Method responsible for creating and applying Butterworth filter.\n",
    "        :param deque data: raw data\n",
    "        :param float lowcut: filter lowcut frequency value\n",
    "        :param float highcut: filter highcut frequency value\n",
    "        :param int signal_freq: signal frequency in samples per second (Hz)\n",
    "        :param int filter_order: filter order\n",
    "        :return array: filtered data\n",
    "        \"\"\"\n",
    "        nyquist_freq = 0.5 * signal_freq\n",
    "        low = lowcut / nyquist_freq\n",
    "        high = highcut / nyquist_freq\n",
    "        #b, a = butter(filter_order, [low, high], btype=\"band\")\n",
    "        b, a = signal.cheby2(filter_order, 40, [low, high], 'band', analog=False)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects=[['a11'],['a15'],['a17'],['b01'],['c07'],\n",
    "          ['a11','a15','a17','b01','c07'],\n",
    "          ['a14','a19','b05','c01','c07'],\n",
    "          ['a04','a19','b05','c01','c09'],['b02','b03'],['x16','x21']]\n",
    "len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def getTrainTestList(reclist,opt='rec_cv',fold=1):\n",
    "    train_dtlist=[]\n",
    "    test_dtlist=[]\n",
    "    if opt=='rec_cv':#reclist is rec list\n",
    "        kf = KFold(n_splits=10)\n",
    "        kf_idx=kf.split(reclist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_rec,test_rec=list(np.array(reclist)[train_idx]),list(np.array(reclist)[test_idx])\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "    elif opt=='physionet':\n",
    "        train_rec=[rec for rec in reclist if rec[-3]!='x']\n",
    "        test_rec=[rec for rec in reclist if rec[-3]=='x']\n",
    "        print(len(train_rec),len(test_rec))\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "    elif opt=='physionet_train':\n",
    "        train_rec=[rec for rec in reclist if rec[-3]!='x']\n",
    "        #print(len(train_rec),len(test_rec))\n",
    "        kf_idx=kf.split(dtlist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_dtlist,test_dtlist=list(np.array(dtlist)[train_idx]),list(np.array(dtlist)[test_idx])\n",
    "    elif opt=='blind':\n",
    "        subjects=[['a11'],\n",
    "                  ['a15','x27','x28'],\n",
    "                  ['a17','x12'],\n",
    "                  ['b01','x03'],\n",
    "                  ['c07','x34'],\n",
    "                  ['a11','a15','x27','x28','a17','x12','b01','x03','c07','x34'],\n",
    "                  ['a14','a19','x05','x08','x25','b05','x11','c01','x35','c07','x34'],\n",
    "                  ['a04','a19','x05','x08','x25','b05','x11','c01','x35','c09'],\n",
    "                  ['b02','b03','x16','x21']]\n",
    "        train_rec=[rec for rec in reclist if rec.split('/')[-1] not in subjects[fold-1]]\n",
    "        test_rec=[rec for rec in reclist if rec.split('/')[-1] in subjects[fold-1]]\n",
    "        print(len(train_rec),len(test_rec),test_rec)\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "\n",
    "    else:#reclist is npy data list\n",
    "        kf = KFold(n_splits=10)\n",
    "        kf_idx=kf.split(dtlist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_dtlist,test_dtlist=list(np.array(dtlist)[train_idx]),list(np.array(dtlist)[test_idx])\n",
    "         \n",
    "    return train_dtlist,test_dtlist\n",
    "\n",
    "def dtclean(dt_path):\n",
    "    dt=np.load(dt_path)\n",
    "    if dt.std()<0.1:\n",
    "#        print(dt_path)\n",
    "        return 1      \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "#train_dtlist,test_dtlist=getTrainTestList(reclist,opt='kfold',fold=1)#fold 1-10\n",
    "#print('*********')\n",
    "#print(len(train_dtlist),len(test_dtlist))\n",
    "#train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "#np.random.shuffle(train_dtlist)\n",
    "#test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "\n",
    "#print(len(train_dtlist),len(test_dtlist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "ApneaECGDict={'N':0,\n",
    "              'A':1}\n",
    "class ApneaECGDataset(Dataset):\n",
    "    def __init__(self, filelist, istrain=False):\n",
    "        # Get the filelist and img data\n",
    "        self.filelist = filelist\n",
    "        self.istrain = istrain\n",
    "        \n",
    "    def getFeature(self, dt):\n",
    "#         dt=dt.reshape(-1,100)\n",
    "#         if self.istrain:\n",
    "#             shift=np.random.randint(0,5)\n",
    "#             shift=0\n",
    "#         else:\n",
    "#             shift=0\n",
    "#         dt=dt[:,shift::]\n",
    "#         dt_flag=dt[:,20::]*dt[:,0:-20]\n",
    "#         pd_dt=pd.DataFrame(dt)\n",
    "#         pd_dt_flag=pd.DataFrame(dt_flag)\n",
    "#scipy.signal.stft(x,fs=1.0,window='hann',nperseg=256,noverlap=None,nfft=None,detrend=False,return_onesided=True,boundary='zeros',padded=True,axis=-1)\n",
    "        dt=cheb_bandpass_filter(dt, 0.01, 38, 100, 4)\n",
    "    \n",
    "    \n",
    "        f, t, Sxx=signal.spectrogram(dt, fs=100.0, window=('hamming'), nperseg=128, noverlap=64, nfft=128, detrend='constant',\n",
    "        return_onesided=True, scaling='density', axis=-1, mode='psd')\n",
    "        return Sxx[0:26]\n",
    "        \n",
    "#         return np.concatenate((dt_flag.max(axis=1,keepdims=True),\n",
    "#                                dt_flag.min(axis=1,keepdims=True),\n",
    "#                                dt_flag.std(axis=1,keepdims=True),\n",
    "#                                dt.std(axis=1,keepdims=True),\n",
    "#             abs(dt).sum(axis=1,keepdims=True)/100,\n",
    "#             abs(dt_flag).sum(axis=1,keepdims=True)/100,\n",
    "#             (dt.argmax(axis=1)-dt.argmax(axis=1)[0])[:,np.newaxis]/100,\n",
    "#             (dt.argmin(axis=1)-dt.argmin(axis=1)[0])[:,np.newaxis]/100,\n",
    "#             (dt_flag.argmin(axis=1)-dt_flag.argmin(axis=1)[0])[:,np.newaxis]/100,\n",
    "#             (dt_flag.argmax(axis=1)-dt_flag.argmax(axis=1)[0])[:,np.newaxis]/100,\n",
    "#                                dt.mean(axis=1,keepdims=True),#\n",
    "#                                dt.min(axis=1,keepdims=True),\n",
    "#                                dt.max(axis=1,keepdims=True),\n",
    "#                                #pd_dt.skew(axis=1).values[:,np.newaxis],\n",
    "#                                #pd_dt.kurt(axis=1).values[:,np.newaxis],\n",
    "#                                #pd_dt_flag.skew(axis=1).values[:,np.newaxis],\n",
    "#                                #pd_dt_flag.kurt(axis=1).values[:,np.newaxis]\n",
    "#                                ),axis=1)\n",
    "    def __getitem__(self, index):\n",
    "        # return to the data of a Picture\n",
    "        dt_path = self.filelist[index]\n",
    "        label = ApneaECGDict.__getitem__(dt_path.split('_')[0][-1])\n",
    "        data = np.load(dt_path)\n",
    "        seg_id= dt_path.split('_')[1]+'_'+ dt_path.split('_')[-1].split('.')[0]\n",
    "\n",
    "        if self.istrain:\n",
    "            noise = np.random.normal(0, 0.1, data.shape[0])\n",
    "            data = noise+data\n",
    "        data=self.getFeature(data)\n",
    "        return data, label,seg_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "class conv3x3(nn.Module):#ACNet\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, \n",
    "                 padding=1, dilation=1, groups=1, padding_mode='zeros', bias=False, deploy=False):\n",
    "        super(conv3x3, self).__init__()\n",
    "        self.deploy=deploy\n",
    "        if self.deploy:\n",
    "            self.fused_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(kernel_size,kernel_size), stride=stride,\n",
    "                                      padding=padding, dilation=dilation, groups=groups, bias=False, padding_mode=padding_mode)\n",
    "# c=a.square_conv.weight.data.numpy().copy()\n",
    "# c[:,:,1:2,:]=a.square_conv.weight.data[:,:,1:2,:,].numpy().copy()+a.hor_conv.weight.data[:,:,0:1,:,].numpy().copy()\n",
    "# c[:,:,:,1:2]+=a.ver_conv.weight.data[:,:,:,0:1].numpy().copy()\n",
    "# c-a.square_conv.weight.data.numpy()\n",
    "# b.fused_conv.weight.data=torch.FloatTensor(c)    \n",
    "        else:\n",
    "            self.square_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=(kernel_size, kernel_size), stride=stride,\n",
    "                                         padding=padding, dilation=dilation, groups=groups, bias=False,\n",
    "                                         padding_mode=padding_mode)\n",
    "\n",
    "            center_offset_from_origin_border = padding - kernel_size // 2 #1-3//2=0\n",
    "            ver_pad_or_crop = (center_offset_from_origin_border + 1, center_offset_from_origin_border)\n",
    "            hor_pad_or_crop = (center_offset_from_origin_border, center_offset_from_origin_border + 1)\n",
    "            if center_offset_from_origin_border >= 0:\n",
    "                self.ver_conv_crop_layer = nn.Identity()\n",
    "                ver_conv_padding = ver_pad_or_crop\n",
    "                self.hor_conv_crop_layer = nn.Identity()\n",
    "                hor_conv_padding = hor_pad_or_crop\n",
    "\n",
    "            self.ver_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 1),\n",
    "                                      stride=stride,\n",
    "                                      padding=ver_conv_padding, dilation=dilation, groups=groups, bias=False,\n",
    "                                      padding_mode=padding_mode)\n",
    "\n",
    "            self.hor_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1, 3),\n",
    "                                      stride=stride,\n",
    "                                      padding=hor_conv_padding, dilation=dilation, groups=groups, bias=False,\n",
    "                                      padding_mode=padding_mode)\n",
    "\n",
    "    # forward函数\n",
    "    def forward(self, input):\n",
    "        if self.deploy:\n",
    "            #assert self.square_conv\n",
    "            print(\"True\")\n",
    "            return self.fused_conv(input)\n",
    "        square_outputs = self.square_conv(input)\n",
    "        # print(square_outputs.size())\n",
    "        # return square_outputs\n",
    "        vertical_outputs = self.ver_conv(input)\n",
    "        # print(vertical_outputs.size())\n",
    "        #horizontal_outputs = self.hor_conv_crop_layer(input)\n",
    "        horizontal_outputs = self.hor_conv(input)\n",
    "        # print(horizontal_outputs.size())\n",
    "        return square_outputs + vertical_outputs + horizontal_outputs\n",
    "    \n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, class_num,fs):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        #self.bn=nn.BatchNorm1d(60)\n",
    "#         self.conv10=nn.Sequential(nn.Conv1d(1,64,kernel_size=10,stride=10,padding=0, bias=False),\n",
    "#                   nn.Conv1d(64,32,kernel_size=3,stride=2,padding=0, bias=False),\n",
    "#                   nn.MaxPool1d(kernel_size=3,stride=2),\n",
    "#                   nn.Conv1d(32,32,kernel_size=3,stride=2,padding=0, bias=False),\n",
    "#                   nn.MaxPool1d(kernel_size=3,stride=2),\n",
    "#                                nn.ReLU())1200\n",
    "#25 * 65\n",
    "#12* 32\n",
    "#b*64*6*16\n",
    "#b*6*64*16\n",
    "        self.branch1=nn.Sequential(nn.Conv2d(1,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                nn.Conv2d(fs,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                #nn.Conv2d(32,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(3,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                #nn.ReLU(),                               \n",
    "                                nn.LayerNorm([fs,26,92],elementwise_affine=False),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Dropout(p=0.25),\n",
    "                                #nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                #nn.Dropout(p=0.25),\n",
    "                                \n",
    "#                                 nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Dropout(p=0.25),\n",
    "                                nn.LayerNorm([fs,13,46],elementwise_affine=False),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Dropout(p=0.5),\n",
    "                                nn.Conv2d(fs,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(5,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                                          \n",
    "                                nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                #nn.Dropout(p=0.5),\n",
    "                                nn.LayerNorm([fs,6,23],elementwise_affine=False),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.5),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(1,3),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                nn.Conv2d(fs,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False))\n",
    "        \n",
    "#         self.branch2=nn.Sequential(nn.Conv2d(1,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False),\n",
    "#                                 nn.Conv2d(32,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False),\n",
    "#                                 #nn.Conv2d(32,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=(3,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "#                                 #nn.ReLU(),                               \n",
    "#                                 nn.LayerNorm([32,25,92]),\n",
    "#                                 nn.ReLU(), \n",
    "#                                 nn.Dropout(p=0.25),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "#                                 nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#                                 #nn.Dropout(p=0.25),\n",
    "                                \n",
    "# #                                 nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "# #                                 nn.ReLU(),\n",
    "# #                                 nn.Dropout(p=0.25),\n",
    "#                                 nn.LayerNorm([32,12,46]),\n",
    "#                                 nn.ReLU(), \n",
    "#                                 nn.Dropout(p=0.25),\n",
    "#                                 nn.Conv2d(32,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=(5,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                                          \n",
    "#                                 nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#                                 #nn.Dropout(p=0.5),\n",
    "#                                 nn.LayerNorm([32,6,23]),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Dropout(p=0.5),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=(1,3),dilation=1,stride=1,padding=0, bias=False),\n",
    "#                                 nn.Conv2d(32,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False))\n",
    "        \n",
    "        self.avg = nn.Sequential(nn.AdaptiveMaxPool2d((8,8)),nn.LayerNorm([6,8,8],elementwise_affine=False))\n",
    "    \n",
    "        self.lstm = nn.LSTM(64, 8, 2,\n",
    "                            bias=False,\n",
    "                            batch_first=True,\n",
    "                            dropout=0.5,\n",
    "                            bidirectional=True)\n",
    "        #self.conv2=nn.Sequential(nn.Conv1d(64,64,kernel_size=1,stride=1,padding=0, bias=False))\n",
    "        \n",
    "        self.fc=nn.Sequential(nn.Linear(16*2,class_num))\n",
    "    def attention_net(self,lstm_output, final_state):\n",
    "        hidden = final_state.view(-1, 16, 2)   # hidden : [batch_size, n_hidden * num_directions(=2), 1(=n_layer)]\n",
    "        #print('hi',hidden.shape)\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2) # attn_weights : [batch_size, n_step]\n",
    "        #print('att',attn_weights.shape)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        #print('sft',soft_attn_weights.shape)\n",
    "        #print('yimr',torch.bmm(lstm_output.transpose(1, 2),soft_attn_weights).shape)\n",
    "        # [batch_size, n_hidden * num_directions(=2), n_step] * [batch_size, n_step, 1] = [batch_size, n_hidden * num_directions(=2), 1]\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights)\n",
    "        return context#, soft_attn_weights.data.numpy() # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "    def forward(self, x):\n",
    "        x=x.unsqueeze(dim=1)#x.reshape(x.shape[0],1,-1)\n",
    "        #x1=self.conv10(x)\n",
    "        out=self.branch1(x)\n",
    "        #out_1=self.branch1(x)\n",
    "        #out_2=self.branch2(x)\n",
    "        #out=torch.cat((out_1,out_2),1)\n",
    "        #print(out.shape)\n",
    "        out=out.permute(0,2,1,3)\n",
    "        out=self.avg(out)\n",
    "        #print(out.shape)\n",
    "        out=out.view(out.shape[0],out.shape[1],-1)\n",
    "        #print(x2.shape)\n",
    "        #print(x1.shape,x2.shape)\n",
    "        #x=torch.cat((x1,x2),dim=1)\n",
    "        #print(x.shape)\n",
    "        out,(h,c) = self.lstm(out)\n",
    "        out=self.attention_net(out, h)\n",
    "        \n",
    "        #out = self.conv2(out)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out.reshape(out.shape[0],-1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(model,test_dtlist,criterion,my_device):\n",
    "    test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "    test_loader=DataLoader(test_dataset, batch_size=128, shuffle=False, sampler=None, num_workers=0)\n",
    "    #train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "        #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "    #train_loader=DataLoader(train_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "    sft=nn.Softmax().to(my_device)\n",
    "    all_pred_prob=torch.Tensor([]).to(my_device)\n",
    "    all_label=torch.Tensor([]).long().to(my_device)\n",
    "    all_seg=[]#torch.Tensor([]).to(my_device)\n",
    "    flag=0\n",
    "    with torch.no_grad():\n",
    "        for fe, label,seg_id in test_loader:\n",
    "            fe=fe.float().to(my_device)\n",
    "            #fe=(fe-fe_mean)/fe_std\n",
    "            label=label.long().to(my_device)\n",
    "            pred_prob_no_softmax=model(fe)\n",
    "            all_pred_prob=torch.cat((all_pred_prob,pred_prob_no_softmax),0)\n",
    "            all_label=torch.cat((all_label,label),0)\n",
    "            all_seg+=list(seg_id)\n",
    "            loss=criterion(pred_prob_no_softmax,label)\n",
    "            flag+=1\n",
    "            if flag%8==0:\n",
    "                print('Eval Loss: ',loss.item())\n",
    "            #pos=(sft(pred_prob_no_softmax)[:,1]>0.5)\n",
    "            #print(\"Acc: \", sum(label==pos).detach().numpy()/len(label))\n",
    "    all_pred=sft(all_pred_prob)[:,1].detach().cpu().numpy()\n",
    "    all_pred[all_pred>0.5]=1\n",
    "    all_pred[all_pred<=0.5]=0\n",
    "    all_label=all_label.detach().cpu().numpy()\n",
    "    #all_seg=all_seg.detach().cpu().numpy()\n",
    "    print(confusion_matrix(all_label,all_pred))\n",
    "    print(classification_report(all_label,all_pred))\n",
    "    print(\"acc: \",accuracy_score(all_label,all_pred))\n",
    "    print(\"pre: \",precision_score(all_label,all_pred))\n",
    "    print(\"rec: \",recall_score(all_label,all_pred))\n",
    "    print(\"ma F1: \",f1_score(all_label,all_pred, average='macro'))\n",
    "    print(\"mi F1: \",f1_score(all_label,all_pred, average='micro'))\n",
    "    print(\"we F1: \",f1_score(all_label,all_pred, average='weighted'))\n",
    "    return sft(all_pred_prob)[:,1].detach().cpu().numpy(),all_label, accuracy_score(all_label,all_pred),all_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "kernel: 128\n",
      "  \n",
      "*********\n",
      "29459 3432\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29459 461\n",
      "Loss:  0.16663265228271484\n",
      "Loss:  0.15564793348312378\n",
      "Loss:  0.16349181532859802\n",
      "0 **********\n",
      "Epoch:  79.27403664588928  fold:  1  kers:  128\n",
      "epoch:  1\n",
      "29459 461\n",
      "Loss:  0.13513968884944916\n",
      "Loss:  0.1403122991323471\n",
      "Loss:  0.13822351396083832\n",
      "1 **********\n",
      "Epoch:  143.91530990600586  fold:  1  kers:  128\n",
      "epoch:  2\n",
      "29459 461\n",
      "Loss:  0.10495071858167648\n",
      "Loss:  0.11497092992067337\n",
      "Loss:  0.1025097668170929\n",
      "2 **********\n",
      "Epoch:  209.16384744644165  fold:  1  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.4028968811035156\n",
      "Eval Loss:  0.7280868291854858\n",
      "Eval Loss:  0.27643412351608276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\install\\envs\\pytorch-gpu\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\anaconda\\install\\envs\\pytorch-gpu\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 874  165]\n",
      " [ 938 1455]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.84      0.61      1039\n",
      "           1       0.90      0.61      0.73      2393\n",
      "\n",
      "    accuracy                           0.68      3432\n",
      "   macro avg       0.69      0.72      0.67      3432\n",
      "weighted avg       0.77      0.68      0.69      3432\n",
      "\n",
      "acc:  0.6786130536130536\n",
      "pre:  0.8981481481481481\n",
      "rec:  0.6080234015879649\n",
      "ma F1:  0.6691307442324196\n",
      "mi F1:  0.6786130536130536\n",
      "we F1:  0.6912289316702481\n",
      "update!  Acc:  0.6786130536130536\n",
      "Eval Loss:  0.4403660297393799\n",
      "Eval Loss:  0.4998396039009094\n",
      "Eval Loss:  0.49914804100990295\n",
      "Eval Loss:  0.5315762162208557\n",
      "Eval Loss:  0.4509856700897217\n",
      "Eval Loss:  0.515860378742218\n",
      "Eval Loss:  0.44479233026504517\n",
      "Eval Loss:  0.46627068519592285\n",
      "Eval Loss:  0.4494766891002655\n",
      "Eval Loss:  0.42986950278282166\n",
      "Eval Loss:  0.3680554926395416\n",
      "Eval Loss:  0.49180129170417786\n",
      "Eval Loss:  0.43434739112854004\n",
      "Eval Loss:  0.4592033922672272\n",
      "Eval Loss:  0.45176976919174194\n",
      "Eval Loss:  0.5950891971588135\n",
      "Eval Loss:  0.45162129402160645\n",
      "Eval Loss:  0.5102076530456543\n",
      "Eval Loss:  0.4743603765964508\n",
      "Eval Loss:  0.4972302317619324\n",
      "Eval Loss:  0.3963606059551239\n",
      "Eval Loss:  0.4934019148349762\n",
      "Eval Loss:  0.4175871014595032\n",
      "Eval Loss:  0.5092034339904785\n",
      "Eval Loss:  0.4149894714355469\n",
      "Eval Loss:  0.43902474641799927\n",
      "Eval Loss:  0.4052214026451111\n",
      "Eval Loss:  0.5299950242042542\n",
      "[[16981  2144]\n",
      " [ 3819  6515]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85     19125\n",
      "           1       0.75      0.63      0.69     10334\n",
      "\n",
      "    accuracy                           0.80     29459\n",
      "   macro avg       0.78      0.76      0.77     29459\n",
      "weighted avg       0.79      0.80      0.79     29459\n",
      "\n",
      "acc:  0.797583081570997\n",
      "pre:  0.7523963506178543\n",
      "rec:  0.6304431972130831\n",
      "ma F1:  0.7683435926909896\n",
      "mi F1:  0.797583081570997\n",
      "we F1:  0.7929035340959338\n",
      "29459 461\n",
      "Loss:  0.10356231778860092\n",
      "Loss:  0.09932757169008255\n",
      "Loss:  0.0950329601764679\n",
      "3 **********\n",
      "Epoch:  314.1605234146118  fold:  1  kers:  128\n",
      "epoch:  4\n",
      "29459 461\n",
      "Loss:  0.0770518034696579\n",
      "Loss:  0.0752716213464737\n",
      "Loss:  0.10859677195549011\n",
      "4 **********\n",
      "Epoch:  378.1544165611267  fold:  1  kers:  128\n",
      "epoch:  5\n",
      "29459 461\n",
      "Loss:  0.08538662642240524\n",
      "Loss:  0.08016412705183029\n",
      "Loss:  0.09870991855859756\n",
      "5 **********\n",
      "Epoch:  442.19717931747437  fold:  1  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.4400615990161896\n",
      "Eval Loss:  0.823584794998169\n",
      "Eval Loss:  0.1657462865114212\n",
      "[[ 935  104]\n",
      " [ 885 1508]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.90      0.65      1039\n",
      "           1       0.94      0.63      0.75      2393\n",
      "\n",
      "    accuracy                           0.71      3432\n",
      "   macro avg       0.72      0.77      0.70      3432\n",
      "weighted avg       0.81      0.71      0.72      3432\n",
      "\n",
      "acc:  0.7118298368298368\n",
      "pre:  0.9354838709677419\n",
      "rec:  0.630171333054743\n",
      "ma F1:  0.7035667640004035\n",
      "mi F1:  0.7118298368298368\n",
      "we F1:  0.723092419517075\n",
      "update!  Acc:  0.7118298368298368\n",
      "Eval Loss:  0.41986283659935\n",
      "Eval Loss:  0.5162458419799805\n",
      "Eval Loss:  0.5944503545761108\n",
      "Eval Loss:  0.5981942415237427\n",
      "Eval Loss:  0.43309685587882996\n",
      "Eval Loss:  0.5038663148880005\n",
      "Eval Loss:  0.48102426528930664\n",
      "Eval Loss:  0.40857842564582825\n",
      "Eval Loss:  0.39987295866012573\n",
      "Eval Loss:  0.4200161397457123\n",
      "Eval Loss:  0.32963162660598755\n",
      "Eval Loss:  0.5114234089851379\n",
      "Eval Loss:  0.39940470457077026\n",
      "Eval Loss:  0.4642060697078705\n",
      "Eval Loss:  0.43610450625419617\n",
      "Eval Loss:  0.6398359537124634\n",
      "Eval Loss:  0.4889191687107086\n",
      "Eval Loss:  0.5829281806945801\n",
      "Eval Loss:  0.5142521262168884\n",
      "Eval Loss:  0.47696930170059204\n",
      "Eval Loss:  0.39358338713645935\n",
      "Eval Loss:  0.44967085123062134\n",
      "Eval Loss:  0.3999120891094208\n",
      "Eval Loss:  0.5495213866233826\n",
      "Eval Loss:  0.4734558165073395\n",
      "Eval Loss:  0.5033377408981323\n",
      "Eval Loss:  0.3587436079978943\n",
      "Eval Loss:  0.5536735653877258\n",
      "[[18305   820]\n",
      " [ 4226  6108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88     19125\n",
      "           1       0.88      0.59      0.71     10334\n",
      "\n",
      "    accuracy                           0.83     29459\n",
      "   macro avg       0.85      0.77      0.79     29459\n",
      "weighted avg       0.84      0.83      0.82     29459\n",
      "\n",
      "acc:  0.8287110899894768\n",
      "pre:  0.8816397228637414\n",
      "rec:  0.5910586413779756\n",
      "ma F1:  0.7932733011141988\n",
      "mi F1:  0.8287110899894768\n",
      "we F1:  0.8188151230378333\n",
      "29459 461\n",
      "Loss:  0.07459667325019836\n",
      "Loss:  0.09680413454771042\n",
      "Loss:  0.10491630434989929\n",
      "6 **********\n",
      "Epoch:  546.7695751190186  fold:  1  kers:  128\n",
      "epoch:  7\n",
      "29459 461\n",
      "Loss:  0.06683994829654694\n",
      "Loss:  0.07207845151424408\n",
      "Loss:  0.0938340350985527\n",
      "7 **********\n",
      "Epoch:  610.7345445156097  fold:  1  kers:  128\n",
      "epoch:  8\n",
      "29459 461\n",
      "Loss:  0.09497468173503876\n",
      "Loss:  0.09523225575685501\n",
      "Loss:  0.11598700284957886\n",
      "8 **********\n",
      "Epoch:  674.7802994251251  fold:  1  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.4219934940338135\n",
      "Eval Loss:  0.6653253436088562\n",
      "Eval Loss:  0.10399919003248215\n",
      "[[ 947   92]\n",
      " [ 947 1446]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.91      0.65      1039\n",
      "           1       0.94      0.60      0.74      2393\n",
      "\n",
      "    accuracy                           0.70      3432\n",
      "   macro avg       0.72      0.76      0.69      3432\n",
      "weighted avg       0.81      0.70      0.71      3432\n",
      "\n",
      "acc:  0.6972610722610723\n",
      "pre:  0.9401820546163849\n",
      "rec:  0.6042624320936063\n",
      "ma F1:  0.690722931703838\n",
      "mi F1:  0.6972610722610723\n",
      "we F1:  0.708463697865151\n",
      "Eval Loss:  0.3443624973297119\n",
      "Eval Loss:  0.4183623790740967\n",
      "Eval Loss:  0.5712220668792725\n",
      "Eval Loss:  0.5475984811782837\n",
      "Eval Loss:  0.42781415581703186\n",
      "Eval Loss:  0.4492299258708954\n",
      "Eval Loss:  0.48990821838378906\n",
      "Eval Loss:  0.3652077317237854\n",
      "Eval Loss:  0.357494056224823\n",
      "Eval Loss:  0.3695952296257019\n",
      "Eval Loss:  0.31518062949180603\n",
      "Eval Loss:  0.453943133354187\n",
      "Eval Loss:  0.3812423348426819\n",
      "Eval Loss:  0.39829859137535095\n",
      "Eval Loss:  0.3835259675979614\n",
      "Eval Loss:  0.5965701937675476\n",
      "Eval Loss:  0.43004587292671204\n",
      "Eval Loss:  0.48700544238090515\n",
      "Eval Loss:  0.4428877830505371\n",
      "Eval Loss:  0.4281262457370758\n",
      "Eval Loss:  0.35412850975990295\n",
      "Eval Loss:  0.33397403359413147\n",
      "Eval Loss:  0.3322078585624695\n",
      "Eval Loss:  0.5116399526596069\n",
      "Eval Loss:  0.4012860059738159\n",
      "Eval Loss:  0.473310649394989\n",
      "Eval Loss:  0.3335328996181488\n",
      "Eval Loss:  0.47190889716148376\n",
      "[[18667   458]\n",
      " [ 4195  6139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89     19125\n",
      "           1       0.93      0.59      0.73     10334\n",
      "\n",
      "    accuracy                           0.84     29459\n",
      "   macro avg       0.87      0.79      0.81     29459\n",
      "weighted avg       0.86      0.84      0.83     29459\n",
      "\n",
      "acc:  0.8420516650259683\n",
      "pre:  0.9305745035622253\n",
      "rec:  0.5940584478420747\n",
      "ma F1:  0.8071793253162558\n",
      "mi F1:  0.8420516650259683\n",
      "we F1:  0.831649531126288\n",
      "29459 461\n",
      "Loss:  0.0727301687002182\n",
      "Loss:  0.07141753286123276\n",
      "Loss:  0.1111004650592804\n",
      "9 **********\n",
      "Epoch:  779.5701124668121  fold:  1  kers:  128\n",
      "epoch:  10\n",
      "29459 461\n",
      "Loss:  0.0999828651547432\n",
      "Loss:  0.05455542728304863\n",
      "Loss:  0.08856984972953796\n",
      "10 **********\n",
      "Epoch:  843.59193110466  fold:  1  kers:  128\n",
      "epoch:  11\n",
      "29459 461\n",
      "Loss:  0.06723462045192719\n",
      "Loss:  0.07707865536212921\n",
      "Loss:  0.08806765824556351\n",
      "11 **********\n",
      "Epoch:  907.9917390346527  fold:  1  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.6408515572547913\n",
      "Eval Loss:  0.5806021690368652\n",
      "Eval Loss:  0.06926020234823227\n",
      "[[ 910  129]\n",
      " [ 722 1671]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.88      0.68      1039\n",
      "           1       0.93      0.70      0.80      2393\n",
      "\n",
      "    accuracy                           0.75      3432\n",
      "   macro avg       0.74      0.79      0.74      3432\n",
      "weighted avg       0.82      0.75      0.76      3432\n",
      "\n",
      "acc:  0.752039627039627\n",
      "pre:  0.9283333333333333\n",
      "rec:  0.69828666945257\n",
      "ma F1:  0.7392177135003223\n",
      "mi F1:  0.7520396270396271\n",
      "we F1:  0.762030947314013\n",
      "update!  Acc:  0.752039627039627\n",
      "Eval Loss:  0.25267553329467773\n",
      "Eval Loss:  0.3464311361312866\n",
      "Eval Loss:  0.4896983802318573\n",
      "Eval Loss:  0.4800874888896942\n",
      "Eval Loss:  0.3802860677242279\n",
      "Eval Loss:  0.36854690313339233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.4223805069923401\n",
      "Eval Loss:  0.29920896887779236\n",
      "Eval Loss:  0.33690664172172546\n",
      "Eval Loss:  0.2665312886238098\n",
      "Eval Loss:  0.2370409071445465\n",
      "Eval Loss:  0.3469729423522949\n",
      "Eval Loss:  0.3197765648365021\n",
      "Eval Loss:  0.34642472863197327\n",
      "Eval Loss:  0.3464012145996094\n",
      "Eval Loss:  0.5074449777603149\n",
      "Eval Loss:  0.387678861618042\n",
      "Eval Loss:  0.4029199481010437\n",
      "Eval Loss:  0.37017813324928284\n",
      "Eval Loss:  0.35940736532211304\n",
      "Eval Loss:  0.2584151029586792\n",
      "Eval Loss:  0.2428557127714157\n",
      "Eval Loss:  0.26676076650619507\n",
      "Eval Loss:  0.4527418911457062\n",
      "Eval Loss:  0.3064638674259186\n",
      "Eval Loss:  0.4305464029312134\n",
      "Eval Loss:  0.3232746422290802\n",
      "Eval Loss:  0.37803030014038086\n",
      "[[18578   547]\n",
      " [ 3307  7027]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91     19125\n",
      "           1       0.93      0.68      0.78     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.89      0.83      0.85     29459\n",
      "weighted avg       0.88      0.87      0.86     29459\n",
      "\n",
      "acc:  0.8691741063851455\n",
      "pre:  0.9277792447847901\n",
      "rec:  0.6799883878459454\n",
      "ma F1:  0.84540592119564\n",
      "mi F1:  0.8691741063851455\n",
      "we F1:  0.8634949278618111\n",
      "29459 461\n",
      "Loss:  0.07214073836803436\n",
      "Loss:  0.10077739506959915\n",
      "Loss:  0.09307314455509186\n",
      "12 **********\n",
      "Epoch:  1012.7995045185089  fold:  1  kers:  128\n",
      "epoch:  13\n",
      "29459 461\n",
      "Loss:  0.07104827463626862\n",
      "Loss:  0.09861445426940918\n",
      "Loss:  0.11283732205629349\n",
      "13 **********\n",
      "Epoch:  1076.8302993774414  fold:  1  kers:  128\n",
      "epoch:  14\n",
      "29459 461\n",
      "Loss:  0.05788017436861992\n",
      "Loss:  0.09490412473678589\n",
      "Loss:  0.07356386631727219\n",
      "14 **********\n",
      "Epoch:  1140.9428753852844  fold:  1  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.5572046041488647\n",
      "Eval Loss:  0.3750762939453125\n",
      "Eval Loss:  0.055234260857105255\n",
      "[[ 909  130]\n",
      " [ 726 1667]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.87      0.68      1039\n",
      "           1       0.93      0.70      0.80      2393\n",
      "\n",
      "    accuracy                           0.75      3432\n",
      "   macro avg       0.74      0.79      0.74      3432\n",
      "weighted avg       0.82      0.75      0.76      3432\n",
      "\n",
      "acc:  0.7505827505827506\n",
      "pre:  0.9276572064552031\n",
      "rec:  0.6966151274550773\n",
      "ma F1:  0.7377921931871125\n",
      "mi F1:  0.7505827505827506\n",
      "we F1:  0.7606397060020123\n",
      "Eval Loss:  0.20757777988910675\n",
      "Eval Loss:  0.330679327249527\n",
      "Eval Loss:  0.436979204416275\n",
      "Eval Loss:  0.4427705407142639\n",
      "Eval Loss:  0.34429851174354553\n",
      "Eval Loss:  0.34854206442832947\n",
      "Eval Loss:  0.38868725299835205\n",
      "Eval Loss:  0.2816809415817261\n",
      "Eval Loss:  0.31356099247932434\n",
      "Eval Loss:  0.22089706361293793\n",
      "Eval Loss:  0.2058531790971756\n",
      "Eval Loss:  0.30580639839172363\n",
      "Eval Loss:  0.31542423367500305\n",
      "Eval Loss:  0.32598641514778137\n",
      "Eval Loss:  0.310010701417923\n",
      "Eval Loss:  0.46576792001724243\n",
      "Eval Loss:  0.35638976097106934\n",
      "Eval Loss:  0.35208091139793396\n",
      "Eval Loss:  0.33012863993644714\n",
      "Eval Loss:  0.3221043348312378\n",
      "Eval Loss:  0.2316543459892273\n",
      "Eval Loss:  0.20639581978321075\n",
      "Eval Loss:  0.2293253093957901\n",
      "Eval Loss:  0.4121449589729309\n",
      "Eval Loss:  0.2726250886917114\n",
      "Eval Loss:  0.4029000997543335\n",
      "Eval Loss:  0.28336381912231445\n",
      "Eval Loss:  0.33855438232421875\n",
      "[[18582   543]\n",
      " [ 2967  7367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     19125\n",
      "           1       0.93      0.71      0.81     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.90      0.84      0.86     29459\n",
      "weighted avg       0.89      0.88      0.88     29459\n",
      "\n",
      "acc:  0.8808513527275196\n",
      "pre:  0.9313527180783818\n",
      "rec:  0.7128894910005806\n",
      "ma F1:  0.8606560334271927\n",
      "mi F1:  0.8808513527275196\n",
      "we F1:  0.8764863546014392\n",
      "29459 461\n",
      "Loss:  0.059388190507888794\n",
      "Loss:  0.06247559189796448\n",
      "Loss:  0.07282967120409012\n",
      "15 **********\n",
      "Epoch:  1245.4285018444061  fold:  1  kers:  128\n",
      "epoch:  16\n",
      "29459 461\n",
      "Loss:  0.05517248809337616\n",
      "Loss:  0.075842946767807\n",
      "Loss:  0.06225894019007683\n",
      "16 **********\n",
      "Epoch:  1309.4991898536682  fold:  1  kers:  128\n",
      "epoch:  17\n",
      "29459 461\n",
      "Loss:  0.0465632788836956\n",
      "Loss:  0.0636868104338646\n",
      "Loss:  0.04398149251937866\n",
      "17 **********\n",
      "Epoch:  1373.5808482170105  fold:  1  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.7267721891403198\n",
      "Eval Loss:  0.3798215389251709\n",
      "Eval Loss:  0.07368756830692291\n",
      "[[ 898  141]\n",
      " [ 614 1779]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.86      0.70      1039\n",
      "           1       0.93      0.74      0.82      2393\n",
      "\n",
      "    accuracy                           0.78      3432\n",
      "   macro avg       0.76      0.80      0.76      3432\n",
      "weighted avg       0.83      0.78      0.79      3432\n",
      "\n",
      "acc:  0.780011655011655\n",
      "pre:  0.9265625\n",
      "rec:  0.7434183033848726\n",
      "ma F1:  0.7644927322182316\n",
      "mi F1:  0.7800116550116551\n",
      "we F1:  0.7883436078848551\n",
      "update!  Acc:  0.780011655011655\n",
      "Eval Loss:  0.20133689045906067\n",
      "Eval Loss:  0.29435262084007263\n",
      "Eval Loss:  0.43087756633758545\n",
      "Eval Loss:  0.412258505821228\n",
      "Eval Loss:  0.30505770444869995\n",
      "Eval Loss:  0.30533522367477417\n",
      "Eval Loss:  0.36366212368011475\n",
      "Eval Loss:  0.254229873418808\n",
      "Eval Loss:  0.27102839946746826\n",
      "Eval Loss:  0.21560122072696686\n",
      "Eval Loss:  0.18756498396396637\n",
      "Eval Loss:  0.2726832926273346\n",
      "Eval Loss:  0.2905154526233673\n",
      "Eval Loss:  0.28628018498420715\n",
      "Eval Loss:  0.3067016005516052\n",
      "Eval Loss:  0.43394413590431213\n",
      "Eval Loss:  0.290132999420166\n",
      "Eval Loss:  0.32518675923347473\n",
      "Eval Loss:  0.3025616407394409\n",
      "Eval Loss:  0.28741705417633057\n",
      "Eval Loss:  0.21075637638568878\n",
      "Eval Loss:  0.18149782717227936\n",
      "Eval Loss:  0.21533478796482086\n",
      "Eval Loss:  0.3579541742801666\n",
      "Eval Loss:  0.24246925115585327\n",
      "Eval Loss:  0.36735713481903076\n",
      "Eval Loss:  0.26332035660743713\n",
      "Eval Loss:  0.31515127420425415\n",
      "[[18592   533]\n",
      " [ 2661  7673]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     19125\n",
      "           1       0.94      0.74      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.90      0.86      0.87     29459\n",
      "weighted avg       0.90      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8915781255303982\n",
      "pre:  0.9350475262003413\n",
      "rec:  0.7425004838397523\n",
      "ma F1:  0.8743106793979205\n",
      "mi F1:  0.8915781255303982\n",
      "we F1:  0.8882128791369635\n",
      "29459 461\n",
      "Loss:  0.03704880550503731\n",
      "Loss:  0.04277990385890007\n",
      "Loss:  0.040096480399370193\n",
      "18 **********\n",
      "Epoch:  1478.1632165908813  fold:  1  kers:  128\n",
      "epoch:  19\n",
      "29459 461\n",
      "Loss:  0.0707554966211319\n",
      "Loss:  0.0557466559112072\n",
      "Loss:  0.08321696519851685\n",
      "19 **********\n",
      "Epoch:  1542.2438776493073  fold:  1  kers:  128\n",
      "epoch:  20\n",
      "29459 461\n",
      "Loss:  0.062385451048612595\n",
      "Loss:  0.0716715082526207\n",
      "Loss:  0.049911580979824066\n",
      "20 **********\n",
      "Epoch:  1606.3564541339874  fold:  1  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.8960809707641602\n",
      "Eval Loss:  0.2661055028438568\n",
      "Eval Loss:  0.1403234899044037\n",
      "[[ 778  261]\n",
      " [ 399 1994]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70      1039\n",
      "           1       0.88      0.83      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.79      0.78      3432\n",
      "weighted avg       0.82      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8076923076923077\n",
      "pre:  0.8842572062084257\n",
      "rec:  0.8332636857501045\n",
      "ma F1:  0.7800847536613706\n",
      "mi F1:  0.8076923076923077\n",
      "we F1:  0.8108254018175293\n",
      "update!  Acc:  0.8076923076923077\n",
      "Eval Loss:  0.15965227782726288\n",
      "Eval Loss:  0.23660624027252197\n",
      "Eval Loss:  0.3454451858997345\n",
      "Eval Loss:  0.3171955943107605\n",
      "Eval Loss:  0.2501121759414673\n",
      "Eval Loss:  0.2517988681793213\n",
      "Eval Loss:  0.30071431398391724\n",
      "Eval Loss:  0.21439450979232788\n",
      "Eval Loss:  0.26424935460090637\n",
      "Eval Loss:  0.16525328159332275\n",
      "Eval Loss:  0.13070954382419586\n",
      "Eval Loss:  0.20784461498260498\n",
      "Eval Loss:  0.25271469354629517\n",
      "Eval Loss:  0.2790966331958771\n",
      "Eval Loss:  0.25640246272087097\n",
      "Eval Loss:  0.31481295824050903\n",
      "Eval Loss:  0.21453994512557983\n",
      "Eval Loss:  0.25636234879493713\n",
      "Eval Loss:  0.31098949909210205\n",
      "Eval Loss:  0.24820750951766968\n",
      "Eval Loss:  0.17878201603889465\n",
      "Eval Loss:  0.17258012294769287\n",
      "Eval Loss:  0.16965989768505096\n",
      "Eval Loss:  0.28109320998191833\n",
      "Eval Loss:  0.18796990811824799\n",
      "Eval Loss:  0.3381378650665283\n",
      "Eval Loss:  0.23352625966072083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24502329528331757\n",
      "[[17962  1163]\n",
      " [ 1583  8751]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     19125\n",
      "           1       0.88      0.85      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.89      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9067857021623273\n",
      "pre:  0.8826911438369982\n",
      "rec:  0.8468163344300368\n",
      "ma F1:  0.8966852737970552\n",
      "mi F1:  0.9067857021623273\n",
      "we F1:  0.9063251463146003\n",
      "29459 461\n",
      "Loss:  0.07609304785728455\n",
      "Loss:  0.07296551018953323\n",
      "Loss:  0.04665142670273781\n",
      "21 **********\n",
      "Epoch:  1710.8919470310211  fold:  1  kers:  128\n",
      "epoch:  22\n",
      "29459 461\n",
      "Loss:  0.06113831698894501\n",
      "Loss:  0.06045575067400932\n",
      "Loss:  0.07519461959600449\n",
      "22 **********\n",
      "Epoch:  1774.9895629882812  fold:  1  kers:  128\n",
      "epoch:  23\n",
      "29459 461\n",
      "Loss:  0.06896345317363739\n",
      "Loss:  0.07157579064369202\n",
      "Loss:  0.08188551664352417\n",
      "23 **********\n",
      "Epoch:  1839.0821928977966  fold:  1  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.8805434703826904\n",
      "Eval Loss:  0.28352969884872437\n",
      "Eval Loss:  0.05588128790259361\n",
      "[[ 820  219]\n",
      " [ 475 1918]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70      1039\n",
      "           1       0.90      0.80      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.77      0.80      0.77      3432\n",
      "weighted avg       0.82      0.80      0.80      3432\n",
      "\n",
      "acc:  0.7977855477855478\n",
      "pre:  0.8975198876930276\n",
      "rec:  0.8015043877977435\n",
      "ma F1:  0.7747277504440547\n",
      "mi F1:  0.7977855477855478\n",
      "we F1:  0.803161500535477\n",
      "Eval Loss:  0.14030539989471436\n",
      "Eval Loss:  0.23232309520244598\n",
      "Eval Loss:  0.32460808753967285\n",
      "Eval Loss:  0.32794249057769775\n",
      "Eval Loss:  0.23749347031116486\n",
      "Eval Loss:  0.25552868843078613\n",
      "Eval Loss:  0.3245465159416199\n",
      "Eval Loss:  0.1922013908624649\n",
      "Eval Loss:  0.22318041324615479\n",
      "Eval Loss:  0.14517703652381897\n",
      "Eval Loss:  0.1216973066329956\n",
      "Eval Loss:  0.19915863871574402\n",
      "Eval Loss:  0.2747742533683777\n",
      "Eval Loss:  0.27628573775291443\n",
      "Eval Loss:  0.26066988706588745\n",
      "Eval Loss:  0.30952173471450806\n",
      "Eval Loss:  0.21020863950252533\n",
      "Eval Loss:  0.25364527106285095\n",
      "Eval Loss:  0.2589859962463379\n",
      "Eval Loss:  0.2750813066959381\n",
      "Eval Loss:  0.1824588030576706\n",
      "Eval Loss:  0.13755075633525848\n",
      "Eval Loss:  0.1689131259918213\n",
      "Eval Loss:  0.27060121297836304\n",
      "Eval Loss:  0.19713707268238068\n",
      "Eval Loss:  0.32263049483299255\n",
      "Eval Loss:  0.23149776458740234\n",
      "Eval Loss:  0.2718142867088318\n",
      "[[18301   824]\n",
      " [ 1786  8548]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     19125\n",
      "           1       0.91      0.83      0.87     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.89      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9114022879255915\n",
      "pre:  0.9120785317968416\n",
      "rec:  0.8271724404877104\n",
      "ma F1:  0.9004958863880084\n",
      "mi F1:  0.9114022879255916\n",
      "we F1:  0.9103265206458667\n",
      "29459 461\n",
      "Loss:  0.046822044998407364\n",
      "Loss:  0.07089363038539886\n",
      "Loss:  0.026582876220345497\n",
      "24 **********\n",
      "Epoch:  1943.5807845592499  fold:  1  kers:  128\n",
      "epoch:  25\n",
      "29459 461\n",
      "Loss:  0.08232404291629791\n",
      "Loss:  0.08947407454252243\n",
      "Loss:  0.03702729940414429\n",
      "25 **********\n",
      "Epoch:  2007.6534671783447  fold:  1  kers:  128\n",
      "epoch:  26\n",
      "29459 461\n",
      "Loss:  0.07392682880163193\n",
      "Loss:  0.07646217197179794\n",
      "Loss:  0.04248180240392685\n",
      "26 **********\n",
      "Epoch:  2071.730139017105  fold:  1  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.968244731426239\n",
      "Eval Loss:  0.3001488149166107\n",
      "Eval Loss:  0.11743628978729248\n",
      "[[ 788  251]\n",
      " [ 439 1954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70      1039\n",
      "           1       0.89      0.82      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.79      0.77      3432\n",
      "weighted avg       0.81      0.80      0.80      3432\n",
      "\n",
      "acc:  0.798951048951049\n",
      "pre:  0.8861678004535147\n",
      "rec:  0.8165482657751776\n",
      "ma F1:  0.7727167151610872\n",
      "mi F1:  0.798951048951049\n",
      "we F1:  0.8031809415346791\n",
      "Eval Loss:  0.13558565080165863\n",
      "Eval Loss:  0.21446333825588226\n",
      "Eval Loss:  0.31908613443374634\n",
      "Eval Loss:  0.2697373926639557\n",
      "Eval Loss:  0.19580364227294922\n",
      "Eval Loss:  0.23344816267490387\n",
      "Eval Loss:  0.2784948945045471\n",
      "Eval Loss:  0.15446223318576813\n",
      "Eval Loss:  0.21837787330150604\n",
      "Eval Loss:  0.16227228939533234\n",
      "Eval Loss:  0.1456049084663391\n",
      "Eval Loss:  0.19575181603431702\n",
      "Eval Loss:  0.24988125264644623\n",
      "Eval Loss:  0.26250118017196655\n",
      "Eval Loss:  0.2171521782875061\n",
      "Eval Loss:  0.2714887261390686\n",
      "Eval Loss:  0.1934245228767395\n",
      "Eval Loss:  0.24999789893627167\n",
      "Eval Loss:  0.25890275835990906\n",
      "Eval Loss:  0.24659892916679382\n",
      "Eval Loss:  0.16241998970508575\n",
      "Eval Loss:  0.13555531203746796\n",
      "Eval Loss:  0.14325757324695587\n",
      "Eval Loss:  0.2644685208797455\n",
      "Eval Loss:  0.17907452583312988\n",
      "Eval Loss:  0.2732648551464081\n",
      "Eval Loss:  0.21379287540912628\n",
      "Eval Loss:  0.22242861986160278\n",
      "[[18265   860]\n",
      " [ 1577  8757]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     19125\n",
      "           1       0.91      0.85      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.90      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.917274856580332\n",
      "pre:  0.9105750233960694\n",
      "rec:  0.8473969421327656\n",
      "ma F1:  0.9076553181336824\n",
      "mi F1:  0.917274856580332\n",
      "we F1:  0.9165494454458929\n",
      "29459 461\n",
      "Loss:  0.07165315747261047\n",
      "Loss:  0.0756353810429573\n",
      "Loss:  0.044325489550828934\n",
      "27 **********\n",
      "Epoch:  2176.2785983085632  fold:  1  kers:  128\n",
      "epoch:  28\n",
      "29459 461\n",
      "Loss:  0.08284168690443039\n",
      "Loss:  0.05356895178556442\n",
      "Loss:  0.10667755454778671\n",
      "28 **********\n",
      "Epoch:  2240.328341960907  fold:  1  kers:  128\n",
      "epoch:  29\n",
      "29459 461\n",
      "Loss:  0.0814434140920639\n",
      "Loss:  0.052438389509916306\n",
      "Loss:  0.038550060242414474\n",
      "29 **********\n",
      "Epoch:  2304.418976545334  fold:  1  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  1.0708988904953003\n",
      "Eval Loss:  0.2724768817424774\n",
      "Eval Loss:  0.11769726127386093\n",
      "[[ 735  304]\n",
      " [ 364 2029]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      1039\n",
      "           1       0.87      0.85      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.78      0.77      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8053613053613053\n",
      "pre:  0.8696956708101158\n",
      "rec:  0.8478896782281655\n",
      "ma F1:  0.773106359462037\n",
      "mi F1:  0.8053613053613053\n",
      "we F1:  0.8068568979068665\n",
      "Eval Loss:  0.11867848038673401\n",
      "Eval Loss:  0.2032156139612198\n",
      "Eval Loss:  0.3268035054206848\n",
      "Eval Loss:  0.250053733587265\n",
      "Eval Loss:  0.17172499001026154\n",
      "Eval Loss:  0.22959569096565247\n",
      "Eval Loss:  0.26191404461860657\n",
      "Eval Loss:  0.137033611536026\n",
      "Eval Loss:  0.21407367289066315\n",
      "Eval Loss:  0.17891953885555267\n",
      "Eval Loss:  0.13249222934246063\n",
      "Eval Loss:  0.19344434142112732\n",
      "Eval Loss:  0.2065332978963852\n",
      "Eval Loss:  0.26256999373435974\n",
      "Eval Loss:  0.21349720656871796\n",
      "Eval Loss:  0.24354928731918335\n",
      "Eval Loss:  0.18180601298809052\n",
      "Eval Loss:  0.24314476549625397\n",
      "Eval Loss:  0.2691200077533722\n",
      "Eval Loss:  0.2406589686870575\n",
      "Eval Loss:  0.1590442806482315\n",
      "Eval Loss:  0.124197818338871\n",
      "Eval Loss:  0.1314886212348938\n",
      "Eval Loss:  0.2337644100189209\n",
      "Eval Loss:  0.15638023614883423\n",
      "Eval Loss:  0.28141242265701294\n",
      "Eval Loss:  0.2090839296579361\n",
      "Eval Loss:  0.18149688839912415\n",
      "[[18070  1055]\n",
      " [ 1260  9074]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     19125\n",
      "           1       0.90      0.88      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9214162055738484\n",
      "pre:  0.895843617336361\n",
      "rec:  0.8780723824269402\n",
      "ma F1:  0.9133343745013889\n",
      "mi F1:  0.9214162055738484\n",
      "we F1:  0.9212320375691959\n",
      "29459 461\n",
      "Loss:  0.05118344724178314\n",
      "Loss:  0.036877524107694626\n",
      "Loss:  0.04457822069525719\n",
      "30 **********\n",
      "Epoch:  2408.987381696701  fold:  1  kers:  128\n",
      "epoch:  31\n",
      "29459 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0731552243232727\n",
      "Loss:  0.040343835949897766\n",
      "Loss:  0.07971369475126266\n",
      "31 **********\n",
      "Epoch:  2473.0760219097137  fold:  1  kers:  128\n",
      "epoch:  32\n",
      "29459 461\n",
      "Loss:  0.056734006851911545\n",
      "Loss:  0.08393938094377518\n",
      "Loss:  0.03912864625453949\n",
      "32 **********\n",
      "Epoch:  2537.164662361145  fold:  1  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  1.1171334981918335\n",
      "Eval Loss:  0.37007033824920654\n",
      "Eval Loss:  0.07445254176855087\n",
      "[[ 840  199]\n",
      " [ 522 1871]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70      1039\n",
      "           1       0.90      0.78      0.84      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.76      0.80      0.77      3432\n",
      "weighted avg       0.82      0.79      0.80      3432\n",
      "\n",
      "acc:  0.789918414918415\n",
      "pre:  0.9038647342995169\n",
      "rec:  0.7818637693272044\n",
      "ma F1:  0.7690789641294243\n",
      "mi F1:  0.789918414918415\n",
      "we F1:  0.7964471662325215\n",
      "Eval Loss:  0.14670324325561523\n",
      "Eval Loss:  0.2247896045446396\n",
      "Eval Loss:  0.3193040192127228\n",
      "Eval Loss:  0.3061259984970093\n",
      "Eval Loss:  0.19362281262874603\n",
      "Eval Loss:  0.234130397439003\n",
      "Eval Loss:  0.31790703535079956\n",
      "Eval Loss:  0.13326188921928406\n",
      "Eval Loss:  0.21600601077079773\n",
      "Eval Loss:  0.183528333902359\n",
      "Eval Loss:  0.16135656833648682\n",
      "Eval Loss:  0.20021682977676392\n",
      "Eval Loss:  0.237463116645813\n",
      "Eval Loss:  0.30635857582092285\n",
      "Eval Loss:  0.2494911253452301\n",
      "Eval Loss:  0.3013526499271393\n",
      "Eval Loss:  0.21463985741138458\n",
      "Eval Loss:  0.2739187180995941\n",
      "Eval Loss:  0.27045193314552307\n",
      "Eval Loss:  0.28480297327041626\n",
      "Eval Loss:  0.15897442400455475\n",
      "Eval Loss:  0.14035378396511078\n",
      "Eval Loss:  0.15020540356636047\n",
      "Eval Loss:  0.280141144990921\n",
      "Eval Loss:  0.19574366509914398\n",
      "Eval Loss:  0.3091229498386383\n",
      "Eval Loss:  0.233544260263443\n",
      "Eval Loss:  0.27061593532562256\n",
      "[[18509   616]\n",
      " [ 1999  8335]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93     19125\n",
      "           1       0.93      0.81      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.92      0.89      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9112325605078244\n",
      "pre:  0.9311808736454027\n",
      "rec:  0.8065608670408361\n",
      "ma F1:  0.8992110076898765\n",
      "mi F1:  0.9112325605078244\n",
      "we F1:  0.9095984139040086\n",
      "29459 461\n",
      "Loss:  0.05568335950374603\n",
      "Loss:  0.0639737993478775\n",
      "Loss:  0.06641463935375214\n",
      "33 **********\n",
      "Epoch:  2641.847819328308  fold:  1  kers:  128\n",
      "epoch:  34\n",
      "29459 461\n",
      "Loss:  0.04591907933354378\n",
      "Loss:  0.028418689966201782\n",
      "Loss:  0.05312686786055565\n",
      "34 **********\n",
      "Epoch:  2705.926488161087  fold:  1  kers:  128\n",
      "epoch:  35\n",
      "29459 461\n",
      "Loss:  0.06947425752878189\n",
      "Loss:  0.04559602215886116\n",
      "Loss:  0.07527509331703186\n",
      "35 **********\n",
      "Epoch:  2769.9981710910797  fold:  1  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.8778864145278931\n",
      "Eval Loss:  0.2734563946723938\n",
      "Eval Loss:  0.11460287123918533\n",
      "[[ 748  291]\n",
      " [ 348 2045]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70      1039\n",
      "           1       0.88      0.85      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.79      0.78      3432\n",
      "weighted avg       0.82      0.81      0.82      3432\n",
      "\n",
      "acc:  0.8138111888111889\n",
      "pre:  0.8754280821917808\n",
      "rec:  0.8545758462181362\n",
      "ma F1:  0.7827894356561216\n",
      "mi F1:  0.8138111888111889\n",
      "we F1:  0.8151745195203939\n",
      "update!  Acc:  0.8138111888111889\n",
      "Eval Loss:  0.14118872582912445\n",
      "Eval Loss:  0.21045687794685364\n",
      "Eval Loss:  0.29594898223876953\n",
      "Eval Loss:  0.25459524989128113\n",
      "Eval Loss:  0.17880117893218994\n",
      "Eval Loss:  0.19511090219020844\n",
      "Eval Loss:  0.2585364580154419\n",
      "Eval Loss:  0.1321546882390976\n",
      "Eval Loss:  0.2527076005935669\n",
      "Eval Loss:  0.16301429271697998\n",
      "Eval Loss:  0.13122941553592682\n",
      "Eval Loss:  0.16162213683128357\n",
      "Eval Loss:  0.22867384552955627\n",
      "Eval Loss:  0.2770531475543976\n",
      "Eval Loss:  0.2254728078842163\n",
      "Eval Loss:  0.25559666752815247\n",
      "Eval Loss:  0.17593246698379517\n",
      "Eval Loss:  0.22240348160266876\n",
      "Eval Loss:  0.2596299350261688\n",
      "Eval Loss:  0.2390163242816925\n",
      "Eval Loss:  0.15480448305606842\n",
      "Eval Loss:  0.13060882687568665\n",
      "Eval Loss:  0.14330291748046875\n",
      "Eval Loss:  0.24376989901065826\n",
      "Eval Loss:  0.1404636651277542\n",
      "Eval Loss:  0.2501045763492584\n",
      "Eval Loss:  0.21041829884052277\n",
      "Eval Loss:  0.1795516461133957\n",
      "[[17973  1152]\n",
      " [ 1149  9185]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     19125\n",
      "           1       0.89      0.89      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.91      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9218914423435962\n",
      "pre:  0.8885556737931701\n",
      "rec:  0.888813624927424\n",
      "ma F1:  0.914261524670734\n",
      "mi F1:  0.9218914423435962\n",
      "we F1:  0.9218940470037029\n",
      "29459 461\n",
      "Loss:  0.07002754509449005\n",
      "Loss:  0.07052638381719589\n",
      "Loss:  0.07708026468753815\n",
      "36 **********\n",
      "Epoch:  2874.3441712856293  fold:  1  kers:  128\n",
      "epoch:  37\n",
      "29459 461\n",
      "Loss:  0.036092858761548996\n",
      "Loss:  0.03391089290380478\n",
      "Loss:  0.06939046084880829\n",
      "37 **********\n",
      "Epoch:  2938.4328112602234  fold:  1  kers:  128\n",
      "epoch:  38\n",
      "29459 461\n",
      "Loss:  0.047684960067272186\n",
      "Loss:  0.06952101737260818\n",
      "Loss:  0.047370292246341705\n",
      "38 **********\n",
      "Epoch:  3002.456624507904  fold:  1  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.6644695997238159\n",
      "Eval Loss:  0.2997235655784607\n",
      "Eval Loss:  0.07234123349189758\n",
      "[[ 777  262]\n",
      " [ 389 2004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.70      1039\n",
      "           1       0.88      0.84      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.79      0.78      3432\n",
      "weighted avg       0.82      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8103146853146853\n",
      "pre:  0.884377758164166\n",
      "rec:  0.8374425407438362\n",
      "ma F1:  0.7825161745316285\n",
      "mi F1:  0.8103146853146852\n",
      "we F1:  0.8131919557869334\n",
      "Eval Loss:  0.1676718294620514\n",
      "Eval Loss:  0.1857883185148239\n",
      "Eval Loss:  0.2827833294868469\n",
      "Eval Loss:  0.2517726421356201\n",
      "Eval Loss:  0.1749534010887146\n",
      "Eval Loss:  0.24031439423561096\n",
      "Eval Loss:  0.30023548007011414\n",
      "Eval Loss:  0.13293196260929108\n",
      "Eval Loss:  0.2146511822938919\n",
      "Eval Loss:  0.14196452498435974\n",
      "Eval Loss:  0.13448688387870789\n",
      "Eval Loss:  0.16983677446842194\n",
      "Eval Loss:  0.22205102443695068\n",
      "Eval Loss:  0.2756845951080322\n",
      "Eval Loss:  0.24008406698703766\n",
      "Eval Loss:  0.21938474476337433\n",
      "Eval Loss:  0.1643725335597992\n",
      "Eval Loss:  0.22080586850643158\n",
      "Eval Loss:  0.2463177740573883\n",
      "Eval Loss:  0.23433999717235565\n",
      "Eval Loss:  0.12707160413265228\n",
      "Eval Loss:  0.11401162296533585\n",
      "Eval Loss:  0.1433747112751007\n",
      "Eval Loss:  0.24249012768268585\n",
      "Eval Loss:  0.15110570192337036\n",
      "Eval Loss:  0.2521275579929352\n",
      "Eval Loss:  0.19191287457942963\n",
      "Eval Loss:  0.17696064710617065\n",
      "[[18195   930]\n",
      " [ 1306  9028]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.91      0.87      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.92     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.924097898774568\n",
      "pre:  0.9066077525607552\n",
      "rec:  0.873621056706019\n",
      "ma F1:  0.9159601613675363\n",
      "mi F1:  0.924097898774568\n",
      "we F1:  0.9237641157195835\n",
      "29459 461\n",
      "Loss:  0.042288340628147125\n",
      "Loss:  0.07576071470975876\n",
      "Loss:  0.041084498167037964\n",
      "39 **********\n",
      "Epoch:  3106.7128648757935  fold:  1  kers:  128\n",
      "epoch:  40\n",
      "29459 461\n",
      "Loss:  0.08580394089221954\n",
      "Loss:  0.037808217108249664\n",
      "Loss:  0.05509189888834953\n",
      "40 **********\n",
      "Epoch:  3170.6818249225616  fold:  1  kers:  128\n",
      "epoch:  41\n",
      "29459 461\n",
      "Loss:  0.035257767885923386\n",
      "Loss:  0.07753614336252213\n",
      "Loss:  0.03005051799118519\n",
      "41 **********\n",
      "Epoch:  3234.6477925777435  fold:  1  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  1.0979562997817993\n",
      "Eval Loss:  0.25847169756889343\n",
      "Eval Loss:  0.08098092675209045\n",
      "[[ 786  253]\n",
      " [ 359 2034]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72      1039\n",
      "           1       0.89      0.85      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.80      0.79      3432\n",
      "weighted avg       0.83      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8216783216783217\n",
      "pre:  0.8893747267162221\n",
      "rec:  0.8499791057250313\n",
      "ma F1:  0.7945054945054945\n",
      "mi F1:  0.8216783216783218\n",
      "we F1:  0.8239862701401163\n",
      "update!  Acc:  0.8216783216783217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.13907761871814728\n",
      "Eval Loss:  0.20562565326690674\n",
      "Eval Loss:  0.29640454053878784\n",
      "Eval Loss:  0.26467305421829224\n",
      "Eval Loss:  0.14324523508548737\n",
      "Eval Loss:  0.19722560048103333\n",
      "Eval Loss:  0.2768102288246155\n",
      "Eval Loss:  0.12655320763587952\n",
      "Eval Loss:  0.21707281470298767\n",
      "Eval Loss:  0.16296809911727905\n",
      "Eval Loss:  0.13254903256893158\n",
      "Eval Loss:  0.16515880823135376\n",
      "Eval Loss:  0.18904387950897217\n",
      "Eval Loss:  0.2611846923828125\n",
      "Eval Loss:  0.2066243588924408\n",
      "Eval Loss:  0.25300800800323486\n",
      "Eval Loss:  0.1984945386648178\n",
      "Eval Loss:  0.20142264664173126\n",
      "Eval Loss:  0.2583392560482025\n",
      "Eval Loss:  0.23065006732940674\n",
      "Eval Loss:  0.15656980872154236\n",
      "Eval Loss:  0.12251787632703781\n",
      "Eval Loss:  0.13496966660022736\n",
      "Eval Loss:  0.2472134232521057\n",
      "Eval Loss:  0.15467914938926697\n",
      "Eval Loss:  0.2581990361213684\n",
      "Eval Loss:  0.1967693269252777\n",
      "Eval Loss:  0.1740112155675888\n",
      "[[18318   807]\n",
      " [ 1430  8904]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     19125\n",
      "           1       0.92      0.86      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.92     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9240639532910147\n",
      "pre:  0.9168983626814952\n",
      "rec:  0.8616218308496226\n",
      "ma F1:  0.9154273642927651\n",
      "mi F1:  0.9240639532910147\n",
      "we F1:  0.9234924008217232\n",
      "29459 461\n",
      "Loss:  0.06652072072029114\n",
      "Loss:  0.054459504783153534\n",
      "Loss:  0.034722473472356796\n",
      "42 **********\n",
      "Epoch:  3339.0426619052887  fold:  1  kers:  128\n",
      "epoch:  43\n",
      "29459 461\n",
      "Loss:  0.040811918675899506\n",
      "Loss:  0.06445665657520294\n",
      "Loss:  0.04617699235677719\n",
      "43 **********\n",
      "Epoch:  3402.9886837005615  fold:  1  kers:  128\n",
      "epoch:  44\n",
      "29459 461\n",
      "Loss:  0.0670691505074501\n",
      "Loss:  0.05179506540298462\n",
      "Loss:  0.0616447739303112\n",
      "44 **********\n",
      "Epoch:  3466.9875631332397  fold:  1  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  1.6332628726959229\n",
      "Eval Loss:  0.3047747313976288\n",
      "Eval Loss:  0.09642500430345535\n",
      "[[ 769  270]\n",
      " [ 383 2010]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70      1039\n",
      "           1       0.88      0.84      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.79      0.78      3432\n",
      "weighted avg       0.82      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8097319347319347\n",
      "pre:  0.881578947368421\n",
      "rec:  0.8399498537400752\n",
      "ma F1:  0.7811118242117068\n",
      "mi F1:  0.8097319347319346\n",
      "we F1:  0.8123379560766454\n",
      "Eval Loss:  0.1556246280670166\n",
      "Eval Loss:  0.19106988608837128\n",
      "Eval Loss:  0.3011922538280487\n",
      "Eval Loss:  0.2596263587474823\n",
      "Eval Loss:  0.1446802020072937\n",
      "Eval Loss:  0.18308767676353455\n",
      "Eval Loss:  0.26824408769607544\n",
      "Eval Loss:  0.10891107469797134\n",
      "Eval Loss:  0.2158363163471222\n",
      "Eval Loss:  0.14915257692337036\n",
      "Eval Loss:  0.1180550754070282\n",
      "Eval Loss:  0.17487719655036926\n",
      "Eval Loss:  0.17449715733528137\n",
      "Eval Loss:  0.25958186388015747\n",
      "Eval Loss:  0.2127947062253952\n",
      "Eval Loss:  0.22144223749637604\n",
      "Eval Loss:  0.16681157052516937\n",
      "Eval Loss:  0.21574898064136505\n",
      "Eval Loss:  0.2450745850801468\n",
      "Eval Loss:  0.2193015217781067\n",
      "Eval Loss:  0.14067889750003815\n",
      "Eval Loss:  0.1345631331205368\n",
      "Eval Loss:  0.13252010941505432\n",
      "Eval Loss:  0.23687955737113953\n",
      "Eval Loss:  0.15604709088802338\n",
      "Eval Loss:  0.25236639380455017\n",
      "Eval Loss:  0.17756693065166473\n",
      "Eval Loss:  0.19521485269069672\n",
      "[[18397   728]\n",
      " [ 1408  8926]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95     19125\n",
      "           1       0.92      0.86      0.89     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.93      0.91      0.92     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9274924471299094\n",
      "pre:  0.924590843173814\n",
      "rec:  0.8637507257596284\n",
      "ma F1:  0.9191340851261335\n",
      "mi F1:  0.9274924471299094\n",
      "we F1:  0.9268923324469227\n",
      "29459 461\n",
      "Loss:  0.04343222826719284\n",
      "Loss:  0.028747912496328354\n",
      "Loss:  0.033057618886232376\n",
      "45 **********\n",
      "Epoch:  3571.3864221572876  fold:  1  kers:  128\n",
      "epoch:  46\n",
      "29459 461\n",
      "Loss:  0.05153069272637367\n",
      "Loss:  0.0514313206076622\n",
      "Loss:  0.0478433296084404\n",
      "46 **********\n",
      "Epoch:  3635.3424167633057  fold:  1  kers:  128\n",
      "epoch:  47\n",
      "29459 461\n",
      "Loss:  0.08028507977724075\n",
      "Loss:  0.03129631653428078\n",
      "Loss:  0.03440554067492485\n",
      "47 **********\n",
      "Epoch:  3699.334315776825  fold:  1  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  1.4651066064834595\n",
      "Eval Loss:  0.26062116026878357\n",
      "Eval Loss:  0.11121051758527756\n",
      "[[ 730  309]\n",
      " [ 274 2119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71      1039\n",
      "           1       0.87      0.89      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.79      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8301282051282052\n",
      "pre:  0.8727347611202636\n",
      "rec:  0.885499373171751\n",
      "ma F1:  0.7968530361996173\n",
      "mi F1:  0.8301282051282052\n",
      "we F1:  0.8292897379485792\n",
      "update!  Acc:  0.8301282051282052\n",
      "Eval Loss:  0.13508659601211548\n",
      "Eval Loss:  0.1676989495754242\n",
      "Eval Loss:  0.2901409864425659\n",
      "Eval Loss:  0.2358347773551941\n",
      "Eval Loss:  0.1464420109987259\n",
      "Eval Loss:  0.19444052875041962\n",
      "Eval Loss:  0.25181952118873596\n",
      "Eval Loss:  0.10529952496290207\n",
      "Eval Loss:  0.2164132297039032\n",
      "Eval Loss:  0.1468496173620224\n",
      "Eval Loss:  0.12374677509069443\n",
      "Eval Loss:  0.163387268781662\n",
      "Eval Loss:  0.16574060916900635\n",
      "Eval Loss:  0.2263570874929428\n",
      "Eval Loss:  0.20762431621551514\n",
      "Eval Loss:  0.208207905292511\n",
      "Eval Loss:  0.16669636964797974\n",
      "Eval Loss:  0.1997627466917038\n",
      "Eval Loss:  0.23243080079555511\n",
      "Eval Loss:  0.2290869951248169\n",
      "Eval Loss:  0.15457923710346222\n",
      "Eval Loss:  0.11526811122894287\n",
      "Eval Loss:  0.11702834069728851\n",
      "Eval Loss:  0.21198567748069763\n",
      "Eval Loss:  0.1340668499469757\n",
      "Eval Loss:  0.231332927942276\n",
      "Eval Loss:  0.18298470973968506\n",
      "Eval Loss:  0.14405915141105652\n",
      "[[18052  1073]\n",
      " [  981  9353]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     19125\n",
      "           1       0.90      0.91      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.92      0.92      0.92     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9302759767812893\n",
      "pre:  0.8970842125455591\n",
      "rec:  0.905070640603832\n",
      "ma F1:  0.9236154566132644\n",
      "mi F1:  0.9302759767812893\n",
      "we F1:  0.9303464179648112\n",
      "29459 461\n",
      "Loss:  0.05309288576245308\n",
      "Loss:  0.053049635142087936\n",
      "Loss:  0.03886324539780617\n",
      "48 **********\n",
      "Epoch:  3803.815952539444  fold:  1  kers:  128\n",
      "epoch:  49\n",
      "29459 461\n",
      "Loss:  0.07300850003957748\n",
      "Loss:  0.05907703936100006\n",
      "Loss:  0.07674425095319748\n",
      "49 **********\n",
      "Epoch:  3867.7669603824615  fold:  1  kers:  128\n",
      "epoch:  50\n",
      "29459 461\n",
      "Loss:  0.06623975187540054\n",
      "Loss:  0.04474666714668274\n",
      "Loss:  0.0488138422369957\n",
      "50 **********\n",
      "Epoch:  3931.750880718231  fold:  1  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  1.3697317838668823\n",
      "Eval Loss:  0.22965550422668457\n",
      "Eval Loss:  0.07636731117963791\n",
      "[[ 703  336]\n",
      " [ 359 2034]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67      1039\n",
      "           1       0.86      0.85      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.76      0.76      3432\n",
      "weighted avg       0.80      0.80      0.80      3432\n",
      "\n",
      "acc:  0.7974941724941725\n",
      "pre:  0.8582278481012658\n",
      "rec:  0.8499791057250313\n",
      "ma F1:  0.7616443505951747\n",
      "mi F1:  0.7974941724941725\n",
      "we F1:  0.7981136660356278\n",
      "Eval Loss:  0.1262197345495224\n",
      "Eval Loss:  0.14119668304920197\n",
      "Eval Loss:  0.2788470387458801\n",
      "Eval Loss:  0.24456259608268738\n",
      "Eval Loss:  0.14337190985679626\n",
      "Eval Loss:  0.17808672785758972\n",
      "Eval Loss:  0.23847481608390808\n",
      "Eval Loss:  0.11631517857313156\n",
      "Eval Loss:  0.19771111011505127\n",
      "Eval Loss:  0.13501903414726257\n",
      "Eval Loss:  0.1400931030511856\n",
      "Eval Loss:  0.15203213691711426\n",
      "Eval Loss:  0.22575588524341583\n",
      "Eval Loss:  0.24608543515205383\n",
      "Eval Loss:  0.2137555480003357\n",
      "Eval Loss:  0.21510401368141174\n",
      "Eval Loss:  0.16474536061286926\n",
      "Eval Loss:  0.20075207948684692\n",
      "Eval Loss:  0.22481675446033478\n",
      "Eval Loss:  0.23680749535560608\n",
      "Eval Loss:  0.1396843045949936\n",
      "Eval Loss:  0.10739939659833908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.13325367867946625\n",
      "Eval Loss:  0.2308558076620102\n",
      "Eval Loss:  0.13265681266784668\n",
      "Eval Loss:  0.20382460951805115\n",
      "Eval Loss:  0.19839368760585785\n",
      "Eval Loss:  0.18062306940555573\n",
      "[[18018  1107]\n",
      " [  947  9387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     19125\n",
      "           1       0.89      0.91      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.92      0.93      0.92     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9302759767812893\n",
      "pre:  0.8945111492281304\n",
      "rec:  0.9083607509192956\n",
      "ma F1:  0.9237289196546261\n",
      "mi F1:  0.9302759767812893\n",
      "we F1:  0.9303973450051642\n",
      "29459 461\n",
      "Loss:  0.06759805977344513\n",
      "Loss:  0.05191748961806297\n",
      "Loss:  0.05711370334029198\n",
      "51 **********\n",
      "Epoch:  4036.1826510429382  fold:  1  kers:  128\n",
      "epoch:  52\n",
      "29459 461\n",
      "Loss:  0.055240146815776825\n",
      "Loss:  0.05580234155058861\n",
      "Loss:  0.0723283588886261\n",
      "52 **********\n",
      "Epoch:  4100.12468290329  fold:  1  kers:  128\n",
      "epoch:  53\n",
      "29459 461\n",
      "Loss:  0.051581233739852905\n",
      "Loss:  0.04837540537118912\n",
      "Loss:  0.053076185286045074\n",
      "53 **********\n",
      "Epoch:  4164.106608390808  fold:  1  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  1.5630148649215698\n",
      "Eval Loss:  0.25761374831199646\n",
      "Eval Loss:  0.0358453132212162\n",
      "[[ 741  298]\n",
      " [ 329 2064]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      1039\n",
      "           1       0.87      0.86      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.78      0.79      0.79      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8173076923076923\n",
      "pre:  0.8738357324301439\n",
      "rec:  0.8625156707062265\n",
      "ma F1:  0.7854207519822661\n",
      "mi F1:  0.8173076923076923\n",
      "we F1:  0.8180548541747278\n",
      "Eval Loss:  0.1184803694486618\n",
      "Eval Loss:  0.16226951777935028\n",
      "Eval Loss:  0.30848824977874756\n",
      "Eval Loss:  0.2215353399515152\n",
      "Eval Loss:  0.1424839049577713\n",
      "Eval Loss:  0.19060999155044556\n",
      "Eval Loss:  0.23447014391422272\n",
      "Eval Loss:  0.11636597663164139\n",
      "Eval Loss:  0.18902269005775452\n",
      "Eval Loss:  0.1599818915128708\n",
      "Eval Loss:  0.1311468631029129\n",
      "Eval Loss:  0.14796949923038483\n",
      "Eval Loss:  0.23845770955085754\n",
      "Eval Loss:  0.24088157713413239\n",
      "Eval Loss:  0.20930327475070953\n",
      "Eval Loss:  0.21554997563362122\n",
      "Eval Loss:  0.19350776076316833\n",
      "Eval Loss:  0.18490248918533325\n",
      "Eval Loss:  0.24574404954910278\n",
      "Eval Loss:  0.25021788477897644\n",
      "Eval Loss:  0.15016858279705048\n",
      "Eval Loss:  0.1198512464761734\n",
      "Eval Loss:  0.1171560138463974\n",
      "Eval Loss:  0.23679670691490173\n",
      "Eval Loss:  0.13522033393383026\n",
      "Eval Loss:  0.21587631106376648\n",
      "Eval Loss:  0.1634661704301834\n",
      "Eval Loss:  0.12823911011219025\n",
      "[[18126   999]\n",
      " [ 1124  9210]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     19125\n",
      "           1       0.90      0.89      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.92      0.92      0.92     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9279337384161037\n",
      "pre:  0.9021451660299735\n",
      "rec:  0.8912328236887943\n",
      "ma F1:  0.9206666597956681\n",
      "mi F1:  0.9279337384161037\n",
      "we F1:  0.9278318558647853\n",
      "29459 461\n",
      "Loss:  0.058262646198272705\n",
      "Loss:  0.04772985354065895\n",
      "Loss:  0.04863470792770386\n",
      "54 **********\n",
      "Epoch:  4268.3668377399445  fold:  1  kers:  128\n",
      "epoch:  55\n",
      "29459 461\n",
      "Loss:  0.04746200516819954\n",
      "Loss:  0.03433583676815033\n",
      "Loss:  0.02755206823348999\n",
      "55 **********\n",
      "Epoch:  4332.341782093048  fold:  1  kers:  128\n",
      "epoch:  56\n",
      "29459 461\n",
      "Loss:  0.020365001633763313\n",
      "Loss:  0.05591972544789314\n",
      "Loss:  0.0582781545817852\n",
      "56 **********\n",
      "Epoch:  4396.388533592224  fold:  1  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  1.6131466627120972\n",
      "Eval Loss:  0.20740258693695068\n",
      "Eval Loss:  0.08181621879339218\n",
      "[[ 728  311]\n",
      " [ 286 2107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71      1039\n",
      "           1       0.87      0.88      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.79      0.79      0.79      3432\n",
      "weighted avg       0.82      0.83      0.83      3432\n",
      "\n",
      "acc:  0.826048951048951\n",
      "pre:  0.8713813068651778\n",
      "rec:  0.8804847471792728\n",
      "ma F1:  0.7925577071459979\n",
      "mi F1:  0.8260489510489509\n",
      "we F1:  0.8254417856409932\n",
      "Eval Loss:  0.13095645606517792\n",
      "Eval Loss:  0.17799963057041168\n",
      "Eval Loss:  0.302341490983963\n",
      "Eval Loss:  0.22179599106311798\n",
      "Eval Loss:  0.11527804285287857\n",
      "Eval Loss:  0.16510009765625\n",
      "Eval Loss:  0.24311989545822144\n",
      "Eval Loss:  0.09534776955842972\n",
      "Eval Loss:  0.20926135778427124\n",
      "Eval Loss:  0.16949111223220825\n",
      "Eval Loss:  0.10515821725130081\n",
      "Eval Loss:  0.16371475160121918\n",
      "Eval Loss:  0.16999146342277527\n",
      "Eval Loss:  0.2286606729030609\n",
      "Eval Loss:  0.18021371960639954\n",
      "Eval Loss:  0.1886644810438156\n",
      "Eval Loss:  0.19728799164295197\n",
      "Eval Loss:  0.19453294575214386\n",
      "Eval Loss:  0.2340010702610016\n",
      "Eval Loss:  0.22120454907417297\n",
      "Eval Loss:  0.128530353307724\n",
      "Eval Loss:  0.13397955894470215\n",
      "Eval Loss:  0.10616675764322281\n",
      "Eval Loss:  0.2201228141784668\n",
      "Eval Loss:  0.14213739335536957\n",
      "Eval Loss:  0.22021780908107758\n",
      "Eval Loss:  0.14020437002182007\n",
      "Eval Loss:  0.13741850852966309\n",
      "[[18275   850]\n",
      " [ 1104  9230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     19125\n",
      "           1       0.92      0.89      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.93      0.92      0.93     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9336705251366306\n",
      "pre:  0.9156746031746031\n",
      "rec:  0.8931681826978904\n",
      "ma F1:  0.9267667006450782\n",
      "mi F1:  0.9336705251366306\n",
      "we F1:  0.9334766532271941\n",
      "29459 461\n",
      "Loss:  0.029476458206772804\n",
      "Loss:  0.07454952597618103\n",
      "Loss:  0.044602591544389725\n",
      "57 **********\n",
      "Epoch:  4505.4469339847565  fold:  1  kers:  128\n",
      "epoch:  58\n",
      "29459 461\n",
      "Loss:  0.022729819640517235\n",
      "Loss:  0.04129108414053917\n",
      "Loss:  0.056123219430446625\n",
      "58 **********\n",
      "Epoch:  4570.788224935532  fold:  1  kers:  128\n",
      "epoch:  59\n",
      "29459 461\n",
      "Loss:  0.07296805083751678\n",
      "Loss:  0.06759575009346008\n",
      "Loss:  0.03356190770864487\n",
      "59 **********\n",
      "Epoch:  4634.770150184631  fold:  1  kers:  128\n",
      "Eval Loss:  1.1144620180130005\n",
      "Eval Loss:  0.2236291617155075\n",
      "Eval Loss:  0.0804673284292221\n",
      "[[ 806  233]\n",
      " [ 405 1988]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72      1039\n",
      "           1       0.90      0.83      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.80      0.79      3432\n",
      "weighted avg       0.83      0.81      0.82      3432\n",
      "\n",
      "acc:  0.8141025641025641\n",
      "pre:  0.895092300765421\n",
      "rec:  0.8307563727538655\n",
      "ma F1:  0.7890848143331888\n",
      "mi F1:  0.8141025641025641\n",
      "we F1:  0.817743048840578\n",
      "update!  Acc:  0.8301282051282052\n",
      "Epoch:  4639.138470172882  fold:  1  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29797 3094\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29797 466\n",
      "Loss:  0.1686757355928421\n",
      "Loss:  0.16367332637310028\n",
      "Loss:  0.16378545761108398\n",
      "0 **********\n",
      "Epoch:  77.16766929626465  fold:  2  kers:  128\n",
      "epoch:  1\n",
      "29797 466\n",
      "Loss:  0.16518306732177734\n",
      "Loss:  0.11896036565303802\n",
      "Loss:  0.1090717762708664\n",
      "1 **********\n",
      "Epoch:  141.80584001541138  fold:  2  kers:  128\n",
      "epoch:  2\n",
      "29797 466\n",
      "Loss:  0.11156641691923141\n",
      "Loss:  0.10102950781583786\n",
      "Loss:  0.10861106216907501\n",
      "2 **********\n",
      "Epoch:  206.49686908721924  fold:  2  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.7586417198181152\n",
      "Eval Loss:  0.20982469618320465\n",
      "Eval Loss:  0.6310229897499084\n",
      "[[1138  292]\n",
      " [ 545 1119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.73      1430\n",
      "           1       0.79      0.67      0.73      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.73      0.73      0.73      3094\n",
      "weighted avg       0.74      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7294764059469941\n",
      "pre:  0.7930545712260808\n",
      "rec:  0.6724759615384616\n",
      "ma F1:  0.7294662038814412\n",
      "mi F1:  0.7294764059469941\n",
      "we F1:  0.7293405573898956\n",
      "update!  Acc:  0.7294764059469941\n",
      "Eval Loss:  0.36680763959884644\n",
      "Eval Loss:  0.42280060052871704\n",
      "Eval Loss:  0.3558674454689026\n",
      "Eval Loss:  0.3923813998699188\n",
      "Eval Loss:  0.37340790033340454\n",
      "Eval Loss:  0.43413814902305603\n",
      "Eval Loss:  0.40728625655174255\n",
      "Eval Loss:  0.3764314353466034\n",
      "Eval Loss:  0.3140595555305481\n",
      "Eval Loss:  0.4196600615978241\n",
      "Eval Loss:  0.36990004777908325\n",
      "Eval Loss:  0.3608899414539337\n",
      "Eval Loss:  0.3873133361339569\n",
      "Eval Loss:  0.3278820812702179\n",
      "Eval Loss:  0.31641334295272827\n",
      "Eval Loss:  0.3553467094898224\n",
      "Eval Loss:  0.31858184933662415\n",
      "Eval Loss:  0.30909988284111023\n",
      "Eval Loss:  0.36556679010391235\n",
      "Eval Loss:  0.3545560836791992\n",
      "Eval Loss:  0.33407139778137207\n",
      "Eval Loss:  0.35579782724380493\n",
      "Eval Loss:  0.3721476197242737\n",
      "Eval Loss:  0.5183261632919312\n",
      "Eval Loss:  0.35141521692276\n",
      "Eval Loss:  0.29081180691719055\n",
      "Eval Loss:  0.3343907296657562\n",
      "Eval Loss:  0.31948888301849365\n",
      "Eval Loss:  0.3049792945384979\n",
      "[[16219  2515]\n",
      " [ 2314  8749]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87     18734\n",
      "           1       0.78      0.79      0.78     11063\n",
      "\n",
      "    accuracy                           0.84     29797\n",
      "   macro avg       0.83      0.83      0.83     29797\n",
      "weighted avg       0.84      0.84      0.84     29797\n",
      "\n",
      "acc:  0.8379367050374199\n",
      "pre:  0.7767223011363636\n",
      "rec:  0.790834312573443\n",
      "ma F1:  0.8270681686848735\n",
      "mi F1:  0.8379367050374199\n",
      "we F1:  0.83822915159791\n",
      "29797 466\n",
      "Loss:  0.09022864699363708\n",
      "Loss:  0.09650055319070816\n",
      "Loss:  0.09235967695713043\n",
      "3 **********\n",
      "Epoch:  311.6197919845581  fold:  2  kers:  128\n",
      "epoch:  4\n",
      "29797 466\n",
      "Loss:  0.07330261170864105\n",
      "Loss:  0.11399432271718979\n",
      "Loss:  0.06994037330150604\n",
      "4 **********\n",
      "Epoch:  376.28788232803345  fold:  2  kers:  128\n",
      "epoch:  5\n",
      "29797 466\n",
      "Loss:  0.09750723093748093\n",
      "Loss:  0.10224044322967529\n",
      "Loss:  0.06524291634559631\n",
      "5 **********\n",
      "Epoch:  440.9838981628418  fold:  2  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  1.1405314207077026\n",
      "Eval Loss:  0.06219694763422012\n",
      "Eval Loss:  0.9481613636016846\n",
      "[[1360   70]\n",
      " [ 973  691]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72      1430\n",
      "           1       0.91      0.42      0.57      1664\n",
      "\n",
      "    accuracy                           0.66      3094\n",
      "   macro avg       0.75      0.68      0.65      3094\n",
      "weighted avg       0.76      0.66      0.64      3094\n",
      "\n",
      "acc:  0.6628959276018099\n",
      "pre:  0.9080157687253614\n",
      "rec:  0.4152644230769231\n",
      "ma F1:  0.6463622192207905\n",
      "mi F1:  0.6628959276018099\n",
      "we F1:  0.6405791283969363\n",
      "Eval Loss:  0.38212281465530396\n",
      "Eval Loss:  0.3632754981517792\n",
      "Eval Loss:  0.40294691920280457\n",
      "Eval Loss:  0.4056392312049866\n",
      "Eval Loss:  0.345319539308548\n",
      "Eval Loss:  0.501087486743927\n",
      "Eval Loss:  0.43488672375679016\n",
      "Eval Loss:  0.34356504678726196\n",
      "Eval Loss:  0.343571275472641\n",
      "Eval Loss:  0.5686962604522705\n",
      "Eval Loss:  0.39072802662849426\n",
      "Eval Loss:  0.32773056626319885\n",
      "Eval Loss:  0.4217406213283539\n",
      "Eval Loss:  0.43451598286628723\n",
      "Eval Loss:  0.295993834733963\n",
      "Eval Loss:  0.4113921821117401\n",
      "Eval Loss:  0.43340831995010376\n",
      "Eval Loss:  0.3584371507167816\n",
      "Eval Loss:  0.3940168023109436\n",
      "Eval Loss:  0.252749502658844\n",
      "Eval Loss:  0.37968677282333374\n",
      "Eval Loss:  0.2987308204174042\n",
      "Eval Loss:  0.37994202971458435\n",
      "Eval Loss:  0.6884489059448242\n",
      "Eval Loss:  0.4027535021305084\n",
      "Eval Loss:  0.276389479637146\n",
      "Eval Loss:  0.339422345161438\n",
      "Eval Loss:  0.3716401755809784\n",
      "Eval Loss:  0.2881183922290802\n",
      "[[18150   584]\n",
      " [ 3871  7192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     18734\n",
      "           1       0.92      0.65      0.76     11063\n",
      "\n",
      "    accuracy                           0.85     29797\n",
      "   macro avg       0.87      0.81      0.83     29797\n",
      "weighted avg       0.86      0.85      0.84     29797\n",
      "\n",
      "acc:  0.8504883041916972\n",
      "pre:  0.9248971193415638\n",
      "rec:  0.6500949109644761\n",
      "ma F1:  0.8271053695355466\n",
      "mi F1:  0.8504883041916972\n",
      "we F1:  0.8434742773423848\n",
      "29797 466\n",
      "Loss:  0.09627275913953781\n",
      "Loss:  0.059538211673498154\n",
      "Loss:  0.07770247757434845\n",
      "6 **********\n",
      "Epoch:  546.0619416236877  fold:  2  kers:  128\n",
      "epoch:  7\n",
      "29797 466\n",
      "Loss:  0.0681758001446724\n",
      "Loss:  0.04838436096906662\n",
      "Loss:  0.06158199533820152\n",
      "7 **********\n",
      "Epoch:  610.7559626102448  fold:  2  kers:  128\n",
      "epoch:  8\n",
      "29797 466\n",
      "Loss:  0.07522594183683395\n",
      "Loss:  0.09344450384378433\n",
      "Loss:  0.05575518310070038\n",
      "8 **********\n",
      "Epoch:  675.4509809017181  fold:  2  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  1.0206714868545532\n",
      "Eval Loss:  0.11682721227407455\n",
      "Eval Loss:  0.565484344959259\n",
      "[[1354   76]\n",
      " [ 885  779]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.95      0.74      1430\n",
      "           1       0.91      0.47      0.62      1664\n",
      "\n",
      "    accuracy                           0.69      3094\n",
      "   macro avg       0.76      0.71      0.68      3094\n",
      "weighted avg       0.77      0.69      0.67      3094\n",
      "\n",
      "acc:  0.68939883645766\n",
      "pre:  0.9111111111111111\n",
      "rec:  0.46814903846153844\n",
      "ma F1:  0.6782875872450866\n",
      "mi F1:  0.68939883645766\n",
      "we F1:  0.6737657919133612\n",
      "Eval Loss:  0.35963982343673706\n",
      "Eval Loss:  0.3383767008781433\n",
      "Eval Loss:  0.36781421303749084\n",
      "Eval Loss:  0.3350942134857178\n",
      "Eval Loss:  0.2644248902797699\n",
      "Eval Loss:  0.3991186320781708\n",
      "Eval Loss:  0.3485966920852661\n",
      "Eval Loss:  0.3087577819824219\n",
      "Eval Loss:  0.2928132116794586\n",
      "Eval Loss:  0.4990803897380829\n",
      "Eval Loss:  0.3593060374259949\n",
      "Eval Loss:  0.2653037905693054\n",
      "Eval Loss:  0.3652507960796356\n",
      "Eval Loss:  0.3601575791835785\n",
      "Eval Loss:  0.2736101746559143\n",
      "Eval Loss:  0.36863771080970764\n",
      "Eval Loss:  0.3499172329902649\n",
      "Eval Loss:  0.29635629057884216\n",
      "Eval Loss:  0.3532746434211731\n",
      "Eval Loss:  0.1989462971687317\n",
      "Eval Loss:  0.3014582693576813\n",
      "Eval Loss:  0.2602715790271759\n",
      "Eval Loss:  0.3284774422645569\n",
      "Eval Loss:  0.5734859704971313\n",
      "Eval Loss:  0.37772336602211\n",
      "Eval Loss:  0.25676199793815613\n",
      "Eval Loss:  0.329318106174469\n",
      "Eval Loss:  0.3053857088088989\n",
      "Eval Loss:  0.2635166049003601\n",
      "[[18171   563]\n",
      " [ 3327  7736]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90     18734\n",
      "           1       0.93      0.70      0.80     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.89      0.83      0.85     29797\n",
      "weighted avg       0.88      0.87      0.86     29797\n",
      "\n",
      "acc:  0.8694499446252979\n",
      "pre:  0.9321605012652127\n",
      "rec:  0.6992678297026124\n",
      "ma F1:  0.8512009001853911\n",
      "mi F1:  0.8694499446252979\n",
      "we F1:  0.8646161776073868\n",
      "29797 466\n",
      "Loss:  0.046156637370586395\n",
      "Loss:  0.08426504582166672\n",
      "Loss:  0.06407526880502701\n",
      "9 **********\n",
      "Epoch:  780.5449810028076  fold:  2  kers:  128\n",
      "epoch:  10\n",
      "29797 466\n",
      "Loss:  0.09261152893304825\n",
      "Loss:  0.08275824785232544\n",
      "Loss:  0.0912756472826004\n",
      "10 **********\n",
      "Epoch:  845.2400000095367  fold:  2  kers:  128\n",
      "epoch:  11\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04907730594277382\n",
      "Loss:  0.04997717961668968\n",
      "Loss:  0.07321567833423615\n",
      "11 **********\n",
      "Epoch:  909.949978351593  fold:  2  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.5609974265098572\n",
      "Eval Loss:  0.3933209180831909\n",
      "Eval Loss:  0.5404314994812012\n",
      "[[1284  146]\n",
      " [ 641 1023]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      1430\n",
      "           1       0.88      0.61      0.72      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.77      0.76      0.74      3094\n",
      "weighted avg       0.78      0.75      0.74      3094\n",
      "\n",
      "acc:  0.7456367162249515\n",
      "pre:  0.8751069289991446\n",
      "rec:  0.6147836538461539\n",
      "ma F1:  0.7438136756336198\n",
      "mi F1:  0.7456367162249515\n",
      "we F1:  0.742179225448288\n",
      "update!  Acc:  0.7456367162249515\n",
      "Eval Loss:  0.25199949741363525\n",
      "Eval Loss:  0.23965959250926971\n",
      "Eval Loss:  0.22856509685516357\n",
      "Eval Loss:  0.22536838054656982\n",
      "Eval Loss:  0.19739308953285217\n",
      "Eval Loss:  0.25334474444389343\n",
      "Eval Loss:  0.23692002892494202\n",
      "Eval Loss:  0.27956971526145935\n",
      "Eval Loss:  0.19651803374290466\n",
      "Eval Loss:  0.29088154435157776\n",
      "Eval Loss:  0.24859203398227692\n",
      "Eval Loss:  0.18082906305789948\n",
      "Eval Loss:  0.2418753057718277\n",
      "Eval Loss:  0.24728667736053467\n",
      "Eval Loss:  0.20732350647449493\n",
      "Eval Loss:  0.24956153333187103\n",
      "Eval Loss:  0.18304716050624847\n",
      "Eval Loss:  0.18895289301872253\n",
      "Eval Loss:  0.2514340579509735\n",
      "Eval Loss:  0.1781725287437439\n",
      "Eval Loss:  0.21087495982646942\n",
      "Eval Loss:  0.18871165812015533\n",
      "Eval Loss:  0.25123330950737\n",
      "Eval Loss:  0.3853278160095215\n",
      "Eval Loss:  0.25461387634277344\n",
      "Eval Loss:  0.21655595302581787\n",
      "Eval Loss:  0.2949303090572357\n",
      "Eval Loss:  0.18615633249282837\n",
      "Eval Loss:  0.1967569887638092\n",
      "[[17619  1115]\n",
      " [ 1680  9383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18734\n",
      "           1       0.89      0.85      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.90      0.89      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9061986105983824\n",
      "pre:  0.8937892931987045\n",
      "rec:  0.848142456838109\n",
      "ma F1:  0.8984394906772093\n",
      "mi F1:  0.9061986105983824\n",
      "we F1:  0.9056663251739697\n",
      "29797 466\n",
      "Loss:  0.0474475733935833\n",
      "Loss:  0.08036043494939804\n",
      "Loss:  0.08425688743591309\n",
      "12 **********\n",
      "Epoch:  1015.190586566925  fold:  2  kers:  128\n",
      "epoch:  13\n",
      "29797 466\n",
      "Loss:  0.04861769452691078\n",
      "Loss:  0.08654773980379105\n",
      "Loss:  0.04490000382065773\n",
      "13 **********\n",
      "Epoch:  1079.9005651474  fold:  2  kers:  128\n",
      "epoch:  14\n",
      "29797 466\n",
      "Loss:  0.07034668326377869\n",
      "Loss:  0.03785417228937149\n",
      "Loss:  0.046719860285520554\n",
      "14 **********\n",
      "Epoch:  1144.595584154129  fold:  2  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.5578961372375488\n",
      "Eval Loss:  0.1802137792110443\n",
      "Eval Loss:  0.6959418058395386\n",
      "[[1332   98]\n",
      " [ 730  934]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.76      1430\n",
      "           1       0.91      0.56      0.69      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.78      0.75      0.73      3094\n",
      "weighted avg       0.79      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7323852617970265\n",
      "pre:  0.9050387596899225\n",
      "rec:  0.5612980769230769\n",
      "ma F1:  0.727882468108538\n",
      "mi F1:  0.7323852617970265\n",
      "we F1:  0.7252350969449541\n",
      "Eval Loss:  0.2647414207458496\n",
      "Eval Loss:  0.2740023732185364\n",
      "Eval Loss:  0.27897441387176514\n",
      "Eval Loss:  0.22137898206710815\n",
      "Eval Loss:  0.20767943561077118\n",
      "Eval Loss:  0.25002697110176086\n",
      "Eval Loss:  0.2537279725074768\n",
      "Eval Loss:  0.2750101387500763\n",
      "Eval Loss:  0.1869068443775177\n",
      "Eval Loss:  0.3071506917476654\n",
      "Eval Loss:  0.28551191091537476\n",
      "Eval Loss:  0.16573306918144226\n",
      "Eval Loss:  0.2897621691226959\n",
      "Eval Loss:  0.24676752090454102\n",
      "Eval Loss:  0.19956213235855103\n",
      "Eval Loss:  0.27596795558929443\n",
      "Eval Loss:  0.21771661937236786\n",
      "Eval Loss:  0.22272513806819916\n",
      "Eval Loss:  0.25810128450393677\n",
      "Eval Loss:  0.17610476911067963\n",
      "Eval Loss:  0.2199818640947342\n",
      "Eval Loss:  0.18531876802444458\n",
      "Eval Loss:  0.2640373110771179\n",
      "Eval Loss:  0.43736422061920166\n",
      "Eval Loss:  0.26900091767311096\n",
      "Eval Loss:  0.19011448323726654\n",
      "Eval Loss:  0.2855921983718872\n",
      "Eval Loss:  0.2041037231683731\n",
      "Eval Loss:  0.18765705823898315\n",
      "[[17948   786]\n",
      " [ 2138  8925]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18734\n",
      "           1       0.92      0.81      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.88      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9018693157029231\n",
      "pre:  0.919060858819895\n",
      "rec:  0.8067431980475459\n",
      "ma F1:  0.8919625684366386\n",
      "mi F1:  0.9018693157029231\n",
      "we F1:  0.9003848956315481\n",
      "29797 466\n",
      "Loss:  0.060174986720085144\n",
      "Loss:  0.0589924156665802\n",
      "Loss:  0.06646952033042908\n",
      "15 **********\n",
      "Epoch:  1249.8012850284576  fold:  2  kers:  128\n",
      "epoch:  16\n",
      "29797 466\n",
      "Loss:  0.03773663565516472\n",
      "Loss:  0.03441481664776802\n",
      "Loss:  0.07628519833087921\n",
      "16 **********\n",
      "Epoch:  1314.502287864685  fold:  2  kers:  128\n",
      "epoch:  17\n",
      "29797 466\n",
      "Loss:  0.06183318793773651\n",
      "Loss:  0.05697941407561302\n",
      "Loss:  0.05360475182533264\n",
      "17 **********\n",
      "Epoch:  1379.1923198699951  fold:  2  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.5406532883644104\n",
      "Eval Loss:  0.19624018669128418\n",
      "Eval Loss:  0.6114272475242615\n",
      "[[1316  114]\n",
      " [ 728  936]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.92      0.76      1430\n",
      "           1       0.89      0.56      0.69      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.77      0.74      0.72      3094\n",
      "weighted avg       0.78      0.73      0.72      3094\n",
      "\n",
      "acc:  0.7278603749191984\n",
      "pre:  0.8914285714285715\n",
      "rec:  0.5625\n",
      "ma F1:  0.72369245546133\n",
      "mi F1:  0.7278603749191984\n",
      "we F1:  0.7211258945320109\n",
      "Eval Loss:  0.2412552386522293\n",
      "Eval Loss:  0.2756076753139496\n",
      "Eval Loss:  0.26550182700157166\n",
      "Eval Loss:  0.22576992213726044\n",
      "Eval Loss:  0.18787690997123718\n",
      "Eval Loss:  0.23598352074623108\n",
      "Eval Loss:  0.26727595925331116\n",
      "Eval Loss:  0.25721701979637146\n",
      "Eval Loss:  0.18886548280715942\n",
      "Eval Loss:  0.2580355107784271\n",
      "Eval Loss:  0.24112078547477722\n",
      "Eval Loss:  0.19099968671798706\n",
      "Eval Loss:  0.3031972050666809\n",
      "Eval Loss:  0.24549132585525513\n",
      "Eval Loss:  0.21478304266929626\n",
      "Eval Loss:  0.2384844273328781\n",
      "Eval Loss:  0.19263628125190735\n",
      "Eval Loss:  0.1986682265996933\n",
      "Eval Loss:  0.21087287366390228\n",
      "Eval Loss:  0.17272450029850006\n",
      "Eval Loss:  0.19660116732120514\n",
      "Eval Loss:  0.1726527363061905\n",
      "Eval Loss:  0.2760564088821411\n",
      "Eval Loss:  0.3897361755371094\n",
      "Eval Loss:  0.2668355703353882\n",
      "Eval Loss:  0.17928548157215118\n",
      "Eval Loss:  0.2544933557510376\n",
      "Eval Loss:  0.21266396343708038\n",
      "Eval Loss:  0.17566540837287903\n",
      "[[17893   841]\n",
      " [ 2006  9057]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18734\n",
      "           1       0.92      0.82      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.89      0.90     29797\n",
      "weighted avg       0.91      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9044534684699802\n",
      "pre:  0.9150333400687007\n",
      "rec:  0.818674862153123\n",
      "ma F1:  0.8952414264872861\n",
      "mi F1:  0.9044534684699802\n",
      "we F1:  0.9032388884666033\n",
      "29797 466\n",
      "Loss:  0.053310420364141464\n",
      "Loss:  0.07186610251665115\n",
      "Loss:  0.06825600564479828\n",
      "18 **********\n",
      "Epoch:  1484.3920373916626  fold:  2  kers:  128\n",
      "epoch:  19\n",
      "29797 466\n",
      "Loss:  0.04526110738515854\n",
      "Loss:  0.05703747645020485\n",
      "Loss:  0.07031537592411041\n",
      "19 **********\n",
      "Epoch:  1549.0740902423859  fold:  2  kers:  128\n",
      "epoch:  20\n",
      "29797 466\n",
      "Loss:  0.05927152931690216\n",
      "Loss:  0.08175897598266602\n",
      "Loss:  0.05387042462825775\n",
      "20 **********\n",
      "Epoch:  1613.787061214447  fold:  2  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.5978685021400452\n",
      "Eval Loss:  0.19720867276191711\n",
      "Eval Loss:  0.9117965698242188\n",
      "[[1314  116]\n",
      " [ 719  945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76      1430\n",
      "           1       0.89      0.57      0.69      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.77      0.74      0.73      3094\n",
      "weighted avg       0.78      0.73      0.72      3094\n",
      "\n",
      "acc:  0.7301228183581124\n",
      "pre:  0.8906691800188501\n",
      "rec:  0.5679086538461539\n",
      "ma F1:  0.7262287829134733\n",
      "mi F1:  0.7301228183581123\n",
      "we F1:  0.7237593945827264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22844375669956207\n",
      "Eval Loss:  0.2727242410182953\n",
      "Eval Loss:  0.26200053095817566\n",
      "Eval Loss:  0.2083042711019516\n",
      "Eval Loss:  0.20045171678066254\n",
      "Eval Loss:  0.2218388170003891\n",
      "Eval Loss:  0.24762655794620514\n",
      "Eval Loss:  0.25181710720062256\n",
      "Eval Loss:  0.19006507098674774\n",
      "Eval Loss:  0.2585933208465576\n",
      "Eval Loss:  0.22874927520751953\n",
      "Eval Loss:  0.16194836795330048\n",
      "Eval Loss:  0.26090994477272034\n",
      "Eval Loss:  0.2477443367242813\n",
      "Eval Loss:  0.1902136355638504\n",
      "Eval Loss:  0.23676326870918274\n",
      "Eval Loss:  0.1747157722711563\n",
      "Eval Loss:  0.192504420876503\n",
      "Eval Loss:  0.19161070883274078\n",
      "Eval Loss:  0.14464548230171204\n",
      "Eval Loss:  0.18451671302318573\n",
      "Eval Loss:  0.17226526141166687\n",
      "Eval Loss:  0.2892111837863922\n",
      "Eval Loss:  0.3870239555835724\n",
      "Eval Loss:  0.2590688467025757\n",
      "Eval Loss:  0.15952350199222565\n",
      "Eval Loss:  0.25423070788383484\n",
      "Eval Loss:  0.21551495790481567\n",
      "Eval Loss:  0.1802462339401245\n",
      "[[18056   678]\n",
      " [ 2073  8990]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18734\n",
      "           1       0.93      0.81      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.89      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.907675269322415\n",
      "pre:  0.9298717418287132\n",
      "rec:  0.8126186387055953\n",
      "ma F1:  0.8982565272384931\n",
      "mi F1:  0.907675269322415\n",
      "we F1:  0.9062259923306799\n",
      "29797 466\n",
      "Loss:  0.043800655752420425\n",
      "Loss:  0.05605596676468849\n",
      "Loss:  0.06341236084699631\n",
      "21 **********\n",
      "Epoch:  1719.0436263084412  fold:  2  kers:  128\n",
      "epoch:  22\n",
      "29797 466\n",
      "Loss:  0.05610113963484764\n",
      "Loss:  0.06674554198980331\n",
      "Loss:  0.0731816440820694\n",
      "22 **********\n",
      "Epoch:  1783.7167041301727  fold:  2  kers:  128\n",
      "epoch:  23\n",
      "29797 466\n",
      "Loss:  0.043720878660678864\n",
      "Loss:  0.06881456077098846\n",
      "Loss:  0.03789360448718071\n",
      "23 **********\n",
      "Epoch:  1848.4346611499786  fold:  2  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.5924655795097351\n",
      "Eval Loss:  0.35629189014434814\n",
      "Eval Loss:  0.6771675944328308\n",
      "[[1168  262]\n",
      " [ 479 1185]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      1430\n",
      "           1       0.82      0.71      0.76      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.76      0.76      0.76      3094\n",
      "weighted avg       0.77      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7605042016806722\n",
      "pre:  0.8189357290946786\n",
      "rec:  0.7121394230769231\n",
      "ma F1:  0.7604969711822778\n",
      "mi F1:  0.7605042016806722\n",
      "we F1:  0.7605964968660602\n",
      "update!  Acc:  0.7605042016806722\n",
      "Eval Loss:  0.19771045446395874\n",
      "Eval Loss:  0.18039953708648682\n",
      "Eval Loss:  0.21299217641353607\n",
      "Eval Loss:  0.19773247838020325\n",
      "Eval Loss:  0.16273242235183716\n",
      "Eval Loss:  0.2299804836511612\n",
      "Eval Loss:  0.21384964883327484\n",
      "Eval Loss:  0.2697972059249878\n",
      "Eval Loss:  0.15963788330554962\n",
      "Eval Loss:  0.18445897102355957\n",
      "Eval Loss:  0.2046857625246048\n",
      "Eval Loss:  0.12323135137557983\n",
      "Eval Loss:  0.22737151384353638\n",
      "Eval Loss:  0.20944242179393768\n",
      "Eval Loss:  0.20220665633678436\n",
      "Eval Loss:  0.21236874163150787\n",
      "Eval Loss:  0.13187159597873688\n",
      "Eval Loss:  0.14931577444076538\n",
      "Eval Loss:  0.1881878525018692\n",
      "Eval Loss:  0.19227272272109985\n",
      "Eval Loss:  0.19822722673416138\n",
      "Eval Loss:  0.19030439853668213\n",
      "Eval Loss:  0.23279064893722534\n",
      "Eval Loss:  0.293680876493454\n",
      "Eval Loss:  0.21822470426559448\n",
      "Eval Loss:  0.15824471414089203\n",
      "Eval Loss:  0.2661387026309967\n",
      "Eval Loss:  0.19082094728946686\n",
      "Eval Loss:  0.17591315507888794\n",
      "[[17388  1346]\n",
      " [ 1101  9962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18734\n",
      "           1       0.88      0.90      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.91      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9178776386884586\n",
      "pre:  0.880969225327202\n",
      "rec:  0.9004790743921178\n",
      "ma F1:  0.9124391961019908\n",
      "mi F1:  0.9178776386884586\n",
      "we F1:  0.9180570648174223\n",
      "29797 466\n",
      "Loss:  0.0520215705037117\n",
      "Loss:  0.041526827961206436\n",
      "Loss:  0.054033588618040085\n",
      "24 **********\n",
      "Epoch:  1953.7181544303894  fold:  2  kers:  128\n",
      "epoch:  25\n",
      "29797 466\n",
      "Loss:  0.05265709385275841\n",
      "Loss:  0.06030971556901932\n",
      "Loss:  0.05724220722913742\n",
      "25 **********\n",
      "Epoch:  2018.3922290802002  fold:  2  kers:  128\n",
      "epoch:  26\n",
      "29797 466\n",
      "Loss:  0.05443738028407097\n",
      "Loss:  0.06589166820049286\n",
      "Loss:  0.06798460334539413\n",
      "26 **********\n",
      "Epoch:  2083.0932319164276  fold:  2  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.5825536251068115\n",
      "Eval Loss:  0.2896586060523987\n",
      "Eval Loss:  0.719036340713501\n",
      "[[1186  244]\n",
      " [ 505 1159]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.83      0.76      1430\n",
      "           1       0.83      0.70      0.76      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.76      0.76      0.76      3094\n",
      "weighted avg       0.77      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7579185520361991\n",
      "pre:  0.8260869565217391\n",
      "rec:  0.6965144230769231\n",
      "ma F1:  0.7579001154082378\n",
      "mi F1:  0.7579185520361991\n",
      "we F1:  0.757740331299239\n",
      "Eval Loss:  0.19709278643131256\n",
      "Eval Loss:  0.18502622842788696\n",
      "Eval Loss:  0.22626735270023346\n",
      "Eval Loss:  0.20223724842071533\n",
      "Eval Loss:  0.18088535964488983\n",
      "Eval Loss:  0.186425119638443\n",
      "Eval Loss:  0.2011944055557251\n",
      "Eval Loss:  0.22392712533473969\n",
      "Eval Loss:  0.13791103661060333\n",
      "Eval Loss:  0.1660890281200409\n",
      "Eval Loss:  0.19357842206954956\n",
      "Eval Loss:  0.10355150699615479\n",
      "Eval Loss:  0.19623708724975586\n",
      "Eval Loss:  0.23028169572353363\n",
      "Eval Loss:  0.19646964967250824\n",
      "Eval Loss:  0.20889437198638916\n",
      "Eval Loss:  0.1408899426460266\n",
      "Eval Loss:  0.13965246081352234\n",
      "Eval Loss:  0.15594615042209625\n",
      "Eval Loss:  0.1542467474937439\n",
      "Eval Loss:  0.23160244524478912\n",
      "Eval Loss:  0.16532666981220245\n",
      "Eval Loss:  0.2764028310775757\n",
      "Eval Loss:  0.28106895089149475\n",
      "Eval Loss:  0.2163134515285492\n",
      "Eval Loss:  0.13232770562171936\n",
      "Eval Loss:  0.243204265832901\n",
      "Eval Loss:  0.19620175659656525\n",
      "Eval Loss:  0.1590113639831543\n",
      "[[17810   924]\n",
      " [ 1383  9680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18734\n",
      "           1       0.91      0.87      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.91      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.922576098264926\n",
      "pre:  0.9128630705394191\n",
      "rec:  0.8749887010756576\n",
      "ma F1:  0.9163486680461319\n",
      "mi F1:  0.922576098264926\n",
      "we F1:  0.922224512721208\n",
      "29797 466\n",
      "Loss:  0.05939067155122757\n",
      "Loss:  0.08222745358943939\n",
      "Loss:  0.05924033746123314\n",
      "27 **********\n",
      "Epoch:  2188.2031903266907  fold:  2  kers:  128\n",
      "epoch:  28\n",
      "29797 466\n",
      "Loss:  0.055443838238716125\n",
      "Loss:  0.03666660934686661\n",
      "Loss:  0.034225884824991226\n",
      "28 **********\n",
      "Epoch:  2252.9101758003235  fold:  2  kers:  128\n",
      "epoch:  29\n",
      "29797 466\n",
      "Loss:  0.029860572889447212\n",
      "Loss:  0.0724899098277092\n",
      "Loss:  0.048594892024993896\n",
      "29 **********\n",
      "Epoch:  2317.6420958042145  fold:  2  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.5749947428703308\n",
      "Eval Loss:  0.17520014941692352\n",
      "Eval Loss:  0.9195600152015686\n",
      "[[1255  175]\n",
      " [ 620 1044]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76      1430\n",
      "           1       0.86      0.63      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.76      0.75      0.74      3094\n",
      "weighted avg       0.77      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7430510665804784\n",
      "pre:  0.8564397046759639\n",
      "rec:  0.6274038461538461\n",
      "ma F1:  0.7418504740869714\n",
      "mi F1:  0.7430510665804783\n",
      "we F1:  0.7405190113216602\n",
      "Eval Loss:  0.198188915848732\n",
      "Eval Loss:  0.19194358587265015\n",
      "Eval Loss:  0.21185655891895294\n",
      "Eval Loss:  0.16853351891040802\n",
      "Eval Loss:  0.1441146284341812\n",
      "Eval Loss:  0.20106692612171173\n",
      "Eval Loss:  0.21684810519218445\n",
      "Eval Loss:  0.20156176388263702\n",
      "Eval Loss:  0.12303601205348969\n",
      "Eval Loss:  0.16619282960891724\n",
      "Eval Loss:  0.1845678836107254\n",
      "Eval Loss:  0.12216456234455109\n",
      "Eval Loss:  0.22286099195480347\n",
      "Eval Loss:  0.19813278317451477\n",
      "Eval Loss:  0.17728286981582642\n",
      "Eval Loss:  0.20118898153305054\n",
      "Eval Loss:  0.14161363244056702\n",
      "Eval Loss:  0.152845561504364\n",
      "Eval Loss:  0.17490050196647644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.14510132372379303\n",
      "Eval Loss:  0.22110971808433533\n",
      "Eval Loss:  0.16955091059207916\n",
      "Eval Loss:  0.2604616582393646\n",
      "Eval Loss:  0.30375048518180847\n",
      "Eval Loss:  0.21802882850170135\n",
      "Eval Loss:  0.1650879979133606\n",
      "Eval Loss:  0.24068951606750488\n",
      "Eval Loss:  0.1955823004245758\n",
      "Eval Loss:  0.14902432262897491\n",
      "[[17817   917]\n",
      " [ 1324  9739]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18734\n",
      "           1       0.91      0.88      0.90     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.92      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.924791086350975\n",
      "pre:  0.9139451951951952\n",
      "rec:  0.8803217933652716\n",
      "ma F1:  0.9188250685283088\n",
      "mi F1:  0.924791086350975\n",
      "we F1:  0.9244904959506499\n",
      "29797 466\n",
      "Loss:  0.0538741759955883\n",
      "Loss:  0.044248420745134354\n",
      "Loss:  0.0556514710187912\n",
      "30 **********\n",
      "Epoch:  2422.9265863895416  fold:  2  kers:  128\n",
      "epoch:  31\n",
      "29797 466\n",
      "Loss:  0.07133779674768448\n",
      "Loss:  0.09276041388511658\n",
      "Loss:  0.044816069304943085\n",
      "31 **********\n",
      "Epoch:  2487.6166186332703  fold:  2  kers:  128\n",
      "epoch:  32\n",
      "29797 466\n",
      "Loss:  0.033834464848041534\n",
      "Loss:  0.08176468312740326\n",
      "Loss:  0.04472249746322632\n",
      "32 **********\n",
      "Epoch:  2552.342554330826  fold:  2  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.6415003538131714\n",
      "Eval Loss:  0.3227280378341675\n",
      "Eval Loss:  1.1479289531707764\n",
      "[[1173  257]\n",
      " [ 570 1094]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.74      1430\n",
      "           1       0.81      0.66      0.73      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.74      0.74      0.73      3094\n",
      "weighted avg       0.75      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7327084680025856\n",
      "pre:  0.8097705403404886\n",
      "rec:  0.6574519230769231\n",
      "ma F1:  0.7325340938965222\n",
      "mi F1:  0.7327084680025856\n",
      "we F1:  0.732017593379828\n",
      "Eval Loss:  0.18777409195899963\n",
      "Eval Loss:  0.16833378374576569\n",
      "Eval Loss:  0.22348642349243164\n",
      "Eval Loss:  0.20535336434841156\n",
      "Eval Loss:  0.18042120337486267\n",
      "Eval Loss:  0.1871252954006195\n",
      "Eval Loss:  0.23625724017620087\n",
      "Eval Loss:  0.25287115573883057\n",
      "Eval Loss:  0.15137073397636414\n",
      "Eval Loss:  0.20942626893520355\n",
      "Eval Loss:  0.1934649497270584\n",
      "Eval Loss:  0.12244823575019836\n",
      "Eval Loss:  0.22783291339874268\n",
      "Eval Loss:  0.24085554480552673\n",
      "Eval Loss:  0.2563740611076355\n",
      "Eval Loss:  0.19947190582752228\n",
      "Eval Loss:  0.15075719356536865\n",
      "Eval Loss:  0.13702347874641418\n",
      "Eval Loss:  0.1912393867969513\n",
      "Eval Loss:  0.13683724403381348\n",
      "Eval Loss:  0.2470279037952423\n",
      "Eval Loss:  0.20574213564395905\n",
      "Eval Loss:  0.29620397090911865\n",
      "Eval Loss:  0.2940931022167206\n",
      "Eval Loss:  0.2266216278076172\n",
      "Eval Loss:  0.16037030518054962\n",
      "Eval Loss:  0.2375396341085434\n",
      "Eval Loss:  0.1981976330280304\n",
      "Eval Loss:  0.15441711246967316\n",
      "[[17767   967]\n",
      " [ 1530  9533]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18734\n",
      "           1       0.91      0.86      0.88     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.91      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9161996174111487\n",
      "pre:  0.9079047619047619\n",
      "rec:  0.8617011660489922\n",
      "ma F1:  0.9092714113079872\n",
      "mi F1:  0.9161996174111487\n",
      "we F1:  0.9157259011084914\n",
      "29797 466\n",
      "Loss:  0.034381940960884094\n",
      "Loss:  0.06260563433170319\n",
      "Loss:  0.07499001920223236\n",
      "33 **********\n",
      "Epoch:  2657.354773044586  fold:  2  kers:  128\n",
      "epoch:  34\n",
      "29797 466\n",
      "Loss:  0.0721798911690712\n",
      "Loss:  0.04286622256040573\n",
      "Loss:  0.02590731531381607\n",
      "34 **********\n",
      "Epoch:  2722.035829305649  fold:  2  kers:  128\n",
      "epoch:  35\n",
      "29797 466\n",
      "Loss:  0.055140651762485504\n",
      "Loss:  0.038418665528297424\n",
      "Loss:  0.05185516178607941\n",
      "35 **********\n",
      "Epoch:  2786.756778240204  fold:  2  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.5771096348762512\n",
      "Eval Loss:  0.12447718530893326\n",
      "Eval Loss:  1.0697474479675293\n",
      "[[1214  216]\n",
      " [ 590 1074]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.85      0.75      1430\n",
      "           1       0.83      0.65      0.73      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7394957983193278\n",
      "pre:  0.8325581395348837\n",
      "rec:  0.6454326923076923\n",
      "ma F1:  0.7389613320554418\n",
      "mi F1:  0.7394957983193278\n",
      "we F1:  0.738068009871518\n",
      "Eval Loss:  0.16517497599124908\n",
      "Eval Loss:  0.1811523139476776\n",
      "Eval Loss:  0.2281283736228943\n",
      "Eval Loss:  0.16575874388217926\n",
      "Eval Loss:  0.16734524071216583\n",
      "Eval Loss:  0.19397057592868805\n",
      "Eval Loss:  0.19918163120746613\n",
      "Eval Loss:  0.20734550058841705\n",
      "Eval Loss:  0.15792912244796753\n",
      "Eval Loss:  0.1969337910413742\n",
      "Eval Loss:  0.20095479488372803\n",
      "Eval Loss:  0.10594492405653\n",
      "Eval Loss:  0.2297317385673523\n",
      "Eval Loss:  0.2206902951002121\n",
      "Eval Loss:  0.17044778168201447\n",
      "Eval Loss:  0.2065654993057251\n",
      "Eval Loss:  0.12682071328163147\n",
      "Eval Loss:  0.1657591164112091\n",
      "Eval Loss:  0.19491194188594818\n",
      "Eval Loss:  0.15036359429359436\n",
      "Eval Loss:  0.19502662122249603\n",
      "Eval Loss:  0.1475774049758911\n",
      "Eval Loss:  0.27291205525398254\n",
      "Eval Loss:  0.31348922848701477\n",
      "Eval Loss:  0.21155457198619843\n",
      "Eval Loss:  0.14002981781959534\n",
      "Eval Loss:  0.21123194694519043\n",
      "Eval Loss:  0.1888415515422821\n",
      "Eval Loss:  0.16793540120124817\n",
      "[[18004   730]\n",
      " [ 1530  9533]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18734\n",
      "           1       0.93      0.86      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.93      0.91      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9241534382655973\n",
      "pre:  0.9288707005748806\n",
      "rec:  0.8617011660489922\n",
      "ma F1:  0.9174844478769508\n",
      "mi F1:  0.9241534382655973\n",
      "we F1:  0.9235236197895121\n",
      "29797 466\n",
      "Loss:  0.06875114887952805\n",
      "Loss:  0.04020138829946518\n",
      "Loss:  0.04089425876736641\n",
      "36 **********\n",
      "Epoch:  2891.838810443878  fold:  2  kers:  128\n",
      "epoch:  37\n",
      "29797 466\n",
      "Loss:  0.08347834646701813\n",
      "Loss:  0.06507755815982819\n",
      "Loss:  0.04033243656158447\n",
      "37 **********\n",
      "Epoch:  2956.5148797035217  fold:  2  kers:  128\n",
      "epoch:  38\n",
      "29797 466\n",
      "Loss:  0.07579916715621948\n",
      "Loss:  0.03352261707186699\n",
      "Loss:  0.04575430229306221\n",
      "38 **********\n",
      "Epoch:  3021.24480509758  fold:  2  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.40944886207580566\n",
      "Eval Loss:  0.1682344228029251\n",
      "Eval Loss:  1.0813835859298706\n",
      "[[1172  258]\n",
      " [ 548 1116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74      1430\n",
      "           1       0.81      0.67      0.73      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.75      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7394957983193278\n",
      "pre:  0.8122270742358079\n",
      "rec:  0.6706730769230769\n",
      "ma F1:  0.7394104308390022\n",
      "mi F1:  0.7394957983193278\n",
      "we F1:  0.739053716724785\n",
      "Eval Loss:  0.15730904042720795\n",
      "Eval Loss:  0.16283100843429565\n",
      "Eval Loss:  0.19934214651584625\n",
      "Eval Loss:  0.16399995982646942\n",
      "Eval Loss:  0.16397421061992645\n",
      "Eval Loss:  0.17627693712711334\n",
      "Eval Loss:  0.1830073893070221\n",
      "Eval Loss:  0.18957528471946716\n",
      "Eval Loss:  0.14302200078964233\n",
      "Eval Loss:  0.15402919054031372\n",
      "Eval Loss:  0.17001190781593323\n",
      "Eval Loss:  0.09143564105033875\n",
      "Eval Loss:  0.19206418097019196\n",
      "Eval Loss:  0.19675885140895844\n",
      "Eval Loss:  0.16640441119670868\n",
      "Eval Loss:  0.1602882742881775\n",
      "Eval Loss:  0.09005367755889893\n",
      "Eval Loss:  0.14754948019981384\n",
      "Eval Loss:  0.16506043076515198\n",
      "Eval Loss:  0.15948238968849182\n",
      "Eval Loss:  0.1878405660390854\n",
      "Eval Loss:  0.16625432670116425\n",
      "Eval Loss:  0.2460138350725174\n",
      "Eval Loss:  0.25526872277259827\n",
      "Eval Loss:  0.1833643615245819\n",
      "Eval Loss:  0.12578867375850677\n",
      "Eval Loss:  0.20829711854457855\n",
      "Eval Loss:  0.15804673731327057\n",
      "Eval Loss:  0.1445256471633911\n",
      "[[17818   916]\n",
      " [ 1132  9931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18734\n",
      "           1       0.92      0.90      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.92      0.93     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9312682484813908\n",
      "pre:  0.9155526873789988\n",
      "rec:  0.897676941155202\n",
      "ma F1:  0.9260900139045727\n",
      "mi F1:  0.9312682484813908\n",
      "we F1:  0.9311264330042013\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0496598444879055\n",
      "Loss:  0.05013073980808258\n",
      "Loss:  0.028210116550326347\n",
      "39 **********\n",
      "Epoch:  3126.4415304660797  fold:  2  kers:  128\n",
      "epoch:  40\n",
      "29797 466\n",
      "Loss:  0.04694115370512009\n",
      "Loss:  0.0440734401345253\n",
      "Loss:  0.0626600831747055\n",
      "40 **********\n",
      "Epoch:  3191.120591878891  fold:  2  kers:  128\n",
      "epoch:  41\n",
      "29797 466\n",
      "Loss:  0.0723579078912735\n",
      "Loss:  0.06168803945183754\n",
      "Loss:  0.04883147031068802\n",
      "41 **********\n",
      "Epoch:  3255.8515145778656  fold:  2  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.38739749789237976\n",
      "Eval Loss:  0.1352769285440445\n",
      "Eval Loss:  1.0480481386184692\n",
      "[[1213  217]\n",
      " [ 576 1088]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.75      1430\n",
      "           1       0.83      0.65      0.73      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.76      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7436974789915967\n",
      "pre:  0.8337164750957854\n",
      "rec:  0.6538461538461539\n",
      "ma F1:  0.7432784522597649\n",
      "mi F1:  0.7436974789915967\n",
      "we F1:  0.7424940342177759\n",
      "Eval Loss:  0.17050433158874512\n",
      "Eval Loss:  0.16079261898994446\n",
      "Eval Loss:  0.18732620775699615\n",
      "Eval Loss:  0.13057279586791992\n",
      "Eval Loss:  0.15722286701202393\n",
      "Eval Loss:  0.16649691760540009\n",
      "Eval Loss:  0.15259790420532227\n",
      "Eval Loss:  0.16639964282512665\n",
      "Eval Loss:  0.10730690509080887\n",
      "Eval Loss:  0.16330985724925995\n",
      "Eval Loss:  0.17493538558483124\n",
      "Eval Loss:  0.10398530215024948\n",
      "Eval Loss:  0.17901583015918732\n",
      "Eval Loss:  0.16489839553833008\n",
      "Eval Loss:  0.15214380621910095\n",
      "Eval Loss:  0.13470140099525452\n",
      "Eval Loss:  0.09009521454572678\n",
      "Eval Loss:  0.15642407536506653\n",
      "Eval Loss:  0.1649591028690338\n",
      "Eval Loss:  0.12459985166788101\n",
      "Eval Loss:  0.15045787394046783\n",
      "Eval Loss:  0.15173612534999847\n",
      "Eval Loss:  0.22674015164375305\n",
      "Eval Loss:  0.21802103519439697\n",
      "Eval Loss:  0.18713350594043732\n",
      "Eval Loss:  0.11268720030784607\n",
      "Eval Loss:  0.18054819107055664\n",
      "Eval Loss:  0.16395625472068787\n",
      "Eval Loss:  0.13996769487857819\n",
      "[[17877   857]\n",
      " [ 1057 10006]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18734\n",
      "           1       0.92      0.90      0.91     11063\n",
      "\n",
      "    accuracy                           0.94     29797\n",
      "   macro avg       0.93      0.93      0.93     29797\n",
      "weighted avg       0.94      0.94      0.94     29797\n",
      "\n",
      "acc:  0.935765345504581\n",
      "pre:  0.9211083494430636\n",
      "rec:  0.9044562957606436\n",
      "ma F1:  0.9309470076837851\n",
      "mi F1:  0.935765345504581\n",
      "we F1:  0.9356429128322193\n",
      "29797 466\n",
      "Loss:  0.043928977102041245\n",
      "Loss:  0.03133248910307884\n",
      "Loss:  0.04608125239610672\n",
      "42 **********\n",
      "Epoch:  3360.9704484939575  fold:  2  kers:  128\n",
      "epoch:  43\n",
      "29797 466\n",
      "Loss:  0.06262274086475372\n",
      "Loss:  0.0333070233464241\n",
      "Loss:  0.06544990092515945\n",
      "43 **********\n",
      "Epoch:  3425.7701869010925  fold:  2  kers:  128\n",
      "epoch:  44\n",
      "29797 466\n",
      "Loss:  0.058116547763347626\n",
      "Loss:  0.03462284058332443\n",
      "Loss:  0.03506791591644287\n",
      "44 **********\n",
      "Epoch:  3490.5190613269806  fold:  2  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.6559589505195618\n",
      "Eval Loss:  0.17117591202259064\n",
      "Eval Loss:  0.6012510061264038\n",
      "[[1056  374]\n",
      " [ 425 1239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73      1430\n",
      "           1       0.77      0.74      0.76      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.74      0.74      0.74      3094\n",
      "weighted avg       0.74      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7417582417582418\n",
      "pre:  0.7681339119652821\n",
      "rec:  0.7445913461538461\n",
      "ma F1:  0.7408516536823747\n",
      "mi F1:  0.7417582417582419\n",
      "we F1:  0.7420108974515162\n",
      "Eval Loss:  0.18695540726184845\n",
      "Eval Loss:  0.17712783813476562\n",
      "Eval Loss:  0.22613942623138428\n",
      "Eval Loss:  0.19988547265529633\n",
      "Eval Loss:  0.16119126975536346\n",
      "Eval Loss:  0.17487919330596924\n",
      "Eval Loss:  0.2117784023284912\n",
      "Eval Loss:  0.2199726700782776\n",
      "Eval Loss:  0.13674861192703247\n",
      "Eval Loss:  0.18660883605480194\n",
      "Eval Loss:  0.20006883144378662\n",
      "Eval Loss:  0.08431456238031387\n",
      "Eval Loss:  0.16974981129169464\n",
      "Eval Loss:  0.21171119809150696\n",
      "Eval Loss:  0.2186555117368698\n",
      "Eval Loss:  0.1719934046268463\n",
      "Eval Loss:  0.11690080910921097\n",
      "Eval Loss:  0.13441480696201324\n",
      "Eval Loss:  0.19417433440685272\n",
      "Eval Loss:  0.1489199846982956\n",
      "Eval Loss:  0.22315941751003265\n",
      "Eval Loss:  0.19561661779880524\n",
      "Eval Loss:  0.2787541151046753\n",
      "Eval Loss:  0.30859729647636414\n",
      "Eval Loss:  0.2181086242198944\n",
      "Eval Loss:  0.17480823397636414\n",
      "Eval Loss:  0.22581025958061218\n",
      "Eval Loss:  0.1731404960155487\n",
      "Eval Loss:  0.1460520625114441\n",
      "[[17716  1018]\n",
      " [ 1283  9780]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18734\n",
      "           1       0.91      0.88      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.91      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9227774608182032\n",
      "pre:  0.9057232820892758\n",
      "rec:  0.8840278405495797\n",
      "ma F1:  0.9168814803497629\n",
      "mi F1:  0.9227774608182032\n",
      "we F1:  0.9225805814300811\n",
      "29797 466\n",
      "Loss:  0.05240350216627121\n",
      "Loss:  0.0638907253742218\n",
      "Loss:  0.08632795512676239\n",
      "45 **********\n",
      "Epoch:  3595.9830718040466  fold:  2  kers:  128\n",
      "epoch:  46\n",
      "29797 466\n",
      "Loss:  0.03213334456086159\n",
      "Loss:  0.061970923095941544\n",
      "Loss:  0.04110369458794594\n",
      "46 **********\n",
      "Epoch:  3660.6910560131073  fold:  2  kers:  128\n",
      "epoch:  47\n",
      "29797 466\n",
      "Loss:  0.07198543101549149\n",
      "Loss:  0.03396175801753998\n",
      "Loss:  0.06195875257253647\n",
      "47 **********\n",
      "Epoch:  3727.474490404129  fold:  2  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.4470618963241577\n",
      "Eval Loss:  0.0994260162115097\n",
      "Eval Loss:  1.111250877380371\n",
      "[[1242  188]\n",
      " [ 626 1038]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.75      1430\n",
      "           1       0.85      0.62      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.76      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.73      3094\n",
      "\n",
      "acc:  0.7369101486748546\n",
      "pre:  0.8466557911908646\n",
      "rec:  0.6237980769230769\n",
      "ma F1:  0.7357614240359576\n",
      "mi F1:  0.7369101486748545\n",
      "we F1:  0.7344437693031052\n",
      "Eval Loss:  0.16728609800338745\n",
      "Eval Loss:  0.1887475997209549\n",
      "Eval Loss:  0.20353597402572632\n",
      "Eval Loss:  0.18262404203414917\n",
      "Eval Loss:  0.13530699908733368\n",
      "Eval Loss:  0.14840315282344818\n",
      "Eval Loss:  0.1993943154811859\n",
      "Eval Loss:  0.18278013169765472\n",
      "Eval Loss:  0.12218903750181198\n",
      "Eval Loss:  0.16708660125732422\n",
      "Eval Loss:  0.18824060261249542\n",
      "Eval Loss:  0.10843385010957718\n",
      "Eval Loss:  0.20307733118534088\n",
      "Eval Loss:  0.2465004175901413\n",
      "Eval Loss:  0.18192781507968903\n",
      "Eval Loss:  0.1662394106388092\n",
      "Eval Loss:  0.10368353128433228\n",
      "Eval Loss:  0.13603566586971283\n",
      "Eval Loss:  0.1490762084722519\n",
      "Eval Loss:  0.1163414716720581\n",
      "Eval Loss:  0.1921253651380539\n",
      "Eval Loss:  0.14158225059509277\n",
      "Eval Loss:  0.2590138614177704\n",
      "Eval Loss:  0.310361385345459\n",
      "Eval Loss:  0.2112823724746704\n",
      "Eval Loss:  0.10152137279510498\n",
      "Eval Loss:  0.21401168406009674\n",
      "Eval Loss:  0.18914708495140076\n",
      "Eval Loss:  0.13284902274608612\n",
      "[[18131   603]\n",
      " [ 1482  9581]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     18734\n",
      "           1       0.94      0.87      0.90     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.92      0.92     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9300265127361815\n",
      "pre:  0.9407894736842105\n",
      "rec:  0.8660399529964747\n",
      "ma F1:  0.9237482897528623\n",
      "mi F1:  0.9300265127361815\n",
      "we F1:  0.9293810673557912\n",
      "29797 466\n",
      "Loss:  0.04466807842254639\n",
      "Loss:  0.055607870221138\n",
      "Loss:  0.04269722104072571\n",
      "48 **********\n",
      "Epoch:  3832.891626358032  fold:  2  kers:  128\n",
      "epoch:  49\n",
      "29797 466\n",
      "Loss:  0.08090710639953613\n",
      "Loss:  0.03406105190515518\n",
      "Loss:  0.05619635060429573\n",
      "49 **********\n",
      "Epoch:  3897.589637517929  fold:  2  kers:  128\n",
      "epoch:  50\n",
      "29797 466\n",
      "Loss:  0.05425919592380524\n",
      "Loss:  0.04546068608760834\n",
      "Loss:  0.03725987672805786\n",
      "50 **********\n",
      "Epoch:  3962.324548959732  fold:  2  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.5561078786849976\n",
      "Eval Loss:  0.0906505361199379\n",
      "Eval Loss:  0.9046318531036377\n",
      "[[1174  256]\n",
      " [ 482 1182]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      1430\n",
      "           1       0.82      0.71      0.76      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.77      0.76      3094\n",
      "weighted avg       0.77      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7614738202973497\n",
      "pre:  0.8219749652294854\n",
      "rec:  0.7103365384615384\n",
      "ma F1:  0.7614722255998576\n",
      "mi F1:  0.7614738202973498\n",
      "we F1:  0.7615188705015018\n",
      "update!  Acc:  0.7614738202973497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17939876019954681\n",
      "Eval Loss:  0.152908593416214\n",
      "Eval Loss:  0.16866910457611084\n",
      "Eval Loss:  0.16142837703227997\n",
      "Eval Loss:  0.13451075553894043\n",
      "Eval Loss:  0.18644516170024872\n",
      "Eval Loss:  0.1980983167886734\n",
      "Eval Loss:  0.20779985189437866\n",
      "Eval Loss:  0.14172735810279846\n",
      "Eval Loss:  0.17107337713241577\n",
      "Eval Loss:  0.19355621933937073\n",
      "Eval Loss:  0.09062858670949936\n",
      "Eval Loss:  0.16794301569461823\n",
      "Eval Loss:  0.20172464847564697\n",
      "Eval Loss:  0.17007586359977722\n",
      "Eval Loss:  0.13300374150276184\n",
      "Eval Loss:  0.08224262297153473\n",
      "Eval Loss:  0.16516298055648804\n",
      "Eval Loss:  0.18332761526107788\n",
      "Eval Loss:  0.1578330546617508\n",
      "Eval Loss:  0.1669163554906845\n",
      "Eval Loss:  0.1417340189218521\n",
      "Eval Loss:  0.21069374680519104\n",
      "Eval Loss:  0.2690149247646332\n",
      "Eval Loss:  0.20154781639575958\n",
      "Eval Loss:  0.12260468304157257\n",
      "Eval Loss:  0.21201518177986145\n",
      "Eval Loss:  0.17356593906879425\n",
      "Eval Loss:  0.12686359882354736\n",
      "[[17859   875]\n",
      " [ 1106  9957]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18734\n",
      "           1       0.92      0.90      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.93      0.93     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9335167969929858\n",
      "pre:  0.9192208271787297\n",
      "rec:  0.9000271174184218\n",
      "ma F1:  0.9284874545716659\n",
      "mi F1:  0.9335167969929858\n",
      "we F1:  0.933369773695172\n",
      "29797 466\n",
      "Loss:  0.052860524505376816\n",
      "Loss:  0.05144708603620529\n",
      "Loss:  0.04562520235776901\n",
      "51 **********\n",
      "Epoch:  4067.464426279068  fold:  2  kers:  128\n",
      "epoch:  52\n",
      "29797 466\n",
      "Loss:  0.025534864515066147\n",
      "Loss:  0.038584474474191666\n",
      "Loss:  0.0764734074473381\n",
      "52 **********\n",
      "Epoch:  4132.124538660049  fold:  2  kers:  128\n",
      "epoch:  53\n",
      "29797 466\n",
      "Loss:  0.025643490254878998\n",
      "Loss:  0.019673723727464676\n",
      "Loss:  0.029578877612948418\n",
      "53 **********\n",
      "Epoch:  4196.83052778244  fold:  2  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.6313388347625732\n",
      "Eval Loss:  0.12321999669075012\n",
      "Eval Loss:  1.1168766021728516\n",
      "[[1133  297]\n",
      " [ 475 1189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.75      1430\n",
      "           1       0.80      0.71      0.75      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.75      0.75      0.75      3094\n",
      "weighted avg       0.76      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7504848093083387\n",
      "pre:  0.8001345895020189\n",
      "rec:  0.7145432692307693\n",
      "ma F1:  0.7504030429376052\n",
      "mi F1:  0.7504848093083387\n",
      "we F1:  0.7507447095581704\n",
      "Eval Loss:  0.16868211328983307\n",
      "Eval Loss:  0.14618900418281555\n",
      "Eval Loss:  0.15901239216327667\n",
      "Eval Loss:  0.12306497991085052\n",
      "Eval Loss:  0.1486058235168457\n",
      "Eval Loss:  0.15938271582126617\n",
      "Eval Loss:  0.15268325805664062\n",
      "Eval Loss:  0.17247271537780762\n",
      "Eval Loss:  0.11823971569538116\n",
      "Eval Loss:  0.16454586386680603\n",
      "Eval Loss:  0.17063435912132263\n",
      "Eval Loss:  0.07532448321580887\n",
      "Eval Loss:  0.15397369861602783\n",
      "Eval Loss:  0.1611490249633789\n",
      "Eval Loss:  0.16718539595603943\n",
      "Eval Loss:  0.12409701943397522\n",
      "Eval Loss:  0.061281390488147736\n",
      "Eval Loss:  0.16291449964046478\n",
      "Eval Loss:  0.19174303114414215\n",
      "Eval Loss:  0.13740214705467224\n",
      "Eval Loss:  0.16251590847969055\n",
      "Eval Loss:  0.14979571104049683\n",
      "Eval Loss:  0.23216111958026886\n",
      "Eval Loss:  0.21519947052001953\n",
      "Eval Loss:  0.1823200285434723\n",
      "Eval Loss:  0.12435183674097061\n",
      "Eval Loss:  0.18853425979614258\n",
      "Eval Loss:  0.13524462282657623\n",
      "Eval Loss:  0.12140990048646927\n",
      "[[17720  1014]\n",
      " [  815 10248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95     18734\n",
      "           1       0.91      0.93      0.92     11063\n",
      "\n",
      "    accuracy                           0.94     29797\n",
      "   macro avg       0.93      0.94      0.93     29797\n",
      "weighted avg       0.94      0.94      0.94     29797\n",
      "\n",
      "acc:  0.9386179816760076\n",
      "pre:  0.9099627064464572\n",
      "rec:  0.926331013287535\n",
      "ma F1:  0.934499134451724\n",
      "mi F1:  0.9386179816760076\n",
      "we F1:  0.938727677955134\n",
      "29797 466\n",
      "Loss:  0.029141142964363098\n",
      "Loss:  0.041862498968839645\n",
      "Loss:  0.07332176715135574\n",
      "54 **********\n",
      "Epoch:  4301.861696004868  fold:  2  kers:  128\n",
      "epoch:  55\n",
      "29797 466\n",
      "Loss:  0.04272964224219322\n",
      "Loss:  0.058590590953826904\n",
      "Loss:  0.0428665466606617\n",
      "55 **********\n",
      "Epoch:  4366.5666880607605  fold:  2  kers:  128\n",
      "epoch:  56\n",
      "29797 466\n",
      "Loss:  0.022934526205062866\n",
      "Loss:  0.062144502997398376\n",
      "Loss:  0.027371037751436234\n",
      "56 **********\n",
      "Epoch:  4431.29362154007  fold:  2  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.7219421863555908\n",
      "Eval Loss:  0.2701142430305481\n",
      "Eval Loss:  1.1052693128585815\n",
      "[[ 959  471]\n",
      " [ 412 1252]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68      1430\n",
      "           1       0.73      0.75      0.74      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.71      0.71      0.71      3094\n",
      "weighted avg       0.71      0.71      0.71      3094\n",
      "\n",
      "acc:  0.7146089204912734\n",
      "pre:  0.726639582124202\n",
      "rec:  0.7524038461538461\n",
      "ma F1:  0.7120263788703411\n",
      "mi F1:  0.7146089204912734\n",
      "we F1:  0.7140888865129971\n",
      "Eval Loss:  0.18115419149398804\n",
      "Eval Loss:  0.172720804810524\n",
      "Eval Loss:  0.18081486225128174\n",
      "Eval Loss:  0.14839844405651093\n",
      "Eval Loss:  0.19844397902488708\n",
      "Eval Loss:  0.19258587062358856\n",
      "Eval Loss:  0.1992107331752777\n",
      "Eval Loss:  0.23726050555706024\n",
      "Eval Loss:  0.16780492663383484\n",
      "Eval Loss:  0.19194895029067993\n",
      "Eval Loss:  0.1918550431728363\n",
      "Eval Loss:  0.09955598413944244\n",
      "Eval Loss:  0.18718373775482178\n",
      "Eval Loss:  0.17603877186775208\n",
      "Eval Loss:  0.20330017805099487\n",
      "Eval Loss:  0.13888368010520935\n",
      "Eval Loss:  0.09933096170425415\n",
      "Eval Loss:  0.1714322566986084\n",
      "Eval Loss:  0.21805603802204132\n",
      "Eval Loss:  0.1914503276348114\n",
      "Eval Loss:  0.15885888040065765\n",
      "Eval Loss:  0.18948082625865936\n",
      "Eval Loss:  0.22234296798706055\n",
      "Eval Loss:  0.246356800198555\n",
      "Eval Loss:  0.19906847178936005\n",
      "Eval Loss:  0.14342832565307617\n",
      "Eval Loss:  0.179955393075943\n",
      "Eval Loss:  0.15812958776950836\n",
      "Eval Loss:  0.15930511057376862\n",
      "[[17355  1379]\n",
      " [  760 10303]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94     18734\n",
      "           1       0.88      0.93      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.92      0.93      0.92     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9282142497566869\n",
      "pre:  0.8819551446670091\n",
      "rec:  0.9313025399981921\n",
      "ma F1:  0.9239548225249241\n",
      "mi F1:  0.9282142497566869\n",
      "we F1:  0.9285881274447841\n",
      "29797 466\n",
      "Loss:  0.035661742091178894\n",
      "Loss:  0.03048529475927353\n",
      "Loss:  0.0334383100271225\n",
      "57 **********\n",
      "Epoch:  4536.454442501068  fold:  2  kers:  128\n",
      "epoch:  58\n",
      "29797 466\n",
      "Loss:  0.04053947329521179\n",
      "Loss:  0.03825974464416504\n",
      "Loss:  0.032727599143981934\n",
      "58 **********\n",
      "Epoch:  4601.1684103012085  fold:  2  kers:  128\n",
      "epoch:  59\n",
      "29797 466\n",
      "Loss:  0.046409279108047485\n",
      "Loss:  0.03786642104387283\n",
      "Loss:  0.06919965893030167\n",
      "59 **********\n",
      "Epoch:  4665.880383968353  fold:  2  kers:  128\n",
      "Eval Loss:  0.6168825626373291\n",
      "Eval Loss:  0.2246619462966919\n",
      "Eval Loss:  0.7279446721076965\n",
      "[[1011  419]\n",
      " [ 364 1300]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72      1430\n",
      "           1       0.76      0.78      0.77      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.75      0.74      0.74      3094\n",
      "weighted avg       0.75      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7469295410471881\n",
      "pre:  0.7562536358347877\n",
      "rec:  0.78125\n",
      "ma F1:  0.7447021202268025\n",
      "mi F1:  0.7469295410471881\n",
      "we F1:  0.7465056374308517\n",
      "update!  Acc:  0.7614738202973497\n",
      "Epoch:  4669.700170755386  fold:  2  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.16647633910179138\n",
      "Loss:  0.15873803198337555\n",
      "Loss:  0.15639261901378632\n",
      "0 **********\n",
      "Epoch:  76.27505588531494  fold:  3  kers:  128\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.15222695469856262\n",
      "Loss:  0.1284547746181488\n",
      "Loss:  0.11758904904127121\n",
      "1 **********\n",
      "Epoch:  140.25897645950317  fold:  3  kers:  128\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.118489570915699\n",
      "Loss:  0.10294690728187561\n",
      "Loss:  0.09804585576057434\n",
      "2 **********\n",
      "Epoch:  204.247882604599  fold:  3  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  1.0545073747634888\n",
      "Eval Loss:  0.8866720199584961\n",
      "Eval Loss:  0.43332043290138245\n",
      "[[1389  147]\n",
      " [ 730 1165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      1536\n",
      "           1       0.89      0.61      0.73      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.77      0.76      0.74      3431\n",
      "weighted avg       0.78      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7443893908481493\n",
      "pre:  0.8879573170731707\n",
      "rec:  0.6147757255936676\n",
      "ma F1:  0.7432952113558022\n",
      "mi F1:  0.7443893908481491\n",
      "we F1:  0.7415415933301209\n",
      "update!  Acc:  0.7443893908481493\n",
      "Eval Loss:  0.42117318511009216\n",
      "Eval Loss:  0.657565176486969\n",
      "Eval Loss:  0.2866322100162506\n",
      "Eval Loss:  0.34860822558403015\n",
      "Eval Loss:  0.4419243633747101\n",
      "Eval Loss:  0.36546123027801514\n",
      "Eval Loss:  0.5327557325363159\n",
      "Eval Loss:  0.4185278117656708\n",
      "Eval Loss:  0.3661208748817444\n",
      "Eval Loss:  0.4367935359477997\n",
      "Eval Loss:  0.4224497675895691\n",
      "Eval Loss:  0.47976478934288025\n",
      "Eval Loss:  0.48685571551322937\n",
      "Eval Loss:  0.34331026673316956\n",
      "Eval Loss:  0.3591690957546234\n",
      "Eval Loss:  0.381195604801178\n",
      "Eval Loss:  0.3755389153957367\n",
      "Eval Loss:  0.39279505610466003\n",
      "Eval Loss:  0.3960980474948883\n",
      "Eval Loss:  0.43858107924461365\n",
      "Eval Loss:  0.36767256259918213\n",
      "Eval Loss:  0.4578941762447357\n",
      "Eval Loss:  0.4549940228462219\n",
      "Eval Loss:  0.31141889095306396\n",
      "Eval Loss:  0.3795645236968994\n",
      "Eval Loss:  0.3982624113559723\n",
      "Eval Loss:  0.4524630010128021\n",
      "Eval Loss:  0.4379291236400604\n",
      "[[17157  1471]\n",
      " [ 3406  7426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.88     18628\n",
      "           1       0.83      0.69      0.75     10832\n",
      "\n",
      "    accuracy                           0.83     29460\n",
      "   macro avg       0.83      0.80      0.81     29460\n",
      "weighted avg       0.83      0.83      0.83     29460\n",
      "\n",
      "acc:  0.8344534962661235\n",
      "pre:  0.8346633696751714\n",
      "rec:  0.6855612998522895\n",
      "ma F1:  0.8141793049540236\n",
      "mi F1:  0.8344534962661235\n",
      "we F1:  0.8304219928041039\n",
      "29460 461\n",
      "Loss:  0.10184039920568466\n",
      "Loss:  0.1145358681678772\n",
      "Loss:  0.12356667220592499\n",
      "3 **********\n",
      "Epoch:  309.09753608703613  fold:  3  kers:  128\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.08131865411996841\n",
      "Loss:  0.07787398248910904\n",
      "Loss:  0.09656523913145065\n",
      "4 **********\n",
      "Epoch:  373.0904321670532  fold:  3  kers:  128\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.08569057285785675\n",
      "Loss:  0.08230799436569214\n",
      "Loss:  0.10222737491130829\n",
      "5 **********\n",
      "Epoch:  437.0723569393158  fold:  3  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  1.207514762878418\n",
      "Eval Loss:  0.7527529001235962\n",
      "Eval Loss:  0.7393854856491089\n",
      "[[1454   82]\n",
      " [ 880 1015]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.95      0.75      1536\n",
      "           1       0.93      0.54      0.68      1895\n",
      "\n",
      "    accuracy                           0.72      3431\n",
      "   macro avg       0.77      0.74      0.71      3431\n",
      "weighted avg       0.79      0.72      0.71      3431\n",
      "\n",
      "acc:  0.7196152725153017\n",
      "pre:  0.9252506836827712\n",
      "rec:  0.5356200527704486\n",
      "ma F1:  0.714948562229684\n",
      "mi F1:  0.7196152725153017\n",
      "we F1:  0.7111322775086435\n",
      "Eval Loss:  0.4953431487083435\n",
      "Eval Loss:  0.8169772624969482\n",
      "Eval Loss:  0.2543260157108307\n",
      "Eval Loss:  0.4235406219959259\n",
      "Eval Loss:  0.4429531395435333\n",
      "Eval Loss:  0.4066869616508484\n",
      "Eval Loss:  0.6103891730308533\n",
      "Eval Loss:  0.48045775294303894\n",
      "Eval Loss:  0.41039082407951355\n",
      "Eval Loss:  0.5301392078399658\n",
      "Eval Loss:  0.4176793098449707\n",
      "Eval Loss:  0.5447787046432495\n",
      "Eval Loss:  0.5520873665809631\n",
      "Eval Loss:  0.35929185152053833\n",
      "Eval Loss:  0.451434850692749\n",
      "Eval Loss:  0.4230097234249115\n",
      "Eval Loss:  0.4034093916416168\n",
      "Eval Loss:  0.44632285833358765\n",
      "Eval Loss:  0.49655386805534363\n",
      "Eval Loss:  0.5691495537757874\n",
      "Eval Loss:  0.3996216356754303\n",
      "Eval Loss:  0.4923960566520691\n",
      "Eval Loss:  0.5972474813461304\n",
      "Eval Loss:  0.3432425260543823\n",
      "Eval Loss:  0.4403586685657501\n",
      "Eval Loss:  0.44794782996177673\n",
      "Eval Loss:  0.5634244084358215\n",
      "Eval Loss:  0.5223837494850159\n",
      "[[18204   424]\n",
      " [ 4854  5978]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87     18628\n",
      "           1       0.93      0.55      0.69     10832\n",
      "\n",
      "    accuracy                           0.82     29460\n",
      "   macro avg       0.86      0.76      0.78     29460\n",
      "weighted avg       0.84      0.82      0.81     29460\n",
      "\n",
      "acc:  0.8208418194161575\n",
      "pre:  0.9337706966572946\n",
      "rec:  0.5518833087149188\n",
      "ma F1:  0.7835658356878217\n",
      "mi F1:  0.8208418194161575\n",
      "we F1:  0.8073351444679709\n",
      "29460 461\n",
      "Loss:  0.10154503583908081\n",
      "Loss:  0.07140279561281204\n",
      "Loss:  0.08692380785942078\n",
      "6 **********\n",
      "Epoch:  541.646746635437  fold:  3  kers:  128\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.07735524326562881\n",
      "Loss:  0.07528433203697205\n",
      "Loss:  0.07920043915510178\n",
      "7 **********\n",
      "Epoch:  605.6236848831177  fold:  3  kers:  128\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.07074099779129028\n",
      "Loss:  0.0779753252863884\n",
      "Loss:  0.08043144643306732\n",
      "8 **********\n",
      "Epoch:  669.6624586582184  fold:  3  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.8043873310089111\n",
      "Eval Loss:  0.28931725025177\n",
      "Eval Loss:  0.7558131814002991\n",
      "[[1353  183]\n",
      " [ 639 1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77      1536\n",
      "           1       0.87      0.66      0.75      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.77      0.76      3431\n",
      "weighted avg       0.79      0.76      0.76      3431\n",
      "\n",
      "acc:  0.76041970271058\n",
      "pre:  0.8728283530229326\n",
      "rec:  0.6627968337730871\n",
      "ma F1:  0.7602280564295304\n",
      "mi F1:  0.76041970271058\n",
      "we F1:  0.7595187676161613\n",
      "update!  Acc:  0.76041970271058\n",
      "Eval Loss:  0.37563610076904297\n",
      "Eval Loss:  0.5540189146995544\n",
      "Eval Loss:  0.20825177431106567\n",
      "Eval Loss:  0.3156651258468628\n",
      "Eval Loss:  0.3702303469181061\n",
      "Eval Loss:  0.29064077138900757\n",
      "Eval Loss:  0.4702380895614624\n",
      "Eval Loss:  0.38004550337791443\n",
      "Eval Loss:  0.32181185483932495\n",
      "Eval Loss:  0.390341579914093\n",
      "Eval Loss:  0.36324506998062134\n",
      "Eval Loss:  0.4174845218658447\n",
      "Eval Loss:  0.48473018407821655\n",
      "Eval Loss:  0.25918853282928467\n",
      "Eval Loss:  0.3163513243198395\n",
      "Eval Loss:  0.3219633400440216\n",
      "Eval Loss:  0.31626319885253906\n",
      "Eval Loss:  0.3041527271270752\n",
      "Eval Loss:  0.3195641040802002\n",
      "Eval Loss:  0.40015968680381775\n",
      "Eval Loss:  0.30725470185279846\n",
      "Eval Loss:  0.40776526927948\n",
      "Eval Loss:  0.44992589950561523\n",
      "Eval Loss:  0.2648371756076813\n",
      "Eval Loss:  0.3468218445777893\n",
      "Eval Loss:  0.36663034558296204\n",
      "Eval Loss:  0.4563240706920624\n",
      "Eval Loss:  0.37032389640808105\n",
      "[[17921   707]\n",
      " [ 3391  7441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     18628\n",
      "           1       0.91      0.69      0.78     10832\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.88      0.82      0.84     29460\n",
      "weighted avg       0.87      0.86      0.86     29460\n",
      "\n",
      "acc:  0.8608961303462321\n",
      "pre:  0.9132302405498282\n",
      "rec:  0.6869460856720827\n",
      "ma F1:  0.8407423041833562\n",
      "mi F1:  0.8608961303462321\n",
      "we F1:  0.8557345970045185\n",
      "29460 461\n",
      "Loss:  0.07999417930841446\n",
      "Loss:  0.0750451609492302\n",
      "Loss:  0.06031830608844757\n",
      "9 **********\n",
      "Epoch:  774.1052002906799  fold:  3  kers:  128\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.06193767860531807\n",
      "Loss:  0.08816341310739517\n",
      "Loss:  0.08558117598295212\n",
      "10 **********\n",
      "Epoch:  838.1010875701904  fold:  3  kers:  128\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07038170844316483\n",
      "Loss:  0.08608280122280121\n",
      "Loss:  0.07747863978147507\n",
      "11 **********\n",
      "Epoch:  902.11891746521  fold:  3  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.8893061876296997\n",
      "Eval Loss:  0.25001025199890137\n",
      "Eval Loss:  0.7780781984329224\n",
      "[[1345  191]\n",
      " [ 651 1244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76      1536\n",
      "           1       0.87      0.66      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.77      0.75      3431\n",
      "weighted avg       0.78      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7545904983969688\n",
      "pre:  0.8668989547038327\n",
      "rec:  0.6564643799472295\n",
      "ma F1:  0.754377650583766\n",
      "mi F1:  0.7545904983969688\n",
      "we F1:  0.7536210925150555\n",
      "Eval Loss:  0.3976615369319916\n",
      "Eval Loss:  0.5148065090179443\n",
      "Eval Loss:  0.18371504545211792\n",
      "Eval Loss:  0.30520302057266235\n",
      "Eval Loss:  0.30620166659355164\n",
      "Eval Loss:  0.31975501775741577\n",
      "Eval Loss:  0.4241489768028259\n",
      "Eval Loss:  0.3475717008113861\n",
      "Eval Loss:  0.26456642150878906\n",
      "Eval Loss:  0.3938426971435547\n",
      "Eval Loss:  0.34816643595695496\n",
      "Eval Loss:  0.42089205980300903\n",
      "Eval Loss:  0.4658038318157196\n",
      "Eval Loss:  0.23931901156902313\n",
      "Eval Loss:  0.3208443820476532\n",
      "Eval Loss:  0.3194524645805359\n",
      "Eval Loss:  0.30335718393325806\n",
      "Eval Loss:  0.27974891662597656\n",
      "Eval Loss:  0.30886757373809814\n",
      "Eval Loss:  0.3960255980491638\n",
      "Eval Loss:  0.3079969584941864\n",
      "Eval Loss:  0.40378981828689575\n",
      "Eval Loss:  0.45051315426826477\n",
      "Eval Loss:  0.256965696811676\n",
      "Eval Loss:  0.3050120174884796\n",
      "Eval Loss:  0.3105756342411041\n",
      "Eval Loss:  0.4369420111179352\n",
      "Eval Loss:  0.361112117767334\n",
      "[[18029   599]\n",
      " [ 3279  7553]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90     18628\n",
      "           1       0.93      0.70      0.80     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.89      0.83      0.85     29460\n",
      "weighted avg       0.88      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8683638832315004\n",
      "pre:  0.9265210991167812\n",
      "rec:  0.6972858197932054\n",
      "ma F1:  0.8493086726372816\n",
      "mi F1:  0.8683638832315004\n",
      "we F1:  0.8634891252711621\n",
      "29460 461\n",
      "Loss:  0.06800667196512222\n",
      "Loss:  0.08139395713806152\n",
      "Loss:  0.06356029212474823\n",
      "12 **********\n",
      "Epoch:  1006.6294770240784  fold:  3  kers:  128\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.0813499167561531\n",
      "Loss:  0.06889643520116806\n",
      "Loss:  0.10002642124891281\n",
      "13 **********\n",
      "Epoch:  1070.6064157485962  fold:  3  kers:  128\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.08866400271654129\n",
      "Loss:  0.07933084666728973\n",
      "Loss:  0.06644295901060104\n",
      "14 **********\n",
      "Epoch:  1134.6232483386993  fold:  3  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.6591041088104248\n",
      "Eval Loss:  0.2270767092704773\n",
      "Eval Loss:  0.7164178490638733\n",
      "[[1308  228]\n",
      " [ 558 1337]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1536\n",
      "           1       0.85      0.71      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.78      0.77      3431\n",
      "weighted avg       0.79      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7709122704750802\n",
      "pre:  0.8543130990415335\n",
      "rec:  0.7055408970976254\n",
      "ma F1:  0.7708959027841493\n",
      "mi F1:  0.77091227047508\n",
      "we F1:  0.7710985235098092\n",
      "update!  Acc:  0.7709122704750802\n",
      "Eval Loss:  0.32309937477111816\n",
      "Eval Loss:  0.39131149649620056\n",
      "Eval Loss:  0.14588919281959534\n",
      "Eval Loss:  0.18958015739917755\n",
      "Eval Loss:  0.242673859000206\n",
      "Eval Loss:  0.22419720888137817\n",
      "Eval Loss:  0.322207510471344\n",
      "Eval Loss:  0.2560974955558777\n",
      "Eval Loss:  0.2388097047805786\n",
      "Eval Loss:  0.27767494320869446\n",
      "Eval Loss:  0.31017163395881653\n",
      "Eval Loss:  0.2828449606895447\n",
      "Eval Loss:  0.3708502948284149\n",
      "Eval Loss:  0.18188633024692535\n",
      "Eval Loss:  0.2675829231739044\n",
      "Eval Loss:  0.24017703533172607\n",
      "Eval Loss:  0.261078804731369\n",
      "Eval Loss:  0.20229285955429077\n",
      "Eval Loss:  0.23468200862407684\n",
      "Eval Loss:  0.2972552478313446\n",
      "Eval Loss:  0.20614886283874512\n",
      "Eval Loss:  0.32852092385292053\n",
      "Eval Loss:  0.3564002215862274\n",
      "Eval Loss:  0.18091683089733124\n",
      "Eval Loss:  0.2409350574016571\n",
      "Eval Loss:  0.2457653433084488\n",
      "Eval Loss:  0.3461807668209076\n",
      "Eval Loss:  0.30071038007736206\n",
      "[[17813   815]\n",
      " [ 2145  8687]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18628\n",
      "           1       0.91      0.80      0.85     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.8995247793618466\n",
      "pre:  0.9142285834561145\n",
      "rec:  0.8019756277695717\n",
      "ma F1:  0.8888596207599915\n",
      "mi F1:  0.8995247793618466\n",
      "we F1:  0.8979704663067877\n",
      "29460 461\n",
      "Loss:  0.09938626736402512\n",
      "Loss:  0.0431525856256485\n",
      "Loss:  0.08088824152946472\n",
      "15 **********\n",
      "Epoch:  1239.0719735622406  fold:  3  kers:  128\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.08036208897829056\n",
      "Loss:  0.08783365041017532\n",
      "Loss:  0.05217943340539932\n",
      "16 **********\n",
      "Epoch:  1303.070853471756  fold:  3  kers:  128\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.05125191807746887\n",
      "Loss:  0.05125762149691582\n",
      "Loss:  0.06514401733875275\n",
      "17 **********\n",
      "Epoch:  1367.1156108379364  fold:  3  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.6271536946296692\n",
      "Eval Loss:  0.21324685215950012\n",
      "Eval Loss:  0.8517976403236389\n",
      "[[1333  203]\n",
      " [ 670 1225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.75      1536\n",
      "           1       0.86      0.65      0.74      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.77      0.75      0.74      3431\n",
      "\n",
      "acc:  0.7455552317108715\n",
      "pre:  0.8578431372549019\n",
      "rec:  0.6464379947229552\n",
      "ma F1:  0.7453028661243185\n",
      "mi F1:  0.7455552317108716\n",
      "we F1:  0.7444639842208695\n",
      "Eval Loss:  0.358076274394989\n",
      "Eval Loss:  0.41017383337020874\n",
      "Eval Loss:  0.15186052024364471\n",
      "Eval Loss:  0.1986788809299469\n",
      "Eval Loss:  0.22727224230766296\n",
      "Eval Loss:  0.22794394195079803\n",
      "Eval Loss:  0.32651087641716003\n",
      "Eval Loss:  0.2571127414703369\n",
      "Eval Loss:  0.22571736574172974\n",
      "Eval Loss:  0.30602800846099854\n",
      "Eval Loss:  0.2832582890987396\n",
      "Eval Loss:  0.3326180577278137\n",
      "Eval Loss:  0.38021689653396606\n",
      "Eval Loss:  0.1881394237279892\n",
      "Eval Loss:  0.2785007953643799\n",
      "Eval Loss:  0.23580163717269897\n",
      "Eval Loss:  0.25233572721481323\n",
      "Eval Loss:  0.20870985090732574\n",
      "Eval Loss:  0.2509893774986267\n",
      "Eval Loss:  0.3332415521144867\n",
      "Eval Loss:  0.19034257531166077\n",
      "Eval Loss:  0.32829752564430237\n",
      "Eval Loss:  0.3547764718532562\n",
      "Eval Loss:  0.2046046108007431\n",
      "Eval Loss:  0.23456473648548126\n",
      "Eval Loss:  0.237074077129364\n",
      "Eval Loss:  0.34224745631217957\n",
      "Eval Loss:  0.2913551926612854\n",
      "[[18053   575]\n",
      " [ 2484  8348]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18628\n",
      "           1       0.94      0.77      0.85     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.91      0.87      0.88     29460\n",
      "weighted avg       0.90      0.90      0.89     29460\n",
      "\n",
      "acc:  0.8961642905634759\n",
      "pre:  0.9355597893085286\n",
      "rec:  0.7706794682422452\n",
      "ma F1:  0.8835238372475696\n",
      "mi F1:  0.8961642905634759\n",
      "we F1:  0.8936778788808315\n",
      "29460 461\n",
      "Loss:  0.06661228090524673\n",
      "Loss:  0.046137385070323944\n",
      "Loss:  0.06510671973228455\n",
      "18 **********\n",
      "Epoch:  1471.6540958881378  fold:  3  kers:  128\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.03426256403326988\n",
      "Loss:  0.07055331766605377\n",
      "Loss:  0.06864051520824432\n",
      "19 **********\n",
      "Epoch:  1535.6390130519867  fold:  3  kers:  128\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.06348150223493576\n",
      "Loss:  0.05903482064604759\n",
      "Loss:  0.06897284835577011\n",
      "20 **********\n",
      "Epoch:  1599.6588373184204  fold:  3  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.6348771452903748\n",
      "Eval Loss:  0.20942836999893188\n",
      "Eval Loss:  0.7605457901954651\n",
      "[[1286  250]\n",
      " [ 652 1243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.84      0.74      1536\n",
      "           1       0.83      0.66      0.73      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.76      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7371028854561352\n",
      "pre:  0.8325519089082385\n",
      "rec:  0.6559366754617414\n",
      "ma F1:  0.7370615855071815\n",
      "mi F1:  0.7371028854561352\n",
      "we F1:  0.736716778956613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.31588512659072876\n",
      "Eval Loss:  0.3727566599845886\n",
      "Eval Loss:  0.15704292058944702\n",
      "Eval Loss:  0.16008146107196808\n",
      "Eval Loss:  0.24243488907814026\n",
      "Eval Loss:  0.214284285902977\n",
      "Eval Loss:  0.30432507395744324\n",
      "Eval Loss:  0.2247651219367981\n",
      "Eval Loss:  0.22895419597625732\n",
      "Eval Loss:  0.2535381615161896\n",
      "Eval Loss:  0.26722562313079834\n",
      "Eval Loss:  0.25623682141304016\n",
      "Eval Loss:  0.3538898825645447\n",
      "Eval Loss:  0.15961457788944244\n",
      "Eval Loss:  0.25905346870422363\n",
      "Eval Loss:  0.21259379386901855\n",
      "Eval Loss:  0.23319818079471588\n",
      "Eval Loss:  0.19114837050437927\n",
      "Eval Loss:  0.22138752043247223\n",
      "Eval Loss:  0.277571439743042\n",
      "Eval Loss:  0.17529436945915222\n",
      "Eval Loss:  0.33323124051094055\n",
      "Eval Loss:  0.3307264745235443\n",
      "Eval Loss:  0.17079690098762512\n",
      "Eval Loss:  0.22664611041545868\n",
      "Eval Loss:  0.22503440082073212\n",
      "Eval Loss:  0.3406117856502533\n",
      "Eval Loss:  0.20911654829978943\n",
      "[[17847   781]\n",
      " [ 1911  8921]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18628\n",
      "           1       0.92      0.82      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9086218601493551\n",
      "pre:  0.9195011337868481\n",
      "rec:  0.8235782865583456\n",
      "ma F1:  0.8993853127893822\n",
      "mi F1:  0.9086218601493551\n",
      "we F1:  0.9074525459529884\n",
      "29460 461\n",
      "Loss:  0.06725163757801056\n",
      "Loss:  0.08886808156967163\n",
      "Loss:  0.09612961858510971\n",
      "21 **********\n",
      "Epoch:  1704.1684000492096  fold:  3  kers:  128\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.039300739765167236\n",
      "Loss:  0.04606566205620766\n",
      "Loss:  0.08549802750349045\n",
      "22 **********\n",
      "Epoch:  1768.1702723503113  fold:  3  kers:  128\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.04672395810484886\n",
      "Loss:  0.06683981418609619\n",
      "Loss:  0.04771954566240311\n",
      "23 **********\n",
      "Epoch:  1832.2000708580017  fold:  3  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.5544595718383789\n",
      "Eval Loss:  0.16488681733608246\n",
      "Eval Loss:  0.7652266621589661\n",
      "[[1270  266]\n",
      " [ 632 1263]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.83      0.74      1536\n",
      "           1       0.83      0.67      0.74      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.76      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7382687263188574\n",
      "pre:  0.8260300850228908\n",
      "rec:  0.666490765171504\n",
      "ma F1:  0.738267636856899\n",
      "mi F1:  0.7382687263188574\n",
      "we F1:  0.7382117630221703\n",
      "Eval Loss:  0.28044643998146057\n",
      "Eval Loss:  0.29159659147262573\n",
      "Eval Loss:  0.14643576741218567\n",
      "Eval Loss:  0.15435908734798431\n",
      "Eval Loss:  0.20284207165241241\n",
      "Eval Loss:  0.18155871331691742\n",
      "Eval Loss:  0.24634778499603271\n",
      "Eval Loss:  0.23548024892807007\n",
      "Eval Loss:  0.1964207887649536\n",
      "Eval Loss:  0.20731177926063538\n",
      "Eval Loss:  0.262272447347641\n",
      "Eval Loss:  0.21401989459991455\n",
      "Eval Loss:  0.32297903299331665\n",
      "Eval Loss:  0.13892044126987457\n",
      "Eval Loss:  0.2384399175643921\n",
      "Eval Loss:  0.182035431265831\n",
      "Eval Loss:  0.2012386918067932\n",
      "Eval Loss:  0.18109460175037384\n",
      "Eval Loss:  0.204443097114563\n",
      "Eval Loss:  0.25716057419776917\n",
      "Eval Loss:  0.15185043215751648\n",
      "Eval Loss:  0.3139810562133789\n",
      "Eval Loss:  0.29595932364463806\n",
      "Eval Loss:  0.15831667184829712\n",
      "Eval Loss:  0.20959728956222534\n",
      "Eval Loss:  0.20263580977916718\n",
      "Eval Loss:  0.28998875617980957\n",
      "Eval Loss:  0.1800963580608368\n",
      "[[17714   914]\n",
      " [ 1511  9321]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18628\n",
      "           1       0.91      0.86      0.88     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9176849966055669\n",
      "pre:  0.9106985832926233\n",
      "rec:  0.8605059084194978\n",
      "ma F1:  0.9104137236707648\n",
      "mi F1:  0.9176849966055669\n",
      "we F1:  0.9171677858415876\n",
      "29460 461\n",
      "Loss:  0.07012535631656647\n",
      "Loss:  0.05963214486837387\n",
      "Loss:  0.04727768898010254\n",
      "24 **********\n",
      "Epoch:  1936.6318399906158  fold:  3  kers:  128\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.07209215313196182\n",
      "Loss:  0.04894028231501579\n",
      "Loss:  0.05739133432507515\n",
      "25 **********\n",
      "Epoch:  2000.631716966629  fold:  3  kers:  128\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.05755172297358513\n",
      "Loss:  0.04278647154569626\n",
      "Loss:  0.04756757244467735\n",
      "26 **********\n",
      "Epoch:  2064.665504217148  fold:  3  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.6594249606132507\n",
      "Eval Loss:  0.17253854870796204\n",
      "Eval Loss:  0.9596409797668457\n",
      "[[1292  244]\n",
      " [ 623 1272]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.75      1536\n",
      "           1       0.84      0.67      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.77      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7473039930049549\n",
      "pre:  0.8390501319261213\n",
      "rec:  0.6712401055408971\n",
      "ma F1:  0.7472954061981447\n",
      "mi F1:  0.7473039930049548\n",
      "we F1:  0.7471412730159048\n",
      "Eval Loss:  0.2765536308288574\n",
      "Eval Loss:  0.29300716519355774\n",
      "Eval Loss:  0.1464027315378189\n",
      "Eval Loss:  0.1546477973461151\n",
      "Eval Loss:  0.1989440619945526\n",
      "Eval Loss:  0.18262633681297302\n",
      "Eval Loss:  0.24235469102859497\n",
      "Eval Loss:  0.20297124981880188\n",
      "Eval Loss:  0.19718937575817108\n",
      "Eval Loss:  0.20047050714492798\n",
      "Eval Loss:  0.2531600296497345\n",
      "Eval Loss:  0.2328735738992691\n",
      "Eval Loss:  0.29797565937042236\n",
      "Eval Loss:  0.12556542456150055\n",
      "Eval Loss:  0.2293415069580078\n",
      "Eval Loss:  0.1777772158384323\n",
      "Eval Loss:  0.19178104400634766\n",
      "Eval Loss:  0.19328421354293823\n",
      "Eval Loss:  0.20954248309135437\n",
      "Eval Loss:  0.22527074813842773\n",
      "Eval Loss:  0.1498819887638092\n",
      "Eval Loss:  0.2960833013057709\n",
      "Eval Loss:  0.29238611459732056\n",
      "Eval Loss:  0.16339005529880524\n",
      "Eval Loss:  0.21030545234680176\n",
      "Eval Loss:  0.1840921938419342\n",
      "Eval Loss:  0.2757408916950226\n",
      "Eval Loss:  0.16862733662128448\n",
      "[[17812   816]\n",
      " [ 1534  9298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18628\n",
      "           1       0.92      0.86      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9202308214528174\n",
      "pre:  0.9193197547953332\n",
      "rec:  0.8583825701624815\n",
      "ma F1:  0.912961146945255\n",
      "mi F1:  0.9202308214528174\n",
      "we F1:  0.919617757523239\n",
      "29460 461\n",
      "Loss:  0.03420911729335785\n",
      "Loss:  0.06607723981142044\n",
      "Loss:  0.05911620333790779\n",
      "27 **********\n",
      "Epoch:  2169.269813299179  fold:  3  kers:  128\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.06420379132032394\n",
      "Loss:  0.03788191080093384\n",
      "Loss:  0.062204986810684204\n",
      "28 **********\n",
      "Epoch:  2233.28564786911  fold:  3  kers:  128\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.03815390542149544\n",
      "Loss:  0.02427705191075802\n",
      "Loss:  0.04903354495763779\n",
      "29 **********\n",
      "Epoch:  2297.323424100876  fold:  3  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.4202074110507965\n",
      "Eval Loss:  0.10726345330476761\n",
      "Eval Loss:  0.844765841960907\n",
      "[[1224  312]\n",
      " [ 545 1350]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74      1536\n",
      "           1       0.81      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7502185951617604\n",
      "pre:  0.8122743682310469\n",
      "rec:  0.712401055408971\n",
      "ma F1:  0.749881272230887\n",
      "mi F1:  0.7502185951617604\n",
      "we F1:  0.7508423748672647\n",
      "Eval Loss:  0.23889856040477753\n",
      "Eval Loss:  0.24388885498046875\n",
      "Eval Loss:  0.18220464885234833\n",
      "Eval Loss:  0.15700548887252808\n",
      "Eval Loss:  0.19622938334941864\n",
      "Eval Loss:  0.15304401516914368\n",
      "Eval Loss:  0.21583440899848938\n",
      "Eval Loss:  0.2126334011554718\n",
      "Eval Loss:  0.19767366349697113\n",
      "Eval Loss:  0.19446422159671783\n",
      "Eval Loss:  0.2682683765888214\n",
      "Eval Loss:  0.23484519124031067\n",
      "Eval Loss:  0.28592658042907715\n",
      "Eval Loss:  0.13169632852077484\n",
      "Eval Loss:  0.20444248616695404\n",
      "Eval Loss:  0.1719142496585846\n",
      "Eval Loss:  0.1880766600370407\n",
      "Eval Loss:  0.18722182512283325\n",
      "Eval Loss:  0.19892318546772003\n",
      "Eval Loss:  0.2036583125591278\n",
      "Eval Loss:  0.15356817841529846\n",
      "Eval Loss:  0.2632383704185486\n",
      "Eval Loss:  0.2921741008758545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1707150638103485\n",
      "Eval Loss:  0.19710992276668549\n",
      "Eval Loss:  0.1997634321451187\n",
      "Eval Loss:  0.2594965100288391\n",
      "Eval Loss:  0.14359930157661438\n",
      "[[17370  1258]\n",
      " [ 1076  9756]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18628\n",
      "           1       0.89      0.90      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9207739307535642\n",
      "pre:  0.8857817323406574\n",
      "rec:  0.9006646971935007\n",
      "ma F1:  0.9151030243528027\n",
      "mi F1:  0.9207739307535642\n",
      "we F1:  0.9209094843344596\n",
      "29460 461\n",
      "Loss:  0.05952402949333191\n",
      "Loss:  0.06893207877874374\n",
      "Loss:  0.03953733667731285\n",
      "30 **********\n",
      "Epoch:  2402.0005388259888  fold:  3  kers:  128\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.061997201293706894\n",
      "Loss:  0.04641573131084442\n",
      "Loss:  0.050312772393226624\n",
      "31 **********\n",
      "Epoch:  2466.0532755851746  fold:  3  kers:  128\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.046454597264528275\n",
      "Loss:  0.044602856040000916\n",
      "Loss:  0.03627553582191467\n",
      "32 **********\n",
      "Epoch:  2530.1459033489227  fold:  3  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.6772676706314087\n",
      "Eval Loss:  0.18977104127407074\n",
      "Eval Loss:  1.2140356302261353\n",
      "[[1306  230]\n",
      " [ 683 1212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.74      1536\n",
      "           1       0.84      0.64      0.73      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.75      0.74      0.73      3431\n",
      "weighted avg       0.76      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7338968230836491\n",
      "pre:  0.840499306518724\n",
      "rec:  0.6395778364116095\n",
      "ma F1:  0.7336969333732893\n",
      "mi F1:  0.7338968230836491\n",
      "we F1:  0.7329335247986177\n",
      "Eval Loss:  0.2864990234375\n",
      "Eval Loss:  0.26976633071899414\n",
      "Eval Loss:  0.14461924135684967\n",
      "Eval Loss:  0.1422121673822403\n",
      "Eval Loss:  0.19443483650684357\n",
      "Eval Loss:  0.16026031970977783\n",
      "Eval Loss:  0.25295597314834595\n",
      "Eval Loss:  0.19625842571258545\n",
      "Eval Loss:  0.16516199707984924\n",
      "Eval Loss:  0.21336865425109863\n",
      "Eval Loss:  0.2536381185054779\n",
      "Eval Loss:  0.2727991044521332\n",
      "Eval Loss:  0.29142293334007263\n",
      "Eval Loss:  0.15563148260116577\n",
      "Eval Loss:  0.23367451131343842\n",
      "Eval Loss:  0.17483216524124146\n",
      "Eval Loss:  0.18805916607379913\n",
      "Eval Loss:  0.17344792187213898\n",
      "Eval Loss:  0.20507609844207764\n",
      "Eval Loss:  0.2500217854976654\n",
      "Eval Loss:  0.14742355048656464\n",
      "Eval Loss:  0.28143006563186646\n",
      "Eval Loss:  0.2982484698295593\n",
      "Eval Loss:  0.1541437953710556\n",
      "Eval Loss:  0.21780121326446533\n",
      "Eval Loss:  0.18642422556877136\n",
      "Eval Loss:  0.25843650102615356\n",
      "Eval Loss:  0.16845400631427765\n",
      "[[18027   601]\n",
      " [ 1686  9146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     18628\n",
      "           1       0.94      0.84      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.93      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9223693143245079\n",
      "pre:  0.9383400020519134\n",
      "rec:  0.8443500738552437\n",
      "ma F1:  0.9146091760611237\n",
      "mi F1:  0.9223693143245079\n",
      "we F1:  0.9214212510415699\n",
      "29460 461\n",
      "Loss:  0.04908245429396629\n",
      "Loss:  0.05258050560951233\n",
      "Loss:  0.057101838290691376\n",
      "33 **********\n",
      "Epoch:  2634.861914396286  fold:  3  kers:  128\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.04230468347668648\n",
      "Loss:  0.059077564626932144\n",
      "Loss:  0.04120739921927452\n",
      "34 **********\n",
      "Epoch:  2698.855808019638  fold:  3  kers:  128\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.05525702238082886\n",
      "Loss:  0.03077808953821659\n",
      "Loss:  0.041675664484500885\n",
      "35 **********\n",
      "Epoch:  2762.9125344753265  fold:  3  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.6184284687042236\n",
      "Eval Loss:  0.1790781468153\n",
      "Eval Loss:  0.9996747970581055\n",
      "[[1312  224]\n",
      " [ 596 1299]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1536\n",
      "           1       0.85      0.69      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7610026231419411\n",
      "pre:  0.8529218647406435\n",
      "rec:  0.6854881266490765\n",
      "ma F1:  0.7609991919529661\n",
      "mi F1:  0.7610026231419411\n",
      "we F1:  0.7609044383497325\n",
      "Eval Loss:  0.2650289833545685\n",
      "Eval Loss:  0.24211075901985168\n",
      "Eval Loss:  0.1336558312177658\n",
      "Eval Loss:  0.14808644354343414\n",
      "Eval Loss:  0.2096659243106842\n",
      "Eval Loss:  0.15206378698349\n",
      "Eval Loss:  0.24024975299835205\n",
      "Eval Loss:  0.19663433730602264\n",
      "Eval Loss:  0.1478085070848465\n",
      "Eval Loss:  0.17259709537029266\n",
      "Eval Loss:  0.21799680590629578\n",
      "Eval Loss:  0.2306482493877411\n",
      "Eval Loss:  0.26947498321533203\n",
      "Eval Loss:  0.13088320195674896\n",
      "Eval Loss:  0.2120785415172577\n",
      "Eval Loss:  0.16288770735263824\n",
      "Eval Loss:  0.1676952987909317\n",
      "Eval Loss:  0.16086965799331665\n",
      "Eval Loss:  0.19317084550857544\n",
      "Eval Loss:  0.22169898450374603\n",
      "Eval Loss:  0.15816745162010193\n",
      "Eval Loss:  0.29832711815834045\n",
      "Eval Loss:  0.2548210620880127\n",
      "Eval Loss:  0.1379040777683258\n",
      "Eval Loss:  0.19445140659809113\n",
      "Eval Loss:  0.15731459856033325\n",
      "Eval Loss:  0.233646422624588\n",
      "Eval Loss:  0.17502546310424805\n",
      "[[17859   769]\n",
      " [ 1444  9388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     18628\n",
      "           1       0.92      0.87      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9248811948404616\n",
      "pre:  0.9242886679137541\n",
      "rec:  0.8666912850812407\n",
      "ma F1:  0.9181105194158712\n",
      "mi F1:  0.9248811948404616\n",
      "we F1:  0.924341682868841\n",
      "29460 461\n",
      "Loss:  0.07770975679159164\n",
      "Loss:  0.05164291709661484\n",
      "Loss:  0.10838508605957031\n",
      "36 **********\n",
      "Epoch:  2867.7093279361725  fold:  3  kers:  128\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.0405300036072731\n",
      "Loss:  0.08934058994054794\n",
      "Loss:  0.05919227376580238\n",
      "37 **********\n",
      "Epoch:  2931.717183828354  fold:  3  kers:  128\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.02573293447494507\n",
      "Loss:  0.035606637597084045\n",
      "Loss:  0.03604409098625183\n",
      "38 **********\n",
      "Epoch:  2995.7439897060394  fold:  3  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.47258660197257996\n",
      "Eval Loss:  0.10492932051420212\n",
      "Eval Loss:  1.1601744890213013\n",
      "[[1282  254]\n",
      " [ 571 1324]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.76      1536\n",
      "           1       0.84      0.70      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7595453220635383\n",
      "pre:  0.8390367553865653\n",
      "rec:  0.6986807387862797\n",
      "ma F1:  0.7595092844968439\n",
      "mi F1:  0.7595453220635383\n",
      "we F1:  0.7598173198883504\n",
      "Eval Loss:  0.24326381087303162\n",
      "Eval Loss:  0.21367813646793365\n",
      "Eval Loss:  0.1449211835861206\n",
      "Eval Loss:  0.1297955960035324\n",
      "Eval Loss:  0.1903993785381317\n",
      "Eval Loss:  0.1249038428068161\n",
      "Eval Loss:  0.1959204226732254\n",
      "Eval Loss:  0.18365947902202606\n",
      "Eval Loss:  0.14601489901542664\n",
      "Eval Loss:  0.17501689493656158\n",
      "Eval Loss:  0.22255989909172058\n",
      "Eval Loss:  0.217010036110878\n",
      "Eval Loss:  0.2546585500240326\n",
      "Eval Loss:  0.13302692770957947\n",
      "Eval Loss:  0.2053009271621704\n",
      "Eval Loss:  0.16171368956565857\n",
      "Eval Loss:  0.15305566787719727\n",
      "Eval Loss:  0.15569327771663666\n",
      "Eval Loss:  0.1806625872850418\n",
      "Eval Loss:  0.19268693029880524\n",
      "Eval Loss:  0.14359402656555176\n",
      "Eval Loss:  0.24965055286884308\n",
      "Eval Loss:  0.26233500242233276\n",
      "Eval Loss:  0.12884575128555298\n",
      "Eval Loss:  0.20664000511169434\n",
      "Eval Loss:  0.16751888394355774\n",
      "Eval Loss:  0.21014270186424255\n",
      "Eval Loss:  0.1476234346628189\n",
      "[[17798   830]\n",
      " [ 1233  9599]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     18628\n",
      "           1       0.92      0.89      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9299728445349627\n",
      "pre:  0.9204142295522102\n",
      "rec:  0.8861706056129985\n",
      "ma F1:  0.9240934069103466\n",
      "mi F1:  0.9299728445349627\n",
      "we F1:  0.9296838564434003\n",
      "29460 461\n",
      "Loss:  0.04799015447497368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07439526170492172\n",
      "Loss:  0.0637393519282341\n",
      "39 **********\n",
      "Epoch:  3100.35129070282  fold:  3  kers:  128\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.04630960524082184\n",
      "Loss:  0.05796019732952118\n",
      "Loss:  0.040139585733413696\n",
      "40 **********\n",
      "Epoch:  3164.3870718479156  fold:  3  kers:  128\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.0323021300137043\n",
      "Loss:  0.042166225612163544\n",
      "Loss:  0.10814909636974335\n",
      "41 **********\n",
      "Epoch:  3228.3939306735992  fold:  3  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.42403316497802734\n",
      "Eval Loss:  0.09647483378648758\n",
      "Eval Loss:  0.9599894285202026\n",
      "[[1246  290]\n",
      " [ 511 1384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1536\n",
      "           1       0.83      0.73      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7665403672398717\n",
      "pre:  0.8267622461170848\n",
      "rec:  0.7303430079155673\n",
      "ma F1:  0.7661620712895578\n",
      "mi F1:  0.7665403672398717\n",
      "we F1:  0.7671461890153741\n",
      "Eval Loss:  0.22061626613140106\n",
      "Eval Loss:  0.18807488679885864\n",
      "Eval Loss:  0.14422491192817688\n",
      "Eval Loss:  0.13193529844284058\n",
      "Eval Loss:  0.18683908879756927\n",
      "Eval Loss:  0.12353574484586716\n",
      "Eval Loss:  0.17608053982257843\n",
      "Eval Loss:  0.19495180249214172\n",
      "Eval Loss:  0.17283117771148682\n",
      "Eval Loss:  0.14790242910385132\n",
      "Eval Loss:  0.21697989106178284\n",
      "Eval Loss:  0.19860713183879852\n",
      "Eval Loss:  0.23813165724277496\n",
      "Eval Loss:  0.12403936684131622\n",
      "Eval Loss:  0.18435652554035187\n",
      "Eval Loss:  0.1522030532360077\n",
      "Eval Loss:  0.16498319804668427\n",
      "Eval Loss:  0.17009755969047546\n",
      "Eval Loss:  0.16823436319828033\n",
      "Eval Loss:  0.19379396736621857\n",
      "Eval Loss:  0.16120991110801697\n",
      "Eval Loss:  0.21771015226840973\n",
      "Eval Loss:  0.2545899450778961\n",
      "Eval Loss:  0.13347789645195007\n",
      "Eval Loss:  0.19593198597431183\n",
      "Eval Loss:  0.17344461381435394\n",
      "Eval Loss:  0.23313352465629578\n",
      "Eval Loss:  0.14915655553340912\n",
      "[[17691   937]\n",
      " [ 1027  9805]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     18628\n",
      "           1       0.91      0.91      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9333333333333333\n",
      "pre:  0.9127722956618879\n",
      "rec:  0.9051883308714919\n",
      "ma F1:  0.9281875971198923\n",
      "mi F1:  0.9333333333333333\n",
      "we F1:  0.9332746069499692\n",
      "29460 461\n",
      "Loss:  0.03892948478460312\n",
      "Loss:  0.05400318652391434\n",
      "Loss:  0.05586279183626175\n",
      "42 **********\n",
      "Epoch:  3332.9124693870544  fold:  3  kers:  128\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.04876123368740082\n",
      "Loss:  0.031547561287879944\n",
      "Loss:  0.08010099083185196\n",
      "43 **********\n",
      "Epoch:  3396.9233174324036  fold:  3  kers:  128\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.055483922362327576\n",
      "Loss:  0.0499887689948082\n",
      "Loss:  0.0643787756562233\n",
      "44 **********\n",
      "Epoch:  3460.9271836280823  fold:  3  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.36082687973976135\n",
      "Eval Loss:  0.09661705046892166\n",
      "Eval Loss:  1.315839171409607\n",
      "[[1231  305]\n",
      " [ 541 1354]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74      1536\n",
      "           1       0.82      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7534246575342466\n",
      "pre:  0.8161543098251959\n",
      "rec:  0.7145118733509235\n",
      "ma F1:  0.7531073525138832\n",
      "mi F1:  0.7534246575342466\n",
      "we F1:  0.7540334704188463\n",
      "Eval Loss:  0.23470868170261383\n",
      "Eval Loss:  0.19819273054599762\n",
      "Eval Loss:  0.1418413519859314\n",
      "Eval Loss:  0.1394132822751999\n",
      "Eval Loss:  0.20824111998081207\n",
      "Eval Loss:  0.1100122407078743\n",
      "Eval Loss:  0.18116356432437897\n",
      "Eval Loss:  0.20242752134799957\n",
      "Eval Loss:  0.18253087997436523\n",
      "Eval Loss:  0.11605186760425568\n",
      "Eval Loss:  0.20462602376937866\n",
      "Eval Loss:  0.1953912377357483\n",
      "Eval Loss:  0.2581919729709625\n",
      "Eval Loss:  0.11858522146940231\n",
      "Eval Loss:  0.2056867778301239\n",
      "Eval Loss:  0.14752598106861115\n",
      "Eval Loss:  0.1621575951576233\n",
      "Eval Loss:  0.17547613382339478\n",
      "Eval Loss:  0.16162091493606567\n",
      "Eval Loss:  0.1922883242368698\n",
      "Eval Loss:  0.15082162618637085\n",
      "Eval Loss:  0.22983796894550323\n",
      "Eval Loss:  0.2537807822227478\n",
      "Eval Loss:  0.15169647336006165\n",
      "Eval Loss:  0.20876820385456085\n",
      "Eval Loss:  0.18013383448123932\n",
      "Eval Loss:  0.2533337473869324\n",
      "Eval Loss:  0.13972434401512146\n",
      "[[17650   978]\n",
      " [ 1048  9784]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18628\n",
      "           1       0.91      0.90      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9312287847929396\n",
      "pre:  0.9091246980115221\n",
      "rec:  0.9032496307237814\n",
      "ma F1:  0.9259495614713863\n",
      "mi F1:  0.9312287847929396\n",
      "we F1:  0.9311818046718477\n",
      "29460 461\n",
      "Loss:  0.07723759114742279\n",
      "Loss:  0.04149439185857773\n",
      "Loss:  0.04150991514325142\n",
      "45 **********\n",
      "Epoch:  3565.5404694080353  fold:  3  kers:  128\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.04234906658530235\n",
      "Loss:  0.03888477757573128\n",
      "Loss:  0.06270138919353485\n",
      "46 **********\n",
      "Epoch:  3629.554309129715  fold:  3  kers:  128\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.04474828764796257\n",
      "Loss:  0.053519126027822495\n",
      "Loss:  0.042791370302438736\n",
      "47 **********\n",
      "Epoch:  3693.562165260315  fold:  3  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.4195593297481537\n",
      "Eval Loss:  0.09804444760084152\n",
      "Eval Loss:  0.8945586085319519\n",
      "[[1247  289]\n",
      " [ 514 1381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1536\n",
      "           1       0.83      0.73      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7659574468085106\n",
      "pre:  0.8269461077844311\n",
      "rec:  0.7287598944591029\n",
      "ma F1:  0.7655999057326542\n",
      "mi F1:  0.7659574468085105\n",
      "we F1:  0.7665577956299113\n",
      "Eval Loss:  0.20215272903442383\n",
      "Eval Loss:  0.2171316295862198\n",
      "Eval Loss:  0.14832182228565216\n",
      "Eval Loss:  0.15947242081165314\n",
      "Eval Loss:  0.1978563666343689\n",
      "Eval Loss:  0.12987133860588074\n",
      "Eval Loss:  0.17697802186012268\n",
      "Eval Loss:  0.19706836342811584\n",
      "Eval Loss:  0.15871727466583252\n",
      "Eval Loss:  0.13872972130775452\n",
      "Eval Loss:  0.23797857761383057\n",
      "Eval Loss:  0.18067790567874908\n",
      "Eval Loss:  0.24758952856063843\n",
      "Eval Loss:  0.10724225640296936\n",
      "Eval Loss:  0.19809775054454803\n",
      "Eval Loss:  0.14518676698207855\n",
      "Eval Loss:  0.165292888879776\n",
      "Eval Loss:  0.1582096964120865\n",
      "Eval Loss:  0.15890386700630188\n",
      "Eval Loss:  0.17441822588443756\n",
      "Eval Loss:  0.16156820952892303\n",
      "Eval Loss:  0.22772452235221863\n",
      "Eval Loss:  0.24776461720466614\n",
      "Eval Loss:  0.1306460201740265\n",
      "Eval Loss:  0.2141100913286209\n",
      "Eval Loss:  0.16837897896766663\n",
      "Eval Loss:  0.22529010474681854\n",
      "Eval Loss:  0.1476457566022873\n",
      "[[17535  1093]\n",
      " [  902  9930]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     18628\n",
      "           1       0.90      0.92      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9322810590631364\n",
      "pre:  0.9008436904653906\n",
      "rec:  0.9167282127031019\n",
      "ma F1:  0.9274460891155524\n",
      "mi F1:  0.9322810590631364\n",
      "we F1:  0.9324024896035689\n",
      "29460 461\n",
      "Loss:  0.057785578072071075\n",
      "Loss:  0.03772161900997162\n",
      "Loss:  0.05074973404407501\n",
      "48 **********\n",
      "Epoch:  3798.02285861969  fold:  3  kers:  128\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.05443025007843971\n",
      "Loss:  0.04989628121256828\n",
      "Loss:  0.049778226763010025\n",
      "49 **********\n",
      "Epoch:  3862.0307149887085  fold:  3  kers:  128\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.07025571167469025\n",
      "Loss:  0.03177232667803764\n",
      "Loss:  0.04321461543440819\n",
      "50 **********\n",
      "Epoch:  3926.0585174560547  fold:  3  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.5070651769638062\n",
      "Eval Loss:  0.1298980563879013\n",
      "Eval Loss:  1.139381766319275\n",
      "[[1268  268]\n",
      " [ 562 1333]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75      1536\n",
      "           1       0.83      0.70      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7580880209851355\n",
      "pre:  0.8326046221111805\n",
      "rec:  0.7034300791556728\n",
      "ma F1:  0.7580011652396899\n",
      "mi F1:  0.7580880209851355\n",
      "we F1:  0.758480876202997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1989198923110962\n",
      "Eval Loss:  0.2014099359512329\n",
      "Eval Loss:  0.13505370914936066\n",
      "Eval Loss:  0.1282510608434677\n",
      "Eval Loss:  0.19516058266162872\n",
      "Eval Loss:  0.14235343039035797\n",
      "Eval Loss:  0.1762414574623108\n",
      "Eval Loss:  0.17131371796131134\n",
      "Eval Loss:  0.14353400468826294\n",
      "Eval Loss:  0.1287127435207367\n",
      "Eval Loss:  0.21401454508304596\n",
      "Eval Loss:  0.20820070803165436\n",
      "Eval Loss:  0.2542383074760437\n",
      "Eval Loss:  0.10444682836532593\n",
      "Eval Loss:  0.19842290878295898\n",
      "Eval Loss:  0.1459379494190216\n",
      "Eval Loss:  0.1462569534778595\n",
      "Eval Loss:  0.1569242924451828\n",
      "Eval Loss:  0.16227570176124573\n",
      "Eval Loss:  0.18177567422389984\n",
      "Eval Loss:  0.1419270932674408\n",
      "Eval Loss:  0.22185978293418884\n",
      "Eval Loss:  0.24714693427085876\n",
      "Eval Loss:  0.13214072585105896\n",
      "Eval Loss:  0.21634632349014282\n",
      "Eval Loss:  0.1800806224346161\n",
      "Eval Loss:  0.2176179587841034\n",
      "Eval Loss:  0.14244712889194489\n",
      "[[17742   886]\n",
      " [ 1052  9780]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18628\n",
      "           1       0.92      0.90      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9342158859470469\n",
      "pre:  0.9169323082692669\n",
      "rec:  0.9028803545051699\n",
      "ma F1:  0.929032180404401\n",
      "mi F1:  0.9342158859470469\n",
      "we F1:  0.9341078106996116\n",
      "29460 461\n",
      "Loss:  0.04442610219120979\n",
      "Loss:  0.06453048437833786\n",
      "Loss:  0.04790468513965607\n",
      "51 **********\n",
      "Epoch:  4030.583039999008  fold:  3  kers:  128\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.030215326696634293\n",
      "Loss:  0.03510354831814766\n",
      "Loss:  0.06090209633111954\n",
      "52 **********\n",
      "Epoch:  4094.6028645038605  fold:  3  kers:  128\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.03386108577251434\n",
      "Loss:  0.03585438430309296\n",
      "Loss:  0.04383997246623039\n",
      "53 **********\n",
      "Epoch:  4158.686518192291  fold:  3  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.6609127521514893\n",
      "Eval Loss:  0.17530623078346252\n",
      "Eval Loss:  1.3125120401382446\n",
      "[[1327  209]\n",
      " [ 672 1223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      1536\n",
      "           1       0.85      0.65      0.74      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.76      0.75      0.74      3431\n",
      "weighted avg       0.77      0.74      0.74      3431\n",
      "\n",
      "acc:  0.743223549985427\n",
      "pre:  0.854050279329609\n",
      "rec:  0.6453825857519789\n",
      "ma F1:  0.7429874044985332\n",
      "mi F1:  0.743223549985427\n",
      "we F1:  0.7421722484428128\n",
      "Eval Loss:  0.24743413925170898\n",
      "Eval Loss:  0.22768227756023407\n",
      "Eval Loss:  0.12955781817436218\n",
      "Eval Loss:  0.1369156390428543\n",
      "Eval Loss:  0.2054162174463272\n",
      "Eval Loss:  0.15736493468284607\n",
      "Eval Loss:  0.2087840735912323\n",
      "Eval Loss:  0.1998010128736496\n",
      "Eval Loss:  0.14933200180530548\n",
      "Eval Loss:  0.15534695982933044\n",
      "Eval Loss:  0.17122139036655426\n",
      "Eval Loss:  0.1923867166042328\n",
      "Eval Loss:  0.2493325173854828\n",
      "Eval Loss:  0.14333580434322357\n",
      "Eval Loss:  0.23589414358139038\n",
      "Eval Loss:  0.141098290681839\n",
      "Eval Loss:  0.16396626830101013\n",
      "Eval Loss:  0.15227623283863068\n",
      "Eval Loss:  0.1931115686893463\n",
      "Eval Loss:  0.2189117819070816\n",
      "Eval Loss:  0.1366928517818451\n",
      "Eval Loss:  0.2885911166667938\n",
      "Eval Loss:  0.24645556509494781\n",
      "Eval Loss:  0.12910296022891998\n",
      "Eval Loss:  0.22382202744483948\n",
      "Eval Loss:  0.1530136615037918\n",
      "Eval Loss:  0.22271379828453064\n",
      "Eval Loss:  0.15806399285793304\n",
      "[[18107   521]\n",
      " [ 1536  9296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     18628\n",
      "           1       0.95      0.86      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9301765105227427\n",
      "pre:  0.9469287969848222\n",
      "rec:  0.8581979320531757\n",
      "ma F1:  0.9233171580944148\n",
      "mi F1:  0.9301765105227427\n",
      "we F1:  0.9293863342981652\n",
      "29460 461\n",
      "Loss:  0.03664153814315796\n",
      "Loss:  0.09206456691026688\n",
      "Loss:  0.06800654530525208\n",
      "54 **********\n",
      "Epoch:  4263.194085359573  fold:  3  kers:  128\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.06629994511604309\n",
      "Loss:  0.041004784405231476\n",
      "Loss:  0.02925547957420349\n",
      "55 **********\n",
      "Epoch:  4327.232858181  fold:  3  kers:  128\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.055862896144390106\n",
      "Loss:  0.06052388250827789\n",
      "Loss:  0.04420820251107216\n",
      "56 **********\n",
      "Epoch:  4391.277616262436  fold:  3  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.507463276386261\n",
      "Eval Loss:  0.06586548686027527\n",
      "Eval Loss:  0.9599556922912598\n",
      "[[1269  267]\n",
      " [ 542 1353]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.83      0.76      1536\n",
      "           1       0.84      0.71      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7642086855144273\n",
      "pre:  0.8351851851851851\n",
      "rec:  0.7139841688654354\n",
      "ma F1:  0.764067267305045\n",
      "mi F1:  0.7642086855144273\n",
      "we F1:  0.764671661795143\n",
      "Eval Loss:  0.1797160655260086\n",
      "Eval Loss:  0.1884123831987381\n",
      "Eval Loss:  0.14302310347557068\n",
      "Eval Loss:  0.12273360043764114\n",
      "Eval Loss:  0.17845715582370758\n",
      "Eval Loss:  0.11454332619905472\n",
      "Eval Loss:  0.1706468164920807\n",
      "Eval Loss:  0.16309259831905365\n",
      "Eval Loss:  0.16232958436012268\n",
      "Eval Loss:  0.1219019889831543\n",
      "Eval Loss:  0.19295141100883484\n",
      "Eval Loss:  0.19351081550121307\n",
      "Eval Loss:  0.22521643340587616\n",
      "Eval Loss:  0.12252770364284515\n",
      "Eval Loss:  0.18847309052944183\n",
      "Eval Loss:  0.14966893196105957\n",
      "Eval Loss:  0.16074703633785248\n",
      "Eval Loss:  0.1502838432788849\n",
      "Eval Loss:  0.16791655123233795\n",
      "Eval Loss:  0.17631128430366516\n",
      "Eval Loss:  0.1409098356962204\n",
      "Eval Loss:  0.23785386979579926\n",
      "Eval Loss:  0.237883523106575\n",
      "Eval Loss:  0.13268190622329712\n",
      "Eval Loss:  0.19369669258594513\n",
      "Eval Loss:  0.15054485201835632\n",
      "Eval Loss:  0.21907471120357513\n",
      "Eval Loss:  0.13641493022441864\n",
      "[[17720   908]\n",
      " [  933  9899]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     18628\n",
      "           1       0.92      0.91      0.91     10832\n",
      "\n",
      "    accuracy                           0.94     29460\n",
      "   macro avg       0.93      0.93      0.93     29460\n",
      "weighted avg       0.94      0.94      0.94     29460\n",
      "\n",
      "acc:  0.9375084860828242\n",
      "pre:  0.9159803830850375\n",
      "rec:  0.9138663220088626\n",
      "ma F1:  0.93277020437183\n",
      "mi F1:  0.9375084860828242\n",
      "we F1:  0.9374933400602214\n",
      "29460 461\n",
      "Loss:  0.0410616472363472\n",
      "Loss:  0.07194840908050537\n",
      "Loss:  0.02577020600438118\n",
      "57 **********\n",
      "Epoch:  4495.715370893478  fold:  3  kers:  128\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.05259726569056511\n",
      "Loss:  0.057631317526102066\n",
      "Loss:  0.027339980006217957\n",
      "58 **********\n",
      "Epoch:  4559.719237327576  fold:  3  kers:  128\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.04089616239070892\n",
      "Loss:  0.03281872719526291\n",
      "Loss:  0.03315392881631851\n",
      "59 **********\n",
      "Epoch:  4623.732080221176  fold:  3  kers:  128\n",
      "Eval Loss:  0.42670315504074097\n",
      "Eval Loss:  0.08407871425151825\n",
      "Eval Loss:  1.1066521406173706\n",
      "[[1240  296]\n",
      " [ 561 1334]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74      1536\n",
      "           1       0.82      0.70      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7502185951617604\n",
      "pre:  0.8184049079754602\n",
      "rec:  0.7039577836411609\n",
      "ma F1:  0.7500309659374689\n",
      "mi F1:  0.7502185951617604\n",
      "we F1:  0.7507475498898167\n",
      "update!  Acc:  0.7709122704750802\n",
      "Epoch:  4627.997675418854  fold:  3  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29520 3371\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29520 462\n",
      "Loss:  0.1823037564754486\n",
      "Loss:  0.16300451755523682\n",
      "Loss:  0.15801399946212769\n",
      "0 **********\n",
      "Epoch:  76.44360494613647  fold:  4  kers:  128\n",
      "epoch:  1\n",
      "29520 462\n",
      "Loss:  0.15696899592876434\n",
      "Loss:  0.1254129558801651\n",
      "Loss:  0.12189505994319916\n",
      "1 **********\n",
      "Epoch:  140.5641589164734  fold:  4  kers:  128\n",
      "epoch:  2\n",
      "29520 462\n",
      "Loss:  0.13570448756217957\n",
      "Loss:  0.09698525071144104\n",
      "Loss:  0.11663872003555298\n",
      "2 **********\n",
      "Epoch:  204.68471550941467  fold:  4  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.2219090312719345\n",
      "Eval Loss:  0.2532064616680145\n",
      "Eval Loss:  0.08780427277088165\n",
      "[[2953  184]\n",
      " [ 201   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.15      0.14      0.15       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.54      0.54      0.54      3371\n",
      "weighted avg       0.88      0.89      0.88      3371\n",
      "\n",
      "acc:  0.8857905665974488\n",
      "pre:  0.15207373271889402\n",
      "rec:  0.14102564102564102\n",
      "ma F1:  0.5425714629106234\n",
      "mi F1:  0.8857905665974488\n",
      "we F1:  0.8837923731855735\n",
      "update!  Acc:  0.8857905665974488\n",
      "Eval Loss:  0.5508711338043213\n",
      "Eval Loss:  0.5052378177642822\n",
      "Eval Loss:  0.37377026677131653\n",
      "Eval Loss:  0.4280300438404083\n",
      "Eval Loss:  0.4362151324748993\n",
      "Eval Loss:  0.3969270586967468\n",
      "Eval Loss:  0.505066990852356\n",
      "Eval Loss:  0.38896071910858154\n",
      "Eval Loss:  0.5447583794593811\n",
      "Eval Loss:  0.4905960261821747\n",
      "Eval Loss:  0.4864642918109894\n",
      "Eval Loss:  0.4214535355567932\n",
      "Eval Loss:  0.5440073013305664\n",
      "Eval Loss:  0.4619549512863159\n",
      "Eval Loss:  0.5110188126564026\n",
      "Eval Loss:  0.43985462188720703\n",
      "Eval Loss:  0.4394458830356598\n",
      "Eval Loss:  0.5147747993469238\n",
      "Eval Loss:  0.5373960733413696\n",
      "Eval Loss:  0.5554679036140442\n",
      "Eval Loss:  0.4114827811717987\n",
      "Eval Loss:  0.4712635278701782\n",
      "Eval Loss:  0.5861210227012634\n",
      "Eval Loss:  0.5541308522224426\n",
      "Eval Loss:  0.45418983697891235\n",
      "Eval Loss:  0.3536349833011627\n",
      "Eval Loss:  0.514476478099823\n",
      "Eval Loss:  0.3973287343978882\n",
      "[[15616  1411]\n",
      " [ 4704  7789]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84     17027\n",
      "           1       0.85      0.62      0.72     12493\n",
      "\n",
      "    accuracy                           0.79     29520\n",
      "   macro avg       0.81      0.77      0.78     29520\n",
      "weighted avg       0.80      0.79      0.79     29520\n",
      "\n",
      "acc:  0.7928523035230353\n",
      "pre:  0.8466304347826087\n",
      "rec:  0.6234691427199232\n",
      "ma F1:  0.7771885645251184\n",
      "mi F1:  0.7928523035230353\n",
      "we F1:  0.7862622061012722\n",
      "29520 462\n",
      "Loss:  0.09600961953401566\n",
      "Loss:  0.08781120926141739\n",
      "Loss:  0.12954181432724\n",
      "3 **********\n",
      "Epoch:  309.2491297721863  fold:  4  kers:  128\n",
      "epoch:  4\n",
      "29520 462\n",
      "Loss:  0.104342520236969\n",
      "Loss:  0.07728776335716248\n",
      "Loss:  0.07737978547811508\n",
      "4 **********\n",
      "Epoch:  373.35771584510803  fold:  4  kers:  128\n",
      "epoch:  5\n",
      "29520 462\n",
      "Loss:  0.11065782606601715\n",
      "Loss:  0.08364883810281754\n",
      "Loss:  0.12490778416395187\n",
      "5 **********\n",
      "Epoch:  437.50320410728455  fold:  4  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.17150598764419556\n",
      "Eval Loss:  0.18254277110099792\n",
      "Eval Loss:  0.04697349667549133\n",
      "[[3107   30]\n",
      " [ 229    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.14      0.02      0.04       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.54      0.51      0.50      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9231681993473747\n",
      "pre:  0.14285714285714285\n",
      "rec:  0.021367521367521368\n",
      "ma F1:  0.4985811810798874\n",
      "mi F1:  0.9231681993473747\n",
      "we F1:  0.8959300250613559\n",
      "update!  Acc:  0.9231681993473747\n",
      "Eval Loss:  0.5345531702041626\n",
      "Eval Loss:  0.49425041675567627\n",
      "Eval Loss:  0.35256144404411316\n",
      "Eval Loss:  0.4893961250782013\n",
      "Eval Loss:  0.43922945857048035\n",
      "Eval Loss:  0.4150400757789612\n",
      "Eval Loss:  0.5498625040054321\n",
      "Eval Loss:  0.36299899220466614\n",
      "Eval Loss:  0.5333125591278076\n",
      "Eval Loss:  0.45202964544296265\n",
      "Eval Loss:  0.5396583080291748\n",
      "Eval Loss:  0.42503899335861206\n",
      "Eval Loss:  0.5520452260971069\n",
      "Eval Loss:  0.4280632734298706\n",
      "Eval Loss:  0.4909176826477051\n",
      "Eval Loss:  0.464291512966156\n",
      "Eval Loss:  0.4211198389530182\n",
      "Eval Loss:  0.5018342137336731\n",
      "Eval Loss:  0.5736058950424194\n",
      "Eval Loss:  0.5435651540756226\n",
      "Eval Loss:  0.4097917377948761\n",
      "Eval Loss:  0.45721927285194397\n",
      "Eval Loss:  0.5571497678756714\n",
      "Eval Loss:  0.5109186172485352\n",
      "Eval Loss:  0.4112367033958435\n",
      "Eval Loss:  0.37830978631973267\n",
      "Eval Loss:  0.5134497880935669\n",
      "Eval Loss:  0.405829519033432\n",
      "[[16511   516]\n",
      " [ 5314  7179]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85     17027\n",
      "           1       0.93      0.57      0.71     12493\n",
      "\n",
      "    accuracy                           0.80     29520\n",
      "   macro avg       0.84      0.77      0.78     29520\n",
      "weighted avg       0.83      0.80      0.79     29520\n",
      "\n",
      "acc:  0.8025067750677507\n",
      "pre:  0.9329434697855751\n",
      "rec:  0.5746417994076682\n",
      "ma F1:  0.780578978889492\n",
      "mi F1:  0.8025067750677507\n",
      "we F1:  0.7912327109803862\n",
      "29520 462\n",
      "Loss:  0.05959239602088928\n",
      "Loss:  0.05553140491247177\n",
      "Loss:  0.08690936863422394\n",
      "6 **********\n",
      "Epoch:  542.2072463035583  fold:  4  kers:  128\n",
      "epoch:  7\n",
      "29520 462\n",
      "Loss:  0.08910030126571655\n",
      "Loss:  0.07079846411943436\n",
      "Loss:  0.0839204415678978\n",
      "7 **********\n",
      "Epoch:  606.3577210903168  fold:  4  kers:  128\n",
      "epoch:  8\n",
      "29520 462\n",
      "Loss:  0.06728573888540268\n",
      "Loss:  0.06694614887237549\n",
      "Loss:  0.09801920503377914\n",
      "8 **********\n",
      "Epoch:  670.5161752700806  fold:  4  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.1305813193321228\n",
      "Eval Loss:  0.1470375955104828\n",
      "Eval Loss:  0.028587887063622475\n",
      "[[3109   28]\n",
      " [ 229    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.15      0.02      0.04       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.54      0.51      0.50      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.92376149510531\n",
      "pre:  0.15151515151515152\n",
      "rec:  0.021367521367521368\n",
      "ma F1:  0.4988810319147397\n",
      "mi F1:  0.92376149510531\n",
      "we F1:  0.8962482950082401\n",
      "update!  Acc:  0.92376149510531\n",
      "Eval Loss:  0.4889092743396759\n",
      "Eval Loss:  0.45220839977264404\n",
      "Eval Loss:  0.3254140615463257\n",
      "Eval Loss:  0.49073368310928345\n",
      "Eval Loss:  0.4347677230834961\n",
      "Eval Loss:  0.3983636200428009\n",
      "Eval Loss:  0.5570873618125916\n",
      "Eval Loss:  0.3499862551689148\n",
      "Eval Loss:  0.5097060799598694\n",
      "Eval Loss:  0.4132966101169586\n",
      "Eval Loss:  0.5119451284408569\n",
      "Eval Loss:  0.4004267454147339\n",
      "Eval Loss:  0.5550922751426697\n",
      "Eval Loss:  0.3941410481929779\n",
      "Eval Loss:  0.4788312613964081\n",
      "Eval Loss:  0.445233553647995\n",
      "Eval Loss:  0.4103359878063202\n",
      "Eval Loss:  0.4415926933288574\n",
      "Eval Loss:  0.562863826751709\n",
      "Eval Loss:  0.4938002824783325\n",
      "Eval Loss:  0.34625399112701416\n",
      "Eval Loss:  0.4470711052417755\n",
      "Eval Loss:  0.5114243030548096\n",
      "Eval Loss:  0.47121965885162354\n",
      "Eval Loss:  0.3690464198589325\n",
      "Eval Loss:  0.35787534713745117\n",
      "Eval Loss:  0.47149235010147095\n",
      "Eval Loss:  0.39168021082878113\n",
      "[[16554   473]\n",
      " [ 4960  7533]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86     17027\n",
      "           1       0.94      0.60      0.73     12493\n",
      "\n",
      "    accuracy                           0.82     29520\n",
      "   macro avg       0.86      0.79      0.80     29520\n",
      "weighted avg       0.84      0.82      0.81     29520\n",
      "\n",
      "acc:  0.8159552845528455\n",
      "pre:  0.9409193105171122\n",
      "rec:  0.6029776674937966\n",
      "ma F1:  0.796997959219034\n",
      "mi F1:  0.8159552845528455\n",
      "we F1:  0.8065260063383669\n",
      "29520 462\n",
      "Loss:  0.10196490585803986\n",
      "Loss:  0.07543409615755081\n",
      "Loss:  0.06487514823675156\n",
      "9 **********\n",
      "Epoch:  775.149406671524  fold:  4  kers:  128\n",
      "epoch:  10\n",
      "29520 462\n",
      "Loss:  0.06760677695274353\n",
      "Loss:  0.1064886823296547\n",
      "Loss:  0.05074802786111832\n",
      "10 **********\n",
      "Epoch:  839.2679665088654  fold:  4  kers:  128\n",
      "epoch:  11\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09520960599184036\n",
      "Loss:  0.08169221132993698\n",
      "Loss:  0.07459700852632523\n",
      "11 **********\n",
      "Epoch:  903.4134542942047  fold:  4  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.1162947341799736\n",
      "Eval Loss:  0.1243341788649559\n",
      "Eval Loss:  0.021812908351421356\n",
      "[[3100   37]\n",
      " [ 224   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.21      0.04      0.07       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.57      0.52      0.52      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9225749035894394\n",
      "pre:  0.2127659574468085\n",
      "rec:  0.042735042735042736\n",
      "ma F1:  0.515389076864692\n",
      "mi F1:  0.9225749035894394\n",
      "we F1:  0.897932913428427\n",
      "Eval Loss:  0.3529670536518097\n",
      "Eval Loss:  0.3909338712692261\n",
      "Eval Loss:  0.2547794580459595\n",
      "Eval Loss:  0.37319639325141907\n",
      "Eval Loss:  0.3260227143764496\n",
      "Eval Loss:  0.3280925154685974\n",
      "Eval Loss:  0.44853994250297546\n",
      "Eval Loss:  0.3233674466609955\n",
      "Eval Loss:  0.40582260489463806\n",
      "Eval Loss:  0.327754944562912\n",
      "Eval Loss:  0.43501976132392883\n",
      "Eval Loss:  0.337215781211853\n",
      "Eval Loss:  0.463662713766098\n",
      "Eval Loss:  0.35350725054740906\n",
      "Eval Loss:  0.37560394406318665\n",
      "Eval Loss:  0.33922624588012695\n",
      "Eval Loss:  0.34841853380203247\n",
      "Eval Loss:  0.33319517970085144\n",
      "Eval Loss:  0.42305317521095276\n",
      "Eval Loss:  0.42834749817848206\n",
      "Eval Loss:  0.2656805217266083\n",
      "Eval Loss:  0.4057413637638092\n",
      "Eval Loss:  0.40022537112236023\n",
      "Eval Loss:  0.40265050530433655\n",
      "Eval Loss:  0.3140643239021301\n",
      "Eval Loss:  0.2743583917617798\n",
      "Eval Loss:  0.3504928946495056\n",
      "Eval Loss:  0.31449970602989197\n",
      "[[16487   540]\n",
      " [ 4033  8460]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88     17027\n",
      "           1       0.94      0.68      0.79     12493\n",
      "\n",
      "    accuracy                           0.85     29520\n",
      "   macro avg       0.87      0.82      0.83     29520\n",
      "weighted avg       0.86      0.85      0.84     29520\n",
      "\n",
      "acc:  0.8450880758807588\n",
      "pre:  0.94\n",
      "rec:  0.6771792203634035\n",
      "ma F1:  0.8327195172289413\n",
      "mi F1:  0.8450880758807588\n",
      "we F1:  0.8397058190761246\n",
      "29520 462\n",
      "Loss:  0.059319160878658295\n",
      "Loss:  0.10312125831842422\n",
      "Loss:  0.08050905913114548\n",
      "12 **********\n",
      "Epoch:  1007.936980009079  fold:  4  kers:  128\n",
      "epoch:  13\n",
      "29520 462\n",
      "Loss:  0.08755893260240555\n",
      "Loss:  0.11017567664384842\n",
      "Loss:  0.06223231926560402\n",
      "13 **********\n",
      "Epoch:  1072.0705001354218  fold:  4  kers:  128\n",
      "epoch:  14\n",
      "29520 462\n",
      "Loss:  0.061512745916843414\n",
      "Loss:  0.06644560396671295\n",
      "Loss:  0.09165345132350922\n",
      "14 **********\n",
      "Epoch:  1136.2528893947601  fold:  4  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.10601811856031418\n",
      "Eval Loss:  0.1534801572561264\n",
      "Eval Loss:  0.0191256832331419\n",
      "[[3096   41]\n",
      " [ 230    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.09      0.02      0.03       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.51      0.50      0.49      3371\n",
      "weighted avg       0.87      0.92      0.89      3371\n",
      "\n",
      "acc:  0.9196084247997627\n",
      "pre:  0.08888888888888889\n",
      "rec:  0.017094017094017096\n",
      "ma F1:  0.4933714216629871\n",
      "mi F1:  0.9196084247997627\n",
      "we F1:  0.8935544812056971\n",
      "Eval Loss:  0.38224202394485474\n",
      "Eval Loss:  0.40827518701553345\n",
      "Eval Loss:  0.270880788564682\n",
      "Eval Loss:  0.4274933934211731\n",
      "Eval Loss:  0.3631841540336609\n",
      "Eval Loss:  0.38549917936325073\n",
      "Eval Loss:  0.4538796842098236\n",
      "Eval Loss:  0.3205932378768921\n",
      "Eval Loss:  0.44261354207992554\n",
      "Eval Loss:  0.3379862904548645\n",
      "Eval Loss:  0.4677408039569855\n",
      "Eval Loss:  0.3478561341762543\n",
      "Eval Loss:  0.5103592872619629\n",
      "Eval Loss:  0.3587741255760193\n",
      "Eval Loss:  0.3983674943447113\n",
      "Eval Loss:  0.40211981534957886\n",
      "Eval Loss:  0.37219759821891785\n",
      "Eval Loss:  0.40527212619781494\n",
      "Eval Loss:  0.46653321385383606\n",
      "Eval Loss:  0.4302944839000702\n",
      "Eval Loss:  0.2571919858455658\n",
      "Eval Loss:  0.4163943827152252\n",
      "Eval Loss:  0.4210614562034607\n",
      "Eval Loss:  0.4038460850715637\n",
      "Eval Loss:  0.3106907606124878\n",
      "Eval Loss:  0.3120364248752594\n",
      "Eval Loss:  0.3584096133708954\n",
      "Eval Loss:  0.31374669075012207\n",
      "[[16623   404]\n",
      " [ 4367  8126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87     17027\n",
      "           1       0.95      0.65      0.77     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.87      0.81      0.82     29520\n",
      "weighted avg       0.86      0.84      0.83     29520\n",
      "\n",
      "acc:  0.8383807588075881\n",
      "pre:  0.9526377491207503\n",
      "rec:  0.6504442487793164\n",
      "ma F1:  0.8237807954167307\n",
      "mi F1:  0.8383807588075881\n",
      "we F1:  0.8315713372566915\n",
      "29520 462\n",
      "Loss:  0.0864369347691536\n",
      "Loss:  0.07305125892162323\n",
      "Loss:  0.06858967244625092\n",
      "15 **********\n",
      "Epoch:  1240.8522119522095  fold:  4  kers:  128\n",
      "epoch:  16\n",
      "29520 462\n",
      "Loss:  0.08906690031290054\n",
      "Loss:  0.07679286599159241\n",
      "Loss:  0.0535476915538311\n",
      "16 **********\n",
      "Epoch:  1304.9817426204681  fold:  4  kers:  128\n",
      "epoch:  17\n",
      "29520 462\n",
      "Loss:  0.0653180256485939\n",
      "Loss:  0.11633146554231644\n",
      "Loss:  0.05327300727367401\n",
      "17 **********\n",
      "Epoch:  1369.133214712143  fold:  4  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.1313176155090332\n",
      "Eval Loss:  0.17308399081230164\n",
      "Eval Loss:  0.015905747190117836\n",
      "[[3079   58]\n",
      " [ 230    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.06      0.02      0.03       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.50      0.50      0.49      3371\n",
      "weighted avg       0.87      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9145654108573124\n",
      "pre:  0.06451612903225806\n",
      "rec:  0.017094017094017096\n",
      "ma F1:  0.491174078204795\n",
      "mi F1:  0.9145654108573124\n",
      "we F1:  0.8908830338764235\n",
      "Eval Loss:  0.3752613365650177\n",
      "Eval Loss:  0.4144723117351532\n",
      "Eval Loss:  0.285706102848053\n",
      "Eval Loss:  0.4181423485279083\n",
      "Eval Loss:  0.35663673281669617\n",
      "Eval Loss:  0.3870716392993927\n",
      "Eval Loss:  0.44872286915779114\n",
      "Eval Loss:  0.31249120831489563\n",
      "Eval Loss:  0.4416275918483734\n",
      "Eval Loss:  0.33777713775634766\n",
      "Eval Loss:  0.5046844482421875\n",
      "Eval Loss:  0.33445054292678833\n",
      "Eval Loss:  0.5080099701881409\n",
      "Eval Loss:  0.3716534972190857\n",
      "Eval Loss:  0.4115259349346161\n",
      "Eval Loss:  0.4067939221858978\n",
      "Eval Loss:  0.3787781000137329\n",
      "Eval Loss:  0.420070081949234\n",
      "Eval Loss:  0.4778071641921997\n",
      "Eval Loss:  0.399079293012619\n",
      "Eval Loss:  0.2547943592071533\n",
      "Eval Loss:  0.45146363973617554\n",
      "Eval Loss:  0.40324532985687256\n",
      "Eval Loss:  0.3899213373661041\n",
      "Eval Loss:  0.3011074364185333\n",
      "Eval Loss:  0.3042382597923279\n",
      "Eval Loss:  0.3422453701496124\n",
      "Eval Loss:  0.28668415546417236\n",
      "[[16652   375]\n",
      " [ 4415  8078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87     17027\n",
      "           1       0.96      0.65      0.77     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.87      0.81      0.82     29520\n",
      "weighted avg       0.86      0.84      0.83     29520\n",
      "\n",
      "acc:  0.8377371273712737\n",
      "pre:  0.9556370519342245\n",
      "rec:  0.6466020971744176\n",
      "ma F1:  0.8227875662905477\n",
      "mi F1:  0.8377371273712737\n",
      "we F1:  0.8306930141491914\n",
      "29520 462\n",
      "Loss:  0.0755576491355896\n",
      "Loss:  0.06728119403123856\n",
      "Loss:  0.0867118164896965\n",
      "18 **********\n",
      "Epoch:  1473.8382546901703  fold:  4  kers:  128\n",
      "epoch:  19\n",
      "29520 462\n",
      "Loss:  0.03645938262343407\n",
      "Loss:  0.09138426184654236\n",
      "Loss:  0.049901824444532394\n",
      "19 **********\n",
      "Epoch:  1537.9897260665894  fold:  4  kers:  128\n",
      "epoch:  20\n",
      "29520 462\n",
      "Loss:  0.04759763926267624\n",
      "Loss:  0.04664412885904312\n",
      "Loss:  0.060473471879959106\n",
      "20 **********\n",
      "Epoch:  1603.7309482097626  fold:  4  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.09916945546865463\n",
      "Eval Loss:  0.1422543227672577\n",
      "Eval Loss:  0.015650779008865356\n",
      "[[3073   64]\n",
      " [ 219   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.19      0.06      0.10       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.56      0.52      0.53      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9160486502521507\n",
      "pre:  0.189873417721519\n",
      "rec:  0.0641025641025641\n",
      "ma F1:  0.5259136788821818\n",
      "mi F1:  0.9160486502521507\n",
      "we F1:  0.8962739868897095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22178788483142853\n",
      "Eval Loss:  0.25125959515571594\n",
      "Eval Loss:  0.20958372950553894\n",
      "Eval Loss:  0.2755274474620819\n",
      "Eval Loss:  0.21843862533569336\n",
      "Eval Loss:  0.2822861075401306\n",
      "Eval Loss:  0.28040120005607605\n",
      "Eval Loss:  0.25222423672676086\n",
      "Eval Loss:  0.2652268707752228\n",
      "Eval Loss:  0.2690621614456177\n",
      "Eval Loss:  0.36318403482437134\n",
      "Eval Loss:  0.21422134339809418\n",
      "Eval Loss:  0.345245897769928\n",
      "Eval Loss:  0.2653157413005829\n",
      "Eval Loss:  0.234672412276268\n",
      "Eval Loss:  0.2390948086977005\n",
      "Eval Loss:  0.2514723539352417\n",
      "Eval Loss:  0.2172342985868454\n",
      "Eval Loss:  0.30966654419898987\n",
      "Eval Loss:  0.32495588064193726\n",
      "Eval Loss:  0.17434194684028625\n",
      "Eval Loss:  0.3322106599807739\n",
      "Eval Loss:  0.27711644768714905\n",
      "Eval Loss:  0.2675760090351105\n",
      "Eval Loss:  0.2452176958322525\n",
      "Eval Loss:  0.22483855485916138\n",
      "Eval Loss:  0.2045082002878189\n",
      "Eval Loss:  0.16257347166538239\n",
      "[[16291   736]\n",
      " [ 2350 10143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17027\n",
      "           1       0.93      0.81      0.87     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.88      0.89     29520\n",
      "weighted avg       0.90      0.90      0.89     29520\n",
      "\n",
      "acc:  0.8954607046070461\n",
      "pre:  0.9323467230443975\n",
      "rec:  0.8118946610101657\n",
      "ma F1:  0.8907207667202071\n",
      "mi F1:  0.8954607046070461\n",
      "we F1:  0.8942163552659013\n",
      "29520 462\n",
      "Loss:  0.0530732199549675\n",
      "Loss:  0.03725331276655197\n",
      "Loss:  0.06559580564498901\n",
      "21 **********\n",
      "Epoch:  1708.3352570533752  fold:  4  kers:  128\n",
      "epoch:  22\n",
      "29520 462\n",
      "Loss:  0.07634627819061279\n",
      "Loss:  0.08239060640335083\n",
      "Loss:  0.09583112597465515\n",
      "22 **********\n",
      "Epoch:  1772.5655210018158  fold:  4  kers:  128\n",
      "epoch:  23\n",
      "29520 462\n",
      "Loss:  0.05430671572685242\n",
      "Loss:  0.08072541654109955\n",
      "Loss:  0.04983546584844589\n",
      "23 **********\n",
      "Epoch:  1836.718985080719  fold:  4  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.08321353793144226\n",
      "Eval Loss:  0.14769969880580902\n",
      "Eval Loss:  0.010474253445863724\n",
      "[[3084   53]\n",
      " [ 227    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.12      0.03      0.05       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.52      0.51      0.50      3371\n",
      "weighted avg       0.87      0.92      0.89      3371\n",
      "\n",
      "acc:  0.9169385938890537\n",
      "pre:  0.11666666666666667\n",
      "rec:  0.029914529914529916\n",
      "ma F1:  0.5020973650005908\n",
      "mi F1:  0.9169385938890537\n",
      "we F1:  0.8934799088625368\n",
      "Eval Loss:  0.31222742795944214\n",
      "Eval Loss:  0.3221828043460846\n",
      "Eval Loss:  0.2549113929271698\n",
      "Eval Loss:  0.3514545261859894\n",
      "Eval Loss:  0.27838006615638733\n",
      "Eval Loss:  0.3413294553756714\n",
      "Eval Loss:  0.34012821316719055\n",
      "Eval Loss:  0.28025710582733154\n",
      "Eval Loss:  0.36515164375305176\n",
      "Eval Loss:  0.2949182093143463\n",
      "Eval Loss:  0.45501279830932617\n",
      "Eval Loss:  0.2760894298553467\n",
      "Eval Loss:  0.43562251329421997\n",
      "Eval Loss:  0.31158533692359924\n",
      "Eval Loss:  0.3186502158641815\n",
      "Eval Loss:  0.3236292004585266\n",
      "Eval Loss:  0.31041419506073\n",
      "Eval Loss:  0.3138349950313568\n",
      "Eval Loss:  0.39949703216552734\n",
      "Eval Loss:  0.3525677025318146\n",
      "Eval Loss:  0.20458154380321503\n",
      "Eval Loss:  0.38114315271377563\n",
      "Eval Loss:  0.3232802450656891\n",
      "Eval Loss:  0.3404358923435211\n",
      "Eval Loss:  0.25420552492141724\n",
      "Eval Loss:  0.2437092363834381\n",
      "Eval Loss:  0.2643136978149414\n",
      "Eval Loss:  0.20475727319717407\n",
      "[[16581   446]\n",
      " [ 3336  9157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     17027\n",
      "           1       0.95      0.73      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.89      0.85      0.86     29520\n",
      "weighted avg       0.88      0.87      0.87     29520\n",
      "\n",
      "acc:  0.8718834688346884\n",
      "pre:  0.9535561803603041\n",
      "rec:  0.7329704634595373\n",
      "ma F1:  0.8632333211759293\n",
      "mi F1:  0.8718834688346885\n",
      "we F1:  0.8685161565052416\n",
      "29520 462\n",
      "Loss:  0.0907275527715683\n",
      "Loss:  0.05673758685588837\n",
      "Loss:  0.0643189549446106\n",
      "24 **********\n",
      "Epoch:  1941.4140515327454  fold:  4  kers:  128\n",
      "epoch:  25\n",
      "29520 462\n",
      "Loss:  0.07256213575601578\n",
      "Loss:  0.0699133351445198\n",
      "Loss:  0.06578972935676575\n",
      "25 **********\n",
      "Epoch:  2005.563529253006  fold:  4  kers:  128\n",
      "epoch:  26\n",
      "29520 462\n",
      "Loss:  0.060716018080711365\n",
      "Loss:  0.04494176805019379\n",
      "Loss:  0.053319383412599564\n",
      "26 **********\n",
      "Epoch:  2069.7060253620148  fold:  4  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.06184503436088562\n",
      "Eval Loss:  0.13796180486679077\n",
      "Eval Loss:  0.018144292756915092\n",
      "[[3022  115]\n",
      " [ 209   25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.18      0.11      0.13       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.56      0.54      0.54      3371\n",
      "weighted avg       0.88      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9038860872144764\n",
      "pre:  0.17857142857142858\n",
      "rec:  0.10683760683760683\n",
      "ma F1:  0.541405221293634\n",
      "mi F1:  0.9038860872144765\n",
      "we F1:  0.8925169843127218\n",
      "Eval Loss:  0.19675381481647491\n",
      "Eval Loss:  0.23206128180027008\n",
      "Eval Loss:  0.20157796144485474\n",
      "Eval Loss:  0.2575681507587433\n",
      "Eval Loss:  0.21567368507385254\n",
      "Eval Loss:  0.2685191333293915\n",
      "Eval Loss:  0.24645425379276276\n",
      "Eval Loss:  0.23785807192325592\n",
      "Eval Loss:  0.22952675819396973\n",
      "Eval Loss:  0.2307354211807251\n",
      "Eval Loss:  0.34141793847084045\n",
      "Eval Loss:  0.18708781898021698\n",
      "Eval Loss:  0.3089446425437927\n",
      "Eval Loss:  0.22714850306510925\n",
      "Eval Loss:  0.22319069504737854\n",
      "Eval Loss:  0.19076646864414215\n",
      "Eval Loss:  0.1892467439174652\n",
      "Eval Loss:  0.2190089374780655\n",
      "Eval Loss:  0.2535378038883209\n",
      "Eval Loss:  0.30173397064208984\n",
      "Eval Loss:  0.1472575068473816\n",
      "Eval Loss:  0.30971238017082214\n",
      "Eval Loss:  0.2136007398366928\n",
      "Eval Loss:  0.23399768769741058\n",
      "Eval Loss:  0.21671375632286072\n",
      "Eval Loss:  0.1889411211013794\n",
      "Eval Loss:  0.1879594326019287\n",
      "Eval Loss:  0.1345001757144928\n",
      "[[16145   882]\n",
      " [ 1953 10540]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17027\n",
      "           1       0.92      0.84      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9039634146341463\n",
      "pre:  0.9227805988443355\n",
      "rec:  0.8436724565756824\n",
      "ma F1:  0.9003717049485016\n",
      "mi F1:  0.9039634146341463\n",
      "we F1:  0.9032771129261489\n",
      "29520 462\n",
      "Loss:  0.06783514469861984\n",
      "Loss:  0.04717253893613815\n",
      "Loss:  0.05111243575811386\n",
      "27 **********\n",
      "Epoch:  2174.2804148197174  fold:  4  kers:  128\n",
      "epoch:  28\n",
      "29520 462\n",
      "Loss:  0.04867049306631088\n",
      "Loss:  0.04408537596464157\n",
      "Loss:  0.044895146042108536\n",
      "28 **********\n",
      "Epoch:  2238.442857027054  fold:  4  kers:  128\n",
      "epoch:  29\n",
      "29520 462\n",
      "Loss:  0.05017882585525513\n",
      "Loss:  0.04967762157320976\n",
      "Loss:  0.06408697366714478\n",
      "29 **********\n",
      "Epoch:  2302.6013107299805  fold:  4  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.06310558319091797\n",
      "Eval Loss:  0.0816778913140297\n",
      "Eval Loss:  0.01114683412015438\n",
      "[[3087   50]\n",
      " [ 217   17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.25      0.07      0.11       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.59      0.53      0.54      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9207950163156333\n",
      "pre:  0.2537313432835821\n",
      "rec:  0.07264957264957266\n",
      "ma F1:  0.5357518100664297\n",
      "mi F1:  0.9207950163156334\n",
      "we F1:  0.8998496692655952\n",
      "Eval Loss:  0.22478985786437988\n",
      "Eval Loss:  0.2430366426706314\n",
      "Eval Loss:  0.23096288740634918\n",
      "Eval Loss:  0.2569272518157959\n",
      "Eval Loss:  0.20756903290748596\n",
      "Eval Loss:  0.2772316038608551\n",
      "Eval Loss:  0.26354384422302246\n",
      "Eval Loss:  0.22554118931293488\n",
      "Eval Loss:  0.25007542967796326\n",
      "Eval Loss:  0.27151796221733093\n",
      "Eval Loss:  0.4157252311706543\n",
      "Eval Loss:  0.2088235765695572\n",
      "Eval Loss:  0.3150728940963745\n",
      "Eval Loss:  0.262418270111084\n",
      "Eval Loss:  0.17905494570732117\n",
      "Eval Loss:  0.22146914899349213\n",
      "Eval Loss:  0.23291417956352234\n",
      "Eval Loss:  0.22306916117668152\n",
      "Eval Loss:  0.31147968769073486\n",
      "Eval Loss:  0.3097853660583496\n",
      "Eval Loss:  0.15070974826812744\n",
      "Eval Loss:  0.3402114808559418\n",
      "Eval Loss:  0.23391054570674896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2818034291267395\n",
      "Eval Loss:  0.23350943624973297\n",
      "Eval Loss:  0.21931235492229462\n",
      "Eval Loss:  0.1986662745475769\n",
      "Eval Loss:  0.1548912525177002\n",
      "[[16241   786]\n",
      " [ 2261 10232]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     17027\n",
      "           1       0.93      0.82      0.87     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.89      0.89     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.8967818428184282\n",
      "pre:  0.9286621891450354\n",
      "rec:  0.8190186504442488\n",
      "ma F1:  0.8923200805795781\n",
      "mi F1:  0.8967818428184283\n",
      "we F1:  0.8956866357453206\n",
      "29520 462\n",
      "Loss:  0.06958454847335815\n",
      "Loss:  0.08170004189014435\n",
      "Loss:  0.09467875212430954\n",
      "30 **********\n",
      "Epoch:  2407.2594759464264  fold:  4  kers:  128\n",
      "epoch:  31\n",
      "29520 462\n",
      "Loss:  0.054920442402362823\n",
      "Loss:  0.03456461802124977\n",
      "Loss:  0.06361453980207443\n",
      "31 **********\n",
      "Epoch:  2471.3999769687653  fold:  4  kers:  128\n",
      "epoch:  32\n",
      "29520 462\n",
      "Loss:  0.07565276324748993\n",
      "Loss:  0.05148305743932724\n",
      "Loss:  0.07780814915895462\n",
      "32 **********\n",
      "Epoch:  2535.5624198913574  fold:  4  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.06212935596704483\n",
      "Eval Loss:  0.08543392270803452\n",
      "Eval Loss:  0.009520377032458782\n",
      "[[3109   28]\n",
      " [ 224   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.26      0.04      0.07       234\n",
      "\n",
      "    accuracy                           0.93      3371\n",
      "   macro avg       0.60      0.52      0.52      3371\n",
      "weighted avg       0.89      0.93      0.90      3371\n",
      "\n",
      "acc:  0.9252447345001483\n",
      "pre:  0.2631578947368421\n",
      "rec:  0.042735042735042736\n",
      "ma F1:  0.5172902082007454\n",
      "mi F1:  0.9252447345001484\n",
      "we F1:  0.8994431574899246\n",
      "update!  Acc:  0.9252447345001483\n",
      "Eval Loss:  0.2745085060596466\n",
      "Eval Loss:  0.27474814653396606\n",
      "Eval Loss:  0.22775353491306305\n",
      "Eval Loss:  0.30142608284950256\n",
      "Eval Loss:  0.2186000943183899\n",
      "Eval Loss:  0.2914286255836487\n",
      "Eval Loss:  0.2632070481777191\n",
      "Eval Loss:  0.23756609857082367\n",
      "Eval Loss:  0.30402326583862305\n",
      "Eval Loss:  0.2659578025341034\n",
      "Eval Loss:  0.4249558746814728\n",
      "Eval Loss:  0.2464631050825119\n",
      "Eval Loss:  0.3547024726867676\n",
      "Eval Loss:  0.2684532105922699\n",
      "Eval Loss:  0.25454211235046387\n",
      "Eval Loss:  0.29470187425613403\n",
      "Eval Loss:  0.25850820541381836\n",
      "Eval Loss:  0.26207464933395386\n",
      "Eval Loss:  0.34957343339920044\n",
      "Eval Loss:  0.3164677321910858\n",
      "Eval Loss:  0.18611888587474823\n",
      "Eval Loss:  0.3544659912586212\n",
      "Eval Loss:  0.26780229806900024\n",
      "Eval Loss:  0.30224019289016724\n",
      "Eval Loss:  0.22957509756088257\n",
      "Eval Loss:  0.21969425678253174\n",
      "Eval Loss:  0.21910491585731506\n",
      "Eval Loss:  0.17768628895282745\n",
      "[[16569   458]\n",
      " [ 2786  9707]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     17027\n",
      "           1       0.95      0.78      0.86     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.91      0.88      0.88     29520\n",
      "weighted avg       0.90      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8901084010840108\n",
      "pre:  0.9549434333497294\n",
      "rec:  0.7769951172656687\n",
      "ma F1:  0.8838313194338403\n",
      "mi F1:  0.8901084010840108\n",
      "we F1:  0.8879788403026647\n",
      "29520 462\n",
      "Loss:  0.07802962511777878\n",
      "Loss:  0.05560799688100815\n",
      "Loss:  0.05831930786371231\n",
      "33 **********\n",
      "Epoch:  2640.3941209316254  fold:  4  kers:  128\n",
      "epoch:  34\n",
      "29520 462\n",
      "Loss:  0.10028726607561111\n",
      "Loss:  0.05703064799308777\n",
      "Loss:  0.05389367416501045\n",
      "34 **********\n",
      "Epoch:  2704.530633211136  fold:  4  kers:  128\n",
      "epoch:  35\n",
      "29520 462\n",
      "Loss:  0.059065092355012894\n",
      "Loss:  0.10227670520544052\n",
      "Loss:  0.06294302642345428\n",
      "35 **********\n",
      "Epoch:  2768.706041574478  fold:  4  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.10495413094758987\n",
      "Eval Loss:  0.06262893974781036\n",
      "Eval Loss:  0.009562389925122261\n",
      "[[3094   43]\n",
      " [ 220   14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.25      0.06      0.10       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.59      0.52      0.53      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.921981607831504\n",
      "pre:  0.24561403508771928\n",
      "rec:  0.05982905982905983\n",
      "ma F1:  0.5277255291142693\n",
      "mi F1:  0.921981607831504\n",
      "we F1:  0.8993246838272992\n",
      "Eval Loss:  0.21235495805740356\n",
      "Eval Loss:  0.2253444343805313\n",
      "Eval Loss:  0.21606360375881195\n",
      "Eval Loss:  0.2708576023578644\n",
      "Eval Loss:  0.1957269161939621\n",
      "Eval Loss:  0.2690873444080353\n",
      "Eval Loss:  0.23337478935718536\n",
      "Eval Loss:  0.19419316947460175\n",
      "Eval Loss:  0.2388327568769455\n",
      "Eval Loss:  0.2491825670003891\n",
      "Eval Loss:  0.3994060754776001\n",
      "Eval Loss:  0.22837981581687927\n",
      "Eval Loss:  0.2825085520744324\n",
      "Eval Loss:  0.26838064193725586\n",
      "Eval Loss:  0.1933133453130722\n",
      "Eval Loss:  0.21817710995674133\n",
      "Eval Loss:  0.23747369647026062\n",
      "Eval Loss:  0.20808908343315125\n",
      "Eval Loss:  0.28547608852386475\n",
      "Eval Loss:  0.26901426911354065\n",
      "Eval Loss:  0.16745224595069885\n",
      "Eval Loss:  0.35107526183128357\n",
      "Eval Loss:  0.2317011058330536\n",
      "Eval Loss:  0.2672622799873352\n",
      "Eval Loss:  0.21599404513835907\n",
      "Eval Loss:  0.2133762091398239\n",
      "Eval Loss:  0.19831842184066772\n",
      "Eval Loss:  0.149748757481575\n",
      "[[16309   718]\n",
      " [ 2067 10426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     17027\n",
      "           1       0.94      0.83      0.88     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.91      0.90     29520\n",
      "\n",
      "acc:  0.9056571815718157\n",
      "pre:  0.9355707106963388\n",
      "rec:  0.8345473465140478\n",
      "ma F1:  0.9017552996486484\n",
      "mi F1:  0.9056571815718157\n",
      "we F1:  0.9047624614095936\n",
      "29520 462\n",
      "Loss:  0.06634264439344406\n",
      "Loss:  0.04114224389195442\n",
      "Loss:  0.04695466533303261\n",
      "36 **********\n",
      "Epoch:  2873.312345266342  fold:  4  kers:  128\n",
      "epoch:  37\n",
      "29520 462\n",
      "Loss:  0.062079451978206635\n",
      "Loss:  0.053373195230960846\n",
      "Loss:  0.08945173770189285\n",
      "37 **********\n",
      "Epoch:  2937.4747879505157  fold:  4  kers:  128\n",
      "epoch:  38\n",
      "29520 462\n",
      "Loss:  0.04720771312713623\n",
      "Loss:  0.04947540536522865\n",
      "Loss:  0.08883938193321228\n",
      "38 **********\n",
      "Epoch:  3001.6342389583588  fold:  4  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.20737364888191223\n",
      "Eval Loss:  0.05245506390929222\n",
      "Eval Loss:  0.007355846464633942\n",
      "[[3114   23]\n",
      " [ 221   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.36      0.06      0.10       234\n",
      "\n",
      "    accuracy                           0.93      3371\n",
      "   macro avg       0.65      0.52      0.53      3371\n",
      "weighted avg       0.89      0.93      0.90      3371\n",
      "\n",
      "acc:  0.9276179175318896\n",
      "pre:  0.3611111111111111\n",
      "rec:  0.05555555555555555\n",
      "ma F1:  0.529297715515268\n",
      "mi F1:  0.9276179175318896\n",
      "we F1:  0.9021850249168328\n",
      "update!  Acc:  0.9276179175318896\n",
      "Eval Loss:  0.205815851688385\n",
      "Eval Loss:  0.2580009698867798\n",
      "Eval Loss:  0.20659084618091583\n",
      "Eval Loss:  0.2689022123813629\n",
      "Eval Loss:  0.18202045559883118\n",
      "Eval Loss:  0.26923176646232605\n",
      "Eval Loss:  0.2694163918495178\n",
      "Eval Loss:  0.19937564432621002\n",
      "Eval Loss:  0.21826015412807465\n",
      "Eval Loss:  0.19615916907787323\n",
      "Eval Loss:  0.3818584084510803\n",
      "Eval Loss:  0.23015393316745758\n",
      "Eval Loss:  0.28989332914352417\n",
      "Eval Loss:  0.265468955039978\n",
      "Eval Loss:  0.18273955583572388\n",
      "Eval Loss:  0.21461622416973114\n",
      "Eval Loss:  0.22142116725444794\n",
      "Eval Loss:  0.19686110317707062\n",
      "Eval Loss:  0.283369779586792\n",
      "Eval Loss:  0.269949346780777\n",
      "Eval Loss:  0.1500203013420105\n",
      "Eval Loss:  0.3548329770565033\n",
      "Eval Loss:  0.20926032960414886\n",
      "Eval Loss:  0.23948851227760315\n",
      "Eval Loss:  0.17562897503376007\n",
      "Eval Loss:  0.18215665221214294\n",
      "Eval Loss:  0.1733252853155136\n",
      "Eval Loss:  0.15614548325538635\n",
      "[[16402   625]\n",
      " [ 2232 10261]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17027\n",
      "           1       0.94      0.82      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.91      0.89      0.90     29520\n",
      "weighted avg       0.91      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9032181571815718\n",
      "pre:  0.9425868087451773\n",
      "rec:  0.8213399503722084\n",
      "ma F1:  0.8988403902780526\n",
      "mi F1:  0.9032181571815718\n",
      "we F1:  0.9020725666565832\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04968535155057907\n",
      "Loss:  0.05026809126138687\n",
      "Loss:  0.04078473895788193\n",
      "39 **********\n",
      "Epoch:  3106.203641653061  fold:  4  kers:  128\n",
      "epoch:  40\n",
      "29520 462\n",
      "Loss:  0.06025991961359978\n",
      "Loss:  0.05005885288119316\n",
      "Loss:  0.09510311484336853\n",
      "40 **********\n",
      "Epoch:  3170.366084098816  fold:  4  kers:  128\n",
      "epoch:  41\n",
      "29520 462\n",
      "Loss:  0.031806617975234985\n",
      "Loss:  0.06003112345933914\n",
      "Loss:  0.05774560570716858\n",
      "41 **********\n",
      "Epoch:  3234.531518936157  fold:  4  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.06369506567716599\n",
      "Eval Loss:  0.048249974846839905\n",
      "Eval Loss:  0.00778005039319396\n",
      "[[3100   37]\n",
      " [ 213   21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      3137\n",
      "           1       0.36      0.09      0.14       234\n",
      "\n",
      "    accuracy                           0.93      3371\n",
      "   macro avg       0.65      0.54      0.55      3371\n",
      "weighted avg       0.90      0.93      0.90      3371\n",
      "\n",
      "acc:  0.9258380302580836\n",
      "pre:  0.3620689655172414\n",
      "rec:  0.08974358974358974\n",
      "ma F1:  0.5525379632579377\n",
      "mi F1:  0.9258380302580836\n",
      "we F1:  0.9044996698189716\n",
      "Eval Loss:  0.21037185192108154\n",
      "Eval Loss:  0.22968831658363342\n",
      "Eval Loss:  0.1983472853899002\n",
      "Eval Loss:  0.25935301184654236\n",
      "Eval Loss:  0.17973235249519348\n",
      "Eval Loss:  0.2514595687389374\n",
      "Eval Loss:  0.21447625756263733\n",
      "Eval Loss:  0.20945405960083008\n",
      "Eval Loss:  0.2180662900209427\n",
      "Eval Loss:  0.2080424427986145\n",
      "Eval Loss:  0.3507818579673767\n",
      "Eval Loss:  0.19750505685806274\n",
      "Eval Loss:  0.2884010076522827\n",
      "Eval Loss:  0.24441459774971008\n",
      "Eval Loss:  0.17781442403793335\n",
      "Eval Loss:  0.21090905368328094\n",
      "Eval Loss:  0.2025257647037506\n",
      "Eval Loss:  0.20658822357654572\n",
      "Eval Loss:  0.2616281509399414\n",
      "Eval Loss:  0.2916266620159149\n",
      "Eval Loss:  0.1379907727241516\n",
      "Eval Loss:  0.33528396487236023\n",
      "Eval Loss:  0.20805779099464417\n",
      "Eval Loss:  0.23777522146701813\n",
      "Eval Loss:  0.18011212348937988\n",
      "Eval Loss:  0.19506198167800903\n",
      "Eval Loss:  0.18371930718421936\n",
      "Eval Loss:  0.1403239667415619\n",
      "[[16381   646]\n",
      " [ 2064 10429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     17027\n",
      "           1       0.94      0.83      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9081978319783198\n",
      "pre:  0.9416704288939052\n",
      "rec:  0.8347874809893541\n",
      "ma F1:  0.9043076458802422\n",
      "mi F1:  0.9081978319783198\n",
      "we F1:  0.9072710369704108\n",
      "29520 462\n",
      "Loss:  0.035118989646434784\n",
      "Loss:  0.08960045129060745\n",
      "Loss:  0.04085434973239899\n",
      "42 **********\n",
      "Epoch:  3339.0261216163635  fold:  4  kers:  128\n",
      "epoch:  43\n",
      "29520 462\n",
      "Loss:  0.051265500485897064\n",
      "Loss:  0.0743134543299675\n",
      "Loss:  0.04633951559662819\n",
      "43 **********\n",
      "Epoch:  3403.141689300537  fold:  4  kers:  128\n",
      "epoch:  44\n",
      "29520 462\n",
      "Loss:  0.05809161812067032\n",
      "Loss:  0.0507943257689476\n",
      "Loss:  0.052858248353004456\n",
      "44 **********\n",
      "Epoch:  3467.2811937332153  fold:  4  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.12707844376564026\n",
      "Eval Loss:  0.04396824538707733\n",
      "Eval Loss:  0.008466549217700958\n",
      "[[3110   27]\n",
      " [ 217   17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.39      0.07      0.12       234\n",
      "\n",
      "    accuracy                           0.93      3371\n",
      "   macro avg       0.66      0.53      0.54      3371\n",
      "weighted avg       0.90      0.93      0.90      3371\n",
      "\n",
      "acc:  0.9276179175318896\n",
      "pre:  0.38636363636363635\n",
      "rec:  0.07264957264957266\n",
      "ma F1:  0.542277316760453\n",
      "mi F1:  0.9276179175318896\n",
      "we F1:  0.9039468169348729\n",
      "Eval Loss:  0.20301082730293274\n",
      "Eval Loss:  0.2400502860546112\n",
      "Eval Loss:  0.1867595911026001\n",
      "Eval Loss:  0.23694650828838348\n",
      "Eval Loss:  0.1719021499156952\n",
      "Eval Loss:  0.25336456298828125\n",
      "Eval Loss:  0.20847786962985992\n",
      "Eval Loss:  0.2121776044368744\n",
      "Eval Loss:  0.20791617035865784\n",
      "Eval Loss:  0.1978873610496521\n",
      "Eval Loss:  0.3604581952095032\n",
      "Eval Loss:  0.1986837536096573\n",
      "Eval Loss:  0.2744910418987274\n",
      "Eval Loss:  0.24950428307056427\n",
      "Eval Loss:  0.16121576726436615\n",
      "Eval Loss:  0.22287742793560028\n",
      "Eval Loss:  0.19814050197601318\n",
      "Eval Loss:  0.15247340500354767\n",
      "Eval Loss:  0.25183767080307007\n",
      "Eval Loss:  0.26817652583122253\n",
      "Eval Loss:  0.13281694054603577\n",
      "Eval Loss:  0.3276842534542084\n",
      "Eval Loss:  0.17439152300357819\n",
      "Eval Loss:  0.23754966259002686\n",
      "Eval Loss:  0.17439506947994232\n",
      "Eval Loss:  0.17170731723308563\n",
      "Eval Loss:  0.20703691244125366\n",
      "Eval Loss:  0.1257345825433731\n",
      "[[16321   706]\n",
      " [ 1890 10603]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     17027\n",
      "           1       0.94      0.85      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.92      0.90      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9120596205962059\n",
      "pre:  0.9375718454328411\n",
      "rec:  0.848715280557112\n",
      "ma F1:  0.9086315328087061\n",
      "mi F1:  0.9120596205962059\n",
      "we F1:  0.9113497822015926\n",
      "29520 462\n",
      "Loss:  0.04388611018657684\n",
      "Loss:  0.07638295739889145\n",
      "Loss:  0.07559942454099655\n",
      "45 **********\n",
      "Epoch:  3571.7738013267517  fold:  4  kers:  128\n",
      "epoch:  46\n",
      "29520 462\n",
      "Loss:  0.041852131485939026\n",
      "Loss:  0.04493093118071556\n",
      "Loss:  0.03593362867832184\n",
      "46 **********\n",
      "Epoch:  3635.892361164093  fold:  4  kers:  128\n",
      "epoch:  47\n",
      "29520 462\n",
      "Loss:  0.04627188667654991\n",
      "Loss:  0.10712137818336487\n",
      "Loss:  0.04018300026655197\n",
      "47 **********\n",
      "Epoch:  3700.0268783569336  fold:  4  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.04363511502742767\n",
      "Eval Loss:  0.028144415467977524\n",
      "Eval Loss:  0.006628938484936953\n",
      "[[3116   21]\n",
      " [ 219   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.42      0.06      0.11       234\n",
      "\n",
      "    accuracy                           0.93      3371\n",
      "   macro avg       0.68      0.53      0.54      3371\n",
      "weighted avg       0.90      0.93      0.90      3371\n",
      "\n",
      "acc:  0.9288045090477604\n",
      "pre:  0.4166666666666667\n",
      "rec:  0.0641025641025641\n",
      "ma F1:  0.5370141464084603\n",
      "mi F1:  0.9288045090477605\n",
      "we F1:  0.9037885490985241\n",
      "update!  Acc:  0.9288045090477604\n",
      "Eval Loss:  0.263824462890625\n",
      "Eval Loss:  0.2706676423549652\n",
      "Eval Loss:  0.22426334023475647\n",
      "Eval Loss:  0.27850762009620667\n",
      "Eval Loss:  0.21074141561985016\n",
      "Eval Loss:  0.28436383605003357\n",
      "Eval Loss:  0.24360886216163635\n",
      "Eval Loss:  0.19950266182422638\n",
      "Eval Loss:  0.2665386497974396\n",
      "Eval Loss:  0.1983134001493454\n",
      "Eval Loss:  0.4022273123264313\n",
      "Eval Loss:  0.26885923743247986\n",
      "Eval Loss:  0.2721501290798187\n",
      "Eval Loss:  0.28113651275634766\n",
      "Eval Loss:  0.1961771696805954\n",
      "Eval Loss:  0.24568472802639008\n",
      "Eval Loss:  0.25268444418907166\n",
      "Eval Loss:  0.22692985832691193\n",
      "Eval Loss:  0.33090680837631226\n",
      "Eval Loss:  0.2609817087650299\n",
      "Eval Loss:  0.15986257791519165\n",
      "Eval Loss:  0.36060631275177\n",
      "Eval Loss:  0.2274455428123474\n",
      "Eval Loss:  0.26943472027778625\n",
      "Eval Loss:  0.19650918245315552\n",
      "Eval Loss:  0.18813051283359528\n",
      "Eval Loss:  0.19520410895347595\n",
      "Eval Loss:  0.1944560557603836\n",
      "[[16634   393]\n",
      " [ 2595  9898]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92     17027\n",
      "           1       0.96      0.79      0.87     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.91      0.88      0.89     29520\n",
      "weighted avg       0.91      0.90      0.90     29520\n",
      "\n",
      "acc:  0.8987804878048781\n",
      "pre:  0.9618112914196871\n",
      "rec:  0.7922836788601617\n",
      "ma F1:  0.8932206959003144\n",
      "mi F1:  0.8987804878048781\n",
      "we F1:  0.8969629905106605\n",
      "29520 462\n",
      "Loss:  0.047944024205207825\n",
      "Loss:  0.04669354856014252\n",
      "Loss:  0.05683894455432892\n",
      "48 **********\n",
      "Epoch:  3804.621214389801  fold:  4  kers:  128\n",
      "epoch:  49\n",
      "29520 462\n",
      "Loss:  0.06896547228097916\n",
      "Loss:  0.05189035087823868\n",
      "Loss:  0.06960633397102356\n",
      "49 **********\n",
      "Epoch:  3868.7537372112274  fold:  4  kers:  128\n",
      "epoch:  50\n",
      "29520 462\n",
      "Loss:  0.09870558232069016\n",
      "Loss:  0.053016699850559235\n",
      "Loss:  0.04842475801706314\n",
      "50 **********\n",
      "Epoch:  3932.898228406906  fold:  4  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.06295313686132431\n",
      "Eval Loss:  0.04809028282761574\n",
      "Eval Loss:  0.005639620125293732\n",
      "[[3089   48]\n",
      " [ 211   23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.32      0.10      0.15       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.63      0.54      0.56      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9231681993473747\n",
      "pre:  0.323943661971831\n",
      "rec:  0.09829059829059829\n",
      "ma F1:  0.5552917686428613\n",
      "mi F1:  0.9231681993473747\n",
      "we F1:  0.9036105156536904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1898367553949356\n",
      "Eval Loss:  0.23092448711395264\n",
      "Eval Loss:  0.19263379275798798\n",
      "Eval Loss:  0.24840131402015686\n",
      "Eval Loss:  0.17178580164909363\n",
      "Eval Loss:  0.24238406121730804\n",
      "Eval Loss:  0.18457432091236115\n",
      "Eval Loss:  0.15978050231933594\n",
      "Eval Loss:  0.16923215985298157\n",
      "Eval Loss:  0.18558984994888306\n",
      "Eval Loss:  0.3237149715423584\n",
      "Eval Loss:  0.1880582869052887\n",
      "Eval Loss:  0.2715517282485962\n",
      "Eval Loss:  0.232991024851799\n",
      "Eval Loss:  0.14595389366149902\n",
      "Eval Loss:  0.20722337067127228\n",
      "Eval Loss:  0.1720007061958313\n",
      "Eval Loss:  0.1759728044271469\n",
      "Eval Loss:  0.2467212677001953\n",
      "Eval Loss:  0.2665282189846039\n",
      "Eval Loss:  0.1371682733297348\n",
      "Eval Loss:  0.31539633870124817\n",
      "Eval Loss:  0.15315751731395721\n",
      "Eval Loss:  0.23553691804409027\n",
      "Eval Loss:  0.17077580094337463\n",
      "Eval Loss:  0.1836794763803482\n",
      "Eval Loss:  0.16684217751026154\n",
      "Eval Loss:  0.11750607937574387\n",
      "[[16416   611]\n",
      " [ 1869 10624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     17027\n",
      "           1       0.95      0.85      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9159891598915989\n",
      "pre:  0.9456163773920784\n",
      "rec:  0.8503962218842552\n",
      "ma F1:  0.9126255239489628\n",
      "mi F1:  0.9159891598915989\n",
      "we F1:  0.9152585911733951\n",
      "29520 462\n",
      "Loss:  0.04679117724299431\n",
      "Loss:  0.03245372325181961\n",
      "Loss:  0.03776548057794571\n",
      "51 **********\n",
      "Epoch:  4037.3668999671936  fold:  4  kers:  128\n",
      "epoch:  52\n",
      "29520 462\n",
      "Loss:  0.05768720805644989\n",
      "Loss:  0.04297894611954689\n",
      "Loss:  0.044616736471652985\n",
      "52 **********\n",
      "Epoch:  4101.487454652786  fold:  4  kers:  128\n",
      "epoch:  53\n",
      "29520 462\n",
      "Loss:  0.05008472129702568\n",
      "Loss:  0.045979470014572144\n",
      "Loss:  0.04321514070034027\n",
      "53 **********\n",
      "Epoch:  4165.62895321846  fold:  4  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.04933018237352371\n",
      "Eval Loss:  0.024829551577568054\n",
      "Eval Loss:  0.005762184038758278\n",
      "[[3115   22]\n",
      " [ 200   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      3137\n",
      "           1       0.61      0.15      0.23       234\n",
      "\n",
      "    accuracy                           0.93      3371\n",
      "   macro avg       0.77      0.57      0.60      3371\n",
      "weighted avg       0.92      0.93      0.91      3371\n",
      "\n",
      "acc:  0.9341441708691783\n",
      "pre:  0.6071428571428571\n",
      "rec:  0.1452991452991453\n",
      "ma F1:  0.6000374115484106\n",
      "mi F1:  0.9341441708691783\n",
      "we F1:  0.9148416706552553\n",
      "update!  Acc:  0.9341441708691783\n",
      "Eval Loss:  0.1836625039577484\n",
      "Eval Loss:  0.20859530568122864\n",
      "Eval Loss:  0.16969752311706543\n",
      "Eval Loss:  0.2286178469657898\n",
      "Eval Loss:  0.1559072583913803\n",
      "Eval Loss:  0.2109798789024353\n",
      "Eval Loss:  0.15608972311019897\n",
      "Eval Loss:  0.17614977061748505\n",
      "Eval Loss:  0.15626384317874908\n",
      "Eval Loss:  0.19627131521701813\n",
      "Eval Loss:  0.3258594870567322\n",
      "Eval Loss:  0.16963842511177063\n",
      "Eval Loss:  0.22940593957901\n",
      "Eval Loss:  0.2314590960741043\n",
      "Eval Loss:  0.12999725341796875\n",
      "Eval Loss:  0.21441589295864105\n",
      "Eval Loss:  0.1781207174062729\n",
      "Eval Loss:  0.15240296721458435\n",
      "Eval Loss:  0.21228614449501038\n",
      "Eval Loss:  0.2499857097864151\n",
      "Eval Loss:  0.10785303264856339\n",
      "Eval Loss:  0.282010555267334\n",
      "Eval Loss:  0.1254642903804779\n",
      "Eval Loss:  0.20591075718402863\n",
      "Eval Loss:  0.19841919839382172\n",
      "Eval Loss:  0.18369720876216888\n",
      "Eval Loss:  0.1618814319372177\n",
      "Eval Loss:  0.11835700273513794\n",
      "[[16192   835]\n",
      " [ 1471 11022]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     17027\n",
      "           1       0.93      0.88      0.91     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.92      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9218834688346883\n",
      "pre:  0.9295774647887324\n",
      "rec:  0.8822540622748739\n",
      "ma F1:  0.9194116264739675\n",
      "mi F1:  0.9218834688346884\n",
      "we F1:  0.9215793891941819\n",
      "29520 462\n",
      "Loss:  0.060640379786491394\n",
      "Loss:  0.06520576030015945\n",
      "Loss:  0.040622416883707047\n",
      "54 **********\n",
      "Epoch:  4270.266174316406  fold:  4  kers:  128\n",
      "epoch:  55\n",
      "29520 462\n",
      "Loss:  0.0351593978703022\n",
      "Loss:  0.028378257527947426\n",
      "Loss:  0.069500632584095\n",
      "55 **********\n",
      "Epoch:  4334.410665035248  fold:  4  kers:  128\n",
      "epoch:  56\n",
      "29520 462\n",
      "Loss:  0.03581976145505905\n",
      "Loss:  0.03949570655822754\n",
      "Loss:  0.03209917992353439\n",
      "56 **********\n",
      "Epoch:  4398.576100111008  fold:  4  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.059360045939683914\n",
      "Eval Loss:  0.06596392393112183\n",
      "Eval Loss:  0.00937671773135662\n",
      "[[3110   27]\n",
      " [ 189   45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      3137\n",
      "           1       0.62      0.19      0.29       234\n",
      "\n",
      "    accuracy                           0.94      3371\n",
      "   macro avg       0.78      0.59      0.63      3371\n",
      "weighted avg       0.92      0.94      0.92      3371\n",
      "\n",
      "acc:  0.9359240581429843\n",
      "pre:  0.625\n",
      "rec:  0.19230769230769232\n",
      "ma F1:  0.6302782144554528\n",
      "mi F1:  0.9359240581429843\n",
      "we F1:  0.9197692044146385\n",
      "update!  Acc:  0.9359240581429843\n",
      "Eval Loss:  0.17373444139957428\n",
      "Eval Loss:  0.20312245190143585\n",
      "Eval Loss:  0.16657325625419617\n",
      "Eval Loss:  0.22799372673034668\n",
      "Eval Loss:  0.1467166244983673\n",
      "Eval Loss:  0.2147575467824936\n",
      "Eval Loss:  0.15730440616607666\n",
      "Eval Loss:  0.16667598485946655\n",
      "Eval Loss:  0.16622242331504822\n",
      "Eval Loss:  0.17439930140972137\n",
      "Eval Loss:  0.3098646104335785\n",
      "Eval Loss:  0.1819317638874054\n",
      "Eval Loss:  0.21350614726543427\n",
      "Eval Loss:  0.24191918969154358\n",
      "Eval Loss:  0.13769572973251343\n",
      "Eval Loss:  0.20943377912044525\n",
      "Eval Loss:  0.1908038854598999\n",
      "Eval Loss:  0.13013185560703278\n",
      "Eval Loss:  0.21778108179569244\n",
      "Eval Loss:  0.24857619404792786\n",
      "Eval Loss:  0.11683617532253265\n",
      "Eval Loss:  0.28486108779907227\n",
      "Eval Loss:  0.16878361999988556\n",
      "Eval Loss:  0.1881449669599533\n",
      "Eval Loss:  0.17007559537887573\n",
      "Eval Loss:  0.15953680872917175\n",
      "Eval Loss:  0.15893466770648956\n",
      "Eval Loss:  0.14757801592350006\n",
      "[[16294   733]\n",
      " [ 1540 10953]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     17027\n",
      "           1       0.94      0.88      0.91     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.93      0.92      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9230013550135502\n",
      "pre:  0.9372753722402876\n",
      "rec:  0.876730969342832\n",
      "ma F1:  0.9203955011163019\n",
      "mi F1:  0.9230013550135502\n",
      "we F1:  0.9226076227358719\n",
      "29520 462\n",
      "Loss:  0.06881201267242432\n",
      "Loss:  0.048341527581214905\n",
      "Loss:  0.0382814034819603\n",
      "57 **********\n",
      "Epoch:  4503.2392518520355  fold:  4  kers:  128\n",
      "epoch:  58\n",
      "29520 462\n",
      "Loss:  0.036043405532836914\n",
      "Loss:  0.09570637345314026\n",
      "Loss:  0.06520785391330719\n",
      "58 **********\n",
      "Epoch:  4567.365790605545  fold:  4  kers:  128\n",
      "epoch:  59\n",
      "29520 462\n",
      "Loss:  0.034718334674835205\n",
      "Loss:  0.06378860771656036\n",
      "Loss:  0.05006411299109459\n",
      "59 **********\n",
      "Epoch:  4631.510281085968  fold:  4  kers:  128\n",
      "Eval Loss:  0.0879284217953682\n",
      "Eval Loss:  0.06274715811014175\n",
      "Eval Loss:  0.008374905213713646\n",
      "[[3089   48]\n",
      " [ 199   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.42      0.15      0.22       234\n",
      "\n",
      "    accuracy                           0.93      3371\n",
      "   macro avg       0.68      0.57      0.59      3371\n",
      "weighted avg       0.90      0.93      0.91      3371\n",
      "\n",
      "acc:  0.9267279738949866\n",
      "pre:  0.42168674698795183\n",
      "rec:  0.14957264957264957\n",
      "ma F1:  0.5911883047539555\n",
      "mi F1:  0.9267279738949867\n",
      "we F1:  0.9101377675949553\n",
      "update!  Acc:  0.9359240581429843\n",
      "Epoch:  4635.69110250473  fold:  4  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29673 3218\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29673 464\n",
      "Loss:  0.17193324863910675\n",
      "Loss:  0.16839982569217682\n",
      "Loss:  0.15577776730060577\n",
      "0 **********\n",
      "Epoch:  76.71687293052673  fold:  5  kers:  128\n",
      "epoch:  1\n",
      "29673 464\n",
      "Loss:  0.14999152719974518\n",
      "Loss:  0.13915526866912842\n",
      "Loss:  0.1270810216665268\n",
      "1 **********\n",
      "Epoch:  141.1645531654358  fold:  5  kers:  128\n",
      "epoch:  2\n",
      "29673 464\n",
      "Loss:  0.12605085968971252\n",
      "Loss:  0.1122189462184906\n",
      "Loss:  0.10449987649917603\n",
      "2 **********\n",
      "Epoch:  205.59228658676147  fold:  5  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.17413640022277832\n",
      "Eval Loss:  0.33513978123664856\n",
      "Eval Loss:  0.2569580674171448\n",
      "[[2823  274]\n",
      " [  47   74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95      3097\n",
      "           1       0.21      0.61      0.32       121\n",
      "\n",
      "    accuracy                           0.90      3218\n",
      "   macro avg       0.60      0.76      0.63      3218\n",
      "weighted avg       0.95      0.90      0.92      3218\n",
      "\n",
      "acc:  0.9002486016159105\n",
      "pre:  0.21264367816091953\n",
      "rec:  0.6115702479338843\n",
      "ma F1:  0.6308845773288266\n",
      "mi F1:  0.9002486016159105\n",
      "we F1:  0.9224914657531124\n",
      "update!  Acc:  0.9002486016159105\n",
      "Eval Loss:  0.41634202003479004\n",
      "Eval Loss:  0.3975539803504944\n",
      "Eval Loss:  0.43956148624420166\n",
      "Eval Loss:  0.3487124741077423\n",
      "Eval Loss:  0.38338732719421387\n",
      "Eval Loss:  0.43365299701690674\n",
      "Eval Loss:  0.4110284447669983\n",
      "Eval Loss:  0.4692012369632721\n",
      "Eval Loss:  0.41416701674461365\n",
      "Eval Loss:  0.4427388906478882\n",
      "Eval Loss:  0.42091718316078186\n",
      "Eval Loss:  0.6251558065414429\n",
      "Eval Loss:  0.3859628736972809\n",
      "Eval Loss:  0.4654453992843628\n",
      "Eval Loss:  0.35831013321876526\n",
      "Eval Loss:  0.4836692214012146\n",
      "Eval Loss:  0.4116016924381256\n",
      "Eval Loss:  0.4766755700111389\n",
      "Eval Loss:  0.4920218884944916\n",
      "Eval Loss:  0.4497763514518738\n",
      "Eval Loss:  0.40102824568748474\n",
      "Eval Loss:  0.5216753482818604\n",
      "Eval Loss:  0.48449230194091797\n",
      "Eval Loss:  0.3732508718967438\n",
      "Eval Loss:  0.41383102536201477\n",
      "Eval Loss:  0.4410592019557953\n",
      "Eval Loss:  0.4799688160419464\n",
      "Eval Loss:  0.4423162341117859\n",
      "Eval Loss:  0.3651791512966156\n",
      "[[14933  2134]\n",
      " [ 3434  9172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84     17067\n",
      "           1       0.81      0.73      0.77     12606\n",
      "\n",
      "    accuracy                           0.81     29673\n",
      "   macro avg       0.81      0.80      0.81     29673\n",
      "weighted avg       0.81      0.81      0.81     29673\n",
      "\n",
      "acc:  0.8123546658578505\n",
      "pre:  0.8112506633645852\n",
      "rec:  0.7275900364905601\n",
      "ma F1:  0.8050044949484869\n",
      "mi F1:  0.8123546658578505\n",
      "we F1:  0.81069606107011\n",
      "29673 464\n",
      "Loss:  0.10926982015371323\n",
      "Loss:  0.08053406327962875\n",
      "Loss:  0.09542755037546158\n",
      "3 **********\n",
      "Epoch:  310.9226543903351  fold:  5  kers:  128\n",
      "epoch:  4\n",
      "29673 464\n",
      "Loss:  0.08195134252309799\n",
      "Loss:  0.1091485545039177\n",
      "Loss:  0.0965866819024086\n",
      "4 **********\n",
      "Epoch:  375.34540152549744  fold:  5  kers:  128\n",
      "epoch:  5\n",
      "29673 464\n",
      "Loss:  0.09326513111591339\n",
      "Loss:  0.11078000068664551\n",
      "Loss:  0.10453277081251144\n",
      "5 **********\n",
      "Epoch:  440.25185441970825  fold:  5  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.10417404770851135\n",
      "Eval Loss:  0.21860343217849731\n",
      "Eval Loss:  0.10937248170375824\n",
      "[[3018   79]\n",
      " [  44   77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.49      0.64      0.56       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.74      0.81      0.77      3218\n",
      "weighted avg       0.97      0.96      0.96      3218\n",
      "\n",
      "acc:  0.9617775015537601\n",
      "pre:  0.4935897435897436\n",
      "rec:  0.6363636363636364\n",
      "ma F1:  0.7679929521119926\n",
      "mi F1:  0.9617775015537601\n",
      "we F1:  0.9640836760625877\n",
      "update!  Acc:  0.9617775015537601\n",
      "Eval Loss:  0.4127248525619507\n",
      "Eval Loss:  0.3843711316585541\n",
      "Eval Loss:  0.4160767197608948\n",
      "Eval Loss:  0.32497429847717285\n",
      "Eval Loss:  0.41047602891921997\n",
      "Eval Loss:  0.37411627173423767\n",
      "Eval Loss:  0.43153950572013855\n",
      "Eval Loss:  0.40722280740737915\n",
      "Eval Loss:  0.39979633688926697\n",
      "Eval Loss:  0.3977658152580261\n",
      "Eval Loss:  0.433806836605072\n",
      "Eval Loss:  0.6185957789421082\n",
      "Eval Loss:  0.36843833327293396\n",
      "Eval Loss:  0.459225058555603\n",
      "Eval Loss:  0.30552923679351807\n",
      "Eval Loss:  0.47063952684402466\n",
      "Eval Loss:  0.40230876207351685\n",
      "Eval Loss:  0.42645761370658875\n",
      "Eval Loss:  0.5069848299026489\n",
      "Eval Loss:  0.46345055103302\n",
      "Eval Loss:  0.3615514934062958\n",
      "Eval Loss:  0.5565903782844543\n",
      "Eval Loss:  0.5116111040115356\n",
      "Eval Loss:  0.3104662001132965\n",
      "Eval Loss:  0.3768523633480072\n",
      "Eval Loss:  0.42004987597465515\n",
      "Eval Loss:  0.5030524730682373\n",
      "Eval Loss:  0.5441057085990906\n",
      "Eval Loss:  0.3827317953109741\n",
      "[[16129   938]\n",
      " [ 4144  8462]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.86     17067\n",
      "           1       0.90      0.67      0.77     12606\n",
      "\n",
      "    accuracy                           0.83     29673\n",
      "   macro avg       0.85      0.81      0.82     29673\n",
      "weighted avg       0.84      0.83      0.82     29673\n",
      "\n",
      "acc:  0.8287331917905166\n",
      "pre:  0.9002127659574468\n",
      "rec:  0.6712676503252419\n",
      "ma F1:  0.8164811432593175\n",
      "mi F1:  0.8287331917905166\n",
      "we F1:  0.8236099274640494\n",
      "29673 464\n",
      "Loss:  0.09260328859090805\n",
      "Loss:  0.08406919240951538\n",
      "Loss:  0.09818468987941742\n",
      "6 **********\n",
      "Epoch:  545.7497746944427  fold:  5  kers:  128\n",
      "epoch:  7\n",
      "29673 464\n",
      "Loss:  0.13106690347194672\n",
      "Loss:  0.11163633316755295\n",
      "Loss:  0.08615663647651672\n",
      "7 **********\n",
      "Epoch:  610.2602865695953  fold:  5  kers:  128\n",
      "epoch:  8\n",
      "29673 464\n",
      "Loss:  0.10205169022083282\n",
      "Loss:  0.1104794517159462\n",
      "Loss:  0.07964512705802917\n",
      "8 **********\n",
      "Epoch:  674.7129528522491  fold:  5  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.091276615858078\n",
      "Eval Loss:  0.16705097258090973\n",
      "Eval Loss:  0.0652705729007721\n",
      "[[3052   45]\n",
      " [  46   75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.62      0.62      0.62       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.81      0.80      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9717215661901802\n",
      "pre:  0.625\n",
      "rec:  0.6198347107438017\n",
      "ma F1:  0.8038586867337132\n",
      "mi F1:  0.9717215661901802\n",
      "we F1:  0.9716651795998354\n",
      "update!  Acc:  0.9717215661901802\n",
      "Eval Loss:  0.41811591386795044\n",
      "Eval Loss:  0.355266273021698\n",
      "Eval Loss:  0.385771781206131\n",
      "Eval Loss:  0.27666929364204407\n",
      "Eval Loss:  0.44807806611061096\n",
      "Eval Loss:  0.34711796045303345\n",
      "Eval Loss:  0.39568042755126953\n",
      "Eval Loss:  0.35271745920181274\n",
      "Eval Loss:  0.37343481183052063\n",
      "Eval Loss:  0.37840887904167175\n",
      "Eval Loss:  0.4168529212474823\n",
      "Eval Loss:  0.5374106168746948\n",
      "Eval Loss:  0.3338415324687958\n",
      "Eval Loss:  0.4020019769668579\n",
      "Eval Loss:  0.26180577278137207\n",
      "Eval Loss:  0.41255688667297363\n",
      "Eval Loss:  0.4146714210510254\n",
      "Eval Loss:  0.35604730248451233\n",
      "Eval Loss:  0.46620482206344604\n",
      "Eval Loss:  0.3973552882671356\n",
      "Eval Loss:  0.29770687222480774\n",
      "Eval Loss:  0.5332460403442383\n",
      "Eval Loss:  0.44247591495513916\n",
      "Eval Loss:  0.2796823978424072\n",
      "Eval Loss:  0.32171881198883057\n",
      "Eval Loss:  0.3998461365699768\n",
      "Eval Loss:  0.45505809783935547\n",
      "Eval Loss:  0.5044335126876831\n",
      "Eval Loss:  0.3510495126247406\n",
      "[[16429   638]\n",
      " [ 4065  8541]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87     17067\n",
      "           1       0.93      0.68      0.78     12606\n",
      "\n",
      "    accuracy                           0.84     29673\n",
      "   macro avg       0.87      0.82      0.83     29673\n",
      "weighted avg       0.86      0.84      0.84     29673\n",
      "\n",
      "acc:  0.8415057459643447\n",
      "pre:  0.9304935178123979\n",
      "rec:  0.6775345073774394\n",
      "ma F1:  0.8294539265474042\n",
      "mi F1:  0.8415057459643447\n",
      "we F1:  0.8362697437911887\n",
      "29673 464\n",
      "Loss:  0.08491003513336182\n",
      "Loss:  0.07612092792987823\n",
      "Loss:  0.09754642099142075\n",
      "9 **********\n",
      "Epoch:  780.2956464290619  fold:  5  kers:  128\n",
      "epoch:  10\n",
      "29673 464\n",
      "Loss:  0.08377493172883987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08173689246177673\n",
      "Loss:  0.06718982756137848\n",
      "10 **********\n",
      "Epoch:  844.7134065628052  fold:  5  kers:  128\n",
      "epoch:  11\n",
      "29673 464\n",
      "Loss:  0.05970942601561546\n",
      "Loss:  0.10137597471475601\n",
      "Loss:  0.10746455192565918\n",
      "11 **********\n",
      "Epoch:  909.1640787124634  fold:  5  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.07395321130752563\n",
      "Eval Loss:  0.11983022093772888\n",
      "Eval Loss:  0.05187072977423668\n",
      "[[3061   36]\n",
      " [  47   74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.67      0.61      0.64       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.83      0.80      0.81      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9742075823492853\n",
      "pre:  0.6727272727272727\n",
      "rec:  0.6115702479338843\n",
      "ma F1:  0.81365816563238\n",
      "mi F1:  0.9742075823492853\n",
      "we F1:  0.973616339100579\n",
      "update!  Acc:  0.9742075823492853\n",
      "Eval Loss:  0.413000226020813\n",
      "Eval Loss:  0.30359864234924316\n",
      "Eval Loss:  0.3404598832130432\n",
      "Eval Loss:  0.23792417347431183\n",
      "Eval Loss:  0.44821763038635254\n",
      "Eval Loss:  0.2864803671836853\n",
      "Eval Loss:  0.35764992237091064\n",
      "Eval Loss:  0.2809792459011078\n",
      "Eval Loss:  0.30965107679367065\n",
      "Eval Loss:  0.36381328105926514\n",
      "Eval Loss:  0.3555915057659149\n",
      "Eval Loss:  0.44320693612098694\n",
      "Eval Loss:  0.29932481050491333\n",
      "Eval Loss:  0.3711034059524536\n",
      "Eval Loss:  0.21704407036304474\n",
      "Eval Loss:  0.3773653209209442\n",
      "Eval Loss:  0.3984745442867279\n",
      "Eval Loss:  0.31767693161964417\n",
      "Eval Loss:  0.42749637365341187\n",
      "Eval Loss:  0.357703298330307\n",
      "Eval Loss:  0.24686287343502045\n",
      "Eval Loss:  0.44678276777267456\n",
      "Eval Loss:  0.3672597110271454\n",
      "Eval Loss:  0.25322556495666504\n",
      "Eval Loss:  0.330058217048645\n",
      "Eval Loss:  0.34523046016693115\n",
      "Eval Loss:  0.43201571702957153\n",
      "Eval Loss:  0.45900261402130127\n",
      "Eval Loss:  0.3648829758167267\n",
      "[[16399   668]\n",
      " [ 3593  9013]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89     17067\n",
      "           1       0.93      0.71      0.81     12606\n",
      "\n",
      "    accuracy                           0.86     29673\n",
      "   macro avg       0.88      0.84      0.85     29673\n",
      "weighted avg       0.87      0.86      0.85     29673\n",
      "\n",
      "acc:  0.8564014423887035\n",
      "pre:  0.9309988637537444\n",
      "rec:  0.7149769950817071\n",
      "ma F1:  0.8469167472745063\n",
      "mi F1:  0.8564014423887035\n",
      "we F1:  0.8526453182065985\n",
      "29673 464\n",
      "Loss:  0.08240815997123718\n",
      "Loss:  0.09189918637275696\n",
      "Loss:  0.0630321055650711\n",
      "12 **********\n",
      "Epoch:  1014.4425849914551  fold:  5  kers:  128\n",
      "epoch:  13\n",
      "29673 464\n",
      "Loss:  0.0947720855474472\n",
      "Loss:  0.07783906906843185\n",
      "Loss:  0.07722814381122589\n",
      "13 **********\n",
      "Epoch:  1078.8882706165314  fold:  5  kers:  128\n",
      "epoch:  14\n",
      "29673 464\n",
      "Loss:  0.08756639808416367\n",
      "Loss:  0.10720205307006836\n",
      "Loss:  0.08064758777618408\n",
      "14 **********\n",
      "Epoch:  1143.2950596809387  fold:  5  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.0727417841553688\n",
      "Eval Loss:  0.12895047664642334\n",
      "Eval Loss:  0.0517808198928833\n",
      "[[3048   49]\n",
      " [  46   75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.60      0.62      0.61       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.79      0.80      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9704785581106277\n",
      "pre:  0.6048387096774194\n",
      "rec:  0.6198347107438017\n",
      "ma F1:  0.7984500212619372\n",
      "mi F1:  0.9704785581106277\n",
      "we F1:  0.9706521489651673\n",
      "Eval Loss:  0.3260197341442108\n",
      "Eval Loss:  0.24659447371959686\n",
      "Eval Loss:  0.29189634323120117\n",
      "Eval Loss:  0.18782652914524078\n",
      "Eval Loss:  0.3818538784980774\n",
      "Eval Loss:  0.2646791934967041\n",
      "Eval Loss:  0.28927937150001526\n",
      "Eval Loss:  0.21428169310092926\n",
      "Eval Loss:  0.30068492889404297\n",
      "Eval Loss:  0.3289242684841156\n",
      "Eval Loss:  0.30793970823287964\n",
      "Eval Loss:  0.3480185568332672\n",
      "Eval Loss:  0.23754622042179108\n",
      "Eval Loss:  0.31663599610328674\n",
      "Eval Loss:  0.1930728256702423\n",
      "Eval Loss:  0.31991761922836304\n",
      "Eval Loss:  0.3305351138114929\n",
      "Eval Loss:  0.3000256419181824\n",
      "Eval Loss:  0.32233279943466187\n",
      "Eval Loss:  0.2989561855792999\n",
      "Eval Loss:  0.2370789498090744\n",
      "Eval Loss:  0.35317912697792053\n",
      "Eval Loss:  0.28807374835014343\n",
      "Eval Loss:  0.22045809030532837\n",
      "Eval Loss:  0.2899646461009979\n",
      "Eval Loss:  0.2781845033168793\n",
      "Eval Loss:  0.36927157640457153\n",
      "Eval Loss:  0.3717289865016937\n",
      "Eval Loss:  0.30339139699935913\n",
      "[[16167   900]\n",
      " [ 2668  9938]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     17067\n",
      "           1       0.92      0.79      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.87      0.87     29673\n",
      "weighted avg       0.88      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8797560071445422\n",
      "pre:  0.9169588484960325\n",
      "rec:  0.788354751705537\n",
      "ma F1:  0.8742129456639204\n",
      "mi F1:  0.8797560071445422\n",
      "we F1:  0.8781826995995528\n",
      "29673 464\n",
      "Loss:  0.0951329842209816\n",
      "Loss:  0.1073373332619667\n",
      "Loss:  0.062356092035770416\n",
      "15 **********\n",
      "Epoch:  1248.2215077877045  fold:  5  kers:  128\n",
      "epoch:  16\n",
      "29673 464\n",
      "Loss:  0.07605625689029694\n",
      "Loss:  0.10564275830984116\n",
      "Loss:  0.10219091176986694\n",
      "16 **********\n",
      "Epoch:  1312.6472463607788  fold:  5  kers:  128\n",
      "epoch:  17\n",
      "29673 464\n",
      "Loss:  0.11097848415374756\n",
      "Loss:  0.05263429135084152\n",
      "Loss:  0.04955527186393738\n",
      "17 **********\n",
      "Epoch:  1377.0809643268585  fold:  5  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.07230746001005173\n",
      "Eval Loss:  0.11290259659290314\n",
      "Eval Loss:  0.037231314927339554\n",
      "[[3050   47]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.65      0.74      0.69       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.82      0.86      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9754505904288377\n",
      "pre:  0.6544117647058824\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.83991088178045\n",
      "mi F1:  0.9754505904288377\n",
      "we F1:  0.97613721509271\n",
      "update!  Acc:  0.9754505904288377\n",
      "Eval Loss:  0.28996264934539795\n",
      "Eval Loss:  0.21896763145923615\n",
      "Eval Loss:  0.24232131242752075\n",
      "Eval Loss:  0.183481827378273\n",
      "Eval Loss:  0.35851553082466125\n",
      "Eval Loss:  0.24863365292549133\n",
      "Eval Loss:  0.29277679324150085\n",
      "Eval Loss:  0.18345443904399872\n",
      "Eval Loss:  0.29107391834259033\n",
      "Eval Loss:  0.3183468282222748\n",
      "Eval Loss:  0.2921750545501709\n",
      "Eval Loss:  0.3053859770298004\n",
      "Eval Loss:  0.23373255133628845\n",
      "Eval Loss:  0.32284849882125854\n",
      "Eval Loss:  0.1848587542772293\n",
      "Eval Loss:  0.30531105399131775\n",
      "Eval Loss:  0.27970901131629944\n",
      "Eval Loss:  0.32251307368278503\n",
      "Eval Loss:  0.2603147327899933\n",
      "Eval Loss:  0.2819605767726898\n",
      "Eval Loss:  0.21451336145401\n",
      "Eval Loss:  0.27303677797317505\n",
      "Eval Loss:  0.23826166987419128\n",
      "Eval Loss:  0.21006597578525543\n",
      "Eval Loss:  0.31194740533828735\n",
      "Eval Loss:  0.21833892166614532\n",
      "Eval Loss:  0.36983969807624817\n",
      "Eval Loss:  0.34503793716430664\n",
      "Eval Loss:  0.3005360960960388\n",
      "[[15849  1218]\n",
      " [ 1894 10712]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     17067\n",
      "           1       0.90      0.85      0.87     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.89     29673\n",
      "\n",
      "acc:  0.8951235129579078\n",
      "pre:  0.8979044425817267\n",
      "rec:  0.8497540853561796\n",
      "ma F1:  0.8918831812024979\n",
      "mi F1:  0.8951235129579078\n",
      "we F1:  0.8946971037177566\n",
      "29673 464\n",
      "Loss:  0.052027635276317596\n",
      "Loss:  0.07426203042268753\n",
      "Loss:  0.059838008135557175\n",
      "18 **********\n",
      "Epoch:  1482.1969048976898  fold:  5  kers:  128\n",
      "epoch:  19\n",
      "29673 464\n",
      "Loss:  0.07587771862745285\n",
      "Loss:  0.08296266198158264\n",
      "Loss:  0.0648278295993805\n",
      "19 **********\n",
      "Epoch:  1546.6326172351837  fold:  5  kers:  128\n",
      "epoch:  20\n",
      "29673 464\n",
      "Loss:  0.08720731735229492\n",
      "Loss:  0.0635380819439888\n",
      "Loss:  0.07656361907720566\n",
      "20 **********\n",
      "Epoch:  1611.0693266391754  fold:  5  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.06069976091384888\n",
      "Eval Loss:  0.10096351057291031\n",
      "Eval Loss:  0.035447631031274796\n",
      "[[3066   31]\n",
      " [  39   82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.73      0.68      0.70       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.83      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.978247358607831\n",
      "pre:  0.7256637168141593\n",
      "rec:  0.6776859504132231\n",
      "ma F1:  0.8447840095695627\n",
      "mi F1:  0.978247358607831\n",
      "we F1:  0.9778895480205971\n",
      "update!  Acc:  0.978247358607831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3015015125274658\n",
      "Eval Loss:  0.21197518706321716\n",
      "Eval Loss:  0.2547149658203125\n",
      "Eval Loss:  0.18011148273944855\n",
      "Eval Loss:  0.3613913655281067\n",
      "Eval Loss:  0.25128236413002014\n",
      "Eval Loss:  0.29257047176361084\n",
      "Eval Loss:  0.17667868733406067\n",
      "Eval Loss:  0.2979525029659271\n",
      "Eval Loss:  0.2946125566959381\n",
      "Eval Loss:  0.32435527443885803\n",
      "Eval Loss:  0.3236149847507477\n",
      "Eval Loss:  0.18852193653583527\n",
      "Eval Loss:  0.3474869728088379\n",
      "Eval Loss:  0.16864317655563354\n",
      "Eval Loss:  0.30180835723876953\n",
      "Eval Loss:  0.2747001647949219\n",
      "Eval Loss:  0.23944257199764252\n",
      "Eval Loss:  0.2943688929080963\n",
      "Eval Loss:  0.24643710255622864\n",
      "Eval Loss:  0.2120523899793625\n",
      "Eval Loss:  0.2726016938686371\n",
      "Eval Loss:  0.23733894526958466\n",
      "Eval Loss:  0.19697214663028717\n",
      "Eval Loss:  0.2844790518283844\n",
      "Eval Loss:  0.21775321662425995\n",
      "Eval Loss:  0.35661765933036804\n",
      "Eval Loss:  0.37585312128067017\n",
      "Eval Loss:  0.2796497046947479\n",
      "[[16233   834]\n",
      " [ 2260 10346]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     17067\n",
      "           1       0.93      0.82      0.87     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.89     29673\n",
      "\n",
      "acc:  0.8957301250294881\n",
      "pre:  0.9254025044722719\n",
      "rec:  0.8207202919244804\n",
      "ma F1:  0.8914578051934208\n",
      "mi F1:  0.8957301250294881\n",
      "we F1:  0.8946952468086231\n",
      "29673 464\n",
      "Loss:  0.0528297945857048\n",
      "Loss:  0.0791095495223999\n",
      "Loss:  0.07388144731521606\n",
      "21 **********\n",
      "Epoch:  1716.147369146347  fold:  5  kers:  128\n",
      "epoch:  22\n",
      "29673 464\n",
      "Loss:  0.07533065974712372\n",
      "Loss:  0.07191047072410583\n",
      "Loss:  0.10103514790534973\n",
      "22 **********\n",
      "Epoch:  1780.565129518509  fold:  5  kers:  128\n",
      "epoch:  23\n",
      "29673 464\n",
      "Loss:  0.0775311216711998\n",
      "Loss:  0.044373031705617905\n",
      "Loss:  0.05880195274949074\n",
      "23 **********\n",
      "Epoch:  1845.0247776508331  fold:  5  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.07132411003112793\n",
      "Eval Loss:  0.07565340399742126\n",
      "Eval Loss:  0.035016365349292755\n",
      "[[3058   39]\n",
      " [  43   78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.67      0.64      0.66       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.83      0.82      0.82      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9745183343691733\n",
      "pre:  0.6666666666666666\n",
      "rec:  0.6446280991735537\n",
      "ma F1:  0.82111605532823\n",
      "mi F1:  0.9745183343691733\n",
      "we F1:  0.9743124252697896\n",
      "Eval Loss:  0.25073885917663574\n",
      "Eval Loss:  0.18975505232810974\n",
      "Eval Loss:  0.24558834731578827\n",
      "Eval Loss:  0.15585657954216003\n",
      "Eval Loss:  0.3335557281970978\n",
      "Eval Loss:  0.22003819048404694\n",
      "Eval Loss:  0.28552404046058655\n",
      "Eval Loss:  0.16611310839653015\n",
      "Eval Loss:  0.30582594871520996\n",
      "Eval Loss:  0.27242040634155273\n",
      "Eval Loss:  0.2868575155735016\n",
      "Eval Loss:  0.2820173501968384\n",
      "Eval Loss:  0.17085179686546326\n",
      "Eval Loss:  0.2973756790161133\n",
      "Eval Loss:  0.14772166311740875\n",
      "Eval Loss:  0.2585303485393524\n",
      "Eval Loss:  0.25766801834106445\n",
      "Eval Loss:  0.24712564051151276\n",
      "Eval Loss:  0.254898339509964\n",
      "Eval Loss:  0.2197355180978775\n",
      "Eval Loss:  0.19857195019721985\n",
      "Eval Loss:  0.2293386161327362\n",
      "Eval Loss:  0.20097191631793976\n",
      "Eval Loss:  0.18071433901786804\n",
      "Eval Loss:  0.2597777843475342\n",
      "Eval Loss:  0.20453569293022156\n",
      "Eval Loss:  0.31222406029701233\n",
      "Eval Loss:  0.33781930804252625\n",
      "Eval Loss:  0.2369900643825531\n",
      "[[16150   917]\n",
      " [ 1894 10712]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17067\n",
      "           1       0.92      0.85      0.88     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.90     29673\n",
      "weighted avg       0.91      0.91      0.90     29673\n",
      "\n",
      "acc:  0.9052674148215549\n",
      "pre:  0.9211454123312408\n",
      "rec:  0.8497540853561796\n",
      "ma F1:  0.9019751741738131\n",
      "mi F1:  0.9052674148215549\n",
      "we F1:  0.9046759254664899\n",
      "29673 464\n",
      "Loss:  0.06759733706712723\n",
      "Loss:  0.08899803459644318\n",
      "Loss:  0.049199894070625305\n",
      "24 **********\n",
      "Epoch:  1949.955215215683  fold:  5  kers:  128\n",
      "epoch:  25\n",
      "29673 464\n",
      "Loss:  0.08879224210977554\n",
      "Loss:  0.06682267040014267\n",
      "Loss:  0.09977997839450836\n",
      "25 **********\n",
      "Epoch:  2014.3610062599182  fold:  5  kers:  128\n",
      "epoch:  26\n",
      "29673 464\n",
      "Loss:  0.06252415478229523\n",
      "Loss:  0.0639057457447052\n",
      "Loss:  0.10391644388437271\n",
      "26 **********\n",
      "Epoch:  2078.7747774124146  fold:  5  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.05682448297739029\n",
      "Eval Loss:  0.11057578027248383\n",
      "Eval Loss:  0.04600290209054947\n",
      "[[3060   37]\n",
      " [  37   84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.69      0.69      0.69       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.84      0.84      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9770043505282784\n",
      "pre:  0.6942148760330579\n",
      "rec:  0.6942148760330579\n",
      "ma F1:  0.8411339152525639\n",
      "mi F1:  0.9770043505282784\n",
      "we F1:  0.9770043505282784\n",
      "Eval Loss:  0.21831899881362915\n",
      "Eval Loss:  0.1847754269838333\n",
      "Eval Loss:  0.23189373314380646\n",
      "Eval Loss:  0.18872711062431335\n",
      "Eval Loss:  0.30454158782958984\n",
      "Eval Loss:  0.21679635345935822\n",
      "Eval Loss:  0.2622257471084595\n",
      "Eval Loss:  0.14871513843536377\n",
      "Eval Loss:  0.2721133828163147\n",
      "Eval Loss:  0.2620861232280731\n",
      "Eval Loss:  0.2887263596057892\n",
      "Eval Loss:  0.28322574496269226\n",
      "Eval Loss:  0.17022627592086792\n",
      "Eval Loss:  0.2918204367160797\n",
      "Eval Loss:  0.14692769944667816\n",
      "Eval Loss:  0.2543647885322571\n",
      "Eval Loss:  0.22951242327690125\n",
      "Eval Loss:  0.25154122710227966\n",
      "Eval Loss:  0.24198602139949799\n",
      "Eval Loss:  0.1997004747390747\n",
      "Eval Loss:  0.17970427870750427\n",
      "Eval Loss:  0.21427099406719208\n",
      "Eval Loss:  0.21917681396007538\n",
      "Eval Loss:  0.18066257238388062\n",
      "Eval Loss:  0.28483590483665466\n",
      "Eval Loss:  0.18013767898082733\n",
      "Eval Loss:  0.33676642179489136\n",
      "Eval Loss:  0.3287924528121948\n",
      "Eval Loss:  0.27422913908958435\n",
      "[[15894  1173]\n",
      " [ 1566 11040]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     17067\n",
      "           1       0.90      0.88      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9076938631078758\n",
      "pre:  0.903954802259887\n",
      "rec:  0.8757734412184673\n",
      "ma F1:  0.9051558901180843\n",
      "mi F1:  0.9076938631078758\n",
      "we F1:  0.9074883782737209\n",
      "29673 464\n",
      "Loss:  0.04188958555459976\n",
      "Loss:  0.11714396625757217\n",
      "Loss:  0.053975820541381836\n",
      "27 **********\n",
      "Epoch:  2183.751092195511  fold:  5  kers:  128\n",
      "epoch:  28\n",
      "29673 464\n",
      "Loss:  0.0501834973692894\n",
      "Loss:  0.07357168942689896\n",
      "Loss:  0.04996197670698166\n",
      "28 **********\n",
      "Epoch:  2248.180820465088  fold:  5  kers:  128\n",
      "epoch:  29\n",
      "29673 464\n",
      "Loss:  0.040190741419792175\n",
      "Loss:  0.062250956892967224\n",
      "Loss:  0.0753672793507576\n",
      "29 **********\n",
      "Epoch:  2312.6145374774933  fold:  5  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.059577133506536484\n",
      "Eval Loss:  0.08487292379140854\n",
      "Eval Loss:  0.030709099024534225\n",
      "[[3077   20]\n",
      " [  54   67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.77      0.55      0.64       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.77      0.82      3218\n",
      "weighted avg       0.97      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9770043505282784\n",
      "pre:  0.7701149425287356\n",
      "rec:  0.5537190082644629\n",
      "ma F1:  0.8161744726051084\n",
      "mi F1:  0.9770043505282784\n",
      "we F1:  0.9751876675218372\n",
      "Eval Loss:  0.24662046134471893\n",
      "Eval Loss:  0.18159404397010803\n",
      "Eval Loss:  0.24613285064697266\n",
      "Eval Loss:  0.1811775416135788\n",
      "Eval Loss:  0.2833293378353119\n",
      "Eval Loss:  0.24374298751354218\n",
      "Eval Loss:  0.25613927841186523\n",
      "Eval Loss:  0.1551072746515274\n",
      "Eval Loss:  0.2669697701931\n",
      "Eval Loss:  0.26995328068733215\n",
      "Eval Loss:  0.26656433939933777\n",
      "Eval Loss:  0.2622048854827881\n",
      "Eval Loss:  0.17368891835212708\n",
      "Eval Loss:  0.27705442905426025\n",
      "Eval Loss:  0.13972947001457214\n",
      "Eval Loss:  0.24853944778442383\n",
      "Eval Loss:  0.2363964319229126\n",
      "Eval Loss:  0.21375589072704315\n",
      "Eval Loss:  0.23934584856033325\n",
      "Eval Loss:  0.21272756159305573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18592862784862518\n",
      "Eval Loss:  0.22291390597820282\n",
      "Eval Loss:  0.20122838020324707\n",
      "Eval Loss:  0.17513763904571533\n",
      "Eval Loss:  0.2656715512275696\n",
      "Eval Loss:  0.19572769105434418\n",
      "Eval Loss:  0.30303263664245605\n",
      "Eval Loss:  0.3049125671386719\n",
      "Eval Loss:  0.2630602717399597\n",
      "[[16209   858]\n",
      " [ 1888 10718]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17067\n",
      "           1       0.93      0.85      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.90     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9074579584133724\n",
      "pre:  0.9258811333794057\n",
      "rec:  0.8502300491829288\n",
      "ma F1:  0.9041766165784417\n",
      "mi F1:  0.9074579584133724\n",
      "we F1:  0.9068424453756783\n",
      "29673 464\n",
      "Loss:  0.08466839045286179\n",
      "Loss:  0.062414802610874176\n",
      "Loss:  0.06834473460912704\n",
      "30 **********\n",
      "Epoch:  2417.655678510666  fold:  5  kers:  128\n",
      "epoch:  31\n",
      "29673 464\n",
      "Loss:  0.08519969880580902\n",
      "Loss:  0.07965961843729019\n",
      "Loss:  0.05803830549120903\n",
      "31 **********\n",
      "Epoch:  2482.063465118408  fold:  5  kers:  128\n",
      "epoch:  32\n",
      "29673 464\n",
      "Loss:  0.05650654435157776\n",
      "Loss:  0.061069514602422714\n",
      "Loss:  0.0613492950797081\n",
      "32 **********\n",
      "Epoch:  2546.516131877899  fold:  5  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.06325539946556091\n",
      "Eval Loss:  0.05342560634016991\n",
      "Eval Loss:  0.035427309572696686\n",
      "[[3070   27]\n",
      " [  39   82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.75      0.68      0.71       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.83      0.85      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9794903666873834\n",
      "pre:  0.7522935779816514\n",
      "rec:  0.6776859504132231\n",
      "ma F1:  0.8512043043898612\n",
      "mi F1:  0.9794903666873834\n",
      "we F1:  0.9789751616179154\n",
      "update!  Acc:  0.9794903666873834\n",
      "Eval Loss:  0.24248233437538147\n",
      "Eval Loss:  0.1489647626876831\n",
      "Eval Loss:  0.21748320758342743\n",
      "Eval Loss:  0.16086366772651672\n",
      "Eval Loss:  0.3013764023780823\n",
      "Eval Loss:  0.2155918926000595\n",
      "Eval Loss:  0.25123050808906555\n",
      "Eval Loss:  0.13526247441768646\n",
      "Eval Loss:  0.2781582474708557\n",
      "Eval Loss:  0.25946569442749023\n",
      "Eval Loss:  0.2657110095024109\n",
      "Eval Loss:  0.27263975143432617\n",
      "Eval Loss:  0.17009340226650238\n",
      "Eval Loss:  0.2887965440750122\n",
      "Eval Loss:  0.12620912492275238\n",
      "Eval Loss:  0.25519078969955444\n",
      "Eval Loss:  0.23516543209552765\n",
      "Eval Loss:  0.19412387907505035\n",
      "Eval Loss:  0.22916936874389648\n",
      "Eval Loss:  0.20509038865566254\n",
      "Eval Loss:  0.17831987142562866\n",
      "Eval Loss:  0.21610823273658752\n",
      "Eval Loss:  0.18998731672763824\n",
      "Eval Loss:  0.1779152750968933\n",
      "Eval Loss:  0.2847100794315338\n",
      "Eval Loss:  0.17030102014541626\n",
      "Eval Loss:  0.2781437337398529\n",
      "Eval Loss:  0.3155498504638672\n",
      "Eval Loss:  0.259769082069397\n",
      "[[16209   858]\n",
      " [ 1802 10804]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17067\n",
      "           1       0.93      0.86      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9103562160887002\n",
      "pre:  0.9264277139427199\n",
      "rec:  0.8570521973663335\n",
      "ma F1:  0.9072798163443013\n",
      "mi F1:  0.9103562160887002\n",
      "we F1:  0.9098189133396322\n",
      "29673 464\n",
      "Loss:  0.05650687962770462\n",
      "Loss:  0.05414973944425583\n",
      "Loss:  0.06435099989175797\n",
      "33 **********\n",
      "Epoch:  2651.4226331710815  fold:  5  kers:  128\n",
      "epoch:  34\n",
      "29673 464\n",
      "Loss:  0.07826857268810272\n",
      "Loss:  0.08410344272851944\n",
      "Loss:  0.060401640832424164\n",
      "34 **********\n",
      "Epoch:  2715.832414150238  fold:  5  kers:  128\n",
      "epoch:  35\n",
      "29673 464\n",
      "Loss:  0.10552570968866348\n",
      "Loss:  0.05687391385436058\n",
      "Loss:  0.026952004060149193\n",
      "35 **********\n",
      "Epoch:  2780.2781002521515  fold:  5  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.0848078578710556\n",
      "Eval Loss:  0.20162825286388397\n",
      "Eval Loss:  0.06337624043226242\n",
      "[[2979  118]\n",
      " [  14  107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      3097\n",
      "           1       0.48      0.88      0.62       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.74      0.92      0.80      3218\n",
      "weighted avg       0.98      0.96      0.96      3218\n",
      "\n",
      "acc:  0.958980733374767\n",
      "pre:  0.47555555555555556\n",
      "rec:  0.8842975206611571\n",
      "ma F1:  0.7984111164896495\n",
      "mi F1:  0.958980733374767\n",
      "we F1:  0.964795232036345\n",
      "Eval Loss:  0.20626473426818848\n",
      "Eval Loss:  0.21761822700500488\n",
      "Eval Loss:  0.23474949598312378\n",
      "Eval Loss:  0.20284287631511688\n",
      "Eval Loss:  0.317055881023407\n",
      "Eval Loss:  0.2701399028301239\n",
      "Eval Loss:  0.2726326882839203\n",
      "Eval Loss:  0.24140174686908722\n",
      "Eval Loss:  0.30901938676834106\n",
      "Eval Loss:  0.2857341170310974\n",
      "Eval Loss:  0.3196248710155487\n",
      "Eval Loss:  0.3237907290458679\n",
      "Eval Loss:  0.22444428503513336\n",
      "Eval Loss:  0.27559712529182434\n",
      "Eval Loss:  0.1698606014251709\n",
      "Eval Loss:  0.3062010407447815\n",
      "Eval Loss:  0.23101341724395752\n",
      "Eval Loss:  0.3213571310043335\n",
      "Eval Loss:  0.2385997623205185\n",
      "Eval Loss:  0.24109265208244324\n",
      "Eval Loss:  0.22967681288719177\n",
      "Eval Loss:  0.2520773708820343\n",
      "Eval Loss:  0.2152356505393982\n",
      "Eval Loss:  0.20724189281463623\n",
      "Eval Loss:  0.3630112111568451\n",
      "Eval Loss:  0.21813295781612396\n",
      "Eval Loss:  0.32706475257873535\n",
      "Eval Loss:  0.24816641211509705\n",
      "Eval Loss:  0.3172493577003479\n",
      "[[14677  2390]\n",
      " [  737 11869]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90     17067\n",
      "           1       0.83      0.94      0.88     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.90      0.89     29673\n",
      "weighted avg       0.90      0.89      0.90     29673\n",
      "\n",
      "acc:  0.8946180028982577\n",
      "pre:  0.8323865628725717\n",
      "rec:  0.9415357766143106\n",
      "ma F1:  0.8936657673392052\n",
      "mi F1:  0.8946180028982577\n",
      "we F1:  0.8951785603694521\n",
      "29673 464\n",
      "Loss:  0.07875367999076843\n",
      "Loss:  0.0667242556810379\n",
      "Loss:  0.03647807240486145\n",
      "36 **********\n",
      "Epoch:  2885.139720916748  fold:  5  kers:  128\n",
      "epoch:  37\n",
      "29673 464\n",
      "Loss:  0.03633185476064682\n",
      "Loss:  0.08097358793020248\n",
      "Loss:  0.07035306096076965\n",
      "37 **********\n",
      "Epoch:  2949.5604734420776  fold:  5  kers:  128\n",
      "epoch:  38\n",
      "29673 464\n",
      "Loss:  0.04496372491121292\n",
      "Loss:  0.058398231863975525\n",
      "Loss:  0.059403665363788605\n",
      "38 **********\n",
      "Epoch:  3014.0041642189026  fold:  5  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.061074838042259216\n",
      "Eval Loss:  0.10831230878829956\n",
      "Eval Loss:  0.03439989313483238\n",
      "[[3064   33]\n",
      " [  23   98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.75      0.81      0.78       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.90      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9825978868862648\n",
      "pre:  0.7480916030534351\n",
      "rec:  0.8099173553719008\n",
      "ma F1:  0.8843610751760816\n",
      "mi F1:  0.9825978868862648\n",
      "we F1:  0.9829290966357935\n",
      "update!  Acc:  0.9825978868862648\n",
      "Eval Loss:  0.18770547211170197\n",
      "Eval Loss:  0.16515077650547028\n",
      "Eval Loss:  0.22090595960617065\n",
      "Eval Loss:  0.1459326297044754\n",
      "Eval Loss:  0.300893098115921\n",
      "Eval Loss:  0.22520610690116882\n",
      "Eval Loss:  0.25862354040145874\n",
      "Eval Loss:  0.1519620269536972\n",
      "Eval Loss:  0.2655431032180786\n",
      "Eval Loss:  0.22427120804786682\n",
      "Eval Loss:  0.28398382663726807\n",
      "Eval Loss:  0.27189013361930847\n",
      "Eval Loss:  0.15176938474178314\n",
      "Eval Loss:  0.2590075731277466\n",
      "Eval Loss:  0.135110005736351\n",
      "Eval Loss:  0.23255254328250885\n",
      "Eval Loss:  0.20775307714939117\n",
      "Eval Loss:  0.1953805387020111\n",
      "Eval Loss:  0.22117626667022705\n",
      "Eval Loss:  0.2038584202528\n",
      "Eval Loss:  0.17996545135974884\n",
      "Eval Loss:  0.19421575963497162\n",
      "Eval Loss:  0.17670662701129913\n",
      "Eval Loss:  0.17524462938308716\n",
      "Eval Loss:  0.2765415608882904\n",
      "Eval Loss:  0.16527880728244781\n",
      "Eval Loss:  0.265974760055542\n",
      "Eval Loss:  0.25894731283187866\n",
      "Eval Loss:  0.25812429189682007\n",
      "[[15703  1364]\n",
      " [ 1195 11411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     17067\n",
      "           1       0.89      0.91      0.90     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.91      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9137599838236781\n",
      "pre:  0.8932289628180039\n",
      "rec:  0.9052038711724576\n",
      "ma F1:  0.9119171426459722\n",
      "mi F1:  0.9137599838236781\n",
      "we F1:  0.9138325467684665\n",
      "29673 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.02750796265900135\n",
      "Loss:  0.03304331749677658\n",
      "Loss:  0.054711975157260895\n",
      "39 **********\n",
      "Epoch:  3119.101155757904  fold:  5  kers:  128\n",
      "epoch:  40\n",
      "29673 464\n",
      "Loss:  0.03164683282375336\n",
      "Loss:  0.07856515049934387\n",
      "Loss:  0.03206290677189827\n",
      "40 **********\n",
      "Epoch:  3183.5129318237305  fold:  5  kers:  128\n",
      "epoch:  41\n",
      "29673 464\n",
      "Loss:  0.07189290225505829\n",
      "Loss:  0.07014140486717224\n",
      "Loss:  0.0905839055776596\n",
      "41 **********\n",
      "Epoch:  3247.956622362137  fold:  5  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.06251661479473114\n",
      "Eval Loss:  0.0681745782494545\n",
      "Eval Loss:  0.026620477437973022\n",
      "[[3070   27]\n",
      " [  36   85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.76      0.70      0.73       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.85      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9804226227470478\n",
      "pre:  0.7589285714285714\n",
      "rec:  0.7024793388429752\n",
      "ma F1:  0.8597286789792284\n",
      "mi F1:  0.9804226227470478\n",
      "we F1:  0.9800587214090544\n",
      "Eval Loss:  0.2269606590270996\n",
      "Eval Loss:  0.16532284021377563\n",
      "Eval Loss:  0.1977796107530594\n",
      "Eval Loss:  0.14039593935012817\n",
      "Eval Loss:  0.3192562758922577\n",
      "Eval Loss:  0.20575441420078278\n",
      "Eval Loss:  0.2710832357406616\n",
      "Eval Loss:  0.14952141046524048\n",
      "Eval Loss:  0.23346425592899323\n",
      "Eval Loss:  0.24950356781482697\n",
      "Eval Loss:  0.27343374490737915\n",
      "Eval Loss:  0.24796706438064575\n",
      "Eval Loss:  0.19596152007579803\n",
      "Eval Loss:  0.25040048360824585\n",
      "Eval Loss:  0.12458743900060654\n",
      "Eval Loss:  0.2211303859949112\n",
      "Eval Loss:  0.21383967995643616\n",
      "Eval Loss:  0.20006480813026428\n",
      "Eval Loss:  0.22889591753482819\n",
      "Eval Loss:  0.21690960228443146\n",
      "Eval Loss:  0.17085321247577667\n",
      "Eval Loss:  0.1999974250793457\n",
      "Eval Loss:  0.15067505836486816\n",
      "Eval Loss:  0.2047232836484909\n",
      "Eval Loss:  0.2804006338119507\n",
      "Eval Loss:  0.1576249897480011\n",
      "Eval Loss:  0.2569108307361603\n",
      "Eval Loss:  0.21931825578212738\n",
      "Eval Loss:  0.2682770788669586\n",
      "[[15743  1324]\n",
      " [ 1194 11412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     17067\n",
      "           1       0.90      0.91      0.90     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.91      0.91      0.91     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9151417113200553\n",
      "pre:  0.8960427135678392\n",
      "rec:  0.9052831984769157\n",
      "ma F1:  0.9132945716200773\n",
      "mi F1:  0.9151417113200554\n",
      "we F1:  0.9151971553655407\n",
      "29673 464\n",
      "Loss:  0.07355266064405441\n",
      "Loss:  0.05445272475481033\n",
      "Loss:  0.083033986389637\n",
      "42 **********\n",
      "Epoch:  3352.918974876404  fold:  5  kers:  128\n",
      "epoch:  43\n",
      "29673 464\n",
      "Loss:  0.04866106063127518\n",
      "Loss:  0.04757042974233627\n",
      "Loss:  0.047466401010751724\n",
      "43 **********\n",
      "Epoch:  3417.3357367515564  fold:  5  kers:  128\n",
      "epoch:  44\n",
      "29673 464\n",
      "Loss:  0.0725642740726471\n",
      "Loss:  0.06033065542578697\n",
      "Loss:  0.0727243721485138\n",
      "44 **********\n",
      "Epoch:  3481.8193209171295  fold:  5  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.06986113637685776\n",
      "Eval Loss:  0.061525002121925354\n",
      "Eval Loss:  0.04570671170949936\n",
      "[[3053   44]\n",
      " [  23   98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.69      0.81      0.75       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.84      0.90      0.87      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9791796146674954\n",
      "pre:  0.6901408450704225\n",
      "rec:  0.8099173553719008\n",
      "ma F1:  0.8671967152428182\n",
      "mi F1:  0.9791796146674954\n",
      "we F1:  0.9799754322268586\n",
      "Eval Loss:  0.16831117868423462\n",
      "Eval Loss:  0.13565632700920105\n",
      "Eval Loss:  0.20322935283184052\n",
      "Eval Loss:  0.16500210762023926\n",
      "Eval Loss:  0.2782656252384186\n",
      "Eval Loss:  0.16767147183418274\n",
      "Eval Loss:  0.23008772730827332\n",
      "Eval Loss:  0.14423586428165436\n",
      "Eval Loss:  0.24843549728393555\n",
      "Eval Loss:  0.20112767815589905\n",
      "Eval Loss:  0.29092898964881897\n",
      "Eval Loss:  0.24218414723873138\n",
      "Eval Loss:  0.15530215203762054\n",
      "Eval Loss:  0.2559511661529541\n",
      "Eval Loss:  0.11128953844308853\n",
      "Eval Loss:  0.2536388039588928\n",
      "Eval Loss:  0.17927654087543488\n",
      "Eval Loss:  0.20614542067050934\n",
      "Eval Loss:  0.2208118885755539\n",
      "Eval Loss:  0.1814480721950531\n",
      "Eval Loss:  0.1689690500497818\n",
      "Eval Loss:  0.18337096273899078\n",
      "Eval Loss:  0.13691358268260956\n",
      "Eval Loss:  0.167686328291893\n",
      "Eval Loss:  0.25069335103034973\n",
      "Eval Loss:  0.14010809361934662\n",
      "Eval Loss:  0.21191096305847168\n",
      "Eval Loss:  0.22954080998897552\n",
      "Eval Loss:  0.2520226538181305\n",
      "[[15637  1430]\n",
      " [  965 11641]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     17067\n",
      "           1       0.89      0.92      0.91     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.92      0.92     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9192868938091868\n",
      "pre:  0.8905975059291561\n",
      "rec:  0.9234491511978423\n",
      "ma F1:  0.9177960899046289\n",
      "mi F1:  0.9192868938091868\n",
      "we F1:  0.919460373242525\n",
      "29673 464\n",
      "Loss:  0.04828309267759323\n",
      "Loss:  0.039632923901081085\n",
      "Loss:  0.04755619168281555\n",
      "45 **********\n",
      "Epoch:  3586.7846653461456  fold:  5  kers:  128\n",
      "epoch:  46\n",
      "29673 464\n",
      "Loss:  0.07053934782743454\n",
      "Loss:  0.05947905033826828\n",
      "Loss:  0.04522940143942833\n",
      "46 **********\n",
      "Epoch:  3651.22935295105  fold:  5  kers:  128\n",
      "epoch:  47\n",
      "29673 464\n",
      "Loss:  0.0677899420261383\n",
      "Loss:  0.055024534463882446\n",
      "Loss:  0.054029207676649094\n",
      "47 **********\n",
      "Epoch:  3715.6660628318787  fold:  5  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.0582747720181942\n",
      "Eval Loss:  0.04351259022951126\n",
      "Eval Loss:  0.025824211537837982\n",
      "[[3077   20]\n",
      " [  40   81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.80      0.67      0.73       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.89      0.83      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9813548788067122\n",
      "pre:  0.801980198019802\n",
      "rec:  0.6694214876033058\n",
      "ma F1:  0.8600370566897764\n",
      "mi F1:  0.9813548788067122\n",
      "we F1:  0.9805450135055312\n",
      "Eval Loss:  0.21740706264972687\n",
      "Eval Loss:  0.16928496956825256\n",
      "Eval Loss:  0.23278866708278656\n",
      "Eval Loss:  0.1459755152463913\n",
      "Eval Loss:  0.2849392890930176\n",
      "Eval Loss:  0.16480889916419983\n",
      "Eval Loss:  0.26490163803100586\n",
      "Eval Loss:  0.11296546459197998\n",
      "Eval Loss:  0.2376435399055481\n",
      "Eval Loss:  0.22473043203353882\n",
      "Eval Loss:  0.2553477883338928\n",
      "Eval Loss:  0.2217661440372467\n",
      "Eval Loss:  0.1575000286102295\n",
      "Eval Loss:  0.2850649058818817\n",
      "Eval Loss:  0.14590144157409668\n",
      "Eval Loss:  0.22510366141796112\n",
      "Eval Loss:  0.21472808718681335\n",
      "Eval Loss:  0.1895247846841812\n",
      "Eval Loss:  0.25619760155677795\n",
      "Eval Loss:  0.20060667395591736\n",
      "Eval Loss:  0.13277141749858856\n",
      "Eval Loss:  0.19280649721622467\n",
      "Eval Loss:  0.142977774143219\n",
      "Eval Loss:  0.16834546625614166\n",
      "Eval Loss:  0.21654540300369263\n",
      "Eval Loss:  0.15464496612548828\n",
      "Eval Loss:  0.24615660309791565\n",
      "Eval Loss:  0.25684648752212524\n",
      "Eval Loss:  0.2540493309497833\n",
      "[[16348   719]\n",
      " [ 1691 10915]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     17067\n",
      "           1       0.94      0.87      0.90     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.91      0.92     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9187813837495367\n",
      "pre:  0.9381983840467595\n",
      "rec:  0.8658575281611931\n",
      "ma F1:  0.9159641620032795\n",
      "mi F1:  0.9187813837495367\n",
      "we F1:  0.9182773639561698\n",
      "29673 464\n",
      "Loss:  0.06699884682893753\n",
      "Loss:  0.07342518866062164\n",
      "Loss:  0.05548323690891266\n",
      "48 **********\n",
      "Epoch:  3820.7341315746307  fold:  5  kers:  128\n",
      "epoch:  49\n",
      "29673 464\n",
      "Loss:  0.042904287576675415\n",
      "Loss:  0.08725908398628235\n",
      "Loss:  0.03653421625494957\n",
      "49 **********\n",
      "Epoch:  3885.14989733696  fold:  5  kers:  128\n",
      "epoch:  50\n",
      "29673 464\n",
      "Loss:  0.05857875570654869\n",
      "Loss:  0.08849513530731201\n",
      "Loss:  0.0743170902132988\n",
      "50 **********\n",
      "Epoch:  3949.593587398529  fold:  5  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.07819224894046783\n",
      "Eval Loss:  0.08940350264310837\n",
      "Eval Loss:  0.06698262691497803\n",
      "[[3041   56]\n",
      " [  24   97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.63      0.80      0.71       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.81      0.89      0.85      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9751398384089497\n",
      "pre:  0.6339869281045751\n",
      "rec:  0.8016528925619835\n",
      "ma F1:  0.8475231996436838\n",
      "mi F1:  0.9751398384089497\n",
      "we F1:  0.976526975786833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18181930482387543\n",
      "Eval Loss:  0.14845669269561768\n",
      "Eval Loss:  0.2004585713148117\n",
      "Eval Loss:  0.18464921414852142\n",
      "Eval Loss:  0.2840721607208252\n",
      "Eval Loss:  0.21916525065898895\n",
      "Eval Loss:  0.22726622223854065\n",
      "Eval Loss:  0.16301816701889038\n",
      "Eval Loss:  0.2647612988948822\n",
      "Eval Loss:  0.21024726331233978\n",
      "Eval Loss:  0.24213461577892303\n",
      "Eval Loss:  0.2572278082370758\n",
      "Eval Loss:  0.1687338948249817\n",
      "Eval Loss:  0.2647148370742798\n",
      "Eval Loss:  0.1251736730337143\n",
      "Eval Loss:  0.24926690757274628\n",
      "Eval Loss:  0.1927228718996048\n",
      "Eval Loss:  0.21175584197044373\n",
      "Eval Loss:  0.21750381588935852\n",
      "Eval Loss:  0.20924139022827148\n",
      "Eval Loss:  0.2024998813867569\n",
      "Eval Loss:  0.18235090374946594\n",
      "Eval Loss:  0.15236355364322662\n",
      "Eval Loss:  0.18459178507328033\n",
      "Eval Loss:  0.26476621627807617\n",
      "Eval Loss:  0.16280212998390198\n",
      "Eval Loss:  0.20222459733486176\n",
      "Eval Loss:  0.20091846585273743\n",
      "Eval Loss:  0.28973525762557983\n",
      "[[15455  1612]\n",
      " [  887 11719]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93     17067\n",
      "           1       0.88      0.93      0.90     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.91      0.92      0.91     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9157820240622788\n",
      "pre:  0.8790788387967894\n",
      "rec:  0.9296366809455815\n",
      "ma F1:  0.9144254755915431\n",
      "mi F1:  0.9157820240622787\n",
      "we F1:  0.9160452728955989\n",
      "29673 464\n",
      "Loss:  0.05039936676621437\n",
      "Loss:  0.08525687456130981\n",
      "Loss:  0.05803363397717476\n",
      "51 **********\n",
      "Epoch:  4054.805273294449  fold:  5  kers:  128\n",
      "epoch:  52\n",
      "29673 464\n",
      "Loss:  0.0474192276597023\n",
      "Loss:  0.04435182362794876\n",
      "Loss:  0.07475001364946365\n",
      "52 **********\n",
      "Epoch:  4119.2240307331085  fold:  5  kers:  128\n",
      "epoch:  53\n",
      "29673 464\n",
      "Loss:  0.07220936566591263\n",
      "Loss:  0.06760009378194809\n",
      "Loss:  0.03199245408177376\n",
      "53 **********\n",
      "Epoch:  4185.547694683075  fold:  5  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.05979519337415695\n",
      "Eval Loss:  0.07800754904747009\n",
      "Eval Loss:  0.04387907683849335\n",
      "[[3065   32]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.73      0.73      0.73       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.86      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9798011187072716\n",
      "pre:  0.7333333333333333\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.8598990619526523\n",
      "mi F1:  0.9798011187072716\n",
      "we F1:  0.979760842571311\n",
      "Eval Loss:  0.19050945341587067\n",
      "Eval Loss:  0.14978620409965515\n",
      "Eval Loss:  0.20183931291103363\n",
      "Eval Loss:  0.15766488015651703\n",
      "Eval Loss:  0.2835564613342285\n",
      "Eval Loss:  0.1734418123960495\n",
      "Eval Loss:  0.23954489827156067\n",
      "Eval Loss:  0.13947506248950958\n",
      "Eval Loss:  0.2089664489030838\n",
      "Eval Loss:  0.22786076366901398\n",
      "Eval Loss:  0.24256019294261932\n",
      "Eval Loss:  0.2402043640613556\n",
      "Eval Loss:  0.18427439033985138\n",
      "Eval Loss:  0.23346592485904694\n",
      "Eval Loss:  0.12308766692876816\n",
      "Eval Loss:  0.22049888968467712\n",
      "Eval Loss:  0.17584958672523499\n",
      "Eval Loss:  0.1848735213279724\n",
      "Eval Loss:  0.20930518209934235\n",
      "Eval Loss:  0.18749988079071045\n",
      "Eval Loss:  0.14931601285934448\n",
      "Eval Loss:  0.19145908951759338\n",
      "Eval Loss:  0.14500759541988373\n",
      "Eval Loss:  0.17726658284664154\n",
      "Eval Loss:  0.2821463942527771\n",
      "Eval Loss:  0.13305926322937012\n",
      "Eval Loss:  0.20269310474395752\n",
      "Eval Loss:  0.2033059149980545\n",
      "Eval Loss:  0.26580101251602173\n",
      "[[15867  1200]\n",
      " [ 1087 11519]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     17067\n",
      "           1       0.91      0.91      0.91     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.92      0.92     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9229265662386682\n",
      "pre:  0.9056529601383757\n",
      "rec:  0.9137712200539425\n",
      "ma F1:  0.9212353963014482\n",
      "mi F1:  0.9229265662386682\n",
      "we F1:  0.9229705179872666\n",
      "29673 464\n",
      "Loss:  0.02355213835835457\n",
      "Loss:  0.06791990995407104\n",
      "Loss:  0.05598621070384979\n",
      "54 **********\n",
      "Epoch:  4290.789299964905  fold:  5  kers:  128\n",
      "epoch:  55\n",
      "29673 464\n",
      "Loss:  0.049127619713544846\n",
      "Loss:  0.029601581394672394\n",
      "Loss:  0.05284073203802109\n",
      "55 **********\n",
      "Epoch:  4355.179134607315  fold:  5  kers:  128\n",
      "epoch:  56\n",
      "29673 464\n",
      "Loss:  0.0608430951833725\n",
      "Loss:  0.041088223457336426\n",
      "Loss:  0.11349031329154968\n",
      "56 **********\n",
      "Epoch:  4419.632798433304  fold:  5  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.06372017413377762\n",
      "Eval Loss:  0.0688653290271759\n",
      "Eval Loss:  0.05216410756111145\n",
      "[[3057   40]\n",
      " [  20  101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.72      0.83      0.77       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.85      0.91      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9813548788067122\n",
      "pre:  0.7163120567375887\n",
      "rec:  0.8347107438016529\n",
      "ma F1:  0.8806370967143673\n",
      "mi F1:  0.9813548788067122\n",
      "we F1:  0.982036325234942\n",
      "Eval Loss:  0.15818238258361816\n",
      "Eval Loss:  0.14315801858901978\n",
      "Eval Loss:  0.1619395762681961\n",
      "Eval Loss:  0.15994568169116974\n",
      "Eval Loss:  0.28653484582901\n",
      "Eval Loss:  0.1770680695772171\n",
      "Eval Loss:  0.2392779439687729\n",
      "Eval Loss:  0.13844159245491028\n",
      "Eval Loss:  0.21079155802726746\n",
      "Eval Loss:  0.19358576834201813\n",
      "Eval Loss:  0.22840182483196259\n",
      "Eval Loss:  0.23787850141525269\n",
      "Eval Loss:  0.15535001456737518\n",
      "Eval Loss:  0.2440595179796219\n",
      "Eval Loss:  0.11180490255355835\n",
      "Eval Loss:  0.21001343429088593\n",
      "Eval Loss:  0.1560826301574707\n",
      "Eval Loss:  0.1953667253255844\n",
      "Eval Loss:  0.20025546848773956\n",
      "Eval Loss:  0.19854654371738434\n",
      "Eval Loss:  0.17470470070838928\n",
      "Eval Loss:  0.17143331468105316\n",
      "Eval Loss:  0.1508297175168991\n",
      "Eval Loss:  0.1712489277124405\n",
      "Eval Loss:  0.23093484342098236\n",
      "Eval Loss:  0.13582471013069153\n",
      "Eval Loss:  0.2058316171169281\n",
      "Eval Loss:  0.19653457403182983\n",
      "Eval Loss:  0.2596222758293152\n",
      "[[15780  1287]\n",
      " [  937 11669]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     17067\n",
      "           1       0.90      0.93      0.91     12606\n",
      "\n",
      "    accuracy                           0.93     29673\n",
      "   macro avg       0.92      0.93      0.92     29673\n",
      "weighted avg       0.93      0.93      0.93     29673\n",
      "\n",
      "acc:  0.925049708489199\n",
      "pre:  0.9006637851188638\n",
      "rec:  0.9256703157226718\n",
      "ma F1:  0.9235829372657431\n",
      "mi F1:  0.925049708489199\n",
      "we F1:  0.9251745856305779\n",
      "29673 464\n",
      "Loss:  0.05457368865609169\n",
      "Loss:  0.060782622545957565\n",
      "Loss:  0.04213908687233925\n",
      "57 **********\n",
      "Epoch:  4525.978452920914  fold:  5  kers:  128\n",
      "epoch:  58\n",
      "29673 464\n",
      "Loss:  0.04448772966861725\n",
      "Loss:  0.07473327964544296\n",
      "Loss:  0.039032161235809326\n",
      "58 **********\n",
      "Epoch:  4590.402195692062  fold:  5  kers:  128\n",
      "epoch:  59\n",
      "29673 464\n",
      "Loss:  0.041077081114053726\n",
      "Loss:  0.07378415018320084\n",
      "Loss:  0.05259087309241295\n",
      "59 **********\n",
      "Epoch:  4654.8448894023895  fold:  5  kers:  128\n",
      "Eval Loss:  0.05742087587714195\n",
      "Eval Loss:  0.05041396617889404\n",
      "Eval Loss:  0.04051458090543747\n",
      "[[3063   34]\n",
      " [  19  102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.75      0.84      0.79       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.92      0.89      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9835301429459291\n",
      "pre:  0.75\n",
      "rec:  0.8429752066115702\n",
      "ma F1:  0.8925984396754918\n",
      "mi F1:  0.9835301429459291\n",
      "we F1:  0.9839907898723246\n",
      "update!  Acc:  0.9835301429459291\n",
      "Epoch:  4658.898051738739  fold:  5  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0/UlEQVR4nO3dd3wUdfoH8M+TkBBqaAFigoQSQAQMEJAmgpXiGbnTn2DD0zvkBD31vDssd3IqgpUTj5NDxa7YUFGaVAGlhd5JgAAJARJ6TX1+f+xsMruZ3Z3Znd3ZzTzv1yuv7M5O+Q4b5pn5ludLzAwhhBD2E2V1AYQQQlhDAoAQQtiUBAAhhLApCQBCCGFTEgCEEMKmalhdACOaNGnCKSkpVhdDCCEiyvr16wuZOcF9eUQFgJSUFGRmZlpdDCGEiChEdEBruVQBCSGETUkAEEIIm5IAIIQQNiUBQAghbEoCgBBC2JQEACGEsCkJAEIIYVO2DQBnLpVg9ubDVhdDCCEsE1EDwQJRXFqO/NMXce2ry/D0kA5Yl3MSC3ccxRXN6yG1WT2riyeEECFnmwAwbtYWzNqQBwB4ae4udEqqDwC4VFJuZbGEEMIytqgC+nTNgYqLvxBCCAddAYCIBhHRbiLKJqJxGp93IKJVRFRERE+qlrcnok2qnzNE9Jjy2XgiylN9NsS0s3LzzLfbgrVrIYSIWD6rgIgoGsBUADcCyAWwjohmM/MO1WonADwK4Db1tsy8G0Caaj95AL5VrTKZmV8LoPxCCCH8pOcJoCeAbGbex8zFAGYCyFCvwMzHmHkdgBIv+7kewF5m1sxKF2rb8s4AABhscUmEEMIaegJAEoBDqve5yjKjhgP43G3ZWCLaQkQziKih1kZENIqIMokos6CgwI/DCiGE0KInAJDGMkO3zUQUC+BWAF+pFr8NoA0cVUT5AF7X2paZpzNzOjOnJyRUmc9ACCGEn/QEgFwALVTvkwEYHUE1GMAGZj7qXMDMR5m5jJnLAbwDR1WTEEKIENETANYBSCWiVsqd/HAAsw0eZwTcqn+IKFH1dhgAS7rqZB09Z8VhhRDCcj57ATFzKRGNBbAAQDSAGcy8nYhGK59PI6LmADIB1AdQrnT17MjMZ4ioNhw9iB5y2/UrRJQGR3VSjsbnIfGXrzbjd92TrTi0EEJYStdIYGaeC2Cu27JpqtdH4Kga0tr2AoDGGsvvNVTSIMo+dhatm9RFVJRWc4cQQlRPthgJ7MsNbyzH/5bvs7oYQggRUhIAFO+t3G91EYQQIqQkACgKzxVZXQQhhAgpCQBCCGFTEgCEEMKmJAAIIYRN2SIANKoTa3URhBAi7NgiALxzX7rVRRBCiLBjiwDQrlldq4sghBBhxxYBoF5cjNVFMOzE+WKriyCEqOZsEQAA4P4+KX5vy8w4cvqSeYXxYemuY+j2wkKszCoM2TGFEPZjmwBwR7p/Cd8OHr+A26b+gl4TF2Nn/hmTS6Ut88AJAMCmQydDcjwhhD3ZJgCwnzM/Zkxdic25pwEAOYXnTSyREEJYyzYBwF8nL3ib5lgIISKXbQJAarO6SG+pOe2wEELYkm0CQM0a0fj6T30C2od7LdKafceRe/JCQPsUQgir6JoQxo72HD2Ln3cXeF3nzumrER1F2PvSkBCVSgghzGObJwA9Fu2omLMeQ6eswIS5O31uU1au3bq8MqsQQ95cgZKyctPKJ4QQZrJdAGjdpI7Hz177aXfF65IyP7sNKcbN2oId+WdMHT/w9rK9+HZjrmn7E0LYm1QBGeBvV1KzvDx/FwBgWFeZxF4IETjbPQE8d+uVHj/bdeQsHv50PQa8ujSEJRJCCGvoCgBENIiIdhNRNhGN0/i8AxGtIqIiInrS7bMcItpKRJuIKFO1vBERLSSiLOV3SPpoXtsuwevnc7ceQc5xzz17mBkvz9+FrKNnzS6aEEKElM8AQETRAKYCGAygI4ARRNTRbbUTAB4F8JqH3Qxk5jRmVudlHgdgMTOnAlisvA97heeK8fayvbjr3TUVy4pKyzyuz+yYb3hb3mmX5YdOXPC6nT+KSsvw9fpcsNV1VUKIiKDnCaAngGxm3sfMxQBmAshQr8DMx5h5HQAjw2YzAHyovP4QwG0Gtg3Ivb1a+rUdq0YCqC+yl4pde/rM35aP3JMXK94P+vcK3PLWysr1S8pwzStL8devtvhVDk/+vSgLT361GQu2HzF1v0KI6klPAEgCcEj1PldZphcD+ImI1hPRKNXyZsycDwDK76ZaGxPRKCLKJKLMggLv/fL16pwUb8p+tBw4fh6jP9ngsqzwXJHL+zOXHHFy9ubDph674GyRsv9SU/cr9CspK5cnMBEx9AQA0lhm5C+8LzN3g6MKaQwR9TewLZh5OjOnM3N6QoL3+nu9SOuMTPLpmoM+1zl0wnMbw897CjB16V4ziyRC5HxRKVKfmYd/L8qyuihC6KInAOQCaKF6nwxA960rMx9Wfh8D8C0cVUoAcJSIEgFA+X1M7z4D5e/92ULVQDH9xzJ2tJEz1ho+hggPpy86nuy+zDzkY00hwoOeALAOQCoRtSKiWADDAczWs3MiqkNE9ZyvAdwEYJvy8WwAI5XXIwF8b6TggYiJ9u8RYN3+E4Yv6MJ+zhWVYvOhU1YXQwiffAYAZi4FMBbAAgA7AXzJzNuJaDQRjQYAImpORLkAngDwLBHlElF9AM0ArCSizQDWApjDzPOVXU8CcCMRZQG4UXkfErd0uSxUh/IgiHVQwnJnL5UiY+ovuFhsbi8vIcymayQwM88FMNdt2TTV6yNwVA25OwPgKg/7PA7get0lNVFMtP/j3y4UOf5TF56TOXuFdyXl5aiFaKuLIYRHthsJHAgiwoDXlnlfx+29JR1CpJZKCKGDBAADwr17n1QshZcw/3MRwr4BYOJvOxve5rBJmT31dkN97ac90qMkggSze7EQwWDbANA8Ps7qImhyv4j87WtzRwurMTPeXbGvYgBZuGNmTJy7U3rYCGES2waA/qnmDCqLZLuOnMWLc3bi0c83Wl0UXcoZ+N/yfRj231+sLooQ1YJtA0B0VJCe1wPcrZ5645Kycjzx5SaszCoM6FilyqQ3Z4uMpHASukkbgAhztg0AVgo09KQ+Mw+zNuThnvfWYNXe4xXL5XojhDDC1gHgq9G9rS4CAKC8nDFrQy5KPcwfvHxPgcceSD/tOIL9heeDWTwXv2YXou+kJTLISYhqwNYBoEdKo6Afo0xHnc7XG3LxxJebMfYz7br4+2as9dgb6P1fcjDwtWUoPFcUkm6gE+buRN6pi9hbcC4ER4ss5PYNSNoQEe5sHQBM4+XKe/3rP/vc/OR5x6ji+V7y+KurerT8d+leXcHGl/NFpZbMdrZ8TwF+3mNOum8hhD4SAMyguu663wVqIS8dxv3tSz7jl/2YtSHPr20PHL+AX/c6GpQf+ng9bpy8HGXl3oNJSVk53lm+D8Wl2tVWRt03Y61kQhUixCQAmOBccSnOFfmehGX+tqp3+OEwuvjspVLc9Y5jiktnIPDlk9UHMWHuTry7cl8wiyaECCJdyeCEd30nLQEAJDWohXbN6npcb/Qn65EzaajLsimLs7Hx0MmK957igbenhmBwBCbPxzyvBLzzOgKfXYVBbBfCKwkAJso7dRF5py76XlFl8qI9utb7dqP+6h1/Gx83HDzpCDTs2MOB4+cRHUVIbljbtGM4DX5zBXq3box//qZjQPsRQvhPqoBC7GJxWdgmbTtxrtilbNe+ugz9Xl7qso6RB5G8UxdxoVj7CWFn/hnM+GW/H6UMX5ILSEQaCQAhZlajqV55py7i9MUS/HvRHkM5f8yovug7aQnufc//hl334BEO7SVGRFZphR1JFVA152yfAIANB0/howd6VrzXumM1+y52/YGTvlfSMGdLPsZ8tgE/PtIPnZLiXT4rZ8fguahgpfMIkSOnL6Fx3diAJigSIhDyl1eNPeKW5O1Sifmjd7fkng7KnfnPe44BALYfPq35uRljHpzGz96O4dNXmbY/PS4Wl6HXxMV4atbWKp+dLyrV3bieU3g+5E+VovqQABBiv+4tRMbU0GSz/GHzYUPr/+GjTN3rOsc7rMgqjPg5Cz74NQer950I6TGdwXjRzqMVy5gZmTkncOVzC3Dlcwt87uP0hRIMeG0Znv62ahARQg8JACH2p083WF0EXeZty/f6uboXUPYxY2khbnlrhV9lCpWCs0VV8jIdPXMJv2Qby75q9Mno0zUHcfs0/U8i55Q2kl8NlkuEj4vFZSj3MegymHQFACIaRES7iSibiMZpfN6BiFYRURERPala3oKIlhLRTiLaTkR/Vn02nojyiGiT8jPEnFMSgXDe2f955iavnwfyN7st74z/GwfZ+aJS9JiwCP/4frvL8qFTVuLud9d43TbQFol9BaFL6ie0MTO25mpXO5qtuLQcV/xzPp7/cUdIjqfFZwAgomgAUwEMBtARwAgicu+8fQLAowBec1teCuAvzHwFgF4AxrhtO5mZ05Sfuf6ehNBH14T1Pq5iwe7quGrvcfz1q82m7s9I4roLSpbThTtcR20XnjM+a9rGg6cMbyOs9f4vOfjNf1aG5KmqRHnKtLIKVc8TQE8A2cy8j5mLAcwEkKFegZmPMfM6ACVuy/OZeYPy+iyAnQCSTCm5Se66+nKriyBURryzGl+tzw2oG+oX6w5WVEuNeGe1roR8APCkiYEHcLQteCJdRMPTriOOp9NDJy9YXJLQ0BMAkgCoQ1Qu/LiIE1EKgK4A1M/RY4loCxHNIKKGRvdphrYJnlM3RLL3NQZZ6bnohFvHSk/J9crK2WP+pb9/sxWD/r3c8LG+Xp+LmWsPGt4uEOqzMzq62kgbw5JdRw2PUhehYeXwFj0BQOt/oKEiE1FdAN8AeIyZnRXAbwNoAyANQD6A1z1sO4qIMokos6BA0gXr9a8fvNcrHj1zybRjBZKn6LCfF6Xxs7ej03MLPHaBLPWzkeL1hfpScwCOIKS+CFv1/1jPv/8DH2Tilinh3fjulFN4Ht1fWFjtA1Y4jBzXEwByAbRQvU8GoLt/IRHFwHHx/5SZZzmXM/NRZi5j5nIA78BR1VQFM09n5nRmTk9IMH8i9wa1Y0zfZ7hy/r1tOHgSV7+0GLM25uraru+kJXh1wS6XfZjluteX+bXd1+sdZS8tL8f42dvxS3Yhjpy+hPzToblolJaVo83TczFx3q6QHM8MJy+UmDIWZOrSbLxhIFB68/HqA0gZN8elXJ+vO4jj54sxe5OxbszCOD0BYB2AVCJqRUSxAIYDmK1n5+S4NXkPwE5mfsPts0TV22EAtukrsrluSwurJomQ2H3EMeHLupyqfd+17kryTl3E1KV7g1KWSyXad/BG7qY/+DUHd7+7Br0mLkbviUt8b6CDr8fyYqUB7+NVByqWBRoc/a0KUN8pv7N8HzYe9Dz62ownv1cX7MaUxVkB7wdAxX7OXCzxsaYIBp8BgJlLAYwFsACORtwvmXk7EY0motEAQETNiSgXwBMAniWiXCKqD6AvgHsBXKfR3fMVItpKRFsADATwuPmn51ukpxPQEkidoqcLspnH8Jf6kOHw+BwIM0ZPa+1iwtydGPbfXwE4urSmjJuDd1dUztmwaOexgI9rJ+//sh8T5+0M6jGsnDpUVy4gpYvmXLdl01Svj8BRNeRuJTzcGDHzvfqLKcKNegSrFn+6TaqpL27l5YxHPt/o0mMrEvLC6fmPHUj7yUUf1TknlKlG1b2RXvhxBx7s18rvY/pyqaQMZy+VIqFezaAdI5ScbWlPDb7C9H3rmT0w2CQZnA3lHHcMODp53pzH7unL9+HWqy5Dp6R4vLZgN2rFRldJ4ObkrH7ypeLiSY4Rr3O25mPxrqpBx9//RL/uLURSg1oo8jOPjp4ApG8dR/qH26etQs9WjQyVITNHX6K9UAbLO6evxuZDp6pMfBRpIuEGwwwSAGzEebP5v58dVQL+9LLwdMFctPMoOiXF4z9LswEAHz6g2aaPT1Yf0LUs2E/FzikwraK+8/9phyOwrd0f2nxEwbD50ClD64fbhTZUd+WfrD6AZvXjAIR/N9Bq7+EBbawugqlyjmsPYjHjD22Xzjt4NV8Xtme/89L+b9F/Dl81M1a2QUyYswMp4+ZYWndsOutrQ3S5UFzqtZFdr2e/24Y/Gki+GCwSAADUqGb52Kf9HJweO978e1EWxs+uzJ8zckblRDD/9z/zUy0H+9JXeK4Yby9z/DtqpabQk0bDW5AIpBH4nRX7PZdBAHDk2flh82HTU5U/NnMThv3314r2lUhXva58wqeX5gavR4PX1AfMmLs1H3uOGn+C0FIWggyKL8/fhUslZfhqvefxEt4v8r6PEUgjsO99B23Xplu3P/C7arUpi7PwyOcbTe/1tDXPkSjOzLk1rIzj0gZgI2v2n8Aai+qZF2w/gocNpMLW+k+ht4uqVXpOWOzyPth36O67/9Mn67XXC+tHBUfZxny2AUO7mNdwnH/aMd7h1IXqcaceLPIEIHRTV+sYlXvSWIOz2Ret7zbmmbo/p3C5tuaevIB521wzmAbz6UKLp9xMl0rK8L+f91aZY0Gvu99djZsnG8/tpBczY5+OjLFZR89WBJbqQgKA0O3nPaHLxbRZlZP9QKF/mRnVaXa35Z3Gqr3HQzp71qp9x03NuVSFKvo88YXnTKbuMWrHYXPmY/gluxBLdx2rmL7yHtV8CeoAPnVpNibO2+W1Ks37cY5jt0lVh1o++DUH173+MzaoGne14rqev/+SsnI8+91WHFEFiqLSMnyVeSgsn8QkAIiwtL/QMVbh1Z924zf/WelxPW/z4f7t6y0Vr99duR8j3lmNz9YElu1zW95pZB+rvBgVl5V7bRD8ZoP2RU/vpeDE+WKPCfN8NYN4uv8fMmVFRdrjQNz97hr8/oN1+Ps3jn/nTaouoB+ruvaeveQIEBeLjdWbB9LLyci2znIf9NB7TsuFYu2nnZVZhfhk9UGXG403Fu7BX7/eUtHdV6OwlpEAAKB1kzpWF6Hae3GOf43PBWe9jyge9XFwu9KdueQ6WO6Wt1bihjcqqyPKyhndXljo9/59VdJ0e2Eh+kwyJ7+RmvPf1YwJ5Z0DC9XeXbEfp/3M7+NtfuYvMw/hiS826d6Xt2qwO6b9igwPNxe+vpeHPvbQ3qJczdV3+85/a2cgDCcSAABkpF2G90amW10M4YdgN2pvy9OeHtCsm7bj54s9jq1QzxU7Y+V+ZLlVg3irUjh7qQS/7j2urKe9zpfrDqHds/Nw6IT5k58cPHEBQ970nX7avWzni0q9Dib729dbMMuk9px1OSddqhqN2FtNpu+UAADHXULXyy2Zj0ZYIGXcHNP3+c/v/U9mu9xD3fKUJZUZN5//cQduectzVZi7MZ9t9DrD2fM/7MCcrfkAgGwDU2YakXfqIo6cvoQft+Tr3qa0TF9oneWhai2YgtWobuWAPgkAinBsoBHh6+fdrhftj1ZppLNA5R3uuaJSPPPt1ooGUz2XkhVZrvPSuqfhUP/FuldVqZ8WtC4wWcdUF/0g/ukPn76qIjFgaXk5UsbNwRfrHO0weacu4rhb+8lVz/+ka79PfOlj+s7KVFK6BftCzOyYQOi1BbuDehwjJAAI4cUDH2i3MYz5TP+YBsCRMO/TNQcxfbkjD5MZlxr1PYs/KTpC0Uv08KnK3jDONoGX5zsugH/72tw5mNWc/zR6RuwG45/BJXW56ghZx85V5MsKBxIAhAiyPUfPYtlux4jUN5UJUNYfCHzk6/M/ep/208nTw+3JC44LcqB3vtvy/OtRZPSh+4gfffAnBHHku5a1yojmZbsLcO97VRMOlmuctK9/hzOXSnD2UnAmzJEAIESQ3TR5Oba4NTb+Z0no7gKPeehJZSRz57PfbQ1K24kvJarBY70mLvayprn8DYnqPFzuVXj+6jL+J3Qer69qzCgJAAppARChtNVD7yK1ULVLfbfxMB74YF2V4zEzFu88irJyxiervY+f6PCPeUEpW+oz/u1X69+urJzx32XZFe0wWiIpf5IZJAAIEUR6e7Xo5SnfTyBmbz6MJbuO4btNrt0rF+44igc/zNSVXVZPniajmSDMnhR+/rYjeGX+bo9TPIY6d1M4kACgkE5AIhgmL9pTZVlmjv9jF9zz/Zjpcbd0EgVK7x11HqfyALKwlpU7IoDem2x/GradtErpnHgo66hrt1dn905moMTkgO3Yv/fPrbz0SAAQIsT0zpfs7yAlAKYkLdOqKvnnbP/HOwTzJuvwqYsYPn1VRcK57zWeHlbtcwyMW7P/hEvbgtPEebs8pu4IhJ7z3pJ7Cp+vDSxNiT8kACiq1exKIqyN/kRfF9JQzHmgpbyc8cnqA3hp7q4qn81ce0hjC332Frjfebt+PnuzsSqfe95dg+nLHdVTfSYtwep9J9D2mXmYsXK/z22/yqy80J9UUkb7CszuN/J/+3qzoYZxbw8Ct/7nFzw1yzVR4f7C80h9Zq7u/ftDVwAgokFEtJuIsolonMbnHYhoFREVEdGTerYlokZEtJCIspTfMhRXiDAwb9sRt2k6zQlES3d7z6b56OcbDe1vZXahZpDS0z22uLQyMd0yH+UCgN4TF2NFlut6XypBxH0QnieeGp89BfpvN+YFpUpKzWcAIKJoAFMBDAbQEcAIIurottoJAI8CeM3AtuMALGbmVACLlffWkQcAIQAA54pcL2ifq+76S014Kgl1T5vj54oCzneUf/qSxwDWxUcXTWePpPE/7MC0ZaGfrtUbPTOC9QSQzcz7AICIZgLIAFARZpn5GIBjROQ+pY+3bTMADFDW+xDAMgB/9/dEhBD25Ovi3v3FRVWWjf/B+1OCme0V6uR1c4PYiO8PPVVASQDUFX+5yjI9vG3bjJnzAUD53VRrB0Q0iogyiSizoCB4E5JERdmsA7AQFjEjBbWaVdOcqjnz/JjJ3xnUjNATALSujHrPNJBtHSszT2fmdGZOT0hIMLKpIU3q1sSQzs2Dtn8hIgUFJTtOpTOXSl0mjAlHH/6aY2j9Aa8tQ9rz/s8LoSUUc2DrCQC5AFqo3icD0Ntc723bo0SUCADK72M69xk0v+/byuoiCGGpsnIOSY+4f3y3zbRAMzUIydWMTkF54PgFvyfA8SQU34OeNoB1AFKJqBWAPADDAdylc//etp0NYCSAScrv7w2UWwgRBG2eDm63w2BwTh8aCcKtotlnAGDmUiIaC2ABgGgAM5h5OxGNVj6fRkTNAWQCqA+gnIgeA9CRmc9obavsehKAL4noQQAHAdxh8rkZFm5fjhCRrjgE9djVVSiyE+h5AgAzzwUw123ZNNXrI3BU7+jaVll+HMD1RgorhBChonfEtjd5py66vA+3gCgjgVXslglQCOHZW4uzfK/kw5hPXUd9672rn7c1H+e8ZC01i64nALuIrxVrdRGEEGHCfbpKf2wyMOeCU/axc/jTp8ZmnPOXPAGotG1a1+oiCGEbelMoWMXIZPZmKS4tx8XiMt8rmkSeAIQQlnCfJU0A17yyBEfPBN72oJc8AQghRJgI5cUfkAAghBC2JQFACCFsSgKAEELYlAQANx2a17O6CEIIERISANzMHNXL6iIIIURISABw06B2LDom1re6GEIIEXQSADS8/LsuSIyPs7oYQggRVBIANHROjseM+3tYXQwhhAgqCQAe1I6NtroIQggRVBIAPGjZuA4WPNbf6mIIIUTQSADwor10CRVCVGMSAIQQwqYkAAghhE1JABBCCJuSACCEEDYlAUAIIWxKVwAgokFEtJuIsolonMbnRERTlM+3EFE3ZXl7Itqk+jlDRI8pn40nojzVZ0NMPTMhhBBe+ZwSkoiiAUwFcCOAXADriGg2M+9QrTYYQKryczWAtwFczcy7AaSp9pMH4FvVdpOZ+TUTzkMIIYRBep4AegLIZuZ9zFwMYCaADLd1MgB8xA6rATQgokS3da4HsJeZDwRc6hDq3y7B6iIIIURQ6AkASQAOqd7nKsuMrjMcwOduy8YqVUYziKih1sGJaBQRZRJRZkFBgY7imuujB3qG/JhCCBEKegIAaSxjI+sQUSyAWwF8pfr8bQBt4KgiygfwutbBmXk6M6czc3pCgtyNCyGEWfQEgFwALVTvkwEcNrjOYAAbmPmocwEzH2XmMmYuB/AOHFVNQgghQkRPAFgHIJWIWil38sMBzHZbZzaA+5TeQL0AnGbmfNXnI+BW/ePWRjAMwDbDpRdCCOE3nwGAmUsBjAWwAMBOAF8y83YiGk1Eo5XV5gLYByAbjrv5h53bE1FtOHoQzXLb9StEtJWItgAYCODxQE8m2Gbcn251EYQQwjQ+u4ECADPPheMir142TfWaAYzxsO0FAI01lt9rqKRhILWpZAcVQlij8FwRmtStaeo+ZSSwEEJEgMOnLpq+TwkABjSrL/MECyGqDwkABsTWiML9fVKsLoYQwoZIs7d9YCQACCFEBCDzr/8SAMzWuE6s1UUQQghdJACYqIPMISyECBJ5ArDI0C6JqBHl+Nd39HgFnvtNxyrrffFQ75CWSwhhH4dOmN8LSNc4ALubele3Ksvcg3G7ZnURXysGrZrUwfHzxaEpmBDCNrKOnsWgTs1N3ac8AZhs8p1pVhdBCFENuWfgNIMEAIMeHtgW/dslYFi3ZM3PWzSqjYcHtAlxqYQQ1R0HIQJIADCoWf04fPRAT8TXinFZru6je0PHZprbThnRNahlE0IIIyQABOCha1trLu92eUPNxHFtE+oGu0hCiGrqYkmZ6fuUABCAG6/QvtMHgOs6VP0sGN24hBD2sOHgSdP3KQFACCEigbQBhJcWjWobWj8YjThCCOEvCQABaFY/DuufvQEAMKq/dnuAEEKEKxkIFqDGdWsiZ9JQq4shhKjmOAh1QPIEIIQQNiUBQAghbEoCgEXu7dUSdWKjrS6GECJClAehE4m0AYTY1Lu6oUtyPFo0qo0mdWti8qI9FZ9dk9oEK7IKAQDpLRsi84D5/X6FEJGJg9CNUNcTABENIqLdRJRNROM0PicimqJ8voWIuqk+yyGirUS0iYgyVcsbEdFCIspSfjc055TC29AuiR67j5JqpNjljY11MRVCCKN8BgAiigYwFcBgAB0BjCAi92T4gwGkKj+jALzt9vlAZk5jZnV+hHEAFjNzKoDFyntb++M1rSpeB2P+TyFE5LIqG2hPANnMvI+ZiwHMBJDhtk4GgI/YYTWABkSU6GO/GQA+VF5/COA2/cWuHmJquF7k69asgRTlzv+OdO1so0IIYRY9ASAJwCHV+1xlmd51GMBPRLSeiEap1mnGzPkAoPxuqnVwIhpFRJlElFlQUKCjuJGjY2J9l/dEhPjajjmFa9aQ9nkhRCWr0kFr1UW4F8XbOn2ZuRsc1URjiKi/gfKBmaczczozpyckJBjZ1HJRbv8q7sngBrRviuV/HYguyfGOz3Xut30zmXtYCLvZdOiU6fvUEwByAbRQvU8GcFjvOszs/H0MwLdwVCkBwFFnNZHy+5jRwoe7f9zi2lSiFcEvb1zbZ2Rf9dR1JpZKCCEc9ASAdQBSiagVEcUCGA5gtts6swHcp/QG6gXgNDPnE1EdIqoHAERUB8BNALapthmpvB4J4PsAzyXs3OhhYhh3ziHentJFJ8bX8rsM9/dJ8XtbIUT15jMAMHMpgLEAFgDYCeBLZt5ORKOJaLSy2lwA+wBkA3gHwMPK8mYAVhLRZgBrAcxh5vnKZ5MA3EhEWQBuVN5XK8kNayNn0lB0aK6vykZvz58o97olL8bfeqXudYUQ9qJrIBgzz4XjIq9eNk31mgGM0dhuH4CrPOzzOIDrjRS2ujLauDPtnm649tVlmp8N79ECM9c52uNnjuoVYMmAkb1bYvGuY8g9eTHgfQkhwouMBA4DzgCgrgJyjwk/PtIPheeKEFsjCi0b18Go/q0xffm+is9v7NgMk37bGfG1YioCQK/WjQMu25WXxWPxrmrXPCOEgASAsOOpcqdTUrzL+6eHXIExA9siLiYKpy+WIL5WDGrWMD+30B3pyWhQOwajPl5v+r6FENaSABAGJt+ZhimLs9BeZ1uBU3ytGABA03quF/5fxl2Hs5dKTCkbEeGmK5ubsi8hRHiRABAG2jevh6l3d/O9ok5JDWoB0O451L5ZPew+eta0YwkhIpcMN7WZuCCnoL6vd8sqy4Z29pUVRAhhBQkANvDHa1rh/1S5hZxVR07PDr0CD5k0p3FvjYZn9/YLIYRxwcgAIAHABp4Z2hEjel4OwNHI7Ew9AQB92zbGH65pjaeGXGHKseq7BRchRPiSABACr95+Fa5JbYK2Tev6XLd1kzoAHJlBzdQluQFG9m6JKcO7onebyrt0b2MQHuzXyvOHHnRv2RD92xnP2dQzpZHhbYQQgZEAEAKdk+Px8YNXI1ZHhs8Jwzrj/d/3QDuTH/eiowj/yuiEyxvXxuj+bfDK7V28rj/tnu5VchnpERcTjY8e6FnxfvS1bXB1a98X9yduaoevR/c2fDwhhP8kAISZWrHRGNheMzO2aaKiSOkppJ97u4GWFo2q7rPb5Q3Q7XJ9k72lpzTCrhcGYclfrjVUNiHsoEa0+ZNESQCwOb1pKJ4d6ruNQCtp3dU6RyM7/7TjYqLROsFzVdm17RLw7n3pHj8f3qOFX1VXQoS7O3u08L2SQRIAbMrovcTt3f2boUzPkwOgf7q7+/ukoOvlDTx+Pul3XZBQr6bOvQlhbxIAwtibw9Ow8HFD8+eY5nK3ievVE9ar78BrxUQjrUUDAEDz+nEu21yVrN3988uHHHX9Teoav1D3bdvE5zptvTxBuKsTG41Xfue9PUSIcBCMGcFkJHAYy0hzn3nTfKxx773ibwPRwi0AAI4RxukpDXGDap6DnS8MAgB8vykP119RuXzxX65FU4078S3jb0JMlOO+484eyZi6dK/PMt7fJwUXiksxYVhnxET7vme5Qec8DADw9j3dceJ8se71/dExsT525J8J6jFE9VcehAggTwB2pVEHNKB9At4cnqZ58QccOYbeHN5V87OMtCSXrqttEuqiXlzV6p/6cTGoFRuNPS8OxpM3tUdifFyVddwlN6yFV26/StfF30nvRDj92yW4ZGH1tl2jOrG6j2/GdkKoWTUnsKiG6isX5+SGlRf7D37fU/dTx/dj+mLF3wb6ffzYGlEgIvzxGscIZE9BRwt5mjpNZfytV2L22L5VqrJ8ubqV5y6rQzprJ8V7c3iay/vHbkg1dEwh9AjC9V8CgF11SorHtHu644WMTn5tf1WLBoYu2p78vm8Ktv3r5irdUt+/v0fA++6S3AC3da0MaI9c1xYAMGZgG4/beBus52nGNnUQdTei5+Uep/o0wldQqWfywEERfliqgISZBnVqjlpBTg7nNLRLIpIbVu0mSkSao547JJozEE597f3LTe2x+bmb8Jcb23tcv01CXXwxqpfuaTw9GdHT0WXvud90RK0Y139jrXxJvjx2Qzuvn+vtIvjHa6SLrKgkAUCExNS7umHl36+zuhiIrxWDqCjC77pVdmu9THn6eLBfK0RFEa5u3Rj9dPQ28uSyBrUw4bbO2Pn8IMTFRGPS77pgYPvK9Bifj+qFnElD/T8JDXXj9D0B1I6VJ4VIJW0Awpaio7zXoWwdf5PHzzxVv7x6exfseXEwAKBHSiN8N6YvnlElxLsisb7ufTmltWiADx/oiTu6JyMqiiqerhrVicWffdzBB8qZ7M+bf97SEQPaa+dpemlYZ7OLZJiv79nuLOsFRESDiGg3EWUT0TiNz4mIpiifbyGibsryFkS0lIh2EtF2IvqzapvxRJRHRJuUnyHmnZaoTtwvbu6XCa3eRk7XddBOqxEVRS65mdJaNECU6gL0225JmP/YNbrK1zGxPjo0r4d/3NIR17ZL0Gyk7nRZ1YCi9s9bOlYkAvRHHR1tAA/0a1VRNvcuun3a6KuW+s1VlxkvnE4D/EgiqHZLl0T0SNGXdiQSuFcdWtIITETRAKYCGAygI4ARROSeJWwwgFTlZxSAt5XlpQD+wsxXAOgFYIzbtpOZOU35mRvYqYjqKi7G/3aKLskN/NqOiNCheX28OTzNZ96kWrHRmP9Yf3Rv6fniUyM6Ck3qeu4O+kC/Vljy5ACvVUPeLr5Gs8eqB+HteP5mpAQQfLy5VVXmXj6SAgbaWN6qSR1dPcQixcMDXDsrWFUF1BNANjPvY+ZiADMBZLitkwHgI3ZYDaABESUycz4zbwAAZj4LYCeA4I9uEhHP2U310eut7VKZkZZU0XAa6KVlyZMDsObp6/3e/t5elbOtrXvmBuxSBuE5ZU0Y7LOBuaXSc0s93sFIu0ArD4Fi4eP98fSQDlWW//VmR4N7fK0YzBzVG28OT0PrhOAEm5tNnLt683OeqxVDJSqK0Eb1b6U1aDPgY+hYJwnAIdX7XFS9iPtch4hSAHQFsEa1eKxSZTSDiDRvn4hoFBFlElFmQUGBjuKK6qBOzRrImjAYj2t0f6ynavD8YWy/UBYrIPXjYtCsvu+Bbz//dQAWPVE1BYj65jahXs0qT0Yx0VEu9ejb/nVzlX00rBOLnElD8X8avYZ8peP+7A9X49Hr2ro8bcTXisHCx/sjtVk9jOrfBt/8qTcm/rayPaFpfceThjNBX0ZaUkV2WGdwcLqvd4rX4/tCBJdjO3mqBvRGbw4rp8T4ODzUvzUm33mVx3XeG+k5iaEn6tQnVj0BaN34uBfF6zpEVBfANwAeY2bnmPi3AbQBkAYgH8DrWgdn5unMnM7M6QkJgdURisgSEx2l+UhfQzUiuLOSb+j9+3tg9ti+QSnH//Vogd92TcKfb2hXpZrC7N48ANCycR20bVoPWRMGuyzX8wTyB+Vp5dM/XI26NWsYKl96SiNck+q591Oftk1QIzoK0+/rXrHsuzF9kaqau6J7y0YubTY1a0QjZ9JQzSc59wDWv10C1jx9fUUXWrXHdTSiMzu68XZKqmxv+eiBnogKcrXQS8M6Y9VT1+OpIVegjpenqZaNjT/5pAd5oiQ9ASAXgPobSQZwWO86RBQDx8X/U2ae5VyBmY8ycxkzlwN4B46qJiF0ua5DU7x4W+UgtoEdmnqs7//5rwPw2R+v9vtYtWNr4I0709CoTixiDaSjCJR76gvnBWSS6i537dPX49dxld1rB7RvipxJQ3UlzdPifIIY2buly3L1nXWfNk2w6In+eP/+Hh6rhLxx3smqG+Gdr5vVj8PE33bBtHsqg8yPj/TD0C6Juvf/4yOVjfc1dUzC5MmuFwZ5TIOujilXqhr4b+zYDM/9RnsiJaNxKMEtWaJVA8HWAUglolZEFAtgOIDZbuvMBnCf0huoF4DTzJxPjtu39wDsZOY31BsQkfobHQZgm99nIWxnxv09cE+vlr5XhOPC2aeN//36PfnmT30C2l5vvqKblOR2CfVqImfSUAxX3WE3rR9XMY7Bk2eHXuF1DgW1l3/XBff3SXGZDS5n0tAqPbHaNq2HgX5UrajF1YjCL+OuwwsZV2Len117XA3qVFmf3ykpHm2b1kXmszdUuaDf3j0ZHTW67Dr1dEvt4Xy60JOfKS4m2mPX1L0ThmDpkwPw1oiuuErJhgs4Og+MDKAqa+6j12BI5+Z4c3ga7khPdnnqs6QKiJlLAYwFsACORtwvmXk7EY0motHOcgPYByAbjrv5h5XlfQHcC+A6je6erxDRViLaAmAggMdNOyshQqCFxshmI8bfeqXPdbImDHa5G/bHH65prTtDarP6cRh/65Uu1WzBlNSgFu7tnYI2OlJ4N6lbs0r6kQnDvKcyISLcke4Y9PfjI/3w0rDO+PGRfljwmHaa9W/+1MfndKmLnrgWUVGEVk3qaPbMUt/p/31QZcO4+mKuTkeyXdVW0/Gy+vjv3d2RkZZUpfqz3Kp00EoXzbluy6apXjOAMRrbrYSHqktmvtdQSYUIA6HuZWgkA2o4uTO9Bb7IPKT52cg+LfHtxlz099Hvf8KwTpi8MMtlmXvf+Jo1fHcRvvnK5i5tIZ2StOepAIDuLRu6dOd1v+tOaVzba74odyN6tsDL83cBcE1ieG+vlIpU6HVq1sD1HZoisUHVDgJaKdXNFJl/XUJUEx8/2BNvjdBOsR3JXr69i8cG6C7JDbBv4lCfPaLuvrolMp+9weexHrrWkVH28sbGkhM6q4G8VSG5+31f37mUPI1FUC9tHh+HzqpA9N79PfDibVV7MF3dujEm33kVOjSvh+EajeOBksQgQljomlTrerbNebQfDp24aNnxzZKRluTX5Emzx/bFtrzTGNQpESnj5nhd9/4+Kbqq7NzVrBGNhrVjcPJCSZWnxy8e6oWzl0p97mNY12QM6+rflKy+SAAQwoCnh1yBf36/3epimOLKy+Jx5WWeq0PC2ccP9vTabvD0kA5YvPOY130kN6xdkco7MT4O+acvVVmnsTJ62995pmvFRmPhE9ei8FxRRTrxFo0cbUe1Y2tYnpxPAoAQBtzXOwVvLclGwdkiq4tiS87RsPG1Yrz2fhrVvw1G9fc874O7bx/ui+2HT1dZ7kxlMbSz/m6o7prUrYkmdWvi0IkLAILTm8df0gYghEHOye71NECK4PA0OY+/msfHucxpXXEcImSkJfnVK8pTF9JwCgDyBCCEQW8O74qsY+cQX9tYuoBIs/Dx/jh1scTqYkSkDx/oWSW7q3MMg555sENFAoAQBtWpWQNpqsE/1ZU6xYMw5lqNLq5N68dhyoiu6Ksz9XYoSAAQQkSMOKXaLVKzPt8axPkU/CEBQAgRMd66qys+X3vIJf+O8J8EACFExEiMr4Unbgzu9Jp2Ir2AhBDCpiQACCGETUkAEEIIm5IAIIQQNiUBQAghbEoCgBBC2JQEACGEsCkJAEIIYVMUjJnmg4WICgAc8HPzJgAKTSxOOKmu51ZdzwuQc4tEkXxeLZm5SoKiiAoAgSCiTGZOt7ocwVBdz626nhcg5xaJquN5SRWQEELYlAQAIYSwKTsFgOlWFyCIquu5VdfzAuTcIlG1Oy/btAEIIYRwZacnACGEECoSAIQQwqZsEQCIaBAR7SaibCIaZ3V59CCiHCLaSkSbiChTWdaIiBYSUZbyu6Fq/aeU89tNRDerlndX9pNNRFOIQj+ZHhHNIKJjRLRNtcy0cyGimkT0hbJ8DRGlWHhe44koT/neNhHRkEg7L+XYLYhoKRHtJKLtRPRnZXlEf29ezqtafG+GMXO1/gEQDWAvgNYAYgFsBtDR6nLpKHcOgCZuy14BME55PQ7Ay8rrjsp51QTQSjnfaOWztQB6AyAA8wAMtuBc+gPoBmBbMM4FwMMApimvhwP4wsLzGg/gSY11I+a8lOMlAuimvK4HYI9yDhH9vXk5r2rxvRn9scMTQE8A2cy8j5mLAcwEkGFxmfyVAeBD5fWHAG5TLZ/JzEXMvB9ANoCeRJQIoD4zr2LHX+NHqm1ChpmXAzjhttjMc1Hv62sA14fiScfDeXkSMecFAMycz8wblNdnAewEkIQI/968nJcnEXFe/rJDAEgCcEj1Phfev/BwwQB+IqL1RDRKWdaMmfMBxx8ygKbKck/nmKS8dl8eDsw8l4ptmLkUwGkAjYNWct/GEtEWpYrIWUUSseelVGF0BbAG1eh7czsvoJp9b3rYIQBoRd5I6Pval5m7ARgMYAwR9feyrqdzjMRz9+dcwuk83wbQBkAagHwAryvLI/K8iKgugG8APMbMZ7ytqrEsbM9P47yq1femlx0CQC6AFqr3yQAOW1QW3Zj5sPL7GIBv4ajKOqo8ekL5fUxZ3dM55iqv3ZeHAzPPpWIbIqoBIB76q2ZMxcxHmbmMmcsBvAPH9+ZSRkXYnxcRxcBxkfyUmWcpiyP+e9M6r+r0vRlhhwCwDkAqEbUiolg4GmVmW1wmr4ioDhHVc74GcBOAbXCUe6Sy2kgA3yuvZwMYrvQ+aAUgFcBa5RH9LBH1Uuog71NtYzUzz0W9r9sBLFHqZUPOeXFUDIPjewMi7LyUsrwHYCczv6H6KKK/N0/nVV2+N8OsboUOxQ+AIXC09u8F8IzV5dFR3tZw9DzYDGC7s8xw1CMuBpCl/G6k2uYZ5fx2Q9XTB0A6HH/MewH8B8ro7xCfz+dwPFaXwHF39KCZ5wIgDsBXcDTQrQXQ2sLz+hjAVgBb4LgQJEbaeSnH7gdHtcUWAJuUnyGR/r15Oa9q8b0Z/ZFUEEIIYVN2qAISQgihQQKAEELYlAQAIYSwKQkAQghhUxIAhBDCpiQACCGETUkAEEIIm/p/rXWDZwRYvhkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29479 3412\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29479 461\n",
      "Loss:  0.17526808381080627\n",
      "Loss:  0.16993491351604462\n",
      "Loss:  0.1663074940443039\n",
      "0 **********\n",
      "Epoch:  76.27904462814331  fold:  6  kers:  128\n",
      "epoch:  1\n",
      "29479 461\n",
      "Loss:  0.15217281877994537\n",
      "Loss:  0.13495968282222748\n",
      "Loss:  0.12704148888587952\n",
      "1 **********\n",
      "Epoch:  140.28291177749634  fold:  6  kers:  128\n",
      "epoch:  2\n",
      "29479 461\n",
      "Loss:  0.12383060902357101\n",
      "Loss:  0.0897487998008728\n",
      "Loss:  0.11265639960765839\n",
      "2 **********\n",
      "Epoch:  204.29475712776184  fold:  6  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.08789549767971039\n",
      "Eval Loss:  0.349578857421875\n",
      "Eval Loss:  0.537849485874176\n",
      "[[1956  276]\n",
      " [ 170 1010]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      2232\n",
      "           1       0.79      0.86      0.82      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.85      0.87      0.86      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8692848769050411\n",
      "pre:  0.7853810264385692\n",
      "rec:  0.8559322033898306\n",
      "ma F1:  0.8583998925078172\n",
      "mi F1:  0.8692848769050411\n",
      "we F1:  0.8705045474611781\n",
      "update!  Acc:  0.8692848769050411\n",
      "Eval Loss:  0.4128762185573578\n",
      "Eval Loss:  0.4234999418258667\n",
      "Eval Loss:  0.4249328672885895\n",
      "Eval Loss:  0.3541230261325836\n",
      "Eval Loss:  0.385448157787323\n",
      "Eval Loss:  0.4577994644641876\n",
      "Eval Loss:  0.4518768787384033\n",
      "Eval Loss:  0.4097256064414978\n",
      "Eval Loss:  0.4302082061767578\n",
      "Eval Loss:  0.4393748342990875\n",
      "Eval Loss:  0.5302983522415161\n",
      "Eval Loss:  0.35841572284698486\n",
      "Eval Loss:  0.4674501419067383\n",
      "Eval Loss:  0.3962618112564087\n",
      "Eval Loss:  0.474270224571228\n",
      "Eval Loss:  0.3852544128894806\n",
      "Eval Loss:  0.5070826411247253\n",
      "Eval Loss:  0.48397859930992126\n",
      "Eval Loss:  0.36368367075920105\n",
      "Eval Loss:  0.5662080645561218\n",
      "Eval Loss:  0.4409749507904053\n",
      "Eval Loss:  0.422907292842865\n",
      "Eval Loss:  0.43719562888145447\n",
      "Eval Loss:  0.41018664836883545\n",
      "Eval Loss:  0.4315057694911957\n",
      "Eval Loss:  0.5178613066673279\n",
      "Eval Loss:  0.37843799591064453\n",
      "Eval Loss:  0.45533666014671326\n",
      "[[16572  1360]\n",
      " [ 3956  7591]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86     17932\n",
      "           1       0.85      0.66      0.74     11547\n",
      "\n",
      "    accuracy                           0.82     29479\n",
      "   macro avg       0.83      0.79      0.80     29479\n",
      "weighted avg       0.82      0.82      0.81     29479\n",
      "\n",
      "acc:  0.8196682384070016\n",
      "pre:  0.8480616690872528\n",
      "rec:  0.6574001905256777\n",
      "ma F1:  0.8012180481365024\n",
      "mi F1:  0.8196682384070016\n",
      "we F1:  0.8143351247289906\n",
      "29479 461\n",
      "Loss:  0.09161326289176941\n",
      "Loss:  0.08820068836212158\n",
      "Loss:  0.09340760111808777\n",
      "3 **********\n",
      "Epoch:  308.9898235797882  fold:  6  kers:  128\n",
      "epoch:  4\n",
      "29479 461\n",
      "Loss:  0.11312466114759445\n",
      "Loss:  0.09304327517747879\n",
      "Loss:  0.09256839007139206\n",
      "4 **********\n",
      "Epoch:  373.01563119888306  fold:  6  kers:  128\n",
      "epoch:  5\n",
      "29479 461\n",
      "Loss:  0.0755355954170227\n",
      "Loss:  0.12832188606262207\n",
      "Loss:  0.06187044084072113\n",
      "5 **********\n",
      "Epoch:  437.02149271965027  fold:  6  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.03829873353242874\n",
      "Eval Loss:  0.31166723370552063\n",
      "Eval Loss:  0.4863815903663635\n",
      "[[2025  207]\n",
      " [ 181  999]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      2232\n",
      "           1       0.83      0.85      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.87      0.88      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8862837045720985\n",
      "pre:  0.8283582089552238\n",
      "rec:  0.8466101694915255\n",
      "ma F1:  0.8749789877636067\n",
      "mi F1:  0.8862837045720985\n",
      "we F1:  0.8865701788771869\n",
      "update!  Acc:  0.8862837045720985\n",
      "Eval Loss:  0.27471262216567993\n",
      "Eval Loss:  0.33762651681900024\n",
      "Eval Loss:  0.36907246708869934\n",
      "Eval Loss:  0.2835231423377991\n",
      "Eval Loss:  0.3496735692024231\n",
      "Eval Loss:  0.3825564682483673\n",
      "Eval Loss:  0.3980093002319336\n",
      "Eval Loss:  0.3380342423915863\n",
      "Eval Loss:  0.3728503882884979\n",
      "Eval Loss:  0.37536928057670593\n",
      "Eval Loss:  0.4247867465019226\n",
      "Eval Loss:  0.32114389538764954\n",
      "Eval Loss:  0.36023956537246704\n",
      "Eval Loss:  0.35848063230514526\n",
      "Eval Loss:  0.3856399953365326\n",
      "Eval Loss:  0.29150480031967163\n",
      "Eval Loss:  0.47628024220466614\n",
      "Eval Loss:  0.34405839443206787\n",
      "Eval Loss:  0.30901452898979187\n",
      "Eval Loss:  0.517738401889801\n",
      "Eval Loss:  0.37490329146385193\n",
      "Eval Loss:  0.4011145234107971\n",
      "Eval Loss:  0.39731520414352417\n",
      "Eval Loss:  0.3484587073326111\n",
      "Eval Loss:  0.3627147674560547\n",
      "Eval Loss:  0.47580742835998535\n",
      "Eval Loss:  0.32409051060676575\n",
      "Eval Loss:  0.35750529170036316\n",
      "[[16840  1092]\n",
      " [ 3159  8388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     17932\n",
      "           1       0.88      0.73      0.80     11547\n",
      "\n",
      "    accuracy                           0.86     29479\n",
      "   macro avg       0.86      0.83      0.84     29479\n",
      "weighted avg       0.86      0.86      0.85     29479\n",
      "\n",
      "acc:  0.8557956511414906\n",
      "pre:  0.8848101265822785\n",
      "rec:  0.7264224473889321\n",
      "ma F1:  0.8428797198075145\n",
      "mi F1:  0.8557956511414906\n",
      "we F1:  0.8526369632490003\n",
      "29479 461\n",
      "Loss:  0.08879958093166351\n",
      "Loss:  0.06282050162553787\n",
      "Loss:  0.08167062699794769\n",
      "6 **********\n",
      "Epoch:  541.733514547348  fold:  6  kers:  128\n",
      "epoch:  7\n",
      "29479 461\n",
      "Loss:  0.10651491582393646\n",
      "Loss:  0.10182258486747742\n",
      "Loss:  0.07429207116365433\n",
      "7 **********\n",
      "Epoch:  605.7284052371979  fold:  6  kers:  128\n",
      "epoch:  8\n",
      "29479 461\n",
      "Loss:  0.0912436917424202\n",
      "Loss:  0.10177430510520935\n",
      "Loss:  0.07741793245077133\n",
      "8 **********\n",
      "Epoch:  669.7691729068756  fold:  6  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.01687435433268547\n",
      "Eval Loss:  0.39602136611938477\n",
      "Eval Loss:  0.48569372296333313\n",
      "[[2129  103]\n",
      " [ 278  902]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92      2232\n",
      "           1       0.90      0.76      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.86      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.888335287221571\n",
      "pre:  0.8975124378109453\n",
      "rec:  0.764406779661017\n",
      "ma F1:  0.8717497606355035\n",
      "mi F1:  0.888335287221571\n",
      "we F1:  0.8859697883197276\n",
      "update!  Acc:  0.888335287221571\n",
      "Eval Loss:  0.3709167242050171\n",
      "Eval Loss:  0.43539777398109436\n",
      "Eval Loss:  0.4419151544570923\n",
      "Eval Loss:  0.37586963176727295\n",
      "Eval Loss:  0.3912689983844757\n",
      "Eval Loss:  0.3975425362586975\n",
      "Eval Loss:  0.4907551407814026\n",
      "Eval Loss:  0.4577449560165405\n",
      "Eval Loss:  0.39575231075286865\n",
      "Eval Loss:  0.4417687952518463\n",
      "Eval Loss:  0.5801916122436523\n",
      "Eval Loss:  0.343983918428421\n",
      "Eval Loss:  0.45586177706718445\n",
      "Eval Loss:  0.4245399534702301\n",
      "Eval Loss:  0.49681511521339417\n",
      "Eval Loss:  0.3521645665168762\n",
      "Eval Loss:  0.5560368895530701\n",
      "Eval Loss:  0.45209550857543945\n",
      "Eval Loss:  0.36556240916252136\n",
      "Eval Loss:  0.6539526581764221\n",
      "Eval Loss:  0.39277249574661255\n",
      "Eval Loss:  0.4156076908111572\n",
      "Eval Loss:  0.40233081579208374\n",
      "Eval Loss:  0.40621909499168396\n",
      "Eval Loss:  0.4381498396396637\n",
      "Eval Loss:  0.5269330739974976\n",
      "Eval Loss:  0.39022505283355713\n",
      "Eval Loss:  0.44905075430870056\n",
      "[[17450   482]\n",
      " [ 4652  6895]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     17932\n",
      "           1       0.93      0.60      0.73     11547\n",
      "\n",
      "    accuracy                           0.83     29479\n",
      "   macro avg       0.86      0.79      0.80     29479\n",
      "weighted avg       0.85      0.83      0.82     29479\n",
      "\n",
      "acc:  0.825842124902473\n",
      "pre:  0.9346617866341331\n",
      "rec:  0.5971247943188707\n",
      "ma F1:  0.8002316478467408\n",
      "mi F1:  0.825842124902473\n",
      "we F1:  0.815724106018304\n",
      "29479 461\n",
      "Loss:  0.0841081291437149\n",
      "Loss:  0.04788157343864441\n",
      "Loss:  0.047945983707904816\n",
      "9 **********\n",
      "Epoch:  774.6966183185577  fold:  6  kers:  128\n",
      "epoch:  10\n",
      "29479 461\n",
      "Loss:  0.08826981484889984\n",
      "Loss:  0.0852365717291832\n",
      "Loss:  0.07999362796545029\n",
      "10 **********\n",
      "Epoch:  838.6994874477386  fold:  6  kers:  128\n",
      "epoch:  11\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0850410908460617\n",
      "Loss:  0.08428148180246353\n",
      "Loss:  0.08667405694723129\n",
      "11 **********\n",
      "Epoch:  902.7392582893372  fold:  6  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.01746399700641632\n",
      "Eval Loss:  0.4005921185016632\n",
      "Eval Loss:  0.5001878142356873\n",
      "[[2153   79]\n",
      " [ 307  873]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      2232\n",
      "           1       0.92      0.74      0.82      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.90      0.85      0.87      3412\n",
      "weighted avg       0.89      0.89      0.88      3412\n",
      "\n",
      "acc:  0.8868698710433763\n",
      "pre:  0.917016806722689\n",
      "rec:  0.7398305084745763\n",
      "ma F1:  0.868340826827509\n",
      "mi F1:  0.8868698710433763\n",
      "we F1:  0.883569385042425\n",
      "Eval Loss:  0.2961011230945587\n",
      "Eval Loss:  0.34039589762687683\n",
      "Eval Loss:  0.33889469504356384\n",
      "Eval Loss:  0.29586705565452576\n",
      "Eval Loss:  0.32058706879615784\n",
      "Eval Loss:  0.3122844099998474\n",
      "Eval Loss:  0.4227195382118225\n",
      "Eval Loss:  0.37803637981414795\n",
      "Eval Loss:  0.35201746225357056\n",
      "Eval Loss:  0.3492732644081116\n",
      "Eval Loss:  0.4397071897983551\n",
      "Eval Loss:  0.27260953187942505\n",
      "Eval Loss:  0.36892497539520264\n",
      "Eval Loss:  0.36824628710746765\n",
      "Eval Loss:  0.3783816993236542\n",
      "Eval Loss:  0.24460847675800323\n",
      "Eval Loss:  0.4391775131225586\n",
      "Eval Loss:  0.3790806531906128\n",
      "Eval Loss:  0.30405479669570923\n",
      "Eval Loss:  0.5381543636322021\n",
      "Eval Loss:  0.33080023527145386\n",
      "Eval Loss:  0.3272269070148468\n",
      "Eval Loss:  0.3380260467529297\n",
      "Eval Loss:  0.323604553937912\n",
      "Eval Loss:  0.36483293771743774\n",
      "Eval Loss:  0.44830724596977234\n",
      "Eval Loss:  0.31890612840652466\n",
      "Eval Loss:  0.3303414285182953\n",
      "[[17433   499]\n",
      " [ 3585  7962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     17932\n",
      "           1       0.94      0.69      0.80     11547\n",
      "\n",
      "    accuracy                           0.86     29479\n",
      "   macro avg       0.89      0.83      0.85     29479\n",
      "weighted avg       0.87      0.86      0.86     29479\n",
      "\n",
      "acc:  0.8614607008378846\n",
      "pre:  0.941023519678525\n",
      "rec:  0.68952974798649\n",
      "ma F1:  0.845514636250763\n",
      "mi F1:  0.8614607008378846\n",
      "we F1:  0.8562648867405499\n",
      "29479 461\n",
      "Loss:  0.08823828399181366\n",
      "Loss:  0.09859936684370041\n",
      "Loss:  0.06890752911567688\n",
      "12 **********\n",
      "Epoch:  1007.2617864608765  fold:  6  kers:  128\n",
      "epoch:  13\n",
      "29479 461\n",
      "Loss:  0.10145921260118484\n",
      "Loss:  0.0855737254023552\n",
      "Loss:  0.04300326108932495\n",
      "13 **********\n",
      "Epoch:  1071.2736310958862  fold:  6  kers:  128\n",
      "epoch:  14\n",
      "29479 461\n",
      "Loss:  0.06861406564712524\n",
      "Loss:  0.05821212753653526\n",
      "Loss:  0.074875108897686\n",
      "14 **********\n",
      "Epoch:  1135.279492855072  fold:  6  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.01173312310129404\n",
      "Eval Loss:  0.2556562125682831\n",
      "Eval Loss:  0.5029306411743164\n",
      "[[2127  105]\n",
      " [ 363  817]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      2232\n",
      "           1       0.89      0.69      0.78      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.87      0.82      0.84      3412\n",
      "weighted avg       0.87      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8628370457209847\n",
      "pre:  0.886117136659436\n",
      "rec:  0.6923728813559322\n",
      "ma F1:  0.8391221768582473\n",
      "mi F1:  0.8628370457209847\n",
      "we F1:  0.8581664837617586\n",
      "Eval Loss:  0.20394189655780792\n",
      "Eval Loss:  0.2963133156299591\n",
      "Eval Loss:  0.3064517378807068\n",
      "Eval Loss:  0.23717209696769714\n",
      "Eval Loss:  0.2799144983291626\n",
      "Eval Loss:  0.24209925532341003\n",
      "Eval Loss:  0.34999868273735046\n",
      "Eval Loss:  0.2976877987384796\n",
      "Eval Loss:  0.2885086238384247\n",
      "Eval Loss:  0.24889808893203735\n",
      "Eval Loss:  0.25927308201789856\n",
      "Eval Loss:  0.21012556552886963\n",
      "Eval Loss:  0.2864999771118164\n",
      "Eval Loss:  0.30199307203292847\n",
      "Eval Loss:  0.28555744886398315\n",
      "Eval Loss:  0.16335374116897583\n",
      "Eval Loss:  0.3001488447189331\n",
      "Eval Loss:  0.2893860638141632\n",
      "Eval Loss:  0.19707487523555756\n",
      "Eval Loss:  0.3880564272403717\n",
      "Eval Loss:  0.26042813062667847\n",
      "Eval Loss:  0.28475669026374817\n",
      "Eval Loss:  0.3410415053367615\n",
      "Eval Loss:  0.23505957424640656\n",
      "Eval Loss:  0.25923773646354675\n",
      "Eval Loss:  0.3157424330711365\n",
      "Eval Loss:  0.29494354128837585\n",
      "Eval Loss:  0.26635652780532837\n",
      "[[16936   996]\n",
      " [ 2276  9271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     17932\n",
      "           1       0.90      0.80      0.85     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.89      0.87      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8890057328946029\n",
      "pre:  0.9029901626570566\n",
      "rec:  0.8028925261972807\n",
      "ma F1:  0.880957493484406\n",
      "mi F1:  0.8890057328946029\n",
      "we F1:  0.887661734663024\n",
      "29479 461\n",
      "Loss:  0.06575049459934235\n",
      "Loss:  0.06777689605951309\n",
      "Loss:  0.07806660979986191\n",
      "15 **********\n",
      "Epoch:  1239.7361972332  fold:  6  kers:  128\n",
      "epoch:  16\n",
      "29479 461\n",
      "Loss:  0.04668429121375084\n",
      "Loss:  0.06157217174768448\n",
      "Loss:  0.04979405552148819\n",
      "16 **********\n",
      "Epoch:  1303.752031803131  fold:  6  kers:  128\n",
      "epoch:  17\n",
      "29479 461\n",
      "Loss:  0.04031198099255562\n",
      "Loss:  0.05265370011329651\n",
      "Loss:  0.04146135598421097\n",
      "17 **********\n",
      "Epoch:  1367.8237171173096  fold:  6  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.009042013436555862\n",
      "Eval Loss:  0.32566702365875244\n",
      "Eval Loss:  0.48834148049354553\n",
      "[[2143   89]\n",
      " [ 404  776]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      2232\n",
      "           1       0.90      0.66      0.76      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.87      0.81      0.83      3412\n",
      "weighted avg       0.86      0.86      0.85      3412\n",
      "\n",
      "acc:  0.8555099648300117\n",
      "pre:  0.8971098265895954\n",
      "rec:  0.6576271186440678\n",
      "ma F1:  0.8278822742735\n",
      "mi F1:  0.8555099648300117\n",
      "we F1:  0.8491436718341806\n",
      "Eval Loss:  0.20486849546432495\n",
      "Eval Loss:  0.2684130370616913\n",
      "Eval Loss:  0.2229112833738327\n",
      "Eval Loss:  0.22650361061096191\n",
      "Eval Loss:  0.24012422561645508\n",
      "Eval Loss:  0.21510647237300873\n",
      "Eval Loss:  0.37314465641975403\n",
      "Eval Loss:  0.3029690086841583\n",
      "Eval Loss:  0.2817503809928894\n",
      "Eval Loss:  0.2655431926250458\n",
      "Eval Loss:  0.26943185925483704\n",
      "Eval Loss:  0.19849693775177002\n",
      "Eval Loss:  0.2733796536922455\n",
      "Eval Loss:  0.29474830627441406\n",
      "Eval Loss:  0.28496670722961426\n",
      "Eval Loss:  0.19436539709568024\n",
      "Eval Loss:  0.28394612669944763\n",
      "Eval Loss:  0.31373822689056396\n",
      "Eval Loss:  0.2185024470090866\n",
      "Eval Loss:  0.42101114988327026\n",
      "Eval Loss:  0.22324883937835693\n",
      "Eval Loss:  0.243768572807312\n",
      "Eval Loss:  0.3118019700050354\n",
      "Eval Loss:  0.2486969530582428\n",
      "Eval Loss:  0.2946338951587677\n",
      "Eval Loss:  0.30220210552215576\n",
      "Eval Loss:  0.26976555585861206\n",
      "Eval Loss:  0.2495468407869339\n",
      "[[17277   655]\n",
      " [ 2405  9142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17932\n",
      "           1       0.93      0.79      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.91      0.88      0.89     29479\n",
      "weighted avg       0.90      0.90      0.89     29479\n",
      "\n",
      "acc:  0.8961972929882289\n",
      "pre:  0.9331427988159641\n",
      "rec:  0.7917207932796397\n",
      "ma F1:  0.887640747539773\n",
      "mi F1:  0.8961972929882289\n",
      "we F1:  0.8943566101935396\n",
      "29479 461\n",
      "Loss:  0.07784365117549896\n",
      "Loss:  0.09695637971162796\n",
      "Loss:  0.05794600769877434\n",
      "18 **********\n",
      "Epoch:  1472.3831465244293  fold:  6  kers:  128\n",
      "epoch:  19\n",
      "29479 461\n",
      "Loss:  0.05100833252072334\n",
      "Loss:  0.08392826467752457\n",
      "Loss:  0.06445032358169556\n",
      "19 **********\n",
      "Epoch:  1536.405962228775  fold:  6  kers:  128\n",
      "epoch:  20\n",
      "29479 461\n",
      "Loss:  0.055621348321437836\n",
      "Loss:  0.07306499779224396\n",
      "Loss:  0.08329475671052933\n",
      "20 **********\n",
      "Epoch:  1600.4487249851227  fold:  6  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.010783216916024685\n",
      "Eval Loss:  0.18840660154819489\n",
      "Eval Loss:  0.4189593195915222\n",
      "[[2108  124]\n",
      " [ 322  858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      2232\n",
      "           1       0.87      0.73      0.79      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8692848769050411\n",
      "pre:  0.8737270875763747\n",
      "rec:  0.7271186440677966\n",
      "ma F1:  0.8490212162737603\n",
      "mi F1:  0.8692848769050411\n",
      "we F1:  0.8660751130610461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1725078970193863\n",
      "Eval Loss:  0.2852817177772522\n",
      "Eval Loss:  0.21703974902629852\n",
      "Eval Loss:  0.2048490345478058\n",
      "Eval Loss:  0.2182348519563675\n",
      "Eval Loss:  0.21970191597938538\n",
      "Eval Loss:  0.3503205478191376\n",
      "Eval Loss:  0.25533953309059143\n",
      "Eval Loss:  0.24194881319999695\n",
      "Eval Loss:  0.24141404032707214\n",
      "Eval Loss:  0.22573058307170868\n",
      "Eval Loss:  0.18441633880138397\n",
      "Eval Loss:  0.24007868766784668\n",
      "Eval Loss:  0.24194638431072235\n",
      "Eval Loss:  0.2500663101673126\n",
      "Eval Loss:  0.16172513365745544\n",
      "Eval Loss:  0.22376136481761932\n",
      "Eval Loss:  0.2684869170188904\n",
      "Eval Loss:  0.19603687524795532\n",
      "Eval Loss:  0.3466828167438507\n",
      "Eval Loss:  0.16596265137195587\n",
      "Eval Loss:  0.22043335437774658\n",
      "Eval Loss:  0.2620408535003662\n",
      "Eval Loss:  0.19745992124080658\n",
      "Eval Loss:  0.24259315431118011\n",
      "Eval Loss:  0.24295449256896973\n",
      "Eval Loss:  0.21893393993377686\n",
      "Eval Loss:  0.19639991223812103\n",
      "[[16906  1026]\n",
      " [ 1669  9878]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     17932\n",
      "           1       0.91      0.86      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9085789884324434\n",
      "pre:  0.9059060895084373\n",
      "rec:  0.855460292716723\n",
      "ma F1:  0.9030696723146946\n",
      "mi F1:  0.9085789884324433\n",
      "we F1:  0.90807493461006\n",
      "29479 461\n",
      "Loss:  0.07864498347043991\n",
      "Loss:  0.0434153713285923\n",
      "Loss:  0.09962023049592972\n",
      "21 **********\n",
      "Epoch:  1704.9672636985779  fold:  6  kers:  128\n",
      "epoch:  22\n",
      "29479 461\n",
      "Loss:  0.04989684000611305\n",
      "Loss:  0.07646039873361588\n",
      "Loss:  0.0700746551156044\n",
      "22 **********\n",
      "Epoch:  1768.9711301326752  fold:  6  kers:  128\n",
      "epoch:  23\n",
      "29479 461\n",
      "Loss:  0.05590036138892174\n",
      "Loss:  0.05602447688579559\n",
      "Loss:  0.046655695885419846\n",
      "23 **********\n",
      "Epoch:  1833.0128948688507  fold:  6  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.006190301850438118\n",
      "Eval Loss:  0.29209932684898376\n",
      "Eval Loss:  0.42799392342567444\n",
      "[[2097  135]\n",
      " [ 368  812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      2232\n",
      "           1       0.86      0.69      0.76      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.85      0.81      0.83      3412\n",
      "weighted avg       0.85      0.85      0.85      3412\n",
      "\n",
      "acc:  0.8525791324736225\n",
      "pre:  0.8574445617740233\n",
      "rec:  0.688135593220339\n",
      "ma F1:  0.8282135292470791\n",
      "mi F1:  0.8525791324736225\n",
      "we F1:  0.8481610892426616\n",
      "Eval Loss:  0.1900167316198349\n",
      "Eval Loss:  0.24872829020023346\n",
      "Eval Loss:  0.2151416689157486\n",
      "Eval Loss:  0.22317764163017273\n",
      "Eval Loss:  0.20754215121269226\n",
      "Eval Loss:  0.21975596249103546\n",
      "Eval Loss:  0.35893726348876953\n",
      "Eval Loss:  0.27372345328330994\n",
      "Eval Loss:  0.24548044800758362\n",
      "Eval Loss:  0.24403449892997742\n",
      "Eval Loss:  0.2572183609008789\n",
      "Eval Loss:  0.16230162978172302\n",
      "Eval Loss:  0.23156341910362244\n",
      "Eval Loss:  0.2460123896598816\n",
      "Eval Loss:  0.28440067172050476\n",
      "Eval Loss:  0.17055869102478027\n",
      "Eval Loss:  0.24948157370090485\n",
      "Eval Loss:  0.3109884560108185\n",
      "Eval Loss:  0.22623953223228455\n",
      "Eval Loss:  0.3189764618873596\n",
      "Eval Loss:  0.15831878781318665\n",
      "Eval Loss:  0.20643751323223114\n",
      "Eval Loss:  0.24873776733875275\n",
      "Eval Loss:  0.21946421265602112\n",
      "Eval Loss:  0.2641943097114563\n",
      "Eval Loss:  0.25895199179649353\n",
      "Eval Loss:  0.24208582937717438\n",
      "Eval Loss:  0.19532997906208038\n",
      "[[17100   832]\n",
      " [ 1953  9594]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17932\n",
      "           1       0.92      0.83      0.87     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.89      0.90     29479\n",
      "weighted avg       0.91      0.91      0.90     29479\n",
      "\n",
      "acc:  0.9055259676379795\n",
      "pre:  0.9201995012468828\n",
      "rec:  0.8308651597817615\n",
      "ma F1:  0.8989763704064375\n",
      "mi F1:  0.9055259676379795\n",
      "we F1:  0.9045478037029198\n",
      "29479 461\n",
      "Loss:  0.04976080730557442\n",
      "Loss:  0.05176327005028725\n",
      "Loss:  0.03933078795671463\n",
      "24 **********\n",
      "Epoch:  1937.4616208076477  fold:  6  kers:  128\n",
      "epoch:  25\n",
      "29479 461\n",
      "Loss:  0.04093793034553528\n",
      "Loss:  0.11529715359210968\n",
      "Loss:  0.07885326445102692\n",
      "25 **********\n",
      "Epoch:  2001.4934129714966  fold:  6  kers:  128\n",
      "epoch:  26\n",
      "29479 461\n",
      "Loss:  0.07761502265930176\n",
      "Loss:  0.0471222847700119\n",
      "Loss:  0.03376479819417\n",
      "26 **********\n",
      "Epoch:  2065.525204896927  fold:  6  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.010013901628553867\n",
      "Eval Loss:  0.21067143976688385\n",
      "Eval Loss:  0.33993077278137207\n",
      "[[2118  114]\n",
      " [ 325  855]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      2232\n",
      "           1       0.88      0.72      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8713364595545134\n",
      "pre:  0.8823529411764706\n",
      "rec:  0.7245762711864406\n",
      "ma F1:  0.8509075978629532\n",
      "mi F1:  0.8713364595545134\n",
      "we F1:  0.8679235618372377\n",
      "Eval Loss:  0.15989986062049866\n",
      "Eval Loss:  0.2248193621635437\n",
      "Eval Loss:  0.18334388732910156\n",
      "Eval Loss:  0.20375874638557434\n",
      "Eval Loss:  0.20110780000686646\n",
      "Eval Loss:  0.1934681534767151\n",
      "Eval Loss:  0.3117380440235138\n",
      "Eval Loss:  0.25888073444366455\n",
      "Eval Loss:  0.23620569705963135\n",
      "Eval Loss:  0.24032190442085266\n",
      "Eval Loss:  0.22088906168937683\n",
      "Eval Loss:  0.1565999984741211\n",
      "Eval Loss:  0.23433732986450195\n",
      "Eval Loss:  0.21368110179901123\n",
      "Eval Loss:  0.2593330144882202\n",
      "Eval Loss:  0.14342573285102844\n",
      "Eval Loss:  0.22335202991962433\n",
      "Eval Loss:  0.2623041570186615\n",
      "Eval Loss:  0.1625162959098816\n",
      "Eval Loss:  0.24926462769508362\n",
      "Eval Loss:  0.1742895245552063\n",
      "Eval Loss:  0.19374601542949677\n",
      "Eval Loss:  0.22502949833869934\n",
      "Eval Loss:  0.17048020660877228\n",
      "Eval Loss:  0.2609896659851074\n",
      "Eval Loss:  0.23294107615947723\n",
      "Eval Loss:  0.2034326195716858\n",
      "Eval Loss:  0.17320694029331207\n",
      "[[17009   923]\n",
      " [ 1563  9984]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     17932\n",
      "           1       0.92      0.86      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9156687811662539\n",
      "pre:  0.9153754469606674\n",
      "rec:  0.8646401662769551\n",
      "ma F1:  0.9105913170796247\n",
      "mi F1:  0.9156687811662539\n",
      "we F1:  0.9152062079256215\n",
      "29479 461\n",
      "Loss:  0.06978212296962738\n",
      "Loss:  0.06599712371826172\n",
      "Loss:  0.03714344650506973\n",
      "27 **********\n",
      "Epoch:  2170.113557100296  fold:  6  kers:  128\n",
      "epoch:  28\n",
      "29479 461\n",
      "Loss:  0.042757730931043625\n",
      "Loss:  0.05087679624557495\n",
      "Loss:  0.09704572707414627\n",
      "28 **********\n",
      "Epoch:  2234.1244049072266  fold:  6  kers:  128\n",
      "epoch:  29\n",
      "29479 461\n",
      "Loss:  0.0803709477186203\n",
      "Loss:  0.03424730524420738\n",
      "Loss:  0.09922321885824203\n",
      "29 **********\n",
      "Epoch:  2298.1811299324036  fold:  6  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.012350273318588734\n",
      "Eval Loss:  0.2185414731502533\n",
      "Eval Loss:  0.3818797171115875\n",
      "[[2109  123]\n",
      " [ 336  844]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      2232\n",
      "           1       0.87      0.72      0.79      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.83      0.84      3412\n",
      "weighted avg       0.87      0.87      0.86      3412\n",
      "\n",
      "acc:  0.8654747948417351\n",
      "pre:  0.8728024819027922\n",
      "rec:  0.7152542372881356\n",
      "ma F1:  0.8440367438432372\n",
      "mi F1:  0.8654747948417351\n",
      "we F1:  0.8618650676775611\n",
      "Eval Loss:  0.18099378049373627\n",
      "Eval Loss:  0.23729006946086884\n",
      "Eval Loss:  0.17251558601856232\n",
      "Eval Loss:  0.20264948904514313\n",
      "Eval Loss:  0.16932818293571472\n",
      "Eval Loss:  0.17078760266304016\n",
      "Eval Loss:  0.31159070134162903\n",
      "Eval Loss:  0.24368208646774292\n",
      "Eval Loss:  0.22397269308567047\n",
      "Eval Loss:  0.2629629373550415\n",
      "Eval Loss:  0.21194368600845337\n",
      "Eval Loss:  0.16321316361427307\n",
      "Eval Loss:  0.21818025410175323\n",
      "Eval Loss:  0.2132970541715622\n",
      "Eval Loss:  0.2387886941432953\n",
      "Eval Loss:  0.13791032135486603\n",
      "Eval Loss:  0.23176483809947968\n",
      "Eval Loss:  0.23574486374855042\n",
      "Eval Loss:  0.16839314997196198\n",
      "Eval Loss:  0.27243274450302124\n",
      "Eval Loss:  0.15212468802928925\n",
      "Eval Loss:  0.1477552056312561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2296609878540039\n",
      "Eval Loss:  0.16799145936965942\n",
      "Eval Loss:  0.23977452516555786\n",
      "Eval Loss:  0.23580732941627502\n",
      "Eval Loss:  0.2056625485420227\n",
      "Eval Loss:  0.17072516679763794\n",
      "[[17047   885]\n",
      " [ 1523 10024]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     17932\n",
      "           1       0.92      0.87      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9183147325214559\n",
      "pre:  0.9188743239526996\n",
      "rec:  0.8681042695072313\n",
      "ma F1:  0.9133995458999207\n",
      "mi F1:  0.9183147325214559\n",
      "we F1:  0.9178682154967459\n",
      "29479 461\n",
      "Loss:  0.04661322757601738\n",
      "Loss:  0.06590992957353592\n",
      "Loss:  0.050612710416316986\n",
      "30 **********\n",
      "Epoch:  2402.627861022949  fold:  6  kers:  128\n",
      "epoch:  31\n",
      "29479 461\n",
      "Loss:  0.04607420414686203\n",
      "Loss:  0.07369258254766464\n",
      "Loss:  0.08603904396295547\n",
      "31 **********\n",
      "Epoch:  2466.634719848633  fold:  6  kers:  128\n",
      "epoch:  32\n",
      "29479 461\n",
      "Loss:  0.05651146173477173\n",
      "Loss:  0.05018723011016846\n",
      "Loss:  0.05723181739449501\n",
      "32 **********\n",
      "Epoch:  2530.671498298645  fold:  6  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.014806956984102726\n",
      "Eval Loss:  0.28332844376564026\n",
      "Eval Loss:  0.3415583074092865\n",
      "[[2092  140]\n",
      " [ 310  870]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      2232\n",
      "           1       0.86      0.74      0.79      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8681125439624854\n",
      "pre:  0.8613861386138614\n",
      "rec:  0.7372881355932204\n",
      "ma F1:  0.8487061091042385\n",
      "mi F1:  0.8681125439624854\n",
      "we F1:  0.8654127944322874\n",
      "Eval Loss:  0.17037443816661835\n",
      "Eval Loss:  0.26453644037246704\n",
      "Eval Loss:  0.18960726261138916\n",
      "Eval Loss:  0.21336525678634644\n",
      "Eval Loss:  0.17333418130874634\n",
      "Eval Loss:  0.17675501108169556\n",
      "Eval Loss:  0.3344767391681671\n",
      "Eval Loss:  0.27322641015052795\n",
      "Eval Loss:  0.19495375454425812\n",
      "Eval Loss:  0.25686028599739075\n",
      "Eval Loss:  0.22504165768623352\n",
      "Eval Loss:  0.15948046743869781\n",
      "Eval Loss:  0.22101369500160217\n",
      "Eval Loss:  0.22564063966274261\n",
      "Eval Loss:  0.27458488941192627\n",
      "Eval Loss:  0.1509009748697281\n",
      "Eval Loss:  0.24152573943138123\n",
      "Eval Loss:  0.2595285475254059\n",
      "Eval Loss:  0.1726783663034439\n",
      "Eval Loss:  0.22208037972450256\n",
      "Eval Loss:  0.15441422164440155\n",
      "Eval Loss:  0.16440549492835999\n",
      "Eval Loss:  0.19267497956752777\n",
      "Eval Loss:  0.1535644233226776\n",
      "Eval Loss:  0.2409580647945404\n",
      "Eval Loss:  0.2330986112356186\n",
      "Eval Loss:  0.1660919487476349\n",
      "Eval Loss:  0.16332417726516724\n",
      "[[16847  1085]\n",
      " [ 1353 10194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     17932\n",
      "           1       0.90      0.88      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9172970589233014\n",
      "pre:  0.9038035286816207\n",
      "rec:  0.8828267082359055\n",
      "ma F1:  0.9128585797479299\n",
      "mi F1:  0.9172970589233014\n",
      "we F1:  0.9171182655340033\n",
      "29479 461\n",
      "Loss:  0.04063674435019493\n",
      "Loss:  0.06497346609830856\n",
      "Loss:  0.056247785687446594\n",
      "33 **********\n",
      "Epoch:  2635.1481490135193  fold:  6  kers:  128\n",
      "epoch:  34\n",
      "29479 461\n",
      "Loss:  0.04457973688840866\n",
      "Loss:  0.04829785227775574\n",
      "Loss:  0.052192289382219315\n",
      "34 **********\n",
      "Epoch:  2699.1550076007843  fold:  6  kers:  128\n",
      "epoch:  35\n",
      "29479 461\n",
      "Loss:  0.059484418481588364\n",
      "Loss:  0.054887451231479645\n",
      "Loss:  0.011145683005452156\n",
      "35 **********\n",
      "Epoch:  2763.169845342636  fold:  6  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.010324310511350632\n",
      "Eval Loss:  0.26636335253715515\n",
      "Eval Loss:  0.34768587350845337\n",
      "[[2112  120]\n",
      " [ 354  826]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      2232\n",
      "           1       0.87      0.70      0.78      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.82      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8610785463071512\n",
      "pre:  0.8731501057082452\n",
      "rec:  0.7\n",
      "ma F1:  0.8380760492545616\n",
      "mi F1:  0.8610785463071512\n",
      "we F1:  0.8568930219601015\n",
      "Eval Loss:  0.15563125908374786\n",
      "Eval Loss:  0.255852609872818\n",
      "Eval Loss:  0.15823890268802643\n",
      "Eval Loss:  0.21077032387256622\n",
      "Eval Loss:  0.1525772511959076\n",
      "Eval Loss:  0.15620830655097961\n",
      "Eval Loss:  0.3271886110305786\n",
      "Eval Loss:  0.24060887098312378\n",
      "Eval Loss:  0.21180693805217743\n",
      "Eval Loss:  0.2423098236322403\n",
      "Eval Loss:  0.1716500222682953\n",
      "Eval Loss:  0.17155097424983978\n",
      "Eval Loss:  0.18688644468784332\n",
      "Eval Loss:  0.2094787210226059\n",
      "Eval Loss:  0.2323078066110611\n",
      "Eval Loss:  0.14695702493190765\n",
      "Eval Loss:  0.21553410589694977\n",
      "Eval Loss:  0.25018054246902466\n",
      "Eval Loss:  0.1431010216474533\n",
      "Eval Loss:  0.24891386926174164\n",
      "Eval Loss:  0.17001526057720184\n",
      "Eval Loss:  0.15347489714622498\n",
      "Eval Loss:  0.23275445401668549\n",
      "Eval Loss:  0.13657070696353912\n",
      "Eval Loss:  0.25128498673439026\n",
      "Eval Loss:  0.23002734780311584\n",
      "Eval Loss:  0.15978176891803741\n",
      "Eval Loss:  0.1415514498949051\n",
      "[[16944   988]\n",
      " [ 1307 10240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     17932\n",
      "           1       0.91      0.89      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.92      0.92     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9221479697411716\n",
      "pre:  0.9120057000356252\n",
      "rec:  0.8868104269507231\n",
      "ma F1:  0.9179020185626103\n",
      "mi F1:  0.9221479697411716\n",
      "we F1:  0.9219459323864638\n",
      "29479 461\n",
      "Loss:  0.036265306174755096\n",
      "Loss:  0.03692815452814102\n",
      "Loss:  0.059632398188114166\n",
      "36 **********\n",
      "Epoch:  2867.7033438682556  fold:  6  kers:  128\n",
      "epoch:  37\n",
      "29479 461\n",
      "Loss:  0.05345212668180466\n",
      "Loss:  0.059290628880262375\n",
      "Loss:  0.029472870752215385\n",
      "37 **********\n",
      "Epoch:  2931.7092049121857  fold:  6  kers:  128\n",
      "epoch:  38\n",
      "29479 461\n",
      "Loss:  0.03421653434634209\n",
      "Loss:  0.05672144889831543\n",
      "Loss:  0.034820303320884705\n",
      "38 **********\n",
      "Epoch:  2995.7489759922028  fold:  6  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.007526670582592487\n",
      "Eval Loss:  0.3432769477367401\n",
      "Eval Loss:  0.41960036754608154\n",
      "[[2123  109]\n",
      " [ 367  813]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      2232\n",
      "           1       0.88      0.69      0.77      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.87      0.82      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8604923798358733\n",
      "pre:  0.8817787418655098\n",
      "rec:  0.6889830508474576\n",
      "ma F1:  0.8363721285994137\n",
      "mi F1:  0.8604923798358733\n",
      "we F1:  0.8557419792106774\n",
      "Eval Loss:  0.15098229050636292\n",
      "Eval Loss:  0.21604329347610474\n",
      "Eval Loss:  0.15261295437812805\n",
      "Eval Loss:  0.20130611956119537\n",
      "Eval Loss:  0.15184558928012848\n",
      "Eval Loss:  0.17022094130516052\n",
      "Eval Loss:  0.3140016794204712\n",
      "Eval Loss:  0.23679783940315247\n",
      "Eval Loss:  0.23812177777290344\n",
      "Eval Loss:  0.2448592185974121\n",
      "Eval Loss:  0.19453507661819458\n",
      "Eval Loss:  0.15663884580135345\n",
      "Eval Loss:  0.1848454475402832\n",
      "Eval Loss:  0.18256130814552307\n",
      "Eval Loss:  0.22704389691352844\n",
      "Eval Loss:  0.14689598977565765\n",
      "Eval Loss:  0.19980548322200775\n",
      "Eval Loss:  0.2337064892053604\n",
      "Eval Loss:  0.17475491762161255\n",
      "Eval Loss:  0.21834079921245575\n",
      "Eval Loss:  0.15504460036754608\n",
      "Eval Loss:  0.1580786406993866\n",
      "Eval Loss:  0.20487622916698456\n",
      "Eval Loss:  0.16131429374217987\n",
      "Eval Loss:  0.23685388267040253\n",
      "Eval Loss:  0.23131845891475677\n",
      "Eval Loss:  0.17228761315345764\n",
      "Eval Loss:  0.15002594888210297\n",
      "[[17119   813]\n",
      " [ 1411 10136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     17932\n",
      "           1       0.93      0.88      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.92      0.92     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9245564639234709\n",
      "pre:  0.9257466435290894\n",
      "rec:  0.8778037585520049\n",
      "ma F1:  0.9200714857916732\n",
      "mi F1:  0.9245564639234709\n",
      "we F1:  0.9241723858878393\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.048577167093753815\n",
      "Loss:  0.06361685693264008\n",
      "Loss:  0.06090996041893959\n",
      "39 **********\n",
      "Epoch:  3102.7977492809296  fold:  6  kers:  128\n",
      "epoch:  40\n",
      "29479 461\n",
      "Loss:  0.0782904103398323\n",
      "Loss:  0.035481907427310944\n",
      "Loss:  0.04217958077788353\n",
      "40 **********\n",
      "Epoch:  3166.7916424274445  fold:  6  kers:  128\n",
      "epoch:  41\n",
      "29479 461\n",
      "Loss:  0.07916194945573807\n",
      "Loss:  0.05003281682729721\n",
      "Loss:  0.10277433693408966\n",
      "41 **********\n",
      "Epoch:  3231.482671737671  fold:  6  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.01121016126126051\n",
      "Eval Loss:  0.3998183608055115\n",
      "Eval Loss:  0.34993240237236023\n",
      "[[2107  125]\n",
      " [ 328  852]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      2232\n",
      "           1       0.87      0.72      0.79      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.83      0.85      3412\n",
      "weighted avg       0.87      0.87      0.86      3412\n",
      "\n",
      "acc:  0.8672332942555686\n",
      "pre:  0.872057318321392\n",
      "rec:  0.7220338983050848\n",
      "ma F1:  0.8464607982004861\n",
      "mi F1:  0.8672332942555686\n",
      "we F1:  0.8638732809494477\n",
      "Eval Loss:  0.155019611120224\n",
      "Eval Loss:  0.22431188821792603\n",
      "Eval Loss:  0.19533905386924744\n",
      "Eval Loss:  0.22645825147628784\n",
      "Eval Loss:  0.17880003154277802\n",
      "Eval Loss:  0.18788518011569977\n",
      "Eval Loss:  0.3751216232776642\n",
      "Eval Loss:  0.24483747780323029\n",
      "Eval Loss:  0.1942005455493927\n",
      "Eval Loss:  0.26140058040618896\n",
      "Eval Loss:  0.21652084589004517\n",
      "Eval Loss:  0.17029723525047302\n",
      "Eval Loss:  0.19514645636081696\n",
      "Eval Loss:  0.2056388258934021\n",
      "Eval Loss:  0.24985264241695404\n",
      "Eval Loss:  0.17242704331874847\n",
      "Eval Loss:  0.2245386689901352\n",
      "Eval Loss:  0.2567800283432007\n",
      "Eval Loss:  0.20585033297538757\n",
      "Eval Loss:  0.23431749641895294\n",
      "Eval Loss:  0.15445652604103088\n",
      "Eval Loss:  0.17175595462322235\n",
      "Eval Loss:  0.19125822186470032\n",
      "Eval Loss:  0.18631480634212494\n",
      "Eval Loss:  0.25593987107276917\n",
      "Eval Loss:  0.23789671063423157\n",
      "Eval Loss:  0.16298985481262207\n",
      "Eval Loss:  0.17407315969467163\n",
      "[[16948   984]\n",
      " [ 1406 10141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     17932\n",
      "           1       0.91      0.88      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9189253366803487\n",
      "pre:  0.9115505617977528\n",
      "rec:  0.8782367714557894\n",
      "ma F1:  0.9143590021382313\n",
      "mi F1:  0.9189253366803487\n",
      "we F1:  0.9186422467469313\n",
      "29479 461\n",
      "Loss:  0.04696442559361458\n",
      "Loss:  0.04505450651049614\n",
      "Loss:  0.03603846952319145\n",
      "42 **********\n",
      "Epoch:  3336.1617810726166  fold:  6  kers:  128\n",
      "epoch:  43\n",
      "29479 461\n",
      "Loss:  0.03212098777294159\n",
      "Loss:  0.0724831074476242\n",
      "Loss:  0.06649993360042572\n",
      "43 **********\n",
      "Epoch:  3400.226484775543  fold:  6  kers:  128\n",
      "epoch:  44\n",
      "29479 461\n",
      "Loss:  0.04553225636482239\n",
      "Loss:  0.051475487649440765\n",
      "Loss:  0.05915417522192001\n",
      "44 **********\n",
      "Epoch:  3464.2652583122253  fold:  6  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.030741535127162933\n",
      "Eval Loss:  0.18217648565769196\n",
      "Eval Loss:  0.3032265901565552\n",
      "[[2037  195]\n",
      " [ 273  907]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      2232\n",
      "           1       0.82      0.77      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.85      0.84      0.85      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8628370457209847\n",
      "pre:  0.823049001814882\n",
      "rec:  0.7686440677966102\n",
      "ma F1:  0.8459392152935442\n",
      "mi F1:  0.8628370457209847\n",
      "we F1:  0.8616706468065243\n",
      "Eval Loss:  0.1435004025697708\n",
      "Eval Loss:  0.22012494504451752\n",
      "Eval Loss:  0.15166470408439636\n",
      "Eval Loss:  0.17455577850341797\n",
      "Eval Loss:  0.1362115442752838\n",
      "Eval Loss:  0.18600228428840637\n",
      "Eval Loss:  0.3195072114467621\n",
      "Eval Loss:  0.2501096725463867\n",
      "Eval Loss:  0.1970287561416626\n",
      "Eval Loss:  0.22677819430828094\n",
      "Eval Loss:  0.1886235624551773\n",
      "Eval Loss:  0.14338211715221405\n",
      "Eval Loss:  0.203879252076149\n",
      "Eval Loss:  0.21140003204345703\n",
      "Eval Loss:  0.2648654282093048\n",
      "Eval Loss:  0.11569849401712418\n",
      "Eval Loss:  0.2188704013824463\n",
      "Eval Loss:  0.24214854836463928\n",
      "Eval Loss:  0.1781676709651947\n",
      "Eval Loss:  0.1915775090456009\n",
      "Eval Loss:  0.1353895515203476\n",
      "Eval Loss:  0.12827584147453308\n",
      "Eval Loss:  0.2040460854768753\n",
      "Eval Loss:  0.1384846270084381\n",
      "Eval Loss:  0.2641136646270752\n",
      "Eval Loss:  0.22494444251060486\n",
      "Eval Loss:  0.14039865136146545\n",
      "Eval Loss:  0.1448797881603241\n",
      "[[16833  1099]\n",
      " [ 1116 10431]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     17932\n",
      "           1       0.90      0.90      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.92      0.92     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9248617660029174\n",
      "pre:  0.904683434518647\n",
      "rec:  0.9033515198752923\n",
      "ma F1:  0.9211425754097574\n",
      "mi F1:  0.9248617660029174\n",
      "we F1:  0.9248518899891585\n",
      "29479 461\n",
      "Loss:  0.06280740350484848\n",
      "Loss:  0.055354297161102295\n",
      "Loss:  0.052059661597013474\n",
      "45 **********\n",
      "Epoch:  3568.8865225315094  fold:  6  kers:  128\n",
      "epoch:  46\n",
      "29479 461\n",
      "Loss:  0.033126361668109894\n",
      "Loss:  0.041719693690538406\n",
      "Loss:  0.04513612389564514\n",
      "46 **********\n",
      "Epoch:  3632.89737033844  fold:  6  kers:  128\n",
      "epoch:  47\n",
      "29479 461\n",
      "Loss:  0.05630803853273392\n",
      "Loss:  0.036288708448410034\n",
      "Loss:  0.04748057574033737\n",
      "47 **********\n",
      "Epoch:  3696.8912637233734  fold:  6  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.010815258137881756\n",
      "Eval Loss:  0.33476370573043823\n",
      "Eval Loss:  0.26900145411491394\n",
      "[[2076  156]\n",
      " [ 330  850]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90      2232\n",
      "           1       0.84      0.72      0.78      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.85      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.85      3412\n",
      "\n",
      "acc:  0.8575615474794842\n",
      "pre:  0.8449304174950298\n",
      "rec:  0.7203389830508474\n",
      "ma F1:  0.8364447874217796\n",
      "mi F1:  0.8575615474794841\n",
      "we F1:  0.8545645521695\n",
      "Eval Loss:  0.13676562905311584\n",
      "Eval Loss:  0.19997763633728027\n",
      "Eval Loss:  0.1620180308818817\n",
      "Eval Loss:  0.19885914027690887\n",
      "Eval Loss:  0.14061826467514038\n",
      "Eval Loss:  0.17774145305156708\n",
      "Eval Loss:  0.410347044467926\n",
      "Eval Loss:  0.2592325806617737\n",
      "Eval Loss:  0.18503621220588684\n",
      "Eval Loss:  0.2436070740222931\n",
      "Eval Loss:  0.17863166332244873\n",
      "Eval Loss:  0.1429733783006668\n",
      "Eval Loss:  0.19798389077186584\n",
      "Eval Loss:  0.22093871235847473\n",
      "Eval Loss:  0.2925887703895569\n",
      "Eval Loss:  0.12774859368801117\n",
      "Eval Loss:  0.22938397526741028\n",
      "Eval Loss:  0.2881862223148346\n",
      "Eval Loss:  0.18162527680397034\n",
      "Eval Loss:  0.208682119846344\n",
      "Eval Loss:  0.1446317732334137\n",
      "Eval Loss:  0.13058006763458252\n",
      "Eval Loss:  0.18174433708190918\n",
      "Eval Loss:  0.11992248147726059\n",
      "Eval Loss:  0.2523573637008667\n",
      "Eval Loss:  0.23329591751098633\n",
      "Eval Loss:  0.15260517597198486\n",
      "Eval Loss:  0.13328993320465088\n",
      "[[16849  1083]\n",
      " [ 1116 10431]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     17932\n",
      "           1       0.91      0.90      0.90     11547\n",
      "\n",
      "    accuracy                           0.93     29479\n",
      "   macro avg       0.92      0.92      0.92     29479\n",
      "weighted avg       0.93      0.93      0.93     29479\n",
      "\n",
      "acc:  0.9254045252552665\n",
      "pre:  0.905940594059406\n",
      "rec:  0.9033515198752923\n",
      "ma F1:  0.9216928017519039\n",
      "mi F1:  0.9254045252552665\n",
      "we F1:  0.9253854403572278\n",
      "29479 461\n",
      "Loss:  0.06647592782974243\n",
      "Loss:  0.06422479450702667\n",
      "Loss:  0.03890868276357651\n",
      "48 **********\n",
      "Epoch:  3801.3280210494995  fold:  6  kers:  128\n",
      "epoch:  49\n",
      "29479 461\n",
      "Loss:  0.05282563716173172\n",
      "Loss:  0.03495980426669121\n",
      "Loss:  0.06418877094984055\n",
      "49 **********\n",
      "Epoch:  3865.319919347763  fold:  6  kers:  128\n",
      "epoch:  50\n",
      "29479 461\n",
      "Loss:  0.04729852452874184\n",
      "Loss:  0.03701024502515793\n",
      "Loss:  0.0593181848526001\n",
      "50 **********\n",
      "Epoch:  3929.3417382240295  fold:  6  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.008548974990844727\n",
      "Eval Loss:  0.3507422208786011\n",
      "Eval Loss:  0.37670111656188965\n",
      "[[2108  124]\n",
      " [ 378  802]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      2232\n",
      "           1       0.87      0.68      0.76      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.86      0.81      0.83      3412\n",
      "weighted avg       0.85      0.85      0.85      3412\n",
      "\n",
      "acc:  0.8528722157092614\n",
      "pre:  0.8660907127429806\n",
      "rec:  0.6796610169491526\n",
      "ma F1:  0.8276162054599245\n",
      "mi F1:  0.8528722157092614\n",
      "we F1:  0.8479602504693444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.15211252868175507\n",
      "Eval Loss:  0.215500608086586\n",
      "Eval Loss:  0.14208458364009857\n",
      "Eval Loss:  0.1832229346036911\n",
      "Eval Loss:  0.1233748272061348\n",
      "Eval Loss:  0.15541361272335052\n",
      "Eval Loss:  0.3063914477825165\n",
      "Eval Loss:  0.2203393429517746\n",
      "Eval Loss:  0.17524345219135284\n",
      "Eval Loss:  0.20599031448364258\n",
      "Eval Loss:  0.17555026710033417\n",
      "Eval Loss:  0.15466992557048798\n",
      "Eval Loss:  0.1791786253452301\n",
      "Eval Loss:  0.17414799332618713\n",
      "Eval Loss:  0.20571209490299225\n",
      "Eval Loss:  0.1320495903491974\n",
      "Eval Loss:  0.20074176788330078\n",
      "Eval Loss:  0.18970656394958496\n",
      "Eval Loss:  0.15648746490478516\n",
      "Eval Loss:  0.19786636531352997\n",
      "Eval Loss:  0.1644497513771057\n",
      "Eval Loss:  0.115165576338768\n",
      "Eval Loss:  0.16620729863643646\n",
      "Eval Loss:  0.1113506406545639\n",
      "Eval Loss:  0.21855975687503815\n",
      "Eval Loss:  0.20785900950431824\n",
      "Eval Loss:  0.13968463242053986\n",
      "Eval Loss:  0.13919256627559662\n",
      "[[16977   955]\n",
      " [ 1021 10526]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     17932\n",
      "           1       0.92      0.91      0.91     11547\n",
      "\n",
      "    accuracy                           0.93     29479\n",
      "   macro avg       0.93      0.93      0.93     29479\n",
      "weighted avg       0.93      0.93      0.93     29479\n",
      "\n",
      "acc:  0.9329692323348825\n",
      "pre:  0.9168190924135529\n",
      "rec:  0.9115787650471984\n",
      "ma F1:  0.9295977969631085\n",
      "mi F1:  0.9329692323348825\n",
      "we F1:  0.9329347392741884\n",
      "29479 461\n",
      "Loss:  0.02286756969988346\n",
      "Loss:  0.060627300292253494\n",
      "Loss:  0.04419467970728874\n",
      "51 **********\n",
      "Epoch:  4033.874240875244  fold:  6  kers:  128\n",
      "epoch:  52\n",
      "29479 461\n",
      "Loss:  0.032823044806718826\n",
      "Loss:  0.04416356980800629\n",
      "Loss:  0.056848376989364624\n",
      "52 **********\n",
      "Epoch:  4097.8940641880035  fold:  6  kers:  128\n",
      "epoch:  53\n",
      "29479 461\n",
      "Loss:  0.046340737491846085\n",
      "Loss:  0.040911801159381866\n",
      "Loss:  0.0642305389046669\n",
      "53 **********\n",
      "Epoch:  4161.926852941513  fold:  6  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.005360214039683342\n",
      "Eval Loss:  0.2649398744106293\n",
      "Eval Loss:  0.2552042603492737\n",
      "[[2097  135]\n",
      " [ 337  843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      2232\n",
      "           1       0.86      0.71      0.78      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.861664712778429\n",
      "pre:  0.8619631901840491\n",
      "rec:  0.714406779661017\n",
      "ma F1:  0.8400608269074847\n",
      "mi F1:  0.861664712778429\n",
      "we F1:  0.8581846609874156\n",
      "Eval Loss:  0.11367271840572357\n",
      "Eval Loss:  0.21867601573467255\n",
      "Eval Loss:  0.14855743944644928\n",
      "Eval Loss:  0.18048712611198425\n",
      "Eval Loss:  0.15919262170791626\n",
      "Eval Loss:  0.14747978746891022\n",
      "Eval Loss:  0.28417253494262695\n",
      "Eval Loss:  0.2328949123620987\n",
      "Eval Loss:  0.17995065450668335\n",
      "Eval Loss:  0.21876458823680878\n",
      "Eval Loss:  0.16913925111293793\n",
      "Eval Loss:  0.1451842337846756\n",
      "Eval Loss:  0.1801854521036148\n",
      "Eval Loss:  0.17536386847496033\n",
      "Eval Loss:  0.20180237293243408\n",
      "Eval Loss:  0.11110380291938782\n",
      "Eval Loss:  0.16806836426258087\n",
      "Eval Loss:  0.16745074093341827\n",
      "Eval Loss:  0.14907747507095337\n",
      "Eval Loss:  0.1734975278377533\n",
      "Eval Loss:  0.18258123099803925\n",
      "Eval Loss:  0.12374673038721085\n",
      "Eval Loss:  0.1933213472366333\n",
      "Eval Loss:  0.12715286016464233\n",
      "Eval Loss:  0.20552733540534973\n",
      "Eval Loss:  0.22134700417518616\n",
      "Eval Loss:  0.18929021060466766\n",
      "Eval Loss:  0.15064355731010437\n",
      "[[16955   977]\n",
      " [ 1089 10458]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     17932\n",
      "           1       0.91      0.91      0.91     11547\n",
      "\n",
      "    accuracy                           0.93     29479\n",
      "   macro avg       0.93      0.93      0.93     29479\n",
      "weighted avg       0.93      0.93      0.93     29479\n",
      "\n",
      "acc:  0.9299162115404186\n",
      "pre:  0.9145605596851771\n",
      "rec:  0.9056897895557288\n",
      "ma F1:  0.9263381928179737\n",
      "mi F1:  0.9299162115404186\n",
      "we F1:  0.9298545310575935\n",
      "29479 461\n",
      "Loss:  0.02900339849293232\n",
      "Loss:  0.05938752740621567\n",
      "Loss:  0.05151565372943878\n",
      "54 **********\n",
      "Epoch:  4266.400511741638  fold:  6  kers:  128\n",
      "epoch:  55\n",
      "29479 461\n",
      "Loss:  0.06078297272324562\n",
      "Loss:  0.044571660459041595\n",
      "Loss:  0.050145432353019714\n",
      "55 **********\n",
      "Epoch:  4330.438287734985  fold:  6  kers:  128\n",
      "epoch:  56\n",
      "29479 461\n",
      "Loss:  0.07020292431116104\n",
      "Loss:  0.03239332139492035\n",
      "Loss:  0.057901982218027115\n",
      "56 **********\n",
      "Epoch:  4394.467087507248  fold:  6  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.007270996458828449\n",
      "Eval Loss:  0.38618481159210205\n",
      "Eval Loss:  0.2992749810218811\n",
      "[[2089  143]\n",
      " [ 323  857]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      2232\n",
      "           1       0.86      0.73      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8634232121922626\n",
      "pre:  0.857\n",
      "rec:  0.726271186440678\n",
      "ma F1:  0.8429470007665016\n",
      "mi F1:  0.8634232121922626\n",
      "we F1:  0.8604315579255118\n",
      "Eval Loss:  0.10965528339147568\n",
      "Eval Loss:  0.1829729527235031\n",
      "Eval Loss:  0.14721475541591644\n",
      "Eval Loss:  0.19137270748615265\n",
      "Eval Loss:  0.13870084285736084\n",
      "Eval Loss:  0.1729481816291809\n",
      "Eval Loss:  0.32071617245674133\n",
      "Eval Loss:  0.23148579895496368\n",
      "Eval Loss:  0.16110144555568695\n",
      "Eval Loss:  0.23880842328071594\n",
      "Eval Loss:  0.18924760818481445\n",
      "Eval Loss:  0.1574573814868927\n",
      "Eval Loss:  0.16214749217033386\n",
      "Eval Loss:  0.18220071494579315\n",
      "Eval Loss:  0.20905250310897827\n",
      "Eval Loss:  0.1349877566099167\n",
      "Eval Loss:  0.227642223238945\n",
      "Eval Loss:  0.19276629388332367\n",
      "Eval Loss:  0.17059201002120972\n",
      "Eval Loss:  0.16844166815280914\n",
      "Eval Loss:  0.1323162466287613\n",
      "Eval Loss:  0.1267842799425125\n",
      "Eval Loss:  0.16933028399944305\n",
      "Eval Loss:  0.12392731010913849\n",
      "Eval Loss:  0.21063052117824554\n",
      "Eval Loss:  0.19960230588912964\n",
      "Eval Loss:  0.12761108577251434\n",
      "Eval Loss:  0.1479663848876953\n",
      "[[17065   867]\n",
      " [ 1142 10405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     17932\n",
      "           1       0.92      0.90      0.91     11547\n",
      "\n",
      "    accuracy                           0.93     29479\n",
      "   macro avg       0.93      0.93      0.93     29479\n",
      "weighted avg       0.93      0.93      0.93     29479\n",
      "\n",
      "acc:  0.9318497913769124\n",
      "pre:  0.9230837473385379\n",
      "rec:  0.9010998527756127\n",
      "ma F1:  0.9281842096356412\n",
      "mi F1:  0.9318497913769124\n",
      "we F1:  0.9316984347734815\n",
      "29479 461\n",
      "Loss:  0.02977129817008972\n",
      "Loss:  0.028314713388681412\n",
      "Loss:  0.05466692894697189\n",
      "57 **********\n",
      "Epoch:  4499.010559558868  fold:  6  kers:  128\n",
      "epoch:  58\n",
      "29479 461\n",
      "Loss:  0.05646105483174324\n",
      "Loss:  0.04560653492808342\n",
      "Loss:  0.05303572490811348\n",
      "58 **********\n",
      "Epoch:  4563.019413232803  fold:  6  kers:  128\n",
      "epoch:  59\n",
      "29479 461\n",
      "Loss:  0.07057783007621765\n",
      "Loss:  0.04692670702934265\n",
      "Loss:  0.03950520604848862\n",
      "59 **********\n",
      "Epoch:  4627.05220246315  fold:  6  kers:  128\n",
      "Eval Loss:  0.0062670623883605\n",
      "Eval Loss:  0.29488644003868103\n",
      "Eval Loss:  0.2860229015350342\n",
      "[[2117  115]\n",
      " [ 364  816]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      2232\n",
      "           1       0.88      0.69      0.77      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.82      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8596131301289566\n",
      "pre:  0.8764769065520945\n",
      "rec:  0.6915254237288135\n",
      "ma F1:  0.8357297708958449\n",
      "mi F1:  0.8596131301289566\n",
      "we F1:  0.8550420644494447\n",
      "update!  Acc:  0.888335287221571\n",
      "Epoch:  4631.337743520737  fold:  6  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.1598127782344818\n",
      "Loss:  0.166143998503685\n",
      "Loss:  0.14079909026622772\n",
      "0 **********\n",
      "Epoch:  76.27704954147339  fold:  7  kers:  128\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.11716792732477188\n",
      "Loss:  0.125512033700943\n",
      "Loss:  0.10314831137657166\n",
      "1 **********\n",
      "Epoch:  140.27193927764893  fold:  7  kers:  128\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.11303666979074478\n",
      "Loss:  0.10773240029811859\n",
      "Loss:  0.10096018761396408\n",
      "2 **********\n",
      "Epoch:  204.25685715675354  fold:  7  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.7623918652534485\n",
      "Eval Loss:  0.1061565950512886\n",
      "Eval Loss:  2.2451934814453125\n",
      "[[1765  362]\n",
      " [ 742  562]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.83      0.76      2127\n",
      "           1       0.61      0.43      0.50      1304\n",
      "\n",
      "    accuracy                           0.68      3431\n",
      "   macro avg       0.66      0.63      0.63      3431\n",
      "weighted avg       0.67      0.68      0.66      3431\n",
      "\n",
      "acc:  0.6782279218886622\n",
      "pre:  0.6082251082251082\n",
      "rec:  0.43098159509202455\n",
      "ma F1:  0.6331246140268362\n",
      "mi F1:  0.6782279218886622\n",
      "we F1:  0.6639808254734553\n",
      "update!  Acc:  0.6782279218886622\n",
      "Eval Loss:  0.32234281301498413\n",
      "Eval Loss:  0.3313775956630707\n",
      "Eval Loss:  0.47295114398002625\n",
      "Eval Loss:  0.44335678219795227\n",
      "Eval Loss:  0.48709073662757874\n",
      "Eval Loss:  0.5043299794197083\n",
      "Eval Loss:  0.46547064185142517\n",
      "Eval Loss:  0.3652157783508301\n",
      "Eval Loss:  0.4412221908569336\n",
      "Eval Loss:  0.48726871609687805\n",
      "Eval Loss:  0.4147898554801941\n",
      "Eval Loss:  0.35467252135276794\n",
      "Eval Loss:  0.3256877362728119\n",
      "Eval Loss:  0.4732327461242676\n",
      "Eval Loss:  0.3105382025241852\n",
      "Eval Loss:  0.4303287863731384\n",
      "Eval Loss:  0.421191543340683\n",
      "Eval Loss:  0.4255719780921936\n",
      "Eval Loss:  0.541515588760376\n",
      "Eval Loss:  0.3516567349433899\n",
      "Eval Loss:  0.3957309126853943\n",
      "Eval Loss:  0.3506050109863281\n",
      "Eval Loss:  0.43690308928489685\n",
      "Eval Loss:  0.44701331853866577\n",
      "Eval Loss:  0.4921298325061798\n",
      "Eval Loss:  0.46292632818222046\n",
      "Eval Loss:  0.44694817066192627\n",
      "Eval Loss:  0.38760262727737427\n",
      "[[16211  1826]\n",
      " [ 3318  8105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86     18037\n",
      "           1       0.82      0.71      0.76     11423\n",
      "\n",
      "    accuracy                           0.83     29460\n",
      "   macro avg       0.82      0.80      0.81     29460\n",
      "weighted avg       0.82      0.83      0.82     29460\n",
      "\n",
      "acc:  0.8253903598099117\n",
      "pre:  0.8161313060114792\n",
      "rec:  0.7095333975312965\n",
      "ma F1:  0.8110880156721678\n",
      "mi F1:  0.8253903598099118\n",
      "we F1:  0.8227578533389626\n",
      "29460 461\n",
      "Loss:  0.08184985816478729\n",
      "Loss:  0.10214000940322876\n",
      "Loss:  0.10063616931438446\n",
      "3 **********\n",
      "Epoch:  308.93895840644836  fold:  7  kers:  128\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.08320487290620804\n",
      "Loss:  0.09410829097032547\n",
      "Loss:  0.0731024518609047\n",
      "4 **********\n",
      "Epoch:  372.8959505558014  fold:  7  kers:  128\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.09614293277263641\n",
      "Loss:  0.0620780810713768\n",
      "Loss:  0.08252722769975662\n",
      "5 **********\n",
      "Epoch:  436.8848567008972  fold:  7  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.6401649713516235\n",
      "Eval Loss:  0.0963985025882721\n",
      "Eval Loss:  2.614823818206787\n",
      "[[1982  145]\n",
      " [ 837  467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80      2127\n",
      "           1       0.76      0.36      0.49      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.73      0.64      0.64      3431\n",
      "weighted avg       0.73      0.71      0.68      3431\n",
      "\n",
      "acc:  0.7137860682016904\n",
      "pre:  0.7630718954248366\n",
      "rec:  0.3581288343558282\n",
      "ma F1:  0.6444648128809936\n",
      "mi F1:  0.7137860682016904\n",
      "we F1:  0.6821224981146131\n",
      "update!  Acc:  0.7137860682016904\n",
      "Eval Loss:  0.26109522581100464\n",
      "Eval Loss:  0.2787216901779175\n",
      "Eval Loss:  0.4283716082572937\n",
      "Eval Loss:  0.4013708233833313\n",
      "Eval Loss:  0.4383181631565094\n",
      "Eval Loss:  0.39522871375083923\n",
      "Eval Loss:  0.4026773273944855\n",
      "Eval Loss:  0.36952173709869385\n",
      "Eval Loss:  0.3737826645374298\n",
      "Eval Loss:  0.4443710446357727\n",
      "Eval Loss:  0.3666282594203949\n",
      "Eval Loss:  0.27239254117012024\n",
      "Eval Loss:  0.27290427684783936\n",
      "Eval Loss:  0.40657246112823486\n",
      "Eval Loss:  0.22569498419761658\n",
      "Eval Loss:  0.4047720730304718\n",
      "Eval Loss:  0.3505822420120239\n",
      "Eval Loss:  0.3685570955276489\n",
      "Eval Loss:  0.46860432624816895\n",
      "Eval Loss:  0.30153322219848633\n",
      "Eval Loss:  0.3664316236972809\n",
      "Eval Loss:  0.296413779258728\n",
      "Eval Loss:  0.3263687193393707\n",
      "Eval Loss:  0.3589112460613251\n",
      "Eval Loss:  0.4330288767814636\n",
      "Eval Loss:  0.3698894679546356\n",
      "Eval Loss:  0.3785928189754486\n",
      "Eval Loss:  0.33496758341789246\n",
      "[[17051   986]\n",
      " [ 3248  8175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18037\n",
      "           1       0.89      0.72      0.79     11423\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.87      0.83      0.84     29460\n",
      "weighted avg       0.86      0.86      0.85     29460\n",
      "\n",
      "acc:  0.8562797012898846\n",
      "pre:  0.8923698286213295\n",
      "rec:  0.715661384925151\n",
      "ma F1:  0.8419308832345916\n",
      "mi F1:  0.8562797012898846\n",
      "we F1:  0.8526229835745767\n",
      "29460 461\n",
      "Loss:  0.06684821844100952\n",
      "Loss:  0.07006024569272995\n",
      "Loss:  0.060183510184288025\n",
      "6 **********\n",
      "Epoch:  541.5948836803436  fold:  7  kers:  128\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.08222252875566483\n",
      "Loss:  0.07201746851205826\n",
      "Loss:  0.054143600165843964\n",
      "7 **********\n",
      "Epoch:  605.5827925205231  fold:  7  kers:  128\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.09654145687818527\n",
      "Loss:  0.0989849865436554\n",
      "Loss:  0.0668383538722992\n",
      "8 **********\n",
      "Epoch:  669.5856626033783  fold:  7  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.9428953528404236\n",
      "Eval Loss:  0.052213121205568314\n",
      "Eval Loss:  3.4497175216674805\n",
      "[[2075   52]\n",
      " [ 976  328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80      2127\n",
      "           1       0.86      0.25      0.39      1304\n",
      "\n",
      "    accuracy                           0.70      3431\n",
      "   macro avg       0.77      0.61      0.60      3431\n",
      "weighted avg       0.75      0.70      0.64      3431\n",
      "\n",
      "acc:  0.7003788982803847\n",
      "pre:  0.8631578947368421\n",
      "rec:  0.25153374233128833\n",
      "ma F1:  0.5955082208760065\n",
      "mi F1:  0.7003788982803847\n",
      "we F1:  0.6449120946618128\n",
      "Eval Loss:  0.23839785158634186\n",
      "Eval Loss:  0.32304897904396057\n",
      "Eval Loss:  0.4746341109275818\n",
      "Eval Loss:  0.44282132387161255\n",
      "Eval Loss:  0.5330315828323364\n",
      "Eval Loss:  0.4357333183288574\n",
      "Eval Loss:  0.3922867476940155\n",
      "Eval Loss:  0.4317505955696106\n",
      "Eval Loss:  0.40660929679870605\n",
      "Eval Loss:  0.5111709237098694\n",
      "Eval Loss:  0.40306904911994934\n",
      "Eval Loss:  0.267588347196579\n",
      "Eval Loss:  0.3292430639266968\n",
      "Eval Loss:  0.449535995721817\n",
      "Eval Loss:  0.25573328137397766\n",
      "Eval Loss:  0.4115211069583893\n",
      "Eval Loss:  0.39576902985572815\n",
      "Eval Loss:  0.39718133211135864\n",
      "Eval Loss:  0.533674418926239\n",
      "Eval Loss:  0.3128189146518707\n",
      "Eval Loss:  0.3750123679637909\n",
      "Eval Loss:  0.3267413079738617\n",
      "Eval Loss:  0.33904045820236206\n",
      "Eval Loss:  0.4250882863998413\n",
      "Eval Loss:  0.501800000667572\n",
      "Eval Loss:  0.3993995189666748\n",
      "Eval Loss:  0.3733704090118408\n",
      "Eval Loss:  0.3593220114707947\n",
      "[[17506   531]\n",
      " [ 4140  7283]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88     18037\n",
      "           1       0.93      0.64      0.76     11423\n",
      "\n",
      "    accuracy                           0.84     29460\n",
      "   macro avg       0.87      0.80      0.82     29460\n",
      "weighted avg       0.86      0.84      0.83     29460\n",
      "\n",
      "acc:  0.8414460285132382\n",
      "pre:  0.9320450473509087\n",
      "rec:  0.6375733169920336\n",
      "ma F1:  0.8197394184646547\n",
      "mi F1:  0.8414460285132382\n",
      "we F1:  0.8337829985156507\n",
      "29460 461\n",
      "Loss:  0.0710364431142807\n",
      "Loss:  0.05927176773548126\n",
      "Loss:  0.07690636813640594\n",
      "9 **********\n",
      "Epoch:  774.2149050235748  fold:  7  kers:  128\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.08427811414003372\n",
      "Loss:  0.07772119343280792\n",
      "Loss:  0.06341475993394852\n",
      "10 **********\n",
      "Epoch:  838.2127873897552  fold:  7  kers:  128\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.10569347441196442\n",
      "Loss:  0.12674660980701447\n",
      "Loss:  0.0853014886379242\n",
      "11 **********\n",
      "Epoch:  902.2385954856873  fold:  7  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.8700850009918213\n",
      "Eval Loss:  0.07921487838029861\n",
      "Eval Loss:  2.8885622024536133\n",
      "[[2055   72]\n",
      " [ 872  432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81      2127\n",
      "           1       0.86      0.33      0.48      1304\n",
      "\n",
      "    accuracy                           0.72      3431\n",
      "   macro avg       0.78      0.65      0.65      3431\n",
      "weighted avg       0.76      0.72      0.69      3431\n",
      "\n",
      "acc:  0.7248615563975518\n",
      "pre:  0.8571428571428571\n",
      "rec:  0.3312883435582822\n",
      "ma F1:  0.6455466799275786\n",
      "mi F1:  0.7248615563975518\n",
      "we F1:  0.6857661151307751\n",
      "update!  Acc:  0.7248615563975518\n",
      "Eval Loss:  0.218893364071846\n",
      "Eval Loss:  0.26830703020095825\n",
      "Eval Loss:  0.3462619185447693\n",
      "Eval Loss:  0.385257363319397\n",
      "Eval Loss:  0.39027127623558044\n",
      "Eval Loss:  0.37490081787109375\n",
      "Eval Loss:  0.33097657561302185\n",
      "Eval Loss:  0.33240896463394165\n",
      "Eval Loss:  0.3494146466255188\n",
      "Eval Loss:  0.42284512519836426\n",
      "Eval Loss:  0.31103193759918213\n",
      "Eval Loss:  0.2234756201505661\n",
      "Eval Loss:  0.27228888869285583\n",
      "Eval Loss:  0.3613359034061432\n",
      "Eval Loss:  0.22205571830272675\n",
      "Eval Loss:  0.31687453389167786\n",
      "Eval Loss:  0.32750728726387024\n",
      "Eval Loss:  0.31840234994888306\n",
      "Eval Loss:  0.41145625710487366\n",
      "Eval Loss:  0.2596202790737152\n",
      "Eval Loss:  0.2743721306324005\n",
      "Eval Loss:  0.2881879508495331\n",
      "Eval Loss:  0.30303066968917847\n",
      "Eval Loss:  0.29075899720191956\n",
      "Eval Loss:  0.4028150141239166\n",
      "Eval Loss:  0.33487391471862793\n",
      "Eval Loss:  0.32352352142333984\n",
      "Eval Loss:  0.31315526366233826\n",
      "[[17459   578]\n",
      " [ 3490  7933]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     18037\n",
      "           1       0.93      0.69      0.80     11423\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.88      0.83      0.85     29460\n",
      "weighted avg       0.87      0.86      0.86     29460\n",
      "\n",
      "acc:  0.8619144602851324\n",
      "pre:  0.9320878862648337\n",
      "rec:  0.6944760570778254\n",
      "ma F1:  0.8457907040496759\n",
      "mi F1:  0.8619144602851324\n",
      "we F1:  0.8569855942177748\n",
      "29460 461\n",
      "Loss:  0.0625765398144722\n",
      "Loss:  0.06173551827669144\n",
      "Loss:  0.11023256927728653\n",
      "12 **********\n",
      "Epoch:  1006.9466271400452  fold:  7  kers:  128\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.06927405297756195\n",
      "Loss:  0.08310440182685852\n",
      "Loss:  0.044597093015909195\n",
      "13 **********\n",
      "Epoch:  1070.9365315437317  fold:  7  kers:  128\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.08858700841665268\n",
      "Loss:  0.08752982318401337\n",
      "Loss:  0.04909313842654228\n",
      "14 **********\n",
      "Epoch:  1134.9403982162476  fold:  7  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.5455573201179504\n",
      "Eval Loss:  0.0759975016117096\n",
      "Eval Loss:  2.3190808296203613\n",
      "[[1983  144]\n",
      " [ 694  610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.83      2127\n",
      "           1       0.81      0.47      0.59      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.70      0.71      3431\n",
      "weighted avg       0.77      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7557563392596911\n",
      "pre:  0.8090185676392573\n",
      "rec:  0.4677914110429448\n",
      "ma F1:  0.7091852918162627\n",
      "mi F1:  0.7557563392596912\n",
      "we F1:  0.7371007849305683\n",
      "update!  Acc:  0.7557563392596911\n",
      "Eval Loss:  0.18237468600273132\n",
      "Eval Loss:  0.23396891355514526\n",
      "Eval Loss:  0.2689417004585266\n",
      "Eval Loss:  0.30939701199531555\n",
      "Eval Loss:  0.3045629858970642\n",
      "Eval Loss:  0.28535568714141846\n",
      "Eval Loss:  0.2786838710308075\n",
      "Eval Loss:  0.29453298449516296\n",
      "Eval Loss:  0.2823754549026489\n",
      "Eval Loss:  0.34275758266448975\n",
      "Eval Loss:  0.2815869450569153\n",
      "Eval Loss:  0.15742221474647522\n",
      "Eval Loss:  0.22750544548034668\n",
      "Eval Loss:  0.2809848189353943\n",
      "Eval Loss:  0.198109433054924\n",
      "Eval Loss:  0.3037826120853424\n",
      "Eval Loss:  0.2712990343570709\n",
      "Eval Loss:  0.30081021785736084\n",
      "Eval Loss:  0.34347569942474365\n",
      "Eval Loss:  0.20141255855560303\n",
      "Eval Loss:  0.2533578872680664\n",
      "Eval Loss:  0.22848497331142426\n",
      "Eval Loss:  0.28824540972709656\n",
      "Eval Loss:  0.22779007256031036\n",
      "Eval Loss:  0.3148331344127655\n",
      "Eval Loss:  0.29064419865608215\n",
      "Eval Loss:  0.25303417444229126\n",
      "Eval Loss:  0.26724034547805786\n",
      "[[17106   931]\n",
      " [ 2259  9164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18037\n",
      "           1       0.91      0.80      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.88      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8917175831636117\n",
      "pre:  0.9077761267954433\n",
      "rec:  0.8022410925326097\n",
      "ma F1:  0.8832312324275724\n",
      "mi F1:  0.8917175831636117\n",
      "we F1:  0.8902985610309675\n",
      "29460 461\n",
      "Loss:  0.06982584297657013\n",
      "Loss:  0.05176836624741554\n",
      "Loss:  0.05974810570478439\n",
      "15 **********\n",
      "Epoch:  1239.667379617691  fold:  7  kers:  128\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.06010577455163002\n",
      "Loss:  0.10942357778549194\n",
      "Loss:  0.06221065670251846\n",
      "16 **********\n",
      "Epoch:  1303.670248746872  fold:  7  kers:  128\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.11228416115045547\n",
      "Loss:  0.0434563048183918\n",
      "Loss:  0.06757500767707825\n",
      "17 **********\n",
      "Epoch:  1367.6721212863922  fold:  7  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.4456029534339905\n",
      "Eval Loss:  0.059903960675001144\n",
      "Eval Loss:  1.8663208484649658\n",
      "[[1927  200]\n",
      " [ 608  696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      2127\n",
      "           1       0.78      0.53      0.63      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.72      0.73      3431\n",
      "weighted avg       0.77      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7645001457301078\n",
      "pre:  0.7767857142857143\n",
      "rec:  0.5337423312883436\n",
      "ma F1:  0.7297055497055498\n",
      "mi F1:  0.7645001457301079\n",
      "we F1:  0.7529678994441455\n",
      "update!  Acc:  0.7645001457301078\n",
      "Eval Loss:  0.17560717463493347\n",
      "Eval Loss:  0.2087695300579071\n",
      "Eval Loss:  0.23374150693416595\n",
      "Eval Loss:  0.27306699752807617\n",
      "Eval Loss:  0.24010589718818665\n",
      "Eval Loss:  0.2449505627155304\n",
      "Eval Loss:  0.2826772630214691\n",
      "Eval Loss:  0.23785129189491272\n",
      "Eval Loss:  0.2540428936481476\n",
      "Eval Loss:  0.29317545890808105\n",
      "Eval Loss:  0.2908620238304138\n",
      "Eval Loss:  0.14559055864810944\n",
      "Eval Loss:  0.19139990210533142\n",
      "Eval Loss:  0.2381363809108734\n",
      "Eval Loss:  0.19607044756412506\n",
      "Eval Loss:  0.30307650566101074\n",
      "Eval Loss:  0.23909848928451538\n",
      "Eval Loss:  0.27581432461738586\n",
      "Eval Loss:  0.30400314927101135\n",
      "Eval Loss:  0.16301229596138\n",
      "Eval Loss:  0.2202458530664444\n",
      "Eval Loss:  0.21606528759002686\n",
      "Eval Loss:  0.2700677514076233\n",
      "Eval Loss:  0.22180722653865814\n",
      "Eval Loss:  0.31784236431121826\n",
      "Eval Loss:  0.25436174869537354\n",
      "Eval Loss:  0.22522883117198944\n",
      "Eval Loss:  0.24793878197669983\n",
      "[[16929  1108]\n",
      " [ 1670  9753]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     18037\n",
      "           1       0.90      0.85      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9057026476578411\n",
      "pre:  0.8979836110855354\n",
      "rec:  0.8538037293180425\n",
      "ma F1:  0.8997547544978578\n",
      "mi F1:  0.9057026476578411\n",
      "we F1:  0.9052368288234053\n",
      "29460 461\n",
      "Loss:  0.03843189403414726\n",
      "Loss:  0.08109016716480255\n",
      "Loss:  0.050590574741363525\n",
      "18 **********\n",
      "Epoch:  1472.1727077960968  fold:  7  kers:  128\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.09410522133111954\n",
      "Loss:  0.04514094442129135\n",
      "Loss:  0.03803497925400734\n",
      "19 **********\n",
      "Epoch:  1536.1586225032806  fold:  7  kers:  128\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.08466663211584091\n",
      "Loss:  0.07662233710289001\n",
      "Loss:  0.05875749513506889\n",
      "20 **********\n",
      "Epoch:  1600.1914114952087  fold:  7  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.5618472099304199\n",
      "Eval Loss:  0.05640764534473419\n",
      "Eval Loss:  2.6476924419403076\n",
      "[[2059   68]\n",
      " [ 820  484]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.82      2127\n",
      "           1       0.88      0.37      0.52      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.80      0.67      0.67      3431\n",
      "weighted avg       0.78      0.74      0.71      3431\n",
      "\n",
      "acc:  0.741183328475663\n",
      "pre:  0.8768115942028986\n",
      "rec:  0.37116564417177916\n",
      "ma F1:  0.672082294350228\n",
      "mi F1:  0.7411833284756629\n",
      "we F1:  0.7081903267852966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18713271617889404\n",
      "Eval Loss:  0.21794117987155914\n",
      "Eval Loss:  0.2880302965641022\n",
      "Eval Loss:  0.32317519187927246\n",
      "Eval Loss:  0.26643994450569153\n",
      "Eval Loss:  0.26051759719848633\n",
      "Eval Loss:  0.27307841181755066\n",
      "Eval Loss:  0.25025784969329834\n",
      "Eval Loss:  0.251675009727478\n",
      "Eval Loss:  0.305083304643631\n",
      "Eval Loss:  0.26188942790031433\n",
      "Eval Loss:  0.1582472175359726\n",
      "Eval Loss:  0.20901060104370117\n",
      "Eval Loss:  0.24306830763816833\n",
      "Eval Loss:  0.1952681839466095\n",
      "Eval Loss:  0.2787429690361023\n",
      "Eval Loss:  0.265910267829895\n",
      "Eval Loss:  0.2767079174518585\n",
      "Eval Loss:  0.3440318703651428\n",
      "Eval Loss:  0.19410771131515503\n",
      "Eval Loss:  0.24498765170574188\n",
      "Eval Loss:  0.21771471202373505\n",
      "Eval Loss:  0.24429821968078613\n",
      "Eval Loss:  0.24574105441570282\n",
      "Eval Loss:  0.30080607533454895\n",
      "Eval Loss:  0.25711920857429504\n",
      "Eval Loss:  0.2612778842449188\n",
      "Eval Loss:  0.238234281539917\n",
      "[[17251   786]\n",
      " [ 2321  9102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18037\n",
      "           1       0.92      0.80      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8945349626612356\n",
      "pre:  0.9205097087378641\n",
      "rec:  0.7968134465551957\n",
      "ma F1:  0.8857967717013895\n",
      "mi F1:  0.8945349626612356\n",
      "we F1:  0.8928889787216892\n",
      "29460 461\n",
      "Loss:  0.046431366354227066\n",
      "Loss:  0.06621690839529037\n",
      "Loss:  0.05474984645843506\n",
      "21 **********\n",
      "Epoch:  1704.6092195510864  fold:  7  kers:  128\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.0663687139749527\n",
      "Loss:  0.04152963310480118\n",
      "Loss:  0.06048326939344406\n",
      "22 **********\n",
      "Epoch:  1768.6210651397705  fold:  7  kers:  128\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.042750075459480286\n",
      "Loss:  0.05461585149168968\n",
      "Loss:  0.057804666459560394\n",
      "23 **********\n",
      "Epoch:  1832.6119663715363  fold:  7  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.5731474757194519\n",
      "Eval Loss:  0.04489881545305252\n",
      "Eval Loss:  2.4762237071990967\n",
      "[[2026  101]\n",
      " [ 764  540]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82      2127\n",
      "           1       0.84      0.41      0.56      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.68      0.69      3431\n",
      "weighted avg       0.77      0.75      0.72      3431\n",
      "\n",
      "acc:  0.747886913436316\n",
      "pre:  0.8424336973478939\n",
      "rec:  0.41411042944785276\n",
      "ma F1:  0.6896748231438798\n",
      "mi F1:  0.747886913436316\n",
      "we F1:  0.7219147627876717\n",
      "Eval Loss:  0.16631165146827698\n",
      "Eval Loss:  0.17505329847335815\n",
      "Eval Loss:  0.23523113131523132\n",
      "Eval Loss:  0.2937508225440979\n",
      "Eval Loss:  0.2504289150238037\n",
      "Eval Loss:  0.2417956292629242\n",
      "Eval Loss:  0.25895604491233826\n",
      "Eval Loss:  0.22716811299324036\n",
      "Eval Loss:  0.2375282496213913\n",
      "Eval Loss:  0.2980700135231018\n",
      "Eval Loss:  0.28429070115089417\n",
      "Eval Loss:  0.13207679986953735\n",
      "Eval Loss:  0.20824404060840607\n",
      "Eval Loss:  0.24862733483314514\n",
      "Eval Loss:  0.19330871105194092\n",
      "Eval Loss:  0.2735755145549774\n",
      "Eval Loss:  0.23157167434692383\n",
      "Eval Loss:  0.23588009178638458\n",
      "Eval Loss:  0.32171276211738586\n",
      "Eval Loss:  0.15212514996528625\n",
      "Eval Loss:  0.21420949697494507\n",
      "Eval Loss:  0.2052113562822342\n",
      "Eval Loss:  0.24202574789524078\n",
      "Eval Loss:  0.22138746082782745\n",
      "Eval Loss:  0.31644192337989807\n",
      "Eval Loss:  0.24424314498901367\n",
      "Eval Loss:  0.23172175884246826\n",
      "Eval Loss:  0.24387526512145996\n",
      "[[17325   712]\n",
      " [ 2121  9302]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18037\n",
      "           1       0.93      0.81      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9038357094365241\n",
      "pre:  0.9288995406430997\n",
      "rec:  0.8143219819662085\n",
      "ma F1:  0.8961321920774071\n",
      "mi F1:  0.9038357094365241\n",
      "we F1:  0.9024828170073834\n",
      "29460 461\n",
      "Loss:  0.05710144713521004\n",
      "Loss:  0.0708838552236557\n",
      "Loss:  0.05511678382754326\n",
      "24 **********\n",
      "Epoch:  1937.2282435894012  fold:  7  kers:  128\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.048729218542575836\n",
      "Loss:  0.05640590563416481\n",
      "Loss:  0.058688003569841385\n",
      "25 **********\n",
      "Epoch:  2001.2640249729156  fold:  7  kers:  128\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.031386200338602066\n",
      "Loss:  0.06858091801404953\n",
      "Loss:  0.07937605679035187\n",
      "26 **********\n",
      "Epoch:  2065.29781293869  fold:  7  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.46188029646873474\n",
      "Eval Loss:  0.05649434030056\n",
      "Eval Loss:  1.4874258041381836\n",
      "[[1893  234]\n",
      " [ 544  760]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      2127\n",
      "           1       0.76      0.58      0.66      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.74      0.75      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7732439522005247\n",
      "pre:  0.7645875251509054\n",
      "rec:  0.5828220858895705\n",
      "ma F1:  0.7454901148657256\n",
      "mi F1:  0.7732439522005248\n",
      "we F1:  0.7656502279518151\n",
      "update!  Acc:  0.7732439522005247\n",
      "Eval Loss:  0.1988253891468048\n",
      "Eval Loss:  0.20100080966949463\n",
      "Eval Loss:  0.20839378237724304\n",
      "Eval Loss:  0.2652835249900818\n",
      "Eval Loss:  0.19580978155136108\n",
      "Eval Loss:  0.19331899285316467\n",
      "Eval Loss:  0.2762196362018585\n",
      "Eval Loss:  0.213314026594162\n",
      "Eval Loss:  0.20986156165599823\n",
      "Eval Loss:  0.268561452627182\n",
      "Eval Loss:  0.3150649070739746\n",
      "Eval Loss:  0.13061469793319702\n",
      "Eval Loss:  0.1931769996881485\n",
      "Eval Loss:  0.2303086817264557\n",
      "Eval Loss:  0.21523116528987885\n",
      "Eval Loss:  0.2957265377044678\n",
      "Eval Loss:  0.18186043202877045\n",
      "Eval Loss:  0.28390607237815857\n",
      "Eval Loss:  0.26201844215393066\n",
      "Eval Loss:  0.14774228632450104\n",
      "Eval Loss:  0.22829684615135193\n",
      "Eval Loss:  0.22521540522575378\n",
      "Eval Loss:  0.2290380299091339\n",
      "Eval Loss:  0.22703474760055542\n",
      "Eval Loss:  0.2857334613800049\n",
      "Eval Loss:  0.24276797473430634\n",
      "Eval Loss:  0.24185293912887573\n",
      "Eval Loss:  0.2310827672481537\n",
      "[[16639  1398]\n",
      " [ 1240 10183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     18037\n",
      "           1       0.88      0.89      0.89     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.91      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9104548540393754\n",
      "pre:  0.8792850358345566\n",
      "rec:  0.8914470804517202\n",
      "ma F1:  0.905937566139226\n",
      "mi F1:  0.9104548540393754\n",
      "we F1:  0.910565407243871\n",
      "29460 461\n",
      "Loss:  0.0555456206202507\n",
      "Loss:  0.04610449820756912\n",
      "Loss:  0.0405096672475338\n",
      "27 **********\n",
      "Epoch:  2174.6424465179443  fold:  7  kers:  128\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.05042887479066849\n",
      "Loss:  0.035798583179712296\n",
      "Loss:  0.10757270455360413\n",
      "28 **********\n",
      "Epoch:  2238.68620634079  fold:  7  kers:  128\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.07002721726894379\n",
      "Loss:  0.061338625848293304\n",
      "Loss:  0.04921755567193031\n",
      "29 **********\n",
      "Epoch:  2305.9224302768707  fold:  7  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.6572686433792114\n",
      "Eval Loss:  0.035282474011182785\n",
      "Eval Loss:  2.3335394859313965\n",
      "[[2009  118]\n",
      " [ 735  569]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.94      0.82      2127\n",
      "           1       0.83      0.44      0.57      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.69      0.70      3431\n",
      "weighted avg       0.77      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7513844360244827\n",
      "pre:  0.8282387190684134\n",
      "rec:  0.4363496932515337\n",
      "ma F1:  0.698227014379324\n",
      "mi F1:  0.7513844360244826\n",
      "we F1:  0.7286079574445778\n",
      "Eval Loss:  0.17666199803352356\n",
      "Eval Loss:  0.17105381190776825\n",
      "Eval Loss:  0.2199958860874176\n",
      "Eval Loss:  0.27237802743911743\n",
      "Eval Loss:  0.2250676453113556\n",
      "Eval Loss:  0.23450905084609985\n",
      "Eval Loss:  0.26332879066467285\n",
      "Eval Loss:  0.21308916807174683\n",
      "Eval Loss:  0.2260560691356659\n",
      "Eval Loss:  0.2709925174713135\n",
      "Eval Loss:  0.26308172941207886\n",
      "Eval Loss:  0.12084868550300598\n",
      "Eval Loss:  0.19517198204994202\n",
      "Eval Loss:  0.24796278774738312\n",
      "Eval Loss:  0.1752343773841858\n",
      "Eval Loss:  0.26672476530075073\n",
      "Eval Loss:  0.19564120471477509\n",
      "Eval Loss:  0.19163450598716736\n",
      "Eval Loss:  0.2980922758579254\n",
      "Eval Loss:  0.14266107976436615\n",
      "Eval Loss:  0.19745367765426636\n",
      "Eval Loss:  0.201298326253891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20978456735610962\n",
      "Eval Loss:  0.22173894941806793\n",
      "Eval Loss:  0.30960631370544434\n",
      "Eval Loss:  0.23697622120380402\n",
      "Eval Loss:  0.2158794105052948\n",
      "Eval Loss:  0.2350885421037674\n",
      "[[17435   602]\n",
      " [ 2088  9335]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     18037\n",
      "           1       0.94      0.82      0.87     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.92      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9086897488119484\n",
      "pre:  0.9394183355137365\n",
      "rec:  0.8172108903090256\n",
      "ma F1:  0.901222463534001\n",
      "mi F1:  0.9086897488119484\n",
      "we F1:  0.90731982462392\n",
      "29460 461\n",
      "Loss:  0.05314098671078682\n",
      "Loss:  0.060987770557403564\n",
      "Loss:  0.05728716775774956\n",
      "30 **********\n",
      "Epoch:  2410.541699409485  fold:  7  kers:  128\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.07632141560316086\n",
      "Loss:  0.03800278902053833\n",
      "Loss:  0.03391553461551666\n",
      "31 **********\n",
      "Epoch:  2474.5296092033386  fold:  7  kers:  128\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.05146166309714317\n",
      "Loss:  0.04102799668908119\n",
      "Loss:  0.03760838881134987\n",
      "32 **********\n",
      "Epoch:  2538.518515586853  fold:  7  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.6018134951591492\n",
      "Eval Loss:  0.050098441541194916\n",
      "Eval Loss:  1.9944560527801514\n",
      "[[1991  136]\n",
      " [ 654  650]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83      2127\n",
      "           1       0.83      0.50      0.62      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.72      0.73      3431\n",
      "weighted avg       0.78      0.77      0.75      3431\n",
      "\n",
      "acc:  0.769746429612358\n",
      "pre:  0.8269720101781171\n",
      "rec:  0.49846625766871167\n",
      "ma F1:  0.7282302666672014\n",
      "mi F1:  0.769746429612358\n",
      "we F1:  0.7537096120093818\n",
      "Eval Loss:  0.16360598802566528\n",
      "Eval Loss:  0.17008408904075623\n",
      "Eval Loss:  0.2144024819135666\n",
      "Eval Loss:  0.28573909401893616\n",
      "Eval Loss:  0.23503023386001587\n",
      "Eval Loss:  0.21567897498607635\n",
      "Eval Loss:  0.24715813994407654\n",
      "Eval Loss:  0.20301057398319244\n",
      "Eval Loss:  0.202668234705925\n",
      "Eval Loss:  0.2563336491584778\n",
      "Eval Loss:  0.26057830452919006\n",
      "Eval Loss:  0.11102009564638138\n",
      "Eval Loss:  0.17634128034114838\n",
      "Eval Loss:  0.2254948765039444\n",
      "Eval Loss:  0.16021685302257538\n",
      "Eval Loss:  0.2525310218334198\n",
      "Eval Loss:  0.2012288123369217\n",
      "Eval Loss:  0.21685916185379028\n",
      "Eval Loss:  0.28809690475463867\n",
      "Eval Loss:  0.12848564982414246\n",
      "Eval Loss:  0.19979748129844666\n",
      "Eval Loss:  0.20561224222183228\n",
      "Eval Loss:  0.18033556640148163\n",
      "Eval Loss:  0.24055323004722595\n",
      "Eval Loss:  0.3019561171531677\n",
      "Eval Loss:  0.23860302567481995\n",
      "Eval Loss:  0.22019198536872864\n",
      "Eval Loss:  0.22247833013534546\n",
      "[[17375   662]\n",
      " [ 1911  9512]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18037\n",
      "           1       0.93      0.83      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.92      0.90      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9126612355736592\n",
      "pre:  0.934932180066837\n",
      "rec:  0.832705944147772\n",
      "ma F1:  0.9059621793622206\n",
      "mi F1:  0.9126612355736592\n",
      "we F1:  0.9115971224860226\n",
      "29460 461\n",
      "Loss:  0.08208304643630981\n",
      "Loss:  0.06245719641447067\n",
      "Loss:  0.0543057806789875\n",
      "33 **********\n",
      "Epoch:  2643.223555803299  fold:  7  kers:  128\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.06869232654571533\n",
      "Loss:  0.030752919614315033\n",
      "Loss:  0.03594747185707092\n",
      "34 **********\n",
      "Epoch:  2707.2034862041473  fold:  7  kers:  128\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.045878369361162186\n",
      "Loss:  0.03607076406478882\n",
      "Loss:  0.06526395678520203\n",
      "35 **********\n",
      "Epoch:  2771.2153317928314  fold:  7  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.4945070445537567\n",
      "Eval Loss:  0.12183482944965363\n",
      "Eval Loss:  1.685593605041504\n",
      "[[1945  182]\n",
      " [ 564  740]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84      2127\n",
      "           1       0.80      0.57      0.66      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.79      0.74      0.75      3431\n",
      "weighted avg       0.79      0.78      0.77      3431\n",
      "\n",
      "acc:  0.7825706791023025\n",
      "pre:  0.8026030368763557\n",
      "rec:  0.5674846625766872\n",
      "ma F1:  0.7519775699688442\n",
      "mi F1:  0.7825706791023025\n",
      "we F1:  0.7728722826799116\n",
      "update!  Acc:  0.7825706791023025\n",
      "Eval Loss:  0.1738976389169693\n",
      "Eval Loss:  0.1636648327112198\n",
      "Eval Loss:  0.1810673624277115\n",
      "Eval Loss:  0.20264287292957306\n",
      "Eval Loss:  0.18670262396335602\n",
      "Eval Loss:  0.1803250014781952\n",
      "Eval Loss:  0.23865525424480438\n",
      "Eval Loss:  0.17358458042144775\n",
      "Eval Loss:  0.19281095266342163\n",
      "Eval Loss:  0.24723221361637115\n",
      "Eval Loss:  0.24412000179290771\n",
      "Eval Loss:  0.11747607588768005\n",
      "Eval Loss:  0.17538709938526154\n",
      "Eval Loss:  0.20964421331882477\n",
      "Eval Loss:  0.16646742820739746\n",
      "Eval Loss:  0.22657479345798492\n",
      "Eval Loss:  0.18970562517642975\n",
      "Eval Loss:  0.22087863087654114\n",
      "Eval Loss:  0.22618556022644043\n",
      "Eval Loss:  0.14163415133953094\n",
      "Eval Loss:  0.18790197372436523\n",
      "Eval Loss:  0.18844826519489288\n",
      "Eval Loss:  0.17737321555614471\n",
      "Eval Loss:  0.19511252641677856\n",
      "Eval Loss:  0.25604739785194397\n",
      "Eval Loss:  0.24650049209594727\n",
      "Eval Loss:  0.21164155006408691\n",
      "Eval Loss:  0.20594649016857147\n",
      "[[17007  1030]\n",
      " [ 1274 10149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18037\n",
      "           1       0.91      0.89      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9217922606924643\n",
      "pre:  0.9078629573307093\n",
      "rec:  0.8884706294318481\n",
      "ma F1:  0.9173112508388099\n",
      "mi F1:  0.9217922606924643\n",
      "we F1:  0.9216328313538391\n",
      "29460 461\n",
      "Loss:  0.038165561854839325\n",
      "Loss:  0.06874401867389679\n",
      "Loss:  0.07206249982118607\n",
      "36 **********\n",
      "Epoch:  2875.7707719802856  fold:  7  kers:  128\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.07396291196346283\n",
      "Loss:  0.03572557866573334\n",
      "Loss:  0.04541371762752533\n",
      "37 **********\n",
      "Epoch:  2939.7666597366333  fold:  7  kers:  128\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.06492218375205994\n",
      "Loss:  0.04697507247328758\n",
      "Loss:  0.045520562678575516\n",
      "38 **********\n",
      "Epoch:  3003.771523475647  fold:  7  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.5285478830337524\n",
      "Eval Loss:  0.050205908715724945\n",
      "Eval Loss:  1.9901666641235352\n",
      "[[1978  149]\n",
      " [ 636  668]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.83      2127\n",
      "           1       0.82      0.51      0.63      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.72      0.73      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7712037306907608\n",
      "pre:  0.817625458996328\n",
      "rec:  0.5122699386503068\n",
      "ma F1:  0.7321573390351962\n",
      "mi F1:  0.7712037306907608\n",
      "we F1:  0.7566880110447608\n",
      "Eval Loss:  0.18059216439723969\n",
      "Eval Loss:  0.16850122809410095\n",
      "Eval Loss:  0.2106320858001709\n",
      "Eval Loss:  0.23843608796596527\n",
      "Eval Loss:  0.17951779067516327\n",
      "Eval Loss:  0.1971266120672226\n",
      "Eval Loss:  0.27990099787712097\n",
      "Eval Loss:  0.18352311849594116\n",
      "Eval Loss:  0.1781289279460907\n",
      "Eval Loss:  0.25613266229629517\n",
      "Eval Loss:  0.2825077176094055\n",
      "Eval Loss:  0.08904816210269928\n",
      "Eval Loss:  0.15505820512771606\n",
      "Eval Loss:  0.20564523339271545\n",
      "Eval Loss:  0.15261250734329224\n",
      "Eval Loss:  0.23351207375526428\n",
      "Eval Loss:  0.17233847081661224\n",
      "Eval Loss:  0.23444700241088867\n",
      "Eval Loss:  0.26324841380119324\n",
      "Eval Loss:  0.12408953905105591\n",
      "Eval Loss:  0.20056182146072388\n",
      "Eval Loss:  0.18031789362430573\n",
      "Eval Loss:  0.17613817751407623\n",
      "Eval Loss:  0.19724330306053162\n",
      "Eval Loss:  0.29560235142707825\n",
      "Eval Loss:  0.23783071339130402\n",
      "Eval Loss:  0.23323482275009155\n",
      "Eval Loss:  0.23442864418029785\n",
      "[[17201   836]\n",
      " [ 1563  9860]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18037\n",
      "           1       0.92      0.86      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9185675492192804\n",
      "pre:  0.9218399401645475\n",
      "rec:  0.8631707957629344\n",
      "ma F1:  0.913176381474635\n",
      "mi F1:  0.9185675492192804\n",
      "we F1:  0.9180336466242173\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04763055592775345\n",
      "Loss:  0.05922438204288483\n",
      "Loss:  0.08354128152132034\n",
      "39 **********\n",
      "Epoch:  3108.2551555633545  fold:  7  kers:  128\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.04229765385389328\n",
      "Loss:  0.03836986422538757\n",
      "Loss:  0.04113287106156349\n",
      "40 **********\n",
      "Epoch:  3172.2101531028748  fold:  7  kers:  128\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.039230044931173325\n",
      "Loss:  0.04573323577642441\n",
      "Loss:  0.05738668888807297\n",
      "41 **********\n",
      "Epoch:  3236.2269854545593  fold:  7  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.4883013367652893\n",
      "Eval Loss:  0.06991250813007355\n",
      "Eval Loss:  1.6879584789276123\n",
      "[[1925  202]\n",
      " [ 557  747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84      2127\n",
      "           1       0.79      0.57      0.66      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.74      0.75      3431\n",
      "weighted avg       0.78      0.78      0.77      3431\n",
      "\n",
      "acc:  0.7787816962984553\n",
      "pre:  0.7871443624868283\n",
      "rec:  0.5728527607361963\n",
      "ma F1:  0.7492190206216691\n",
      "mi F1:  0.7787816962984554\n",
      "we F1:  0.769872740555451\n",
      "Eval Loss:  0.16552449762821198\n",
      "Eval Loss:  0.15493527054786682\n",
      "Eval Loss:  0.17827169597148895\n",
      "Eval Loss:  0.23551031947135925\n",
      "Eval Loss:  0.18392647802829742\n",
      "Eval Loss:  0.18462389707565308\n",
      "Eval Loss:  0.23977184295654297\n",
      "Eval Loss:  0.16829447448253632\n",
      "Eval Loss:  0.1795240044593811\n",
      "Eval Loss:  0.22381094098091125\n",
      "Eval Loss:  0.24853917956352234\n",
      "Eval Loss:  0.10395237058401108\n",
      "Eval Loss:  0.14267389476299286\n",
      "Eval Loss:  0.19187921285629272\n",
      "Eval Loss:  0.12340667843818665\n",
      "Eval Loss:  0.21876133978366852\n",
      "Eval Loss:  0.17555895447731018\n",
      "Eval Loss:  0.17626723647117615\n",
      "Eval Loss:  0.22166600823402405\n",
      "Eval Loss:  0.1304982304573059\n",
      "Eval Loss:  0.16151459515094757\n",
      "Eval Loss:  0.19891159236431122\n",
      "Eval Loss:  0.1553870141506195\n",
      "Eval Loss:  0.2027636468410492\n",
      "Eval Loss:  0.2554014325141907\n",
      "Eval Loss:  0.2547726035118103\n",
      "Eval Loss:  0.20037028193473816\n",
      "Eval Loss:  0.22932453453540802\n",
      "[[17216   821]\n",
      " [ 1386 10037]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18037\n",
      "           1       0.92      0.88      0.90     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.92     29460\n",
      "\n",
      "acc:  0.9250848608282417\n",
      "pre:  0.924387548351446\n",
      "rec:  0.8786658496016808\n",
      "ma F1:  0.920355317517517\n",
      "mi F1:  0.9250848608282417\n",
      "we F1:  0.9247126374028958\n",
      "29460 461\n",
      "Loss:  0.06254974752664566\n",
      "Loss:  0.03709690272808075\n",
      "Loss:  0.033586859703063965\n",
      "42 **********\n",
      "Epoch:  3340.6467876434326  fold:  7  kers:  128\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.05180806294083595\n",
      "Loss:  0.03545204550027847\n",
      "Loss:  0.07784820348024368\n",
      "43 **********\n",
      "Epoch:  3404.626718521118  fold:  7  kers:  128\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.04192241281270981\n",
      "Loss:  0.029934046790003777\n",
      "Loss:  0.044659022241830826\n",
      "44 **********\n",
      "Epoch:  3468.6285903453827  fold:  7  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.5219746828079224\n",
      "Eval Loss:  0.20995602011680603\n",
      "Eval Loss:  1.4540013074874878\n",
      "[[1857  270]\n",
      " [ 502  802]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83      2127\n",
      "           1       0.75      0.62      0.68      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.74      0.75      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.774992713494608\n",
      "pre:  0.7481343283582089\n",
      "rec:  0.6150306748466258\n",
      "ma F1:  0.7514966127315659\n",
      "mi F1:  0.774992713494608\n",
      "we F1:  0.7698257984452944\n",
      "Eval Loss:  0.18123535811901093\n",
      "Eval Loss:  0.156918004155159\n",
      "Eval Loss:  0.18988028168678284\n",
      "Eval Loss:  0.2082323431968689\n",
      "Eval Loss:  0.1735825091600418\n",
      "Eval Loss:  0.17095187306404114\n",
      "Eval Loss:  0.21953687071800232\n",
      "Eval Loss:  0.1716468185186386\n",
      "Eval Loss:  0.1752527356147766\n",
      "Eval Loss:  0.2033604085445404\n",
      "Eval Loss:  0.23396682739257812\n",
      "Eval Loss:  0.09044697135686874\n",
      "Eval Loss:  0.1503181904554367\n",
      "Eval Loss:  0.19212223589420319\n",
      "Eval Loss:  0.1528390794992447\n",
      "Eval Loss:  0.2043384313583374\n",
      "Eval Loss:  0.20096927881240845\n",
      "Eval Loss:  0.212605819106102\n",
      "Eval Loss:  0.20641940832138062\n",
      "Eval Loss:  0.1284213662147522\n",
      "Eval Loss:  0.18689531087875366\n",
      "Eval Loss:  0.1911691576242447\n",
      "Eval Loss:  0.13995753228664398\n",
      "Eval Loss:  0.19176460802555084\n",
      "Eval Loss:  0.2802126407623291\n",
      "Eval Loss:  0.2595864534378052\n",
      "Eval Loss:  0.21061857044696808\n",
      "Eval Loss:  0.20011673867702484\n",
      "[[17019  1018]\n",
      " [ 1251 10172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18037\n",
      "           1       0.91      0.89      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9229803122878479\n",
      "pre:  0.9090259159964253\n",
      "rec:  0.8904841110041145\n",
      "ma F1:  0.9185823260992871\n",
      "mi F1:  0.9229803122878479\n",
      "we F1:  0.922830651008173\n",
      "29460 461\n",
      "Loss:  0.05839063599705696\n",
      "Loss:  0.049367506057024\n",
      "Loss:  0.058535996824502945\n",
      "45 **********\n",
      "Epoch:  3572.961625099182  fold:  7  kers:  128\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.07893075048923492\n",
      "Loss:  0.06633083522319794\n",
      "Loss:  0.04793602228164673\n",
      "46 **********\n",
      "Epoch:  3636.93656873703  fold:  7  kers:  128\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.03926141560077667\n",
      "Loss:  0.08135686814785004\n",
      "Loss:  0.04425432160496712\n",
      "47 **********\n",
      "Epoch:  3700.9284677505493  fold:  7  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.45583686232566833\n",
      "Eval Loss:  0.05728583037853241\n",
      "Eval Loss:  1.2566618919372559\n",
      "[[1888  239]\n",
      " [ 542  762]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      2127\n",
      "           1       0.76      0.58      0.66      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.74      0.74      3431\n",
      "weighted avg       0.77      0.77      0.76      3431\n",
      "\n",
      "acc:  0.772369571553483\n",
      "pre:  0.7612387612387612\n",
      "rec:  0.5843558282208589\n",
      "ma F1:  0.7448933418444699\n",
      "mi F1:  0.772369571553483\n",
      "we F1:  0.7649758791895124\n",
      "Eval Loss:  0.17360542714595795\n",
      "Eval Loss:  0.15481142699718475\n",
      "Eval Loss:  0.1839141696691513\n",
      "Eval Loss:  0.23474064469337463\n",
      "Eval Loss:  0.1765362024307251\n",
      "Eval Loss:  0.17258286476135254\n",
      "Eval Loss:  0.23279237747192383\n",
      "Eval Loss:  0.15983164310455322\n",
      "Eval Loss:  0.16975995898246765\n",
      "Eval Loss:  0.21088288724422455\n",
      "Eval Loss:  0.24536922574043274\n",
      "Eval Loss:  0.09246063232421875\n",
      "Eval Loss:  0.1375691294670105\n",
      "Eval Loss:  0.18439623713493347\n",
      "Eval Loss:  0.1596735119819641\n",
      "Eval Loss:  0.23426488041877747\n",
      "Eval Loss:  0.14753501117229462\n",
      "Eval Loss:  0.18340523540973663\n",
      "Eval Loss:  0.22210873663425446\n",
      "Eval Loss:  0.13073724508285522\n",
      "Eval Loss:  0.17479205131530762\n",
      "Eval Loss:  0.18491071462631226\n",
      "Eval Loss:  0.160453662276268\n",
      "Eval Loss:  0.17878520488739014\n",
      "Eval Loss:  0.26819494366645813\n",
      "Eval Loss:  0.23747587203979492\n",
      "Eval Loss:  0.2199508100748062\n",
      "Eval Loss:  0.2084667831659317\n",
      "[[17084   953]\n",
      " [ 1190 10233]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18037\n",
      "           1       0.91      0.90      0.91     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9272572980312288\n",
      "pre:  0.9148042195601644\n",
      "rec:  0.8958242143044735\n",
      "ma F1:  0.9230984045212425\n",
      "mi F1:  0.9272572980312288\n",
      "we F1:  0.9271134273901739\n",
      "29460 461\n",
      "Loss:  0.037087034434080124\n",
      "Loss:  0.07770227640867233\n",
      "Loss:  0.040097810328006744\n",
      "48 **********\n",
      "Epoch:  3805.3791873455048  fold:  7  kers:  128\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.05660024657845497\n",
      "Loss:  0.06134235858917236\n",
      "Loss:  0.06029415875673294\n",
      "49 **********\n",
      "Epoch:  3869.394024848938  fold:  7  kers:  128\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.04108065366744995\n",
      "Loss:  0.07094763964414597\n",
      "Loss:  0.04988589137792587\n",
      "50 **********\n",
      "Epoch:  3933.4038758277893  fold:  7  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.4385907053947449\n",
      "Eval Loss:  0.24506312608718872\n",
      "Eval Loss:  1.534439206123352\n",
      "[[1790  337]\n",
      " [ 480  824]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      2127\n",
      "           1       0.71      0.63      0.67      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.75      0.74      0.74      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7618770037889828\n",
      "pre:  0.7097329888027563\n",
      "rec:  0.6319018404907976\n",
      "ma F1:  0.741375665964393\n",
      "mi F1:  0.7618770037889828\n",
      "we F1:  0.7588421266575994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18644990026950836\n",
      "Eval Loss:  0.13376955687999725\n",
      "Eval Loss:  0.16618867218494415\n",
      "Eval Loss:  0.19652420282363892\n",
      "Eval Loss:  0.17594371736049652\n",
      "Eval Loss:  0.17112423479557037\n",
      "Eval Loss:  0.2049275040626526\n",
      "Eval Loss:  0.15376946330070496\n",
      "Eval Loss:  0.19136007130146027\n",
      "Eval Loss:  0.21389231085777283\n",
      "Eval Loss:  0.23096783459186554\n",
      "Eval Loss:  0.07130606472492218\n",
      "Eval Loss:  0.1276371330022812\n",
      "Eval Loss:  0.17611254751682281\n",
      "Eval Loss:  0.12856197357177734\n",
      "Eval Loss:  0.21092258393764496\n",
      "Eval Loss:  0.16478502750396729\n",
      "Eval Loss:  0.1955891102552414\n",
      "Eval Loss:  0.19293303787708282\n",
      "Eval Loss:  0.12338344007730484\n",
      "Eval Loss:  0.17577731609344482\n",
      "Eval Loss:  0.16709715127944946\n",
      "Eval Loss:  0.1365225911140442\n",
      "Eval Loss:  0.18770819902420044\n",
      "Eval Loss:  0.265922486782074\n",
      "Eval Loss:  0.22960226237773895\n",
      "Eval Loss:  0.20564717054367065\n",
      "Eval Loss:  0.21971331536769867\n",
      "[[17066   971]\n",
      " [ 1092 10331]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18037\n",
      "           1       0.91      0.90      0.91     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9299728445349627\n",
      "pre:  0.9140860024774377\n",
      "rec:  0.9044033966558698\n",
      "ma F1:  0.926111049563307\n",
      "mi F1:  0.9299728445349627\n",
      "we F1:  0.9299034641056279\n",
      "29460 461\n",
      "Loss:  0.04899420216679573\n",
      "Loss:  0.03989427164196968\n",
      "Loss:  0.048425812274217606\n",
      "51 **********\n",
      "Epoch:  4037.8805265426636  fold:  7  kers:  128\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.03875217214226723\n",
      "Loss:  0.054642949253320694\n",
      "Loss:  0.056944169104099274\n",
      "52 **********\n",
      "Epoch:  4101.873422384262  fold:  7  kers:  128\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.036343980580568314\n",
      "Loss:  0.04608152434229851\n",
      "Loss:  0.05419555678963661\n",
      "53 **********\n",
      "Epoch:  4165.923166036606  fold:  7  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.6073800921440125\n",
      "Eval Loss:  0.13965724408626556\n",
      "Eval Loss:  1.7197940349578857\n",
      "[[1940  187]\n",
      " [ 587  717]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83      2127\n",
      "           1       0.79      0.55      0.65      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.73      0.74      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7744097930632469\n",
      "pre:  0.793141592920354\n",
      "rec:  0.5498466257668712\n",
      "ma F1:  0.7415739849778591\n",
      "mi F1:  0.7744097930632469\n",
      "we F1:  0.7636703627818445\n",
      "Eval Loss:  0.16832304000854492\n",
      "Eval Loss:  0.15660884976387024\n",
      "Eval Loss:  0.1847749799489975\n",
      "Eval Loss:  0.21469746530056\n",
      "Eval Loss:  0.18044379353523254\n",
      "Eval Loss:  0.15039806067943573\n",
      "Eval Loss:  0.19787457585334778\n",
      "Eval Loss:  0.1402694284915924\n",
      "Eval Loss:  0.1590214967727661\n",
      "Eval Loss:  0.20547853410243988\n",
      "Eval Loss:  0.21489831805229187\n",
      "Eval Loss:  0.06604476273059845\n",
      "Eval Loss:  0.12995608150959015\n",
      "Eval Loss:  0.16553395986557007\n",
      "Eval Loss:  0.12876133620738983\n",
      "Eval Loss:  0.18634659051895142\n",
      "Eval Loss:  0.1493816375732422\n",
      "Eval Loss:  0.17512458562850952\n",
      "Eval Loss:  0.22611741721630096\n",
      "Eval Loss:  0.11344275623559952\n",
      "Eval Loss:  0.17326447367668152\n",
      "Eval Loss:  0.17336586117744446\n",
      "Eval Loss:  0.17446261644363403\n",
      "Eval Loss:  0.18615292012691498\n",
      "Eval Loss:  0.2642372250556946\n",
      "Eval Loss:  0.19514413177967072\n",
      "Eval Loss:  0.196599081158638\n",
      "Eval Loss:  0.1796548068523407\n",
      "[[17309   728]\n",
      " [ 1404 10019]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18037\n",
      "           1       0.93      0.88      0.90     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9276306856754922\n",
      "pre:  0.932260165627617\n",
      "rec:  0.8770900814146897\n",
      "ma F1:  0.9229102022405715\n",
      "mi F1:  0.9276306856754922\n",
      "we F1:  0.9271929563473706\n",
      "29460 461\n",
      "Loss:  0.05429515987634659\n",
      "Loss:  0.06983974575996399\n",
      "Loss:  0.0761069506406784\n",
      "54 **********\n",
      "Epoch:  4270.381864786148  fold:  7  kers:  128\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.060785043984651566\n",
      "Loss:  0.03602136671543121\n",
      "Loss:  0.03422290459275246\n",
      "55 **********\n",
      "Epoch:  4334.371771097183  fold:  7  kers:  128\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.0414804182946682\n",
      "Loss:  0.03531913459300995\n",
      "Loss:  0.021179718896746635\n",
      "56 **********\n",
      "Epoch:  4398.398574352264  fold:  7  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.5375779867172241\n",
      "Eval Loss:  0.20176243782043457\n",
      "Eval Loss:  1.2454036474227905\n",
      "[[1879  248]\n",
      " [ 507  797]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83      2127\n",
      "           1       0.76      0.61      0.68      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.75      0.76      3431\n",
      "weighted avg       0.78      0.78      0.77      3431\n",
      "\n",
      "acc:  0.7799475371611775\n",
      "pre:  0.7626794258373206\n",
      "rec:  0.6111963190184049\n",
      "ma F1:  0.7556460750019078\n",
      "mi F1:  0.7799475371611775\n",
      "we F1:  0.7741304588809087\n",
      "Eval Loss:  0.16074877977371216\n",
      "Eval Loss:  0.1435246616601944\n",
      "Eval Loss:  0.18452918529510498\n",
      "Eval Loss:  0.20571793615818024\n",
      "Eval Loss:  0.15659889578819275\n",
      "Eval Loss:  0.1488799899816513\n",
      "Eval Loss:  0.21863016486167908\n",
      "Eval Loss:  0.1591588705778122\n",
      "Eval Loss:  0.16562436521053314\n",
      "Eval Loss:  0.21014375984668732\n",
      "Eval Loss:  0.2000400871038437\n",
      "Eval Loss:  0.08755216747522354\n",
      "Eval Loss:  0.16304247081279755\n",
      "Eval Loss:  0.1717354953289032\n",
      "Eval Loss:  0.13105957210063934\n",
      "Eval Loss:  0.1845870018005371\n",
      "Eval Loss:  0.16420145332813263\n",
      "Eval Loss:  0.15257489681243896\n",
      "Eval Loss:  0.2165953516960144\n",
      "Eval Loss:  0.11916380375623703\n",
      "Eval Loss:  0.15398792922496796\n",
      "Eval Loss:  0.18096841871738434\n",
      "Eval Loss:  0.11992976069450378\n",
      "Eval Loss:  0.20088109374046326\n",
      "Eval Loss:  0.24379272758960724\n",
      "Eval Loss:  0.22278526425361633\n",
      "Eval Loss:  0.18237647414207458\n",
      "Eval Loss:  0.202254056930542\n",
      "[[17251   786]\n",
      " [ 1272 10151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     18037\n",
      "           1       0.93      0.89      0.91     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.930142566191446\n",
      "pre:  0.9281338575477737\n",
      "rec:  0.8886457147859581\n",
      "ma F1:  0.925834807780383\n",
      "mi F1:  0.930142566191446\n",
      "we F1:  0.9298476970945759\n",
      "29460 461\n",
      "Loss:  0.04524550586938858\n",
      "Loss:  0.0489996112883091\n",
      "Loss:  0.03368193283677101\n",
      "57 **********\n",
      "Epoch:  4502.848297119141  fold:  7  kers:  128\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.03480861335992813\n",
      "Loss:  0.040621623396873474\n",
      "Loss:  0.031641311943531036\n",
      "58 **********\n",
      "Epoch:  4566.826232671738  fold:  7  kers:  128\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.05434277281165123\n",
      "Loss:  0.043209508061409\n",
      "Loss:  0.03417830541729927\n",
      "59 **********\n",
      "Epoch:  4630.863011837006  fold:  7  kers:  128\n",
      "Eval Loss:  0.5537149906158447\n",
      "Eval Loss:  0.1670350730419159\n",
      "Eval Loss:  1.525763988494873\n",
      "[[1862  265]\n",
      " [ 555  749]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      2127\n",
      "           1       0.74      0.57      0.65      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.75      0.72      0.73      3431\n",
      "weighted avg       0.76      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7610026231419411\n",
      "pre:  0.7386587771203156\n",
      "rec:  0.5743865030674846\n",
      "ma F1:  0.7328945089866203\n",
      "mi F1:  0.7610026231419411\n",
      "we F1:  0.7536788557519652\n",
      "update!  Acc:  0.7825706791023025\n",
      "Epoch:  4635.117635250092  fold:  7  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29817 3074\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29817 466\n",
      "Loss:  0.17357991635799408\n",
      "Loss:  0.1690523624420166\n",
      "Loss:  0.16156317293643951\n",
      "0 **********\n",
      "Epoch:  76.99612712860107  fold:  8  kers:  128\n",
      "epoch:  1\n",
      "29817 466\n",
      "Loss:  0.13335853815078735\n",
      "Loss:  0.13532036542892456\n",
      "Loss:  0.11473546177148819\n",
      "1 **********\n",
      "Epoch:  141.70311427116394  fold:  8  kers:  128\n",
      "epoch:  2\n",
      "29817 466\n",
      "Loss:  0.11940255761146545\n",
      "Loss:  0.13735900819301605\n",
      "Loss:  0.08844121545553207\n",
      "2 **********\n",
      "Epoch:  206.43802618980408  fold:  8  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.2749529480934143\n",
      "Eval Loss:  1.2585328817367554\n",
      "Eval Loss:  0.21518754959106445\n",
      "[[1942  131]\n",
      " [ 468  533]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87      2073\n",
      "           1       0.80      0.53      0.64      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.80      0.73      0.75      3074\n",
      "weighted avg       0.80      0.81      0.79      3074\n",
      "\n",
      "acc:  0.8051398828887443\n",
      "pre:  0.802710843373494\n",
      "rec:  0.5324675324675324\n",
      "ma F1:  0.7533121790092568\n",
      "mi F1:  0.8051398828887443\n",
      "we F1:  0.7927439026138065\n",
      "update!  Acc:  0.8051398828887443\n",
      "Eval Loss:  0.44936081767082214\n",
      "Eval Loss:  0.42894652485847473\n",
      "Eval Loss:  0.3746984302997589\n",
      "Eval Loss:  0.4811282157897949\n",
      "Eval Loss:  0.3845890164375305\n",
      "Eval Loss:  0.3019797205924988\n",
      "Eval Loss:  0.6155388951301575\n",
      "Eval Loss:  0.41731494665145874\n",
      "Eval Loss:  0.41584014892578125\n",
      "Eval Loss:  0.2929591238498688\n",
      "Eval Loss:  0.4219661355018616\n",
      "Eval Loss:  0.3386399447917938\n",
      "Eval Loss:  0.37842297554016113\n",
      "Eval Loss:  0.33258023858070374\n",
      "Eval Loss:  0.3820871412754059\n",
      "Eval Loss:  0.4138895571231842\n",
      "Eval Loss:  0.40373945236206055\n",
      "Eval Loss:  0.43468719720840454\n",
      "Eval Loss:  0.4652153551578522\n",
      "Eval Loss:  0.4114448130130768\n",
      "Eval Loss:  0.45292186737060547\n",
      "Eval Loss:  0.44702833890914917\n",
      "Eval Loss:  0.39166226983070374\n",
      "Eval Loss:  0.39067795872688293\n",
      "Eval Loss:  0.39770928025245667\n",
      "Eval Loss:  0.49936479330062866\n",
      "Eval Loss:  0.28260865807533264\n",
      "Eval Loss:  0.377815842628479\n",
      "Eval Loss:  0.5048898458480835\n",
      "[[16335  1756]\n",
      " [ 3376  8350]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86     18091\n",
      "           1       0.83      0.71      0.76     11726\n",
      "\n",
      "    accuracy                           0.83     29817\n",
      "   macro avg       0.83      0.81      0.81     29817\n",
      "weighted avg       0.83      0.83      0.83     29817\n",
      "\n",
      "acc:  0.8278834222088071\n",
      "pre:  0.8262418365327528\n",
      "rec:  0.7120927852635169\n",
      "ma F1:  0.8145860984514227\n",
      "mi F1:  0.8278834222088071\n",
      "we F1:  0.8251856558359877\n",
      "29817 466\n",
      "Loss:  0.09806197881698608\n",
      "Loss:  0.09760919958353043\n",
      "Loss:  0.10773995518684387\n",
      "3 **********\n",
      "Epoch:  311.908020734787  fold:  8  kers:  128\n",
      "epoch:  4\n",
      "29817 466\n",
      "Loss:  0.0915822684764862\n",
      "Loss:  0.10061211884021759\n",
      "Loss:  0.10927508771419525\n",
      "4 **********\n",
      "Epoch:  376.6269760131836  fold:  8  kers:  128\n",
      "epoch:  5\n",
      "29817 466\n",
      "Loss:  0.09789632260799408\n",
      "Loss:  0.08622992783784866\n",
      "Loss:  0.08801855146884918\n",
      "5 **********\n",
      "Epoch:  441.3439357280731  fold:  8  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.17097117006778717\n",
      "Eval Loss:  1.7953137159347534\n",
      "Eval Loss:  0.10202109813690186\n",
      "[[2044   29]\n",
      " [ 655  346]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86      2073\n",
      "           1       0.92      0.35      0.50      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.84      0.67      0.68      3074\n",
      "weighted avg       0.81      0.78      0.74      3074\n",
      "\n",
      "acc:  0.7774886141834743\n",
      "pre:  0.9226666666666666\n",
      "rec:  0.34565434565434566\n",
      "ma F1:  0.6797854246671475\n",
      "mi F1:  0.7774886141834743\n",
      "we F1:  0.7414684748211535\n",
      "Eval Loss:  0.5000425577163696\n",
      "Eval Loss:  0.41712290048599243\n",
      "Eval Loss:  0.4097673296928406\n",
      "Eval Loss:  0.5232685804367065\n",
      "Eval Loss:  0.36936572194099426\n",
      "Eval Loss:  0.3168596029281616\n",
      "Eval Loss:  0.6881464719772339\n",
      "Eval Loss:  0.428566038608551\n",
      "Eval Loss:  0.4917943477630615\n",
      "Eval Loss:  0.3100599944591522\n",
      "Eval Loss:  0.47545942664146423\n",
      "Eval Loss:  0.32237425446510315\n",
      "Eval Loss:  0.4442296326160431\n",
      "Eval Loss:  0.3616993725299835\n",
      "Eval Loss:  0.43505436182022095\n",
      "Eval Loss:  0.44715943932533264\n",
      "Eval Loss:  0.4088298976421356\n",
      "Eval Loss:  0.49478819966316223\n",
      "Eval Loss:  0.5608721375465393\n",
      "Eval Loss:  0.42994987964630127\n",
      "Eval Loss:  0.5239737033843994\n",
      "Eval Loss:  0.4389132559299469\n",
      "Eval Loss:  0.4259593188762665\n",
      "Eval Loss:  0.4424315094947815\n",
      "Eval Loss:  0.45830121636390686\n",
      "Eval Loss:  0.5300395488739014\n",
      "Eval Loss:  0.3086455464363098\n",
      "Eval Loss:  0.4184892773628235\n",
      "Eval Loss:  0.5699926614761353\n",
      "[[17548   543]\n",
      " [ 4664  7062]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     18091\n",
      "           1       0.93      0.60      0.73     11726\n",
      "\n",
      "    accuracy                           0.83     29817\n",
      "   macro avg       0.86      0.79      0.80     29817\n",
      "weighted avg       0.84      0.83      0.82     29817\n",
      "\n",
      "acc:  0.8253680786128719\n",
      "pre:  0.9285996055226824\n",
      "rec:  0.6022514071294559\n",
      "ma F1:  0.8007217835372455\n",
      "mi F1:  0.8253680786128719\n",
      "we F1:  0.8156820799473505\n",
      "29817 466\n",
      "Loss:  0.0587148517370224\n",
      "Loss:  0.08788567781448364\n",
      "Loss:  0.10010553896427155\n",
      "6 **********\n",
      "Epoch:  546.8219084739685  fold:  8  kers:  128\n",
      "epoch:  7\n",
      "29817 466\n",
      "Loss:  0.09006615728139877\n",
      "Loss:  0.0453476756811142\n",
      "Loss:  0.06436201184988022\n",
      "7 **********\n",
      "Epoch:  611.5408635139465  fold:  8  kers:  128\n",
      "epoch:  8\n",
      "29817 466\n",
      "Loss:  0.10497435927391052\n",
      "Loss:  0.06117815896868706\n",
      "Loss:  0.11663369834423065\n",
      "8 **********\n",
      "Epoch:  676.3046979904175  fold:  8  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.1936432421207428\n",
      "Eval Loss:  1.8407169580459595\n",
      "Eval Loss:  0.08904668688774109\n",
      "[[2011   62]\n",
      " [ 539  462]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87      2073\n",
      "           1       0.88      0.46      0.61      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.84      0.72      0.74      3074\n",
      "weighted avg       0.82      0.80      0.78      3074\n",
      "\n",
      "acc:  0.8044892648015615\n",
      "pre:  0.8816793893129771\n",
      "rec:  0.46153846153846156\n",
      "ma F1:  0.7379497381233532\n",
      "mi F1:  0.8044892648015615\n",
      "we F1:  0.7839990425772198\n",
      "Eval Loss:  0.40727320313453674\n",
      "Eval Loss:  0.3372029662132263\n",
      "Eval Loss:  0.3377661406993866\n",
      "Eval Loss:  0.4531340003013611\n",
      "Eval Loss:  0.29610711336135864\n",
      "Eval Loss:  0.2754722535610199\n",
      "Eval Loss:  0.5929489135742188\n",
      "Eval Loss:  0.366326242685318\n",
      "Eval Loss:  0.40668314695358276\n",
      "Eval Loss:  0.2551079988479614\n",
      "Eval Loss:  0.40066462755203247\n",
      "Eval Loss:  0.22016359865665436\n",
      "Eval Loss:  0.35947462916374207\n",
      "Eval Loss:  0.33172014355659485\n",
      "Eval Loss:  0.3788008689880371\n",
      "Eval Loss:  0.3881128132343292\n",
      "Eval Loss:  0.37757107615470886\n",
      "Eval Loss:  0.4332772195339203\n",
      "Eval Loss:  0.47400176525115967\n",
      "Eval Loss:  0.34573885798454285\n",
      "Eval Loss:  0.37644052505493164\n",
      "Eval Loss:  0.32451993227005005\n",
      "Eval Loss:  0.3704332709312439\n",
      "Eval Loss:  0.41189056634902954\n",
      "Eval Loss:  0.38957318663597107\n",
      "Eval Loss:  0.4669795036315918\n",
      "Eval Loss:  0.2616596519947052\n",
      "Eval Loss:  0.34119275212287903\n",
      "Eval Loss:  0.44820836186408997\n",
      "[[17622   469]\n",
      " [ 3958  7768]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     18091\n",
      "           1       0.94      0.66      0.78     11726\n",
      "\n",
      "    accuracy                           0.85     29817\n",
      "   macro avg       0.88      0.82      0.83     29817\n",
      "weighted avg       0.87      0.85      0.85     29817\n",
      "\n",
      "acc:  0.851527652010598\n",
      "pre:  0.9430617943426005\n",
      "rec:  0.6624594917277844\n",
      "ma F1:  0.8333234461621964\n",
      "mi F1:  0.851527652010598\n",
      "we F1:  0.8450820995237832\n",
      "29817 466\n",
      "Loss:  0.059917982667684555\n",
      "Loss:  0.06912565976381302\n",
      "Loss:  0.08942252397537231\n",
      "9 **********\n",
      "Epoch:  781.5363302230835  fold:  8  kers:  128\n",
      "epoch:  10\n",
      "29817 466\n",
      "Loss:  0.09687378257513046\n",
      "Loss:  0.05189470574259758\n",
      "Loss:  0.08477012068033218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 **********\n",
      "Epoch:  846.2562825679779  fold:  8  kers:  128\n",
      "epoch:  11\n",
      "29817 466\n",
      "Loss:  0.06566675752401352\n",
      "Loss:  0.06462997943162918\n",
      "Loss:  0.061472877860069275\n",
      "11 **********\n",
      "Epoch:  910.9503030776978  fold:  8  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.45851564407348633\n",
      "Eval Loss:  1.183899998664856\n",
      "Eval Loss:  0.09725630283355713\n",
      "[[1808  265]\n",
      " [ 327  674]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      2073\n",
      "           1       0.72      0.67      0.69      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.78      0.77      0.78      3074\n",
      "weighted avg       0.80      0.81      0.81      3074\n",
      "\n",
      "acc:  0.8074170461938842\n",
      "pre:  0.7177848775292864\n",
      "rec:  0.6733266733266733\n",
      "ma F1:  0.7770804750891772\n",
      "mi F1:  0.8074170461938842\n",
      "we F1:  0.8057584329588826\n",
      "update!  Acc:  0.8074170461938842\n",
      "Eval Loss:  0.2811231017112732\n",
      "Eval Loss:  0.2891029119491577\n",
      "Eval Loss:  0.19124296307563782\n",
      "Eval Loss:  0.2837361991405487\n",
      "Eval Loss:  0.2050277441740036\n",
      "Eval Loss:  0.19672425091266632\n",
      "Eval Loss:  0.4233270585536957\n",
      "Eval Loss:  0.2889539301395416\n",
      "Eval Loss:  0.29480478167533875\n",
      "Eval Loss:  0.16847418248653412\n",
      "Eval Loss:  0.2243296205997467\n",
      "Eval Loss:  0.1406087577342987\n",
      "Eval Loss:  0.25712504982948303\n",
      "Eval Loss:  0.24311545491218567\n",
      "Eval Loss:  0.2673461139202118\n",
      "Eval Loss:  0.30203819274902344\n",
      "Eval Loss:  0.26373356580734253\n",
      "Eval Loss:  0.2938551902770996\n",
      "Eval Loss:  0.2839323580265045\n",
      "Eval Loss:  0.2271067202091217\n",
      "Eval Loss:  0.25545400381088257\n",
      "Eval Loss:  0.1870954930782318\n",
      "Eval Loss:  0.28479844331741333\n",
      "Eval Loss:  0.3129156231880188\n",
      "Eval Loss:  0.31354936957359314\n",
      "Eval Loss:  0.3915270268917084\n",
      "Eval Loss:  0.20631912350654602\n",
      "Eval Loss:  0.23579423129558563\n",
      "Eval Loss:  0.29001548886299133\n",
      "[[17083  1008]\n",
      " [ 2182  9544]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     18091\n",
      "           1       0.90      0.81      0.86     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.88      0.89     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8930140523862227\n",
      "pre:  0.9044730856709629\n",
      "rec:  0.8139177895275457\n",
      "ma F1:  0.8857074132619704\n",
      "mi F1:  0.8930140523862227\n",
      "we F1:  0.8918762364515003\n",
      "29817 466\n",
      "Loss:  0.06142612546682358\n",
      "Loss:  0.08978918194770813\n",
      "Loss:  0.09125068783760071\n",
      "12 **********\n",
      "Epoch:  1016.3066022396088  fold:  8  kers:  128\n",
      "epoch:  13\n",
      "29817 466\n",
      "Loss:  0.07644650340080261\n",
      "Loss:  0.05020195618271828\n",
      "Loss:  0.05843965336680412\n",
      "13 **********\n",
      "Epoch:  1081.0145859718323  fold:  8  kers:  128\n",
      "epoch:  14\n",
      "29817 466\n",
      "Loss:  0.08207722008228302\n",
      "Loss:  0.04828570783138275\n",
      "Loss:  0.0812692940235138\n",
      "14 **********\n",
      "Epoch:  1149.6490714550018  fold:  8  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.3989248275756836\n",
      "Eval Loss:  1.0449836254119873\n",
      "Eval Loss:  0.09382039308547974\n",
      "[[1930  143]\n",
      " [ 285  716]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      2073\n",
      "           1       0.83      0.72      0.77      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.85      0.82      0.84      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8607677293428757\n",
      "pre:  0.8335273573923166\n",
      "rec:  0.7152847152847153\n",
      "ma F1:  0.8350395201412293\n",
      "mi F1:  0.8607677293428756\n",
      "we F1:  0.8577583341973783\n",
      "update!  Acc:  0.8607677293428757\n",
      "Eval Loss:  0.28463634848594666\n",
      "Eval Loss:  0.24446740746498108\n",
      "Eval Loss:  0.1650458425283432\n",
      "Eval Loss:  0.2679542005062103\n",
      "Eval Loss:  0.18050390481948853\n",
      "Eval Loss:  0.19141589105129242\n",
      "Eval Loss:  0.38492152094841003\n",
      "Eval Loss:  0.28708696365356445\n",
      "Eval Loss:  0.2789037823677063\n",
      "Eval Loss:  0.14154204726219177\n",
      "Eval Loss:  0.20538663864135742\n",
      "Eval Loss:  0.14146724343299866\n",
      "Eval Loss:  0.23059549927711487\n",
      "Eval Loss:  0.22962342202663422\n",
      "Eval Loss:  0.2526584565639496\n",
      "Eval Loss:  0.29591938853263855\n",
      "Eval Loss:  0.24881978332996368\n",
      "Eval Loss:  0.25521227717399597\n",
      "Eval Loss:  0.25350871682167053\n",
      "Eval Loss:  0.233138769865036\n",
      "Eval Loss:  0.2323475033044815\n",
      "Eval Loss:  0.19461677968502045\n",
      "Eval Loss:  0.24945653975009918\n",
      "Eval Loss:  0.3092350959777832\n",
      "Eval Loss:  0.33299940824508667\n",
      "Eval Loss:  0.3610639274120331\n",
      "Eval Loss:  0.19936373829841614\n",
      "Eval Loss:  0.2291947454214096\n",
      "Eval Loss:  0.2560409903526306\n",
      "[[16951  1140]\n",
      " [ 1863  9863]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18091\n",
      "           1       0.90      0.84      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8992856424187544\n",
      "pre:  0.8963918931200582\n",
      "rec:  0.8411222923418046\n",
      "ma F1:  0.8932534766701993\n",
      "mi F1:  0.8992856424187544\n",
      "we F1:  0.8986703410874614\n",
      "29817 466\n",
      "Loss:  0.07650483399629593\n",
      "Loss:  0.04903748631477356\n",
      "Loss:  0.06209580972790718\n",
      "15 **********\n",
      "Epoch:  1255.0981223583221  fold:  8  kers:  128\n",
      "epoch:  16\n",
      "29817 466\n",
      "Loss:  0.05162929370999336\n",
      "Loss:  0.08121850341558456\n",
      "Loss:  0.0603780634701252\n",
      "16 **********\n",
      "Epoch:  1319.8011190891266  fold:  8  kers:  128\n",
      "epoch:  17\n",
      "29817 466\n",
      "Loss:  0.04909339174628258\n",
      "Loss:  0.0504048652946949\n",
      "Loss:  0.05800851806998253\n",
      "17 **********\n",
      "Epoch:  1384.5051143169403  fold:  8  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.4741075932979584\n",
      "Eval Loss:  1.0780932903289795\n",
      "Eval Loss:  0.09998547285795212\n",
      "[[1931  142]\n",
      " [ 276  725]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      2073\n",
      "           1       0.84      0.72      0.78      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.86      0.83      0.84      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8640208197787899\n",
      "pre:  0.8362168396770473\n",
      "rec:  0.7242757242757243\n",
      "ma F1:  0.8392838559907143\n",
      "mi F1:  0.8640208197787899\n",
      "we F1:  0.8612722682467815\n",
      "update!  Acc:  0.8640208197787899\n",
      "Eval Loss:  0.25703683495521545\n",
      "Eval Loss:  0.25094783306121826\n",
      "Eval Loss:  0.16975310444831848\n",
      "Eval Loss:  0.2735816240310669\n",
      "Eval Loss:  0.21055370569229126\n",
      "Eval Loss:  0.1916283369064331\n",
      "Eval Loss:  0.36650630831718445\n",
      "Eval Loss:  0.24535687267780304\n",
      "Eval Loss:  0.27956706285476685\n",
      "Eval Loss:  0.15075281262397766\n",
      "Eval Loss:  0.18811185657978058\n",
      "Eval Loss:  0.15507769584655762\n",
      "Eval Loss:  0.21053270995616913\n",
      "Eval Loss:  0.22411677241325378\n",
      "Eval Loss:  0.2213437557220459\n",
      "Eval Loss:  0.2674524784088135\n",
      "Eval Loss:  0.25630444288253784\n",
      "Eval Loss:  0.23639942705631256\n",
      "Eval Loss:  0.22547884285449982\n",
      "Eval Loss:  0.23587439954280853\n",
      "Eval Loss:  0.24835647642612457\n",
      "Eval Loss:  0.1939210146665573\n",
      "Eval Loss:  0.27073296904563904\n",
      "Eval Loss:  0.2985280752182007\n",
      "Eval Loss:  0.3301915228366852\n",
      "Eval Loss:  0.33743277192115784\n",
      "Eval Loss:  0.19498255848884583\n",
      "Eval Loss:  0.23432765901088715\n",
      "Eval Loss:  0.24564483761787415\n",
      "[[17077  1014]\n",
      " [ 1859  9867]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18091\n",
      "           1       0.91      0.84      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.90     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.9036455713183754\n",
      "pre:  0.9068100358422939\n",
      "rec:  0.8414634146341463\n",
      "ma F1:  0.8976617206103567\n",
      "mi F1:  0.9036455713183754\n",
      "we F1:  0.9029442739746477\n",
      "29817 466\n",
      "Loss:  0.07176187634468079\n",
      "Loss:  0.13225433230400085\n",
      "Loss:  0.04939764365553856\n",
      "18 **********\n",
      "Epoch:  1490.1735780239105  fold:  8  kers:  128\n",
      "epoch:  19\n",
      "29817 466\n",
      "Loss:  0.06665308028459549\n",
      "Loss:  0.05298483371734619\n",
      "Loss:  0.0494876354932785\n",
      "19 **********\n",
      "Epoch:  1554.855631351471  fold:  8  kers:  128\n",
      "epoch:  20\n",
      "29817 466\n",
      "Loss:  0.034341052174568176\n",
      "Loss:  0.08144653588533401\n",
      "Loss:  0.045203424990177155\n",
      "20 **********\n",
      "Epoch:  1619.5456631183624  fold:  8  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.436231404542923\n",
      "Eval Loss:  1.240587830543518\n",
      "Eval Loss:  0.10309770703315735\n",
      "[[1919  154]\n",
      " [ 318  683]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      2073\n",
      "           1       0.82      0.68      0.74      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.80      0.82      3074\n",
      "weighted avg       0.84      0.85      0.84      3074\n",
      "\n",
      "acc:  0.8464541314248536\n",
      "pre:  0.8160095579450418\n",
      "rec:  0.6823176823176823\n",
      "ma F1:  0.8168431842338464\n",
      "mi F1:  0.8464541314248536\n",
      "we F1:  0.8425251707943318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2486199587583542\n",
      "Eval Loss:  0.2615422010421753\n",
      "Eval Loss:  0.19165101647377014\n",
      "Eval Loss:  0.28423169255256653\n",
      "Eval Loss:  0.2242506593465805\n",
      "Eval Loss:  0.2099391669034958\n",
      "Eval Loss:  0.4013957381248474\n",
      "Eval Loss:  0.2533869445323944\n",
      "Eval Loss:  0.2612273395061493\n",
      "Eval Loss:  0.1384049504995346\n",
      "Eval Loss:  0.18654519319534302\n",
      "Eval Loss:  0.15472859144210815\n",
      "Eval Loss:  0.20518901944160461\n",
      "Eval Loss:  0.2080354541540146\n",
      "Eval Loss:  0.2773701548576355\n",
      "Eval Loss:  0.2714720070362091\n",
      "Eval Loss:  0.2734019160270691\n",
      "Eval Loss:  0.27521052956581116\n",
      "Eval Loss:  0.2449013888835907\n",
      "Eval Loss:  0.22504185140132904\n",
      "Eval Loss:  0.2287084311246872\n",
      "Eval Loss:  0.1958364099264145\n",
      "Eval Loss:  0.2613665759563446\n",
      "Eval Loss:  0.2835976779460907\n",
      "Eval Loss:  0.2925770878791809\n",
      "Eval Loss:  0.3182257115840912\n",
      "Eval Loss:  0.18574027717113495\n",
      "Eval Loss:  0.24257467687129974\n",
      "Eval Loss:  0.23333166539669037\n",
      "[[17240   851]\n",
      " [ 1979  9747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18091\n",
      "           1       0.92      0.83      0.87     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.89      0.90     29817\n",
      "weighted avg       0.91      0.91      0.90     29817\n",
      "\n",
      "acc:  0.9050877016467116\n",
      "pre:  0.9197018305340631\n",
      "rec:  0.8312297458638922\n",
      "ma F1:  0.8986898127722178\n",
      "mi F1:  0.9050877016467116\n",
      "we F1:  0.9041245602279969\n",
      "29817 466\n",
      "Loss:  0.05084994435310364\n",
      "Loss:  0.04489409178495407\n",
      "Loss:  0.06017966568470001\n",
      "21 **********\n",
      "Epoch:  1724.8870024681091  fold:  8  kers:  128\n",
      "epoch:  22\n",
      "29817 466\n",
      "Loss:  0.05138944089412689\n",
      "Loss:  0.08054169267416\n",
      "Loss:  0.07347539812326431\n",
      "22 **********\n",
      "Epoch:  1789.583019733429  fold:  8  kers:  128\n",
      "epoch:  23\n",
      "29817 466\n",
      "Loss:  0.07155723869800568\n",
      "Loss:  0.07630479335784912\n",
      "Loss:  0.0465816892683506\n",
      "23 **********\n",
      "Epoch:  1854.2939944267273  fold:  8  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.6192035675048828\n",
      "Eval Loss:  0.9924089312553406\n",
      "Eval Loss:  0.11382966488599777\n",
      "[[1820  253]\n",
      " [ 237  764]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      2073\n",
      "           1       0.75      0.76      0.76      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.82      0.82      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8405985686402082\n",
      "pre:  0.7512291052114061\n",
      "rec:  0.7632367632367633\n",
      "ma F1:  0.8192706321076414\n",
      "mi F1:  0.8405985686402082\n",
      "we F1:  0.840921719193732\n",
      "Eval Loss:  0.2612685561180115\n",
      "Eval Loss:  0.2256515473127365\n",
      "Eval Loss:  0.14361746609210968\n",
      "Eval Loss:  0.23086506128311157\n",
      "Eval Loss:  0.14387966692447662\n",
      "Eval Loss:  0.18047337234020233\n",
      "Eval Loss:  0.3218543827533722\n",
      "Eval Loss:  0.2148997187614441\n",
      "Eval Loss:  0.2566602826118469\n",
      "Eval Loss:  0.11813163012266159\n",
      "Eval Loss:  0.1437358558177948\n",
      "Eval Loss:  0.15112632513046265\n",
      "Eval Loss:  0.1895672082901001\n",
      "Eval Loss:  0.19964535534381866\n",
      "Eval Loss:  0.23261931538581848\n",
      "Eval Loss:  0.24324622750282288\n",
      "Eval Loss:  0.25549066066741943\n",
      "Eval Loss:  0.22610962390899658\n",
      "Eval Loss:  0.20071250200271606\n",
      "Eval Loss:  0.21009337902069092\n",
      "Eval Loss:  0.21319139003753662\n",
      "Eval Loss:  0.1814824342727661\n",
      "Eval Loss:  0.22431504726409912\n",
      "Eval Loss:  0.27597108483314514\n",
      "Eval Loss:  0.306446373462677\n",
      "Eval Loss:  0.3169768154621124\n",
      "Eval Loss:  0.16827380657196045\n",
      "Eval Loss:  0.19990119338035583\n",
      "Eval Loss:  0.21820442378520966\n",
      "[[16926  1165]\n",
      " [ 1313 10413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18091\n",
      "           1       0.90      0.89      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9168930475903009\n",
      "pre:  0.8993781309379858\n",
      "rec:  0.8880266075388027\n",
      "ma F1:  0.9127291154462058\n",
      "mi F1:  0.9168930475903009\n",
      "we F1:  0.9167984272989872\n",
      "29817 466\n",
      "Loss:  0.07705859839916229\n",
      "Loss:  0.05875377729535103\n",
      "Loss:  0.052717071026563644\n",
      "24 **********\n",
      "Epoch:  1959.5794825553894  fold:  8  kers:  128\n",
      "epoch:  25\n",
      "29817 466\n",
      "Loss:  0.04919520020484924\n",
      "Loss:  0.050200920552015305\n",
      "Loss:  0.07299421727657318\n",
      "25 **********\n",
      "Epoch:  2024.244580745697  fold:  8  kers:  128\n",
      "epoch:  26\n",
      "29817 466\n",
      "Loss:  0.07563846558332443\n",
      "Loss:  0.05740070343017578\n",
      "Loss:  0.052087102085351944\n",
      "26 **********\n",
      "Epoch:  2088.9366071224213  fold:  8  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.5605792999267578\n",
      "Eval Loss:  1.15585196018219\n",
      "Eval Loss:  0.09528487175703049\n",
      "[[1900  173]\n",
      " [ 266  735]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      2073\n",
      "           1       0.81      0.73      0.77      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.84      0.83      0.83      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8571893298633702\n",
      "pre:  0.8094713656387665\n",
      "rec:  0.7342657342657343\n",
      "ma F1:  0.8332372537628899\n",
      "mi F1:  0.8571893298633702\n",
      "we F1:  0.8552772757197267\n",
      "Eval Loss:  0.24396543204784393\n",
      "Eval Loss:  0.20483385026454926\n",
      "Eval Loss:  0.1465640813112259\n",
      "Eval Loss:  0.24496282637119293\n",
      "Eval Loss:  0.17153985798358917\n",
      "Eval Loss:  0.1835256665945053\n",
      "Eval Loss:  0.34581485390663147\n",
      "Eval Loss:  0.22161677479743958\n",
      "Eval Loss:  0.2520581781864166\n",
      "Eval Loss:  0.12172792106866837\n",
      "Eval Loss:  0.15004681050777435\n",
      "Eval Loss:  0.1411043107509613\n",
      "Eval Loss:  0.20167428255081177\n",
      "Eval Loss:  0.23845797777175903\n",
      "Eval Loss:  0.23457536101341248\n",
      "Eval Loss:  0.26302510499954224\n",
      "Eval Loss:  0.23827144503593445\n",
      "Eval Loss:  0.21106232702732086\n",
      "Eval Loss:  0.20441849529743195\n",
      "Eval Loss:  0.2372661978006363\n",
      "Eval Loss:  0.20613306760787964\n",
      "Eval Loss:  0.18187831342220306\n",
      "Eval Loss:  0.24353280663490295\n",
      "Eval Loss:  0.27857065200805664\n",
      "Eval Loss:  0.31936216354370117\n",
      "Eval Loss:  0.2987353801727295\n",
      "Eval Loss:  0.16177630424499512\n",
      "Eval Loss:  0.21650409698486328\n",
      "Eval Loss:  0.19704027473926544\n",
      "[[17196   895]\n",
      " [ 1679 10047]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18091\n",
      "           1       0.92      0.86      0.89     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.90      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9136734077875037\n",
      "pre:  0.9182050813379639\n",
      "rec:  0.8568139177895275\n",
      "ma F1:  0.9084081513446018\n",
      "mi F1:  0.9136734077875037\n",
      "we F1:  0.9130959898197831\n",
      "29817 466\n",
      "Loss:  0.07472807914018631\n",
      "Loss:  0.052381064742803574\n",
      "Loss:  0.05611344426870346\n",
      "27 **********\n",
      "Epoch:  2194.1572687625885  fold:  8  kers:  128\n",
      "epoch:  28\n",
      "29817 466\n",
      "Loss:  0.08090206235647202\n",
      "Loss:  0.05200381577014923\n",
      "Loss:  0.056608520448207855\n",
      "28 **********\n",
      "Epoch:  2258.8403198719025  fold:  8  kers:  128\n",
      "epoch:  29\n",
      "29817 466\n",
      "Loss:  0.025133894756436348\n",
      "Loss:  0.07757437974214554\n",
      "Loss:  0.028986535966396332\n",
      "29 **********\n",
      "Epoch:  2323.5094077587128  fold:  8  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.3012404441833496\n",
      "Eval Loss:  1.140835165977478\n",
      "Eval Loss:  0.1223287284374237\n",
      "[[1873  200]\n",
      " [ 258  743]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      2073\n",
      "           1       0.79      0.74      0.76      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.83      0.82      0.83      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8510084580351334\n",
      "pre:  0.7879109225874867\n",
      "rec:  0.7422577422577422\n",
      "ma F1:  0.8277297145967195\n",
      "mi F1:  0.8510084580351335\n",
      "we F1:  0.8498136198763475\n",
      "Eval Loss:  0.24377182126045227\n",
      "Eval Loss:  0.18678033351898193\n",
      "Eval Loss:  0.18171139061450958\n",
      "Eval Loss:  0.21991536021232605\n",
      "Eval Loss:  0.15905506908893585\n",
      "Eval Loss:  0.16608943045139313\n",
      "Eval Loss:  0.3136900067329407\n",
      "Eval Loss:  0.20938804745674133\n",
      "Eval Loss:  0.24143627285957336\n",
      "Eval Loss:  0.13178230822086334\n",
      "Eval Loss:  0.14103859663009644\n",
      "Eval Loss:  0.12564586102962494\n",
      "Eval Loss:  0.1802125871181488\n",
      "Eval Loss:  0.22573792934417725\n",
      "Eval Loss:  0.23868508636951447\n",
      "Eval Loss:  0.2325277030467987\n",
      "Eval Loss:  0.24154075980186462\n",
      "Eval Loss:  0.20699992775917053\n",
      "Eval Loss:  0.1904098391532898\n",
      "Eval Loss:  0.20933090150356293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19466298818588257\n",
      "Eval Loss:  0.18666602671146393\n",
      "Eval Loss:  0.25891655683517456\n",
      "Eval Loss:  0.2556535303592682\n",
      "Eval Loss:  0.286664754152298\n",
      "Eval Loss:  0.304058313369751\n",
      "Eval Loss:  0.1832418292760849\n",
      "Eval Loss:  0.18796373903751373\n",
      "Eval Loss:  0.19982050359249115\n",
      "[[16925  1166]\n",
      " [ 1294 10432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18091\n",
      "           1       0.90      0.89      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9174967300533253\n",
      "pre:  0.8994654250732885\n",
      "rec:  0.8896469384274263\n",
      "ma F1:  0.9133896545595459\n",
      "mi F1:  0.9174967300533253\n",
      "we F1:  0.9174157650659229\n",
      "29817 466\n",
      "Loss:  0.06447361409664154\n",
      "Loss:  0.04802536964416504\n",
      "Loss:  0.052225593477487564\n",
      "30 **********\n",
      "Epoch:  2429.056197166443  fold:  8  kers:  128\n",
      "epoch:  31\n",
      "29817 466\n",
      "Loss:  0.037091467529535294\n",
      "Loss:  0.05653831362724304\n",
      "Loss:  0.05597267299890518\n",
      "31 **********\n",
      "Epoch:  2493.7432367801666  fold:  8  kers:  128\n",
      "epoch:  32\n",
      "29817 466\n",
      "Loss:  0.08139479160308838\n",
      "Loss:  0.07634264975786209\n",
      "Loss:  0.04266706109046936\n",
      "32 **********\n",
      "Epoch:  2558.435263633728  fold:  8  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  1.0445419549942017\n",
      "Eval Loss:  1.0962165594100952\n",
      "Eval Loss:  0.19223788380622864\n",
      "[[1587  486]\n",
      " [ 214  787]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82      2073\n",
      "           1       0.62      0.79      0.69      1001\n",
      "\n",
      "    accuracy                           0.77      3074\n",
      "   macro avg       0.75      0.78      0.76      3074\n",
      "weighted avg       0.80      0.77      0.78      3074\n",
      "\n",
      "acc:  0.7722836694860117\n",
      "pre:  0.6182246661429693\n",
      "rec:  0.7862137862137862\n",
      "ma F1:  0.7557402960176065\n",
      "mi F1:  0.7722836694860117\n",
      "we F1:  0.7779084164652695\n",
      "Eval Loss:  0.22295457124710083\n",
      "Eval Loss:  0.1793389767408371\n",
      "Eval Loss:  0.14555218815803528\n",
      "Eval Loss:  0.2370666116476059\n",
      "Eval Loss:  0.14667895436286926\n",
      "Eval Loss:  0.18042488396167755\n",
      "Eval Loss:  0.31610703468322754\n",
      "Eval Loss:  0.23466341197490692\n",
      "Eval Loss:  0.23371176421642303\n",
      "Eval Loss:  0.1490163505077362\n",
      "Eval Loss:  0.12900973856449127\n",
      "Eval Loss:  0.14211365580558777\n",
      "Eval Loss:  0.1697332262992859\n",
      "Eval Loss:  0.2160397469997406\n",
      "Eval Loss:  0.20515838265419006\n",
      "Eval Loss:  0.22854913771152496\n",
      "Eval Loss:  0.23702377080917358\n",
      "Eval Loss:  0.19167491793632507\n",
      "Eval Loss:  0.16390253603458405\n",
      "Eval Loss:  0.2142201066017151\n",
      "Eval Loss:  0.20724709331989288\n",
      "Eval Loss:  0.1886603683233261\n",
      "Eval Loss:  0.21417725086212158\n",
      "Eval Loss:  0.2479800432920456\n",
      "Eval Loss:  0.25907713174819946\n",
      "Eval Loss:  0.30707478523254395\n",
      "Eval Loss:  0.1534213274717331\n",
      "Eval Loss:  0.18876802921295166\n",
      "Eval Loss:  0.20246824622154236\n",
      "[[16963  1128]\n",
      " [ 1205 10521]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18091\n",
      "           1       0.90      0.90      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.92      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9217560452091089\n",
      "pre:  0.9031676538758692\n",
      "rec:  0.8972369094320314\n",
      "ma F1:  0.9179249337026115\n",
      "mi F1:  0.9217560452091089\n",
      "we F1:  0.9217102526623842\n",
      "29817 466\n",
      "Loss:  0.0521015040576458\n",
      "Loss:  0.04607801511883736\n",
      "Loss:  0.04968386888504028\n",
      "33 **********\n",
      "Epoch:  2663.6469490528107  fold:  8  kers:  128\n",
      "epoch:  34\n",
      "29817 466\n",
      "Loss:  0.0697767585515976\n",
      "Loss:  0.05941309779882431\n",
      "Loss:  0.053428102284669876\n",
      "34 **********\n",
      "Epoch:  2728.3319942951202  fold:  8  kers:  128\n",
      "epoch:  35\n",
      "29817 466\n",
      "Loss:  0.06857024878263474\n",
      "Loss:  0.06260378658771515\n",
      "Loss:  0.02678879164159298\n",
      "35 **********\n",
      "Epoch:  2793.0339941978455  fold:  8  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.5308094024658203\n",
      "Eval Loss:  1.1823817491531372\n",
      "Eval Loss:  0.1680760532617569\n",
      "[[1819  254]\n",
      " [ 240  761]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      2073\n",
      "           1       0.75      0.76      0.75      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.82      0.82      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8392973324658426\n",
      "pre:  0.7497536945812808\n",
      "rec:  0.7602397602397603\n",
      "ma F1:  0.817702811198697\n",
      "mi F1:  0.8392973324658426\n",
      "we F1:  0.8395830822746705\n",
      "Eval Loss:  0.2443578690290451\n",
      "Eval Loss:  0.1665540635585785\n",
      "Eval Loss:  0.1595759242773056\n",
      "Eval Loss:  0.21478572487831116\n",
      "Eval Loss:  0.1568303406238556\n",
      "Eval Loss:  0.18198974430561066\n",
      "Eval Loss:  0.28790587186813354\n",
      "Eval Loss:  0.21142975986003876\n",
      "Eval Loss:  0.23827819526195526\n",
      "Eval Loss:  0.11517670750617981\n",
      "Eval Loss:  0.14641587436199188\n",
      "Eval Loss:  0.12796613574028015\n",
      "Eval Loss:  0.17154689133167267\n",
      "Eval Loss:  0.2310112863779068\n",
      "Eval Loss:  0.22264845669269562\n",
      "Eval Loss:  0.26150792837142944\n",
      "Eval Loss:  0.22484761476516724\n",
      "Eval Loss:  0.18333835899829865\n",
      "Eval Loss:  0.19300970435142517\n",
      "Eval Loss:  0.2201729118824005\n",
      "Eval Loss:  0.20293055474758148\n",
      "Eval Loss:  0.1885099858045578\n",
      "Eval Loss:  0.23191161453723907\n",
      "Eval Loss:  0.26409703493118286\n",
      "Eval Loss:  0.2667733430862427\n",
      "Eval Loss:  0.2803853750228882\n",
      "Eval Loss:  0.15079814195632935\n",
      "Eval Loss:  0.17644476890563965\n",
      "Eval Loss:  0.1935836374759674\n",
      "[[16944  1147]\n",
      " [ 1215 10511]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18091\n",
      "           1       0.90      0.90      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.92      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9207834456853473\n",
      "pre:  0.9016126265225596\n",
      "rec:  0.8963841037011768\n",
      "ma F1:  0.9169160711125791\n",
      "mi F1:  0.9207834456853473\n",
      "we F1:  0.920742565618357\n",
      "29817 466\n",
      "Loss:  0.0318279042840004\n",
      "Loss:  0.04030754789710045\n",
      "Loss:  0.08967593312263489\n",
      "36 **********\n",
      "Epoch:  2898.323471546173  fold:  8  kers:  128\n",
      "epoch:  37\n",
      "29817 466\n",
      "Loss:  0.0373542457818985\n",
      "Loss:  0.04524175450205803\n",
      "Loss:  0.05515056475996971\n",
      "37 **********\n",
      "Epoch:  2963.0294609069824  fold:  8  kers:  128\n",
      "epoch:  38\n",
      "29817 466\n",
      "Loss:  0.07508322596549988\n",
      "Loss:  0.07121585309505463\n",
      "Loss:  0.042218826711177826\n",
      "38 **********\n",
      "Epoch:  3027.745423555374  fold:  8  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.5602872967720032\n",
      "Eval Loss:  1.0061094760894775\n",
      "Eval Loss:  0.1677386313676834\n",
      "[[1792  281]\n",
      " [ 221  780]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      2073\n",
      "           1       0.74      0.78      0.76      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.81      0.82      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8366948601171112\n",
      "pre:  0.7351555136663525\n",
      "rec:  0.7792207792207793\n",
      "ma F1:  0.8168442501731683\n",
      "mi F1:  0.8366948601171112\n",
      "we F1:  0.8378717737501514\n",
      "Eval Loss:  0.21402956545352936\n",
      "Eval Loss:  0.1764981597661972\n",
      "Eval Loss:  0.13890884816646576\n",
      "Eval Loss:  0.19117262959480286\n",
      "Eval Loss:  0.16164325177669525\n",
      "Eval Loss:  0.15461130440235138\n",
      "Eval Loss:  0.28325870633125305\n",
      "Eval Loss:  0.18445761501789093\n",
      "Eval Loss:  0.22013433277606964\n",
      "Eval Loss:  0.10939786583185196\n",
      "Eval Loss:  0.12627114355564117\n",
      "Eval Loss:  0.13234259188175201\n",
      "Eval Loss:  0.16610774397850037\n",
      "Eval Loss:  0.23599329590797424\n",
      "Eval Loss:  0.21378609538078308\n",
      "Eval Loss:  0.23008033633232117\n",
      "Eval Loss:  0.22634905576705933\n",
      "Eval Loss:  0.17932961881160736\n",
      "Eval Loss:  0.15335485339164734\n",
      "Eval Loss:  0.188444122672081\n",
      "Eval Loss:  0.1930137574672699\n",
      "Eval Loss:  0.17874515056610107\n",
      "Eval Loss:  0.23292554914951324\n",
      "Eval Loss:  0.23582448065280914\n",
      "Eval Loss:  0.2962278723716736\n",
      "Eval Loss:  0.27445679903030396\n",
      "Eval Loss:  0.15083494782447815\n",
      "Eval Loss:  0.17940270900726318\n",
      "Eval Loss:  0.19042463600635529\n",
      "[[16959  1132]\n",
      " [ 1078 10648]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18091\n",
      "           1       0.90      0.91      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.92      0.92      0.92     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9258812087064426\n",
      "pre:  0.9039049235993208\n",
      "rec:  0.9080675422138836\n",
      "ma F1:  0.9224050304665631\n",
      "mi F1:  0.9258812087064426\n",
      "we F1:  0.925910952586169\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05463530868291855\n",
      "Loss:  0.05374586954712868\n",
      "Loss:  0.04796651378273964\n",
      "39 **********\n",
      "Epoch:  3133.10670876503  fold:  8  kers:  128\n",
      "epoch:  40\n",
      "29817 466\n",
      "Loss:  0.06912802159786224\n",
      "Loss:  0.05130791664123535\n",
      "Loss:  0.049344029277563095\n",
      "40 **********\n",
      "Epoch:  3197.7987356185913  fold:  8  kers:  128\n",
      "epoch:  41\n",
      "29817 466\n",
      "Loss:  0.03472018241882324\n",
      "Loss:  0.03551380708813667\n",
      "Loss:  0.06883534044027328\n",
      "41 **********\n",
      "Epoch:  3262.5127034187317  fold:  8  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.33863717317581177\n",
      "Eval Loss:  1.0416158437728882\n",
      "Eval Loss:  0.16772982478141785\n",
      "[[1850  223]\n",
      " [ 237  764]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      2073\n",
      "           1       0.77      0.76      0.77      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.83      0.83      0.83      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8503578399479506\n",
      "pre:  0.7740628166160081\n",
      "rec:  0.7632367632367633\n",
      "ma F1:  0.8290173734715989\n",
      "mi F1:  0.8503578399479506\n",
      "we F1:  0.850082732645309\n",
      "Eval Loss:  0.20795463025569916\n",
      "Eval Loss:  0.16232916712760925\n",
      "Eval Loss:  0.13386690616607666\n",
      "Eval Loss:  0.20030522346496582\n",
      "Eval Loss:  0.18767447769641876\n",
      "Eval Loss:  0.16281399130821228\n",
      "Eval Loss:  0.2924115061759949\n",
      "Eval Loss:  0.18392176926136017\n",
      "Eval Loss:  0.22744223475456238\n",
      "Eval Loss:  0.10508699715137482\n",
      "Eval Loss:  0.117824986577034\n",
      "Eval Loss:  0.11374790221452713\n",
      "Eval Loss:  0.1513865441083908\n",
      "Eval Loss:  0.20760217308998108\n",
      "Eval Loss:  0.19353754818439484\n",
      "Eval Loss:  0.2279113382101059\n",
      "Eval Loss:  0.19412371516227722\n",
      "Eval Loss:  0.19181835651397705\n",
      "Eval Loss:  0.1473129689693451\n",
      "Eval Loss:  0.20954182744026184\n",
      "Eval Loss:  0.19456271827220917\n",
      "Eval Loss:  0.16842584311962128\n",
      "Eval Loss:  0.22566981613636017\n",
      "Eval Loss:  0.23337365686893463\n",
      "Eval Loss:  0.2700357437133789\n",
      "Eval Loss:  0.2597059905529022\n",
      "Eval Loss:  0.14536258578300476\n",
      "Eval Loss:  0.19079551100730896\n",
      "Eval Loss:  0.18066881597042084\n",
      "[[17116   975]\n",
      " [ 1142 10584]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18091\n",
      "           1       0.92      0.90      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.92      0.93     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9290002347654023\n",
      "pre:  0.9156501427459123\n",
      "rec:  0.9026095855364148\n",
      "ma F1:  0.925421079364732\n",
      "mi F1:  0.9290002347654023\n",
      "we F1:  0.928908728495973\n",
      "29817 466\n",
      "Loss:  0.03424055501818657\n",
      "Loss:  0.049255724996328354\n",
      "Loss:  0.036470238119363785\n",
      "42 **********\n",
      "Epoch:  3367.737354516983  fold:  8  kers:  128\n",
      "epoch:  43\n",
      "29817 466\n",
      "Loss:  0.04761156812310219\n",
      "Loss:  0.03057895042002201\n",
      "Loss:  0.03442063555121422\n",
      "43 **********\n",
      "Epoch:  3432.414420604706  fold:  8  kers:  128\n",
      "epoch:  44\n",
      "29817 466\n",
      "Loss:  0.030218519270420074\n",
      "Loss:  0.048369184136390686\n",
      "Loss:  0.05067574977874756\n",
      "44 **********\n",
      "Epoch:  3497.1433486938477  fold:  8  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.3751284182071686\n",
      "Eval Loss:  1.0740638971328735\n",
      "Eval Loss:  0.10439587384462357\n",
      "[[1917  156]\n",
      " [ 348  653]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      2073\n",
      "           1       0.81      0.65      0.72      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.83      0.79      0.80      3074\n",
      "weighted avg       0.83      0.84      0.83      3074\n",
      "\n",
      "acc:  0.8360442420299284\n",
      "pre:  0.8071693448702101\n",
      "rec:  0.6523476523476524\n",
      "ma F1:  0.8026821943559295\n",
      "mi F1:  0.8360442420299284\n",
      "we F1:  0.830976589218688\n",
      "Eval Loss:  0.22276173532009125\n",
      "Eval Loss:  0.1650843620300293\n",
      "Eval Loss:  0.11123086512088776\n",
      "Eval Loss:  0.19022193551063538\n",
      "Eval Loss:  0.19154581427574158\n",
      "Eval Loss:  0.1503247320652008\n",
      "Eval Loss:  0.29054293036460876\n",
      "Eval Loss:  0.19659146666526794\n",
      "Eval Loss:  0.21395298838615417\n",
      "Eval Loss:  0.0961684137582779\n",
      "Eval Loss:  0.12858077883720398\n",
      "Eval Loss:  0.10446234047412872\n",
      "Eval Loss:  0.1509852260351181\n",
      "Eval Loss:  0.18472787737846375\n",
      "Eval Loss:  0.2215559184551239\n",
      "Eval Loss:  0.20854906737804413\n",
      "Eval Loss:  0.19984844326972961\n",
      "Eval Loss:  0.18755406141281128\n",
      "Eval Loss:  0.17965273559093475\n",
      "Eval Loss:  0.18635167181491852\n",
      "Eval Loss:  0.16636331379413605\n",
      "Eval Loss:  0.15284550189971924\n",
      "Eval Loss:  0.24414552748203278\n",
      "Eval Loss:  0.23566147685050964\n",
      "Eval Loss:  0.2568458318710327\n",
      "Eval Loss:  0.2709888815879822\n",
      "Eval Loss:  0.13126473128795624\n",
      "Eval Loss:  0.2183217853307724\n",
      "Eval Loss:  0.1762876957654953\n",
      "[[17371   720]\n",
      " [ 1408 10318]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     18091\n",
      "           1       0.93      0.88      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.92      0.92     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9286313177046651\n",
      "pre:  0.9347707918101106\n",
      "rec:  0.8799249530956847\n",
      "ma F1:  0.9244013823376639\n",
      "mi F1:  0.9286313177046651\n",
      "we F1:  0.928218699594287\n",
      "29817 466\n",
      "Loss:  0.03863758593797684\n",
      "Loss:  0.04111918807029724\n",
      "Loss:  0.04961641505360603\n",
      "45 **********\n",
      "Epoch:  3602.4627463817596  fold:  8  kers:  128\n",
      "epoch:  46\n",
      "29817 466\n",
      "Loss:  0.033906206488609314\n",
      "Loss:  0.06503671407699585\n",
      "Loss:  0.020162997767329216\n",
      "46 **********\n",
      "Epoch:  3668.5330872535706  fold:  8  kers:  128\n",
      "epoch:  47\n",
      "29817 466\n",
      "Loss:  0.034328967332839966\n",
      "Loss:  0.03402210772037506\n",
      "Loss:  0.06173563376069069\n",
      "47 **********\n",
      "Epoch:  3734.0638716220856  fold:  8  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.3242585361003876\n",
      "Eval Loss:  0.9629428386688232\n",
      "Eval Loss:  0.10036590695381165\n",
      "[[1909  164]\n",
      " [ 286  715]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      2073\n",
      "           1       0.81      0.71      0.76      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.82      0.83      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8536109303838647\n",
      "pre:  0.8134243458475541\n",
      "rec:  0.7142857142857143\n",
      "ma F1:  0.8276012482801252\n",
      "mi F1:  0.8536109303838647\n",
      "we F1:  0.8509533246747722\n",
      "Eval Loss:  0.23522791266441345\n",
      "Eval Loss:  0.13193674385547638\n",
      "Eval Loss:  0.11246299743652344\n",
      "Eval Loss:  0.17560406029224396\n",
      "Eval Loss:  0.1884721964597702\n",
      "Eval Loss:  0.14265649020671844\n",
      "Eval Loss:  0.2919544577598572\n",
      "Eval Loss:  0.15649506449699402\n",
      "Eval Loss:  0.21452397108078003\n",
      "Eval Loss:  0.10838012397289276\n",
      "Eval Loss:  0.12239887565374374\n",
      "Eval Loss:  0.11661366373300552\n",
      "Eval Loss:  0.14250794053077698\n",
      "Eval Loss:  0.20270133018493652\n",
      "Eval Loss:  0.21349716186523438\n",
      "Eval Loss:  0.23248031735420227\n",
      "Eval Loss:  0.18605494499206543\n",
      "Eval Loss:  0.1886504888534546\n",
      "Eval Loss:  0.16129642724990845\n",
      "Eval Loss:  0.20773494243621826\n",
      "Eval Loss:  0.178350031375885\n",
      "Eval Loss:  0.16399581730365753\n",
      "Eval Loss:  0.23851144313812256\n",
      "Eval Loss:  0.2349158525466919\n",
      "Eval Loss:  0.23689910769462585\n",
      "Eval Loss:  0.24199499189853668\n",
      "Eval Loss:  0.13282783329486847\n",
      "Eval Loss:  0.17446544766426086\n",
      "Eval Loss:  0.17758432030677795\n",
      "[[17246   845]\n",
      " [ 1311 10415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18091\n",
      "           1       0.92      0.89      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.92      0.92     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.927692256095516\n",
      "pre:  0.9249555950266429\n",
      "rec:  0.8881971686849736\n",
      "ma F1:  0.9236869132094927\n",
      "mi F1:  0.927692256095516\n",
      "we F1:  0.9274190179481163\n",
      "29817 466\n",
      "Loss:  0.056326065212488174\n",
      "Loss:  0.07426483929157257\n",
      "Loss:  0.033428408205509186\n",
      "48 **********\n",
      "Epoch:  3841.845685005188  fold:  8  kers:  128\n",
      "epoch:  49\n",
      "29817 466\n",
      "Loss:  0.044244587421417236\n",
      "Loss:  0.05768219381570816\n",
      "Loss:  0.033530957996845245\n",
      "49 **********\n",
      "Epoch:  3907.745481967926  fold:  8  kers:  128\n",
      "epoch:  50\n",
      "29817 466\n",
      "Loss:  0.029629919677972794\n",
      "Loss:  0.04950976371765137\n",
      "Loss:  0.07728839665651321\n",
      "50 **********\n",
      "Epoch:  3972.6000742912292  fold:  8  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.5322125554084778\n",
      "Eval Loss:  1.0176081657409668\n",
      "Eval Loss:  0.11978389322757721\n",
      "[[1885  188]\n",
      " [ 249  752]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      2073\n",
      "           1       0.80      0.75      0.77      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.84      0.83      0.84      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8578399479505531\n",
      "pre:  0.8\n",
      "rec:  0.7512487512487512\n",
      "ma F1:  0.8354919127819522\n",
      "mi F1:  0.857839947950553\n",
      "we F1:  0.8566367439388278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2095964252948761\n",
      "Eval Loss:  0.1523258090019226\n",
      "Eval Loss:  0.1345590502023697\n",
      "Eval Loss:  0.15871752798557281\n",
      "Eval Loss:  0.1721050888299942\n",
      "Eval Loss:  0.13888442516326904\n",
      "Eval Loss:  0.2664013206958771\n",
      "Eval Loss:  0.18541058897972107\n",
      "Eval Loss:  0.2011939287185669\n",
      "Eval Loss:  0.08791717886924744\n",
      "Eval Loss:  0.11516319960355759\n",
      "Eval Loss:  0.11605022847652435\n",
      "Eval Loss:  0.14247137308120728\n",
      "Eval Loss:  0.18543069064617157\n",
      "Eval Loss:  0.20843783020973206\n",
      "Eval Loss:  0.23654384911060333\n",
      "Eval Loss:  0.1777430921792984\n",
      "Eval Loss:  0.18237781524658203\n",
      "Eval Loss:  0.13723234832286835\n",
      "Eval Loss:  0.19491344690322876\n",
      "Eval Loss:  0.17691433429718018\n",
      "Eval Loss:  0.1573970913887024\n",
      "Eval Loss:  0.23569339513778687\n",
      "Eval Loss:  0.22905439138412476\n",
      "Eval Loss:  0.26300621032714844\n",
      "Eval Loss:  0.22894327342510223\n",
      "Eval Loss:  0.12617681920528412\n",
      "Eval Loss:  0.16190584003925323\n",
      "Eval Loss:  0.15624044835567474\n",
      "[[17219   872]\n",
      " [ 1161 10565]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18091\n",
      "           1       0.92      0.90      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.93      0.93     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9318174195928497\n",
      "pre:  0.9237562297805368\n",
      "rec:  0.9009892546477912\n",
      "ma F1:  0.9282438968715622\n",
      "mi F1:  0.9318174195928497\n",
      "we F1:  0.9316622124893852\n",
      "29817 466\n",
      "Loss:  0.06028155982494354\n",
      "Loss:  0.08027250319719315\n",
      "Loss:  0.06826984882354736\n",
      "51 **********\n",
      "Epoch:  4077.783834218979  fold:  8  kers:  128\n",
      "epoch:  52\n",
      "29817 466\n",
      "Loss:  0.022093461826443672\n",
      "Loss:  0.027708612382411957\n",
      "Loss:  0.05208534374833107\n",
      "52 **********\n",
      "Epoch:  4142.552655696869  fold:  8  kers:  128\n",
      "epoch:  53\n",
      "29817 466\n",
      "Loss:  0.038468293845653534\n",
      "Loss:  0.06648428738117218\n",
      "Loss:  0.038317497819662094\n",
      "53 **********\n",
      "Epoch:  4207.387300729752  fold:  8  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.6536095142364502\n",
      "Eval Loss:  0.9350167512893677\n",
      "Eval Loss:  0.1518326997756958\n",
      "[[1783  290]\n",
      " [ 213  788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      2073\n",
      "           1       0.73      0.79      0.76      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.81      0.82      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8363695510735198\n",
      "pre:  0.7309833024118738\n",
      "rec:  0.7872127872127872\n",
      "ma F1:  0.8172195807978555\n",
      "mi F1:  0.8363695510735198\n",
      "we F1:  0.8378515085722396\n",
      "Eval Loss:  0.20351888239383698\n",
      "Eval Loss:  0.1456216424703598\n",
      "Eval Loss:  0.13983701169490814\n",
      "Eval Loss:  0.18820931017398834\n",
      "Eval Loss:  0.17549148201942444\n",
      "Eval Loss:  0.1570463925600052\n",
      "Eval Loss:  0.2876698672771454\n",
      "Eval Loss:  0.15947765111923218\n",
      "Eval Loss:  0.19635869562625885\n",
      "Eval Loss:  0.11957477033138275\n",
      "Eval Loss:  0.09963670372962952\n",
      "Eval Loss:  0.11196768283843994\n",
      "Eval Loss:  0.13470402359962463\n",
      "Eval Loss:  0.20345668494701385\n",
      "Eval Loss:  0.17962127923965454\n",
      "Eval Loss:  0.21477404236793518\n",
      "Eval Loss:  0.20627275109291077\n",
      "Eval Loss:  0.18600255250930786\n",
      "Eval Loss:  0.1424867808818817\n",
      "Eval Loss:  0.18613772094249725\n",
      "Eval Loss:  0.1758236289024353\n",
      "Eval Loss:  0.163435161113739\n",
      "Eval Loss:  0.21809369325637817\n",
      "Eval Loss:  0.23507831990718842\n",
      "Eval Loss:  0.243690624833107\n",
      "Eval Loss:  0.2548346519470215\n",
      "Eval Loss:  0.14295190572738647\n",
      "Eval Loss:  0.16961008310317993\n",
      "Eval Loss:  0.1705763339996338\n",
      "[[17126   965]\n",
      " [ 1068 10658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18091\n",
      "           1       0.92      0.91      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.93      0.93     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9318174195928497\n",
      "pre:  0.9169749634345694\n",
      "rec:  0.9089203479447382\n",
      "ma F1:  0.9284506139747557\n",
      "mi F1:  0.9318174195928497\n",
      "we F1:  0.9317638047229266\n",
      "29817 466\n",
      "Loss:  0.05022242292761803\n",
      "Loss:  0.046678557991981506\n",
      "Loss:  0.04860422760248184\n",
      "54 **********\n",
      "Epoch:  4312.509226322174  fold:  8  kers:  128\n",
      "epoch:  55\n",
      "29817 466\n",
      "Loss:  0.040230777114629745\n",
      "Loss:  0.035697903484106064\n",
      "Loss:  0.047167349606752396\n",
      "55 **********\n",
      "Epoch:  4377.319935321808  fold:  8  kers:  128\n",
      "epoch:  56\n",
      "29817 466\n",
      "Loss:  0.05404620245099068\n",
      "Loss:  0.0614512637257576\n",
      "Loss:  0.06977801024913788\n",
      "56 **********\n",
      "Epoch:  4442.089754581451  fold:  8  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.5000075697898865\n",
      "Eval Loss:  1.0639464855194092\n",
      "Eval Loss:  0.1469649225473404\n",
      "[[1838  235]\n",
      " [ 255  746]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      2073\n",
      "           1       0.76      0.75      0.75      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.82      0.82      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8405985686402082\n",
      "pre:  0.7604485219164119\n",
      "rec:  0.7452547452547452\n",
      "ma F1:  0.8175780778809574\n",
      "mi F1:  0.8405985686402082\n",
      "we F1:  0.8401769479303317\n",
      "Eval Loss:  0.2193310558795929\n",
      "Eval Loss:  0.14715921878814697\n",
      "Eval Loss:  0.116043820977211\n",
      "Eval Loss:  0.17789098620414734\n",
      "Eval Loss:  0.14290478825569153\n",
      "Eval Loss:  0.16483786702156067\n",
      "Eval Loss:  0.24782752990722656\n",
      "Eval Loss:  0.1649136245250702\n",
      "Eval Loss:  0.2057538628578186\n",
      "Eval Loss:  0.08753518760204315\n",
      "Eval Loss:  0.11538051068782806\n",
      "Eval Loss:  0.11199040710926056\n",
      "Eval Loss:  0.14714854955673218\n",
      "Eval Loss:  0.17790929973125458\n",
      "Eval Loss:  0.2049938440322876\n",
      "Eval Loss:  0.19635851681232452\n",
      "Eval Loss:  0.1812705397605896\n",
      "Eval Loss:  0.17789225280284882\n",
      "Eval Loss:  0.14726759493350983\n",
      "Eval Loss:  0.1751464307308197\n",
      "Eval Loss:  0.17180506885051727\n",
      "Eval Loss:  0.1698310673236847\n",
      "Eval Loss:  0.20816916227340698\n",
      "Eval Loss:  0.21364961564540863\n",
      "Eval Loss:  0.24008920788764954\n",
      "Eval Loss:  0.23307067155838013\n",
      "Eval Loss:  0.13488462567329407\n",
      "Eval Loss:  0.15591242909431458\n",
      "Eval Loss:  0.16913770139217377\n",
      "[[17237   854]\n",
      " [ 1067 10659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18091\n",
      "           1       0.93      0.91      0.92     11726\n",
      "\n",
      "    accuracy                           0.94     29817\n",
      "   macro avg       0.93      0.93      0.93     29817\n",
      "weighted avg       0.94      0.94      0.94     29817\n",
      "\n",
      "acc:  0.9355736660294462\n",
      "pre:  0.9258229827151915\n",
      "rec:  0.9090056285178236\n",
      "ma F1:  0.9322776296373418\n",
      "mi F1:  0.9355736660294462\n",
      "we F1:  0.9354669381864059\n",
      "29817 466\n",
      "Loss:  0.03584461286664009\n",
      "Loss:  0.03412352502346039\n",
      "Loss:  0.055448267608881\n",
      "57 **********\n",
      "Epoch:  4547.3792316913605  fold:  8  kers:  128\n",
      "epoch:  58\n",
      "29817 466\n",
      "Loss:  0.05257156118750572\n",
      "Loss:  0.03752181679010391\n",
      "Loss:  0.0680050179362297\n",
      "58 **********\n",
      "Epoch:  4612.1879460811615  fold:  8  kers:  128\n",
      "epoch:  59\n",
      "29817 466\n",
      "Loss:  0.045746706426143646\n",
      "Loss:  0.03694560378789902\n",
      "Loss:  0.035182252526283264\n",
      "59 **********\n",
      "Epoch:  4676.982697725296  fold:  8  kers:  128\n",
      "Eval Loss:  0.5747648477554321\n",
      "Eval Loss:  0.7919059991836548\n",
      "Eval Loss:  0.16616693139076233\n",
      "[[1693  380]\n",
      " [ 141  860]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87      2073\n",
      "           1       0.69      0.86      0.77      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.84      0.82      3074\n",
      "weighted avg       0.85      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8305139882888745\n",
      "pre:  0.6935483870967742\n",
      "rec:  0.8591408591408591\n",
      "ma F1:  0.8170820528652162\n",
      "mi F1:  0.8305139882888745\n",
      "we F1:  0.8343678088966227\n",
      "update!  Acc:  0.8640208197787899\n",
      "Epoch:  4680.797497987747  fold:  8  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29483 3408\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29483 461\n",
      "Loss:  0.16943377256393433\n",
      "Loss:  0.1660066694021225\n",
      "Loss:  0.16152676939964294\n",
      "0 **********\n",
      "Epoch:  76.55829858779907  fold:  9  kers:  128\n",
      "epoch:  1\n",
      "29483 461\n",
      "Loss:  0.142887145280838\n",
      "Loss:  0.14057298004627228\n",
      "Loss:  0.11905819177627563\n",
      "1 **********\n",
      "Epoch:  140.6319785118103  fold:  9  kers:  128\n",
      "epoch:  2\n",
      "29483 461\n",
      "Loss:  0.11580859124660492\n",
      "Loss:  0.08949781954288483\n",
      "Loss:  0.08897080272436142\n",
      "2 **********\n",
      "Epoch:  204.69967436790466  fold:  9  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.13891984522342682\n",
      "Eval Loss:  1.6975901126861572\n",
      "Eval Loss:  0.4107292592525482\n",
      "[[1687   55]\n",
      " [ 735  931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81      1742\n",
      "           1       0.94      0.56      0.70      1666\n",
      "\n",
      "    accuracy                           0.77      3408\n",
      "   macro avg       0.82      0.76      0.76      3408\n",
      "weighted avg       0.82      0.77      0.76      3408\n",
      "\n",
      "acc:  0.7681924882629108\n",
      "pre:  0.9442190669371197\n",
      "rec:  0.5588235294117647\n",
      "ma F1:  0.7561950960832128\n",
      "mi F1:  0.7681924882629108\n",
      "we F1:  0.7574011831277326\n",
      "update!  Acc:  0.7681924882629108\n",
      "Eval Loss:  0.4422185719013214\n",
      "Eval Loss:  0.46415844559669495\n",
      "Eval Loss:  0.48088768124580383\n",
      "Eval Loss:  0.4872324764728546\n",
      "Eval Loss:  0.5644679069519043\n",
      "Eval Loss:  0.5974412560462952\n",
      "Eval Loss:  0.618800699710846\n",
      "Eval Loss:  0.5611741542816162\n",
      "Eval Loss:  0.4774762690067291\n",
      "Eval Loss:  0.4618290364742279\n",
      "Eval Loss:  0.6322211027145386\n",
      "Eval Loss:  0.4445193409919739\n",
      "Eval Loss:  0.48564815521240234\n",
      "Eval Loss:  0.551375687122345\n",
      "Eval Loss:  0.5215493440628052\n",
      "Eval Loss:  0.46974924206733704\n",
      "Eval Loss:  0.5022901296615601\n",
      "Eval Loss:  0.442462682723999\n",
      "Eval Loss:  0.4605894982814789\n",
      "Eval Loss:  0.5276622772216797\n",
      "Eval Loss:  0.5291447043418884\n",
      "Eval Loss:  0.39953717589378357\n",
      "Eval Loss:  0.43619227409362793\n",
      "Eval Loss:  0.5780397057533264\n",
      "Eval Loss:  0.4621047377586365\n",
      "Eval Loss:  0.45185229182243347\n",
      "Eval Loss:  0.48715534806251526\n",
      "Eval Loss:  0.4130996763706207\n",
      "[[17553   869]\n",
      " [ 5427  5634]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.85     18422\n",
      "           1       0.87      0.51      0.64     11061\n",
      "\n",
      "    accuracy                           0.79     29483\n",
      "   macro avg       0.82      0.73      0.74     29483\n",
      "weighted avg       0.80      0.79      0.77     29483\n",
      "\n",
      "acc:  0.7864532103245938\n",
      "pre:  0.8663693679840074\n",
      "rec:  0.5093572009764036\n",
      "ma F1:  0.7447347821639071\n",
      "mi F1:  0.7864532103245938\n",
      "we F1:  0.7704994729677342\n",
      "29483 461\n",
      "Loss:  0.12379549443721771\n",
      "Loss:  0.11458569020032883\n",
      "Loss:  0.1115349680185318\n",
      "3 **********\n",
      "Epoch:  312.95023584365845  fold:  9  kers:  128\n",
      "epoch:  4\n",
      "29483 461\n",
      "Loss:  0.07505350559949875\n",
      "Loss:  0.07457153499126434\n",
      "Loss:  0.08667734265327454\n",
      "4 **********\n",
      "Epoch:  377.03588223457336  fold:  9  kers:  128\n",
      "epoch:  5\n",
      "29483 461\n",
      "Loss:  0.10149464756250381\n",
      "Loss:  0.11150744557380676\n",
      "Loss:  0.08930410444736481\n",
      "5 **********\n",
      "Epoch:  441.08762073516846  fold:  9  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.06890331953763962\n",
      "Eval Loss:  1.8884587287902832\n",
      "Eval Loss:  0.332624614238739\n",
      "[[1699   43]\n",
      " [ 680  986]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.82      1742\n",
      "           1       0.96      0.59      0.73      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.84      0.78      0.78      3408\n",
      "weighted avg       0.83      0.79      0.78      3408\n",
      "\n",
      "acc:  0.7878521126760564\n",
      "pre:  0.9582118561710399\n",
      "rec:  0.5918367346938775\n",
      "ma F1:  0.7781412818817055\n",
      "mi F1:  0.7878521126760564\n",
      "we F1:  0.7791763774502478\n",
      "update!  Acc:  0.7878521126760564\n",
      "Eval Loss:  0.3975123167037964\n",
      "Eval Loss:  0.3628444969654083\n",
      "Eval Loss:  0.424432635307312\n",
      "Eval Loss:  0.4420451521873474\n",
      "Eval Loss:  0.4873535633087158\n",
      "Eval Loss:  0.4787123203277588\n",
      "Eval Loss:  0.553611159324646\n",
      "Eval Loss:  0.47063377499580383\n",
      "Eval Loss:  0.4109957218170166\n",
      "Eval Loss:  0.3662799894809723\n",
      "Eval Loss:  0.5588018298149109\n",
      "Eval Loss:  0.3715330958366394\n",
      "Eval Loss:  0.3996913433074951\n",
      "Eval Loss:  0.47982659935951233\n",
      "Eval Loss:  0.4797229468822479\n",
      "Eval Loss:  0.41701367497444153\n",
      "Eval Loss:  0.4360373318195343\n",
      "Eval Loss:  0.37150487303733826\n",
      "Eval Loss:  0.3894655108451843\n",
      "Eval Loss:  0.49068203568458557\n",
      "Eval Loss:  0.426552951335907\n",
      "Eval Loss:  0.35060685873031616\n",
      "Eval Loss:  0.3767681121826172\n",
      "Eval Loss:  0.47720956802368164\n",
      "Eval Loss:  0.39038926362991333\n",
      "Eval Loss:  0.3779439330101013\n",
      "Eval Loss:  0.399637371301651\n",
      "Eval Loss:  0.33366134762763977\n",
      "[[17865   557]\n",
      " [ 4621  6440]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     18422\n",
      "           1       0.92      0.58      0.71     11061\n",
      "\n",
      "    accuracy                           0.82     29483\n",
      "   macro avg       0.86      0.78      0.79     29483\n",
      "weighted avg       0.84      0.82      0.81     29483\n",
      "\n",
      "acc:  0.8243733677034223\n",
      "pre:  0.9203944547663284\n",
      "rec:  0.5822258385317783\n",
      "ma F1:  0.7933402866894039\n",
      "mi F1:  0.8243733677034223\n",
      "we F1:  0.8133345544657006\n",
      "29483 461\n",
      "Loss:  0.054002195596694946\n",
      "Loss:  0.07642418891191483\n",
      "Loss:  0.07189768552780151\n",
      "6 **********\n",
      "Epoch:  545.6849491596222  fold:  9  kers:  128\n",
      "epoch:  7\n",
      "29483 461\n",
      "Loss:  0.08239337056875229\n",
      "Loss:  0.09043658524751663\n",
      "Loss:  0.08181338757276535\n",
      "7 **********\n",
      "Epoch:  609.7426719665527  fold:  9  kers:  128\n",
      "epoch:  8\n",
      "29483 461\n",
      "Loss:  0.06366845965385437\n",
      "Loss:  0.04044488072395325\n",
      "Loss:  0.06885672360658646\n",
      "8 **********\n",
      "Epoch:  673.8233332633972  fold:  9  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.06129078194499016\n",
      "Eval Loss:  1.1710255146026611\n",
      "Eval Loss:  0.21183060109615326\n",
      "[[1659   83]\n",
      " [ 457 1209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86      1742\n",
      "           1       0.94      0.73      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.86      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8415492957746479\n",
      "pre:  0.9357585139318886\n",
      "rec:  0.7256902761104442\n",
      "ma F1:  0.838737661633002\n",
      "mi F1:  0.8415492957746479\n",
      "we F1:  0.8392125153991468\n",
      "update!  Acc:  0.8415492957746479\n",
      "Eval Loss:  0.2829897403717041\n",
      "Eval Loss:  0.2829785645008087\n",
      "Eval Loss:  0.2978038191795349\n",
      "Eval Loss:  0.2827833592891693\n",
      "Eval Loss:  0.3039143681526184\n",
      "Eval Loss:  0.24973975121974945\n",
      "Eval Loss:  0.3372627794742584\n",
      "Eval Loss:  0.31711089611053467\n",
      "Eval Loss:  0.2234003245830536\n",
      "Eval Loss:  0.25089237093925476\n",
      "Eval Loss:  0.33649641275405884\n",
      "Eval Loss:  0.29171425104141235\n",
      "Eval Loss:  0.2858078181743622\n",
      "Eval Loss:  0.30260133743286133\n",
      "Eval Loss:  0.28790703415870667\n",
      "Eval Loss:  0.280910462141037\n",
      "Eval Loss:  0.30638834834098816\n",
      "Eval Loss:  0.2316984236240387\n",
      "Eval Loss:  0.2700725793838501\n",
      "Eval Loss:  0.3355270326137543\n",
      "Eval Loss:  0.2575233578681946\n",
      "Eval Loss:  0.2797386348247528\n",
      "Eval Loss:  0.2274269312620163\n",
      "Eval Loss:  0.3013994097709656\n",
      "Eval Loss:  0.27416449785232544\n",
      "Eval Loss:  0.29465240240097046\n",
      "Eval Loss:  0.2533424198627472\n",
      "Eval Loss:  0.2116810828447342\n",
      "[[17249  1173]\n",
      " [ 2207  8854]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     18422\n",
      "           1       0.88      0.80      0.84     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.88      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.88     29483\n",
      "\n",
      "acc:  0.8853576637384255\n",
      "pre:  0.8830158571855988\n",
      "rec:  0.8004701202422927\n",
      "ma F1:  0.875242707779733\n",
      "mi F1:  0.8853576637384255\n",
      "we F1:  0.8841118192522686\n",
      "29483 461\n",
      "Loss:  0.06979736685752869\n",
      "Loss:  0.0701855942606926\n",
      "Loss:  0.1256721019744873\n",
      "9 **********\n",
      "Epoch:  778.4954612255096  fold:  9  kers:  128\n",
      "epoch:  10\n",
      "29483 461\n",
      "Loss:  0.0927267074584961\n",
      "Loss:  0.07409738749265671\n",
      "Loss:  0.0613025426864624\n",
      "10 **********\n",
      "Epoch:  842.5741274356842  fold:  9  kers:  128\n",
      "epoch:  11\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08203773945569992\n",
      "Loss:  0.043431926518678665\n",
      "Loss:  0.07174260914325714\n",
      "11 **********\n",
      "Epoch:  906.6597757339478  fold:  9  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.03192386031150818\n",
      "Eval Loss:  1.5653278827667236\n",
      "Eval Loss:  0.17652025818824768\n",
      "[[1673   69]\n",
      " [ 524 1142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85      1742\n",
      "           1       0.94      0.69      0.79      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.82      0.82      3408\n",
      "weighted avg       0.85      0.83      0.82      3408\n",
      "\n",
      "acc:  0.8259976525821596\n",
      "pre:  0.9430222956234517\n",
      "rec:  0.6854741896758704\n",
      "ma F1:  0.8216683463485516\n",
      "mi F1:  0.8259976525821596\n",
      "we F1:  0.8222879833989362\n",
      "Eval Loss:  0.2549266517162323\n",
      "Eval Loss:  0.2934446632862091\n",
      "Eval Loss:  0.2695412337779999\n",
      "Eval Loss:  0.3002074360847473\n",
      "Eval Loss:  0.29518789052963257\n",
      "Eval Loss:  0.19676096737384796\n",
      "Eval Loss:  0.3352024257183075\n",
      "Eval Loss:  0.31820106506347656\n",
      "Eval Loss:  0.22416575253009796\n",
      "Eval Loss:  0.24028591811656952\n",
      "Eval Loss:  0.3281708061695099\n",
      "Eval Loss:  0.30295419692993164\n",
      "Eval Loss:  0.3353021442890167\n",
      "Eval Loss:  0.29391342401504517\n",
      "Eval Loss:  0.24222691357135773\n",
      "Eval Loss:  0.2862989008426666\n",
      "Eval Loss:  0.29778656363487244\n",
      "Eval Loss:  0.18869248032569885\n",
      "Eval Loss:  0.299614280462265\n",
      "Eval Loss:  0.3439771831035614\n",
      "Eval Loss:  0.2343461811542511\n",
      "Eval Loss:  0.2949322462081909\n",
      "Eval Loss:  0.22289735078811646\n",
      "Eval Loss:  0.3023275136947632\n",
      "Eval Loss:  0.2626730501651764\n",
      "Eval Loss:  0.2830166518688202\n",
      "Eval Loss:  0.24051877856254578\n",
      "Eval Loss:  0.22723621129989624\n",
      "[[17246  1176]\n",
      " [ 2014  9047]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18422\n",
      "           1       0.88      0.82      0.85     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.88      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8918020554217685\n",
      "pre:  0.8849652743812971\n",
      "rec:  0.8179188138504656\n",
      "ma F1:  0.8827331768285627\n",
      "mi F1:  0.8918020554217685\n",
      "we F1:  0.8908751472303909\n",
      "29483 461\n",
      "Loss:  0.07163489609956741\n",
      "Loss:  0.05398915335536003\n",
      "Loss:  0.06388841569423676\n",
      "12 **********\n",
      "Epoch:  1011.5114240646362  fold:  9  kers:  128\n",
      "epoch:  13\n",
      "29483 461\n",
      "Loss:  0.05375513434410095\n",
      "Loss:  0.06330125033855438\n",
      "Loss:  0.06879658997058868\n",
      "13 **********\n",
      "Epoch:  1075.5811142921448  fold:  9  kers:  128\n",
      "epoch:  14\n",
      "29483 461\n",
      "Loss:  0.08416169881820679\n",
      "Loss:  0.06862052530050278\n",
      "Loss:  0.05292324349284172\n",
      "14 **********\n",
      "Epoch:  1139.6797277927399  fold:  9  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.04774581640958786\n",
      "Eval Loss:  1.6388009786605835\n",
      "Eval Loss:  0.24666646122932434\n",
      "[[1694   48]\n",
      " [ 670  996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.83      1742\n",
      "           1       0.95      0.60      0.74      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.84      0.79      0.78      3408\n",
      "weighted avg       0.83      0.79      0.78      3408\n",
      "\n",
      "acc:  0.7893192488262911\n",
      "pre:  0.9540229885057471\n",
      "rec:  0.5978391356542617\n",
      "ma F1:  0.7800946504350577\n",
      "mi F1:  0.7893192488262911\n",
      "we F1:  0.7810990479676274\n",
      "Eval Loss:  0.2179105281829834\n",
      "Eval Loss:  0.26461321115493774\n",
      "Eval Loss:  0.24142959713935852\n",
      "Eval Loss:  0.26409220695495605\n",
      "Eval Loss:  0.30420947074890137\n",
      "Eval Loss:  0.24860157072544098\n",
      "Eval Loss:  0.3322179615497589\n",
      "Eval Loss:  0.2779730260372162\n",
      "Eval Loss:  0.23593556880950928\n",
      "Eval Loss:  0.23167064785957336\n",
      "Eval Loss:  0.32188692688941956\n",
      "Eval Loss:  0.28397560119628906\n",
      "Eval Loss:  0.27366286516189575\n",
      "Eval Loss:  0.291574627161026\n",
      "Eval Loss:  0.29175522923469543\n",
      "Eval Loss:  0.2971113324165344\n",
      "Eval Loss:  0.29833292961120605\n",
      "Eval Loss:  0.1721455603837967\n",
      "Eval Loss:  0.26616615056991577\n",
      "Eval Loss:  0.2980441451072693\n",
      "Eval Loss:  0.2084583342075348\n",
      "Eval Loss:  0.2915964126586914\n",
      "Eval Loss:  0.2657614052295685\n",
      "Eval Loss:  0.28324612975120544\n",
      "Eval Loss:  0.21371082961559296\n",
      "Eval Loss:  0.21589696407318115\n",
      "Eval Loss:  0.2655802369117737\n",
      "Eval Loss:  0.22198191285133362\n",
      "[[17595   827]\n",
      " [ 2365  8696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18422\n",
      "           1       0.91      0.79      0.84     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.90      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8917342197198386\n",
      "pre:  0.9131576183975638\n",
      "rec:  0.7861856974957057\n",
      "ma F1:  0.8808820581888335\n",
      "mi F1:  0.8917342197198386\n",
      "we F1:  0.889858657922481\n",
      "29483 461\n",
      "Loss:  0.06951476633548737\n",
      "Loss:  0.0638878270983696\n",
      "Loss:  0.04987231642007828\n",
      "15 **********\n",
      "Epoch:  1244.0905542373657  fold:  9  kers:  128\n",
      "epoch:  16\n",
      "29483 461\n",
      "Loss:  0.08590378612279892\n",
      "Loss:  0.0389024093747139\n",
      "Loss:  0.08514609932899475\n",
      "16 **********\n",
      "Epoch:  1308.175205230713  fold:  9  kers:  128\n",
      "epoch:  17\n",
      "29483 461\n",
      "Loss:  0.049718085676431656\n",
      "Loss:  0.08241187036037445\n",
      "Loss:  0.06663575768470764\n",
      "17 **********\n",
      "Epoch:  1372.2937653064728  fold:  9  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.04336097836494446\n",
      "Eval Loss:  0.8460793495178223\n",
      "Eval Loss:  0.1271839290857315\n",
      "[[1593  149]\n",
      " [ 328 1338]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1742\n",
      "           1       0.90      0.80      0.85      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.86      0.86      0.86      3408\n",
      "weighted avg       0.86      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8600352112676056\n",
      "pre:  0.8997982515131137\n",
      "rec:  0.8031212484993998\n",
      "ma F1:  0.8592471894089402\n",
      "mi F1:  0.8600352112676056\n",
      "we F1:  0.8594820508256407\n",
      "update!  Acc:  0.8600352112676056\n",
      "Eval Loss:  0.23532474040985107\n",
      "Eval Loss:  0.2623990774154663\n",
      "Eval Loss:  0.23536595702171326\n",
      "Eval Loss:  0.24798405170440674\n",
      "Eval Loss:  0.19982343912124634\n",
      "Eval Loss:  0.1901097446680069\n",
      "Eval Loss:  0.30163151025772095\n",
      "Eval Loss:  0.257398396730423\n",
      "Eval Loss:  0.16727067530155182\n",
      "Eval Loss:  0.2276979386806488\n",
      "Eval Loss:  0.26861846446990967\n",
      "Eval Loss:  0.29439255595207214\n",
      "Eval Loss:  0.30908387899398804\n",
      "Eval Loss:  0.25759240984916687\n",
      "Eval Loss:  0.23946459591388702\n",
      "Eval Loss:  0.2551114559173584\n",
      "Eval Loss:  0.2929856479167938\n",
      "Eval Loss:  0.20610198378562927\n",
      "Eval Loss:  0.25949448347091675\n",
      "Eval Loss:  0.27617159485816956\n",
      "Eval Loss:  0.17014510929584503\n",
      "Eval Loss:  0.27317535877227783\n",
      "Eval Loss:  0.1989136040210724\n",
      "Eval Loss:  0.2926267385482788\n",
      "Eval Loss:  0.23158353567123413\n",
      "Eval Loss:  0.24864308536052704\n",
      "Eval Loss:  0.23040282726287842\n",
      "Eval Loss:  0.21420009434223175\n",
      "[[16797  1625]\n",
      " [ 1198  9863]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     18422\n",
      "           1       0.86      0.89      0.87     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.90      0.90     29483\n",
      "weighted avg       0.91      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9042499067259099\n",
      "pre:  0.8585480501392758\n",
      "rec:  0.8916915287948648\n",
      "ma F1:  0.8986436184224676\n",
      "mi F1:  0.90424990672591\n",
      "we F1:  0.9045951454201081\n",
      "29483 461\n",
      "Loss:  0.05238286405801773\n",
      "Loss:  0.042572494596242905\n",
      "Loss:  0.04301833733916283\n",
      "18 **********\n",
      "Epoch:  1476.6986076831818  fold:  9  kers:  128\n",
      "epoch:  19\n",
      "29483 461\n",
      "Loss:  0.06911253929138184\n",
      "Loss:  0.044327445328235626\n",
      "Loss:  0.054552700370550156\n",
      "19 **********\n",
      "Epoch:  1540.7802662849426  fold:  9  kers:  128\n",
      "epoch:  20\n",
      "29483 461\n",
      "Loss:  0.0645294040441513\n",
      "Loss:  0.06200346723198891\n",
      "Loss:  0.04570326954126358\n",
      "20 **********\n",
      "Epoch:  1604.8888530731201  fold:  9  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.036164432764053345\n",
      "Eval Loss:  1.9074087142944336\n",
      "Eval Loss:  0.18524165451526642\n",
      "[[1676   66]\n",
      " [ 631 1035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83      1742\n",
      "           1       0.94      0.62      0.75      1666\n",
      "\n",
      "    accuracy                           0.80      3408\n",
      "   macro avg       0.83      0.79      0.79      3408\n",
      "weighted avg       0.83      0.80      0.79      3408\n",
      "\n",
      "acc:  0.795481220657277\n",
      "pre:  0.9400544959128065\n",
      "rec:  0.6212484993997599\n",
      "ma F1:  0.7879806843935551\n",
      "mi F1:  0.795481220657277\n",
      "we F1:  0.7888699835449481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21907414495944977\n",
      "Eval Loss:  0.32605108618736267\n",
      "Eval Loss:  0.2569080591201782\n",
      "Eval Loss:  0.2458471804857254\n",
      "Eval Loss:  0.29949238896369934\n",
      "Eval Loss:  0.19929558038711548\n",
      "Eval Loss:  0.30718255043029785\n",
      "Eval Loss:  0.2820676565170288\n",
      "Eval Loss:  0.22558429837226868\n",
      "Eval Loss:  0.20359273254871368\n",
      "Eval Loss:  0.2662098705768585\n",
      "Eval Loss:  0.24161158502101898\n",
      "Eval Loss:  0.27900999784469604\n",
      "Eval Loss:  0.3050778806209564\n",
      "Eval Loss:  0.24812275171279907\n",
      "Eval Loss:  0.27915942668914795\n",
      "Eval Loss:  0.28807589411735535\n",
      "Eval Loss:  0.15601198375225067\n",
      "Eval Loss:  0.28870320320129395\n",
      "Eval Loss:  0.33206820487976074\n",
      "Eval Loss:  0.2262459695339203\n",
      "Eval Loss:  0.2635313868522644\n",
      "Eval Loss:  0.2844427525997162\n",
      "Eval Loss:  0.24221384525299072\n",
      "Eval Loss:  0.23808026313781738\n",
      "Eval Loss:  0.189759761095047\n",
      "Eval Loss:  0.2476571947336197\n",
      "Eval Loss:  0.24435396492481232\n",
      "[[17579   843]\n",
      " [ 2037  9024]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18422\n",
      "           1       0.91      0.82      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.89      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.902316589220907\n",
      "pre:  0.9145636971723928\n",
      "rec:  0.8158394358557093\n",
      "ma F1:  0.8933357805883155\n",
      "mi F1:  0.902316589220907\n",
      "we F1:  0.9010631601727112\n",
      "29483 461\n",
      "Loss:  0.10866763442754745\n",
      "Loss:  0.05944158136844635\n",
      "Loss:  0.04437548294663429\n",
      "21 **********\n",
      "Epoch:  1709.390436887741  fold:  9  kers:  128\n",
      "epoch:  22\n",
      "29483 461\n",
      "Loss:  0.06940077990293503\n",
      "Loss:  0.06655675917863846\n",
      "Loss:  0.06887233257293701\n",
      "22 **********\n",
      "Epoch:  1773.4621222019196  fold:  9  kers:  128\n",
      "epoch:  23\n",
      "29483 461\n",
      "Loss:  0.04165266454219818\n",
      "Loss:  0.04706835001707077\n",
      "Loss:  0.05402352288365364\n",
      "23 **********\n",
      "Epoch:  1837.524831533432  fold:  9  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.03921863064169884\n",
      "Eval Loss:  1.5847022533416748\n",
      "Eval Loss:  0.1828724890947342\n",
      "[[1654   88]\n",
      " [ 592 1074]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83      1742\n",
      "           1       0.92      0.64      0.76      1666\n",
      "\n",
      "    accuracy                           0.80      3408\n",
      "   macro avg       0.83      0.80      0.79      3408\n",
      "weighted avg       0.83      0.80      0.80      3408\n",
      "\n",
      "acc:  0.8004694835680751\n",
      "pre:  0.9242685025817556\n",
      "rec:  0.6446578631452581\n",
      "ma F1:  0.7945179243529741\n",
      "mi F1:  0.8004694835680752\n",
      "we F1:  0.795297783836332\n",
      "Eval Loss:  0.20087409019470215\n",
      "Eval Loss:  0.2771912217140198\n",
      "Eval Loss:  0.21381649374961853\n",
      "Eval Loss:  0.24747958779335022\n",
      "Eval Loss:  0.20684123039245605\n",
      "Eval Loss:  0.1625988483428955\n",
      "Eval Loss:  0.2680511772632599\n",
      "Eval Loss:  0.2597363293170929\n",
      "Eval Loss:  0.1816730946302414\n",
      "Eval Loss:  0.21033522486686707\n",
      "Eval Loss:  0.26303818821907043\n",
      "Eval Loss:  0.22400495409965515\n",
      "Eval Loss:  0.28741613030433655\n",
      "Eval Loss:  0.2774706184864044\n",
      "Eval Loss:  0.20885305106639862\n",
      "Eval Loss:  0.24910688400268555\n",
      "Eval Loss:  0.30530792474746704\n",
      "Eval Loss:  0.15533283352851868\n",
      "Eval Loss:  0.26235800981521606\n",
      "Eval Loss:  0.27213871479034424\n",
      "Eval Loss:  0.1592893898487091\n",
      "Eval Loss:  0.2582935690879822\n",
      "Eval Loss:  0.2687559127807617\n",
      "Eval Loss:  0.24031029641628265\n",
      "Eval Loss:  0.19959484040737152\n",
      "Eval Loss:  0.18700474500656128\n",
      "Eval Loss:  0.22304940223693848\n",
      "Eval Loss:  0.22544631361961365\n",
      "[[17349  1073]\n",
      " [ 1601  9460]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18422\n",
      "           1       0.90      0.86      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.90      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9093036665196893\n",
      "pre:  0.8981296876483433\n",
      "rec:  0.8552572100171775\n",
      "ma F1:  0.9023092062857812\n",
      "mi F1:  0.9093036665196893\n",
      "we F1:  0.9088355368450152\n",
      "29483 461\n",
      "Loss:  0.0721009224653244\n",
      "Loss:  0.04377153143286705\n",
      "Loss:  0.03213771805167198\n",
      "24 **********\n",
      "Epoch:  1941.824954509735  fold:  9  kers:  128\n",
      "epoch:  25\n",
      "29483 461\n",
      "Loss:  0.05259809270501137\n",
      "Loss:  0.0707237720489502\n",
      "Loss:  0.07651099562644958\n",
      "25 **********\n",
      "Epoch:  2005.8148584365845  fold:  9  kers:  128\n",
      "epoch:  26\n",
      "29483 461\n",
      "Loss:  0.07972324639558792\n",
      "Loss:  0.08749283105134964\n",
      "Loss:  0.047485098242759705\n",
      "26 **********\n",
      "Epoch:  2069.8077545166016  fold:  9  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.0330704040825367\n",
      "Eval Loss:  1.658811330795288\n",
      "Eval Loss:  0.18592369556427002\n",
      "[[1699   43]\n",
      " [ 587 1079]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84      1742\n",
      "           1       0.96      0.65      0.77      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.85      0.81      0.81      3408\n",
      "weighted avg       0.85      0.82      0.81      3408\n",
      "\n",
      "acc:  0.8151408450704225\n",
      "pre:  0.9616755793226381\n",
      "rec:  0.6476590636254502\n",
      "ma F1:  0.8088131999960106\n",
      "mi F1:  0.8151408450704225\n",
      "we F1:  0.8095888468115837\n",
      "Eval Loss:  0.1970691829919815\n",
      "Eval Loss:  0.2932133674621582\n",
      "Eval Loss:  0.2674456834793091\n",
      "Eval Loss:  0.2667113244533539\n",
      "Eval Loss:  0.24776524305343628\n",
      "Eval Loss:  0.23244823515415192\n",
      "Eval Loss:  0.3318158984184265\n",
      "Eval Loss:  0.3046102821826935\n",
      "Eval Loss:  0.22689856588840485\n",
      "Eval Loss:  0.16301602125167847\n",
      "Eval Loss:  0.26494595408439636\n",
      "Eval Loss:  0.1972605437040329\n",
      "Eval Loss:  0.26872268319129944\n",
      "Eval Loss:  0.2589898109436035\n",
      "Eval Loss:  0.276297390460968\n",
      "Eval Loss:  0.28242501616477966\n",
      "Eval Loss:  0.27751898765563965\n",
      "Eval Loss:  0.19662584364414215\n",
      "Eval Loss:  0.27220118045806885\n",
      "Eval Loss:  0.31840816140174866\n",
      "Eval Loss:  0.195170059800148\n",
      "Eval Loss:  0.2506806552410126\n",
      "Eval Loss:  0.2935952842235565\n",
      "Eval Loss:  0.25624141097068787\n",
      "Eval Loss:  0.23764382302761078\n",
      "Eval Loss:  0.16585999727249146\n",
      "Eval Loss:  0.23532964289188385\n",
      "Eval Loss:  0.22851890325546265\n",
      "[[17858   564]\n",
      " [ 2376  8685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18422\n",
      "           1       0.94      0.79      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9002815181630092\n",
      "pre:  0.9390204346415829\n",
      "rec:  0.7851912123677787\n",
      "ma F1:  0.8895941293640623\n",
      "mi F1:  0.9002815181630092\n",
      "we F1:  0.8981703714821315\n",
      "29483 461\n",
      "Loss:  0.032877400517463684\n",
      "Loss:  0.04089146852493286\n",
      "Loss:  0.04773659631609917\n",
      "27 **********\n",
      "Epoch:  2174.0639939308167  fold:  9  kers:  128\n",
      "epoch:  28\n",
      "29483 461\n",
      "Loss:  0.05992504954338074\n",
      "Loss:  0.052471280097961426\n",
      "Loss:  0.0464346818625927\n",
      "28 **********\n",
      "Epoch:  2238.069855451584  fold:  9  kers:  128\n",
      "epoch:  29\n",
      "29483 461\n",
      "Loss:  0.02957477793097496\n",
      "Loss:  0.04356791824102402\n",
      "Loss:  0.05515230447053909\n",
      "29 **********\n",
      "Epoch:  2302.0846934318542  fold:  9  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.03461950272321701\n",
      "Eval Loss:  1.053623914718628\n",
      "Eval Loss:  0.09715554863214493\n",
      "[[1616  126]\n",
      " [ 319 1347]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      1742\n",
      "           1       0.91      0.81      0.86      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.87      0.87      0.87      3408\n",
      "weighted avg       0.87      0.87      0.87      3408\n",
      "\n",
      "acc:  0.869424882629108\n",
      "pre:  0.9144602851323829\n",
      "rec:  0.8085234093637454\n",
      "ma F1:  0.8686062669861809\n",
      "mi F1:  0.8694248826291081\n",
      "we F1:  0.868837548729164\n",
      "update!  Acc:  0.869424882629108\n",
      "Eval Loss:  0.19509053230285645\n",
      "Eval Loss:  0.23474416136741638\n",
      "Eval Loss:  0.21075564622879028\n",
      "Eval Loss:  0.2520701587200165\n",
      "Eval Loss:  0.17868782579898834\n",
      "Eval Loss:  0.14821964502334595\n",
      "Eval Loss:  0.24545003473758698\n",
      "Eval Loss:  0.23794950544834137\n",
      "Eval Loss:  0.15699268877506256\n",
      "Eval Loss:  0.17787384986877441\n",
      "Eval Loss:  0.2189074158668518\n",
      "Eval Loss:  0.22249779105186462\n",
      "Eval Loss:  0.27213549613952637\n",
      "Eval Loss:  0.19156096875667572\n",
      "Eval Loss:  0.20730683207511902\n",
      "Eval Loss:  0.22375145554542542\n",
      "Eval Loss:  0.27751192450523376\n",
      "Eval Loss:  0.19698014855384827\n",
      "Eval Loss:  0.23478975892066956\n",
      "Eval Loss:  0.24296703934669495\n",
      "Eval Loss:  0.15269654989242554\n",
      "Eval Loss:  0.2115267515182495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19366797804832458\n",
      "Eval Loss:  0.22941343486309052\n",
      "Eval Loss:  0.2508118450641632\n",
      "Eval Loss:  0.19303347170352936\n",
      "Eval Loss:  0.1856437772512436\n",
      "Eval Loss:  0.24044208228588104\n",
      "[[17146  1276]\n",
      " [ 1271  9790]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18422\n",
      "           1       0.88      0.89      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.91      0.91     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9136112335922396\n",
      "pre:  0.8846918489065606\n",
      "rec:  0.885091763854986\n",
      "ma F1:  0.9078765383252294\n",
      "mi F1:  0.9136112335922396\n",
      "we F1:  0.9136151315634652\n",
      "29483 461\n",
      "Loss:  0.0888543576002121\n",
      "Loss:  0.031193504109978676\n",
      "Loss:  0.04660283401608467\n",
      "30 **********\n",
      "Epoch:  2406.3259727954865  fold:  9  kers:  128\n",
      "epoch:  31\n",
      "29483 461\n",
      "Loss:  0.05236601456999779\n",
      "Loss:  0.052044641226530075\n",
      "Loss:  0.044394075870513916\n",
      "31 **********\n",
      "Epoch:  2470.3088958263397  fold:  9  kers:  128\n",
      "epoch:  32\n",
      "29483 461\n",
      "Loss:  0.056781455874443054\n",
      "Loss:  0.05646897107362747\n",
      "Loss:  0.060163941234350204\n",
      "32 **********\n",
      "Epoch:  2534.299796819687  fold:  9  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.03882135823369026\n",
      "Eval Loss:  1.0426359176635742\n",
      "Eval Loss:  0.08813635259866714\n",
      "[[1595  147]\n",
      " [ 330 1336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      1742\n",
      "           1       0.90      0.80      0.85      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.86      0.86      0.86      3408\n",
      "weighted avg       0.86      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8600352112676056\n",
      "pre:  0.9008766014834795\n",
      "rec:  0.801920768307323\n",
      "ma F1:  0.8592221285117156\n",
      "mi F1:  0.8600352112676056\n",
      "we F1:  0.8594607165018611\n",
      "Eval Loss:  0.15733571350574493\n",
      "Eval Loss:  0.2434692531824112\n",
      "Eval Loss:  0.20889727771282196\n",
      "Eval Loss:  0.22467656433582306\n",
      "Eval Loss:  0.13792771100997925\n",
      "Eval Loss:  0.14378367364406586\n",
      "Eval Loss:  0.23184747993946075\n",
      "Eval Loss:  0.25452491641044617\n",
      "Eval Loss:  0.12639276683330536\n",
      "Eval Loss:  0.18598061800003052\n",
      "Eval Loss:  0.2180941253900528\n",
      "Eval Loss:  0.22497722506523132\n",
      "Eval Loss:  0.22852130234241486\n",
      "Eval Loss:  0.2109224647283554\n",
      "Eval Loss:  0.1934463232755661\n",
      "Eval Loss:  0.21458613872528076\n",
      "Eval Loss:  0.31222444772720337\n",
      "Eval Loss:  0.161543607711792\n",
      "Eval Loss:  0.2475123256444931\n",
      "Eval Loss:  0.23432008922100067\n",
      "Eval Loss:  0.11779148131608963\n",
      "Eval Loss:  0.22805486619472504\n",
      "Eval Loss:  0.18298380076885223\n",
      "Eval Loss:  0.22464893758296967\n",
      "Eval Loss:  0.21529464423656464\n",
      "Eval Loss:  0.20886367559432983\n",
      "Eval Loss:  0.1696384847164154\n",
      "Eval Loss:  0.2021874487400055\n",
      "[[17043  1379]\n",
      " [ 1002 10059]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18422\n",
      "           1       0.88      0.91      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.92      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9192415968524235\n",
      "pre:  0.879436964504284\n",
      "rec:  0.9094114456197451\n",
      "ma F1:  0.914440583303323\n",
      "mi F1:  0.9192415968524236\n",
      "we F1:  0.9195007580935476\n",
      "29483 461\n",
      "Loss:  0.05507531017065048\n",
      "Loss:  0.05455182492733002\n",
      "Loss:  0.04538421332836151\n",
      "33 **********\n",
      "Epoch:  2638.450320005417  fold:  9  kers:  128\n",
      "epoch:  34\n",
      "29483 461\n",
      "Loss:  0.03326898068189621\n",
      "Loss:  0.05359446629881859\n",
      "Loss:  0.030084121972322464\n",
      "34 **********\n",
      "Epoch:  2702.4232692718506  fold:  9  kers:  128\n",
      "epoch:  35\n",
      "29483 461\n",
      "Loss:  0.05417758971452713\n",
      "Loss:  0.07982226461172104\n",
      "Loss:  0.06248309463262558\n",
      "35 **********\n",
      "Epoch:  2766.4111783504486  fold:  9  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.03948730602860451\n",
      "Eval Loss:  0.8163031339645386\n",
      "Eval Loss:  0.09595999121665955\n",
      "[[1586  156]\n",
      " [ 294 1372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.88      1742\n",
      "           1       0.90      0.82      0.86      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.87      0.87      0.87      3408\n",
      "weighted avg       0.87      0.87      0.87      3408\n",
      "\n",
      "acc:  0.8679577464788732\n",
      "pre:  0.8979057591623036\n",
      "rec:  0.8235294117647058\n",
      "ma F1:  0.8674350409226023\n",
      "mi F1:  0.8679577464788734\n",
      "we F1:  0.8676206746715583\n",
      "Eval Loss:  0.15407967567443848\n",
      "Eval Loss:  0.2474908083677292\n",
      "Eval Loss:  0.18217037618160248\n",
      "Eval Loss:  0.22617241740226746\n",
      "Eval Loss:  0.1453898549079895\n",
      "Eval Loss:  0.12777379155158997\n",
      "Eval Loss:  0.2285657823085785\n",
      "Eval Loss:  0.25307372212409973\n",
      "Eval Loss:  0.15302890539169312\n",
      "Eval Loss:  0.1705988049507141\n",
      "Eval Loss:  0.22124476730823517\n",
      "Eval Loss:  0.19761818647384644\n",
      "Eval Loss:  0.23599013686180115\n",
      "Eval Loss:  0.23210559785366058\n",
      "Eval Loss:  0.20948408544063568\n",
      "Eval Loss:  0.21700412034988403\n",
      "Eval Loss:  0.2974274456501007\n",
      "Eval Loss:  0.15559211373329163\n",
      "Eval Loss:  0.23801493644714355\n",
      "Eval Loss:  0.21526484191417694\n",
      "Eval Loss:  0.1441645473241806\n",
      "Eval Loss:  0.22062255442142487\n",
      "Eval Loss:  0.1816888302564621\n",
      "Eval Loss:  0.23226352035999298\n",
      "Eval Loss:  0.22957740724086761\n",
      "Eval Loss:  0.19467812776565552\n",
      "Eval Loss:  0.1567053645849228\n",
      "Eval Loss:  0.2076650857925415\n",
      "[[17074  1348]\n",
      " [  969 10092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18422\n",
      "           1       0.88      0.91      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9214123393141811\n",
      "pre:  0.8821678321678321\n",
      "rec:  0.9123949010035259\n",
      "ma F1:  0.916743208810751\n",
      "mi F1:  0.9214123393141811\n",
      "we F1:  0.9216657911132072\n",
      "29483 461\n",
      "Loss:  0.03960108757019043\n",
      "Loss:  0.0535171702504158\n",
      "Loss:  0.04420620948076248\n",
      "36 **********\n",
      "Epoch:  2870.699333190918  fold:  9  kers:  128\n",
      "epoch:  37\n",
      "29483 461\n",
      "Loss:  0.04004817456007004\n",
      "Loss:  0.023417413234710693\n",
      "Loss:  0.04064194858074188\n",
      "37 **********\n",
      "Epoch:  2934.6912322044373  fold:  9  kers:  128\n",
      "epoch:  38\n",
      "29483 461\n",
      "Loss:  0.03874901309609413\n",
      "Loss:  0.063557468354702\n",
      "Loss:  0.0575922392308712\n",
      "38 **********\n",
      "Epoch:  2998.7339944839478  fold:  9  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.03930161893367767\n",
      "Eval Loss:  0.7708929777145386\n",
      "Eval Loss:  0.11707915365695953\n",
      "[[1606  136]\n",
      " [ 290 1376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      1742\n",
      "           1       0.91      0.83      0.87      1666\n",
      "\n",
      "    accuracy                           0.88      3408\n",
      "   macro avg       0.88      0.87      0.87      3408\n",
      "weighted avg       0.88      0.88      0.87      3408\n",
      "\n",
      "acc:  0.875\n",
      "pre:  0.91005291005291\n",
      "rec:  0.8259303721488596\n",
      "ma F1:  0.8744280618089386\n",
      "mi F1:  0.875\n",
      "we F1:  0.8746170500807676\n",
      "update!  Acc:  0.875\n",
      "Eval Loss:  0.15051421523094177\n",
      "Eval Loss:  0.25758054852485657\n",
      "Eval Loss:  0.190992534160614\n",
      "Eval Loss:  0.21602541208267212\n",
      "Eval Loss:  0.1314765214920044\n",
      "Eval Loss:  0.14653624594211578\n",
      "Eval Loss:  0.20447209477424622\n",
      "Eval Loss:  0.2475685328245163\n",
      "Eval Loss:  0.1170690581202507\n",
      "Eval Loss:  0.162648007273674\n",
      "Eval Loss:  0.21312354505062103\n",
      "Eval Loss:  0.19991585612297058\n",
      "Eval Loss:  0.18528209626674652\n",
      "Eval Loss:  0.21454232931137085\n",
      "Eval Loss:  0.21239827573299408\n",
      "Eval Loss:  0.18897032737731934\n",
      "Eval Loss:  0.27377745509147644\n",
      "Eval Loss:  0.17568734288215637\n",
      "Eval Loss:  0.215072363615036\n",
      "Eval Loss:  0.19734197854995728\n",
      "Eval Loss:  0.1115509420633316\n",
      "Eval Loss:  0.19751639664173126\n",
      "Eval Loss:  0.15558534860610962\n",
      "Eval Loss:  0.22621865570545197\n",
      "Eval Loss:  0.2310827672481537\n",
      "Eval Loss:  0.17433807253837585\n",
      "Eval Loss:  0.1653813272714615\n",
      "Eval Loss:  0.14622463285923004\n",
      "[[17231  1191]\n",
      " [  967 10094]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     18422\n",
      "           1       0.89      0.91      0.90     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9268052776176101\n",
      "pre:  0.8944616747895436\n",
      "rec:  0.9125757164813308\n",
      "ma F1:  0.9222491799323318\n",
      "mi F1:  0.9268052776176101\n",
      "we F1:  0.9269482740981345\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05041512846946716\n",
      "Loss:  0.0801820307970047\n",
      "Loss:  0.04211961477994919\n",
      "39 **********\n",
      "Epoch:  3103.063039779663  fold:  9  kers:  128\n",
      "epoch:  40\n",
      "29483 461\n",
      "Loss:  0.06073673069477081\n",
      "Loss:  0.04753459617495537\n",
      "Loss:  0.03950561210513115\n",
      "40 **********\n",
      "Epoch:  3167.050949573517  fold:  9  kers:  128\n",
      "epoch:  41\n",
      "29483 461\n",
      "Loss:  0.06670042127370834\n",
      "Loss:  0.06951852142810822\n",
      "Loss:  0.06618986278772354\n",
      "41 **********\n",
      "Epoch:  3231.0398557186127  fold:  9  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.03906554356217384\n",
      "Eval Loss:  0.7135860919952393\n",
      "Eval Loss:  0.10708518326282501\n",
      "[[1624  118]\n",
      " [ 291 1375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      1742\n",
      "           1       0.92      0.83      0.87      1666\n",
      "\n",
      "    accuracy                           0.88      3408\n",
      "   macro avg       0.88      0.88      0.88      3408\n",
      "weighted avg       0.88      0.88      0.88      3408\n",
      "\n",
      "acc:  0.8799882629107981\n",
      "pre:  0.9209645010046885\n",
      "rec:  0.8253301320528211\n",
      "ma F1:  0.8793441710222314\n",
      "mi F1:  0.8799882629107981\n",
      "we F1:  0.8795407613175369\n",
      "update!  Acc:  0.8799882629107981\n",
      "Eval Loss:  0.1519007682800293\n",
      "Eval Loss:  0.2171076387166977\n",
      "Eval Loss:  0.16766998171806335\n",
      "Eval Loss:  0.20387069880962372\n",
      "Eval Loss:  0.13626885414123535\n",
      "Eval Loss:  0.1450730264186859\n",
      "Eval Loss:  0.19366219639778137\n",
      "Eval Loss:  0.2551010549068451\n",
      "Eval Loss:  0.11625906825065613\n",
      "Eval Loss:  0.14836423099040985\n",
      "Eval Loss:  0.21256369352340698\n",
      "Eval Loss:  0.20147041976451874\n",
      "Eval Loss:  0.1824335753917694\n",
      "Eval Loss:  0.1780397593975067\n",
      "Eval Loss:  0.19063620269298553\n",
      "Eval Loss:  0.19096733629703522\n",
      "Eval Loss:  0.26279544830322266\n",
      "Eval Loss:  0.14209038019180298\n",
      "Eval Loss:  0.2098846435546875\n",
      "Eval Loss:  0.19522884488105774\n",
      "Eval Loss:  0.11463797837495804\n",
      "Eval Loss:  0.17906413972377777\n",
      "Eval Loss:  0.1465408205986023\n",
      "Eval Loss:  0.2003929316997528\n",
      "Eval Loss:  0.20010322332382202\n",
      "Eval Loss:  0.16404742002487183\n",
      "Eval Loss:  0.1389157921075821\n",
      "Eval Loss:  0.16521506011486053\n",
      "[[17335  1087]\n",
      " [  989 10072]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     18422\n",
      "           1       0.90      0.91      0.91     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.92      0.93      0.93     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9295865413967371\n",
      "pre:  0.902589837799086\n",
      "rec:  0.9105867462254769\n",
      "ma F1:  0.9250373559644105\n",
      "mi F1:  0.9295865413967371\n",
      "we F1:  0.9296479237693611\n",
      "29483 461\n",
      "Loss:  0.025448113679885864\n",
      "Loss:  0.04062753543257713\n",
      "Loss:  0.04354079067707062\n",
      "42 **********\n",
      "Epoch:  3335.2791409492493  fold:  9  kers:  128\n",
      "epoch:  43\n",
      "29483 461\n",
      "Loss:  0.07398322969675064\n",
      "Loss:  0.07089493423700333\n",
      "Loss:  0.04743896424770355\n",
      "43 **********\n",
      "Epoch:  3399.2830078601837  fold:  9  kers:  128\n",
      "epoch:  44\n",
      "29483 461\n",
      "Loss:  0.0475008599460125\n",
      "Loss:  0.03888201713562012\n",
      "Loss:  0.05074642226099968\n",
      "44 **********\n",
      "Epoch:  3463.283882856369  fold:  9  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.03476812690496445\n",
      "Eval Loss:  1.5339229106903076\n",
      "Eval Loss:  0.11667174845933914\n",
      "[[1649   93]\n",
      " [ 495 1171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85      1742\n",
      "           1       0.93      0.70      0.80      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.82      0.82      3408\n",
      "weighted avg       0.85      0.83      0.82      3408\n",
      "\n",
      "acc:  0.8274647887323944\n",
      "pre:  0.9264240506329114\n",
      "rec:  0.7028811524609844\n",
      "ma F1:  0.8240025013218011\n",
      "mi F1:  0.8274647887323944\n",
      "we F1:  0.8245529905335272\n",
      "Eval Loss:  0.15320280194282532\n",
      "Eval Loss:  0.2574853003025055\n",
      "Eval Loss:  0.18688403069972992\n",
      "Eval Loss:  0.19610033929347992\n",
      "Eval Loss:  0.15507149696350098\n",
      "Eval Loss:  0.12973156571388245\n",
      "Eval Loss:  0.2259025126695633\n",
      "Eval Loss:  0.25989213585853577\n",
      "Eval Loss:  0.14889803528785706\n",
      "Eval Loss:  0.15867023169994354\n",
      "Eval Loss:  0.21066176891326904\n",
      "Eval Loss:  0.20987944304943085\n",
      "Eval Loss:  0.21006567776203156\n",
      "Eval Loss:  0.20710332691669464\n",
      "Eval Loss:  0.19724571704864502\n",
      "Eval Loss:  0.19765351712703705\n",
      "Eval Loss:  0.27624866366386414\n",
      "Eval Loss:  0.12396221607923508\n",
      "Eval Loss:  0.2267618328332901\n",
      "Eval Loss:  0.22652700543403625\n",
      "Eval Loss:  0.12551139295101166\n",
      "Eval Loss:  0.18764403462409973\n",
      "Eval Loss:  0.19253729283809662\n",
      "Eval Loss:  0.19420063495635986\n",
      "Eval Loss:  0.22069256007671356\n",
      "Eval Loss:  0.15526604652404785\n",
      "Eval Loss:  0.1577453762292862\n",
      "Eval Loss:  0.19540268182754517\n",
      "[[17404  1018]\n",
      " [ 1254  9807]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18422\n",
      "           1       0.91      0.89      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9229386426076044\n",
      "pre:  0.9059584295612009\n",
      "rec:  0.8866286954163276\n",
      "ma F1:  0.9174582106888879\n",
      "mi F1:  0.9229386426076044\n",
      "we F1:  0.9227683935707718\n",
      "29483 461\n",
      "Loss:  0.06761860102415085\n",
      "Loss:  0.045094121247529984\n",
      "Loss:  0.08762142807245255\n",
      "45 **********\n",
      "Epoch:  3570.689701318741  fold:  9  kers:  128\n",
      "epoch:  46\n",
      "29483 461\n",
      "Loss:  0.04108551889657974\n",
      "Loss:  0.055942874401807785\n",
      "Loss:  0.07053517550230026\n",
      "46 **********\n",
      "Epoch:  3634.6466929912567  fold:  9  kers:  128\n",
      "epoch:  47\n",
      "29483 461\n",
      "Loss:  0.06185724958777428\n",
      "Loss:  0.0482478141784668\n",
      "Loss:  0.03152696043252945\n",
      "47 **********\n",
      "Epoch:  3698.641583442688  fold:  9  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.03276930749416351\n",
      "Eval Loss:  1.4298568964004517\n",
      "Eval Loss:  0.06619041413068771\n",
      "[[1608  134]\n",
      " [ 390 1276]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86      1742\n",
      "           1       0.90      0.77      0.83      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.85      0.85      3408\n",
      "\n",
      "acc:  0.846244131455399\n",
      "pre:  0.9049645390070922\n",
      "rec:  0.765906362545018\n",
      "ma F1:  0.8447709713983713\n",
      "mi F1:  0.846244131455399\n",
      "we F1:  0.8451082008090163\n",
      "Eval Loss:  0.15637511014938354\n",
      "Eval Loss:  0.29083725810050964\n",
      "Eval Loss:  0.20290429890155792\n",
      "Eval Loss:  0.19823744893074036\n",
      "Eval Loss:  0.15374493598937988\n",
      "Eval Loss:  0.11995387077331543\n",
      "Eval Loss:  0.23517999053001404\n",
      "Eval Loss:  0.3010097146034241\n",
      "Eval Loss:  0.11343162506818771\n",
      "Eval Loss:  0.16657543182373047\n",
      "Eval Loss:  0.21281708776950836\n",
      "Eval Loss:  0.20869480073451996\n",
      "Eval Loss:  0.25350630283355713\n",
      "Eval Loss:  0.2441283017396927\n",
      "Eval Loss:  0.2061006724834442\n",
      "Eval Loss:  0.24844475090503693\n",
      "Eval Loss:  0.31630638241767883\n",
      "Eval Loss:  0.15297730267047882\n",
      "Eval Loss:  0.23301732540130615\n",
      "Eval Loss:  0.23497508466243744\n",
      "Eval Loss:  0.12496449798345566\n",
      "Eval Loss:  0.25585490465164185\n",
      "Eval Loss:  0.17244304716587067\n",
      "Eval Loss:  0.24413548409938812\n",
      "Eval Loss:  0.2194977104663849\n",
      "Eval Loss:  0.19671578705310822\n",
      "Eval Loss:  0.1684936285018921\n",
      "Eval Loss:  0.1861918568611145\n",
      "[[16849  1573]\n",
      " [  887 10174]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93     18422\n",
      "           1       0.87      0.92      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.92      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9165620866261913\n",
      "pre:  0.8660934706733634\n",
      "rec:  0.9198083355935268\n",
      "ma F1:  0.9120541856234889\n",
      "mi F1:  0.9165620866261913\n",
      "we F1:  0.9170253705344841\n",
      "29483 461\n",
      "Loss:  0.05854696407914162\n",
      "Loss:  0.014974212273955345\n",
      "Loss:  0.045346349477767944\n",
      "48 **********\n",
      "Epoch:  3803.2079944610596  fold:  9  kers:  128\n",
      "epoch:  49\n",
      "29483 461\n",
      "Loss:  0.051625967025756836\n",
      "Loss:  0.04013889282941818\n",
      "Loss:  0.061093464493751526\n",
      "49 **********\n",
      "Epoch:  3867.1739625930786  fold:  9  kers:  128\n",
      "epoch:  50\n",
      "29483 461\n",
      "Loss:  0.05166403204202652\n",
      "Loss:  0.040279075503349304\n",
      "Loss:  0.0969303771853447\n",
      "50 **********\n",
      "Epoch:  3931.6056849956512  fold:  9  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.04810452461242676\n",
      "Eval Loss:  1.2533384561538696\n",
      "Eval Loss:  0.08472985774278641\n",
      "[[1613  129]\n",
      " [ 370 1296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87      1742\n",
      "           1       0.91      0.78      0.84      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.86      0.85      0.85      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8535798122065728\n",
      "pre:  0.9094736842105263\n",
      "rec:  0.7779111644657863\n",
      "ma F1:  0.8523019200580164\n",
      "mi F1:  0.8535798122065728\n",
      "we F1:  0.8526082916772287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.15407831966876984\n",
      "Eval Loss:  0.23598304390907288\n",
      "Eval Loss:  0.18327076733112335\n",
      "Eval Loss:  0.20498619973659515\n",
      "Eval Loss:  0.1298028528690338\n",
      "Eval Loss:  0.1210581585764885\n",
      "Eval Loss:  0.20474117994308472\n",
      "Eval Loss:  0.262959361076355\n",
      "Eval Loss:  0.13604991137981415\n",
      "Eval Loss:  0.16523367166519165\n",
      "Eval Loss:  0.2014676183462143\n",
      "Eval Loss:  0.19637148082256317\n",
      "Eval Loss:  0.16848301887512207\n",
      "Eval Loss:  0.1890798807144165\n",
      "Eval Loss:  0.18448542058467865\n",
      "Eval Loss:  0.22371050715446472\n",
      "Eval Loss:  0.2542661428451538\n",
      "Eval Loss:  0.11250535398721695\n",
      "Eval Loss:  0.19609162211418152\n",
      "Eval Loss:  0.20616517961025238\n",
      "Eval Loss:  0.1109379455447197\n",
      "Eval Loss:  0.1850864738225937\n",
      "Eval Loss:  0.15826798975467682\n",
      "Eval Loss:  0.1815098524093628\n",
      "Eval Loss:  0.1999617964029312\n",
      "Eval Loss:  0.16141894459724426\n",
      "Eval Loss:  0.13801196217536926\n",
      "Eval Loss:  0.1755063682794571\n",
      "[[17279  1143]\n",
      " [  940 10121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     18422\n",
      "           1       0.90      0.92      0.91     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.92      0.93      0.92     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9293491164399824\n",
      "pre:  0.8985262784090909\n",
      "rec:  0.915016725431697\n",
      "ma F1:  0.9249238217133751\n",
      "mi F1:  0.9293491164399824\n",
      "we F1:  0.9294746172543861\n",
      "29483 461\n",
      "Loss:  0.08121775835752487\n",
      "Loss:  0.06225140392780304\n",
      "Loss:  0.06398899108171463\n",
      "51 **********\n",
      "Epoch:  4036.1710987091064  fold:  9  kers:  128\n",
      "epoch:  52\n",
      "29483 461\n",
      "Loss:  0.05395463854074478\n",
      "Loss:  0.042337775230407715\n",
      "Loss:  0.04972512647509575\n",
      "52 **********\n",
      "Epoch:  4100.126096010208  fold:  9  kers:  128\n",
      "epoch:  53\n",
      "29483 461\n",
      "Loss:  0.031136471778154373\n",
      "Loss:  0.020331602543592453\n",
      "Loss:  0.037600528448820114\n",
      "53 **********\n",
      "Epoch:  4164.138938426971  fold:  9  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.04265085235238075\n",
      "Eval Loss:  1.0531306266784668\n",
      "Eval Loss:  0.09884820878505707\n",
      "[[1615  127]\n",
      " [ 378 1288]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86      1742\n",
      "           1       0.91      0.77      0.84      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.86      0.85      0.85      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8518192488262911\n",
      "pre:  0.9102473498233216\n",
      "rec:  0.773109243697479\n",
      "ma F1:  0.850442340605525\n",
      "mi F1:  0.8518192488262911\n",
      "we F1:  0.8507623559718193\n",
      "Eval Loss:  0.13375934958457947\n",
      "Eval Loss:  0.21500448882579803\n",
      "Eval Loss:  0.16986356675624847\n",
      "Eval Loss:  0.17171825468540192\n",
      "Eval Loss:  0.11298874765634537\n",
      "Eval Loss:  0.1156710684299469\n",
      "Eval Loss:  0.17532669007778168\n",
      "Eval Loss:  0.23406335711479187\n",
      "Eval Loss:  0.10494232922792435\n",
      "Eval Loss:  0.13077737390995026\n",
      "Eval Loss:  0.1785248965024948\n",
      "Eval Loss:  0.15556833148002625\n",
      "Eval Loss:  0.16930150985717773\n",
      "Eval Loss:  0.17758667469024658\n",
      "Eval Loss:  0.18211784958839417\n",
      "Eval Loss:  0.18459632992744446\n",
      "Eval Loss:  0.22673262655735016\n",
      "Eval Loss:  0.1349175125360489\n",
      "Eval Loss:  0.1972300410270691\n",
      "Eval Loss:  0.1800725758075714\n",
      "Eval Loss:  0.11494947224855423\n",
      "Eval Loss:  0.18504434823989868\n",
      "Eval Loss:  0.1444961577653885\n",
      "Eval Loss:  0.1929892897605896\n",
      "Eval Loss:  0.20997954905033112\n",
      "Eval Loss:  0.1679815649986267\n",
      "Eval Loss:  0.12372425943613052\n",
      "Eval Loss:  0.18687182664871216\n",
      "[[17385  1037]\n",
      " [  883 10178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     18422\n",
      "           1       0.91      0.92      0.91     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.93      0.93      0.93     29483\n",
      "weighted avg       0.94      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9348777261472713\n",
      "pre:  0.9075345519393669\n",
      "rec:  0.9201699665491366\n",
      "ma F1:  0.9307391239936884\n",
      "mi F1:  0.9348777261472713\n",
      "we F1:  0.9349661602712692\n",
      "29483 461\n",
      "Loss:  0.06049089878797531\n",
      "Loss:  0.05672707036137581\n",
      "Loss:  0.07984528690576553\n",
      "54 **********\n",
      "Epoch:  4268.4929168224335  fold:  9  kers:  128\n",
      "epoch:  55\n",
      "29483 461\n",
      "Loss:  0.035078294575214386\n",
      "Loss:  0.030652018263936043\n",
      "Loss:  0.05196428298950195\n",
      "55 **********\n",
      "Epoch:  4332.45888543129  fold:  9  kers:  128\n",
      "epoch:  56\n",
      "29483 461\n",
      "Loss:  0.06462746113538742\n",
      "Loss:  0.04991975799202919\n",
      "Loss:  0.027706194669008255\n",
      "56 **********\n",
      "Epoch:  4396.451781272888  fold:  9  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.040753304958343506\n",
      "Eval Loss:  0.837020754814148\n",
      "Eval Loss:  0.10371679812669754\n",
      "[[1610  132]\n",
      " [ 314 1352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88      1742\n",
      "           1       0.91      0.81      0.86      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.87      0.87      0.87      3408\n",
      "weighted avg       0.87      0.87      0.87      3408\n",
      "\n",
      "acc:  0.869131455399061\n",
      "pre:  0.9110512129380054\n",
      "rec:  0.8115246098439376\n",
      "ma F1:  0.8683771075260438\n",
      "mi F1:  0.869131455399061\n",
      "we F1:  0.8685993185273977\n",
      "Eval Loss:  0.1369619071483612\n",
      "Eval Loss:  0.19501429796218872\n",
      "Eval Loss:  0.171603724360466\n",
      "Eval Loss:  0.1869225949048996\n",
      "Eval Loss:  0.11784990131855011\n",
      "Eval Loss:  0.11944380402565002\n",
      "Eval Loss:  0.18347859382629395\n",
      "Eval Loss:  0.22180604934692383\n",
      "Eval Loss:  0.09785193204879761\n",
      "Eval Loss:  0.1346668154001236\n",
      "Eval Loss:  0.20180371403694153\n",
      "Eval Loss:  0.18122680485248566\n",
      "Eval Loss:  0.1526118367910385\n",
      "Eval Loss:  0.16235387325286865\n",
      "Eval Loss:  0.18774369359016418\n",
      "Eval Loss:  0.17919673025608063\n",
      "Eval Loss:  0.2320547252893448\n",
      "Eval Loss:  0.14988218247890472\n",
      "Eval Loss:  0.18072707951068878\n",
      "Eval Loss:  0.17881497740745544\n",
      "Eval Loss:  0.10617391765117645\n",
      "Eval Loss:  0.15757349133491516\n",
      "Eval Loss:  0.16563744843006134\n",
      "Eval Loss:  0.18904276192188263\n",
      "Eval Loss:  0.2139224410057068\n",
      "Eval Loss:  0.16822202503681183\n",
      "Eval Loss:  0.1366560310125351\n",
      "Eval Loss:  0.15611255168914795\n",
      "[[17402  1020]\n",
      " [  925 10136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     18422\n",
      "           1       0.91      0.92      0.91     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.93      0.93      0.93     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9340297798731473\n",
      "pre:  0.9085693797059878\n",
      "rec:  0.9163728415152337\n",
      "ma F1:  0.9297639082711989\n",
      "mi F1:  0.9340297798731473\n",
      "we F1:  0.9340855544123964\n",
      "29483 461\n",
      "Loss:  0.06061666086316109\n",
      "Loss:  0.04689641296863556\n",
      "Loss:  0.04136049002408981\n",
      "57 **********\n",
      "Epoch:  4500.729962587357  fold:  9  kers:  128\n",
      "epoch:  58\n",
      "29483 461\n",
      "Loss:  0.05634523183107376\n",
      "Loss:  0.04938707873225212\n",
      "Loss:  0.049376875162124634\n",
      "58 **********\n",
      "Epoch:  4564.706901073456  fold:  9  kers:  128\n",
      "epoch:  59\n",
      "29483 461\n",
      "Loss:  0.04809258505702019\n",
      "Loss:  0.053988125175237656\n",
      "Loss:  0.02605370059609413\n",
      "59 **********\n",
      "Epoch:  4628.697803258896  fold:  9  kers:  128\n",
      "Eval Loss:  0.040314920246601105\n",
      "Eval Loss:  1.4496506452560425\n",
      "Eval Loss:  0.1284235417842865\n",
      "[[1641  101]\n",
      " [ 449 1217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      1742\n",
      "           1       0.92      0.73      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8386150234741784\n",
      "pre:  0.9233687405159332\n",
      "rec:  0.7304921968787516\n",
      "ma F1:  0.8360777311982627\n",
      "mi F1:  0.8386150234741784\n",
      "we F1:  0.8365325288703608\n",
      "update!  Acc:  0.8799882629107981\n",
      "Epoch:  4632.915525436401  fold:  9  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29871 3020\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29871 467\n",
      "Loss:  0.16151387989521027\n",
      "Loss:  0.16307708621025085\n",
      "Loss:  0.1584235429763794\n",
      "0 **********\n",
      "Epoch:  77.13276171684265  fold:  10  kers:  128\n",
      "epoch:  1\n",
      "29871 467\n",
      "Loss:  0.13205166161060333\n",
      "Loss:  0.14194457232952118\n",
      "Loss:  0.10992828756570816\n",
      "1 **********\n",
      "Epoch:  141.88861751556396  fold:  10  kers:  128\n",
      "epoch:  2\n",
      "29871 467\n",
      "Loss:  0.09968262165784836\n",
      "Loss:  0.09995222091674805\n",
      "Loss:  0.09817878156900406\n",
      "2 **********\n",
      "Epoch:  206.69134879112244  fold:  10  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.6240761876106262\n",
      "Eval Loss:  0.18118326365947723\n",
      "Eval Loss:  0.11085242033004761\n",
      "[[1629  122]\n",
      " [ 248 1021]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      1751\n",
      "           1       0.89      0.80      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.88      0.87      0.87      3020\n",
      "weighted avg       0.88      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8774834437086093\n",
      "pre:  0.8932633420822397\n",
      "rec:  0.8045705279747833\n",
      "ma F1:  0.8723078835883062\n",
      "mi F1:  0.8774834437086093\n",
      "we F1:  0.8764108769731517\n",
      "update!  Acc:  0.8774834437086093\n",
      "Eval Loss:  0.43799954652786255\n",
      "Eval Loss:  0.452798992395401\n",
      "Eval Loss:  0.4177316427230835\n",
      "Eval Loss:  0.38683435320854187\n",
      "Eval Loss:  0.46029409766197205\n",
      "Eval Loss:  0.478801965713501\n",
      "Eval Loss:  0.4039386808872223\n",
      "Eval Loss:  0.47434017062187195\n",
      "Eval Loss:  0.5222057104110718\n",
      "Eval Loss:  0.4656327962875366\n",
      "Eval Loss:  0.31169527769088745\n",
      "Eval Loss:  0.44396114349365234\n",
      "Eval Loss:  0.5296205282211304\n",
      "Eval Loss:  0.48580318689346313\n",
      "Eval Loss:  0.49477770924568176\n",
      "Eval Loss:  0.5006515383720398\n",
      "Eval Loss:  0.3160300552845001\n",
      "Eval Loss:  0.46252602338790894\n",
      "Eval Loss:  0.3836285173892975\n",
      "Eval Loss:  0.47187167406082153\n",
      "Eval Loss:  0.4081900715827942\n",
      "Eval Loss:  0.29493722319602966\n",
      "Eval Loss:  0.4120076298713684\n",
      "Eval Loss:  0.4308639466762543\n",
      "Eval Loss:  0.4408520460128784\n",
      "Eval Loss:  0.45262566208839417\n",
      "Eval Loss:  0.5470690727233887\n",
      "Eval Loss:  0.3942522406578064\n",
      "Eval Loss:  0.5614655017852783\n",
      "[[17112  1301]\n",
      " [ 4189  7269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86     18413\n",
      "           1       0.85      0.63      0.73     11458\n",
      "\n",
      "    accuracy                           0.82     29871\n",
      "   macro avg       0.83      0.78      0.79     29871\n",
      "weighted avg       0.82      0.82      0.81     29871\n",
      "\n",
      "acc:  0.8162097017173847\n",
      "pre:  0.8481913652275379\n",
      "rec:  0.6344039099319253\n",
      "ma F1:  0.7938226790696682\n",
      "mi F1:  0.8162097017173847\n",
      "we F1:  0.8096412041651543\n",
      "29871 467\n",
      "Loss:  0.11254092305898666\n",
      "Loss:  0.07956577837467194\n",
      "Loss:  0.11326898634433746\n",
      "3 **********\n",
      "Epoch:  311.84419107437134  fold:  10  kers:  128\n",
      "epoch:  4\n",
      "29871 467\n",
      "Loss:  0.08312756568193436\n",
      "Loss:  0.08654527366161346\n",
      "Loss:  0.0958382859826088\n",
      "4 **********\n",
      "Epoch:  376.61799907684326  fold:  10  kers:  128\n",
      "epoch:  5\n",
      "29871 467\n",
      "Loss:  0.0704445093870163\n",
      "Loss:  0.07642177492380142\n",
      "Loss:  0.11603862047195435\n",
      "5 **********\n",
      "Epoch:  441.40477299690247  fold:  10  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.8521727323532104\n",
      "Eval Loss:  0.10242822021245956\n",
      "Eval Loss:  0.07329672574996948\n",
      "[[1691   60]\n",
      " [ 349  920]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89      1751\n",
      "           1       0.94      0.72      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.88      0.85      0.86      3020\n",
      "weighted avg       0.88      0.86      0.86      3020\n",
      "\n",
      "acc:  0.864569536423841\n",
      "pre:  0.9387755102040817\n",
      "rec:  0.7249802994483846\n",
      "ma F1:  0.855127147573663\n",
      "mi F1:  0.8645695364238412\n",
      "we F1:  0.861030171472218\n",
      "Eval Loss:  0.46005958318710327\n",
      "Eval Loss:  0.4937765300273895\n",
      "Eval Loss:  0.4631567895412445\n",
      "Eval Loss:  0.4041072130203247\n",
      "Eval Loss:  0.541084885597229\n",
      "Eval Loss:  0.5045329332351685\n",
      "Eval Loss:  0.35741081833839417\n",
      "Eval Loss:  0.4431639313697815\n",
      "Eval Loss:  0.5558997988700867\n",
      "Eval Loss:  0.5138422846794128\n",
      "Eval Loss:  0.313426673412323\n",
      "Eval Loss:  0.42021551728248596\n",
      "Eval Loss:  0.6038532257080078\n",
      "Eval Loss:  0.5046061277389526\n",
      "Eval Loss:  0.45612436532974243\n",
      "Eval Loss:  0.5361454486846924\n",
      "Eval Loss:  0.3106544017791748\n",
      "Eval Loss:  0.43816447257995605\n",
      "Eval Loss:  0.428435742855072\n",
      "Eval Loss:  0.5477729439735413\n",
      "Eval Loss:  0.46001285314559937\n",
      "Eval Loss:  0.33857661485671997\n",
      "Eval Loss:  0.3971303105354309\n",
      "Eval Loss:  0.45749571919441223\n",
      "Eval Loss:  0.4707523286342621\n",
      "Eval Loss:  0.4543236792087555\n",
      "Eval Loss:  0.5978726148605347\n",
      "Eval Loss:  0.4517779052257538\n",
      "Eval Loss:  0.6439619064331055\n",
      "[[17927   486]\n",
      " [ 5084  6374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.87     18413\n",
      "           1       0.93      0.56      0.70     11458\n",
      "\n",
      "    accuracy                           0.81     29871\n",
      "   macro avg       0.85      0.76      0.78     29871\n",
      "weighted avg       0.84      0.81      0.80     29871\n",
      "\n",
      "acc:  0.8135315188644505\n",
      "pre:  0.9291545189504373\n",
      "rec:  0.5562925466922675\n",
      "ma F1:  0.7807321949157013\n",
      "mi F1:  0.8135315188644505\n",
      "we F1:  0.8004776548017526\n",
      "29871 467\n",
      "Loss:  0.07733763754367828\n",
      "Loss:  0.09084046632051468\n",
      "Loss:  0.07403313368558884\n",
      "6 **********\n",
      "Epoch:  546.3382017612457  fold:  10  kers:  128\n",
      "epoch:  7\n",
      "29871 467\n",
      "Loss:  0.07308190315961838\n",
      "Loss:  0.07717569917440414\n",
      "Loss:  0.07871825993061066\n",
      "7 **********\n",
      "Epoch:  611.1529004573822  fold:  10  kers:  128\n",
      "epoch:  8\n",
      "29871 467\n",
      "Loss:  0.09079310297966003\n",
      "Loss:  0.07945586740970612\n",
      "Loss:  0.11115524917840958\n",
      "8 **********\n",
      "Epoch:  675.9576268196106  fold:  10  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.4282582998275757\n",
      "Eval Loss:  0.12449141591787338\n",
      "Eval Loss:  0.0924932211637497\n",
      "[[1669   82]\n",
      " [ 200 1069]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1751\n",
      "           1       0.93      0.84      0.88      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9066225165562913\n",
      "pre:  0.9287576020851434\n",
      "rec:  0.8423955870764381\n",
      "ma F1:  0.9027852609469886\n",
      "mi F1:  0.9066225165562913\n",
      "we F1:  0.9058678562864618\n",
      "update!  Acc:  0.9066225165562913\n",
      "Eval Loss:  0.33561986684799194\n",
      "Eval Loss:  0.35209396481513977\n",
      "Eval Loss:  0.30404049158096313\n",
      "Eval Loss:  0.32116931676864624\n",
      "Eval Loss:  0.38208654522895813\n",
      "Eval Loss:  0.3413581848144531\n",
      "Eval Loss:  0.2882513105869293\n",
      "Eval Loss:  0.35227060317993164\n",
      "Eval Loss:  0.3460935950279236\n",
      "Eval Loss:  0.34210407733917236\n",
      "Eval Loss:  0.22945399582386017\n",
      "Eval Loss:  0.38293299078941345\n",
      "Eval Loss:  0.43838053941726685\n",
      "Eval Loss:  0.3653883635997772\n",
      "Eval Loss:  0.3181694746017456\n",
      "Eval Loss:  0.3262246251106262\n",
      "Eval Loss:  0.2269262671470642\n",
      "Eval Loss:  0.3350502550601959\n",
      "Eval Loss:  0.28647348284721375\n",
      "Eval Loss:  0.3745594024658203\n",
      "Eval Loss:  0.2937212884426117\n",
      "Eval Loss:  0.2516016364097595\n",
      "Eval Loss:  0.3059726357460022\n",
      "Eval Loss:  0.3211803734302521\n",
      "Eval Loss:  0.32735660672187805\n",
      "Eval Loss:  0.36890268325805664\n",
      "Eval Loss:  0.37590062618255615\n",
      "Eval Loss:  0.32166892290115356\n",
      "Eval Loss:  0.42821308970451355\n",
      "[[17469   944]\n",
      " [ 3178  8280]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.89     18413\n",
      "           1       0.90      0.72      0.80     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.87      0.84      0.85     29871\n",
      "weighted avg       0.87      0.86      0.86     29871\n",
      "\n",
      "acc:  0.862006628502561\n",
      "pre:  0.8976582827406765\n",
      "rec:  0.7226392040495724\n",
      "ma F1:  0.8475831518491335\n",
      "mi F1:  0.862006628502561\n",
      "we F1:  0.8585000394456714\n",
      "29871 467\n",
      "Loss:  0.10656298696994781\n",
      "Loss:  0.08556962013244629\n",
      "Loss:  0.07635877281427383\n",
      "9 **********\n",
      "Epoch:  781.2570765018463  fold:  10  kers:  128\n",
      "epoch:  10\n",
      "29871 467\n",
      "Loss:  0.04564109817147255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.03629384562373161\n",
      "Loss:  0.0717613622546196\n",
      "10 **********\n",
      "Epoch:  846.0358710289001  fold:  10  kers:  128\n",
      "epoch:  11\n",
      "29871 467\n",
      "Loss:  0.07414643466472626\n",
      "Loss:  0.09127958118915558\n",
      "Loss:  0.07721976190805435\n",
      "11 **********\n",
      "Epoch:  910.8176579475403  fold:  10  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.370883584022522\n",
      "Eval Loss:  0.13861367106437683\n",
      "Eval Loss:  0.09445025771856308\n",
      "[[1658   93]\n",
      " [ 184 1085]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1751\n",
      "           1       0.92      0.86      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9082781456953642\n",
      "pre:  0.9210526315789473\n",
      "rec:  0.8550039401103231\n",
      "ma F1:  0.9048529066701121\n",
      "mi F1:  0.9082781456953642\n",
      "we F1:  0.9077341723074098\n",
      "update!  Acc:  0.9082781456953642\n",
      "Eval Loss:  0.2665427327156067\n",
      "Eval Loss:  0.307134747505188\n",
      "Eval Loss:  0.2571408152580261\n",
      "Eval Loss:  0.30332356691360474\n",
      "Eval Loss:  0.3106619417667389\n",
      "Eval Loss:  0.31119367480278015\n",
      "Eval Loss:  0.2676478624343872\n",
      "Eval Loss:  0.3114127814769745\n",
      "Eval Loss:  0.27414360642433167\n",
      "Eval Loss:  0.29828518629074097\n",
      "Eval Loss:  0.20790474116802216\n",
      "Eval Loss:  0.3315291702747345\n",
      "Eval Loss:  0.3631630837917328\n",
      "Eval Loss:  0.34459030628204346\n",
      "Eval Loss:  0.2684568464756012\n",
      "Eval Loss:  0.3012729585170746\n",
      "Eval Loss:  0.2191038578748703\n",
      "Eval Loss:  0.30240994691848755\n",
      "Eval Loss:  0.2597123086452484\n",
      "Eval Loss:  0.3344916105270386\n",
      "Eval Loss:  0.2775668799877167\n",
      "Eval Loss:  0.20090925693511963\n",
      "Eval Loss:  0.26372650265693665\n",
      "Eval Loss:  0.2947504222393036\n",
      "Eval Loss:  0.2760991156101227\n",
      "Eval Loss:  0.25807252526283264\n",
      "Eval Loss:  0.33834779262542725\n",
      "Eval Loss:  0.29316529631614685\n",
      "Eval Loss:  0.38231033086776733\n",
      "[[17393  1020]\n",
      " [ 2622  8836]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91     18413\n",
      "           1       0.90      0.77      0.83     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.88      0.86      0.87     29871\n",
      "weighted avg       0.88      0.88      0.88     29871\n",
      "\n",
      "acc:  0.8780757256201667\n",
      "pre:  0.8965097402597403\n",
      "rec:  0.7711642520509687\n",
      "ma F1:  0.8671758761535339\n",
      "mi F1:  0.8780757256201667\n",
      "we F1:  0.8760351087163983\n",
      "29871 467\n",
      "Loss:  0.08113791048526764\n",
      "Loss:  0.10579119622707367\n",
      "Loss:  0.059648171067237854\n",
      "12 **********\n",
      "Epoch:  1015.8478281497955  fold:  10  kers:  128\n",
      "epoch:  13\n",
      "29871 467\n",
      "Loss:  0.04347434639930725\n",
      "Loss:  0.07437501847743988\n",
      "Loss:  0.0996028333902359\n",
      "13 **********\n",
      "Epoch:  1080.6375939846039  fold:  10  kers:  128\n",
      "epoch:  14\n",
      "29871 467\n",
      "Loss:  0.052641816437244415\n",
      "Loss:  0.06743095070123672\n",
      "Loss:  0.07741080969572067\n",
      "14 **********\n",
      "Epoch:  1145.434341430664  fold:  10  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.36922895908355713\n",
      "Eval Loss:  0.10146567970514297\n",
      "Eval Loss:  0.07936723530292511\n",
      "[[1668   83]\n",
      " [ 189 1080]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1751\n",
      "           1       0.93      0.85      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.909933774834437\n",
      "pre:  0.9286328460877042\n",
      "rec:  0.851063829787234\n",
      "ma F1:  0.9063849340646517\n",
      "mi F1:  0.909933774834437\n",
      "we F1:  0.9092940178249179\n",
      "update!  Acc:  0.909933774834437\n",
      "Eval Loss:  0.2527869939804077\n",
      "Eval Loss:  0.3049073815345764\n",
      "Eval Loss:  0.2606126070022583\n",
      "Eval Loss:  0.2773382365703583\n",
      "Eval Loss:  0.320907860994339\n",
      "Eval Loss:  0.2935043275356293\n",
      "Eval Loss:  0.2714522182941437\n",
      "Eval Loss:  0.2825133204460144\n",
      "Eval Loss:  0.26434212923049927\n",
      "Eval Loss:  0.27634257078170776\n",
      "Eval Loss:  0.18593354523181915\n",
      "Eval Loss:  0.31936514377593994\n",
      "Eval Loss:  0.3508044481277466\n",
      "Eval Loss:  0.33943670988082886\n",
      "Eval Loss:  0.24184681475162506\n",
      "Eval Loss:  0.25605645775794983\n",
      "Eval Loss:  0.21474993228912354\n",
      "Eval Loss:  0.2862321734428406\n",
      "Eval Loss:  0.2321024388074875\n",
      "Eval Loss:  0.3183150291442871\n",
      "Eval Loss:  0.2705957591533661\n",
      "Eval Loss:  0.18293675780296326\n",
      "Eval Loss:  0.26071053743362427\n",
      "Eval Loss:  0.27237552404403687\n",
      "Eval Loss:  0.2641329765319824\n",
      "Eval Loss:  0.22279246151447296\n",
      "Eval Loss:  0.3152230978012085\n",
      "Eval Loss:  0.2912944555282593\n",
      "Eval Loss:  0.37647926807403564\n",
      "[[17476   937]\n",
      " [ 2489  8969]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18413\n",
      "           1       0.91      0.78      0.84     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.88     29871\n",
      "\n",
      "acc:  0.8853068193230893\n",
      "pre:  0.9054108621037755\n",
      "rec:  0.7827718624541805\n",
      "ma F1:  0.875183438964912\n",
      "mi F1:  0.8853068193230893\n",
      "we F1:  0.8834599301358445\n",
      "29871 467\n",
      "Loss:  0.03888896852731705\n",
      "Loss:  0.07162312418222427\n",
      "Loss:  0.055090948939323425\n",
      "15 **********\n",
      "Epoch:  1250.5542709827423  fold:  10  kers:  128\n",
      "epoch:  16\n",
      "29871 467\n",
      "Loss:  0.07548004388809204\n",
      "Loss:  0.060510654002428055\n",
      "Loss:  0.06860004365444183\n",
      "16 **********\n",
      "Epoch:  1315.3510179519653  fold:  10  kers:  128\n",
      "epoch:  17\n",
      "29871 467\n",
      "Loss:  0.07653658092021942\n",
      "Loss:  0.08132627606391907\n",
      "Loss:  0.07003046572208405\n",
      "17 **********\n",
      "Epoch:  1380.1547455787659  fold:  10  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.6035510897636414\n",
      "Eval Loss:  0.08404187113046646\n",
      "Eval Loss:  0.03690573573112488\n",
      "[[1690   61]\n",
      " [ 243 1026]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      1751\n",
      "           1       0.94      0.81      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.91      0.89      0.89      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8993377483443709\n",
      "pre:  0.9438822447102115\n",
      "rec:  0.8085106382978723\n",
      "ma F1:  0.8942243704248538\n",
      "mi F1:  0.899337748344371\n",
      "we F1:  0.8979361899387202\n",
      "Eval Loss:  0.25306832790374756\n",
      "Eval Loss:  0.31639814376831055\n",
      "Eval Loss:  0.31339120864868164\n",
      "Eval Loss:  0.2786456346511841\n",
      "Eval Loss:  0.38807374238967896\n",
      "Eval Loss:  0.3008385896682739\n",
      "Eval Loss:  0.3054114580154419\n",
      "Eval Loss:  0.32978710532188416\n",
      "Eval Loss:  0.2891016900539398\n",
      "Eval Loss:  0.26938924193382263\n",
      "Eval Loss:  0.19329532980918884\n",
      "Eval Loss:  0.34165266156196594\n",
      "Eval Loss:  0.3503745198249817\n",
      "Eval Loss:  0.35455793142318726\n",
      "Eval Loss:  0.29133403301239014\n",
      "Eval Loss:  0.28206002712249756\n",
      "Eval Loss:  0.23025599122047424\n",
      "Eval Loss:  0.27124735713005066\n",
      "Eval Loss:  0.24209816753864288\n",
      "Eval Loss:  0.33798760175704956\n",
      "Eval Loss:  0.3033961355686188\n",
      "Eval Loss:  0.22245430946350098\n",
      "Eval Loss:  0.27257341146469116\n",
      "Eval Loss:  0.2917308211326599\n",
      "Eval Loss:  0.26305049657821655\n",
      "Eval Loss:  0.23570698499679565\n",
      "Eval Loss:  0.3611955940723419\n",
      "Eval Loss:  0.3534647524356842\n",
      "Eval Loss:  0.4134881794452667\n",
      "[[17769   644]\n",
      " [ 3049  8409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91     18413\n",
      "           1       0.93      0.73      0.82     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.89      0.85      0.86     29871\n",
      "weighted avg       0.88      0.88      0.87     29871\n",
      "\n",
      "acc:  0.8763683840514211\n",
      "pre:  0.9288633602120844\n",
      "rec:  0.7338977133880258\n",
      "ma F1:  0.8629077651013173\n",
      "mi F1:  0.8763683840514213\n",
      "we F1:  0.8729097527934083\n",
      "29871 467\n",
      "Loss:  0.07785794883966446\n",
      "Loss:  0.13450030982494354\n",
      "Loss:  0.1019904837012291\n",
      "18 **********\n",
      "Epoch:  1485.2467510700226  fold:  10  kers:  128\n",
      "epoch:  19\n",
      "29871 467\n",
      "Loss:  0.04638121649622917\n",
      "Loss:  0.07386287301778793\n",
      "Loss:  0.08488620817661285\n",
      "19 **********\n",
      "Epoch:  1550.0514764785767  fold:  10  kers:  128\n",
      "epoch:  20\n",
      "29871 467\n",
      "Loss:  0.07084967195987701\n",
      "Loss:  0.06536939740180969\n",
      "Loss:  0.07535259425640106\n",
      "20 **********\n",
      "Epoch:  1614.8631834983826  fold:  10  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.3073628544807434\n",
      "Eval Loss:  0.11587007343769073\n",
      "Eval Loss:  0.05295231565833092\n",
      "[[1667   84]\n",
      " [ 148 1121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      1751\n",
      "           1       0.93      0.88      0.91      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.92      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9231788079470199\n",
      "pre:  0.9302904564315353\n",
      "rec:  0.8833727344365643\n",
      "ma F1:  0.9205829238777623\n",
      "mi F1:  0.9231788079470199\n",
      "we F1:  0.9228745284956783\n",
      "update!  Acc:  0.9231788079470199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2327645719051361\n",
      "Eval Loss:  0.29109254479408264\n",
      "Eval Loss:  0.21382150053977966\n",
      "Eval Loss:  0.26230716705322266\n",
      "Eval Loss:  0.2918463945388794\n",
      "Eval Loss:  0.2580263614654541\n",
      "Eval Loss:  0.2864365875720978\n",
      "Eval Loss:  0.25261157751083374\n",
      "Eval Loss:  0.191537007689476\n",
      "Eval Loss:  0.24639186263084412\n",
      "Eval Loss:  0.17318518459796906\n",
      "Eval Loss:  0.2658917009830475\n",
      "Eval Loss:  0.27592217922210693\n",
      "Eval Loss:  0.3190288841724396\n",
      "Eval Loss:  0.257266104221344\n",
      "Eval Loss:  0.20525863766670227\n",
      "Eval Loss:  0.18832625448703766\n",
      "Eval Loss:  0.2255999594926834\n",
      "Eval Loss:  0.18597055971622467\n",
      "Eval Loss:  0.26831889152526855\n",
      "Eval Loss:  0.24788743257522583\n",
      "Eval Loss:  0.15314359962940216\n",
      "Eval Loss:  0.2656340003013611\n",
      "Eval Loss:  0.2390572875738144\n",
      "Eval Loss:  0.2101363241672516\n",
      "Eval Loss:  0.19437673687934875\n",
      "Eval Loss:  0.26876088976860046\n",
      "Eval Loss:  0.2745005488395691\n",
      "Eval Loss:  0.3008022904396057\n",
      "[[17298  1115]\n",
      " [ 1890  9568]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18413\n",
      "           1       0.90      0.84      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.899400756586656\n",
      "pre:  0.8956285687540952\n",
      "rec:  0.8350497469017281\n",
      "ma F1:  0.8921804261195236\n",
      "mi F1:  0.899400756586656\n",
      "we F1:  0.8986768554078683\n",
      "29871 467\n",
      "Loss:  0.08561784029006958\n",
      "Loss:  0.07220643758773804\n",
      "Loss:  0.09165208041667938\n",
      "21 **********\n",
      "Epoch:  1720.0599086284637  fold:  10  kers:  128\n",
      "epoch:  22\n",
      "29871 467\n",
      "Loss:  0.03322926536202431\n",
      "Loss:  0.059523534029722214\n",
      "Loss:  0.0414150208234787\n",
      "22 **********\n",
      "Epoch:  1784.8237433433533  fold:  10  kers:  128\n",
      "epoch:  23\n",
      "29871 467\n",
      "Loss:  0.034383002668619156\n",
      "Loss:  0.06110638007521629\n",
      "Loss:  0.09233678132295609\n",
      "23 **********\n",
      "Epoch:  1849.6464204788208  fold:  10  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.30687758326530457\n",
      "Eval Loss:  0.13717034459114075\n",
      "Eval Loss:  0.03452937677502632\n",
      "[[1639  112]\n",
      " [ 117 1152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1751\n",
      "           1       0.91      0.91      0.91      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.92      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9241721854304635\n",
      "pre:  0.9113924050632911\n",
      "rec:  0.9078014184397163\n",
      "ma F1:  0.9221476960353727\n",
      "mi F1:  0.9241721854304635\n",
      "we F1:  0.924151400118399\n",
      "update!  Acc:  0.9241721854304635\n",
      "Eval Loss:  0.23424643278121948\n",
      "Eval Loss:  0.2862049341201782\n",
      "Eval Loss:  0.1708119660615921\n",
      "Eval Loss:  0.2591358721256256\n",
      "Eval Loss:  0.26049384474754333\n",
      "Eval Loss:  0.21061761677265167\n",
      "Eval Loss:  0.29037755727767944\n",
      "Eval Loss:  0.26978737115859985\n",
      "Eval Loss:  0.16947707533836365\n",
      "Eval Loss:  0.2280394285917282\n",
      "Eval Loss:  0.16794078052043915\n",
      "Eval Loss:  0.2780471444129944\n",
      "Eval Loss:  0.24002985656261444\n",
      "Eval Loss:  0.2968984544277191\n",
      "Eval Loss:  0.23155319690704346\n",
      "Eval Loss:  0.15947225689888\n",
      "Eval Loss:  0.1713055819272995\n",
      "Eval Loss:  0.22107279300689697\n",
      "Eval Loss:  0.17385287582874298\n",
      "Eval Loss:  0.29251062870025635\n",
      "Eval Loss:  0.22728639841079712\n",
      "Eval Loss:  0.1481771320104599\n",
      "Eval Loss:  0.24937060475349426\n",
      "Eval Loss:  0.21602992713451385\n",
      "Eval Loss:  0.19540683925151825\n",
      "Eval Loss:  0.20385396480560303\n",
      "Eval Loss:  0.23872621357440948\n",
      "Eval Loss:  0.2824288606643677\n",
      "Eval Loss:  0.25965896248817444\n",
      "[[17075  1338]\n",
      " [ 1484  9974]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     18413\n",
      "           1       0.88      0.87      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.90      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9055270998627432\n",
      "pre:  0.8817185289957568\n",
      "rec:  0.8704835049746902\n",
      "ma F1:  0.8998684828899468\n",
      "mi F1:  0.9055270998627432\n",
      "we F1:  0.9054107559565288\n",
      "29871 467\n",
      "Loss:  0.09061232209205627\n",
      "Loss:  0.053404826670885086\n",
      "Loss:  0.07282647490501404\n",
      "24 **********\n",
      "Epoch:  1954.8780529499054  fold:  10  kers:  128\n",
      "epoch:  25\n",
      "29871 467\n",
      "Loss:  0.07596440613269806\n",
      "Loss:  0.046294815838336945\n",
      "Loss:  0.049829039722681046\n",
      "25 **********\n",
      "Epoch:  2019.6738014221191  fold:  10  kers:  128\n",
      "epoch:  26\n",
      "29871 467\n",
      "Loss:  0.058424219489097595\n",
      "Loss:  0.03909282386302948\n",
      "Loss:  0.03835387900471687\n",
      "26 **********\n",
      "Epoch:  2084.4994711875916  fold:  10  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.5056716203689575\n",
      "Eval Loss:  0.1285790652036667\n",
      "Eval Loss:  0.0282327588647604\n",
      "[[1659   92]\n",
      " [ 166 1103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      1751\n",
      "           1       0.92      0.87      0.90      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9145695364238411\n",
      "pre:  0.9230125523012552\n",
      "rec:  0.8691883372734437\n",
      "ma F1:  0.9115722783927482\n",
      "mi F1:  0.9145695364238411\n",
      "we F1:  0.9141706207866093\n",
      "Eval Loss:  0.21200503408908844\n",
      "Eval Loss:  0.26775985956192017\n",
      "Eval Loss:  0.17878133058547974\n",
      "Eval Loss:  0.22201789915561676\n",
      "Eval Loss:  0.2544485926628113\n",
      "Eval Loss:  0.24089612066745758\n",
      "Eval Loss:  0.2642974257469177\n",
      "Eval Loss:  0.2507532835006714\n",
      "Eval Loss:  0.1801578402519226\n",
      "Eval Loss:  0.21136493980884552\n",
      "Eval Loss:  0.14907735586166382\n",
      "Eval Loss:  0.2526189386844635\n",
      "Eval Loss:  0.2154851108789444\n",
      "Eval Loss:  0.26383107900619507\n",
      "Eval Loss:  0.25757864117622375\n",
      "Eval Loss:  0.16298319399356842\n",
      "Eval Loss:  0.1657445877790451\n",
      "Eval Loss:  0.2374943494796753\n",
      "Eval Loss:  0.1583702117204666\n",
      "Eval Loss:  0.27774885296821594\n",
      "Eval Loss:  0.22706802189350128\n",
      "Eval Loss:  0.13016951084136963\n",
      "Eval Loss:  0.21993102133274078\n",
      "Eval Loss:  0.20742496848106384\n",
      "Eval Loss:  0.17456850409507751\n",
      "Eval Loss:  0.1899217814207077\n",
      "Eval Loss:  0.23491066694259644\n",
      "Eval Loss:  0.2599034309387207\n",
      "Eval Loss:  0.24431295692920685\n",
      "[[17378  1035]\n",
      " [ 1722  9736]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18413\n",
      "           1       0.90      0.85      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9077031234307522\n",
      "pre:  0.9039086435799832\n",
      "rec:  0.8497119916215744\n",
      "ma F1:  0.9012391531941486\n",
      "mi F1:  0.9077031234307522\n",
      "we F1:  0.9071220258708796\n",
      "29871 467\n",
      "Loss:  0.06237879395484924\n",
      "Loss:  0.07920945435762405\n",
      "Loss:  0.04318459704518318\n",
      "27 **********\n",
      "Epoch:  2189.6154124736786  fold:  10  kers:  128\n",
      "epoch:  28\n",
      "29871 467\n",
      "Loss:  0.057288091629743576\n",
      "Loss:  0.0987112894654274\n",
      "Loss:  0.08886508643627167\n",
      "28 **********\n",
      "Epoch:  2254.3942070007324  fold:  10  kers:  128\n",
      "epoch:  29\n",
      "29871 467\n",
      "Loss:  0.06036439165472984\n",
      "Loss:  0.03988497704267502\n",
      "Loss:  0.06555796414613724\n",
      "29 **********\n",
      "Epoch:  2319.1979353427887  fold:  10  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.49655699729919434\n",
      "Eval Loss:  0.10824531316757202\n",
      "Eval Loss:  0.009601917117834091\n",
      "[[1669   82]\n",
      " [ 180 1089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93      1751\n",
      "           1       0.93      0.86      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9132450331125828\n",
      "pre:  0.9299743808710503\n",
      "rec:  0.8581560283687943\n",
      "ma F1:  0.9099225865209472\n",
      "mi F1:  0.9132450331125828\n",
      "we F1:  0.9126836542057202\n",
      "Eval Loss:  0.19962246716022491\n",
      "Eval Loss:  0.27380725741386414\n",
      "Eval Loss:  0.19079360365867615\n",
      "Eval Loss:  0.22265394032001495\n",
      "Eval Loss:  0.29956239461898804\n",
      "Eval Loss:  0.21620525419712067\n",
      "Eval Loss:  0.2553415894508362\n",
      "Eval Loss:  0.2538484036922455\n",
      "Eval Loss:  0.1876835972070694\n",
      "Eval Loss:  0.1945561319589615\n",
      "Eval Loss:  0.12452059984207153\n",
      "Eval Loss:  0.2524005174636841\n",
      "Eval Loss:  0.21431516110897064\n",
      "Eval Loss:  0.2838551104068756\n",
      "Eval Loss:  0.25969934463500977\n",
      "Eval Loss:  0.14019514620304108\n",
      "Eval Loss:  0.1671895533800125\n",
      "Eval Loss:  0.2416263222694397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17265306413173676\n",
      "Eval Loss:  0.29955995082855225\n",
      "Eval Loss:  0.23144571483135223\n",
      "Eval Loss:  0.13579323887825012\n",
      "Eval Loss:  0.22026672959327698\n",
      "Eval Loss:  0.20737791061401367\n",
      "Eval Loss:  0.1994466334581375\n",
      "Eval Loss:  0.21465498208999634\n",
      "Eval Loss:  0.2314884513616562\n",
      "Eval Loss:  0.2817070484161377\n",
      "Eval Loss:  0.2945842146873474\n",
      "[[17566   847]\n",
      " [ 1912  9546]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     18413\n",
      "           1       0.92      0.83      0.87     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.89      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9076361688594289\n",
      "pre:  0.9185028384489561\n",
      "rec:  0.8331296910455577\n",
      "ma F1:  0.9004608155372308\n",
      "mi F1:  0.9076361688594289\n",
      "we F1:  0.9066833320404587\n",
      "29871 467\n",
      "Loss:  0.076591357588768\n",
      "Loss:  0.08323199301958084\n",
      "Loss:  0.05513853207230568\n",
      "30 **********\n",
      "Epoch:  2424.2610177993774  fold:  10  kers:  128\n",
      "epoch:  31\n",
      "29871 467\n",
      "Loss:  0.06621835380792618\n",
      "Loss:  0.049242667853832245\n",
      "Loss:  0.05281226336956024\n",
      "31 **********\n",
      "Epoch:  2489.0607566833496  fold:  10  kers:  128\n",
      "epoch:  32\n",
      "29871 467\n",
      "Loss:  0.060017503798007965\n",
      "Loss:  0.05951935425400734\n",
      "Loss:  0.06596260517835617\n",
      "32 **********\n",
      "Epoch:  2553.871465921402  fold:  10  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.40817075967788696\n",
      "Eval Loss:  0.14368857443332672\n",
      "Eval Loss:  0.015404847450554371\n",
      "[[1633  118]\n",
      " [ 122 1147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1751\n",
      "           1       0.91      0.90      0.91      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.92      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9205298013245033\n",
      "pre:  0.9067193675889328\n",
      "rec:  0.9038613081166272\n",
      "ma F1:  0.9184170016807358\n",
      "mi F1:  0.9205298013245033\n",
      "we F1:  0.9205124120270237\n",
      "Eval Loss:  0.21662035584449768\n",
      "Eval Loss:  0.24021480977535248\n",
      "Eval Loss:  0.1698300987482071\n",
      "Eval Loss:  0.21788984537124634\n",
      "Eval Loss:  0.23323982954025269\n",
      "Eval Loss:  0.20672254264354706\n",
      "Eval Loss:  0.2409479320049286\n",
      "Eval Loss:  0.21561048924922943\n",
      "Eval Loss:  0.14021578431129456\n",
      "Eval Loss:  0.16377775371074677\n",
      "Eval Loss:  0.13461865484714508\n",
      "Eval Loss:  0.19053460657596588\n",
      "Eval Loss:  0.20604127645492554\n",
      "Eval Loss:  0.2581593096256256\n",
      "Eval Loss:  0.22937539219856262\n",
      "Eval Loss:  0.10160005837678909\n",
      "Eval Loss:  0.15584303438663483\n",
      "Eval Loss:  0.22232598066329956\n",
      "Eval Loss:  0.15101513266563416\n",
      "Eval Loss:  0.26504942774772644\n",
      "Eval Loss:  0.21462318301200867\n",
      "Eval Loss:  0.13651211559772491\n",
      "Eval Loss:  0.21546606719493866\n",
      "Eval Loss:  0.1861102432012558\n",
      "Eval Loss:  0.20054419338703156\n",
      "Eval Loss:  0.19795534014701843\n",
      "Eval Loss:  0.2122260332107544\n",
      "Eval Loss:  0.2564108073711395\n",
      "Eval Loss:  0.26184967160224915\n",
      "[[17224  1189]\n",
      " [ 1268 10190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18413\n",
      "           1       0.90      0.89      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9177463091292558\n",
      "pre:  0.8955092714649794\n",
      "rec:  0.8893349624716356\n",
      "ma F1:  0.9129175464553114\n",
      "mi F1:  0.9177463091292558\n",
      "we F1:  0.9176920765089485\n",
      "29871 467\n",
      "Loss:  0.06812730431556702\n",
      "Loss:  0.07517972588539124\n",
      "Loss:  0.052317723631858826\n",
      "33 **********\n",
      "Epoch:  2659.1469807624817  fold:  10  kers:  128\n",
      "epoch:  34\n",
      "29871 467\n",
      "Loss:  0.04807275906205177\n",
      "Loss:  0.03134627640247345\n",
      "Loss:  0.06847888976335526\n",
      "34 **********\n",
      "Epoch:  2724.03049492836  fold:  10  kers:  128\n",
      "epoch:  35\n",
      "29871 467\n",
      "Loss:  0.03531396761536598\n",
      "Loss:  0.03417429327964783\n",
      "Loss:  0.033173587173223495\n",
      "35 **********\n",
      "Epoch:  2788.8631460666656  fold:  10  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.866350531578064\n",
      "Eval Loss:  0.12458466738462448\n",
      "Eval Loss:  0.017978567630052567\n",
      "[[1633  118]\n",
      " [ 231 1038]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      1751\n",
      "           1       0.90      0.82      0.86      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.89      0.88      0.88      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8844370860927152\n",
      "pre:  0.8979238754325259\n",
      "rec:  0.817966903073286\n",
      "ma F1:  0.8797701444439691\n",
      "mi F1:  0.8844370860927152\n",
      "we F1:  0.8835507593594238\n",
      "Eval Loss:  0.23515824973583221\n",
      "Eval Loss:  0.2396029233932495\n",
      "Eval Loss:  0.1438145935535431\n",
      "Eval Loss:  0.2079780399799347\n",
      "Eval Loss:  0.20569199323654175\n",
      "Eval Loss:  0.16968205571174622\n",
      "Eval Loss:  0.23335666954517365\n",
      "Eval Loss:  0.22715646028518677\n",
      "Eval Loss:  0.13115541636943817\n",
      "Eval Loss:  0.182354137301445\n",
      "Eval Loss:  0.17752352356910706\n",
      "Eval Loss:  0.17274592816829681\n",
      "Eval Loss:  0.1749100685119629\n",
      "Eval Loss:  0.23359137773513794\n",
      "Eval Loss:  0.2342260181903839\n",
      "Eval Loss:  0.11387619376182556\n",
      "Eval Loss:  0.16828763484954834\n",
      "Eval Loss:  0.2426036298274994\n",
      "Eval Loss:  0.14159610867500305\n",
      "Eval Loss:  0.2583130896091461\n",
      "Eval Loss:  0.2550167739391327\n",
      "Eval Loss:  0.14159956574440002\n",
      "Eval Loss:  0.1864730715751648\n",
      "Eval Loss:  0.19196993112564087\n",
      "Eval Loss:  0.21116013824939728\n",
      "Eval Loss:  0.1875832974910736\n",
      "Eval Loss:  0.24634025990962982\n",
      "Eval Loss:  0.2352067232131958\n",
      "Eval Loss:  0.21974830329418182\n",
      "[[17067  1346]\n",
      " [ 1186 10272]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18413\n",
      "           1       0.88      0.90      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9152355127046299\n",
      "pre:  0.8841452917886039\n",
      "rec:  0.8964915342991796\n",
      "ma F1:  0.9106099050049385\n",
      "mi F1:  0.9152355127046298\n",
      "we F1:  0.9153444306195603\n",
      "29871 467\n",
      "Loss:  0.06026110798120499\n",
      "Loss:  0.051555853337049484\n",
      "Loss:  0.06675870716571808\n",
      "36 **********\n",
      "Epoch:  2894.4308791160583  fold:  10  kers:  128\n",
      "epoch:  37\n",
      "29871 467\n",
      "Loss:  0.05249921232461929\n",
      "Loss:  0.043912362307310104\n",
      "Loss:  0.05867350101470947\n",
      "37 **********\n",
      "Epoch:  2959.2395939826965  fold:  10  kers:  128\n",
      "epoch:  38\n",
      "29871 467\n",
      "Loss:  0.09322918206453323\n",
      "Loss:  0.07300640642642975\n",
      "Loss:  0.08880344033241272\n",
      "38 **********\n",
      "Epoch:  3029.662297964096  fold:  10  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.5143417716026306\n",
      "Eval Loss:  0.09787730872631073\n",
      "Eval Loss:  0.01627068780362606\n",
      "[[1652   99]\n",
      " [ 155 1114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1751\n",
      "           1       0.92      0.88      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9158940397350993\n",
      "pre:  0.9183841714756801\n",
      "rec:  0.8778565799842396\n",
      "ma F1:  0.9131373771990259\n",
      "mi F1:  0.9158940397350993\n",
      "we F1:  0.915607100883761\n",
      "Eval Loss:  0.2155301421880722\n",
      "Eval Loss:  0.25954315066337585\n",
      "Eval Loss:  0.16315127909183502\n",
      "Eval Loss:  0.19832347333431244\n",
      "Eval Loss:  0.22396306693553925\n",
      "Eval Loss:  0.16680365800857544\n",
      "Eval Loss:  0.2596797049045563\n",
      "Eval Loss:  0.19738557934761047\n",
      "Eval Loss:  0.12070470303297043\n",
      "Eval Loss:  0.18091849982738495\n",
      "Eval Loss:  0.15337558090686798\n",
      "Eval Loss:  0.1618802845478058\n",
      "Eval Loss:  0.21292832493782043\n",
      "Eval Loss:  0.27447575330734253\n",
      "Eval Loss:  0.21205006539821625\n",
      "Eval Loss:  0.1256076693534851\n",
      "Eval Loss:  0.15212863683700562\n",
      "Eval Loss:  0.22192761301994324\n",
      "Eval Loss:  0.14906691014766693\n",
      "Eval Loss:  0.20430360734462738\n",
      "Eval Loss:  0.22156038880348206\n",
      "Eval Loss:  0.13531650602817535\n",
      "Eval Loss:  0.19098390638828278\n",
      "Eval Loss:  0.1714809387922287\n",
      "Eval Loss:  0.18025945127010345\n",
      "Eval Loss:  0.16816653311252594\n",
      "Eval Loss:  0.21956723928451538\n",
      "Eval Loss:  0.19906944036483765\n",
      "Eval Loss:  0.22299739718437195\n",
      "[[17237  1176]\n",
      " [ 1155 10303]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18413\n",
      "           1       0.90      0.90      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9219644471226273\n",
      "pre:  0.8975520515724367\n",
      "rec:  0.899197067551056\n",
      "ma F1:  0.9175200101715681\n",
      "mi F1:  0.9219644471226273\n",
      "we F1:  0.9219779073441405\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0548289529979229\n",
      "Loss:  0.03523977845907211\n",
      "Loss:  0.06517305970191956\n",
      "39 **********\n",
      "Epoch:  3135.0245809555054  fold:  10  kers:  128\n",
      "epoch:  40\n",
      "29871 467\n",
      "Loss:  0.029948534443974495\n",
      "Loss:  0.0538984015583992\n",
      "Loss:  0.03769655525684357\n",
      "40 **********\n",
      "Epoch:  3199.8173377513885  fold:  10  kers:  128\n",
      "epoch:  41\n",
      "29871 467\n",
      "Loss:  0.04227086529135704\n",
      "Loss:  0.07448026537895203\n",
      "Loss:  0.06774593144655228\n",
      "41 **********\n",
      "Epoch:  3264.641012430191  fold:  10  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.8142138123512268\n",
      "Eval Loss:  0.08793218433856964\n",
      "Eval Loss:  0.0110537800937891\n",
      "[[1651  100]\n",
      " [ 219 1050]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1751\n",
      "           1       0.91      0.83      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.89      0.89      3020\n",
      "weighted avg       0.90      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8943708609271523\n",
      "pre:  0.9130434782608695\n",
      "rec:  0.8274231678486997\n",
      "ma F1:  0.890015057312889\n",
      "mi F1:  0.8943708609271522\n",
      "we F1:  0.8935083973163415\n",
      "Eval Loss:  0.22005252540111542\n",
      "Eval Loss:  0.21809101104736328\n",
      "Eval Loss:  0.1531933844089508\n",
      "Eval Loss:  0.215866819024086\n",
      "Eval Loss:  0.23921453952789307\n",
      "Eval Loss:  0.1994444876909256\n",
      "Eval Loss:  0.2165626883506775\n",
      "Eval Loss:  0.2151067852973938\n",
      "Eval Loss:  0.14705942571163177\n",
      "Eval Loss:  0.14876526594161987\n",
      "Eval Loss:  0.1298399716615677\n",
      "Eval Loss:  0.17042212188243866\n",
      "Eval Loss:  0.20707549154758453\n",
      "Eval Loss:  0.21199868619441986\n",
      "Eval Loss:  0.245396688580513\n",
      "Eval Loss:  0.09237024933099747\n",
      "Eval Loss:  0.15653234720230103\n",
      "Eval Loss:  0.22695502638816833\n",
      "Eval Loss:  0.14164312183856964\n",
      "Eval Loss:  0.26017171144485474\n",
      "Eval Loss:  0.20337171852588654\n",
      "Eval Loss:  0.1340266764163971\n",
      "Eval Loss:  0.1961522400379181\n",
      "Eval Loss:  0.17000766098499298\n",
      "Eval Loss:  0.20302335917949677\n",
      "Eval Loss:  0.19954460859298706\n",
      "Eval Loss:  0.20185676217079163\n",
      "Eval Loss:  0.24431154131889343\n",
      "Eval Loss:  0.235958993434906\n",
      "[[17301  1112]\n",
      " [ 1345 10113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18413\n",
      "           1       0.90      0.88      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9177463091292558\n",
      "pre:  0.9009354120267261\n",
      "rec:  0.8826147669750393\n",
      "ma F1:  0.9126906551451096\n",
      "mi F1:  0.9177463091292558\n",
      "we F1:  0.9175824294160803\n",
      "29871 467\n",
      "Loss:  0.07455608248710632\n",
      "Loss:  0.03423696011304855\n",
      "Loss:  0.07493346184492111\n",
      "42 **********\n",
      "Epoch:  3369.7649323940277  fold:  10  kers:  128\n",
      "epoch:  43\n",
      "29871 467\n",
      "Loss:  0.08381941169500351\n",
      "Loss:  0.07070817798376083\n",
      "Loss:  0.08409034460783005\n",
      "43 **********\n",
      "Epoch:  3434.5427298545837  fold:  10  kers:  128\n",
      "epoch:  44\n",
      "29871 467\n",
      "Loss:  0.045051444321870804\n",
      "Loss:  0.09276788681745529\n",
      "Loss:  0.08204130828380585\n",
      "44 **********\n",
      "Epoch:  3499.3474550247192  fold:  10  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.5695160031318665\n",
      "Eval Loss:  0.11272890120744705\n",
      "Eval Loss:  0.009171955287456512\n",
      "[[1599  152]\n",
      " [ 156 1113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1751\n",
      "           1       0.88      0.88      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.90      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8980132450331125\n",
      "pre:  0.8798418972332016\n",
      "rec:  0.8770685579196218\n",
      "ma F1:  0.8953018188236109\n",
      "mi F1:  0.8980132450331125\n",
      "we F1:  0.8979909287680137\n",
      "Eval Loss:  0.22057467699050903\n",
      "Eval Loss:  0.23862911760807037\n",
      "Eval Loss:  0.14770114421844482\n",
      "Eval Loss:  0.21693581342697144\n",
      "Eval Loss:  0.21705196797847748\n",
      "Eval Loss:  0.16986022889614105\n",
      "Eval Loss:  0.21447379887104034\n",
      "Eval Loss:  0.2090708613395691\n",
      "Eval Loss:  0.11184260249137878\n",
      "Eval Loss:  0.17082355916500092\n",
      "Eval Loss:  0.13434642553329468\n",
      "Eval Loss:  0.15075276792049408\n",
      "Eval Loss:  0.1939423382282257\n",
      "Eval Loss:  0.2534189224243164\n",
      "Eval Loss:  0.2612914443016052\n",
      "Eval Loss:  0.09775591641664505\n",
      "Eval Loss:  0.1594991385936737\n",
      "Eval Loss:  0.24154019355773926\n",
      "Eval Loss:  0.1299300342798233\n",
      "Eval Loss:  0.20022167265415192\n",
      "Eval Loss:  0.22466152906417847\n",
      "Eval Loss:  0.12665902078151703\n",
      "Eval Loss:  0.19578951597213745\n",
      "Eval Loss:  0.14264439046382904\n",
      "Eval Loss:  0.18146157264709473\n",
      "Eval Loss:  0.1771048605442047\n",
      "Eval Loss:  0.2409822642803192\n",
      "Eval Loss:  0.22333332896232605\n",
      "Eval Loss:  0.1889064759016037\n",
      "[[17149  1264]\n",
      " [ 1061 10397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18413\n",
      "           1       0.89      0.91      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9221653108365974\n",
      "pre:  0.8916044936111825\n",
      "rec:  0.9074009425728748\n",
      "ma F1:  0.9179743355425511\n",
      "mi F1:  0.9221653108365974\n",
      "we F1:  0.9222913132039984\n",
      "29871 467\n",
      "Loss:  0.04201659932732582\n",
      "Loss:  0.05621691420674324\n",
      "Loss:  0.07853163033723831\n",
      "45 **********\n",
      "Epoch:  3604.6060152053833  fold:  10  kers:  128\n",
      "epoch:  46\n",
      "29871 467\n",
      "Loss:  0.041777875274419785\n",
      "Loss:  0.08269058912992477\n",
      "Loss:  0.055052515119314194\n",
      "46 **********\n",
      "Epoch:  3669.3917915821075  fold:  10  kers:  128\n",
      "epoch:  47\n",
      "29871 467\n",
      "Loss:  0.0610894113779068\n",
      "Loss:  0.08265797793865204\n",
      "Loss:  0.06369080394506454\n",
      "47 **********\n",
      "Epoch:  3734.2025003433228  fold:  10  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.7486007809638977\n",
      "Eval Loss:  0.11836733669042587\n",
      "Eval Loss:  0.008899379521608353\n",
      "[[1632  119]\n",
      " [ 194 1075]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1751\n",
      "           1       0.90      0.85      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.89      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8963576158940397\n",
      "pre:  0.9003350083752094\n",
      "rec:  0.847123719464145\n",
      "ma F1:  0.8927078548369942\n",
      "mi F1:  0.8963576158940397\n",
      "we F1:  0.8958661758953352\n",
      "Eval Loss:  0.2214716225862503\n",
      "Eval Loss:  0.24214646220207214\n",
      "Eval Loss:  0.13011375069618225\n",
      "Eval Loss:  0.19314199686050415\n",
      "Eval Loss:  0.20660893619060516\n",
      "Eval Loss:  0.1597587615251541\n",
      "Eval Loss:  0.25778326392173767\n",
      "Eval Loss:  0.1960844099521637\n",
      "Eval Loss:  0.11584686487913132\n",
      "Eval Loss:  0.14323356747627258\n",
      "Eval Loss:  0.14199677109718323\n",
      "Eval Loss:  0.15192864835262299\n",
      "Eval Loss:  0.19417303800582886\n",
      "Eval Loss:  0.23724400997161865\n",
      "Eval Loss:  0.20322780311107635\n",
      "Eval Loss:  0.112198106944561\n",
      "Eval Loss:  0.17470639944076538\n",
      "Eval Loss:  0.22075480222702026\n",
      "Eval Loss:  0.14509645104408264\n",
      "Eval Loss:  0.18804463744163513\n",
      "Eval Loss:  0.2083195298910141\n",
      "Eval Loss:  0.12489419430494308\n",
      "Eval Loss:  0.2034549117088318\n",
      "Eval Loss:  0.15534338355064392\n",
      "Eval Loss:  0.15460340678691864\n",
      "Eval Loss:  0.18530604243278503\n",
      "Eval Loss:  0.20416979491710663\n",
      "Eval Loss:  0.22290600836277008\n",
      "Eval Loss:  0.19299235939979553\n",
      "[[17102  1311]\n",
      " [  950 10508]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18413\n",
      "           1       0.89      0.92      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.93      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9243078571189448\n",
      "pre:  0.8890769100600727\n",
      "rec:  0.9170884971199162\n",
      "ma F1:  0.9204304137671839\n",
      "mi F1:  0.9243078571189448\n",
      "we F1:  0.9245201344998949\n",
      "29871 467\n",
      "Loss:  0.057977497577667236\n",
      "Loss:  0.04772014170885086\n",
      "Loss:  0.078822061419487\n",
      "48 **********\n",
      "Epoch:  3839.336394071579  fold:  10  kers:  128\n",
      "epoch:  49\n",
      "29871 467\n",
      "Loss:  0.04994851350784302\n",
      "Loss:  0.028503768146038055\n",
      "Loss:  0.06784483790397644\n",
      "49 **********\n",
      "Epoch:  3904.128153562546  fold:  10  kers:  128\n",
      "epoch:  50\n",
      "29871 467\n",
      "Loss:  0.04303648695349693\n",
      "Loss:  0.047738928347826004\n",
      "Loss:  0.05096578598022461\n",
      "50 **********\n",
      "Epoch:  3968.9169216156006  fold:  10  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.9029719829559326\n",
      "Eval Loss:  0.12642547488212585\n",
      "Eval Loss:  0.014341823756694794\n",
      "[[1638  113]\n",
      " [ 246 1023]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1751\n",
      "           1       0.90      0.81      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.88      0.87      0.88      3020\n",
      "weighted avg       0.88      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8811258278145695\n",
      "pre:  0.9005281690140845\n",
      "rec:  0.806146572104019\n",
      "ma F1:  0.8759828074821198\n",
      "mi F1:  0.8811258278145695\n",
      "we F1:  0.8800135974012105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21519488096237183\n",
      "Eval Loss:  0.25275832414627075\n",
      "Eval Loss:  0.14009331166744232\n",
      "Eval Loss:  0.20060564577579498\n",
      "Eval Loss:  0.20204229652881622\n",
      "Eval Loss:  0.1413733959197998\n",
      "Eval Loss:  0.26089414954185486\n",
      "Eval Loss:  0.19810354709625244\n",
      "Eval Loss:  0.09436539560556412\n",
      "Eval Loss:  0.15687867999076843\n",
      "Eval Loss:  0.15752477943897247\n",
      "Eval Loss:  0.16749057173728943\n",
      "Eval Loss:  0.21142499148845673\n",
      "Eval Loss:  0.2151915580034256\n",
      "Eval Loss:  0.22920632362365723\n",
      "Eval Loss:  0.11392942816019058\n",
      "Eval Loss:  0.14684346318244934\n",
      "Eval Loss:  0.23093949258327484\n",
      "Eval Loss:  0.13100233674049377\n",
      "Eval Loss:  0.20592449605464935\n",
      "Eval Loss:  0.1908511221408844\n",
      "Eval Loss:  0.13432374596595764\n",
      "Eval Loss:  0.19416813552379608\n",
      "Eval Loss:  0.15242725610733032\n",
      "Eval Loss:  0.15832656621932983\n",
      "Eval Loss:  0.19194921851158142\n",
      "Eval Loss:  0.20135624706745148\n",
      "Eval Loss:  0.19883908331394196\n",
      "Eval Loss:  0.17224642634391785\n",
      "[[16904  1509]\n",
      " [  821 10637]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     18413\n",
      "           1       0.88      0.93      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.92      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.921997924408289\n",
      "pre:  0.8757615675942697\n",
      "rec:  0.9283470064583697\n",
      "ma F1:  0.91840642475324\n",
      "mi F1:  0.9219979244082891\n",
      "we F1:  0.9223922042491496\n",
      "29871 467\n",
      "Loss:  0.045076724141836166\n",
      "Loss:  0.07510097324848175\n",
      "Loss:  0.036117635667324066\n",
      "51 **********\n",
      "Epoch:  4074.0857224464417  fold:  10  kers:  128\n",
      "epoch:  52\n",
      "29871 467\n",
      "Loss:  0.07248646020889282\n",
      "Loss:  0.04458310455083847\n",
      "Loss:  0.06184877082705498\n",
      "52 **********\n",
      "Epoch:  4138.870500564575  fold:  10  kers:  128\n",
      "epoch:  53\n",
      "29871 467\n",
      "Loss:  0.061453577131032944\n",
      "Loss:  0.06959662586450577\n",
      "Loss:  0.04780120030045509\n",
      "53 **********\n",
      "Epoch:  4203.67023897171  fold:  10  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.5851413011550903\n",
      "Eval Loss:  0.08515595644712448\n",
      "Eval Loss:  0.010843112133443356\n",
      "[[1612  139]\n",
      " [ 142 1127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1751\n",
      "           1       0.89      0.89      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.90      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9069536423841059\n",
      "pre:  0.8902053712480252\n",
      "rec:  0.888100866824271\n",
      "ma F1:  0.9044903448722169\n",
      "mi F1:  0.9069536423841059\n",
      "we F1:  0.9069384054922798\n",
      "Eval Loss:  0.19565299153327942\n",
      "Eval Loss:  0.22860576212406158\n",
      "Eval Loss:  0.14873740077018738\n",
      "Eval Loss:  0.20512272417545319\n",
      "Eval Loss:  0.22135718166828156\n",
      "Eval Loss:  0.17449381947517395\n",
      "Eval Loss:  0.24092145264148712\n",
      "Eval Loss:  0.19997957348823547\n",
      "Eval Loss:  0.10967713594436646\n",
      "Eval Loss:  0.1316857784986496\n",
      "Eval Loss:  0.1146010234951973\n",
      "Eval Loss:  0.14789079129695892\n",
      "Eval Loss:  0.19925224781036377\n",
      "Eval Loss:  0.2454054206609726\n",
      "Eval Loss:  0.19083669781684875\n",
      "Eval Loss:  0.10369867086410522\n",
      "Eval Loss:  0.13510464131832123\n",
      "Eval Loss:  0.2212367206811905\n",
      "Eval Loss:  0.13398465514183044\n",
      "Eval Loss:  0.1935783475637436\n",
      "Eval Loss:  0.19608640670776367\n",
      "Eval Loss:  0.14351283013820648\n",
      "Eval Loss:  0.1963534653186798\n",
      "Eval Loss:  0.14352409541606903\n",
      "Eval Loss:  0.144668847322464\n",
      "Eval Loss:  0.18078812956809998\n",
      "Eval Loss:  0.1856030523777008\n",
      "Eval Loss:  0.2357591688632965\n",
      "Eval Loss:  0.1754501461982727\n",
      "[[17295  1118]\n",
      " [ 1132 10326]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18413\n",
      "           1       0.90      0.90      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9246761072612233\n",
      "pre:  0.9023068857042992\n",
      "rec:  0.901204398673416\n",
      "ma F1:  0.9203401933233717\n",
      "mi F1:  0.9246761072612233\n",
      "we F1:  0.9246673968587078\n",
      "29871 467\n",
      "Loss:  0.05696437880396843\n",
      "Loss:  0.06261467933654785\n",
      "Loss:  0.06086764857172966\n",
      "54 **********\n",
      "Epoch:  4308.827070951462  fold:  10  kers:  128\n",
      "epoch:  55\n",
      "29871 467\n",
      "Loss:  0.05041089281439781\n",
      "Loss:  0.047921497374773026\n",
      "Loss:  0.044869564473629\n",
      "55 **********\n",
      "Epoch:  4373.604868412018  fold:  10  kers:  128\n",
      "epoch:  56\n",
      "29871 467\n",
      "Loss:  0.04698562994599342\n",
      "Loss:  0.04712216183543205\n",
      "Loss:  0.02468552067875862\n",
      "56 **********\n",
      "Epoch:  4438.403609991074  fold:  10  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.694259762763977\n",
      "Eval Loss:  0.07171320170164108\n",
      "Eval Loss:  0.007133107632398605\n",
      "[[1664   87]\n",
      " [ 210 1059]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1751\n",
      "           1       0.92      0.83      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.91      0.89      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9016556291390728\n",
      "pre:  0.9240837696335078\n",
      "rec:  0.83451536643026\n",
      "ma F1:  0.897543799528807\n",
      "mi F1:  0.9016556291390728\n",
      "we F1:  0.9008196703918617\n",
      "Eval Loss:  0.20392414927482605\n",
      "Eval Loss:  0.19576014578342438\n",
      "Eval Loss:  0.12738697230815887\n",
      "Eval Loss:  0.18469539284706116\n",
      "Eval Loss:  0.19528135657310486\n",
      "Eval Loss:  0.13630066812038422\n",
      "Eval Loss:  0.2099044919013977\n",
      "Eval Loss:  0.20100632309913635\n",
      "Eval Loss:  0.09815706312656403\n",
      "Eval Loss:  0.1310630887746811\n",
      "Eval Loss:  0.11239524185657501\n",
      "Eval Loss:  0.14983177185058594\n",
      "Eval Loss:  0.18955174088478088\n",
      "Eval Loss:  0.20340776443481445\n",
      "Eval Loss:  0.20355211198329926\n",
      "Eval Loss:  0.09876143932342529\n",
      "Eval Loss:  0.12075211107730865\n",
      "Eval Loss:  0.24768389761447906\n",
      "Eval Loss:  0.10661132633686066\n",
      "Eval Loss:  0.21691426634788513\n",
      "Eval Loss:  0.17273734509944916\n",
      "Eval Loss:  0.10997284948825836\n",
      "Eval Loss:  0.1654614508152008\n",
      "Eval Loss:  0.14102989435195923\n",
      "Eval Loss:  0.1721343696117401\n",
      "Eval Loss:  0.1742391586303711\n",
      "Eval Loss:  0.19484975934028625\n",
      "Eval Loss:  0.22631478309631348\n",
      "Eval Loss:  0.14594486355781555\n",
      "[[17390  1023]\n",
      " [ 1096 10362]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18413\n",
      "           1       0.91      0.90      0.91     11458\n",
      "\n",
      "    accuracy                           0.93     29871\n",
      "   macro avg       0.93      0.92      0.92     29871\n",
      "weighted avg       0.93      0.93      0.93     29871\n",
      "\n",
      "acc:  0.9290616316829031\n",
      "pre:  0.9101449275362319\n",
      "rec:  0.9043463082562402\n",
      "ma F1:  0.924904660975136\n",
      "mi F1:  0.9290616316829031\n",
      "we F1:  0.9290184531311578\n",
      "29871 467\n",
      "Loss:  0.040218327194452286\n",
      "Loss:  0.05786815658211708\n",
      "Loss:  0.02882988005876541\n",
      "57 **********\n",
      "Epoch:  4543.4387674331665  fold:  10  kers:  128\n",
      "epoch:  58\n",
      "29871 467\n",
      "Loss:  0.07520459592342377\n",
      "Loss:  0.059107523411512375\n",
      "Loss:  0.057073190808296204\n",
      "58 **********\n",
      "Epoch:  4608.235513925552  fold:  10  kers:  128\n",
      "epoch:  59\n",
      "29871 467\n",
      "Loss:  0.04104058817028999\n",
      "Loss:  0.05103154852986336\n",
      "Loss:  0.09074001759290695\n",
      "59 **********\n",
      "Epoch:  4673.024281740189  fold:  10  kers:  128\n",
      "Eval Loss:  0.9541964530944824\n",
      "Eval Loss:  0.08731537312269211\n",
      "Eval Loss:  0.008479513227939606\n",
      "[[1679   72]\n",
      " [ 324  945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89      1751\n",
      "           1       0.93      0.74      0.83      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.88      0.85      0.86      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8688741721854305\n",
      "pre:  0.9292035398230089\n",
      "rec:  0.7446808510638298\n",
      "ma F1:  0.8606420867609982\n",
      "mi F1:  0.8688741721854305\n",
      "we F1:  0.8660478976255436\n",
      "update!  Acc:  0.9241721854304635\n",
      "Epoch:  4676.723391056061  fold:  10  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "  \n",
      "kernel: 64\n",
      "  \n",
      "*********\n",
      "29459 3432\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29459 461\n",
      "Loss:  0.16173821687698364\n",
      "Loss:  0.1553047150373459\n",
      "Loss:  0.14934709668159485\n",
      "0 **********\n",
      "Epoch:  56.41715216636658  fold:  1  kers:  64\n",
      "epoch:  1\n",
      "29459 461\n",
      "Loss:  0.15264514088630676\n",
      "Loss:  0.10652964562177658\n",
      "Loss:  0.11666331440210342\n",
      "1 **********\n",
      "Epoch:  100.5262131690979  fold:  1  kers:  64\n",
      "epoch:  2\n",
      "29459 461\n",
      "Loss:  0.09782268106937408\n",
      "Loss:  0.10807590931653976\n",
      "Loss:  0.11080185323953629\n",
      "2 **********\n",
      "Epoch:  144.5724425315857  fold:  1  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.4078117609024048\n",
      "Eval Loss:  0.4757126271724701\n",
      "Eval Loss:  0.20584258437156677\n",
      "[[ 824  215]\n",
      " [ 686 1707]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.79      0.65      1039\n",
      "           1       0.89      0.71      0.79      2393\n",
      "\n",
      "    accuracy                           0.74      3432\n",
      "   macro avg       0.72      0.75      0.72      3432\n",
      "weighted avg       0.78      0.74      0.75      3432\n",
      "\n",
      "acc:  0.7374708624708625\n",
      "pre:  0.8881373569198752\n",
      "rec:  0.7133305474300041\n",
      "ma F1:  0.718860780611941\n",
      "mi F1:  0.7374708624708625\n",
      "we F1:  0.7473976445269802\n",
      "update!  Acc:  0.7374708624708625\n",
      "Eval Loss:  0.44260573387145996\n",
      "Eval Loss:  0.48953840136528015\n",
      "Eval Loss:  0.38672295212745667\n",
      "Eval Loss:  0.353517085313797\n",
      "Eval Loss:  0.4262978434562683\n",
      "Eval Loss:  0.3713754415512085\n",
      "Eval Loss:  0.4476889669895172\n",
      "Eval Loss:  0.38761481642723083\n",
      "Eval Loss:  0.3634548783302307\n",
      "Eval Loss:  0.3922605514526367\n",
      "Eval Loss:  0.520193338394165\n",
      "Eval Loss:  0.37703683972358704\n",
      "Eval Loss:  0.45146444439888\n",
      "Eval Loss:  0.5653457045555115\n",
      "Eval Loss:  0.33854010701179504\n",
      "Eval Loss:  0.4343440532684326\n",
      "Eval Loss:  0.4416145086288452\n",
      "Eval Loss:  0.43007537722587585\n",
      "Eval Loss:  0.4558117687702179\n",
      "Eval Loss:  0.41306403279304504\n",
      "Eval Loss:  0.5464929938316345\n",
      "Eval Loss:  0.4411762058734894\n",
      "Eval Loss:  0.39959484338760376\n",
      "Eval Loss:  0.3616381585597992\n",
      "Eval Loss:  0.4121347963809967\n",
      "Eval Loss:  0.3769197463989258\n",
      "Eval Loss:  0.3604940176010132\n",
      "Eval Loss:  0.40090280771255493\n",
      "[[17286  1839]\n",
      " [ 3327  7007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87     19125\n",
      "           1       0.79      0.68      0.73     10334\n",
      "\n",
      "    accuracy                           0.82     29459\n",
      "   macro avg       0.82      0.79      0.80     29459\n",
      "weighted avg       0.82      0.82      0.82     29459\n",
      "\n",
      "acc:  0.8246376319630673\n",
      "pre:  0.792109427990052\n",
      "rec:  0.6780530288368493\n",
      "ma F1:  0.8003277122083956\n",
      "mi F1:  0.8246376319630673\n",
      "we F1:  0.8211184996938824\n",
      "29459 461\n",
      "Loss:  0.09549205005168915\n",
      "Loss:  0.08351430296897888\n",
      "Loss:  0.10439477860927582\n",
      "3 **********\n",
      "Epoch:  227.21946096420288  fold:  1  kers:  64\n",
      "epoch:  4\n",
      "29459 461\n",
      "Loss:  0.11334427446126938\n",
      "Loss:  0.09722784906625748\n",
      "Loss:  0.10439593344926834\n",
      "4 **********\n",
      "Epoch:  271.0901606082916  fold:  1  kers:  64\n",
      "epoch:  5\n",
      "29459 461\n",
      "Loss:  0.10447479039430618\n",
      "Loss:  0.1076209619641304\n",
      "Loss:  0.0806385725736618\n",
      "5 **********\n",
      "Epoch:  315.07555174827576  fold:  1  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.5550590753555298\n",
      "Eval Loss:  0.985670268535614\n",
      "Eval Loss:  0.1253022402524948\n",
      "[[ 908  131]\n",
      " [ 902 1491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.87      0.64      1039\n",
      "           1       0.92      0.62      0.74      2393\n",
      "\n",
      "    accuracy                           0.70      3432\n",
      "   macro avg       0.71      0.75      0.69      3432\n",
      "weighted avg       0.79      0.70      0.71      3432\n",
      "\n",
      "acc:  0.699009324009324\n",
      "pre:  0.9192355117139334\n",
      "rec:  0.6230672795653991\n",
      "ma F1:  0.6900657284218927\n",
      "mi F1:  0.699009324009324\n",
      "we F1:  0.7108369607124276\n",
      "Eval Loss:  0.43287771940231323\n",
      "Eval Loss:  0.47384941577911377\n",
      "Eval Loss:  0.33920595049858093\n",
      "Eval Loss:  0.297542005777359\n",
      "Eval Loss:  0.42183735966682434\n",
      "Eval Loss:  0.34666725993156433\n",
      "Eval Loss:  0.5175374150276184\n",
      "Eval Loss:  0.36577722430229187\n",
      "Eval Loss:  0.33522796630859375\n",
      "Eval Loss:  0.41128966212272644\n",
      "Eval Loss:  0.5387664437294006\n",
      "Eval Loss:  0.34296590089797974\n",
      "Eval Loss:  0.4508252739906311\n",
      "Eval Loss:  0.585973858833313\n",
      "Eval Loss:  0.3157411217689514\n",
      "Eval Loss:  0.46313217282295227\n",
      "Eval Loss:  0.3997686803340912\n",
      "Eval Loss:  0.46698445081710815\n",
      "Eval Loss:  0.4326367676258087\n",
      "Eval Loss:  0.4359217882156372\n",
      "Eval Loss:  0.58004230260849\n",
      "Eval Loss:  0.420074999332428\n",
      "Eval Loss:  0.407583624124527\n",
      "Eval Loss:  0.37799882888793945\n",
      "Eval Loss:  0.4537960886955261\n",
      "Eval Loss:  0.42260798811912537\n",
      "Eval Loss:  0.3290148079395294\n",
      "Eval Loss:  0.3848496079444885\n",
      "[[18406   719]\n",
      " [ 3893  6441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     19125\n",
      "           1       0.90      0.62      0.74     10334\n",
      "\n",
      "    accuracy                           0.84     29459\n",
      "   macro avg       0.86      0.79      0.81     29459\n",
      "weighted avg       0.85      0.84      0.84     29459\n",
      "\n",
      "acc:  0.8434434298516582\n",
      "pre:  0.8995810055865922\n",
      "rec:  0.6232823688794271\n",
      "ma F1:  0.8125151654931473\n",
      "mi F1:  0.8434434298516582\n",
      "we F1:  0.8352389742667093\n",
      "29459 461\n",
      "Loss:  0.09536005556583405\n",
      "Loss:  0.1519789844751358\n",
      "Loss:  0.05779416114091873\n",
      "6 **********\n",
      "Epoch:  397.52210664749146  fold:  1  kers:  64\n",
      "epoch:  7\n",
      "29459 461\n",
      "Loss:  0.09590043872594833\n",
      "Loss:  0.08745768666267395\n",
      "Loss:  0.08923579752445221\n",
      "7 **********\n",
      "Epoch:  441.35989332199097  fold:  1  kers:  64\n",
      "epoch:  8\n",
      "29459 461\n",
      "Loss:  0.05955438315868378\n",
      "Loss:  0.06764005124568939\n",
      "Loss:  0.07908307760953903\n",
      "8 **********\n",
      "Epoch:  485.1298611164093  fold:  1  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.5419696569442749\n",
      "Eval Loss:  0.5927934646606445\n",
      "Eval Loss:  0.11245372891426086\n",
      "[[ 892  147]\n",
      " [ 689 1704]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.86      0.68      1039\n",
      "           1       0.92      0.71      0.80      2393\n",
      "\n",
      "    accuracy                           0.76      3432\n",
      "   macro avg       0.74      0.79      0.74      3432\n",
      "weighted avg       0.81      0.76      0.77      3432\n",
      "\n",
      "acc:  0.7564102564102564\n",
      "pre:  0.9205834683954619\n",
      "rec:  0.7120768909318846\n",
      "ma F1:  0.7419660265772604\n",
      "mi F1:  0.7564102564102565\n",
      "we F1:  0.7660516019391774\n",
      "update!  Acc:  0.7564102564102564\n",
      "Eval Loss:  0.38333752751350403\n",
      "Eval Loss:  0.4388980567455292\n",
      "Eval Loss:  0.293745756149292\n",
      "Eval Loss:  0.2466488927602768\n",
      "Eval Loss:  0.37279170751571655\n",
      "Eval Loss:  0.3120529055595398\n",
      "Eval Loss:  0.43063750863075256\n",
      "Eval Loss:  0.2900020182132721\n",
      "Eval Loss:  0.2840259075164795\n",
      "Eval Loss:  0.3800565302371979\n",
      "Eval Loss:  0.5011600255966187\n",
      "Eval Loss:  0.29595354199409485\n",
      "Eval Loss:  0.40518641471862793\n",
      "Eval Loss:  0.47969260811805725\n",
      "Eval Loss:  0.30809104442596436\n",
      "Eval Loss:  0.39323684573173523\n",
      "Eval Loss:  0.33871209621429443\n",
      "Eval Loss:  0.3866715133190155\n",
      "Eval Loss:  0.37389713525772095\n",
      "Eval Loss:  0.3549870550632477\n",
      "Eval Loss:  0.4728356599807739\n",
      "Eval Loss:  0.35686254501342773\n",
      "Eval Loss:  0.3448407053947449\n",
      "Eval Loss:  0.31835630536079407\n",
      "Eval Loss:  0.3613957166671753\n",
      "Eval Loss:  0.3732989728450775\n",
      "Eval Loss:  0.2943841814994812\n",
      "Eval Loss:  0.35597100853919983\n",
      "[[18398   727]\n",
      " [ 3427  6907]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     19125\n",
      "           1       0.90      0.67      0.77     10334\n",
      "\n",
      "    accuracy                           0.86     29459\n",
      "   macro avg       0.87      0.82      0.83     29459\n",
      "weighted avg       0.86      0.86      0.85     29459\n",
      "\n",
      "acc:  0.8589904613191215\n",
      "pre:  0.9047681425203039\n",
      "rec:  0.6683762337913683\n",
      "ma F1:  0.8336852192528952\n",
      "mi F1:  0.8589904613191215\n",
      "we F1:  0.8530445772725798\n",
      "29459 461\n",
      "Loss:  0.05803970992565155\n",
      "Loss:  0.06793531030416489\n",
      "Loss:  0.08567408472299576\n",
      "9 **********\n",
      "Epoch:  567.7988214492798  fold:  1  kers:  64\n",
      "epoch:  10\n",
      "29459 461\n",
      "Loss:  0.08713612705469131\n",
      "Loss:  0.08085845410823822\n",
      "Loss:  0.08442569524049759\n",
      "10 **********\n",
      "Epoch:  611.7253704071045  fold:  1  kers:  64\n",
      "epoch:  11\n",
      "29459 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.10544799268245697\n",
      "Loss:  0.08867017924785614\n",
      "Loss:  0.08546311408281326\n",
      "11 **********\n",
      "Epoch:  655.6160159111023  fold:  1  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.8654513359069824\n",
      "Eval Loss:  0.486489862203598\n",
      "Eval Loss:  0.09380487352609634\n",
      "[[ 861  178]\n",
      " [ 633 1760]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.83      0.68      1039\n",
      "           1       0.91      0.74      0.81      2393\n",
      "\n",
      "    accuracy                           0.76      3432\n",
      "   macro avg       0.74      0.78      0.75      3432\n",
      "weighted avg       0.81      0.76      0.77      3432\n",
      "\n",
      "acc:  0.7636946386946387\n",
      "pre:  0.9081527347781218\n",
      "rec:  0.7354784788967823\n",
      "ma F1:  0.7462858086693649\n",
      "mi F1:  0.7636946386946387\n",
      "we F1:  0.772505559341468\n",
      "update!  Acc:  0.7636946386946387\n",
      "Eval Loss:  0.3114456236362457\n",
      "Eval Loss:  0.37488430738449097\n",
      "Eval Loss:  0.2829262614250183\n",
      "Eval Loss:  0.23359784483909607\n",
      "Eval Loss:  0.32101091742515564\n",
      "Eval Loss:  0.28930604457855225\n",
      "Eval Loss:  0.3440663516521454\n",
      "Eval Loss:  0.274351567029953\n",
      "Eval Loss:  0.27932608127593994\n",
      "Eval Loss:  0.32036957144737244\n",
      "Eval Loss:  0.4466405212879181\n",
      "Eval Loss:  0.24864956736564636\n",
      "Eval Loss:  0.3390812277793884\n",
      "Eval Loss:  0.4198916554450989\n",
      "Eval Loss:  0.2854388356208801\n",
      "Eval Loss:  0.3561163544654846\n",
      "Eval Loss:  0.3126126825809479\n",
      "Eval Loss:  0.33800914883613586\n",
      "Eval Loss:  0.320076584815979\n",
      "Eval Loss:  0.3178371489048004\n",
      "Eval Loss:  0.41688403487205505\n",
      "Eval Loss:  0.3030696511268616\n",
      "Eval Loss:  0.28367236256599426\n",
      "Eval Loss:  0.29651114344596863\n",
      "Eval Loss:  0.3111976385116577\n",
      "Eval Loss:  0.3211418688297272\n",
      "Eval Loss:  0.2744428515434265\n",
      "Eval Loss:  0.3064609467983246\n",
      "[[18401   724]\n",
      " [ 3005  7329]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     19125\n",
      "           1       0.91      0.71      0.80     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.88      0.84      0.85     29459\n",
      "weighted avg       0.88      0.87      0.87     29459\n",
      "\n",
      "acc:  0.8734172918293222\n",
      "pre:  0.9100956165404197\n",
      "rec:  0.7092123088832979\n",
      "ma F1:  0.8525950089571865\n",
      "mi F1:  0.8734172918293223\n",
      "we F1:  0.8691275856126185\n",
      "29459 461\n",
      "Loss:  0.06529182940721512\n",
      "Loss:  0.0834166631102562\n",
      "Loss:  0.06859692931175232\n",
      "12 **********\n",
      "Epoch:  738.0585811138153  fold:  1  kers:  64\n",
      "epoch:  13\n",
      "29459 461\n",
      "Loss:  0.10562708973884583\n",
      "Loss:  0.07014408707618713\n",
      "Loss:  0.057096634060144424\n",
      "13 **********\n",
      "Epoch:  781.856475353241  fold:  1  kers:  64\n",
      "epoch:  14\n",
      "29459 461\n",
      "Loss:  0.08463863283395767\n",
      "Loss:  0.07338754832744598\n",
      "Loss:  0.06381745636463165\n",
      "14 **********\n",
      "Epoch:  825.6683306694031  fold:  1  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.8920012712478638\n",
      "Eval Loss:  0.6799849271774292\n",
      "Eval Loss:  0.07896233350038528\n",
      "[[ 884  155]\n",
      " [ 848 1545]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.85      0.64      1039\n",
      "           1       0.91      0.65      0.75      2393\n",
      "\n",
      "    accuracy                           0.71      3432\n",
      "   macro avg       0.71      0.75      0.70      3432\n",
      "weighted avg       0.79      0.71      0.72      3432\n",
      "\n",
      "acc:  0.7077505827505828\n",
      "pre:  0.9088235294117647\n",
      "rec:  0.6456330965315503\n",
      "ma F1:  0.6964921405542007\n",
      "mi F1:  0.7077505827505828\n",
      "we F1:  0.7195540629958063\n",
      "Eval Loss:  0.3459671437740326\n",
      "Eval Loss:  0.4454595744609833\n",
      "Eval Loss:  0.3165881931781769\n",
      "Eval Loss:  0.25493887066841125\n",
      "Eval Loss:  0.36206117272377014\n",
      "Eval Loss:  0.3214643895626068\n",
      "Eval Loss:  0.3772083818912506\n",
      "Eval Loss:  0.30612900853157043\n",
      "Eval Loss:  0.3164454400539398\n",
      "Eval Loss:  0.3555654287338257\n",
      "Eval Loss:  0.49695995450019836\n",
      "Eval Loss:  0.2533777952194214\n",
      "Eval Loss:  0.40468019247055054\n",
      "Eval Loss:  0.5031632781028748\n",
      "Eval Loss:  0.3161317706108093\n",
      "Eval Loss:  0.4110446572303772\n",
      "Eval Loss:  0.34902822971343994\n",
      "Eval Loss:  0.38280656933784485\n",
      "Eval Loss:  0.336426317691803\n",
      "Eval Loss:  0.3559175431728363\n",
      "Eval Loss:  0.4844810664653778\n",
      "Eval Loss:  0.34595635533332825\n",
      "Eval Loss:  0.28691112995147705\n",
      "Eval Loss:  0.34375303983688354\n",
      "Eval Loss:  0.3584495484828949\n",
      "Eval Loss:  0.36737626791000366\n",
      "Eval Loss:  0.2998601198196411\n",
      "Eval Loss:  0.3546278178691864\n",
      "[[18647   478]\n",
      " [ 3531  6803]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90     19125\n",
      "           1       0.93      0.66      0.77     10334\n",
      "\n",
      "    accuracy                           0.86     29459\n",
      "   macro avg       0.89      0.82      0.84     29459\n",
      "weighted avg       0.87      0.86      0.86     29459\n",
      "\n",
      "acc:  0.8639125564343664\n",
      "pre:  0.934349677242137\n",
      "rec:  0.6583123669440681\n",
      "ma F1:  0.8376733553102629\n",
      "mi F1:  0.8639125564343663\n",
      "we F1:  0.8571489393259665\n",
      "29459 461\n",
      "Loss:  0.0699414387345314\n",
      "Loss:  0.09460783004760742\n",
      "Loss:  0.0428687185049057\n",
      "15 **********\n",
      "Epoch:  908.0909492969513  fold:  1  kers:  64\n",
      "epoch:  16\n",
      "29459 461\n",
      "Loss:  0.07473843544721603\n",
      "Loss:  0.059027720242738724\n",
      "Loss:  0.07530023902654648\n",
      "16 **********\n",
      "Epoch:  951.9147727489471  fold:  1  kers:  64\n",
      "epoch:  17\n",
      "29459 461\n",
      "Loss:  0.05945155769586563\n",
      "Loss:  0.08484011888504028\n",
      "Loss:  0.07514970004558563\n",
      "17 **********\n",
      "Epoch:  995.7206447124481  fold:  1  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  1.3140100240707397\n",
      "Eval Loss:  0.4128682017326355\n",
      "Eval Loss:  0.0497957319021225\n",
      "[[ 803  236]\n",
      " [ 540 1853]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.77      0.67      1039\n",
      "           1       0.89      0.77      0.83      2393\n",
      "\n",
      "    accuracy                           0.77      3432\n",
      "   macro avg       0.74      0.77      0.75      3432\n",
      "weighted avg       0.80      0.77      0.78      3432\n",
      "\n",
      "acc:  0.7738927738927739\n",
      "pre:  0.8870272857826711\n",
      "rec:  0.7743418303384872\n",
      "ma F1:  0.7505431746577691\n",
      "mi F1:  0.7738927738927739\n",
      "we F1:  0.7806530388141468\n",
      "update!  Acc:  0.7738927738927739\n",
      "Eval Loss:  0.24452267587184906\n",
      "Eval Loss:  0.32345935702323914\n",
      "Eval Loss:  0.2349480539560318\n",
      "Eval Loss:  0.21258364617824554\n",
      "Eval Loss:  0.2848261296749115\n",
      "Eval Loss:  0.25791919231414795\n",
      "Eval Loss:  0.2551196217536926\n",
      "Eval Loss:  0.24562697112560272\n",
      "Eval Loss:  0.25829893350601196\n",
      "Eval Loss:  0.2517085075378418\n",
      "Eval Loss:  0.40809378027915955\n",
      "Eval Loss:  0.20170345902442932\n",
      "Eval Loss:  0.2829241156578064\n",
      "Eval Loss:  0.3702673614025116\n",
      "Eval Loss:  0.27571916580200195\n",
      "Eval Loss:  0.2885693609714508\n",
      "Eval Loss:  0.2456900179386139\n",
      "Eval Loss:  0.30218687653541565\n",
      "Eval Loss:  0.2406262904405594\n",
      "Eval Loss:  0.2718666195869446\n",
      "Eval Loss:  0.3946681320667267\n",
      "Eval Loss:  0.2849128842353821\n",
      "Eval Loss:  0.22577081620693207\n",
      "Eval Loss:  0.28503504395484924\n",
      "Eval Loss:  0.2544996738433838\n",
      "Eval Loss:  0.28031396865844727\n",
      "Eval Loss:  0.26479944586753845\n",
      "Eval Loss:  0.2781103253364563\n",
      "[[18350   775]\n",
      " [ 2458  7876]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     19125\n",
      "           1       0.91      0.76      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.90      0.86      0.87     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.890254251671815\n",
      "pre:  0.9104149809270604\n",
      "rec:  0.7621443777820786\n",
      "ma F1:  0.8743735274625556\n",
      "mi F1:  0.890254251671815\n",
      "we F1:  0.8877024797752919\n",
      "29459 461\n",
      "Loss:  0.06719956547021866\n",
      "Loss:  0.06627368181943893\n",
      "Loss:  0.07051313668489456\n",
      "18 **********\n",
      "Epoch:  1078.2938613891602  fold:  1  kers:  64\n",
      "epoch:  19\n",
      "29459 461\n",
      "Loss:  0.05208821967244148\n",
      "Loss:  0.10615933686494827\n",
      "Loss:  0.09630534052848816\n",
      "19 **********\n",
      "Epoch:  1122.0279252529144  fold:  1  kers:  64\n",
      "epoch:  20\n",
      "29459 461\n",
      "Loss:  0.04984954744577408\n",
      "Loss:  0.0447794646024704\n",
      "Loss:  0.05193174257874489\n",
      "20 **********\n",
      "Epoch:  1165.9205651283264  fold:  1  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  1.218558669090271\n",
      "Eval Loss:  0.36521685123443604\n",
      "Eval Loss:  0.07464037835597992\n",
      "[[ 774  265]\n",
      " [ 424 1969]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69      1039\n",
      "           1       0.88      0.82      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.78      0.77      3432\n",
      "weighted avg       0.81      0.80      0.80      3432\n",
      "\n",
      "acc:  0.7992424242424242\n",
      "pre:  0.8813786929274844\n",
      "rec:  0.8228165482657752\n",
      "ma F1:  0.7715448159087219\n",
      "mi F1:  0.7992424242424242\n",
      "we F1:  0.8029277127152769\n",
      "update!  Acc:  0.7992424242424242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20529137551784515\n",
      "Eval Loss:  0.27838844060897827\n",
      "Eval Loss:  0.20868206024169922\n",
      "Eval Loss:  0.1852884739637375\n",
      "Eval Loss:  0.25360602140426636\n",
      "Eval Loss:  0.256443053483963\n",
      "Eval Loss:  0.2328449785709381\n",
      "Eval Loss:  0.20861484110355377\n",
      "Eval Loss:  0.20085906982421875\n",
      "Eval Loss:  0.24154070019721985\n",
      "Eval Loss:  0.36232849955558777\n",
      "Eval Loss:  0.18295373022556305\n",
      "Eval Loss:  0.26347678899765015\n",
      "Eval Loss:  0.3129372298717499\n",
      "Eval Loss:  0.2569371163845062\n",
      "Eval Loss:  0.27279937267303467\n",
      "Eval Loss:  0.21822461485862732\n",
      "Eval Loss:  0.2848629951477051\n",
      "Eval Loss:  0.2334958165884018\n",
      "Eval Loss:  0.2516784071922302\n",
      "Eval Loss:  0.3244454264640808\n",
      "Eval Loss:  0.23548877239227295\n",
      "Eval Loss:  0.22426894307136536\n",
      "Eval Loss:  0.248646080493927\n",
      "Eval Loss:  0.22183653712272644\n",
      "Eval Loss:  0.2517726421356201\n",
      "Eval Loss:  0.2399297058582306\n",
      "Eval Loss:  0.23743867874145508\n",
      "[[18126   999]\n",
      " [ 1921  8413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     19125\n",
      "           1       0.89      0.81      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9008791880240334\n",
      "pre:  0.8938589035274118\n",
      "rec:  0.8141087671763112\n",
      "ma F1:  0.888789453900749\n",
      "mi F1:  0.9008791880240334\n",
      "we F1:  0.8997315781340234\n",
      "29459 461\n",
      "Loss:  0.06751646846532822\n",
      "Loss:  0.05235827714204788\n",
      "Loss:  0.09273563325405121\n",
      "21 **********\n",
      "Epoch:  1248.3062825202942  fold:  1  kers:  64\n",
      "epoch:  22\n",
      "29459 461\n",
      "Loss:  0.09405922889709473\n",
      "Loss:  0.06758708506822586\n",
      "Loss:  0.05951206386089325\n",
      "22 **********\n",
      "Epoch:  1292.1929388046265  fold:  1  kers:  64\n",
      "epoch:  23\n",
      "29459 461\n",
      "Loss:  0.07618796080350876\n",
      "Loss:  0.08229786157608032\n",
      "Loss:  0.08717213571071625\n",
      "23 **********\n",
      "Epoch:  1336.0756051540375  fold:  1  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  1.2918081283569336\n",
      "Eval Loss:  0.277559757232666\n",
      "Eval Loss:  0.0648227110505104\n",
      "[[ 725  314]\n",
      " [ 329 2064]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69      1039\n",
      "           1       0.87      0.86      0.87      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.78      0.78      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8126456876456877\n",
      "pre:  0.8679562657695542\n",
      "rec:  0.8625156707062265\n",
      "ma F1:  0.7790064455151531\n",
      "mi F1:  0.8126456876456877\n",
      "we F1:  0.8130225275500627\n",
      "update!  Acc:  0.8126456876456877\n",
      "Eval Loss:  0.2191677689552307\n",
      "Eval Loss:  0.2812613546848297\n",
      "Eval Loss:  0.21686263382434845\n",
      "Eval Loss:  0.21069833636283875\n",
      "Eval Loss:  0.233529731631279\n",
      "Eval Loss:  0.2523089349269867\n",
      "Eval Loss:  0.22778983414173126\n",
      "Eval Loss:  0.1979614496231079\n",
      "Eval Loss:  0.18339402973651886\n",
      "Eval Loss:  0.21890868246555328\n",
      "Eval Loss:  0.3381552994251251\n",
      "Eval Loss:  0.17768853902816772\n",
      "Eval Loss:  0.2598746716976166\n",
      "Eval Loss:  0.27270179986953735\n",
      "Eval Loss:  0.2710210680961609\n",
      "Eval Loss:  0.24318702518939972\n",
      "Eval Loss:  0.20050109922885895\n",
      "Eval Loss:  0.24964039027690887\n",
      "Eval Loss:  0.19910432398319244\n",
      "Eval Loss:  0.23339879512786865\n",
      "Eval Loss:  0.316988468170166\n",
      "Eval Loss:  0.24255886673927307\n",
      "Eval Loss:  0.20059658586978912\n",
      "Eval Loss:  0.20295573770999908\n",
      "Eval Loss:  0.2189658135175705\n",
      "Eval Loss:  0.25354811549186707\n",
      "Eval Loss:  0.22612950205802917\n",
      "Eval Loss:  0.21312201023101807\n",
      "[[18059  1066]\n",
      " [ 1713  8621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     19125\n",
      "           1       0.89      0.83      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.89      0.89     29459\n",
      "weighted avg       0.91      0.91      0.90     29459\n",
      "\n",
      "acc:  0.9056655012050646\n",
      "pre:  0.8899556106121607\n",
      "rec:  0.8342365008709115\n",
      "ma F1:  0.8948753229372932\n",
      "mi F1:  0.9056655012050646\n",
      "we F1:  0.9049258057887426\n",
      "29459 461\n",
      "Loss:  0.06858444958925247\n",
      "Loss:  0.09958795458078384\n",
      "Loss:  0.03711399435997009\n",
      "24 **********\n",
      "Epoch:  1418.5381174087524  fold:  1  kers:  64\n",
      "epoch:  25\n",
      "29459 461\n",
      "Loss:  0.057196661829948425\n",
      "Loss:  0.06295768916606903\n",
      "Loss:  0.04641740024089813\n",
      "25 **********\n",
      "Epoch:  1462.452698469162  fold:  1  kers:  64\n",
      "epoch:  26\n",
      "29459 461\n",
      "Loss:  0.06718047708272934\n",
      "Loss:  0.07849035412073135\n",
      "Loss:  0.042274411767721176\n",
      "26 **********\n",
      "Epoch:  1506.311428785324  fold:  1  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  1.3346117734909058\n",
      "Eval Loss:  0.4831843674182892\n",
      "Eval Loss:  0.053335897624492645\n",
      "[[ 807  232]\n",
      " [ 497 1896]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.78      0.69      1039\n",
      "           1       0.89      0.79      0.84      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.75      0.78      0.76      3432\n",
      "weighted avg       0.81      0.79      0.79      3432\n",
      "\n",
      "acc:  0.7875874125874126\n",
      "pre:  0.8909774436090225\n",
      "rec:  0.7923109068115336\n",
      "ma F1:  0.7638064618634168\n",
      "mi F1:  0.7875874125874126\n",
      "we F1:  0.7933743289711214\n",
      "Eval Loss:  0.20018424093723297\n",
      "Eval Loss:  0.30216729640960693\n",
      "Eval Loss:  0.2197197824716568\n",
      "Eval Loss:  0.19490686058998108\n",
      "Eval Loss:  0.2645958364009857\n",
      "Eval Loss:  0.24445152282714844\n",
      "Eval Loss:  0.24699532985687256\n",
      "Eval Loss:  0.19818942248821259\n",
      "Eval Loss:  0.2401820570230484\n",
      "Eval Loss:  0.21962302923202515\n",
      "Eval Loss:  0.38308459520339966\n",
      "Eval Loss:  0.1653565913438797\n",
      "Eval Loss:  0.2472366988658905\n",
      "Eval Loss:  0.34774836897850037\n",
      "Eval Loss:  0.24097667634487152\n",
      "Eval Loss:  0.2558608949184418\n",
      "Eval Loss:  0.229850172996521\n",
      "Eval Loss:  0.27728188037872314\n",
      "Eval Loss:  0.20814435184001923\n",
      "Eval Loss:  0.2401510328054428\n",
      "Eval Loss:  0.3475380837917328\n",
      "Eval Loss:  0.2674126625061035\n",
      "Eval Loss:  0.1964358389377594\n",
      "Eval Loss:  0.2719375789165497\n",
      "Eval Loss:  0.2522866725921631\n",
      "Eval Loss:  0.27631357312202454\n",
      "Eval Loss:  0.23193886876106262\n",
      "Eval Loss:  0.24639521539211273\n",
      "[[18305   820]\n",
      " [ 2037  8297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     19125\n",
      "           1       0.91      0.80      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9030177534878985\n",
      "pre:  0.910058133157837\n",
      "rec:  0.8028836849235533\n",
      "ma F1:  0.8903642501553497\n",
      "mi F1:  0.9030177534878985\n",
      "we F1:  0.9014790530926433\n",
      "29459 461\n",
      "Loss:  0.05471404641866684\n",
      "Loss:  0.06376772373914719\n",
      "Loss:  0.05802128091454506\n",
      "27 **********\n",
      "Epoch:  1588.9654290676117  fold:  1  kers:  64\n",
      "epoch:  28\n",
      "29459 461\n",
      "Loss:  0.08039899170398712\n",
      "Loss:  0.07334855198860168\n",
      "Loss:  0.09831982851028442\n",
      "28 **********\n",
      "Epoch:  1632.7613275051117  fold:  1  kers:  64\n",
      "epoch:  29\n",
      "29459 461\n",
      "Loss:  0.07289594411849976\n",
      "Loss:  0.054480478167533875\n",
      "Loss:  0.0671619400382042\n",
      "29 **********\n",
      "Epoch:  1676.5133440494537  fold:  1  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  1.442895770072937\n",
      "Eval Loss:  0.3420397639274597\n",
      "Eval Loss:  0.20031672716140747\n",
      "[[ 680  359]\n",
      " [ 235 2158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.70      1039\n",
      "           1       0.86      0.90      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.78      0.79      3432\n",
      "weighted avg       0.82      0.83      0.82      3432\n",
      "\n",
      "acc:  0.8269230769230769\n",
      "pre:  0.8573698847834724\n",
      "rec:  0.9017969076473047\n",
      "ma F1:  0.7875152957951417\n",
      "mi F1:  0.8269230769230769\n",
      "we F1:  0.8236168760706656\n",
      "update!  Acc:  0.8269230769230769\n",
      "Eval Loss:  0.19609962403774261\n",
      "Eval Loss:  0.27857935428619385\n",
      "Eval Loss:  0.21292877197265625\n",
      "Eval Loss:  0.1902269721031189\n",
      "Eval Loss:  0.1900358349084854\n",
      "Eval Loss:  0.2968286871910095\n",
      "Eval Loss:  0.25166162848472595\n",
      "Eval Loss:  0.23554089665412903\n",
      "Eval Loss:  0.1926659643650055\n",
      "Eval Loss:  0.23606747388839722\n",
      "Eval Loss:  0.31943732500076294\n",
      "Eval Loss:  0.16192227602005005\n",
      "Eval Loss:  0.2521805465221405\n",
      "Eval Loss:  0.2778458595275879\n",
      "Eval Loss:  0.3040388226509094\n",
      "Eval Loss:  0.2459997534751892\n",
      "Eval Loss:  0.18907327950000763\n",
      "Eval Loss:  0.2653866112232208\n",
      "Eval Loss:  0.21723493933677673\n",
      "Eval Loss:  0.1890801042318344\n",
      "Eval Loss:  0.27205753326416016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2565775215625763\n",
      "Eval Loss:  0.21582762897014618\n",
      "Eval Loss:  0.2279036045074463\n",
      "Eval Loss:  0.18728512525558472\n",
      "Eval Loss:  0.21964046359062195\n",
      "Eval Loss:  0.20029929280281067\n",
      "Eval Loss:  0.23142844438552856\n",
      "[[17680  1445]\n",
      " [ 1305  9029]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     19125\n",
      "           1       0.86      0.87      0.87     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.90      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9066499202281136\n",
      "pre:  0.8620393354974222\n",
      "rec:  0.8737178246564737\n",
      "ma F1:  0.8978398772004106\n",
      "mi F1:  0.9066499202281136\n",
      "we F1:  0.9067924940373702\n",
      "29459 461\n",
      "Loss:  0.08639059215784073\n",
      "Loss:  0.06798800826072693\n",
      "Loss:  0.07810717821121216\n",
      "30 **********\n",
      "Epoch:  1763.9744901657104  fold:  1  kers:  64\n",
      "epoch:  31\n",
      "29459 461\n",
      "Loss:  0.07539910823106766\n",
      "Loss:  0.04111308604478836\n",
      "Loss:  0.058123279362916946\n",
      "31 **********\n",
      "Epoch:  1807.8003091812134  fold:  1  kers:  64\n",
      "epoch:  32\n",
      "29459 461\n",
      "Loss:  0.042536232620477676\n",
      "Loss:  0.03203418850898743\n",
      "Loss:  0.05110287293791771\n",
      "32 **********\n",
      "Epoch:  1851.7118985652924  fold:  1  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  1.2812718152999878\n",
      "Eval Loss:  0.3280903995037079\n",
      "Eval Loss:  0.2080414891242981\n",
      "[[ 706  333]\n",
      " [ 240 2153]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71      1039\n",
      "           1       0.87      0.90      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.81      0.79      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.833041958041958\n",
      "pre:  0.8660498793242156\n",
      "rec:  0.8997074801504388\n",
      "ma F1:  0.7969464569018614\n",
      "mi F1:  0.833041958041958\n",
      "we F1:  0.8307220675056561\n",
      "update!  Acc:  0.833041958041958\n",
      "Eval Loss:  0.20611314475536346\n",
      "Eval Loss:  0.28017112612724304\n",
      "Eval Loss:  0.22612714767456055\n",
      "Eval Loss:  0.18245302140712738\n",
      "Eval Loss:  0.2259344607591629\n",
      "Eval Loss:  0.29721319675445557\n",
      "Eval Loss:  0.2588792145252228\n",
      "Eval Loss:  0.22999311983585358\n",
      "Eval Loss:  0.16632020473480225\n",
      "Eval Loss:  0.22576826810836792\n",
      "Eval Loss:  0.34953346848487854\n",
      "Eval Loss:  0.1675761640071869\n",
      "Eval Loss:  0.22974362969398499\n",
      "Eval Loss:  0.2741428017616272\n",
      "Eval Loss:  0.26926711201667786\n",
      "Eval Loss:  0.23915870487689972\n",
      "Eval Loss:  0.21401144564151764\n",
      "Eval Loss:  0.2817375361919403\n",
      "Eval Loss:  0.22000707685947418\n",
      "Eval Loss:  0.20281670987606049\n",
      "Eval Loss:  0.2778063118457794\n",
      "Eval Loss:  0.22999964654445648\n",
      "Eval Loss:  0.22891156375408173\n",
      "Eval Loss:  0.22824250161647797\n",
      "Eval Loss:  0.1919187605381012\n",
      "Eval Loss:  0.24359682202339172\n",
      "Eval Loss:  0.18358692526817322\n",
      "Eval Loss:  0.21226486563682556\n",
      "[[17870  1255]\n",
      " [ 1470  8864]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     19125\n",
      "           1       0.88      0.86      0.87     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.90      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.907498557316949\n",
      "pre:  0.8759758869453503\n",
      "rec:  0.8577511128314302\n",
      "ma F1:  0.8979620436321784\n",
      "mi F1:  0.9074985573169491\n",
      "we F1:  0.9072708923777723\n",
      "29459 461\n",
      "Loss:  0.036667101085186005\n",
      "Loss:  0.06852525472640991\n",
      "Loss:  0.044214747846126556\n",
      "33 **********\n",
      "Epoch:  1934.3499410152435  fold:  1  kers:  64\n",
      "epoch:  34\n",
      "29459 461\n",
      "Loss:  0.06137934327125549\n",
      "Loss:  0.0687846690416336\n",
      "Loss:  0.07247022539377213\n",
      "34 **********\n",
      "Epoch:  1978.354282617569  fold:  1  kers:  64\n",
      "epoch:  35\n",
      "29459 461\n",
      "Loss:  0.039429306983947754\n",
      "Loss:  0.04409472644329071\n",
      "Loss:  0.05973322317004204\n",
      "35 **********\n",
      "Epoch:  2022.2499146461487  fold:  1  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  1.495619535446167\n",
      "Eval Loss:  0.3523196876049042\n",
      "Eval Loss:  0.13272395730018616\n",
      "[[ 699  340]\n",
      " [ 245 2148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70      1039\n",
      "           1       0.86      0.90      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.79      0.79      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8295454545454546\n",
      "pre:  0.8633440514469454\n",
      "rec:  0.897618052653573\n",
      "ma F1:  0.7925699732297361\n",
      "mi F1:  0.8295454545454547\n",
      "we F1:  0.8271212511465634\n",
      "Eval Loss:  0.2082003504037857\n",
      "Eval Loss:  0.24636265635490417\n",
      "Eval Loss:  0.180767223238945\n",
      "Eval Loss:  0.16342198848724365\n",
      "Eval Loss:  0.19611623883247375\n",
      "Eval Loss:  0.2633386552333832\n",
      "Eval Loss:  0.26372236013412476\n",
      "Eval Loss:  0.22568172216415405\n",
      "Eval Loss:  0.16732043027877808\n",
      "Eval Loss:  0.22313687205314636\n",
      "Eval Loss:  0.3103214204311371\n",
      "Eval Loss:  0.14684541523456573\n",
      "Eval Loss:  0.2213578224182129\n",
      "Eval Loss:  0.2680397629737854\n",
      "Eval Loss:  0.2655382752418518\n",
      "Eval Loss:  0.2165135145187378\n",
      "Eval Loss:  0.20186935365200043\n",
      "Eval Loss:  0.23729364573955536\n",
      "Eval Loss:  0.20062001049518585\n",
      "Eval Loss:  0.18400456011295319\n",
      "Eval Loss:  0.2843700647354126\n",
      "Eval Loss:  0.2502831220626831\n",
      "Eval Loss:  0.2278592884540558\n",
      "Eval Loss:  0.20240235328674316\n",
      "Eval Loss:  0.19792157411575317\n",
      "Eval Loss:  0.2083127498626709\n",
      "Eval Loss:  0.18372128903865814\n",
      "Eval Loss:  0.2189762145280838\n",
      "[[17945  1180]\n",
      " [ 1325  9009]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     19125\n",
      "           1       0.88      0.87      0.88     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.91      0.91     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9149665636986999\n",
      "pre:  0.8841888310923545\n",
      "rec:  0.8717824656473776\n",
      "ma F1:  0.9063494756028792\n",
      "mi F1:  0.9149665636986999\n",
      "we F1:  0.9148267385225703\n",
      "29459 461\n",
      "Loss:  0.0415109358727932\n",
      "Loss:  0.07743193954229355\n",
      "Loss:  0.03322748839855194\n",
      "36 **********\n",
      "Epoch:  2104.78822350502  fold:  1  kers:  64\n",
      "epoch:  37\n",
      "29459 461\n",
      "Loss:  0.09008470177650452\n",
      "Loss:  0.055590759962797165\n",
      "Loss:  0.05679730325937271\n",
      "37 **********\n",
      "Epoch:  2148.7347197532654  fold:  1  kers:  64\n",
      "epoch:  38\n",
      "29459 461\n",
      "Loss:  0.040818266570568085\n",
      "Loss:  0.06019170954823494\n",
      "Loss:  0.0369381383061409\n",
      "38 **********\n",
      "Epoch:  2192.590458393097  fold:  1  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  1.006730318069458\n",
      "Eval Loss:  0.3654014468193054\n",
      "Eval Loss:  0.11161036044359207\n",
      "[[ 751  288]\n",
      " [ 302 2091]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72      1039\n",
      "           1       0.88      0.87      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.80      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.828088578088578\n",
      "pre:  0.8789407313997478\n",
      "rec:  0.8737985791893021\n",
      "ma F1:  0.7971676718397152\n",
      "mi F1:  0.828088578088578\n",
      "we F1:  0.8284116323329692\n",
      "Eval Loss:  0.2151256501674652\n",
      "Eval Loss:  0.25839942693710327\n",
      "Eval Loss:  0.18940576910972595\n",
      "Eval Loss:  0.19200780987739563\n",
      "Eval Loss:  0.21445077657699585\n",
      "Eval Loss:  0.2369438111782074\n",
      "Eval Loss:  0.240229532122612\n",
      "Eval Loss:  0.20416951179504395\n",
      "Eval Loss:  0.19122472405433655\n",
      "Eval Loss:  0.18857957422733307\n",
      "Eval Loss:  0.3243023455142975\n",
      "Eval Loss:  0.1526707261800766\n",
      "Eval Loss:  0.1999916434288025\n",
      "Eval Loss:  0.30208685994148254\n",
      "Eval Loss:  0.21576625108718872\n",
      "Eval Loss:  0.23691456019878387\n",
      "Eval Loss:  0.19859205186367035\n",
      "Eval Loss:  0.2409985065460205\n",
      "Eval Loss:  0.18811120092868805\n",
      "Eval Loss:  0.20660065114498138\n",
      "Eval Loss:  0.2707761228084564\n",
      "Eval Loss:  0.28229740262031555\n",
      "Eval Loss:  0.18970228731632233\n",
      "Eval Loss:  0.21299512684345245\n",
      "Eval Loss:  0.2198764830827713\n",
      "Eval Loss:  0.21752506494522095\n",
      "Eval Loss:  0.21665158867835999\n",
      "Eval Loss:  0.21491572260856628\n",
      "[[18156   969]\n",
      " [ 1551  8783]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     19125\n",
      "           1       0.90      0.85      0.87     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.90      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9144573814453987\n",
      "pre:  0.9006357670221493\n",
      "rec:  0.8499129088445907\n",
      "ma F1:  0.9048222741100782\n",
      "mi F1:  0.9144573814453987\n",
      "we F1:  0.9138591063500017\n",
      "29459 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05233868956565857\n",
      "Loss:  0.0500798299908638\n",
      "Loss:  0.055869922041893005\n",
      "39 **********\n",
      "Epoch:  2275.0888743400574  fold:  1  kers:  64\n",
      "epoch:  40\n",
      "29459 461\n",
      "Loss:  0.061300128698349\n",
      "Loss:  0.04492068663239479\n",
      "Loss:  0.05641471967101097\n",
      "40 **********\n",
      "Epoch:  2318.996474504471  fold:  1  kers:  64\n",
      "epoch:  41\n",
      "29459 461\n",
      "Loss:  0.054232798516750336\n",
      "Loss:  0.08895162492990494\n",
      "Loss:  0.04708211123943329\n",
      "41 **********\n",
      "Epoch:  2362.8133170604706  fold:  1  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  1.4812467098236084\n",
      "Eval Loss:  0.3524627089500427\n",
      "Eval Loss:  0.17672035098075867\n",
      "[[ 633  406]\n",
      " [ 259 2134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66      1039\n",
      "           1       0.84      0.89      0.87      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.75      0.76      3432\n",
      "weighted avg       0.80      0.81      0.80      3432\n",
      "\n",
      "acc:  0.8062354312354313\n",
      "pre:  0.8401574803149606\n",
      "rec:  0.8917676556623485\n",
      "ma F1:  0.7604062222491904\n",
      "mi F1:  0.8062354312354313\n",
      "we F1:  0.8017471609349799\n",
      "Eval Loss:  0.22268205881118774\n",
      "Eval Loss:  0.25054576992988586\n",
      "Eval Loss:  0.22040876746177673\n",
      "Eval Loss:  0.17565970122814178\n",
      "Eval Loss:  0.17222629487514496\n",
      "Eval Loss:  0.25446566939353943\n",
      "Eval Loss:  0.24500863254070282\n",
      "Eval Loss:  0.20472121238708496\n",
      "Eval Loss:  0.19993548095226288\n",
      "Eval Loss:  0.2077532559633255\n",
      "Eval Loss:  0.28246933221817017\n",
      "Eval Loss:  0.16153652966022491\n",
      "Eval Loss:  0.2249307632446289\n",
      "Eval Loss:  0.26503661274909973\n",
      "Eval Loss:  0.28274089097976685\n",
      "Eval Loss:  0.22382569313049316\n",
      "Eval Loss:  0.18415771424770355\n",
      "Eval Loss:  0.23359033465385437\n",
      "Eval Loss:  0.20450928807258606\n",
      "Eval Loss:  0.1879458725452423\n",
      "Eval Loss:  0.2220345139503479\n",
      "Eval Loss:  0.31303009390830994\n",
      "Eval Loss:  0.2153303474187851\n",
      "Eval Loss:  0.18926353752613068\n",
      "Eval Loss:  0.21512234210968018\n",
      "Eval Loss:  0.19741027057170868\n",
      "Eval Loss:  0.19929605722427368\n",
      "Eval Loss:  0.2027660757303238\n",
      "[[17557  1568]\n",
      " [  986  9348]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93     19125\n",
      "           1       0.86      0.90      0.88     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.91      0.91     29459\n",
      "weighted avg       0.92      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9133032350045827\n",
      "pre:  0.8563576401612312\n",
      "rec:  0.904586800851558\n",
      "ma F1:  0.9060044275371824\n",
      "mi F1:  0.9133032350045825\n",
      "we F1:  0.9138207043609021\n",
      "29459 461\n",
      "Loss:  0.06106831878423691\n",
      "Loss:  0.04724343866109848\n",
      "Loss:  0.03455808758735657\n",
      "42 **********\n",
      "Epoch:  2445.426426410675  fold:  1  kers:  64\n",
      "epoch:  43\n",
      "29459 461\n",
      "Loss:  0.08320534974336624\n",
      "Loss:  0.028528396040201187\n",
      "Loss:  0.04200822860002518\n",
      "43 **********\n",
      "Epoch:  2489.245263338089  fold:  1  kers:  64\n",
      "epoch:  44\n",
      "29459 461\n",
      "Loss:  0.061945777386426926\n",
      "Loss:  0.06189460679888725\n",
      "Loss:  0.0628957450389862\n",
      "44 **********\n",
      "Epoch:  2533.0321865081787  fold:  1  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  1.067359447479248\n",
      "Eval Loss:  0.28649190068244934\n",
      "Eval Loss:  0.1556313931941986\n",
      "[[ 715  324]\n",
      " [ 344 2049]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68      1039\n",
      "           1       0.86      0.86      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.77      0.77      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8053613053613053\n",
      "pre:  0.8634639696586599\n",
      "rec:  0.856247388215629\n",
      "ma F1:  0.7707210312001078\n",
      "mi F1:  0.8053613053613053\n",
      "we F1:  0.8058806498015032\n",
      "Eval Loss:  0.22307772934436798\n",
      "Eval Loss:  0.22176267206668854\n",
      "Eval Loss:  0.20038104057312012\n",
      "Eval Loss:  0.18861205875873566\n",
      "Eval Loss:  0.17913667857646942\n",
      "Eval Loss:  0.2258215993642807\n",
      "Eval Loss:  0.24690929055213928\n",
      "Eval Loss:  0.18765191733837128\n",
      "Eval Loss:  0.1654679924249649\n",
      "Eval Loss:  0.18339714407920837\n",
      "Eval Loss:  0.3188098967075348\n",
      "Eval Loss:  0.1598130762577057\n",
      "Eval Loss:  0.2193790078163147\n",
      "Eval Loss:  0.26367470622062683\n",
      "Eval Loss:  0.24282552301883698\n",
      "Eval Loss:  0.23863068222999573\n",
      "Eval Loss:  0.18345998227596283\n",
      "Eval Loss:  0.22585712373256683\n",
      "Eval Loss:  0.19961391389369965\n",
      "Eval Loss:  0.19373013079166412\n",
      "Eval Loss:  0.22473198175430298\n",
      "Eval Loss:  0.29830077290534973\n",
      "Eval Loss:  0.19780664145946503\n",
      "Eval Loss:  0.18018773198127747\n",
      "Eval Loss:  0.21828202903270721\n",
      "Eval Loss:  0.21751421689987183\n",
      "Eval Loss:  0.21512991189956665\n",
      "Eval Loss:  0.20156541466712952\n",
      "[[18106  1019]\n",
      " [ 1405  8929]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.90      0.86      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.91      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9177161478665263\n",
      "pre:  0.89756735022115\n",
      "rec:  0.8640410296109928\n",
      "ma F1:  0.9088728726182486\n",
      "mi F1:  0.9177161478665263\n",
      "we F1:  0.9173441848888828\n",
      "29459 461\n",
      "Loss:  0.03973759338259697\n",
      "Loss:  0.05941610038280487\n",
      "Loss:  0.06078292429447174\n",
      "45 **********\n",
      "Epoch:  2615.529605150223  fold:  1  kers:  64\n",
      "epoch:  46\n",
      "29459 461\n",
      "Loss:  0.040663860738277435\n",
      "Loss:  0.056448351591825485\n",
      "Loss:  0.0353974923491478\n",
      "46 **********\n",
      "Epoch:  2659.3683891296387  fold:  1  kers:  64\n",
      "epoch:  47\n",
      "29459 461\n",
      "Loss:  0.055783286690711975\n",
      "Loss:  0.0509108267724514\n",
      "Loss:  0.07517498731613159\n",
      "47 **********\n",
      "Epoch:  2703.220138311386  fold:  1  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  1.3847055435180664\n",
      "Eval Loss:  0.3173239231109619\n",
      "Eval Loss:  0.2095886617898941\n",
      "[[ 599  440]\n",
      " [ 301 2092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62      1039\n",
      "           1       0.83      0.87      0.85      2393\n",
      "\n",
      "    accuracy                           0.78      3432\n",
      "   macro avg       0.75      0.73      0.73      3432\n",
      "weighted avg       0.78      0.78      0.78      3432\n",
      "\n",
      "acc:  0.7840909090909091\n",
      "pre:  0.8262243285939969\n",
      "rec:  0.8742164646886753\n",
      "ma F1:  0.7336936984106623\n",
      "mi F1:  0.7840909090909092\n",
      "we F1:  0.7793988713919443\n",
      "Eval Loss:  0.21431410312652588\n",
      "Eval Loss:  0.2397322952747345\n",
      "Eval Loss:  0.1965552419424057\n",
      "Eval Loss:  0.1561708152294159\n",
      "Eval Loss:  0.1622520238161087\n",
      "Eval Loss:  0.23349612951278687\n",
      "Eval Loss:  0.26943641901016235\n",
      "Eval Loss:  0.1990131139755249\n",
      "Eval Loss:  0.1625354140996933\n",
      "Eval Loss:  0.1875484138727188\n",
      "Eval Loss:  0.28714969754219055\n",
      "Eval Loss:  0.14431343972682953\n",
      "Eval Loss:  0.2113407552242279\n",
      "Eval Loss:  0.25535741448402405\n",
      "Eval Loss:  0.2543097734451294\n",
      "Eval Loss:  0.21559487283229828\n",
      "Eval Loss:  0.17878548800945282\n",
      "Eval Loss:  0.21852724254131317\n",
      "Eval Loss:  0.2012067437171936\n",
      "Eval Loss:  0.17618177831172943\n",
      "Eval Loss:  0.21894067525863647\n",
      "Eval Loss:  0.30515357851982117\n",
      "Eval Loss:  0.19717703759670258\n",
      "Eval Loss:  0.188304603099823\n",
      "Eval Loss:  0.22920279204845428\n",
      "Eval Loss:  0.19504694640636444\n",
      "Eval Loss:  0.2046024352312088\n",
      "Eval Loss:  0.19598375260829926\n",
      "[[17862  1263]\n",
      " [ 1164  9170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     19125\n",
      "           1       0.88      0.89      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.91      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9176143114158661\n",
      "pre:  0.8789418192274514\n",
      "rec:  0.8873621056706019\n",
      "ma F1:  0.9097581296630969\n",
      "mi F1:  0.9176143114158661\n",
      "we F1:  0.9177037916268099\n",
      "29459 461\n",
      "Loss:  0.07964847981929779\n",
      "Loss:  0.0389162078499794\n",
      "Loss:  0.07095487415790558\n",
      "48 **********\n",
      "Epoch:  2785.7664268016815  fold:  1  kers:  64\n",
      "epoch:  49\n",
      "29459 461\n",
      "Loss:  0.045581474900245667\n",
      "Loss:  0.06603999435901642\n",
      "Loss:  0.07159609347581863\n",
      "49 **********\n",
      "Epoch:  2829.5533487796783  fold:  1  kers:  64\n",
      "epoch:  50\n",
      "29459 461\n",
      "Loss:  0.05879747122526169\n",
      "Loss:  0.03827384486794472\n",
      "Loss:  0.06880214065313339\n",
      "50 **********\n",
      "Epoch:  2873.3981170654297  fold:  1  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  1.797438144683838\n",
      "Eval Loss:  0.3623213768005371\n",
      "Eval Loss:  0.1654496043920517\n",
      "[[ 670  369]\n",
      " [ 386 2007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1039\n",
      "           1       0.84      0.84      0.84      2393\n",
      "\n",
      "    accuracy                           0.78      3432\n",
      "   macro avg       0.74      0.74      0.74      3432\n",
      "weighted avg       0.78      0.78      0.78      3432\n",
      "\n",
      "acc:  0.780011655011655\n",
      "pre:  0.8446969696969697\n",
      "rec:  0.8386961972419557\n",
      "ma F1:  0.7406520132258305\n",
      "mi F1:  0.7800116550116551\n",
      "we F1:  0.7805121141817066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2099418193101883\n",
      "Eval Loss:  0.20281071960926056\n",
      "Eval Loss:  0.18781477212905884\n",
      "Eval Loss:  0.13936719298362732\n",
      "Eval Loss:  0.155893474817276\n",
      "Eval Loss:  0.19747395813465118\n",
      "Eval Loss:  0.23815248906612396\n",
      "Eval Loss:  0.18163646757602692\n",
      "Eval Loss:  0.16313965618610382\n",
      "Eval Loss:  0.17160636186599731\n",
      "Eval Loss:  0.2887706458568573\n",
      "Eval Loss:  0.14474308490753174\n",
      "Eval Loss:  0.2088964581489563\n",
      "Eval Loss:  0.24772034585475922\n",
      "Eval Loss:  0.23642994463443756\n",
      "Eval Loss:  0.19690784811973572\n",
      "Eval Loss:  0.16085916757583618\n",
      "Eval Loss:  0.2010151445865631\n",
      "Eval Loss:  0.1842232197523117\n",
      "Eval Loss:  0.15951651334762573\n",
      "Eval Loss:  0.21329309046268463\n",
      "Eval Loss:  0.2857177257537842\n",
      "Eval Loss:  0.20378336310386658\n",
      "Eval Loss:  0.14365124702453613\n",
      "Eval Loss:  0.21852263808250427\n",
      "Eval Loss:  0.17880496382713318\n",
      "Eval Loss:  0.1748582422733307\n",
      "Eval Loss:  0.19905872642993927\n",
      "[[18056  1069]\n",
      " [ 1185  9149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     19125\n",
      "           1       0.90      0.89      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.92     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9234868800706066\n",
      "pre:  0.8953807007242122\n",
      "rec:  0.8853299787110509\n",
      "ma F1:  0.9157885203193505\n",
      "mi F1:  0.9234868800706066\n",
      "we F1:  0.9233866207542097\n",
      "29459 461\n",
      "Loss:  0.06396085023880005\n",
      "Loss:  0.0672721415758133\n",
      "Loss:  0.069776751101017\n",
      "51 **********\n",
      "Epoch:  2955.924458503723  fold:  1  kers:  64\n",
      "epoch:  52\n",
      "29459 461\n",
      "Loss:  0.06443718820810318\n",
      "Loss:  0.044888872653245926\n",
      "Loss:  0.0660419836640358\n",
      "52 **********\n",
      "Epoch:  2999.8968851566315  fold:  1  kers:  64\n",
      "epoch:  53\n",
      "29459 461\n",
      "Loss:  0.05702358856797218\n",
      "Loss:  0.05469396337866783\n",
      "Loss:  0.04617403820157051\n",
      "53 **********\n",
      "Epoch:  3043.855349302292  fold:  1  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  1.6651159524917603\n",
      "Eval Loss:  0.3697991371154785\n",
      "Eval Loss:  0.13106730580329895\n",
      "[[ 712  327]\n",
      " [ 395 1998]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66      1039\n",
      "           1       0.86      0.83      0.85      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.75      0.76      0.76      3432\n",
      "weighted avg       0.79      0.79      0.79      3432\n",
      "\n",
      "acc:  0.7896270396270396\n",
      "pre:  0.8593548387096774\n",
      "rec:  0.8349352277475972\n",
      "ma F1:  0.7552645832600811\n",
      "mi F1:  0.7896270396270395\n",
      "we F1:  0.7914440279885895\n",
      "Eval Loss:  0.20787398517131805\n",
      "Eval Loss:  0.20291945338249207\n",
      "Eval Loss:  0.17836061120033264\n",
      "Eval Loss:  0.14133967459201813\n",
      "Eval Loss:  0.19082854688167572\n",
      "Eval Loss:  0.1838354468345642\n",
      "Eval Loss:  0.2446175068616867\n",
      "Eval Loss:  0.19041891396045685\n",
      "Eval Loss:  0.17254996299743652\n",
      "Eval Loss:  0.17553310096263885\n",
      "Eval Loss:  0.2909577488899231\n",
      "Eval Loss:  0.14401262998580933\n",
      "Eval Loss:  0.18360893428325653\n",
      "Eval Loss:  0.26726439595222473\n",
      "Eval Loss:  0.23063363134860992\n",
      "Eval Loss:  0.22442254424095154\n",
      "Eval Loss:  0.18380753695964813\n",
      "Eval Loss:  0.19634288549423218\n",
      "Eval Loss:  0.17787383496761322\n",
      "Eval Loss:  0.17905931174755096\n",
      "Eval Loss:  0.23282217979431152\n",
      "Eval Loss:  0.2829533517360687\n",
      "Eval Loss:  0.18050318956375122\n",
      "Eval Loss:  0.16755615174770355\n",
      "Eval Loss:  0.210249125957489\n",
      "Eval Loss:  0.19702422618865967\n",
      "Eval Loss:  0.19283215701580048\n",
      "Eval Loss:  0.1864796131849289\n",
      "[[18217   908]\n",
      " [ 1378  8956]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.91      0.87      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9224006245968974\n",
      "pre:  0.907948094079481\n",
      "rec:  0.8666537642732727\n",
      "ma F1:  0.9138906105383153\n",
      "mi F1:  0.9224006245968974\n",
      "we F1:  0.9219687374780621\n",
      "29459 461\n",
      "Loss:  0.04390137270092964\n",
      "Loss:  0.06355743855237961\n",
      "Loss:  0.06888655573129654\n",
      "54 **********\n",
      "Epoch:  3126.184218645096  fold:  1  kers:  64\n",
      "epoch:  55\n",
      "29459 461\n",
      "Loss:  0.06353963166475296\n",
      "Loss:  0.08066413551568985\n",
      "Loss:  0.06079062446951866\n",
      "55 **********\n",
      "Epoch:  3170.1107680797577  fold:  1  kers:  64\n",
      "epoch:  56\n",
      "29459 461\n",
      "Loss:  0.04577092453837395\n",
      "Loss:  0.043467264622449875\n",
      "Loss:  0.054366450756788254\n",
      "56 **********\n",
      "Epoch:  3214.0492849349976  fold:  1  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  1.5379549264907837\n",
      "Eval Loss:  0.31558725237846375\n",
      "Eval Loss:  0.14272190630435944\n",
      "[[ 674  365]\n",
      " [ 339 2054]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1039\n",
      "           1       0.85      0.86      0.85      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.76      0.75      0.76      3432\n",
      "weighted avg       0.79      0.79      0.79      3432\n",
      "\n",
      "acc:  0.7948717948717948\n",
      "pre:  0.8491112029764365\n",
      "rec:  0.8583368157124948\n",
      "ma F1:  0.7553095817959974\n",
      "mi F1:  0.7948717948717948\n",
      "we F1:  0.7941264198428305\n",
      "Eval Loss:  0.20887485146522522\n",
      "Eval Loss:  0.213240846991539\n",
      "Eval Loss:  0.19952018558979034\n",
      "Eval Loss:  0.14026404917240143\n",
      "Eval Loss:  0.157949298620224\n",
      "Eval Loss:  0.1815107762813568\n",
      "Eval Loss:  0.24598386883735657\n",
      "Eval Loss:  0.1733032912015915\n",
      "Eval Loss:  0.15874041616916656\n",
      "Eval Loss:  0.1741887778043747\n",
      "Eval Loss:  0.26808181405067444\n",
      "Eval Loss:  0.14416292309761047\n",
      "Eval Loss:  0.2003997564315796\n",
      "Eval Loss:  0.26194557547569275\n",
      "Eval Loss:  0.24606609344482422\n",
      "Eval Loss:  0.20478390157222748\n",
      "Eval Loss:  0.16816261410713196\n",
      "Eval Loss:  0.1953004002571106\n",
      "Eval Loss:  0.1698978692293167\n",
      "Eval Loss:  0.16582046449184418\n",
      "Eval Loss:  0.2105816900730133\n",
      "Eval Loss:  0.29955244064331055\n",
      "Eval Loss:  0.17601557075977325\n",
      "Eval Loss:  0.16104906797409058\n",
      "Eval Loss:  0.21479973196983337\n",
      "Eval Loss:  0.17965903878211975\n",
      "Eval Loss:  0.18290136754512787\n",
      "Eval Loss:  0.17335790395736694\n",
      "[[18137   988]\n",
      " [ 1264  9070]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.90      0.88      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.92     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9235547710377134\n",
      "pre:  0.9017697355339034\n",
      "rec:  0.877685310625121\n",
      "ma F1:  0.9155552520339192\n",
      "mi F1:  0.9235547710377134\n",
      "we F1:  0.9233112652204588\n",
      "29459 461\n",
      "Loss:  0.05885506793856621\n",
      "Loss:  0.05165300518274307\n",
      "Loss:  0.059888824820518494\n",
      "57 **********\n",
      "Epoch:  3296.6055467128754  fold:  1  kers:  64\n",
      "epoch:  58\n",
      "29459 461\n",
      "Loss:  0.03867674618959427\n",
      "Loss:  0.07001970708370209\n",
      "Loss:  0.058268602937459946\n",
      "58 **********\n",
      "Epoch:  3340.548053264618  fold:  1  kers:  64\n",
      "epoch:  59\n",
      "29459 461\n",
      "Loss:  0.07169361412525177\n",
      "Loss:  0.053703758865594864\n",
      "Loss:  0.08128029108047485\n",
      "59 **********\n",
      "Epoch:  3384.4287252426147  fold:  1  kers:  64\n",
      "Eval Loss:  1.7723966836929321\n",
      "Eval Loss:  0.3881421983242035\n",
      "Eval Loss:  0.3306797742843628\n",
      "[[ 582  457]\n",
      " [ 278 2115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.56      0.61      1039\n",
      "           1       0.82      0.88      0.85      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.75      0.72      0.73      3432\n",
      "weighted avg       0.78      0.79      0.78      3432\n",
      "\n",
      "acc:  0.7858391608391608\n",
      "pre:  0.8223172628304821\n",
      "rec:  0.8838278311742582\n",
      "ma F1:  0.7324589663187335\n",
      "mi F1:  0.7858391608391608\n",
      "we F1:  0.7796062483674345\n",
      "update!  Acc:  0.833041958041958\n",
      "Epoch:  3388.470917224884  fold:  1  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29797 3094\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29797 466\n",
      "Loss:  0.16796964406967163\n",
      "Loss:  0.16056202352046967\n",
      "Loss:  0.15955282747745514\n",
      "0 **********\n",
      "Epoch:  56.74128556251526  fold:  2  kers:  64\n",
      "epoch:  1\n",
      "29797 466\n",
      "Loss:  0.1475857049226761\n",
      "Loss:  0.13591217994689941\n",
      "Loss:  0.12749449908733368\n",
      "1 **********\n",
      "Epoch:  101.04981327056885  fold:  2  kers:  64\n",
      "epoch:  2\n",
      "29797 466\n",
      "Loss:  0.09207093715667725\n",
      "Loss:  0.12236316502094269\n",
      "Loss:  0.12239044904708862\n",
      "2 **********\n",
      "Epoch:  145.28753066062927  fold:  2  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  1.0862672328948975\n",
      "Eval Loss:  0.08354391157627106\n",
      "Eval Loss:  0.82359379529953\n",
      "[[1277  153]\n",
      " [ 756  908]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.89      0.74      1430\n",
      "           1       0.86      0.55      0.67      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.74      0.72      0.70      3094\n",
      "weighted avg       0.75      0.71      0.70      3094\n",
      "\n",
      "acc:  0.7062055591467357\n",
      "pre:  0.8557964184731386\n",
      "rec:  0.5456730769230769\n",
      "ma F1:  0.7019664235549068\n",
      "mi F1:  0.7062055591467357\n",
      "we F1:  0.6992781912283812\n",
      "update!  Acc:  0.7062055591467357\n",
      "Eval Loss:  0.43236932158470154\n",
      "Eval Loss:  0.3323097825050354\n",
      "Eval Loss:  0.40547633171081543\n",
      "Eval Loss:  0.4962341785430908\n",
      "Eval Loss:  0.3880194127559662\n",
      "Eval Loss:  0.40923014283180237\n",
      "Eval Loss:  0.39767760038375854\n",
      "Eval Loss:  0.476119726896286\n",
      "Eval Loss:  0.3292343318462372\n",
      "Eval Loss:  0.42493677139282227\n",
      "Eval Loss:  0.4574337303638458\n",
      "Eval Loss:  0.3421265780925751\n",
      "Eval Loss:  0.44801604747772217\n",
      "Eval Loss:  0.31204327940940857\n",
      "Eval Loss:  0.39772266149520874\n",
      "Eval Loss:  0.44109299778938293\n",
      "Eval Loss:  0.3499377369880676\n",
      "Eval Loss:  0.40945300459861755\n",
      "Eval Loss:  0.4493649899959564\n",
      "Eval Loss:  0.38977524638175964\n",
      "Eval Loss:  0.3793916404247284\n",
      "Eval Loss:  0.4030458927154541\n",
      "Eval Loss:  0.45779308676719666\n",
      "Eval Loss:  0.4155753254890442\n",
      "Eval Loss:  0.39705395698547363\n",
      "Eval Loss:  0.43429121375083923\n",
      "Eval Loss:  0.4572453498840332\n",
      "Eval Loss:  0.42108163237571716\n",
      "Eval Loss:  0.3427061140537262\n",
      "[[17073  1661]\n",
      " [ 3142  7921]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.88     18734\n",
      "           1       0.83      0.72      0.77     11063\n",
      "\n",
      "    accuracy                           0.84     29797\n",
      "   macro avg       0.84      0.81      0.82     29797\n",
      "weighted avg       0.84      0.84      0.84     29797\n",
      "\n",
      "acc:  0.8388092761016209\n",
      "pre:  0.8266541431851389\n",
      "rec:  0.7159902377293682\n",
      "ma F1:  0.8220188827885235\n",
      "mi F1:  0.8388092761016209\n",
      "we F1:  0.8360922117990972\n",
      "29797 466\n",
      "Loss:  0.09488750994205475\n",
      "Loss:  0.13628548383712769\n",
      "Loss:  0.10957478731870651\n",
      "3 **********\n",
      "Epoch:  228.55588793754578  fold:  2  kers:  64\n",
      "epoch:  4\n",
      "29797 466\n",
      "Loss:  0.09212921559810638\n",
      "Loss:  0.07165860384702682\n",
      "Loss:  0.08662378787994385\n",
      "4 **********\n",
      "Epoch:  272.9182720184326  fold:  2  kers:  64\n",
      "epoch:  5\n",
      "29797 466\n",
      "Loss:  0.07084908336400986\n",
      "Loss:  0.054441437125205994\n",
      "Loss:  0.06660213321447372\n",
      "5 **********\n",
      "Epoch:  317.36842131614685  fold:  2  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.9232938885688782\n",
      "Eval Loss:  0.12756241858005524\n",
      "Eval Loss:  0.44849956035614014\n",
      "[[1275  155]\n",
      " [ 700  964]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75      1430\n",
      "           1       0.86      0.58      0.69      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.75      0.74      0.72      3094\n",
      "weighted avg       0.76      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7236586942469295\n",
      "pre:  0.8614834673815907\n",
      "rec:  0.5793269230769231\n",
      "ma F1:  0.7208381282835845\n",
      "mi F1:  0.7236586942469295\n",
      "we F1:  0.7187159018031256\n",
      "update!  Acc:  0.7236586942469295\n",
      "Eval Loss:  0.3712507486343384\n",
      "Eval Loss:  0.24699167907238007\n",
      "Eval Loss:  0.3139050006866455\n",
      "Eval Loss:  0.449386328458786\n",
      "Eval Loss:  0.348477303981781\n",
      "Eval Loss:  0.3511080741882324\n",
      "Eval Loss:  0.34657102823257446\n",
      "Eval Loss:  0.41684404015541077\n",
      "Eval Loss:  0.28493571281433105\n",
      "Eval Loss:  0.34709179401397705\n",
      "Eval Loss:  0.4000057280063629\n",
      "Eval Loss:  0.2684487998485565\n",
      "Eval Loss:  0.41067200899124146\n",
      "Eval Loss:  0.23165300488471985\n",
      "Eval Loss:  0.30302998423576355\n",
      "Eval Loss:  0.39354464411735535\n",
      "Eval Loss:  0.3068179190158844\n",
      "Eval Loss:  0.34399181604385376\n",
      "Eval Loss:  0.3345487415790558\n",
      "Eval Loss:  0.32357335090637207\n",
      "Eval Loss:  0.35979989171028137\n",
      "Eval Loss:  0.33676210045814514\n",
      "Eval Loss:  0.37374451756477356\n",
      "Eval Loss:  0.30580899119377136\n",
      "Eval Loss:  0.3428337872028351\n",
      "Eval Loss:  0.3579625189304352\n",
      "Eval Loss:  0.4250490367412567\n",
      "Eval Loss:  0.35428494215011597\n",
      "Eval Loss:  0.3128965198993683\n",
      "[[17565  1169]\n",
      " [ 2851  8212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     18734\n",
      "           1       0.88      0.74      0.80     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.87      0.84      0.85     29797\n",
      "weighted avg       0.87      0.87      0.86     29797\n",
      "\n",
      "acc:  0.8650870893042923\n",
      "pre:  0.8753864193582773\n",
      "rec:  0.7422941335984814\n",
      "ma F1:  0.8503416491063149\n",
      "mi F1:  0.8650870893042923\n",
      "we F1:  0.8624353379503954\n",
      "29797 466\n",
      "Loss:  0.08357605338096619\n",
      "Loss:  0.046874381601810455\n",
      "Loss:  0.09865651279687881\n",
      "6 **********\n",
      "Epoch:  400.4762079715729  fold:  2  kers:  64\n",
      "epoch:  7\n",
      "29797 466\n",
      "Loss:  0.08665739744901657\n",
      "Loss:  0.06749473512172699\n",
      "Loss:  0.09369175136089325\n",
      "7 **********\n",
      "Epoch:  444.79570627212524  fold:  2  kers:  64\n",
      "epoch:  8\n",
      "29797 466\n",
      "Loss:  0.09771902114152908\n",
      "Loss:  0.07438936084508896\n",
      "Loss:  0.0690307468175888\n",
      "8 **********\n",
      "Epoch:  489.21693301200867  fold:  2  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  1.0701357126235962\n",
      "Eval Loss:  0.04341566935181618\n",
      "Eval Loss:  0.8692125082015991\n",
      "[[1369   61]\n",
      " [ 974  690]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.96      0.73      1430\n",
      "           1       0.92      0.41      0.57      1664\n",
      "\n",
      "    accuracy                           0.67      3094\n",
      "   macro avg       0.75      0.69      0.65      3094\n",
      "weighted avg       0.76      0.67      0.64      3094\n",
      "\n",
      "acc:  0.6654815772462831\n",
      "pre:  0.918774966711052\n",
      "rec:  0.41466346153846156\n",
      "ma F1:  0.6485555261065464\n",
      "mi F1:  0.6654815772462831\n",
      "we F1:  0.642722395080481\n",
      "Eval Loss:  0.39216306805610657\n",
      "Eval Loss:  0.35564467310905457\n",
      "Eval Loss:  0.3972526490688324\n",
      "Eval Loss:  0.5135295987129211\n",
      "Eval Loss:  0.3560101389884949\n",
      "Eval Loss:  0.37484079599380493\n",
      "Eval Loss:  0.40510350465774536\n",
      "Eval Loss:  0.48223283886909485\n",
      "Eval Loss:  0.3528404235839844\n",
      "Eval Loss:  0.4681319296360016\n",
      "Eval Loss:  0.4508751630783081\n",
      "Eval Loss:  0.35852235555648804\n",
      "Eval Loss:  0.4849032461643219\n",
      "Eval Loss:  0.2875617742538452\n",
      "Eval Loss:  0.37659382820129395\n",
      "Eval Loss:  0.4370195269584656\n",
      "Eval Loss:  0.38407275080680847\n",
      "Eval Loss:  0.5006265640258789\n",
      "Eval Loss:  0.46451252698898315\n",
      "Eval Loss:  0.33005258440971375\n",
      "Eval Loss:  0.39892980456352234\n",
      "Eval Loss:  0.459097683429718\n",
      "Eval Loss:  0.4705750644207001\n",
      "Eval Loss:  0.38291221857070923\n",
      "Eval Loss:  0.38512223958969116\n",
      "Eval Loss:  0.4666084051132202\n",
      "Eval Loss:  0.5234997272491455\n",
      "Eval Loss:  0.39169397950172424\n",
      "Eval Loss:  0.3270826041698456\n",
      "[[18272   462]\n",
      " [ 4081  6982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89     18734\n",
      "           1       0.94      0.63      0.75     11063\n",
      "\n",
      "    accuracy                           0.85     29797\n",
      "   macro avg       0.88      0.80      0.82     29797\n",
      "weighted avg       0.86      0.85      0.84     29797\n",
      "\n",
      "acc:  0.8475349867436319\n",
      "pre:  0.9379365932294466\n",
      "rec:  0.6311127180692399\n",
      "ma F1:  0.8219775306904803\n",
      "mi F1:  0.8475349867436319\n",
      "we F1:  0.8393425657111824\n",
      "29797 466\n",
      "Loss:  0.06863120943307877\n",
      "Loss:  0.08001404255628586\n",
      "Loss:  0.09645190089941025\n",
      "9 **********\n",
      "Epoch:  572.2658772468567  fold:  2  kers:  64\n",
      "epoch:  10\n",
      "29797 466\n",
      "Loss:  0.08608782291412354\n",
      "Loss:  0.09695843607187271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09253444522619247\n",
      "10 **********\n",
      "Epoch:  616.6541919708252  fold:  2  kers:  64\n",
      "epoch:  11\n",
      "29797 466\n",
      "Loss:  0.06664523482322693\n",
      "Loss:  0.08433283865451813\n",
      "Loss:  0.08820528537034988\n",
      "11 **********\n",
      "Epoch:  660.974687576294  fold:  2  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.7962079644203186\n",
      "Eval Loss:  0.12653107941150665\n",
      "Eval Loss:  0.6889270544052124\n",
      "[[1329  101]\n",
      " [ 801  863]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.93      0.75      1430\n",
      "           1       0.90      0.52      0.66      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.76      0.72      0.70      3094\n",
      "weighted avg       0.77      0.71      0.70      3094\n",
      "\n",
      "acc:  0.7084680025856497\n",
      "pre:  0.8952282157676349\n",
      "rec:  0.5186298076923077\n",
      "ma F1:  0.7017012125254392\n",
      "mi F1:  0.7084680025856497\n",
      "we F1:  0.6983032964866209\n",
      "Eval Loss:  0.3229128122329712\n",
      "Eval Loss:  0.25086554884910583\n",
      "Eval Loss:  0.2945231795310974\n",
      "Eval Loss:  0.42160701751708984\n",
      "Eval Loss:  0.3102271258831024\n",
      "Eval Loss:  0.3084166646003723\n",
      "Eval Loss:  0.3313911557197571\n",
      "Eval Loss:  0.3983345031738281\n",
      "Eval Loss:  0.26931822299957275\n",
      "Eval Loss:  0.3498866558074951\n",
      "Eval Loss:  0.3691921830177307\n",
      "Eval Loss:  0.26940226554870605\n",
      "Eval Loss:  0.4118313789367676\n",
      "Eval Loss:  0.17142616212368011\n",
      "Eval Loss:  0.2725837230682373\n",
      "Eval Loss:  0.35568517446517944\n",
      "Eval Loss:  0.3164927661418915\n",
      "Eval Loss:  0.35435277223587036\n",
      "Eval Loss:  0.3388521671295166\n",
      "Eval Loss:  0.2744441628456116\n",
      "Eval Loss:  0.3114537000656128\n",
      "Eval Loss:  0.3432208001613617\n",
      "Eval Loss:  0.3884466290473938\n",
      "Eval Loss:  0.2609749436378479\n",
      "Eval Loss:  0.3412698805332184\n",
      "Eval Loss:  0.37196236848831177\n",
      "Eval Loss:  0.4306427538394928\n",
      "Eval Loss:  0.31850650906562805\n",
      "Eval Loss:  0.27045896649360657\n",
      "[[18055   679]\n",
      " [ 3092  7971]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91     18734\n",
      "           1       0.92      0.72      0.81     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.89      0.84      0.86     29797\n",
      "weighted avg       0.88      0.87      0.87     29797\n",
      "\n",
      "acc:  0.8734436352652951\n",
      "pre:  0.9215028901734104\n",
      "rec:  0.7205098074663292\n",
      "ma F1:  0.8570743052652863\n",
      "mi F1:  0.8734436352652951\n",
      "we F1:  0.86952661887398\n",
      "29797 466\n",
      "Loss:  0.10031062364578247\n",
      "Loss:  0.06952908635139465\n",
      "Loss:  0.058833640068769455\n",
      "12 **********\n",
      "Epoch:  744.0764906406403  fold:  2  kers:  64\n",
      "epoch:  13\n",
      "29797 466\n",
      "Loss:  0.06664357334375381\n",
      "Loss:  0.07951444387435913\n",
      "Loss:  0.06531008332967758\n",
      "13 **********\n",
      "Epoch:  788.461813211441  fold:  2  kers:  64\n",
      "epoch:  14\n",
      "29797 466\n",
      "Loss:  0.06184644252061844\n",
      "Loss:  0.039973821491003036\n",
      "Loss:  0.08758716285228729\n",
      "14 **********\n",
      "Epoch:  832.828186750412  fold:  2  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.46384453773498535\n",
      "Eval Loss:  0.21467582881450653\n",
      "Eval Loss:  0.4022413194179535\n",
      "[[1287  143]\n",
      " [ 644 1020]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      1430\n",
      "           1       0.88      0.61      0.72      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.77      0.76      0.74      3094\n",
      "weighted avg       0.78      0.75      0.74      3094\n",
      "\n",
      "acc:  0.7456367162249515\n",
      "pre:  0.8770421324161651\n",
      "rec:  0.6129807692307693\n",
      "ma F1:  0.7437282581457525\n",
      "mi F1:  0.7456367162249515\n",
      "we F1:  0.7420556769078027\n",
      "update!  Acc:  0.7456367162249515\n",
      "Eval Loss:  0.30335739254951477\n",
      "Eval Loss:  0.19691862165927887\n",
      "Eval Loss:  0.22755302488803864\n",
      "Eval Loss:  0.3266720473766327\n",
      "Eval Loss:  0.28074705600738525\n",
      "Eval Loss:  0.26496249437332153\n",
      "Eval Loss:  0.3066653907299042\n",
      "Eval Loss:  0.32049983739852905\n",
      "Eval Loss:  0.2535501718521118\n",
      "Eval Loss:  0.29592978954315186\n",
      "Eval Loss:  0.2940748333930969\n",
      "Eval Loss:  0.24403299391269684\n",
      "Eval Loss:  0.3737103044986725\n",
      "Eval Loss:  0.14639943838119507\n",
      "Eval Loss:  0.2685661017894745\n",
      "Eval Loss:  0.3234877586364746\n",
      "Eval Loss:  0.26086050271987915\n",
      "Eval Loss:  0.27440813183784485\n",
      "Eval Loss:  0.26737523078918457\n",
      "Eval Loss:  0.2547113001346588\n",
      "Eval Loss:  0.24957327544689178\n",
      "Eval Loss:  0.3105933368206024\n",
      "Eval Loss:  0.3248158097267151\n",
      "Eval Loss:  0.2181650847196579\n",
      "Eval Loss:  0.3141756057739258\n",
      "Eval Loss:  0.3003070056438446\n",
      "Eval Loss:  0.36968910694122314\n",
      "Eval Loss:  0.2765291929244995\n",
      "Eval Loss:  0.24054256081581116\n",
      "[[17840   894]\n",
      " [ 2430  8633]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18734\n",
      "           1       0.91      0.78      0.84     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.89      0.87      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8884451454844448\n",
      "pre:  0.9061614359189671\n",
      "rec:  0.7803489107836934\n",
      "ma F1:  0.8766701902132402\n",
      "mi F1:  0.8884451454844448\n",
      "we F1:  0.8864807345692095\n",
      "29797 466\n",
      "Loss:  0.0846356675028801\n",
      "Loss:  0.07045994699001312\n",
      "Loss:  0.07347919791936874\n",
      "15 **********\n",
      "Epoch:  915.8202826976776  fold:  2  kers:  64\n",
      "epoch:  16\n",
      "29797 466\n",
      "Loss:  0.10394510626792908\n",
      "Loss:  0.05110125616192818\n",
      "Loss:  0.08946066349744797\n",
      "16 **********\n",
      "Epoch:  960.0649816989899  fold:  2  kers:  64\n",
      "epoch:  17\n",
      "29797 466\n",
      "Loss:  0.09290429204702377\n",
      "Loss:  0.09437687695026398\n",
      "Loss:  0.060871779918670654\n",
      "17 **********\n",
      "Epoch:  1004.4163947105408  fold:  2  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.4501744210720062\n",
      "Eval Loss:  0.3051539361476898\n",
      "Eval Loss:  0.4376533329486847\n",
      "[[1282  148]\n",
      " [ 608 1056]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77      1430\n",
      "           1       0.88      0.63      0.74      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.78      0.77      0.75      3094\n",
      "weighted avg       0.79      0.76      0.75      3094\n",
      "\n",
      "acc:  0.755656108597285\n",
      "pre:  0.8770764119601329\n",
      "rec:  0.6346153846153846\n",
      "ma F1:  0.7543454151333366\n",
      "mi F1:  0.755656108597285\n",
      "we F1:  0.752988325440576\n",
      "update!  Acc:  0.755656108597285\n",
      "Eval Loss:  0.26371604204177856\n",
      "Eval Loss:  0.19401445984840393\n",
      "Eval Loss:  0.1779802441596985\n",
      "Eval Loss:  0.27910685539245605\n",
      "Eval Loss:  0.2561225891113281\n",
      "Eval Loss:  0.24258555471897125\n",
      "Eval Loss:  0.2715299427509308\n",
      "Eval Loss:  0.2878482937812805\n",
      "Eval Loss:  0.20903189480304718\n",
      "Eval Loss:  0.25765886902809143\n",
      "Eval Loss:  0.28935569524765015\n",
      "Eval Loss:  0.21318376064300537\n",
      "Eval Loss:  0.34426552057266235\n",
      "Eval Loss:  0.12701432406902313\n",
      "Eval Loss:  0.23931770026683807\n",
      "Eval Loss:  0.28240105509757996\n",
      "Eval Loss:  0.24198588728904724\n",
      "Eval Loss:  0.2110467553138733\n",
      "Eval Loss:  0.23524563014507294\n",
      "Eval Loss:  0.2371091991662979\n",
      "Eval Loss:  0.2236682027578354\n",
      "Eval Loss:  0.2837293744087219\n",
      "Eval Loss:  0.3181116580963135\n",
      "Eval Loss:  0.17553862929344177\n",
      "Eval Loss:  0.26108649373054504\n",
      "Eval Loss:  0.3020150363445282\n",
      "Eval Loss:  0.30802619457244873\n",
      "Eval Loss:  0.2584204375743866\n",
      "Eval Loss:  0.21750061213970184\n",
      "[[17761   973]\n",
      " [ 2081  8982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18734\n",
      "           1       0.90      0.81      0.85     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.88      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.8975064603819176\n",
      "pre:  0.9022601707684581\n",
      "rec:  0.8118955075476815\n",
      "ma F1:  0.8877637900108848\n",
      "mi F1:  0.8975064603819176\n",
      "we F1:  0.896276835279844\n",
      "29797 466\n",
      "Loss:  0.04876777529716492\n",
      "Loss:  0.059634074568748474\n",
      "Loss:  0.04922110214829445\n",
      "18 **********\n",
      "Epoch:  1087.3646075725555  fold:  2  kers:  64\n",
      "epoch:  19\n",
      "29797 466\n",
      "Loss:  0.05187132582068443\n",
      "Loss:  0.06686962395906448\n",
      "Loss:  0.03956342488527298\n",
      "19 **********\n",
      "Epoch:  1131.5973386764526  fold:  2  kers:  64\n",
      "epoch:  20\n",
      "29797 466\n",
      "Loss:  0.0819980651140213\n",
      "Loss:  0.030698437243700027\n",
      "Loss:  0.05095535144209862\n",
      "20 **********\n",
      "Epoch:  1175.9467573165894  fold:  2  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.503056526184082\n",
      "Eval Loss:  0.32467877864837646\n",
      "Eval Loss:  0.5867666602134705\n",
      "[[1270  160]\n",
      " [ 636 1028]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76      1430\n",
      "           1       0.87      0.62      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.77      0.75      0.74      3094\n",
      "weighted avg       0.77      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7427278603749192\n",
      "pre:  0.8653198653198653\n",
      "rec:  0.6177884615384616\n",
      "ma F1:  0.7411442514992214\n",
      "mi F1:  0.7427278603749192\n",
      "we F1:  0.7396129933301582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2620336413383484\n",
      "Eval Loss:  0.18210050463676453\n",
      "Eval Loss:  0.17268194258213043\n",
      "Eval Loss:  0.29290351271629333\n",
      "Eval Loss:  0.2722179889678955\n",
      "Eval Loss:  0.24756383895874023\n",
      "Eval Loss:  0.25460442900657654\n",
      "Eval Loss:  0.2961323857307434\n",
      "Eval Loss:  0.2113412469625473\n",
      "Eval Loss:  0.2610743045806885\n",
      "Eval Loss:  0.29185929894447327\n",
      "Eval Loss:  0.21310077607631683\n",
      "Eval Loss:  0.371432900428772\n",
      "Eval Loss:  0.109701007604599\n",
      "Eval Loss:  0.21794812381267548\n",
      "Eval Loss:  0.27683770656585693\n",
      "Eval Loss:  0.2271321713924408\n",
      "Eval Loss:  0.21197038888931274\n",
      "Eval Loss:  0.24077525734901428\n",
      "Eval Loss:  0.23156015574932098\n",
      "Eval Loss:  0.2101857215166092\n",
      "Eval Loss:  0.2785700559616089\n",
      "Eval Loss:  0.3095042407512665\n",
      "Eval Loss:  0.1671503335237503\n",
      "Eval Loss:  0.259610116481781\n",
      "Eval Loss:  0.31483644247055054\n",
      "Eval Loss:  0.3401412069797516\n",
      "Eval Loss:  0.244533970952034\n",
      "Eval Loss:  0.2076311707496643\n",
      "[[17898   836]\n",
      " [ 2172  8891]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18734\n",
      "           1       0.91      0.80      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.88      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.8990502399570427\n",
      "pre:  0.9140536650560296\n",
      "rec:  0.8036698906264124\n",
      "ma F1:  0.8888986368215314\n",
      "mi F1:  0.8990502399570427\n",
      "we F1:  0.8975444620299811\n",
      "29797 466\n",
      "Loss:  0.05482123792171478\n",
      "Loss:  0.044997163116931915\n",
      "Loss:  0.05869705229997635\n",
      "21 **********\n",
      "Epoch:  1258.8480958938599  fold:  2  kers:  64\n",
      "epoch:  22\n",
      "29797 466\n",
      "Loss:  0.0708564817905426\n",
      "Loss:  0.05211390554904938\n",
      "Loss:  0.08472967892885208\n",
      "22 **********\n",
      "Epoch:  1303.1247091293335  fold:  2  kers:  64\n",
      "epoch:  23\n",
      "29797 466\n",
      "Loss:  0.0461815744638443\n",
      "Loss:  0.09087570756673813\n",
      "Loss:  0.07680024951696396\n",
      "23 **********\n",
      "Epoch:  1347.45019197464  fold:  2  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.42151516675949097\n",
      "Eval Loss:  0.4043736159801483\n",
      "Eval Loss:  0.29076793789863586\n",
      "[[1216  214]\n",
      " [ 483 1181]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78      1430\n",
      "           1       0.85      0.71      0.77      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.78      0.78      0.77      3094\n",
      "weighted avg       0.79      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7747252747252747\n",
      "pre:  0.8465949820788531\n",
      "rec:  0.7097355769230769\n",
      "ma F1:  0.7746964434722639\n",
      "mi F1:  0.7747252747252747\n",
      "we F1:  0.7745036859521348\n",
      "update!  Acc:  0.7747252747252747\n",
      "Eval Loss:  0.21521659195423126\n",
      "Eval Loss:  0.15786029398441315\n",
      "Eval Loss:  0.14181658625602722\n",
      "Eval Loss:  0.2344658374786377\n",
      "Eval Loss:  0.26539501547813416\n",
      "Eval Loss:  0.21389394998550415\n",
      "Eval Loss:  0.22484056651592255\n",
      "Eval Loss:  0.25164562463760376\n",
      "Eval Loss:  0.1990005075931549\n",
      "Eval Loss:  0.23460790514945984\n",
      "Eval Loss:  0.24377058446407318\n",
      "Eval Loss:  0.20025262236595154\n",
      "Eval Loss:  0.3228890597820282\n",
      "Eval Loss:  0.10276233404874802\n",
      "Eval Loss:  0.25012123584747314\n",
      "Eval Loss:  0.2436085194349289\n",
      "Eval Loss:  0.22796575725078583\n",
      "Eval Loss:  0.1716984510421753\n",
      "Eval Loss:  0.17764784395694733\n",
      "Eval Loss:  0.25032201409339905\n",
      "Eval Loss:  0.18072925508022308\n",
      "Eval Loss:  0.24139808118343353\n",
      "Eval Loss:  0.30326470732688904\n",
      "Eval Loss:  0.129034623503685\n",
      "Eval Loss:  0.21347489953041077\n",
      "Eval Loss:  0.2900232672691345\n",
      "Eval Loss:  0.29038023948669434\n",
      "Eval Loss:  0.23159557580947876\n",
      "Eval Loss:  0.2000967562198639\n",
      "[[17378  1356]\n",
      " [ 1439  9624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18734\n",
      "           1       0.88      0.87      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.90      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9061986105983824\n",
      "pre:  0.8765027322404372\n",
      "rec:  0.8699267829702613\n",
      "ma F1:  0.8993851357511342\n",
      "mi F1:  0.9061986105983824\n",
      "we F1:  0.9061256781232312\n",
      "29797 466\n",
      "Loss:  0.06443097442388535\n",
      "Loss:  0.06479484587907791\n",
      "Loss:  0.05887520685791969\n",
      "24 **********\n",
      "Epoch:  1430.0144321918488  fold:  2  kers:  64\n",
      "epoch:  25\n",
      "29797 466\n",
      "Loss:  0.04649370536208153\n",
      "Loss:  0.07993872463703156\n",
      "Loss:  0.07812053710222244\n",
      "25 **********\n",
      "Epoch:  1474.1953012943268  fold:  2  kers:  64\n",
      "epoch:  26\n",
      "29797 466\n",
      "Loss:  0.05532797798514366\n",
      "Loss:  0.051309190690517426\n",
      "Loss:  0.08296390622854233\n",
      "26 **********\n",
      "Epoch:  1518.2953867912292  fold:  2  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.7341083884239197\n",
      "Eval Loss:  0.2036198228597641\n",
      "Eval Loss:  0.617879331111908\n",
      "[[1293  137]\n",
      " [ 708  956]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.90      0.75      1430\n",
      "           1       0.87      0.57      0.69      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.76      0.74      0.72      3094\n",
      "weighted avg       0.77      0.73      0.72      3094\n",
      "\n",
      "acc:  0.726890756302521\n",
      "pre:  0.8746569075937786\n",
      "rec:  0.5745192307692307\n",
      "ma F1:  0.7236117766841764\n",
      "mi F1:  0.7268907563025211\n",
      "we F1:  0.7213349777800441\n",
      "Eval Loss:  0.26272910833358765\n",
      "Eval Loss:  0.18274036049842834\n",
      "Eval Loss:  0.2042345106601715\n",
      "Eval Loss:  0.31827017664909363\n",
      "Eval Loss:  0.3023456931114197\n",
      "Eval Loss:  0.254006952047348\n",
      "Eval Loss:  0.2506675124168396\n",
      "Eval Loss:  0.31019723415374756\n",
      "Eval Loss:  0.21194957196712494\n",
      "Eval Loss:  0.2770323157310486\n",
      "Eval Loss:  0.301408588886261\n",
      "Eval Loss:  0.20432792603969574\n",
      "Eval Loss:  0.35959678888320923\n",
      "Eval Loss:  0.12355601042509079\n",
      "Eval Loss:  0.21900048851966858\n",
      "Eval Loss:  0.3359350562095642\n",
      "Eval Loss:  0.24887125194072723\n",
      "Eval Loss:  0.20691873133182526\n",
      "Eval Loss:  0.25993284583091736\n",
      "Eval Loss:  0.23279529809951782\n",
      "Eval Loss:  0.21420244872570038\n",
      "Eval Loss:  0.2696496546268463\n",
      "Eval Loss:  0.3327982425689697\n",
      "Eval Loss:  0.16127924621105194\n",
      "Eval Loss:  0.21710996329784393\n",
      "Eval Loss:  0.35966625809669495\n",
      "Eval Loss:  0.3396548926830292\n",
      "Eval Loss:  0.2519671320915222\n",
      "Eval Loss:  0.20839565992355347\n",
      "[[18065   669]\n",
      " [ 2438  8625]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18734\n",
      "           1       0.93      0.78      0.85     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.87      0.88     29797\n",
      "weighted avg       0.90      0.90      0.89     29797\n",
      "\n",
      "acc:  0.8957277578279692\n",
      "pre:  0.9280180761781794\n",
      "rec:  0.7796257796257796\n",
      "ma F1:  0.8840944524191996\n",
      "mi F1:  0.8957277578279692\n",
      "we F1:  0.8935477454054996\n",
      "29797 466\n",
      "Loss:  0.04563566669821739\n",
      "Loss:  0.05223080515861511\n",
      "Loss:  0.048124074935913086\n",
      "27 **********\n",
      "Epoch:  1600.9822988510132  fold:  2  kers:  64\n",
      "epoch:  28\n",
      "29797 466\n",
      "Loss:  0.06541164964437485\n",
      "Loss:  0.052675798535346985\n",
      "Loss:  0.07363969832658768\n",
      "28 **********\n",
      "Epoch:  1645.0763998031616  fold:  2  kers:  64\n",
      "epoch:  29\n",
      "29797 466\n",
      "Loss:  0.09793008118867874\n",
      "Loss:  0.049862440675497055\n",
      "Loss:  0.05435248464345932\n",
      "29 **********\n",
      "Epoch:  1689.2034132480621  fold:  2  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.5630236268043518\n",
      "Eval Loss:  0.49215826392173767\n",
      "Eval Loss:  0.5853993892669678\n",
      "[[1198  232]\n",
      " [ 560 1104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.84      0.75      1430\n",
      "           1       0.83      0.66      0.74      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7440206851971558\n",
      "pre:  0.8263473053892215\n",
      "rec:  0.6634615384615384\n",
      "ma F1:  0.7437841907151819\n",
      "mi F1:  0.7440206851971558\n",
      "we F1:  0.7431954704089918\n",
      "Eval Loss:  0.21662385761737823\n",
      "Eval Loss:  0.13952817022800446\n",
      "Eval Loss:  0.15757812559604645\n",
      "Eval Loss:  0.2230701893568039\n",
      "Eval Loss:  0.2176736444234848\n",
      "Eval Loss:  0.1761750876903534\n",
      "Eval Loss:  0.1930117905139923\n",
      "Eval Loss:  0.24101902544498444\n",
      "Eval Loss:  0.18970942497253418\n",
      "Eval Loss:  0.20427031815052032\n",
      "Eval Loss:  0.26777273416519165\n",
      "Eval Loss:  0.16007913649082184\n",
      "Eval Loss:  0.3245401978492737\n",
      "Eval Loss:  0.10860170423984528\n",
      "Eval Loss:  0.2137918323278427\n",
      "Eval Loss:  0.22859670221805573\n",
      "Eval Loss:  0.19149959087371826\n",
      "Eval Loss:  0.16969919204711914\n",
      "Eval Loss:  0.21544043719768524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18991734087467194\n",
      "Eval Loss:  0.17198608815670013\n",
      "Eval Loss:  0.22947238385677338\n",
      "Eval Loss:  0.3008674085140228\n",
      "Eval Loss:  0.1275290548801422\n",
      "Eval Loss:  0.19700351357460022\n",
      "Eval Loss:  0.30345815420150757\n",
      "Eval Loss:  0.28604161739349365\n",
      "Eval Loss:  0.20760467648506165\n",
      "Eval Loss:  0.20099025964736938\n",
      "[[17730  1004]\n",
      " [ 1591  9472]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18734\n",
      "           1       0.90      0.86      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9129106957076216\n",
      "pre:  0.9041618938526155\n",
      "rec:  0.8561872909698997\n",
      "ma F1:  0.9056650463067214\n",
      "mi F1:  0.9129106957076216\n",
      "we F1:  0.912395656206734\n",
      "29797 466\n",
      "Loss:  0.07605939358472824\n",
      "Loss:  0.04041334241628647\n",
      "Loss:  0.08785451948642731\n",
      "30 **********\n",
      "Epoch:  1772.0718400478363  fold:  2  kers:  64\n",
      "epoch:  31\n",
      "29797 466\n",
      "Loss:  0.06569086015224457\n",
      "Loss:  0.04218406230211258\n",
      "Loss:  0.03449032083153725\n",
      "31 **********\n",
      "Epoch:  1816.2886135578156  fold:  2  kers:  64\n",
      "epoch:  32\n",
      "29797 466\n",
      "Loss:  0.07938788831233978\n",
      "Loss:  0.06676087528467178\n",
      "Loss:  0.06412164866924286\n",
      "32 **********\n",
      "Epoch:  1860.4634988307953  fold:  2  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.58319491147995\n",
      "Eval Loss:  0.33368122577667236\n",
      "Eval Loss:  0.5612804293632507\n",
      "[[1233  197]\n",
      " [ 556 1108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.77      1430\n",
      "           1       0.85      0.67      0.75      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.76      0.76      3094\n",
      "weighted avg       0.78      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7566257272139625\n",
      "pre:  0.8490421455938697\n",
      "rec:  0.6658653846153846\n",
      "ma F1:  0.7562278367611639\n",
      "mi F1:  0.7566257272139626\n",
      "we F1:  0.7554829858335249\n",
      "Eval Loss:  0.2143482118844986\n",
      "Eval Loss:  0.17113807797431946\n",
      "Eval Loss:  0.13451148569583893\n",
      "Eval Loss:  0.21487879753112793\n",
      "Eval Loss:  0.1898956149816513\n",
      "Eval Loss:  0.18268130719661713\n",
      "Eval Loss:  0.20611712336540222\n",
      "Eval Loss:  0.20263530313968658\n",
      "Eval Loss:  0.17856818437576294\n",
      "Eval Loss:  0.19777630269527435\n",
      "Eval Loss:  0.2692071795463562\n",
      "Eval Loss:  0.17746759951114655\n",
      "Eval Loss:  0.2965877652168274\n",
      "Eval Loss:  0.10112511366605759\n",
      "Eval Loss:  0.20119783282279968\n",
      "Eval Loss:  0.23333251476287842\n",
      "Eval Loss:  0.18428894877433777\n",
      "Eval Loss:  0.16366255283355713\n",
      "Eval Loss:  0.20555631816387177\n",
      "Eval Loss:  0.19500896334648132\n",
      "Eval Loss:  0.16539159417152405\n",
      "Eval Loss:  0.22050902247428894\n",
      "Eval Loss:  0.29073187708854675\n",
      "Eval Loss:  0.1433892548084259\n",
      "Eval Loss:  0.17039494216442108\n",
      "Eval Loss:  0.2865656614303589\n",
      "Eval Loss:  0.27650848031044006\n",
      "Eval Loss:  0.20021069049835205\n",
      "Eval Loss:  0.1759730875492096\n",
      "[[17850   884]\n",
      " [ 1619  9444]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18734\n",
      "           1       0.91      0.85      0.88     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.90      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9159982548578716\n",
      "pre:  0.9144074360960496\n",
      "rec:  0.8536563319172015\n",
      "ma F1:  0.9087348789058862\n",
      "mi F1:  0.9159982548578716\n",
      "we F1:  0.9153631630990434\n",
      "29797 466\n",
      "Loss:  0.07743245363235474\n",
      "Loss:  0.10187045484781265\n",
      "Loss:  0.06541966646909714\n",
      "33 **********\n",
      "Epoch:  1947.5935308933258  fold:  2  kers:  64\n",
      "epoch:  34\n",
      "29797 466\n",
      "Loss:  0.07213674485683441\n",
      "Loss:  0.08476830273866653\n",
      "Loss:  0.05305176228284836\n",
      "34 **********\n",
      "Epoch:  1991.8920850753784  fold:  2  kers:  64\n",
      "epoch:  35\n",
      "29797 466\n",
      "Loss:  0.05161299556493759\n",
      "Loss:  0.060654666274785995\n",
      "Loss:  0.06918653100728989\n",
      "35 **********\n",
      "Epoch:  2036.1886448860168  fold:  2  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.5751318335533142\n",
      "Eval Loss:  0.7823185324668884\n",
      "Eval Loss:  0.4225340187549591\n",
      "[[1107  323]\n",
      " [ 437 1227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74      1430\n",
      "           1       0.79      0.74      0.76      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.75      0.76      0.75      3094\n",
      "weighted avg       0.76      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7543632837750485\n",
      "pre:  0.7916129032258065\n",
      "rec:  0.7373798076923077\n",
      "ma F1:  0.7539932265069307\n",
      "mi F1:  0.7543632837750485\n",
      "we F1:  0.7547148381797605\n",
      "Eval Loss:  0.23216360807418823\n",
      "Eval Loss:  0.11183302104473114\n",
      "Eval Loss:  0.13045603036880493\n",
      "Eval Loss:  0.20543742179870605\n",
      "Eval Loss:  0.1825367510318756\n",
      "Eval Loss:  0.16310562193393707\n",
      "Eval Loss:  0.20016372203826904\n",
      "Eval Loss:  0.21202149987220764\n",
      "Eval Loss:  0.16964000463485718\n",
      "Eval Loss:  0.20461151003837585\n",
      "Eval Loss:  0.27540212869644165\n",
      "Eval Loss:  0.1522354781627655\n",
      "Eval Loss:  0.3339228332042694\n",
      "Eval Loss:  0.11680933833122253\n",
      "Eval Loss:  0.22421419620513916\n",
      "Eval Loss:  0.21172818541526794\n",
      "Eval Loss:  0.2209719866514206\n",
      "Eval Loss:  0.1519259363412857\n",
      "Eval Loss:  0.18649201095104218\n",
      "Eval Loss:  0.19629381597042084\n",
      "Eval Loss:  0.16969065368175507\n",
      "Eval Loss:  0.2362547516822815\n",
      "Eval Loss:  0.3027758300304413\n",
      "Eval Loss:  0.11260349303483963\n",
      "Eval Loss:  0.18599043786525726\n",
      "Eval Loss:  0.320956289768219\n",
      "Eval Loss:  0.2980303168296814\n",
      "Eval Loss:  0.18965473771095276\n",
      "Eval Loss:  0.1632230132818222\n",
      "[[17544  1190]\n",
      " [ 1396  9667]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18734\n",
      "           1       0.89      0.87      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.91      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9132127395375373\n",
      "pre:  0.8903932946486138\n",
      "rec:  0.8738136129440477\n",
      "ma F1:  0.9066920220105716\n",
      "mi F1:  0.9132127395375373\n",
      "we F1:  0.9130422091566112\n",
      "29797 466\n",
      "Loss:  0.049422554671764374\n",
      "Loss:  0.08040744811296463\n",
      "Loss:  0.06042788550257683\n",
      "36 **********\n",
      "Epoch:  2124.6241867542267  fold:  2  kers:  64\n",
      "epoch:  37\n",
      "29797 466\n",
      "Loss:  0.04584742709994316\n",
      "Loss:  0.03685787692666054\n",
      "Loss:  0.04200935736298561\n",
      "37 **********\n",
      "Epoch:  2168.971610546112  fold:  2  kers:  64\n",
      "epoch:  38\n",
      "29797 466\n",
      "Loss:  0.043619491159915924\n",
      "Loss:  0.041063759475946426\n",
      "Loss:  0.029376061633229256\n",
      "38 **********\n",
      "Epoch:  2213.0826663970947  fold:  2  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.6235994696617126\n",
      "Eval Loss:  0.9220110774040222\n",
      "Eval Loss:  0.42705127596855164\n",
      "[[1058  372]\n",
      " [ 355 1309]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1430\n",
      "           1       0.78      0.79      0.78      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.76      0.76      0.76      3094\n",
      "weighted avg       0.76      0.77      0.76      3094\n",
      "\n",
      "acc:  0.7650290885585003\n",
      "pre:  0.7787031528851874\n",
      "rec:  0.7866586538461539\n",
      "ma F1:  0.7634724472086003\n",
      "mi F1:  0.7650290885585003\n",
      "we F1:  0.7649236586662762\n",
      "Eval Loss:  0.22878706455230713\n",
      "Eval Loss:  0.143868550658226\n",
      "Eval Loss:  0.13961394131183624\n",
      "Eval Loss:  0.1890527755022049\n",
      "Eval Loss:  0.20273178815841675\n",
      "Eval Loss:  0.14638927578926086\n",
      "Eval Loss:  0.18445922434329987\n",
      "Eval Loss:  0.2304268479347229\n",
      "Eval Loss:  0.17429977655410767\n",
      "Eval Loss:  0.21733105182647705\n",
      "Eval Loss:  0.29294055700302124\n",
      "Eval Loss:  0.16559496521949768\n",
      "Eval Loss:  0.31980422139167786\n",
      "Eval Loss:  0.13255847990512848\n",
      "Eval Loss:  0.24760130047798157\n",
      "Eval Loss:  0.23830373585224152\n",
      "Eval Loss:  0.2407984435558319\n",
      "Eval Loss:  0.1771368682384491\n",
      "Eval Loss:  0.1776544749736786\n",
      "Eval Loss:  0.19865185022354126\n",
      "Eval Loss:  0.18034465610980988\n",
      "Eval Loss:  0.22168830037117004\n",
      "Eval Loss:  0.31539180874824524\n",
      "Eval Loss:  0.10756757110357285\n",
      "Eval Loss:  0.19305962324142456\n",
      "Eval Loss:  0.3478817641735077\n",
      "Eval Loss:  0.28268706798553467\n",
      "Eval Loss:  0.1986398696899414\n",
      "Eval Loss:  0.17809481918811798\n",
      "[[17230  1504]\n",
      " [ 1129  9934]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     18734\n",
      "           1       0.87      0.90      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.90      0.91      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9116353995368661\n",
      "pre:  0.8685084805035845\n",
      "rec:  0.8979481153394197\n",
      "ma F1:  0.9059996174854059\n",
      "mi F1:  0.9116353995368661\n",
      "we F1:  0.9119250676110572\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0464913547039032\n",
      "Loss:  0.06294926255941391\n",
      "Loss:  0.05313143506646156\n",
      "39 **********\n",
      "Epoch:  2295.8563463687897  fold:  2  kers:  64\n",
      "epoch:  40\n",
      "29797 466\n",
      "Loss:  0.04978033900260925\n",
      "Loss:  0.05080555006861687\n",
      "Loss:  0.06868848949670792\n",
      "40 **********\n",
      "Epoch:  2340.01527428627  fold:  2  kers:  64\n",
      "epoch:  41\n",
      "29797 466\n",
      "Loss:  0.0675588920712471\n",
      "Loss:  0.05930183455348015\n",
      "Loss:  0.0191888976842165\n",
      "41 **********\n",
      "Epoch:  2384.232047557831  fold:  2  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.5830299258232117\n",
      "Eval Loss:  0.49427083134651184\n",
      "Eval Loss:  0.42385318875312805\n",
      "[[1161  269]\n",
      " [ 470 1194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1430\n",
      "           1       0.82      0.72      0.76      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.76      0.76      0.76      3094\n",
      "weighted avg       0.77      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7611506140917905\n",
      "pre:  0.8161312371838687\n",
      "rec:  0.7175480769230769\n",
      "ma F1:  0.7611234396395976\n",
      "mi F1:  0.7611506140917905\n",
      "we F1:  0.7613161312096928\n",
      "Eval Loss:  0.2145114243030548\n",
      "Eval Loss:  0.13419552147388458\n",
      "Eval Loss:  0.1118350550532341\n",
      "Eval Loss:  0.17997300624847412\n",
      "Eval Loss:  0.18581189215183258\n",
      "Eval Loss:  0.12732523679733276\n",
      "Eval Loss:  0.17612037062644958\n",
      "Eval Loss:  0.20207569003105164\n",
      "Eval Loss:  0.1574355959892273\n",
      "Eval Loss:  0.2111508995294571\n",
      "Eval Loss:  0.26443347334861755\n",
      "Eval Loss:  0.14662528038024902\n",
      "Eval Loss:  0.292030930519104\n",
      "Eval Loss:  0.11203934252262115\n",
      "Eval Loss:  0.2145289033651352\n",
      "Eval Loss:  0.23947151005268097\n",
      "Eval Loss:  0.19719542562961578\n",
      "Eval Loss:  0.1693396121263504\n",
      "Eval Loss:  0.17746038734912872\n",
      "Eval Loss:  0.17613644897937775\n",
      "Eval Loss:  0.1493169218301773\n",
      "Eval Loss:  0.21676793694496155\n",
      "Eval Loss:  0.2968544661998749\n",
      "Eval Loss:  0.11187537014484406\n",
      "Eval Loss:  0.1729801595211029\n",
      "Eval Loss:  0.30579057335853577\n",
      "Eval Loss:  0.23758481442928314\n",
      "Eval Loss:  0.18092085421085358\n",
      "Eval Loss:  0.16177991032600403\n",
      "[[17483  1251]\n",
      " [ 1142  9921]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18734\n",
      "           1       0.89      0.90      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.91      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9196899016679532\n",
      "pre:  0.8880236305048335\n",
      "rec:  0.8967730272078098\n",
      "ma F1:  0.9141613531265536\n",
      "mi F1:  0.9196899016679532\n",
      "we F1:  0.9197695911404489\n",
      "29797 466\n",
      "Loss:  0.0631866529583931\n",
      "Loss:  0.04208916425704956\n",
      "Loss:  0.04677614942193031\n",
      "42 **********\n",
      "Epoch:  2467.018693447113  fold:  2  kers:  64\n",
      "epoch:  43\n",
      "29797 466\n",
      "Loss:  0.04086284339427948\n",
      "Loss:  0.06924519687891006\n",
      "Loss:  0.04878750070929527\n",
      "43 **********\n",
      "Epoch:  2511.3401868343353  fold:  2  kers:  64\n",
      "epoch:  44\n",
      "29797 466\n",
      "Loss:  0.040154244750738144\n",
      "Loss:  0.03186437860131264\n",
      "Loss:  0.06123783066868782\n",
      "44 **********\n",
      "Epoch:  2555.588874578476  fold:  2  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.5171831846237183\n",
      "Eval Loss:  0.47375181317329407\n",
      "Eval Loss:  0.45565253496170044\n",
      "[[1138  292]\n",
      " [ 461 1203]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75      1430\n",
      "           1       0.80      0.72      0.76      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.76      0.76      0.76      3094\n",
      "weighted avg       0.76      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7566257272139625\n",
      "pre:  0.8046822742474916\n",
      "rec:  0.7229567307692307\n",
      "ma F1:  0.7565182658172644\n",
      "mi F1:  0.7566257272139626\n",
      "we F1:  0.7569051268453776\n",
      "Eval Loss:  0.20500826835632324\n",
      "Eval Loss:  0.14179714024066925\n",
      "Eval Loss:  0.10711724311113358\n",
      "Eval Loss:  0.16980089247226715\n",
      "Eval Loss:  0.16800758242607117\n",
      "Eval Loss:  0.1294243186712265\n",
      "Eval Loss:  0.16115976870059967\n",
      "Eval Loss:  0.18559734523296356\n",
      "Eval Loss:  0.1431487500667572\n",
      "Eval Loss:  0.18590642511844635\n",
      "Eval Loss:  0.26199814677238464\n",
      "Eval Loss:  0.15498438477516174\n",
      "Eval Loss:  0.2768857181072235\n",
      "Eval Loss:  0.09925428032875061\n",
      "Eval Loss:  0.2221725434064865\n",
      "Eval Loss:  0.21815136075019836\n",
      "Eval Loss:  0.19451411068439484\n",
      "Eval Loss:  0.1556403785943985\n",
      "Eval Loss:  0.17002375423908234\n",
      "Eval Loss:  0.1970447450876236\n",
      "Eval Loss:  0.1335151344537735\n",
      "Eval Loss:  0.2081126719713211\n",
      "Eval Loss:  0.2799049913883209\n",
      "Eval Loss:  0.12099379301071167\n",
      "Eval Loss:  0.17979846894741058\n",
      "Eval Loss:  0.29387664794921875\n",
      "Eval Loss:  0.22626668214797974\n",
      "Eval Loss:  0.1821669638156891\n",
      "Eval Loss:  0.14885659515857697\n",
      "[[17395  1339]\n",
      " [ 1034 10029]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18734\n",
      "           1       0.88      0.91      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.92      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9203611101788771\n",
      "pre:  0.882213230119634\n",
      "rec:  0.9065352978396457\n",
      "ma F1:  0.9151775371010938\n",
      "mi F1:  0.9203611101788771\n",
      "we F1:  0.9205757436011855\n",
      "29797 466\n",
      "Loss:  0.03725956007838249\n",
      "Loss:  0.05830978602170944\n",
      "Loss:  0.054816167801618576\n",
      "45 **********\n",
      "Epoch:  2638.334629058838  fold:  2  kers:  64\n",
      "epoch:  46\n",
      "29797 466\n",
      "Loss:  0.04268908500671387\n",
      "Loss:  0.02777206525206566\n",
      "Loss:  0.04715057834982872\n",
      "46 **********\n",
      "Epoch:  2682.3988106250763  fold:  2  kers:  64\n",
      "epoch:  47\n",
      "29797 466\n",
      "Loss:  0.07536855340003967\n",
      "Loss:  0.06546060740947723\n",
      "Loss:  0.0840127095580101\n",
      "47 **********\n",
      "Epoch:  2726.6784160137177  fold:  2  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.7350715398788452\n",
      "Eval Loss:  1.7291990518569946\n",
      "Eval Loss:  0.24584639072418213\n",
      "[[ 795  635]\n",
      " [ 230 1434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65      1430\n",
      "           1       0.69      0.86      0.77      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.73      0.71      0.71      3094\n",
      "weighted avg       0.73      0.72      0.71      3094\n",
      "\n",
      "acc:  0.7204266321913381\n",
      "pre:  0.6930884485258579\n",
      "rec:  0.8617788461538461\n",
      "ma F1:  0.707970361770372\n",
      "mi F1:  0.7204266321913381\n",
      "we F1:  0.7125318129104442\n",
      "Eval Loss:  0.2724111080169678\n",
      "Eval Loss:  0.18547919392585754\n",
      "Eval Loss:  0.1845911145210266\n",
      "Eval Loss:  0.21143238246440887\n",
      "Eval Loss:  0.22112900018692017\n",
      "Eval Loss:  0.15835897624492645\n",
      "Eval Loss:  0.21146102249622345\n",
      "Eval Loss:  0.24075943231582642\n",
      "Eval Loss:  0.19127941131591797\n",
      "Eval Loss:  0.26423391699790955\n",
      "Eval Loss:  0.36230963468551636\n",
      "Eval Loss:  0.1837092936038971\n",
      "Eval Loss:  0.32995882630348206\n",
      "Eval Loss:  0.1988622099161148\n",
      "Eval Loss:  0.33316200971603394\n",
      "Eval Loss:  0.23473209142684937\n",
      "Eval Loss:  0.2883310914039612\n",
      "Eval Loss:  0.18347889184951782\n",
      "Eval Loss:  0.1916094571352005\n",
      "Eval Loss:  0.30812662839889526\n",
      "Eval Loss:  0.23114041984081268\n",
      "Eval Loss:  0.264160692691803\n",
      "Eval Loss:  0.4095631241798401\n",
      "Eval Loss:  0.13758240640163422\n",
      "Eval Loss:  0.2202306091785431\n",
      "Eval Loss:  0.39201241731643677\n",
      "Eval Loss:  0.30453693866729736\n",
      "Eval Loss:  0.21864448487758636\n",
      "Eval Loss:  0.1553676724433899\n",
      "[[16121  2613]\n",
      " [  699 10364]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91     18734\n",
      "           1       0.80      0.94      0.86     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.88      0.90      0.88     29797\n",
      "weighted avg       0.90      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8888478705909991\n",
      "pre:  0.798643754334592\n",
      "rec:  0.9368164150772846\n",
      "ma F1:  0.8845377709068449\n",
      "mi F1:  0.8888478705909991\n",
      "we F1:  0.890280827130077\n",
      "29797 466\n",
      "Loss:  0.028276100754737854\n",
      "Loss:  0.043311476707458496\n",
      "Loss:  0.07971824705600739\n",
      "48 **********\n",
      "Epoch:  2809.407215833664  fold:  2  kers:  64\n",
      "epoch:  49\n",
      "29797 466\n",
      "Loss:  0.07715758681297302\n",
      "Loss:  0.05436461791396141\n",
      "Loss:  0.07312493771314621\n",
      "49 **********\n",
      "Epoch:  2853.5641491413116  fold:  2  kers:  64\n",
      "epoch:  50\n",
      "29797 466\n",
      "Loss:  0.050985898822546005\n",
      "Loss:  0.0631459504365921\n",
      "Loss:  0.07241751253604889\n",
      "50 **********\n",
      "Epoch:  2897.886640071869  fold:  2  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.6926126480102539\n",
      "Eval Loss:  0.5039104223251343\n",
      "Eval Loss:  1.0767196416854858\n",
      "[[1095  335]\n",
      " [ 508 1156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72      1430\n",
      "           1       0.78      0.69      0.73      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.73      0.73      0.73      3094\n",
      "weighted avg       0.73      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7275371687136393\n",
      "pre:  0.7753185781354796\n",
      "rec:  0.6947115384615384\n",
      "ma F1:  0.7274312201285071\n",
      "mi F1:  0.7275371687136393\n",
      "we F1:  0.7278376458485222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20533661544322968\n",
      "Eval Loss:  0.16264668107032776\n",
      "Eval Loss:  0.11534281820058823\n",
      "Eval Loss:  0.18797962367534637\n",
      "Eval Loss:  0.17456692457199097\n",
      "Eval Loss:  0.13121019303798676\n",
      "Eval Loss:  0.14843392372131348\n",
      "Eval Loss:  0.20201238989830017\n",
      "Eval Loss:  0.15824009478092194\n",
      "Eval Loss:  0.20312510430812836\n",
      "Eval Loss:  0.3182131350040436\n",
      "Eval Loss:  0.1368151307106018\n",
      "Eval Loss:  0.2829936444759369\n",
      "Eval Loss:  0.11568904668092728\n",
      "Eval Loss:  0.22862772643566132\n",
      "Eval Loss:  0.19969706237316132\n",
      "Eval Loss:  0.18961456418037415\n",
      "Eval Loss:  0.15350723266601562\n",
      "Eval Loss:  0.1956525295972824\n",
      "Eval Loss:  0.21668128669261932\n",
      "Eval Loss:  0.14778323471546173\n",
      "Eval Loss:  0.23725107312202454\n",
      "Eval Loss:  0.31330662965774536\n",
      "Eval Loss:  0.12146566808223724\n",
      "Eval Loss:  0.18814663589000702\n",
      "Eval Loss:  0.3310526907444\n",
      "Eval Loss:  0.2478117048740387\n",
      "Eval Loss:  0.16986599564552307\n",
      "Eval Loss:  0.16509909927845\n",
      "[[17220  1514]\n",
      " [  950 10113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93     18734\n",
      "           1       0.87      0.91      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.92      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9173071114541732\n",
      "pre:  0.869785843295777\n",
      "rec:  0.9141281749977402\n",
      "ma F1:  0.9123190378199002\n",
      "mi F1:  0.9173071114541732\n",
      "we F1:  0.9177029568924355\n",
      "29797 466\n",
      "Loss:  0.07283544540405273\n",
      "Loss:  0.05748608335852623\n",
      "Loss:  0.07970236241817474\n",
      "51 **********\n",
      "Epoch:  2980.5506131649017  fold:  2  kers:  64\n",
      "epoch:  52\n",
      "29797 466\n",
      "Loss:  0.05371366813778877\n",
      "Loss:  0.08953620493412018\n",
      "Loss:  0.04387609288096428\n",
      "52 **********\n",
      "Epoch:  3024.846176147461  fold:  2  kers:  64\n",
      "epoch:  53\n",
      "29797 466\n",
      "Loss:  0.06153397262096405\n",
      "Loss:  0.07827889174222946\n",
      "Loss:  0.03685877472162247\n",
      "53 **********\n",
      "Epoch:  3069.006101369858  fold:  2  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.5875087380409241\n",
      "Eval Loss:  0.4742714464664459\n",
      "Eval Loss:  0.5903597474098206\n",
      "[[1059  371]\n",
      " [ 368 1296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1430\n",
      "           1       0.78      0.78      0.78      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.76      0.76      0.76      3094\n",
      "weighted avg       0.76      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7611506140917905\n",
      "pre:  0.7774445110977805\n",
      "rec:  0.7788461538461539\n",
      "ma F1:  0.7597408840721231\n",
      "mi F1:  0.7611506140917905\n",
      "we F1:  0.7611327694079975\n",
      "Eval Loss:  0.23427563905715942\n",
      "Eval Loss:  0.13634376227855682\n",
      "Eval Loss:  0.10376425087451935\n",
      "Eval Loss:  0.17696335911750793\n",
      "Eval Loss:  0.19143958389759064\n",
      "Eval Loss:  0.13244150578975677\n",
      "Eval Loss:  0.1715627908706665\n",
      "Eval Loss:  0.17615041136741638\n",
      "Eval Loss:  0.1527777463197708\n",
      "Eval Loss:  0.18547466397285461\n",
      "Eval Loss:  0.28861069679260254\n",
      "Eval Loss:  0.13923105597496033\n",
      "Eval Loss:  0.26192647218704224\n",
      "Eval Loss:  0.12887978553771973\n",
      "Eval Loss:  0.24863408505916595\n",
      "Eval Loss:  0.19739022850990295\n",
      "Eval Loss:  0.20881231129169464\n",
      "Eval Loss:  0.14561563730239868\n",
      "Eval Loss:  0.1671139895915985\n",
      "Eval Loss:  0.19578176736831665\n",
      "Eval Loss:  0.14546065032482147\n",
      "Eval Loss:  0.23777326941490173\n",
      "Eval Loss:  0.28534209728240967\n",
      "Eval Loss:  0.11124087870121002\n",
      "Eval Loss:  0.17883999645709991\n",
      "Eval Loss:  0.2803720533847809\n",
      "Eval Loss:  0.23813390731811523\n",
      "Eval Loss:  0.17773756384849548\n",
      "Eval Loss:  0.15881630778312683\n",
      "[[17140  1594]\n",
      " [  828 10235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93     18734\n",
      "           1       0.87      0.93      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.92      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9187166493271135\n",
      "pre:  0.8652464282695072\n",
      "rec:  0.9251559251559252\n",
      "ma F1:  0.9141039462936291\n",
      "mi F1:  0.9187166493271135\n",
      "we F1:  0.9192283554130873\n",
      "29797 466\n",
      "Loss:  0.07179471850395203\n",
      "Loss:  0.04418822377920151\n",
      "Loss:  0.0575743243098259\n",
      "54 **********\n",
      "Epoch:  3151.6311786174774  fold:  2  kers:  64\n",
      "epoch:  55\n",
      "29797 466\n",
      "Loss:  0.036954790353775024\n",
      "Loss:  0.0773303210735321\n",
      "Loss:  0.055997949093580246\n",
      "55 **********\n",
      "Epoch:  3196.150144100189  fold:  2  kers:  64\n",
      "epoch:  56\n",
      "29797 466\n",
      "Loss:  0.04164677858352661\n",
      "Loss:  0.054587602615356445\n",
      "Loss:  0.04567060247063637\n",
      "56 **********\n",
      "Epoch:  3240.7279522418976  fold:  2  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.5424264669418335\n",
      "Eval Loss:  0.6945742964744568\n",
      "Eval Loss:  0.45266085863113403\n",
      "[[ 947  483]\n",
      " [ 352 1312]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69      1430\n",
      "           1       0.73      0.79      0.76      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.73      0.73      0.73      3094\n",
      "weighted avg       0.73      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7301228183581124\n",
      "pre:  0.7309192200557103\n",
      "rec:  0.7884615384615384\n",
      "ma F1:  0.7263139339110478\n",
      "mi F1:  0.7301228183581123\n",
      "we F1:  0.7287557940771112\n",
      "Eval Loss:  0.22044534981250763\n",
      "Eval Loss:  0.15147122740745544\n",
      "Eval Loss:  0.12018939107656479\n",
      "Eval Loss:  0.1797492504119873\n",
      "Eval Loss:  0.17509378492832184\n",
      "Eval Loss:  0.12695898115634918\n",
      "Eval Loss:  0.16519570350646973\n",
      "Eval Loss:  0.21355609595775604\n",
      "Eval Loss:  0.14913754165172577\n",
      "Eval Loss:  0.18060703575611115\n",
      "Eval Loss:  0.3140403926372528\n",
      "Eval Loss:  0.1318250447511673\n",
      "Eval Loss:  0.2680991291999817\n",
      "Eval Loss:  0.14903941750526428\n",
      "Eval Loss:  0.2613743841648102\n",
      "Eval Loss:  0.1877841055393219\n",
      "Eval Loss:  0.24420344829559326\n",
      "Eval Loss:  0.16076035797595978\n",
      "Eval Loss:  0.1780904084444046\n",
      "Eval Loss:  0.2236216813325882\n",
      "Eval Loss:  0.15362143516540527\n",
      "Eval Loss:  0.22661595046520233\n",
      "Eval Loss:  0.32027313113212585\n",
      "Eval Loss:  0.11398777365684509\n",
      "Eval Loss:  0.19488829374313354\n",
      "Eval Loss:  0.32531583309173584\n",
      "Eval Loss:  0.2663106322288513\n",
      "Eval Loss:  0.17584970593452454\n",
      "Eval Loss:  0.1460741013288498\n",
      "[[16944  1790]\n",
      " [  750 10313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93     18734\n",
      "           1       0.85      0.93      0.89     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.90      0.92      0.91     29797\n",
      "weighted avg       0.92      0.91      0.92     29797\n",
      "\n",
      "acc:  0.9147565191126623\n",
      "pre:  0.8521027844336115\n",
      "rec:  0.9322064539455844\n",
      "ma F1:  0.9103149865384045\n",
      "mi F1:  0.9147565191126623\n",
      "we F1:  0.9154531250359361\n",
      "29797 466\n",
      "Loss:  0.06009417772293091\n",
      "Loss:  0.05911942571401596\n",
      "Loss:  0.05225416272878647\n",
      "57 **********\n",
      "Epoch:  3323.5355412960052  fold:  2  kers:  64\n",
      "epoch:  58\n",
      "29797 466\n",
      "Loss:  0.03676120564341545\n",
      "Loss:  0.04991469159722328\n",
      "Loss:  0.031056389212608337\n",
      "58 **********\n",
      "Epoch:  3367.7732586860657  fold:  2  kers:  64\n",
      "epoch:  59\n",
      "29797 466\n",
      "Loss:  0.023207854479551315\n",
      "Loss:  0.07042371481657028\n",
      "Loss:  0.03662046045064926\n",
      "59 **********\n",
      "Epoch:  3412.115695953369  fold:  2  kers:  64\n",
      "Eval Loss:  0.5137113928794861\n",
      "Eval Loss:  0.2910778820514679\n",
      "Eval Loss:  0.595721423625946\n",
      "[[1136  294]\n",
      " [ 469 1195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75      1430\n",
      "           1       0.80      0.72      0.76      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.76      0.75      0.75      3094\n",
      "\n",
      "acc:  0.753393665158371\n",
      "pre:  0.8025520483546004\n",
      "rec:  0.7181490384615384\n",
      "ma F1:  0.7533039583127599\n",
      "mi F1:  0.753393665158371\n",
      "we F1:  0.7536597447851839\n",
      "update!  Acc:  0.7747252747252747\n",
      "Epoch:  3415.733024120331  fold:  2  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0mklEQVR4nO3dd5hU5fXA8e/Zpfe2FBdwAakWSlawBUFEigVNNAH9KVETJILdGNRY0BiJ0Rhb7NgSRY2iKE3EBqj0DgILLLCwwEoXhGWX9/fH3Fnuzt6ZudNnds7nefbZmdvmvTtwz71vOa8YY1BKKZV+MhJdAKWUUomhAUAppdKUBgCllEpTGgCUUipNaQBQSqk0VSXRBQhFkyZNTE5OTqKLoZRSKWXhwoU/GmOyfJenVADIyclhwYIFiS6GUkqlFBHZ5LRcq4CUUipNaQBQSqk0pQFAKaXSlAYApZRKUxoAlFIqTWkAUEqpNKUBQCml0lTaBIClW/ayrGBvoouhlFJJI6UGgkViyHNzALj+nDZ0b92Ai047IcElUkqpxEqbAOD16uyNABoAlFJpL22qgJRSSpXnKgCIyEARWSMieSIyxmF9JxH5TkSOiMidtuUdRWSJ7We/iNxqrXtQRLba1g2O2lkppZQKKmgVkIhkAs8B/YECYL6ITDLGrLJtthu4GbjUvq8xZg3QzXacrcBE2yZPGmMej6D8SimlwuTmCaAnkGeM2WCMKQYmAEPsGxhjdhpj5gNHAxynH7DeGOOYlS7eSkqPJboISimVUG4CQDawxfa+wFoWqqHAOz7LRovIMhEZLyINnXYSkREiskBEFhQVFYXxsc5OuncqpcdM1I6nlFKpxk0AEIdlIV05RaQacAnwvm3x80A7PFVEhcATTvsaY14yxuQaY3KzsirMZ+DKqLcXOS5/f8EWx+VKKZUO3ASAAqCV7X1LYFuInzMIWGSM2eFdYIzZYYwpNcYcA17GU9UUE5OXFTou33ngSKw+Uimlkp6bADAfaC8ibaw7+aHApBA/Zxg+1T8i0sL29jJgRYjHjFiG07ONUkqliaC9gIwxJSIyGpgOZALjjTErRWSktf4FEWkOLADqAcesrp5djDH7RaQWnh5EN/gc+jER6YanOinfYX3MiWgEUEqlL1cjgY0xU4ApPstesL3ejqdqyGnfQ0Bjh+VXh1TSGNDrv1IqnaX1SODikmOs2rafF79en+iiKKVU3KVdLiC7f32+jn99vg6AG85tl+DSKKVUfKX1E0Cs7Nh/mNvfW8KRktJEF0UppfzSABADYz9ZyYeLtvL5qp2JLopSSvmlAUAppdKUBgDLrRMWs/PA4UQXQyml4iYtAkB2g5pBt/loyTb+PnVNHEqjlFLJIS0CQOM61RJdBKWUSjppEQCqZabFabpytPQYK7buS3QxlFJJIC2ujH/o3dbVdia0JKcp6W9TVnPRM7PZUPRToouilEqwtAgAA05unugiJI1lBZ67/90HixNcEqVUoqVFAHCt8j8AKKVUGQ0ANnr9V0qlk7QJANNv7Z3oIiilVFJJmwCQ3TD4WIA12w9E9TPToVFZKZW60iYAuEn9v6pwf5Q+SycaUEolv/QJAHG8Juudv1IqFaRPAEjAXbk+CSilklnaBIDqVTKoWz2t579RSqly0iYAZGQIy8cOSHQxlFIqabgKACIyUETWiEieiIxxWN9JRL4TkSMicqfPunwRWS4iS0RkgW15IxGZISLrrN8NIz8dpZRSbgUNACKSCTwHDAK6AMNEpIvPZruBm4HH/RymrzGmmzEm17ZsDDDTGNMemGm9V0opFSdungB6AnnGmA3GmGJgAjDEvoExZqcxZj5wNITPHgK8Yb1+A7g0hH1jZnmBZspUSqUHNwEgG9hie19gLXPLAJ+JyEIRGWFb3swYUwhg/W7qtLOIjBCRBSKyoKioKISPdda1Zf2A6y9+dnZIx1tf9BM5YyYzbcX2SIqllFJx5yYAOPVlDKWj+9nGmB54qpBGiUhIORmMMS8ZY3KNMblZWVmh7Bq2IyWl7DsU/GHmvQVbuO71+QBMXVEY62JFhTE6RkEp5eEmABQArWzvWwLb3H6AMWab9XsnMBFPlRLADhFpAWD93un2mJHo09HxQaOc342fT9eHPgu63V3/W8amXYf8rk/mAWHxHBinlEpObgLAfKC9iLQRkWrAUGCSm4OLSG0Rqet9DVwArLBWTwKGW6+HAx+HUvBwDevZOug2323YFdFn6AAwpVQqCBoAjDElwGhgOrAaeM8Ys1JERorISAARaS4iBcDtwF9EpEBE6gHNgNkishSYB0w2xkyzDj0O6C8i64D+1vuYC+XO98FJK13PnKU1K0qpVONqaKwxZgowxWfZC7bX2/FUDfnaD3T1c8xdQD/XJY2SUO7NX/82nzl5PzLj9nNjVh6llEqUtBkJXCYOtTPJXPevlFJeaRcAsupUD3mfdTsOhNV7RtsClFLJLO0CgIhwRttGrrdft/Mn+j/5Da/M2hhwOwNs2/szD32yitJj+gSglEp+aRcAAO4Z3DnkfZYU7A26ze3vLWH8nI0s3BR8W6WUSrS0DACxukHXO3+lVCpJywCQjKNhd+4/zJGS0rh9XhL+CZRScZaWAUCiMAy2uORYufdOQaVw38+uj9fzbzMZ9d9FEZcrmGicu1KqckjLABAsIZwbI95aEHSbv05eHdIxP1+9s0JgUUqpWEnLABDOXfCeg8Xlsn5+taZiZlKnbp9HS0O7oP/r87Xl3h88UsI/P1sT8nGUUiqYtAwA4fh2vSc/0Mj/LAxpv2tfmx/S9tv3Hy73/p8z1vL0F3l8uKggpOP4462q2lB0MCrHU8Ft/PEgB4+UJLoYSlWgASAMew4WV1hmcB4BPDvvxwrLpi4v5O25m1191s9HPQ3DR0tDa7WdsWoH7873/xl3fbCM4ePnhXRMFZ6+j38V8o2AUvHgKheQKu/RqYHr9oPVMP3Rauy9slfwzKTh+sObnjaK357u/zO+XluxGmvzrkM0rVedGlUzY1a2eDp4pIQqmUL1Kok9n3n5uxP6+Uo50SeAMExfuSPg+mh2sQx2rHfmbXadsTSYw0dL6f2PL7n9vSVROd6cvB/JGTOZ/B8TV9108gPTufDp0GZ5UypdaAAIw76fnWcLO94I7C4CDH3pO465HDzm76ni7g+Xc/Ez0bnAeRuav1lbsdoqHBMXbwUSf/ebtzM6AVKpykargKIljLv+7zfsprj0GDUyKlZPfLiogPZN67o6zsHi+A0gc2Paiu3UreH8T+v61+fTsmFNxg45Jc6lUkr5StsA8NTQbtwyYUmii+HX7e8tTXQRwubtKXX5LypOETHzB8/MnxoAgis9ZiguOUbNapWjPUYln7StAhrSLTvRRQhJIlNLT1xcwNIte8M/gKadCMs9Hy6n8/3Tgm+oVJjSNgDEgreuO5Z5dmatK6Jgj/+J6CPhr9i3vbuUIc/NCfl4mnQiMu8u2JLoIqhKTgNAlNgbhnc5jBMo2+6QcwOyXaBkdVe/Oo8LnvzGdbkOHy3lpwCDkBZuqthA+9ORkqRMmKdS3+Rlhez66Uiii6EsGgCixGnAl9dHi7eWXVDHTQs8huDDRVv5ZFlhheX2XkCHAjT6Hj5aytTlx/fvdN80Tnlgut/tx039wc9xNPWEiq6iA0cY9fYiRrwV2mh6FTsaAOLg1neXlKWSOOKT7O0bh8FYu13cIa3bcaBCfqBJS7fR6b5pPPtlnuuyzc/fw5BnK3YjjWbS0Ls+WFZh2ZrtB4Lut7xgHyu27oteQVJIZUwK6P33um2v+yy5KrZcBQARGSgia0QkT0TGOKzvJCLficgREbnTtryViHwpIqtFZKWI3GJb96CIbBWRJdbP4OicUnI6cNi5GmbEWwtZua38Re7BT1YFPV7/J7/hEVu20dJjhpmrPQPUVhfuD6lsSwv8X2SLDsTmcX3Av4JXY1387GwuCjDG4UhJKcNe+p5lLmZrC8eeg8Vc9u85bHV5wdp7qJi7P1zG4aORd8t949v8iI+hVDBBA4CIZALPAYOALsAwEenis9lu4GbgcZ/lJcAdxpjOwBnAKJ99nzTGdLN+poR7EuEa1jN2qRhC4WakqtMN+aLNe8pej3gzeHrqUHS6bxq/e20ev4/guLGeemDdjp/4bsMu7v5weUyOP3HxVhZv3svL32xwtf3jn63hnXlb+N/CyBP3/RyFIKJUMG6eAHoCecaYDcaYYmACMMS+gTFmpzFmPnDUZ3mhMWaR9foAsBpImv6XLRvWjPtnbt93OPhGfgRqmPX2rwfndNc5YyYzaek2v/svyN9doffSV2uKIuv+GUObdh0M+HSQCDojqEo1bgJANmDvj1ZAGBdxEckBugNzbYtHi8gyERkvIg397DdCRBaIyIKioor15ZGokhG/jorea/LaHeGnJdi0q3z3z1A76kxets1vV8/LX/iO7zfsCq9gfsSyI9HizXv9rtt36GilrENXKtrcBACnq2RI/7VFpA7wAXCrMcZbQf080A7oBhQCTzjta4x5yRiTa4zJzcrKCuVjg+rXuWlUjxdLoVSnhBvWduwP/+kkHAOe/IbLn/824uP4BpquD33Gda9r+mWlgnETAAqAVrb3LQH/dQk+RKQqnov/f40xH3qXG2N2GGNKjTHHgJfxVDXFVcNa1eL9kWFbXXigQtR1mn8A/AeLr9YUOc5lUHa8KN+xBwtaa3YcYMGmPYE3CtPsvB9jkoW0/b1T+O2L3zmui9UTj47JULHiJgDMB9qLSBsRqQYMBSa5Obh4KqNfBVYbY/7ps66F7e1lwAp3RY6exnWqx+2zRv5nIVt2Hwq7YfT1b/N567tN5Zb5y0rqz5GSY+Tv8j+KuLJdaPo8/lXUj3m01DB3Y+DsprFu/Faxt33fYXLGTC7rWVdZBU0GZ4wpEZHRwHQgExhvjFkpIiOt9S+ISHNgAVAPOCYit+LpMXQacDWwXESWWIe8x+rx85iIdMNTnZQP3BDF80o6xsDfpqyOqFvlUp/ujlt2R7c/dbJc/hdu2sOxEIJRspQ7GazZfoB2WbWpkqlDfCLh7Vr8zrwt9OvcLLGFiSFX2UCtC/YUn2Uv2F5vx1M15Gs2fqqkjTFXuy9m5RDpDfZCl9UlnsRxqXtZ/LVDu8DeQ8XUr1m1rIeT/S47WZ5cjlhdN0N9MouW/B8PMuBf3/CHX7bh3gt9e2orVZHeJsTRtJXb4/NBYVZBjA0yAM2ehG7Gqh3kjJkcsE3BnsE0ksFRW3YfottDM3h19sawjxEPH1oT4Dw5Y21Uj+s2vv1ojSBfZPWQOny0lEenrubnJJsvIknitUIDQKXy+arY1lee8/cvy16/PMszOGrNjuApHSCyka2bd3sCzxc/7OSWCYu5+tW5QfaoXNreM4Wv1uwMvqGPN77N58WvN/DiN+tjUKrQRbttpKT0GB8v2RrjJ8DKHa00AFQi3pnBkrENsiQKo6SMgY+XbGPWuuhMWZnMfL/Df38Z+kXcm3vHN2dULNwyYTFfhhGkIvHiNxu4ZcKSgAMcw+U0mDIU367/MWAW3mShAUCFJ8Tr+eLN4Xf3DPZf8ZgxrudWjrdY5VIKJBFtIh8v2ca1r0U+9uK0B6fzl4/cpfbwjlvZGyDFujGGT5ZuczUw8Pmv1rPZ6iUXyd+w6MARrnx5Lje/szjsY8RL2geAdlm1E12EqItnN8RAH2Uvx+er/d8dzlpXRId7p7Jz/2EOHA7wn9lP1Fm74yfa3hM4ldTbczcza10R//ne05XWGMOjU1cHnDA+3L+j/e5x+da94R0krM91Xh7reOCbzNAfN+XYf7iE/3y/OcISHTdz9U5uemcxT80M3C5TdOAIf5/2A1ePj7x60dvetTZI9ejho6U89fk6jpQkro0m7QPAv6/6RaKLEHXxyOXv72IcjqtfnUdx6THu+3gFpz74WYX1h6PwH+Seicu5+tV5/OUjz3CT7fsP8+LXGxg+fl7Ex/blNm4YY3j+q/VljbcBtw3j7+1UjWGMifoTgptkhnbxvEHZc8jTSWH7vsB/Y+/fxDvXRqRVQG68OnsjT36+NqGZX9M+AHRsXjfRRUgp78yL3t2Zr+krnRuxr3vdk5E0mtct77FCGW/g5K3vN5EzZjIHbfW9bg+5tGAff5/2A7e/tzSiMvgK9PFt7p7CNTEIeslg865D5IyZ7DjHRjLyPinYb9iGj5/HqQEmcIq2tA8AKjTe1Mvz8z11+oHulCbMj92ctrG6Q3v401W89f0mx3VOUxl6U0Xb7+JLbRFAAjwPlFiNs3PyfiRnzGTmBRlhHJy7v0kyNqIvL9gXcWPuAmt604lWd9xQuJ3zwa645BhDnpsT1SSKX68t4kAcG481AKiIvPFdftw+K9iNtdsG10BjEl6dvZH7PiqflcR7QfnbFOfpM30FuwzPWldE27sns99q7yi1GrC/Xuu/nSSSB5XkbB4v7+JnZ8ek0dTNuX/xww4u+7dn8KHvdxfo775lzyGWbtnLPT7zUew8EN+kipHQAKAiMnlZIYOfmuWqF06sH81Pf+RzV9t1um9aSMf1jux1W11kfzi51iEr6TNf5HHMeBL8uRXti3gq5rh5bc5GPlhYwA/b9/Pr578NODe2r0APjMtsM+JF+ndesXUfv37eOVlgMtIAoCK2qnA/xS76mkdc92z73xnrLnaR3MW5vVsPtzF2xdZ9/HeuczWV28+//o3oziAXiTl57qqkxn6yijveX8pfP13Nwk17ylKj+F7co9HIvdUa9e4UOA4VlzDoqVmO81X761W252AxhfuSby5kDQAqZJsdMop6e1ukCvslYvHmPeSMmcwP24/Ppez7WO/raOmxuE46Y7+oXfTMbO6dWDF5bqK6gUbqqleiM7I7Gs1C3kMEmpd78ea9rC7cz6NWlaCbP2+vR2dy5qNfRF7AKNMAoELW+x9fVlh25qNfBO33nIyE4w3bA/81q2z5t+t3sSD/+OA1Y0y5xsVzH/uSDn+Z6nzMIBciN429/i/mxy83W3b7T+3tphz+FJdElmLhUHEJ787f7Hf/aAek6Su3c+1rsenZZIynzcg+mtr7Zw2la26yzlCnAUBFzQVPfpPoIrhmb+h1SlNxqLiUycsLy9779szYFmBu50A9f+x8L4Ru9rOnAP/lY1865giK9Pr6zBfruGXCEr/dcoMZO2kVf/5gOd+tL987JpSLYCgzxc3J28WXa463L5U7f58/xqkPTueeieWf7pYXBB7I1um+aeXK4+2B5v3+NsZg4qF40QCgUkY0B5998cPxC6ebO93fv57YOnNvCUt9yvo7W/oF3/Dxmc8FvNRlugxvioX/+OkOG4y3S6xvI+2vQriou5kpzvd7CxRAvWsOHC7h7bnlx7LM/CF4DqOltiDhfbKyf/pch66guwNkyk0WruYDUCoZzM8PflGIlXn5kfbRryiUcBZOtcmSLXutz/HsbH+icWO2y8ZZt6J1QUzUjGvegFNWBWT7Tn78yXNu9rKF0kspUfQJQKW1Hw8Ws74ouo/wkVygSkqPOd6pL9myl9y/uuvm6o+bORn2HirmZ9vI1JLSY/z6+W+ZHcbgsUif1+b7CbrBgmGsGr1PeWA6/Z742jYI0d0HBcsKmshGeg0AKq3Fs3HOW7USSKf7pnGuQyM7eKpWXMWWCK4o3R6awSe2Ebk//lTMwk17uOP9Ja6PYQ+AeTt/ImfMZDYU+U+6588VL4TWn977ueusz1xesC9gteHqwv0hZZE9WFzKhh8PkuGtArLtOurtRRwqdr7Q9//n187ldfGZx44Z11V34dAAoKJqXQr2BIqGDS4aAv/wZvl2hAqNwOJpkC7Y47+/uFPKgveslBv+0mO8+PWGoGULJtyY8vEST8+pT5cdr37avv8wj05Z7Wr/ycsKWbVtv2NDbb5Dd2TwXNihfJWX758mZ8xkBj01q8IsczsPHOGUILl4nNoAwH9a6sIAHQYCWV/0E53um0a7IJluI6FtACqq+qdQT6Bo8HYPtOfCP1JyjD0HPXMY2wXKW+/LX7WUU5/5uz5YRvP6Najn83m+/N1x/vKxLzjlhPqMHXJyxX0iqM4K1Lj+4jcbuHtw56DHGPX2ovAL4MIyh8Fc9iob5zPw9gKKbd1NvyecnxyiydUTgIgMFJE1IpInImMc1ncSke9E5IiI3OlmXxFpJCIzRGSd9bth5KejVHz5u7vr/vAM/ukzN7BvdYTve3vyvFATmtlHWfu7LPlbvmX3z0xdsZ0731/m9/ihXeo8F8hYdY/c7qIqzSvYNXpnCMfyyvDzBJCKggYAEckEngMGAV2AYSLSxWez3cDNwOMh7DsGmGmMaQ/MtN4nxM392ifqo1WUPfxp4Int42n6yu0hbR/p7GGBbtYPFZcEvWN1aiR26vHi1qNTfyjLs+Pvoj1tRWg9k8B/ugVfIscv0gcOl/Dvr/IqbDM3yKA8p7+pt6otlCe6ZOXmCaAnkGeM2WCMKQYmAEPsGxhjdhpj5gO+f5FA+w4B3rBevwFcGt4pRO72/h3IH3dhoj5eRZFvnW4ye2VW/Mra5f7p/PkDd1MtlhNhl8stVk4d37734GngHPmf2FbxeE1dsZ3Hpq0JeT+nMQKB/iRPzVwX8mckkpsAkA3YE7sXWMvcCLRvM2NMIYD1u6nTAURkhIgsEJEFRUWpMdGDUlCxisD3Ljrak4YftHqhLCvYx4eLCoJu/+CkleXeB66ycf8IYG832BCgi22sq1BiNVzg79P8pwUPdL7BLIjBWJNg3AQAp7+j2+8ukn09GxvzkjEm1xiTm5WVFcquSqWVEW8uLHv9tIs70dd9piJ0qoJym9YiGcRjGkfw5IlyMm6qu/ki/LE/EYbTNhEONwGgAGhle98ScDt1T6B9d4hICwDrd/Dx2EqlsII9P5MzZnLMjh/tJwo7+9PL8PHzKjRwe01cXMBPh92V48KnZwXfKIU4zWj2XoBZ8b4OMD/Gn/7nv0E+mtwEgPlAexFpIyLVgKHAJJfHD7TvJGC49Xo48LH7YiuV/GLdTTAaxgdpM3G6qf56bZHfJ4zb3l3Kdy6nSPxhe2zHjIgkPhX2XR+Uv5B78yTNWldULr/QkzPWMs3WaeCoi/k1oiFoADDGlACjgenAauA9Y8xKERkpIiMBRKS5iBQAtwN/EZECEannb1/r0OOA/iKyDuhvvVdKxdFDQXpNeS+g3utowZ7jg6++teYyTha+sWrdjtBHH8da7l8/Z+LiggrVbb6Nx77VTNc5zCwXDa4GghljpgBTfJa9YHu9HU/1jqt9reW7gH6hFFapVBLtHEOhiNaNr3eaTe/TzMXPzC5bd2WUJnKJlu0+YzI+W7WDPh0d+5Yk1LQV2zmv0/FyrSoMnI4aymevjSYdCaxUJbTJT5qEcHnnTNiTxH3fH3FIL7GsYG/8CxLE9JU7ys21sHjz3oSVRXMBKaWCOuCyYTfZTAjQCKs0ACilVNrSAKCUUmlKA4BNRuqMeVFKqYhpAFBKqQTaGWESwEhoAFBKuTIgzeZ6SAcaAJRSrqxJ09neKjMNADZN6lRPdBGUUipuNADYfPDHs/jH5acluhhKKRUXGgBsWjWqxRW5rYJvqJRSlYAGAKWUSlMaAJRSKk1pAFBKqTSlAUAppdKUBgAHvTvo3MNKqeSyoSj6E9xoAHCgKYGUUslm5bb9UT+mBgAHyT+Tq1JKRU4DgFJKpSkNAA60CkgplQ5cBQARGSgia0QkT0TGOKwXEXnaWr9MRHpYyzuKyBLbz34RudVa96CIbLWtGxzVM4uAaARQSqWBoJPCi0gm8BzQHygA5ovIJGPMKttmg4D21k8v4HmglzFmDdDNdpytwETbfk8aYx6PwnlEVU7j2kBRoouhlFIx5eYJoCeQZ4zZYIwpBiYAQ3y2GQK8aTy+BxqISAufbfoB640xmyIudYzVqxE0LiqlVMpzEwCygS229wXWslC3GQq847NstFVlNF5EGjp9uIiMEJEFIrKgqCg+d+U39j0pLp+jlFKJ5CYAONWI+/aUDLiNiFQDLgHet61/HmiHp4qoEHjC6cONMS8ZY3KNMblZWfEZoFWjamZcPkcppRLJTQAoAOw5klsC20LcZhCwyBizw7vAGLPDGFNqjDkGvIynqilp/P6cNokuglJKxZSbADAfaC8ibaw7+aHAJJ9tJgHXWL2BzgD2GWMKbeuH4VP949NGcBmwIuTSx9BfLuqS6CIopVSZL3/YGfVjBm3tNMaUiMhoYDqQCYw3xqwUkZHW+heAKcBgIA84BFzr3V9EauHpQXSDz6EfE5FueKqK8h3WK6WUsszduDvqx3TV3cUYMwXPRd6+7AXbawOM8rPvIaCxw/KrQyqpUkqpqNKRwEoplaY0ACilVJrSAKCUUmlKA4BSSqUpDQBKKZUCtu8/HPVjagBQSqkUUHos+lNVaQBQSqk0pQHAhc9vPzfRRVBKqajTvMcB/G/kmVTNzOCkpnUSXRSllIo6DQAB5OY0SnQRlFIqZrQKyKWuLesnughKKRVVGgBcuv2CjokuglJKRZUGAJc8+e6UUqry0ACglFJpSgOAUkqlKQ0AIerdIT7zEiulVKxpAAhDt1YNEl0EpZSKmAaAMHw06mya1KlWblndGjqkQimVWjQAhOmqXieWe/+Py09LUEmUUio8GgBc6tyiHgDDTm8FwK3nty+3vlHt6nEvk1JKRcJVABCRgSKyRkTyRGSMw3oRkaet9ctEpIdtXb6ILBeRJSKywLa8kYjMEJF11u+G0Tml2GhWrwb54y5k0KktABCRcut93iqlVNILGgBEJBN4DhgEdAGGiUgXn80GAe2tnxHA8z7r+xpjuhljcm3LxgAzjTHtgZnW+5QlwPx7z+f+i3z/NEoplZzcPAH0BPKMMRuMMcXABGCIzzZDgDeNx/dAAxFpEeS4Q4A3rNdvAJe6L3Zy+L8zWgNwSdcT6NG6IVl1q3NO+yYJLpVSSrnjputKNrDF9r4A6OVim2ygEDDAZyJigBeNMS9Z2zQzxhQCGGMKRaSp04eLyAg8TxW0bt3aRXHjZ+wlp/DHPieR3aCm4/rOLeqxunB/nEullFLuuHkCcKrd9k2ME2ibs40xPfBUE40Skd4hlA9jzEvGmFxjTG5WVnINwsrMEL8Xf4D+XZrFsTRKKRUaNwGgAGhle98S2OZ2G2OM9/dOYCKeKiWAHd5qIuv3zlALn/SM4c3revLIZaeEtNvTw7rHqEBKKXWcmwAwH2gvIm1EpBowFJjks80k4BqrN9AZwD6rWqe2iNQFEJHawAXACts+w63Xw4GPIzyXpNS7Q1aFMQPBXNL1hBiVRimljgvaBmCMKRGR0cB0IBMYb4xZKSIjrfUvAFOAwUAecAi41tq9GTDR6jJZBXjbGDPNWjcOeE9Ergc2A1dE7ayShfYNVUolMVf5C4wxU/Bc5O3LXrC9NsAoh/02AF39HHMX0C+UwqayHq0bsGjz3kQXQymlyuhI4Cjzd8//4Y1nx7UcSikVjAaAKDupaZ1EF4E7+nfgMc1NpJQKQgNAlIlIhTxB8XZuxyx+k9sq+IZKqbSmASBBXrkml9euPZ3zOjmOf2Pl2AG8du3pjOrbLuRjn5pdH4Bf6qhkpVQAGgBi4OQT6lu/6zmuXzl2AOd3aUbfjk25/BctHbepXb0KfTs25U8DOlElI7TeRN5EdW9d7ztgWymljtMAEAP9uzTj6z/1YcDJzR3X167u3Pkqq251Pr3pnArL5997flTLp5RSoAEgZk5sXDvkff50QUdOsapv7BrWruawdXR1bFY35p+hlEouGgASzNiyKvmrDoqFJnXKT2DzyvBcP1sqpSorDQBx9Mc+7WhRv4bjusGnNicjhLr+L+44lxev/gVv/95dPf+qhwaUe//XS0/hzet6Om7bvJ5zGQGe8ZOnaHTfk7i5X2J7PymlQqMzmcfRnwd24s8DO4W1729yWzJ95Q72/XwUgLZZdWib5X7MQa1q5b/qmtUy6d0h9OyqF3c9gY+XbOPA4aPM3bi7bPmdAzpijOH/zmhNz0dmhnxcpVT86RNAinjs8q4sfeACx3VDuvlPHvfyNblMvzWkDNzlTLzxrArLXhmey7s3nFlhuYjQtG7Fp4cQOzEppeJEA0Al8NTQ7rRq5DwvQf8uzejYPLQG3teuPb3sddVM//9E3E5/2bej81iHD/5YMbjc0b+D3+MM65lcEwIpleq0CijBOjb3VOP4u0i6ZXyn6AlTdoOadG7hPH7Btzvqdee0oVOLuhw+Wlpu+a3nt+dfn68L+DntsmqT6fBoEKgdpHoVvV9RKpr0f1SCndS0LivHDuCKCFM3hBoATmxUy9V2Gdagsu6tG5BVt3qF9We1a8J5ncrPfHbr+R14+w+BG6f7dGzqN3FetAVq1Pbnxat/EYOSKJVcNAAkAX8Dw2Jl6f0XkNPE3TiFzi3q8sUd54Y8qvisdsfTUPx50PGG75Oa1mHOmPO4e1DojeEmzMecuweH/lkDTm5OnTh/L0oFEs6NTDAaANJQ/VpVXW8rIrTNqhPRxbCDbZDZ27/vRXaDmlTJzKBanKp0csIYlAfw0ShN4a2SR7um4f07DkQDQApyuhh3a90AgN8GqErqbm3jJBaTl4371am8ck35AWZNbXcxvm0N/3U5piGQG/tUTJ7XtVUDJow4w/UxOlmN5smQ2lspr2i189npM26KefjSUzi7XeMKyxvU9NzV9zixgd9937/hTEpj8a/Ij6Eueu3Ur1mVfT8f5U8DOnJWu8Ys2bIXgOvPacOrszeW29ZNyWtWzXRcfkbbin8zf6be8kvX2yoVLxoAFFef4TzB/F0DOlE1M4NLu2f73bdKZkbSfuFX9WpdlsUUcKweilfsEp3LWaUJrQKqJOrXqsqDl5xM9SrOd8DJyrdht5o17qCqQ3fQ3JyGgKe6yt94gQ4hjnmIpYF+ssEqlSxcBQARGSgia0QkT0TGOKwXEXnaWr9MRHpYy1uJyJcislpEVorILbZ9HhSRrSKyxPoZHL3TUqlGrE6hV595Ijf0bstIh7r8wae2ACBThJv6tSd/3IVl6z4adTZv/74XA05uTqMg2VPr1nD/HPT8VT24/pw2nJLtPDYikKpVMvi/M8pXg43ue1K5951b1AtrfEP/Ls38rvv+7n4hH0+lp6D/8kQkE3gOGAR0AYaJiO8Q0EFAe+tnBPC8tbwEuMMY0xk4Axjls++Txphu1s+UyE5FheOz23ozZ8x5NK7t6eM/onfbmHzOc1f24FUXGUdrVM3k7sGdK+Quqhfkot2tVQPOOsnT9XTRff0Df0gIVUmDTm3BfRd1KQtQdn06ZjlmcP1k9DnUqJrBjX3acf9FJ5cbwRxK8PF1u+2px6mx27u8uUPCwZzGx8d93Du4c9hl8OfMto1Z98igqB9XxZabW4+eQJ4xZoMxphiYAAzx2WYI8Kbx+B5oICItjDGFxphFAMaYA8BqwH8ltYq7Ds3qkt2gJjWrZZI/7kKGn5UTk8+58LQW9Ovs/67VjSoZwrVn5/D+yIp5iPz504COFY+TWfFivuFv7h9Aa1XLZOwlJ/PKNbn84/LTyq2rW70Kp7aszw8PD6Jzi3pUq5IR8tNDD5/eWnPGnMfsP/ctl221e+uGFTLL5j0yyPF8AUafd3xfpyaOh4ecXPb6h4cH+j2OP++MOCNg2pBEeOKKrhHtH6jXXCKc2zH05I3BuPnGsoEttvcFVLyIB91GRHKA7sBc2+LRVpXReBFp6PThIjJCRBaIyIKioiIXxVWVkYggIjxw8cl0b13+n0prh1HNr1yTy9x7+jHKVuXivWDef7HnIdQ+Z3IoqbgFGH5WDlUyMyo0GH92e2iJ93zbQBrUqsqHN5Yff5DdoCYtGwYfue1bnou7Hk8SaD+9nm0aVdj36jNzyl7XqJpZFiQu7XZCVLrDJmJQXa+2jWhWr+Lo9VR1SVf/SR/D5SYAOP3P8H2IDriNiNQBPgBuNcbstxY/D7QDugGFwBNOH26MeckYk2uMyc3Kin4EVM6Gn3kiD9nuCmMl0o49M27rzaTRFQdsnd+lGc18Rk56B6Q1qFmN/HEXVhjdXKua/wb0M9oev2g6pcQAT/VOi/rOSfm8zj6pScD10erplD/uwnJzN9i7x57WsgF5tuqaQBfn5vVr8vnt50ZUlsu6ZwevlsMzXsOrbo0qDDqlOdkNPH/PagGeLlY/NJB3/uB+nIdbydYXLCMGvdPchOUCwD66qCWwze02IlIVz8X/v8aYD70bGGN2eF+LyMvApyGVXMXU2CGnxPcDg/zb9pcGon0IU1m2b1qHr9cW+Z1i84s7+rB178+O6/48sBNX9jqRhZv2cJbDOAyAyTc5jx/w9sw6rWV9TsmuT/64C8kZMxnw3+X01z1acmLjWpzYuPyd/w292/LiNxsAd8Hi7kGdeHTqDxWq36rYLqiz/9wXgFl39aWGFSii2eW2aqY4dusd1rMV78w7XnHgfUp58rddGdI1m4wMYdW2/Qx+ehZN6lRj277DjsevWS2TM/18J4GqpW467ySe+SLP7/r4jZgJbljPVjT1c+MRCTcBYD7QXkTaAFuBocCVPttMwlOdMwHoBewzxhSK51/3q8BqY8w/7Tt42wist5cBKyI4D6WCumtgJ/p0bEo3252mXfP6NRwbUMFzwWzTpDZtAuRQat3YuZrm0m4nULj3Z647p03Zsj/2acfzX60n98SGFB04zJGfioHjTyFP/Ma5/vruwZ2526cR94y2jbjiF84jwG84tx03nNuOktJjAOUysL527ekcOlJKg1qegNjKoSrNG58a167GroPFjp8RLt9pSb0a1KoWUpVcIG9e15MJ87fwkhU07VrZqtXaN63Dup0/BT3euyPO4LcvfR+VsrVpUpsv7+xDn398Sf6uQwG3ffRXpwVcH66gVUDGmBJgNDAdTyPue8aYlSIyUkRGWptNATYAecDLwI3W8rOBq4HzHLp7PiYiy0VkGdAXuC1qZ6Uqhd/ktuTZK52noAxHtSoZnNO+fBVMdoOaAasXoqFKZgY39WtfLulfM+tuLkPg/ZFncf9FXbh7UKewqjKe/G03fu1yPmn7k1Tfjk258LQWAbf3XoY/u603M27rTf64C2nrIpHgU0O78buzcvhVj2zucjkL3s3ntadu9Sr0aHW8jadJHU9w6tMpvHTpbbPqcI+LXk8DT6k4ZqN+zYo5s3qFMKLc3sZ018CKjerenlldTjjeSaBKnGdPctUyY3XRnOKz7AXbawOMcthvNn4e7o0xV4dUUpV2Hru8K/sOHY3pZ3xzV9+YHt+fy3NbMT9/Dzf1a0+TOtVpY3s6iIVQRzd7u916L4KN61SnsZ879sGnVrx4DumWzZBu/jv8PXBxF/p2bMqrszfy7JXdWV6wn76dmrJ8bPm5q5vWq8G8e/pRvUomb8/dXG7dv6/qEXKiv8X39af7wzM8b2x/kmvPbsPExVsp2HO8CvDi007gqzUVO56c1rI+ywr2AXBBl2Y8cMnJnD3uiwrb+c53sXLsALo/NINi62nM6/ErujJl+XbA017y/sKCkM4pEsmaGUClidaNarFy237HyWEAxLo5r1vDfQbTUPj73FA8M6y73+oMf+pUr8JzV/WI+LNj5cpeJ4IIQ08PPE/FxkdDH79pH8C36qGBABXmlLBr6pAG+cpercsGBvrKblDTb1uOv/YfoXxj+ENDTuairi1YsGk3N/Y5iV8+9mXZutv6d+Da1+ZzbocsXrrGeWzLbed3YPGWPbbjC7WrV2HtI4OYuXoH17+xoGxdrWpVmHVXXxZt3sPsdT86Hi9WNACohHrjup4s2rTHb0+UejWqcv9FXTg/wjEEsXRxDLrnJVpmhvjNO3VTv5O47d2lQMUni+FnnhhSNUm4olFR4nuMsZeczP0fr+Tj0WdTvYqnS61T3bs3L39XP21JALec357/fL+p7AmisUPgsf/tWjWqRatGtZiTpwFApZEmdapzQZCcOdfFuHokVdWvWZXt+w+T6aJ6x7tFoGSBbl3WvSXN69Usq5+3i3vvsRDYu/ICZSPHwdPY3attY6bfFnwcR+cW9Zh26y9p3zRwD7SrerXm4q4n8NWanVx8mrubBKcR57GkAUCpFPX6daczY9UOxyoSXxkZwtIHLqB2gLEOofDX7TLWzmrXmHU7f+J3IY5YX3r/BdSoVr6xP7tBzbJ05KHq1Lz86O5/X9WD1+ZsZH6+rdpHhPo1q1ZoC4ljRvagNAAolaJa1K/JNbYRvME49WpJJfa2g0CG9WzF45+tLeveCv5nwWtRvwb7fj4atNvpK9fk0jTAqOLBp7Zgfv7ucgEgGKdP9H2Y++7u86iSEbteahoAlFKVyqi+J/HHPie5auB/8/qefL9hN/WCdDI4P0D2VS+31Tc1racwe4Dyp1HtajFN8Z5c2ZuUUpXWpzedw5wx58Xs+JdZ7Rsi4rp3V9O6NaKWY+firla68iCffVa7xjw85GTGOqRa8X0CcNO+Ewl9AlBKxcUp2fVjevwnrujKo7861dW2TgkEI9XQuqNv2TBwPigRKZd8z2ct4MnOemn37HIpO2JBA4BSqlLIyBBqZASvLlk5dkBUxn/48o707tqyQcTHEpGYjX2x0wCglEortWOUmjqrbnU+vemciNJnx3s6ag0ASikVJZFWc3nzUsUrJ5AGAKWUShJ3XNCB6lUy+FUPd8n9IqUBQCmlkkTdGlUrpPuOJe0GqpRSaUoDgFJKpSkNAEoplaY0ACilVJrSAKCUUmlKA4BSSqUpDQBKKZWmNAAopVSaEpNM09MEISJFwKYwd28CxHfCzfiprOem55V6Kuu5pfp5nWiMyfJdmFIBIBIissAYk5vocsRCZT03Pa/UU1nPrbKel1YBKaVUmtIAoJRSaSqdAsBLiS5ADFXWc9PzSj2V9dwq5XmlTRuAUkqp8tLpCUAppZSNBgCllEpTaREARGSgiKwRkTwRGZPo8rghIvkislxElojIAmtZIxGZISLrrN8NbdvfbZ3fGhEZYFv+C+s4eSLytEh8Zx0VkfEislNEVtiWRe08RKS6iLxrLZ8rIjkJPrcHRWSr9b0tEZHBqXZuItJKRL4UkdUislJEbrGWp/T3FuC8Uv47C5sxplL/AJnAeqAtUA1YCnRJdLlclDsfaOKz7DFgjPV6DPB363UX67yqA22s88201s0DzgQEmAoMivN59AZ6ACticR7AjcAL1uuhwLsJPrcHgTsdtk2ZcwNaAD2s13WBtVb5U/p7C3BeKf+dhfuTDk8APYE8Y8wGY0wxMAEYkuAyhWsI8Ib1+g3gUtvyCcaYI8aYjUAe0FNEWgD1jDHfGc+/yDdt+8SFMeYbYLfP4mieh/1Y/wP6xespx8+5+ZMy52aMKTTGLLJeHwBWA9mk+PcW4Lz8SYnzikQ6BIBsYIvtfQGBv/RkYYDPRGShiIywljUzxhSC5x8z0NRa7u8cs63XvssTLZrnUbaPMaYE2Ac0jlnJ3RktIsusKiJvNUlKnptVhdEdmEsl+t58zgsq0XcWinQIAE7RNxX6vp5tjOkBDAJGiUjvANv6O8dUO/dwziPZzvF5oB3QDSgEnrCWp9y5iUgd4APgVmPM/kCbOixL2nNzOK9K852FKh0CQAHQyva+JbAtQWVxzRizzfq9E5iIpyprh/X4ifV7p7W5v3MssF77Lk+0aJ5H2T4iUgWoj/tqmagzxuwwxpQaY44BL+P53iDFzk1EquK5SP7XGPOhtTjlvzen86os31k40iEAzAfai0gbEamGp2FmUoLLFJCI1BaRut7XwAXACjzlHm5tNhz42Ho9CRhq9UBoA7QH5lmP6QdE5AyrHvIa2z6JFM3zsB/rcuALq142IbwXSMtleL43SKFzs8rxKrDaGPNP26qU/t78nVdl+M7CluhW6Hj8AIPxtPivB+5NdHlclLctnt4HS4GV3jLjqUucCayzfjey7XOvdX5rsPX0AXLx/INeDzyLNfo7jufyDp7H6qN47o6uj+Z5ADWA9/E00M0D2ib43N4ClgPL8FwMWqTauQHn4Km2WAYssX4Gp/r3FuC8Uv47C/dHU0EopVSaSocqIKWUUg40ACilVJrSAKCUUmlKA4BSSqUpDQBKKZWmNAAopVSa0gCglFJp6v8Bp3Z567bgrKgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.1689136028289795\n",
      "Loss:  0.16098803281784058\n",
      "Loss:  0.15371479094028473\n",
      "0 **********\n",
      "Epoch:  56.282511472702026  fold:  3  kers:  64\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.14043089747428894\n",
      "Loss:  0.14171746373176575\n",
      "Loss:  0.12440585345029831\n",
      "1 **********\n",
      "Epoch:  100.06444764137268  fold:  3  kers:  64\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.1205996572971344\n",
      "Loss:  0.10764483362436295\n",
      "Loss:  0.13982819020748138\n",
      "2 **********\n",
      "Epoch:  143.87630367279053  fold:  3  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.7192063927650452\n",
      "Eval Loss:  0.838018000125885\n",
      "Eval Loss:  0.3678755462169647\n",
      "[[1244  292]\n",
      " [ 507 1388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1536\n",
      "           1       0.83      0.73      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7671232876712328\n",
      "pre:  0.8261904761904761\n",
      "rec:  0.7324538258575198\n",
      "ma F1:  0.7667123506247326\n",
      "mi F1:  0.7671232876712328\n",
      "we F1:  0.7677368395114933\n",
      "update!  Acc:  0.7671232876712328\n",
      "Eval Loss:  0.3543263375759125\n",
      "Eval Loss:  0.38902026414871216\n",
      "Eval Loss:  0.3664592504501343\n",
      "Eval Loss:  0.421570360660553\n",
      "Eval Loss:  0.4059112071990967\n",
      "Eval Loss:  0.40500590205192566\n",
      "Eval Loss:  0.33503374457359314\n",
      "Eval Loss:  0.4529038369655609\n",
      "Eval Loss:  0.5073240995407104\n",
      "Eval Loss:  0.41908785700798035\n",
      "Eval Loss:  0.45326119661331177\n",
      "Eval Loss:  0.42145371437072754\n",
      "Eval Loss:  0.4082413911819458\n",
      "Eval Loss:  0.5724462270736694\n",
      "Eval Loss:  0.4608311653137207\n",
      "Eval Loss:  0.42576345801353455\n",
      "Eval Loss:  0.414463609457016\n",
      "Eval Loss:  0.3811938762664795\n",
      "Eval Loss:  0.38789552450180054\n",
      "Eval Loss:  0.3990100920200348\n",
      "Eval Loss:  0.48803263902664185\n",
      "Eval Loss:  0.38836926221847534\n",
      "Eval Loss:  0.4484052360057831\n",
      "Eval Loss:  0.47611570358276367\n",
      "Eval Loss:  0.4469403922557831\n",
      "Eval Loss:  0.46072477102279663\n",
      "Eval Loss:  0.43303731083869934\n",
      "Eval Loss:  0.2753579616546631\n",
      "[[15912  2716]\n",
      " [ 2715  8117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     18628\n",
      "           1       0.75      0.75      0.75     10832\n",
      "\n",
      "    accuracy                           0.82     29460\n",
      "   macro avg       0.80      0.80      0.80     29460\n",
      "weighted avg       0.82      0.82      0.82     29460\n",
      "\n",
      "acc:  0.8156483367277665\n",
      "pre:  0.7492845933721037\n",
      "rec:  0.7493537666174298\n",
      "ma F1:  0.8017700441716562\n",
      "mi F1:  0.8156483367277665\n",
      "we F1:  0.8156501171373312\n",
      "29460 461\n",
      "Loss:  0.13076020777225494\n",
      "Loss:  0.10221987962722778\n",
      "Loss:  0.1211795061826706\n",
      "3 **********\n",
      "Epoch:  226.75570058822632  fold:  3  kers:  64\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.10143429785966873\n",
      "Loss:  0.145918607711792\n",
      "Loss:  0.07704508304595947\n",
      "4 **********\n",
      "Epoch:  270.670282125473  fold:  3  kers:  64\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.05952247232198715\n",
      "Loss:  0.08246717602014542\n",
      "Loss:  0.08136732131242752\n",
      "5 **********\n",
      "Epoch:  314.9249541759491  fold:  3  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  1.0079809427261353\n",
      "Eval Loss:  0.728762686252594\n",
      "Eval Loss:  0.5765960216522217\n",
      "[[1416  120]\n",
      " [ 706 1189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.77      1536\n",
      "           1       0.91      0.63      0.74      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.79      0.77      0.76      3431\n",
      "weighted avg       0.80      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7592538618478578\n",
      "pre:  0.9083269671504965\n",
      "rec:  0.6274406332453826\n",
      "ma F1:  0.7581954009101526\n",
      "mi F1:  0.7592538618478578\n",
      "we F1:  0.7565214472685837\n",
      "Eval Loss:  0.3142506778240204\n",
      "Eval Loss:  0.441963255405426\n",
      "Eval Loss:  0.4116348922252655\n",
      "Eval Loss:  0.38585540652275085\n",
      "Eval Loss:  0.38229167461395264\n",
      "Eval Loss:  0.35780876874923706\n",
      "Eval Loss:  0.32573896646499634\n",
      "Eval Loss:  0.449077844619751\n",
      "Eval Loss:  0.5222480297088623\n",
      "Eval Loss:  0.43958115577697754\n",
      "Eval Loss:  0.4507272243499756\n",
      "Eval Loss:  0.37290406227111816\n",
      "Eval Loss:  0.39669638872146606\n",
      "Eval Loss:  0.48412975668907166\n",
      "Eval Loss:  0.4503532350063324\n",
      "Eval Loss:  0.38591647148132324\n",
      "Eval Loss:  0.41825050115585327\n",
      "Eval Loss:  0.3765598237514496\n",
      "Eval Loss:  0.3495859205722809\n",
      "Eval Loss:  0.3626132607460022\n",
      "Eval Loss:  0.4568905532360077\n",
      "Eval Loss:  0.34756386280059814\n",
      "Eval Loss:  0.4883442223072052\n",
      "Eval Loss:  0.4446321129798889\n",
      "Eval Loss:  0.4118821918964386\n",
      "Eval Loss:  0.4174863398075104\n",
      "Eval Loss:  0.4139893352985382\n",
      "Eval Loss:  0.23458591103553772\n",
      "[[17692   936]\n",
      " [ 3542  7290]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     18628\n",
      "           1       0.89      0.67      0.77     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.86      0.81      0.83     29460\n",
      "weighted avg       0.85      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8479972844534963\n",
      "pre:  0.8862144420131292\n",
      "rec:  0.6730059084194978\n",
      "ma F1:  0.8263477461930406\n",
      "mi F1:  0.8479972844534963\n",
      "we F1:  0.8425734528147011\n",
      "29460 461\n",
      "Loss:  0.0759691521525383\n",
      "Loss:  0.08001028746366501\n",
      "Loss:  0.0690598264336586\n",
      "6 **********\n",
      "Epoch:  397.5629971027374  fold:  3  kers:  64\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.060878124088048935\n",
      "Loss:  0.0778963714838028\n",
      "Loss:  0.08772914111614227\n",
      "7 **********\n",
      "Epoch:  441.38283133506775  fold:  3  kers:  64\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.07735255360603333\n",
      "Loss:  0.0814456194639206\n",
      "Loss:  0.08263592422008514\n",
      "8 **********\n",
      "Epoch:  485.3801918029785  fold:  3  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.9420337677001953\n",
      "Eval Loss:  0.2955435514450073\n",
      "Eval Loss:  0.5548816323280334\n",
      "[[1329  207]\n",
      " [ 544 1351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78      1536\n",
      "           1       0.87      0.71      0.78      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.79      0.79      0.78      3431\n",
      "weighted avg       0.80      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7811133780238997\n",
      "pre:  0.8671373555840821\n",
      "rec:  0.7129287598944591\n",
      "ma F1:  0.7811043780551592\n",
      "mi F1:  0.7811133780238997\n",
      "we F1:  0.7812512411814255\n",
      "update!  Acc:  0.7811133780238997\n",
      "Eval Loss:  0.24331484735012054\n",
      "Eval Loss:  0.40242552757263184\n",
      "Eval Loss:  0.36287224292755127\n",
      "Eval Loss:  0.32550135254859924\n",
      "Eval Loss:  0.3256053030490875\n",
      "Eval Loss:  0.29416775703430176\n",
      "Eval Loss:  0.2836209833621979\n",
      "Eval Loss:  0.4073646366596222\n",
      "Eval Loss:  0.4377671480178833\n",
      "Eval Loss:  0.35418811440467834\n",
      "Eval Loss:  0.34808245301246643\n",
      "Eval Loss:  0.3192259669303894\n",
      "Eval Loss:  0.3492274880409241\n",
      "Eval Loss:  0.34931784868240356\n",
      "Eval Loss:  0.36519935727119446\n",
      "Eval Loss:  0.31936877965927124\n",
      "Eval Loss:  0.37358856201171875\n",
      "Eval Loss:  0.3105229139328003\n",
      "Eval Loss:  0.3188501000404358\n",
      "Eval Loss:  0.30175891518592834\n",
      "Eval Loss:  0.34215012192726135\n",
      "Eval Loss:  0.29406845569610596\n",
      "Eval Loss:  0.4329970180988312\n",
      "Eval Loss:  0.3545893132686615\n",
      "Eval Loss:  0.37704625725746155\n",
      "Eval Loss:  0.4017782509326935\n",
      "Eval Loss:  0.3617927134037018\n",
      "Eval Loss:  0.22223037481307983\n",
      "[[17538  1090]\n",
      " [ 2651  8181]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     18628\n",
      "           1       0.88      0.76      0.81     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.85      0.86     29460\n",
      "weighted avg       0.87      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8730142566191446\n",
      "pre:  0.882429079926653\n",
      "rec:  0.7552621861152142\n",
      "ma F1:  0.8587665362013039\n",
      "mi F1:  0.8730142566191446\n",
      "we F1:  0.8706373525289182\n",
      "29460 461\n",
      "Loss:  0.07423942536115646\n",
      "Loss:  0.09318026900291443\n",
      "Loss:  0.08078262954950333\n",
      "9 **********\n",
      "Epoch:  567.6252853870392  fold:  3  kers:  64\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.08495279401540756\n",
      "Loss:  0.08455356955528259\n",
      "Loss:  0.07110828161239624\n",
      "10 **********\n",
      "Epoch:  611.4441220760345  fold:  3  kers:  64\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07935874164104462\n",
      "Loss:  0.07350757718086243\n",
      "Loss:  0.07695476710796356\n",
      "11 **********\n",
      "Epoch:  655.2489969730377  fold:  3  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  1.1699342727661133\n",
      "Eval Loss:  0.4325388967990875\n",
      "Eval Loss:  0.7079406380653381\n",
      "[[1421  115]\n",
      " [ 771 1124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.76      1536\n",
      "           1       0.91      0.59      0.72      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.78      0.76      0.74      3431\n",
      "weighted avg       0.79      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7417662489070241\n",
      "pre:  0.9071832122679581\n",
      "rec:  0.5931398416886543\n",
      "ma F1:  0.7398166242594718\n",
      "mi F1:  0.741766248907024\n",
      "we F1:  0.7374600072612518\n",
      "Eval Loss:  0.2847141921520233\n",
      "Eval Loss:  0.43156519532203674\n",
      "Eval Loss:  0.43657243251800537\n",
      "Eval Loss:  0.3772052824497223\n",
      "Eval Loss:  0.366837739944458\n",
      "Eval Loss:  0.3425622284412384\n",
      "Eval Loss:  0.3183722496032715\n",
      "Eval Loss:  0.4279976189136505\n",
      "Eval Loss:  0.5359958410263062\n",
      "Eval Loss:  0.3928206264972687\n",
      "Eval Loss:  0.42910319566726685\n",
      "Eval Loss:  0.3828428387641907\n",
      "Eval Loss:  0.3746464252471924\n",
      "Eval Loss:  0.41643691062927246\n",
      "Eval Loss:  0.46620213985443115\n",
      "Eval Loss:  0.37003329396247864\n",
      "Eval Loss:  0.4353616237640381\n",
      "Eval Loss:  0.39055395126342773\n",
      "Eval Loss:  0.3648432195186615\n",
      "Eval Loss:  0.3597363233566284\n",
      "Eval Loss:  0.466850608587265\n",
      "Eval Loss:  0.3173803389072418\n",
      "Eval Loss:  0.5175217390060425\n",
      "Eval Loss:  0.4304761290550232\n",
      "Eval Loss:  0.4536617398262024\n",
      "Eval Loss:  0.42292144894599915\n",
      "Eval Loss:  0.43446409702301025\n",
      "Eval Loss:  0.2536469101905823\n",
      "[[18239   389]\n",
      " [ 4002  6830]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89     18628\n",
      "           1       0.95      0.63      0.76     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.88      0.80      0.82     29460\n",
      "weighted avg       0.87      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8509504412763068\n",
      "pre:  0.9461144202798172\n",
      "rec:  0.6305391432791728\n",
      "ma F1:  0.8246519655482157\n",
      "mi F1:  0.8509504412763068\n",
      "we F1:  0.8426222448694707\n",
      "29460 461\n",
      "Loss:  0.05237817019224167\n",
      "Loss:  0.07525904476642609\n",
      "Loss:  0.06430738419294357\n",
      "12 **********\n",
      "Epoch:  737.7613759040833  fold:  3  kers:  64\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.07688722014427185\n",
      "Loss:  0.055205002427101135\n",
      "Loss:  0.06914134323596954\n",
      "13 **********\n",
      "Epoch:  781.5662503242493  fold:  3  kers:  64\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.07468158006668091\n",
      "Loss:  0.08226437121629715\n",
      "Loss:  0.06497179716825485\n",
      "14 **********\n",
      "Epoch:  825.663343667984  fold:  3  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.8026881814002991\n",
      "Eval Loss:  0.299937903881073\n",
      "Eval Loss:  0.7006832361221313\n",
      "[[1329  207]\n",
      " [ 623 1272]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.76      1536\n",
      "           1       0.86      0.67      0.75      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7580880209851355\n",
      "pre:  0.8600405679513184\n",
      "rec:  0.6712401055408971\n",
      "ma F1:  0.7580212349700625\n",
      "mi F1:  0.7580880209851355\n",
      "we F1:  0.7576006002435498\n",
      "Eval Loss:  0.22162896394729614\n",
      "Eval Loss:  0.31383371353149414\n",
      "Eval Loss:  0.33822667598724365\n",
      "Eval Loss:  0.3045429587364197\n",
      "Eval Loss:  0.3022890090942383\n",
      "Eval Loss:  0.2703576683998108\n",
      "Eval Loss:  0.2517033517360687\n",
      "Eval Loss:  0.3408249020576477\n",
      "Eval Loss:  0.41106998920440674\n",
      "Eval Loss:  0.31066298484802246\n",
      "Eval Loss:  0.3472978174686432\n",
      "Eval Loss:  0.2989562749862671\n",
      "Eval Loss:  0.298410028219223\n",
      "Eval Loss:  0.31398218870162964\n",
      "Eval Loss:  0.32864370942115784\n",
      "Eval Loss:  0.2914222478866577\n",
      "Eval Loss:  0.3750820755958557\n",
      "Eval Loss:  0.30824220180511475\n",
      "Eval Loss:  0.2747122645378113\n",
      "Eval Loss:  0.30024728178977966\n",
      "Eval Loss:  0.34874340891838074\n",
      "Eval Loss:  0.27386265993118286\n",
      "Eval Loss:  0.4006662368774414\n",
      "Eval Loss:  0.32921716570854187\n",
      "Eval Loss:  0.34863436222076416\n",
      "Eval Loss:  0.3466033637523651\n",
      "Eval Loss:  0.32523882389068604\n",
      "Eval Loss:  0.18897807598114014\n",
      "[[17921   707]\n",
      " [ 2821  8011]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18628\n",
      "           1       0.92      0.74      0.82     10832\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.85      0.86     29460\n",
      "weighted avg       0.88      0.88      0.88     29460\n",
      "\n",
      "acc:  0.880244399185336\n",
      "pre:  0.918903418215187\n",
      "rec:  0.7395679468242246\n",
      "ma F1:  0.8649641313604878\n",
      "mi F1:  0.8802443991853361\n",
      "we F1:  0.8769848143032242\n",
      "29460 461\n",
      "Loss:  0.09588760137557983\n",
      "Loss:  0.0853235051035881\n",
      "Loss:  0.06482046097517014\n",
      "15 **********\n",
      "Epoch:  907.9433438777924  fold:  3  kers:  64\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.0695977583527565\n",
      "Loss:  0.0497952438890934\n",
      "Loss:  0.06977618485689163\n",
      "16 **********\n",
      "Epoch:  951.688378572464  fold:  3  kers:  64\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.07861655950546265\n",
      "Loss:  0.08379674702882767\n",
      "Loss:  0.04761667549610138\n",
      "17 **********\n",
      "Epoch:  995.4274289608002  fold:  3  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.8744964599609375\n",
      "Eval Loss:  0.2611498534679413\n",
      "Eval Loss:  0.8266036510467529\n",
      "[[1313  223]\n",
      " [ 664 1231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.75      1536\n",
      "           1       0.85      0.65      0.74      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.76      0.75      0.74      3431\n",
      "weighted avg       0.76      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7414747886913436\n",
      "pre:  0.8466299862448419\n",
      "rec:  0.6496042216358839\n",
      "ma F1:  0.7413270353505901\n",
      "mi F1:  0.7414747886913435\n",
      "we F1:  0.7406801640172909\n",
      "Eval Loss:  0.19920772314071655\n",
      "Eval Loss:  0.30137789249420166\n",
      "Eval Loss:  0.3295036852359772\n",
      "Eval Loss:  0.2423008531332016\n",
      "Eval Loss:  0.29782047867774963\n",
      "Eval Loss:  0.24273347854614258\n",
      "Eval Loss:  0.23734326660633087\n",
      "Eval Loss:  0.3298265337944031\n",
      "Eval Loss:  0.3631799519062042\n",
      "Eval Loss:  0.2677265405654907\n",
      "Eval Loss:  0.292437344789505\n",
      "Eval Loss:  0.2799954116344452\n",
      "Eval Loss:  0.24719177186489105\n",
      "Eval Loss:  0.260604590177536\n",
      "Eval Loss:  0.28430822491645813\n",
      "Eval Loss:  0.2789040207862854\n",
      "Eval Loss:  0.33165761828422546\n",
      "Eval Loss:  0.24764278531074524\n",
      "Eval Loss:  0.24930128455162048\n",
      "Eval Loss:  0.25853821635246277\n",
      "Eval Loss:  0.3633120357990265\n",
      "Eval Loss:  0.2776501178741455\n",
      "Eval Loss:  0.38422340154647827\n",
      "Eval Loss:  0.30551934242248535\n",
      "Eval Loss:  0.3528873324394226\n",
      "Eval Loss:  0.3284503221511841\n",
      "Eval Loss:  0.2997767925262451\n",
      "Eval Loss:  0.18515829741954803\n",
      "[[17982   646]\n",
      " [ 2692  8140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     18628\n",
      "           1       0.93      0.75      0.83     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.86      0.87     29460\n",
      "weighted avg       0.89      0.89      0.88     29460\n",
      "\n",
      "acc:  0.886693822131704\n",
      "pre:  0.9264739358069656\n",
      "rec:  0.7514771048744461\n",
      "ma F1:  0.8724590365513649\n",
      "mi F1:  0.886693822131704\n",
      "we F1:  0.8837346297625336\n",
      "29460 461\n",
      "Loss:  0.06451892107725143\n",
      "Loss:  0.10072942078113556\n",
      "Loss:  0.057027317583560944\n",
      "18 **********\n",
      "Epoch:  1077.8490500450134  fold:  3  kers:  64\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.03668598830699921\n",
      "Loss:  0.07755432277917862\n",
      "Loss:  0.06952672451734543\n",
      "19 **********\n",
      "Epoch:  1121.6190185546875  fold:  3  kers:  64\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.10168818384408951\n",
      "Loss:  0.05163135752081871\n",
      "Loss:  0.06570671498775482\n",
      "20 **********\n",
      "Epoch:  1165.401951789856  fold:  3  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.6187678575515747\n",
      "Eval Loss:  0.24368128180503845\n",
      "Eval Loss:  0.7881630659103394\n",
      "[[1275  261]\n",
      " [ 591 1304]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.83      0.75      1536\n",
      "           1       0.83      0.69      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.77      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7516758962401632\n",
      "pre:  0.8332268370607029\n",
      "rec:  0.6881266490765171\n",
      "ma F1:  0.7516581541629711\n",
      "mi F1:  0.7516758962401633\n",
      "we F1:  0.7518777888426941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17695732414722443\n",
      "Eval Loss:  0.23272274434566498\n",
      "Eval Loss:  0.27397558093070984\n",
      "Eval Loss:  0.21249479055404663\n",
      "Eval Loss:  0.2820640206336975\n",
      "Eval Loss:  0.22009271383285522\n",
      "Eval Loss:  0.2088673859834671\n",
      "Eval Loss:  0.26302987337112427\n",
      "Eval Loss:  0.3196726441383362\n",
      "Eval Loss:  0.222312331199646\n",
      "Eval Loss:  0.24510511755943298\n",
      "Eval Loss:  0.23323634266853333\n",
      "Eval Loss:  0.2459515631198883\n",
      "Eval Loss:  0.21557268500328064\n",
      "Eval Loss:  0.24603813886642456\n",
      "Eval Loss:  0.22656790912151337\n",
      "Eval Loss:  0.26522159576416016\n",
      "Eval Loss:  0.2189972698688507\n",
      "Eval Loss:  0.23128773272037506\n",
      "Eval Loss:  0.22430679202079773\n",
      "Eval Loss:  0.31576788425445557\n",
      "Eval Loss:  0.24421149492263794\n",
      "Eval Loss:  0.335884153842926\n",
      "Eval Loss:  0.27122631669044495\n",
      "Eval Loss:  0.3238523602485657\n",
      "Eval Loss:  0.2802860140800476\n",
      "Eval Loss:  0.26217785477638245\n",
      "Eval Loss:  0.15738075971603394\n",
      "[[17822   806]\n",
      " [ 2119  8713]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18628\n",
      "           1       0.92      0.80      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9007128309572301\n",
      "pre:  0.9153272402563295\n",
      "rec:  0.8043759231905465\n",
      "ma F1:  0.8902171553602041\n",
      "mi F1:  0.9007128309572301\n",
      "we F1:  0.899199951161545\n",
      "29460 461\n",
      "Loss:  0.05243938788771629\n",
      "Loss:  0.05106320604681969\n",
      "Loss:  0.040110908448696136\n",
      "21 **********\n",
      "Epoch:  1247.6729757785797  fold:  3  kers:  64\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.0402064174413681\n",
      "Loss:  0.06416717916727066\n",
      "Loss:  0.09065713733434677\n",
      "22 **********\n",
      "Epoch:  1291.3571734428406  fold:  3  kers:  64\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.0506473034620285\n",
      "Loss:  0.08940105885267258\n",
      "Loss:  0.058696262538433075\n",
      "23 **********\n",
      "Epoch:  1335.0204260349274  fold:  3  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.45558595657348633\n",
      "Eval Loss:  0.18672597408294678\n",
      "Eval Loss:  0.8062012195587158\n",
      "[[1202  334]\n",
      " [ 505 1390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      1536\n",
      "           1       0.81      0.73      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7554648790440105\n",
      "pre:  0.8062645011600929\n",
      "rec:  0.7335092348284961\n",
      "ma F1:  0.7547284661068194\n",
      "mi F1:  0.7554648790440105\n",
      "we F1:  0.756134701449647\n",
      "Eval Loss:  0.19821125268936157\n",
      "Eval Loss:  0.211898535490036\n",
      "Eval Loss:  0.26868319511413574\n",
      "Eval Loss:  0.20729590952396393\n",
      "Eval Loss:  0.2984738051891327\n",
      "Eval Loss:  0.21409982442855835\n",
      "Eval Loss:  0.20249506831169128\n",
      "Eval Loss:  0.2527284324169159\n",
      "Eval Loss:  0.3014169931411743\n",
      "Eval Loss:  0.21760010719299316\n",
      "Eval Loss:  0.21361489593982697\n",
      "Eval Loss:  0.22380441427230835\n",
      "Eval Loss:  0.23231810331344604\n",
      "Eval Loss:  0.20020639896392822\n",
      "Eval Loss:  0.18838928639888763\n",
      "Eval Loss:  0.24314023554325104\n",
      "Eval Loss:  0.2853813171386719\n",
      "Eval Loss:  0.22387650609016418\n",
      "Eval Loss:  0.1987486481666565\n",
      "Eval Loss:  0.23398399353027344\n",
      "Eval Loss:  0.2924806475639343\n",
      "Eval Loss:  0.26992103457450867\n",
      "Eval Loss:  0.32434409856796265\n",
      "Eval Loss:  0.2408227026462555\n",
      "Eval Loss:  0.32349616289138794\n",
      "Eval Loss:  0.3034553527832031\n",
      "Eval Loss:  0.2093721330165863\n",
      "Eval Loss:  0.1474706381559372\n",
      "[[17438  1190]\n",
      " [ 1583  9249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18628\n",
      "           1       0.89      0.85      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9058723693143245\n",
      "pre:  0.8860044065523518\n",
      "rec:  0.8538589364844904\n",
      "ma F1:  0.8979903496074486\n",
      "mi F1:  0.9058723693143245\n",
      "we F1:  0.905494101669337\n",
      "29460 461\n",
      "Loss:  0.06837331503629684\n",
      "Loss:  0.03808808699250221\n",
      "Loss:  0.06918000429868698\n",
      "24 **********\n",
      "Epoch:  1417.3183782100677  fold:  3  kers:  64\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.03474754840135574\n",
      "Loss:  0.06459765136241913\n",
      "Loss:  0.03192757070064545\n",
      "25 **********\n",
      "Epoch:  1461.0504477024078  fold:  3  kers:  64\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.08353126794099808\n",
      "Loss:  0.07297562062740326\n",
      "Loss:  0.06764120608568192\n",
      "26 **********\n",
      "Epoch:  1504.7805218696594  fold:  3  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.4828997552394867\n",
      "Eval Loss:  0.19637729227542877\n",
      "Eval Loss:  1.031708002090454\n",
      "[[1251  285]\n",
      " [ 599 1296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74      1536\n",
      "           1       0.82      0.68      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.76      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7423491693383854\n",
      "pre:  0.8197343453510436\n",
      "rec:  0.6839050131926121\n",
      "ma F1:  0.7423048401425485\n",
      "mi F1:  0.7423491693383855\n",
      "we F1:  0.7426584886160009\n",
      "Eval Loss:  0.1969509869813919\n",
      "Eval Loss:  0.20265410840511322\n",
      "Eval Loss:  0.2592815160751343\n",
      "Eval Loss:  0.21067410707473755\n",
      "Eval Loss:  0.28095945715904236\n",
      "Eval Loss:  0.18498675525188446\n",
      "Eval Loss:  0.2274940460920334\n",
      "Eval Loss:  0.20491397380828857\n",
      "Eval Loss:  0.28379586338996887\n",
      "Eval Loss:  0.2304520159959793\n",
      "Eval Loss:  0.19773443043231964\n",
      "Eval Loss:  0.23109516501426697\n",
      "Eval Loss:  0.22897690534591675\n",
      "Eval Loss:  0.20748332142829895\n",
      "Eval Loss:  0.21481463313102722\n",
      "Eval Loss:  0.23169243335723877\n",
      "Eval Loss:  0.26466071605682373\n",
      "Eval Loss:  0.20686712861061096\n",
      "Eval Loss:  0.22485318779945374\n",
      "Eval Loss:  0.23387868702411652\n",
      "Eval Loss:  0.2751474678516388\n",
      "Eval Loss:  0.2392866164445877\n",
      "Eval Loss:  0.3327246606349945\n",
      "Eval Loss:  0.24817264080047607\n",
      "Eval Loss:  0.29714831709861755\n",
      "Eval Loss:  0.28695249557495117\n",
      "Eval Loss:  0.2204051911830902\n",
      "Eval Loss:  0.1461302489042282\n",
      "[[17769   859]\n",
      " [ 1816  9016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.91      0.83      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9091989137813985\n",
      "pre:  0.913012658227848\n",
      "rec:  0.8323485967503693\n",
      "ma F1:  0.9004071384186823\n",
      "mi F1:  0.9091989137813985\n",
      "we F1:  0.9082376743181151\n",
      "29460 461\n",
      "Loss:  0.05094980448484421\n",
      "Loss:  0.04251185804605484\n",
      "Loss:  0.042067352682352066\n",
      "27 **********\n",
      "Epoch:  1586.8730239868164  fold:  3  kers:  64\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.06143873929977417\n",
      "Loss:  0.0783715769648552\n",
      "Loss:  0.06369104981422424\n",
      "28 **********\n",
      "Epoch:  1630.5731785297394  fold:  3  kers:  64\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.0550941601395607\n",
      "Loss:  0.04959053173661232\n",
      "Loss:  0.05130869895219803\n",
      "29 **********\n",
      "Epoch:  1674.2972691059113  fold:  3  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.2361082136631012\n",
      "Eval Loss:  0.14253327250480652\n",
      "Eval Loss:  0.9713032245635986\n",
      "[[1118  418]\n",
      " [ 436 1459]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.72      1536\n",
      "           1       0.78      0.77      0.77      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.75      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7510929758088021\n",
      "pre:  0.7773042088438998\n",
      "rec:  0.7699208443271768\n",
      "ma F1:  0.748609752665699\n",
      "mi F1:  0.751092975808802\n",
      "we F1:  0.7512240550362974\n",
      "Eval Loss:  0.25897982716560364\n",
      "Eval Loss:  0.21151132881641388\n",
      "Eval Loss:  0.2568395137786865\n",
      "Eval Loss:  0.1941772997379303\n",
      "Eval Loss:  0.2899605333805084\n",
      "Eval Loss:  0.23135852813720703\n",
      "Eval Loss:  0.23187191784381866\n",
      "Eval Loss:  0.23572129011154175\n",
      "Eval Loss:  0.2694724500179291\n",
      "Eval Loss:  0.24062402546405792\n",
      "Eval Loss:  0.20453673601150513\n",
      "Eval Loss:  0.22958995401859283\n",
      "Eval Loss:  0.2467755824327469\n",
      "Eval Loss:  0.20306919515132904\n",
      "Eval Loss:  0.18426355719566345\n",
      "Eval Loss:  0.25837472081184387\n",
      "Eval Loss:  0.2874968349933624\n",
      "Eval Loss:  0.24994391202926636\n",
      "Eval Loss:  0.1964355856180191\n",
      "Eval Loss:  0.2214638739824295\n",
      "Eval Loss:  0.24245452880859375\n",
      "Eval Loss:  0.27720382809638977\n",
      "Eval Loss:  0.2958816885948181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2702142596244812\n",
      "Eval Loss:  0.32313138246536255\n",
      "Eval Loss:  0.29937633872032166\n",
      "Eval Loss:  0.2073897272348404\n",
      "Eval Loss:  0.1487368941307068\n",
      "[[16659  1969]\n",
      " [  917  9915]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92     18628\n",
      "           1       0.83      0.92      0.87     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.89      0.90      0.90     29460\n",
      "weighted avg       0.91      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9020366598778005\n",
      "pre:  0.8343150454392461\n",
      "rec:  0.9153434268833087\n",
      "ma F1:  0.8966190180279701\n",
      "mi F1:  0.9020366598778005\n",
      "we F1:  0.9028817605934027\n",
      "29460 461\n",
      "Loss:  0.052921801805496216\n",
      "Loss:  0.08777059614658356\n",
      "Loss:  0.051956918090581894\n",
      "30 **********\n",
      "Epoch:  1756.5204207897186  fold:  3  kers:  64\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.042775705456733704\n",
      "Loss:  0.048442572355270386\n",
      "Loss:  0.07915526628494263\n",
      "31 **********\n",
      "Epoch:  1800.1148586273193  fold:  3  kers:  64\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.0577557235956192\n",
      "Loss:  0.05057912319898605\n",
      "Loss:  0.10485166311264038\n",
      "32 **********\n",
      "Epoch:  1843.707300901413  fold:  3  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.4096081554889679\n",
      "Eval Loss:  0.149375319480896\n",
      "Eval Loss:  1.0934956073760986\n",
      "[[1229  307]\n",
      " [ 556 1339]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74      1536\n",
      "           1       0.81      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7484698338676771\n",
      "pre:  0.8134872417982989\n",
      "rec:  0.7065963060686016\n",
      "ma F1:  0.7482110241103039\n",
      "mi F1:  0.7484698338676772\n",
      "we F1:  0.749055685045731\n",
      "Eval Loss:  0.17772185802459717\n",
      "Eval Loss:  0.18715740740299225\n",
      "Eval Loss:  0.2343088686466217\n",
      "Eval Loss:  0.20126695930957794\n",
      "Eval Loss:  0.27531754970550537\n",
      "Eval Loss:  0.1738322526216507\n",
      "Eval Loss:  0.21062907576560974\n",
      "Eval Loss:  0.17863090336322784\n",
      "Eval Loss:  0.25843125581741333\n",
      "Eval Loss:  0.20453591644763947\n",
      "Eval Loss:  0.1850663423538208\n",
      "Eval Loss:  0.2003941833972931\n",
      "Eval Loss:  0.19274252653121948\n",
      "Eval Loss:  0.18564021587371826\n",
      "Eval Loss:  0.1906694918870926\n",
      "Eval Loss:  0.21171295642852783\n",
      "Eval Loss:  0.2794352173805237\n",
      "Eval Loss:  0.19814126193523407\n",
      "Eval Loss:  0.1826821118593216\n",
      "Eval Loss:  0.19772641360759735\n",
      "Eval Loss:  0.22640544176101685\n",
      "Eval Loss:  0.24389459192752838\n",
      "Eval Loss:  0.27714481949806213\n",
      "Eval Loss:  0.22296452522277832\n",
      "Eval Loss:  0.28589460253715515\n",
      "Eval Loss:  0.2963145077228546\n",
      "Eval Loss:  0.19595365226268768\n",
      "Eval Loss:  0.11670263856649399\n",
      "[[17622  1006]\n",
      " [ 1442  9390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18628\n",
      "           1       0.90      0.87      0.88     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9169042769857434\n",
      "pre:  0.9032320123124279\n",
      "rec:  0.8668759231905465\n",
      "ma F1:  0.9098665707777422\n",
      "mi F1:  0.9169042769857434\n",
      "we F1:  0.9165315316132107\n",
      "29460 461\n",
      "Loss:  0.06288725882768631\n",
      "Loss:  0.04432948678731918\n",
      "Loss:  0.05626583844423294\n",
      "33 **********\n",
      "Epoch:  1926.0032584667206  fold:  3  kers:  64\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.06017875671386719\n",
      "Loss:  0.05727168172597885\n",
      "Loss:  0.06044713407754898\n",
      "34 **********\n",
      "Epoch:  1969.714383840561  fold:  3  kers:  64\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.06472513824701309\n",
      "Loss:  0.07460483908653259\n",
      "Loss:  0.06673108041286469\n",
      "35 **********\n",
      "Epoch:  2013.4554290771484  fold:  3  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.5209538340568542\n",
      "Eval Loss:  0.1525440216064453\n",
      "Eval Loss:  1.1140540838241577\n",
      "[[1262  274]\n",
      " [ 575 1320]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75      1536\n",
      "           1       0.83      0.70      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7525502768872049\n",
      "pre:  0.8281053952321205\n",
      "rec:  0.6965699208443272\n",
      "ma F1:  0.7524795433056857\n",
      "mi F1:  0.7525502768872049\n",
      "we F1:  0.7529173597844002\n",
      "Eval Loss:  0.1799418032169342\n",
      "Eval Loss:  0.1965692788362503\n",
      "Eval Loss:  0.2512899339199066\n",
      "Eval Loss:  0.20098048448562622\n",
      "Eval Loss:  0.275234580039978\n",
      "Eval Loss:  0.17299561202526093\n",
      "Eval Loss:  0.23079492151737213\n",
      "Eval Loss:  0.19115830957889557\n",
      "Eval Loss:  0.30244070291519165\n",
      "Eval Loss:  0.19671525061130524\n",
      "Eval Loss:  0.16842222213745117\n",
      "Eval Loss:  0.2132459133863449\n",
      "Eval Loss:  0.21242207288742065\n",
      "Eval Loss:  0.16617292165756226\n",
      "Eval Loss:  0.17329666018486023\n",
      "Eval Loss:  0.22740434110164642\n",
      "Eval Loss:  0.26313385367393494\n",
      "Eval Loss:  0.19069473445415497\n",
      "Eval Loss:  0.17785927653312683\n",
      "Eval Loss:  0.19990211725234985\n",
      "Eval Loss:  0.2574875056743622\n",
      "Eval Loss:  0.23390933871269226\n",
      "Eval Loss:  0.29376956820487976\n",
      "Eval Loss:  0.22342360019683838\n",
      "Eval Loss:  0.27019003033638\n",
      "Eval Loss:  0.27136915922164917\n",
      "Eval Loss:  0.20888470113277435\n",
      "Eval Loss:  0.11254336684942245\n",
      "[[17766   862]\n",
      " [ 1580  9252]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18628\n",
      "           1       0.91      0.85      0.88     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.90      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9171079429735234\n",
      "pre:  0.9147716037176191\n",
      "rec:  0.854135893648449\n",
      "ma F1:  0.9095536684426861\n",
      "mi F1:  0.9171079429735234\n",
      "we F1:  0.9164708782432978\n",
      "29460 461\n",
      "Loss:  0.10089592635631561\n",
      "Loss:  0.061409980058670044\n",
      "Loss:  0.049883436411619186\n",
      "36 **********\n",
      "Epoch:  2095.7533810138702  fold:  3  kers:  64\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.07104846090078354\n",
      "Loss:  0.06227223575115204\n",
      "Loss:  0.08495747298002243\n",
      "37 **********\n",
      "Epoch:  2141.9787833690643  fold:  3  kers:  64\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.038215167820453644\n",
      "Loss:  0.055642448365688324\n",
      "Loss:  0.05086011439561844\n",
      "38 **********\n",
      "Epoch:  2185.7956261634827  fold:  3  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.46115341782569885\n",
      "Eval Loss:  0.14514568448066711\n",
      "Eval Loss:  1.2540100812911987\n",
      "[[1215  321]\n",
      " [ 550 1345]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74      1536\n",
      "           1       0.81      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.75      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7461381521422326\n",
      "pre:  0.8073229291716687\n",
      "rec:  0.7097625329815304\n",
      "ma F1:  0.7457731741787506\n",
      "mi F1:  0.7461381521422326\n",
      "we F1:  0.7467810748625205\n",
      "Eval Loss:  0.1674465388059616\n",
      "Eval Loss:  0.18556815385818481\n",
      "Eval Loss:  0.24467788636684418\n",
      "Eval Loss:  0.18686391413211823\n",
      "Eval Loss:  0.2662457227706909\n",
      "Eval Loss:  0.15328550338745117\n",
      "Eval Loss:  0.18103305995464325\n",
      "Eval Loss:  0.16897356510162354\n",
      "Eval Loss:  0.2660709619522095\n",
      "Eval Loss:  0.2024007886648178\n",
      "Eval Loss:  0.17616583406925201\n",
      "Eval Loss:  0.19526807963848114\n",
      "Eval Loss:  0.18580281734466553\n",
      "Eval Loss:  0.172517791390419\n",
      "Eval Loss:  0.17726457118988037\n",
      "Eval Loss:  0.20586392283439636\n",
      "Eval Loss:  0.2664637267589569\n",
      "Eval Loss:  0.19950728118419647\n",
      "Eval Loss:  0.16553136706352234\n",
      "Eval Loss:  0.2117728888988495\n",
      "Eval Loss:  0.2242671698331833\n",
      "Eval Loss:  0.24627158045768738\n",
      "Eval Loss:  0.30597633123397827\n",
      "Eval Loss:  0.20712845027446747\n",
      "Eval Loss:  0.288204550743103\n",
      "Eval Loss:  0.27404728531837463\n",
      "Eval Loss:  0.19302113354206085\n",
      "Eval Loss:  0.10770750045776367\n",
      "[[17682   946]\n",
      " [ 1413  9419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.91      0.87      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9199253224711473\n",
      "pre:  0.9087313072841293\n",
      "rec:  0.8695531757754801\n",
      "ma F1:  0.9130879367533575\n",
      "mi F1:  0.9199253224711473\n",
      "we F1:  0.9195388939185383\n",
      "29460 461\n",
      "Loss:  0.0575554184615612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04045889899134636\n",
      "Loss:  0.044429779052734375\n",
      "39 **********\n",
      "Epoch:  2268.2750928401947  fold:  3  kers:  64\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.054437071084976196\n",
      "Loss:  0.07427150756120682\n",
      "Loss:  0.04620423540472984\n",
      "40 **********\n",
      "Epoch:  2312.0560314655304  fold:  3  kers:  64\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.055739875882864\n",
      "Loss:  0.05078002065420151\n",
      "Loss:  0.036622025072574615\n",
      "41 **********\n",
      "Epoch:  2355.8648958206177  fold:  3  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.3183991611003876\n",
      "Eval Loss:  0.11758241057395935\n",
      "Eval Loss:  1.0399317741394043\n",
      "[[1189  347]\n",
      " [ 501 1394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.74      1536\n",
      "           1       0.80      0.74      0.77      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7528417371028855\n",
      "pre:  0.800689259046525\n",
      "rec:  0.7356200527704485\n",
      "ma F1:  0.7519562247607278\n",
      "mi F1:  0.7528417371028855\n",
      "we F1:  0.7535069512526038\n",
      "Eval Loss:  0.17920638620853424\n",
      "Eval Loss:  0.17582213878631592\n",
      "Eval Loss:  0.21973848342895508\n",
      "Eval Loss:  0.185804083943367\n",
      "Eval Loss:  0.2847587764263153\n",
      "Eval Loss:  0.16478165984153748\n",
      "Eval Loss:  0.187781423330307\n",
      "Eval Loss:  0.16370736062526703\n",
      "Eval Loss:  0.2724633812904358\n",
      "Eval Loss:  0.19093365967273712\n",
      "Eval Loss:  0.1701204925775528\n",
      "Eval Loss:  0.20627307891845703\n",
      "Eval Loss:  0.1930396556854248\n",
      "Eval Loss:  0.1587388813495636\n",
      "Eval Loss:  0.17985641956329346\n",
      "Eval Loss:  0.2064693570137024\n",
      "Eval Loss:  0.2851836383342743\n",
      "Eval Loss:  0.20420506596565247\n",
      "Eval Loss:  0.15383952856063843\n",
      "Eval Loss:  0.23328348994255066\n",
      "Eval Loss:  0.22723397612571716\n",
      "Eval Loss:  0.21287059783935547\n",
      "Eval Loss:  0.2870071530342102\n",
      "Eval Loss:  0.19423574209213257\n",
      "Eval Loss:  0.2736545503139496\n",
      "Eval Loss:  0.2981387972831726\n",
      "Eval Loss:  0.20090581476688385\n",
      "Eval Loss:  0.1044950932264328\n",
      "[[17493  1135]\n",
      " [ 1211  9621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18628\n",
      "           1       0.89      0.89      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9203665987780041\n",
      "pre:  0.8944775009297137\n",
      "rec:  0.8882016248153619\n",
      "ma F1:  0.9142434928937448\n",
      "mi F1:  0.9203665987780041\n",
      "we F1:  0.9203074834264793\n",
      "29460 461\n",
      "Loss:  0.038212429732084274\n",
      "Loss:  0.03803480789065361\n",
      "Loss:  0.03106646053493023\n",
      "42 **********\n",
      "Epoch:  2438.2017438411713  fold:  3  kers:  64\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.06470905244350433\n",
      "Loss:  0.05770154669880867\n",
      "Loss:  0.06800859421491623\n",
      "43 **********\n",
      "Epoch:  2482.202095746994  fold:  3  kers:  64\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.07052791863679886\n",
      "Loss:  0.028736282140016556\n",
      "Loss:  0.05390676110982895\n",
      "44 **********\n",
      "Epoch:  2525.959098339081  fold:  3  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.437271386384964\n",
      "Eval Loss:  0.09423647820949554\n",
      "Eval Loss:  1.2254047393798828\n",
      "[[1235  301]\n",
      " [ 527 1368]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75      1536\n",
      "           1       0.82      0.72      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7586709414164966\n",
      "pre:  0.8196524865188736\n",
      "rec:  0.7218997361477573\n",
      "ma F1:  0.7583077592174015\n",
      "mi F1:  0.7586709414164966\n",
      "we F1:  0.7592880780856359\n",
      "Eval Loss:  0.19042988121509552\n",
      "Eval Loss:  0.19316597282886505\n",
      "Eval Loss:  0.22924655675888062\n",
      "Eval Loss:  0.17896881699562073\n",
      "Eval Loss:  0.27249178290367126\n",
      "Eval Loss:  0.17716117203235626\n",
      "Eval Loss:  0.2022235244512558\n",
      "Eval Loss:  0.17352013289928436\n",
      "Eval Loss:  0.2927629351615906\n",
      "Eval Loss:  0.2019527405500412\n",
      "Eval Loss:  0.1602526158094406\n",
      "Eval Loss:  0.20642736554145813\n",
      "Eval Loss:  0.19012536108493805\n",
      "Eval Loss:  0.15310834348201752\n",
      "Eval Loss:  0.162992924451828\n",
      "Eval Loss:  0.21317782998085022\n",
      "Eval Loss:  0.2785896062850952\n",
      "Eval Loss:  0.1860763430595398\n",
      "Eval Loss:  0.16573122143745422\n",
      "Eval Loss:  0.21122464537620544\n",
      "Eval Loss:  0.22092825174331665\n",
      "Eval Loss:  0.23198239505290985\n",
      "Eval Loss:  0.2997395992279053\n",
      "Eval Loss:  0.22059620916843414\n",
      "Eval Loss:  0.2588789463043213\n",
      "Eval Loss:  0.2991909980773926\n",
      "Eval Loss:  0.20483343303203583\n",
      "Eval Loss:  0.09963341057300568\n",
      "[[17691   937]\n",
      " [ 1389  9443]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.91      0.87      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9210454854039375\n",
      "pre:  0.9097302504816955\n",
      "rec:  0.8717688330871491\n",
      "ma F1:  0.9143302822540549\n",
      "mi F1:  0.9210454854039375\n",
      "we F1:  0.9206774844553747\n",
      "29460 461\n",
      "Loss:  0.06164201721549034\n",
      "Loss:  0.06293918937444687\n",
      "Loss:  0.07152125239372253\n",
      "45 **********\n",
      "Epoch:  2608.4345757961273  fold:  3  kers:  64\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.04627569392323494\n",
      "Loss:  0.036955833435058594\n",
      "Loss:  0.050481513142585754\n",
      "46 **********\n",
      "Epoch:  2652.2474291324615  fold:  3  kers:  64\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.0594814270734787\n",
      "Loss:  0.04332870617508888\n",
      "Loss:  0.0657697468996048\n",
      "47 **********\n",
      "Epoch:  2696.0682606697083  fold:  3  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.37307071685791016\n",
      "Eval Loss:  0.12922422587871552\n",
      "Eval Loss:  1.0870652198791504\n",
      "[[1252  284]\n",
      " [ 539 1356]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75      1536\n",
      "           1       0.83      0.72      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7601282424948994\n",
      "pre:  0.8268292682926829\n",
      "rec:  0.7155672823218997\n",
      "ma F1:  0.7599076434759282\n",
      "mi F1:  0.7601282424948994\n",
      "we F1:  0.7606691343202616\n",
      "Eval Loss:  0.14889635145664215\n",
      "Eval Loss:  0.17348866164684296\n",
      "Eval Loss:  0.23213744163513184\n",
      "Eval Loss:  0.17643356323242188\n",
      "Eval Loss:  0.2553477883338928\n",
      "Eval Loss:  0.15128043293952942\n",
      "Eval Loss:  0.19260923564434052\n",
      "Eval Loss:  0.15168313682079315\n",
      "Eval Loss:  0.27676770091056824\n",
      "Eval Loss:  0.18112821877002716\n",
      "Eval Loss:  0.17368464171886444\n",
      "Eval Loss:  0.20734669268131256\n",
      "Eval Loss:  0.19598862528800964\n",
      "Eval Loss:  0.15671910345554352\n",
      "Eval Loss:  0.16804660856723785\n",
      "Eval Loss:  0.20345036685466766\n",
      "Eval Loss:  0.24479986727237701\n",
      "Eval Loss:  0.18242797255516052\n",
      "Eval Loss:  0.16561438143253326\n",
      "Eval Loss:  0.2210339605808258\n",
      "Eval Loss:  0.21731969714164734\n",
      "Eval Loss:  0.21902070939540863\n",
      "Eval Loss:  0.2744382917881012\n",
      "Eval Loss:  0.20415297150611877\n",
      "Eval Loss:  0.2558495104312897\n",
      "Eval Loss:  0.28163257241249084\n",
      "Eval Loss:  0.19496570527553558\n",
      "Eval Loss:  0.09236092865467072\n",
      "[[17718   910]\n",
      " [ 1361  9471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.91      0.87      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9229124236252546\n",
      "pre:  0.9123398516520567\n",
      "rec:  0.8743537666174298\n",
      "ma F1:  0.9163577313447561\n",
      "mi F1:  0.9229124236252546\n",
      "we F1:  0.9225539701005178\n",
      "29460 461\n",
      "Loss:  0.06094774603843689\n",
      "Loss:  0.04870832711458206\n",
      "Loss:  0.019936036318540573\n",
      "48 **********\n",
      "Epoch:  2778.4140853881836  fold:  3  kers:  64\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.045301105827093124\n",
      "Loss:  0.0668722540140152\n",
      "Loss:  0.06353465467691422\n",
      "49 **********\n",
      "Epoch:  2822.179067134857  fold:  3  kers:  64\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.07069379836320877\n",
      "Loss:  0.0618862509727478\n",
      "Loss:  0.05808098614215851\n",
      "50 **********\n",
      "Epoch:  2866.010868549347  fold:  3  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.39224374294281006\n",
      "Eval Loss:  0.17186830937862396\n",
      "Eval Loss:  1.3826113939285278\n",
      "[[1257  279]\n",
      " [ 541 1354]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75      1536\n",
      "           1       0.83      0.71      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7610026231419411\n",
      "pre:  0.8291488058787507\n",
      "rec:  0.7145118733509235\n",
      "ma F1:  0.7608114431535462\n",
      "mi F1:  0.7610026231419411\n",
      "we F1:  0.761519006203379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.15792140364646912\n",
      "Eval Loss:  0.19621729850769043\n",
      "Eval Loss:  0.24490629136562347\n",
      "Eval Loss:  0.1751314401626587\n",
      "Eval Loss:  0.2559446096420288\n",
      "Eval Loss:  0.16452772915363312\n",
      "Eval Loss:  0.192678302526474\n",
      "Eval Loss:  0.16529901325702667\n",
      "Eval Loss:  0.27385592460632324\n",
      "Eval Loss:  0.21655240654945374\n",
      "Eval Loss:  0.17008379101753235\n",
      "Eval Loss:  0.20106005668640137\n",
      "Eval Loss:  0.20015299320220947\n",
      "Eval Loss:  0.1552276313304901\n",
      "Eval Loss:  0.17443037033081055\n",
      "Eval Loss:  0.21996891498565674\n",
      "Eval Loss:  0.29648876190185547\n",
      "Eval Loss:  0.19856968522071838\n",
      "Eval Loss:  0.15806394815444946\n",
      "Eval Loss:  0.22119154036045074\n",
      "Eval Loss:  0.23638813197612762\n",
      "Eval Loss:  0.2467285692691803\n",
      "Eval Loss:  0.2936316430568695\n",
      "Eval Loss:  0.2092054933309555\n",
      "Eval Loss:  0.24808639287948608\n",
      "Eval Loss:  0.28645387291908264\n",
      "Eval Loss:  0.20631937682628632\n",
      "Eval Loss:  0.08888830989599228\n",
      "[[17701   927]\n",
      " [ 1440  9392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18628\n",
      "           1       0.91      0.87      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9196537678207739\n",
      "pre:  0.9101657137319508\n",
      "rec:  0.8670605612998523\n",
      "ma F1:  0.9127099768011006\n",
      "mi F1:  0.9196537678207739\n",
      "we F1:  0.9192250562076927\n",
      "29460 461\n",
      "Loss:  0.047813113778829575\n",
      "Loss:  0.06466715037822723\n",
      "Loss:  0.0746501088142395\n",
      "51 **********\n",
      "Epoch:  2948.3507087230682  fold:  3  kers:  64\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.05774688720703125\n",
      "Loss:  0.05879458039999008\n",
      "Loss:  0.05840277299284935\n",
      "52 **********\n",
      "Epoch:  2992.103722333908  fold:  3  kers:  64\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.04154430702328682\n",
      "Loss:  0.0538080632686615\n",
      "Loss:  0.0221343282610178\n",
      "53 **********\n",
      "Epoch:  3035.8766827583313  fold:  3  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.3550974130630493\n",
      "Eval Loss:  0.10977192968130112\n",
      "Eval Loss:  1.1006512641906738\n",
      "[[1204  332]\n",
      " [ 520 1375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      1536\n",
      "           1       0.81      0.73      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7516758962401632\n",
      "pre:  0.8055067369654364\n",
      "rec:  0.7255936675461742\n",
      "ma F1:  0.7510575242792858\n",
      "mi F1:  0.7516758962401633\n",
      "we F1:  0.7523557437760986\n",
      "Eval Loss:  0.16948607563972473\n",
      "Eval Loss:  0.1682477593421936\n",
      "Eval Loss:  0.20915734767913818\n",
      "Eval Loss:  0.15324930846691132\n",
      "Eval Loss:  0.2550211250782013\n",
      "Eval Loss:  0.1661670058965683\n",
      "Eval Loss:  0.18286386132240295\n",
      "Eval Loss:  0.15371614694595337\n",
      "Eval Loss:  0.2527283728122711\n",
      "Eval Loss:  0.1819867491722107\n",
      "Eval Loss:  0.1487657129764557\n",
      "Eval Loss:  0.20465897023677826\n",
      "Eval Loss:  0.19138982892036438\n",
      "Eval Loss:  0.14258961379528046\n",
      "Eval Loss:  0.1424824595451355\n",
      "Eval Loss:  0.19018805027008057\n",
      "Eval Loss:  0.274834543466568\n",
      "Eval Loss:  0.1840735673904419\n",
      "Eval Loss:  0.1544630229473114\n",
      "Eval Loss:  0.2094215303659439\n",
      "Eval Loss:  0.21468058228492737\n",
      "Eval Loss:  0.21774893999099731\n",
      "Eval Loss:  0.2631252110004425\n",
      "Eval Loss:  0.18293963372707367\n",
      "Eval Loss:  0.24183058738708496\n",
      "Eval Loss:  0.3003491163253784\n",
      "Eval Loss:  0.19785647094249725\n",
      "Eval Loss:  0.10146859288215637\n",
      "[[17587  1041]\n",
      " [ 1129  9703]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18628\n",
      "           1       0.90      0.90      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9263408010862186\n",
      "pre:  0.9031087118391661\n",
      "rec:  0.8957717872968981\n",
      "ma F1:  0.9206584448778181\n",
      "mi F1:  0.9263408010862186\n",
      "we F1:  0.9262773754968808\n",
      "29460 461\n",
      "Loss:  0.056122977286577225\n",
      "Loss:  0.06356079876422882\n",
      "Loss:  0.04166465252637863\n",
      "54 **********\n",
      "Epoch:  3118.060938358307  fold:  3  kers:  64\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.03915026783943176\n",
      "Loss:  0.030897419899702072\n",
      "Loss:  0.06419054418802261\n",
      "55 **********\n",
      "Epoch:  3161.9186718463898  fold:  3  kers:  64\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.043305154889822006\n",
      "Loss:  0.0733051598072052\n",
      "Loss:  0.07570469379425049\n",
      "56 **********\n",
      "Epoch:  3205.6627085208893  fold:  3  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.33392804861068726\n",
      "Eval Loss:  0.1281045824289322\n",
      "Eval Loss:  1.076265573501587\n",
      "[[1202  334]\n",
      " [ 527 1368]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      1536\n",
      "           1       0.80      0.72      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7490527542990382\n",
      "pre:  0.8037602820211516\n",
      "rec:  0.7218997361477573\n",
      "ma F1:  0.7484639445581884\n",
      "mi F1:  0.7490527542990382\n",
      "we F1:  0.7497373342989416\n",
      "Eval Loss:  0.1467486023902893\n",
      "Eval Loss:  0.16062983870506287\n",
      "Eval Loss:  0.22407574951648712\n",
      "Eval Loss:  0.15535983443260193\n",
      "Eval Loss:  0.2542882561683655\n",
      "Eval Loss:  0.15531107783317566\n",
      "Eval Loss:  0.16302689909934998\n",
      "Eval Loss:  0.13951005041599274\n",
      "Eval Loss:  0.2350156158208847\n",
      "Eval Loss:  0.1861199140548706\n",
      "Eval Loss:  0.15072467923164368\n",
      "Eval Loss:  0.19785110652446747\n",
      "Eval Loss:  0.17793090641498566\n",
      "Eval Loss:  0.13942685723304749\n",
      "Eval Loss:  0.14741183817386627\n",
      "Eval Loss:  0.19056889414787292\n",
      "Eval Loss:  0.24881230294704437\n",
      "Eval Loss:  0.17829036712646484\n",
      "Eval Loss:  0.13354703783988953\n",
      "Eval Loss:  0.1979629099369049\n",
      "Eval Loss:  0.18434225022792816\n",
      "Eval Loss:  0.2264803647994995\n",
      "Eval Loss:  0.2613261342048645\n",
      "Eval Loss:  0.16398091614246368\n",
      "Eval Loss:  0.22811369597911835\n",
      "Eval Loss:  0.2814064919948578\n",
      "Eval Loss:  0.1751992106437683\n",
      "Eval Loss:  0.1086082011461258\n",
      "[[17553  1075]\n",
      " [  998  9834]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     18628\n",
      "           1       0.90      0.91      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.93      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9296334012219959\n",
      "pre:  0.9014575121459345\n",
      "rec:  0.9078655834564254\n",
      "ma F1:  0.9244464588729949\n",
      "mi F1:  0.9296334012219959\n",
      "we F1:  0.9296851429710402\n",
      "29460 461\n",
      "Loss:  0.09148522466421127\n",
      "Loss:  0.07743901014328003\n",
      "Loss:  0.04533490538597107\n",
      "57 **********\n",
      "Epoch:  3287.925755739212  fold:  3  kers:  64\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.04056433215737343\n",
      "Loss:  0.06557651609182358\n",
      "Loss:  0.052631981670856476\n",
      "58 **********\n",
      "Epoch:  3331.8662660121918  fold:  3  kers:  64\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.061321839690208435\n",
      "Loss:  0.054313383996486664\n",
      "Loss:  0.05599164590239525\n",
      "59 **********\n",
      "Epoch:  3375.5514607429504  fold:  3  kers:  64\n",
      "Eval Loss:  0.461348295211792\n",
      "Eval Loss:  0.09401995688676834\n",
      "Eval Loss:  1.154616117477417\n",
      "[[1256  280]\n",
      " [ 536 1359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75      1536\n",
      "           1       0.83      0.72      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7621684640046633\n",
      "pre:  0.8291641244661379\n",
      "rec:  0.7171503957783641\n",
      "ma F1:  0.7619539310434897\n",
      "mi F1:  0.7621684640046633\n",
      "we F1:  0.762701672141173\n",
      "update!  Acc:  0.7811133780238997\n",
      "Epoch:  3379.565728187561  fold:  3  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29520 3371\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29520 462\n",
      "Loss:  0.1710306704044342\n",
      "Loss:  0.16659054160118103\n",
      "Loss:  0.15743769705295563\n",
      "0 **********\n",
      "Epoch:  56.38922595977783  fold:  4  kers:  64\n",
      "epoch:  1\n",
      "29520 462\n",
      "Loss:  0.15081927180290222\n",
      "Loss:  0.12637001276016235\n",
      "Loss:  0.12219249457120895\n",
      "1 **********\n",
      "Epoch:  100.36763620376587  fold:  4  kers:  64\n",
      "epoch:  2\n",
      "29520 462\n",
      "Loss:  0.10584516823291779\n",
      "Loss:  0.1161123514175415\n",
      "Loss:  0.1036926880478859\n",
      "2 **********\n",
      "Epoch:  144.21838855743408  fold:  4  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.6138429641723633\n",
      "Eval Loss:  0.44953346252441406\n",
      "Eval Loss:  0.1436333805322647\n",
      "[[2576  561]\n",
      " [ 113  121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88      3137\n",
      "           1       0.18      0.52      0.26       234\n",
      "\n",
      "    accuracy                           0.80      3371\n",
      "   macro avg       0.57      0.67      0.57      3371\n",
      "weighted avg       0.90      0.80      0.84      3371\n",
      "\n",
      "acc:  0.8000593295757935\n",
      "pre:  0.1774193548387097\n",
      "rec:  0.5170940170940171\n",
      "ma F1:  0.5742519229414296\n",
      "mi F1:  0.8000593295757936\n",
      "we F1:  0.8412657320899259\n",
      "update!  Acc:  0.8000593295757935\n",
      "Eval Loss:  0.37323448061943054\n",
      "Eval Loss:  0.4304087460041046\n",
      "Eval Loss:  0.45549148321151733\n",
      "Eval Loss:  0.3992629945278168\n",
      "Eval Loss:  0.3791477084159851\n",
      "Eval Loss:  0.35346972942352295\n",
      "Eval Loss:  0.48424863815307617\n",
      "Eval Loss:  0.4829918444156647\n",
      "Eval Loss:  0.3281775712966919\n",
      "Eval Loss:  0.41430091857910156\n",
      "Eval Loss:  0.32672229409217834\n",
      "Eval Loss:  0.44755643606185913\n",
      "Eval Loss:  0.4220643639564514\n",
      "Eval Loss:  0.4683177173137665\n",
      "Eval Loss:  0.4583454430103302\n",
      "Eval Loss:  0.4154568910598755\n",
      "Eval Loss:  0.374904990196228\n",
      "Eval Loss:  0.3814614713191986\n",
      "Eval Loss:  0.3598106801509857\n",
      "Eval Loss:  0.4491085410118103\n",
      "Eval Loss:  0.46018609404563904\n",
      "Eval Loss:  0.4622272849082947\n",
      "Eval Loss:  0.49200668931007385\n",
      "Eval Loss:  0.4678802192211151\n",
      "Eval Loss:  0.48016324639320374\n",
      "Eval Loss:  0.5397189259529114\n",
      "Eval Loss:  0.524917721748352\n",
      "Eval Loss:  0.401572048664093\n",
      "[[13958  3069]\n",
      " [ 2488 10005]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83     17027\n",
      "           1       0.77      0.80      0.78     12493\n",
      "\n",
      "    accuracy                           0.81     29520\n",
      "   macro avg       0.81      0.81      0.81     29520\n",
      "weighted avg       0.81      0.81      0.81     29520\n",
      "\n",
      "acc:  0.8117547425474255\n",
      "pre:  0.7652592932537862\n",
      "rec:  0.8008484751460818\n",
      "ma F1:  0.8083175547337325\n",
      "mi F1:  0.8117547425474255\n",
      "we F1:  0.8122599300302881\n",
      "29520 462\n",
      "Loss:  0.11222721636295319\n",
      "Loss:  0.11423702538013458\n",
      "Loss:  0.10459595918655396\n",
      "3 **********\n",
      "Epoch:  227.02897000312805  fold:  4  kers:  64\n",
      "epoch:  4\n",
      "29520 462\n",
      "Loss:  0.08380338549613953\n",
      "Loss:  0.1256822645664215\n",
      "Loss:  0.08774429559707642\n",
      "4 **********\n",
      "Epoch:  270.9605059623718  fold:  4  kers:  64\n",
      "epoch:  5\n",
      "29520 462\n",
      "Loss:  0.10342826694250107\n",
      "Loss:  0.10217974334955215\n",
      "Loss:  0.077368825674057\n",
      "5 **********\n",
      "Epoch:  314.88406348228455  fold:  4  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.1589721143245697\n",
      "Eval Loss:  0.21554379165172577\n",
      "Eval Loss:  0.07049402594566345\n",
      "[[3030  107]\n",
      " [ 210   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.18      0.10      0.13       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.56      0.53      0.54      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9059626223672501\n",
      "pre:  0.183206106870229\n",
      "rec:  0.10256410256410256\n",
      "ma F1:  0.540898477190073\n",
      "mi F1:  0.9059626223672501\n",
      "we F1:  0.8934537710853974\n",
      "update!  Acc:  0.9059626223672501\n",
      "Eval Loss:  0.3817567527294159\n",
      "Eval Loss:  0.4119899272918701\n",
      "Eval Loss:  0.47867250442504883\n",
      "Eval Loss:  0.31455478072166443\n",
      "Eval Loss:  0.3245737850666046\n",
      "Eval Loss:  0.3120470643043518\n",
      "Eval Loss:  0.4095284044742584\n",
      "Eval Loss:  0.4417860209941864\n",
      "Eval Loss:  0.3141806423664093\n",
      "Eval Loss:  0.4125288426876068\n",
      "Eval Loss:  0.3451184630393982\n",
      "Eval Loss:  0.411488801240921\n",
      "Eval Loss:  0.3779076635837555\n",
      "Eval Loss:  0.39244771003723145\n",
      "Eval Loss:  0.4556964635848999\n",
      "Eval Loss:  0.36965540051460266\n",
      "Eval Loss:  0.34052103757858276\n",
      "Eval Loss:  0.3991595506668091\n",
      "Eval Loss:  0.3483225107192993\n",
      "Eval Loss:  0.43875375390052795\n",
      "Eval Loss:  0.3803757131099701\n",
      "Eval Loss:  0.3925054371356964\n",
      "Eval Loss:  0.4903140664100647\n",
      "Eval Loss:  0.3891792595386505\n",
      "Eval Loss:  0.4738287627696991\n",
      "Eval Loss:  0.5409557223320007\n",
      "Eval Loss:  0.4842366576194763\n",
      "Eval Loss:  0.36503341794013977\n",
      "[[15761  1266]\n",
      " [ 3582  8911]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87     17027\n",
      "           1       0.88      0.71      0.79     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.85      0.82      0.83     29520\n",
      "weighted avg       0.84      0.84      0.83     29520\n",
      "\n",
      "acc:  0.8357723577235773\n",
      "pre:  0.8756018473027415\n",
      "rec:  0.7132794364844313\n",
      "ma F1:  0.8264262113195034\n",
      "mi F1:  0.8357723577235773\n",
      "we F1:  0.8326124051583459\n",
      "29520 462\n",
      "Loss:  0.09986953437328339\n",
      "Loss:  0.09628351032733917\n",
      "Loss:  0.09023667126893997\n",
      "6 **********\n",
      "Epoch:  398.0786180496216  fold:  4  kers:  64\n",
      "epoch:  7\n",
      "29520 462\n",
      "Loss:  0.07272655516862869\n",
      "Loss:  0.07849743962287903\n",
      "Loss:  0.05909170210361481\n",
      "7 **********\n",
      "Epoch:  442.11587142944336  fold:  4  kers:  64\n",
      "epoch:  8\n",
      "29520 462\n",
      "Loss:  0.0720863938331604\n",
      "Loss:  0.07400868088006973\n",
      "Loss:  0.110588438808918\n",
      "8 **********\n",
      "Epoch:  486.2239351272583  fold:  4  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.06850773096084595\n",
      "Eval Loss:  0.1377144604921341\n",
      "Eval Loss:  0.03304696083068848\n",
      "[[3091   46]\n",
      " [ 222   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.21      0.05      0.08       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.57      0.52      0.52      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9204983684366657\n",
      "pre:  0.20689655172413793\n",
      "rec:  0.05128205128205128\n",
      "ma F1:  0.5203206966125093\n",
      "mi F1:  0.9204983684366657\n",
      "we F1:  0.8976236460459377\n",
      "update!  Acc:  0.9204983684366657\n",
      "Eval Loss:  0.39298033714294434\n",
      "Eval Loss:  0.4513224959373474\n",
      "Eval Loss:  0.47236743569374084\n",
      "Eval Loss:  0.31186625361442566\n",
      "Eval Loss:  0.33777761459350586\n",
      "Eval Loss:  0.2896815538406372\n",
      "Eval Loss:  0.38882145285606384\n",
      "Eval Loss:  0.46858054399490356\n",
      "Eval Loss:  0.37275245785713196\n",
      "Eval Loss:  0.4047583341598511\n",
      "Eval Loss:  0.4047178030014038\n",
      "Eval Loss:  0.4133989214897156\n",
      "Eval Loss:  0.4210335314273834\n",
      "Eval Loss:  0.38359764218330383\n",
      "Eval Loss:  0.46739062666893005\n",
      "Eval Loss:  0.4414454698562622\n",
      "Eval Loss:  0.38120827078819275\n",
      "Eval Loss:  0.42152202129364014\n",
      "Eval Loss:  0.40438225865364075\n",
      "Eval Loss:  0.4697186350822449\n",
      "Eval Loss:  0.3339157700538635\n",
      "Eval Loss:  0.3891090154647827\n",
      "Eval Loss:  0.5006633996963501\n",
      "Eval Loss:  0.39632123708724976\n",
      "Eval Loss:  0.4489624798297882\n",
      "Eval Loss:  0.4967506527900696\n",
      "Eval Loss:  0.5079907178878784\n",
      "Eval Loss:  0.3684645891189575\n",
      "[[16332   695]\n",
      " [ 4112  8381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87     17027\n",
      "           1       0.92      0.67      0.78     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.86      0.82      0.82     29520\n",
      "weighted avg       0.85      0.84      0.83     29520\n",
      "\n",
      "acc:  0.8371612466124662\n",
      "pre:  0.9234244160423094\n",
      "rec:  0.670855679180341\n",
      "ma F1:  0.8244239875483461\n",
      "mi F1:  0.8371612466124662\n",
      "we F1:  0.831687317015925\n",
      "29520 462\n",
      "Loss:  0.061395008116960526\n",
      "Loss:  0.11153875291347504\n",
      "Loss:  0.08618787676095963\n",
      "9 **********\n",
      "Epoch:  569.0764043331146  fold:  4  kers:  64\n",
      "epoch:  10\n",
      "29520 462\n",
      "Loss:  0.07123641669750214\n",
      "Loss:  0.08090183883905411\n",
      "Loss:  0.06334306299686432\n",
      "10 **********\n",
      "Epoch:  613.0089375972748  fold:  4  kers:  64\n",
      "epoch:  11\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08821629732847214\n",
      "Loss:  0.06911627948284149\n",
      "Loss:  0.06596188992261887\n",
      "11 **********\n",
      "Epoch:  656.6622176170349  fold:  4  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.027012433856725693\n",
      "Eval Loss:  0.13636283576488495\n",
      "Eval Loss:  0.029016513377428055\n",
      "[[3091   46]\n",
      " [ 224   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.18      0.04      0.07       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.56      0.51      0.51      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9199050726787303\n",
      "pre:  0.17857142857142858\n",
      "rec:  0.042735042735042736\n",
      "ma F1:  0.5135590140453641\n",
      "mi F1:  0.9199050726787303\n",
      "we F1:  0.8964290589050401\n",
      "Eval Loss:  0.392844557762146\n",
      "Eval Loss:  0.4379550516605377\n",
      "Eval Loss:  0.44854849576950073\n",
      "Eval Loss:  0.2864842712879181\n",
      "Eval Loss:  0.30973148345947266\n",
      "Eval Loss:  0.27674707770347595\n",
      "Eval Loss:  0.3457533121109009\n",
      "Eval Loss:  0.40699055790901184\n",
      "Eval Loss:  0.38361838459968567\n",
      "Eval Loss:  0.3692663908004761\n",
      "Eval Loss:  0.397812157869339\n",
      "Eval Loss:  0.38072067499160767\n",
      "Eval Loss:  0.39639702439308167\n",
      "Eval Loss:  0.3405897319316864\n",
      "Eval Loss:  0.4477026164531708\n",
      "Eval Loss:  0.3951488733291626\n",
      "Eval Loss:  0.3603065609931946\n",
      "Eval Loss:  0.39910227060317993\n",
      "Eval Loss:  0.3984439969062805\n",
      "Eval Loss:  0.44194746017456055\n",
      "Eval Loss:  0.29758620262145996\n",
      "Eval Loss:  0.36045318841934204\n",
      "Eval Loss:  0.40792906284332275\n",
      "Eval Loss:  0.40176093578338623\n",
      "Eval Loss:  0.41970595717430115\n",
      "Eval Loss:  0.42263278365135193\n",
      "Eval Loss:  0.4733171761035919\n",
      "Eval Loss:  0.35886794328689575\n",
      "[[16389   638]\n",
      " [ 3937  8556]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88     17027\n",
      "           1       0.93      0.68      0.79     12493\n",
      "\n",
      "    accuracy                           0.85     29520\n",
      "   macro avg       0.87      0.82      0.83     29520\n",
      "weighted avg       0.86      0.85      0.84     29520\n",
      "\n",
      "acc:  0.845020325203252\n",
      "pre:  0.9306069175549271\n",
      "rec:  0.684863523573201\n",
      "ma F1:  0.8332820028699806\n",
      "mi F1:  0.8450203252032519\n",
      "we F1:  0.8400765328660297\n",
      "29520 462\n",
      "Loss:  0.0704333558678627\n",
      "Loss:  0.09112291783094406\n",
      "Loss:  0.050026170909404755\n",
      "12 **********\n",
      "Epoch:  738.8903565406799  fold:  4  kers:  64\n",
      "epoch:  13\n",
      "29520 462\n",
      "Loss:  0.09206812083721161\n",
      "Loss:  0.0528104230761528\n",
      "Loss:  0.061018187552690506\n",
      "13 **********\n",
      "Epoch:  782.6962287425995  fold:  4  kers:  64\n",
      "epoch:  14\n",
      "29520 462\n",
      "Loss:  0.050474680960178375\n",
      "Loss:  0.08825155347585678\n",
      "Loss:  0.08358202129602432\n",
      "14 **********\n",
      "Epoch:  826.4263031482697  fold:  4  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.01936272531747818\n",
      "Eval Loss:  0.15213662385940552\n",
      "Eval Loss:  0.024585524573922157\n",
      "[[3068   69]\n",
      " [ 222   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      3137\n",
      "           1       0.15      0.05      0.08       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.54      0.51      0.52      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9136754672204094\n",
      "pre:  0.14814814814814814\n",
      "rec:  0.05128205128205128\n",
      "ma F1:  0.51545637081657\n",
      "mi F1:  0.9136754672204094\n",
      "we F1:  0.8937384509410288\n",
      "Eval Loss:  0.34603139758110046\n",
      "Eval Loss:  0.36207038164138794\n",
      "Eval Loss:  0.40920311212539673\n",
      "Eval Loss:  0.21432948112487793\n",
      "Eval Loss:  0.2711538076400757\n",
      "Eval Loss:  0.24240820109844208\n",
      "Eval Loss:  0.31884270906448364\n",
      "Eval Loss:  0.3401126265525818\n",
      "Eval Loss:  0.3477620482444763\n",
      "Eval Loss:  0.3301161527633667\n",
      "Eval Loss:  0.33294183015823364\n",
      "Eval Loss:  0.33675795793533325\n",
      "Eval Loss:  0.3485746383666992\n",
      "Eval Loss:  0.32078251242637634\n",
      "Eval Loss:  0.3816528916358948\n",
      "Eval Loss:  0.33986520767211914\n",
      "Eval Loss:  0.3126598298549652\n",
      "Eval Loss:  0.3223467469215393\n",
      "Eval Loss:  0.3411499559879303\n",
      "Eval Loss:  0.4268936216831207\n",
      "Eval Loss:  0.27589619159698486\n",
      "Eval Loss:  0.3159964680671692\n",
      "Eval Loss:  0.38092130422592163\n",
      "Eval Loss:  0.31581535935401917\n",
      "Eval Loss:  0.37366384267807007\n",
      "Eval Loss:  0.38228362798690796\n",
      "Eval Loss:  0.43813908100128174\n",
      "Eval Loss:  0.3193798065185547\n",
      "[[16326   701]\n",
      " [ 3386  9107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     17027\n",
      "           1       0.93      0.73      0.82     12493\n",
      "\n",
      "    accuracy                           0.86     29520\n",
      "   macro avg       0.88      0.84      0.85     29520\n",
      "weighted avg       0.87      0.86      0.86     29520\n",
      "\n",
      "acc:  0.8615514905149051\n",
      "pre:  0.9285277324632952\n",
      "rec:  0.7289682222044345\n",
      "ma F1:  0.8527452468215397\n",
      "mi F1:  0.8615514905149051\n",
      "we F1:  0.8582761387602734\n",
      "29520 462\n",
      "Loss:  0.08035250008106232\n",
      "Loss:  0.09289062023162842\n",
      "Loss:  0.05566698685288429\n",
      "15 **********\n",
      "Epoch:  908.7970604896545  fold:  4  kers:  64\n",
      "epoch:  16\n",
      "29520 462\n",
      "Loss:  0.05999104306101799\n",
      "Loss:  0.09201908111572266\n",
      "Loss:  0.09375885874032974\n",
      "16 **********\n",
      "Epoch:  952.5740101337433  fold:  4  kers:  64\n",
      "epoch:  17\n",
      "29520 462\n",
      "Loss:  0.09738004952669144\n",
      "Loss:  0.06243853643536568\n",
      "Loss:  0.039102304726839066\n",
      "17 **********\n",
      "Epoch:  996.4117965698242  fold:  4  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.015849001705646515\n",
      "Eval Loss:  0.13830120861530304\n",
      "Eval Loss:  0.010825000703334808\n",
      "[[3095   42]\n",
      " [ 227    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.14      0.03      0.05       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.54      0.51      0.50      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.920201720557698\n",
      "pre:  0.14285714285714285\n",
      "rec:  0.029914529914529916\n",
      "ma F1:  0.5039113254193206\n",
      "mi F1:  0.920201720557698\n",
      "we F1:  0.8952620433878143\n",
      "Eval Loss:  0.39308780431747437\n",
      "Eval Loss:  0.4271642863750458\n",
      "Eval Loss:  0.4506151080131531\n",
      "Eval Loss:  0.261531263589859\n",
      "Eval Loss:  0.31979256868362427\n",
      "Eval Loss:  0.2702946960926056\n",
      "Eval Loss:  0.3602903187274933\n",
      "Eval Loss:  0.38641756772994995\n",
      "Eval Loss:  0.44048091769218445\n",
      "Eval Loss:  0.3747544288635254\n",
      "Eval Loss:  0.4069736897945404\n",
      "Eval Loss:  0.3860075771808624\n",
      "Eval Loss:  0.4030613899230957\n",
      "Eval Loss:  0.36626699566841125\n",
      "Eval Loss:  0.4444859027862549\n",
      "Eval Loss:  0.41744980216026306\n",
      "Eval Loss:  0.4022263288497925\n",
      "Eval Loss:  0.380991131067276\n",
      "Eval Loss:  0.38217127323150635\n",
      "Eval Loss:  0.47312191128730774\n",
      "Eval Loss:  0.3063525855541229\n",
      "Eval Loss:  0.33176130056381226\n",
      "Eval Loss:  0.443342387676239\n",
      "Eval Loss:  0.3800753057003021\n",
      "Eval Loss:  0.3944253921508789\n",
      "Eval Loss:  0.44072282314300537\n",
      "Eval Loss:  0.5136871933937073\n",
      "Eval Loss:  0.3820347785949707\n",
      "[[16587   440]\n",
      " [ 4196  8297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88     17027\n",
      "           1       0.95      0.66      0.78     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.87      0.82      0.83     29520\n",
      "weighted avg       0.86      0.84      0.84     29520\n",
      "\n",
      "acc:  0.8429539295392954\n",
      "pre:  0.9496394643470298\n",
      "rec:  0.6641319138717682\n",
      "ma F1:  0.8295083519339514\n",
      "mi F1:  0.8429539295392954\n",
      "we F1:  0.8368620610850527\n",
      "29520 462\n",
      "Loss:  0.047290582209825516\n",
      "Loss:  0.05355611443519592\n",
      "Loss:  0.09211462736129761\n",
      "18 **********\n",
      "Epoch:  1078.7526338100433  fold:  4  kers:  64\n",
      "epoch:  19\n",
      "29520 462\n",
      "Loss:  0.0636335015296936\n",
      "Loss:  0.09241066873073578\n",
      "Loss:  0.04041450843214989\n",
      "19 **********\n",
      "Epoch:  1122.6023888587952  fold:  4  kers:  64\n",
      "epoch:  20\n",
      "29520 462\n",
      "Loss:  0.0650695264339447\n",
      "Loss:  0.11196398735046387\n",
      "Loss:  0.06446946412324905\n",
      "20 **********\n",
      "Epoch:  1166.4282071590424  fold:  4  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.04164987429976463\n",
      "Eval Loss:  0.1786385029554367\n",
      "Eval Loss:  0.01800405979156494\n",
      "[[3022  115]\n",
      " [ 215   19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      3137\n",
      "           1       0.14      0.08      0.10       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.54      0.52      0.53      3371\n",
      "weighted avg       0.88      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9021061999406704\n",
      "pre:  0.1417910447761194\n",
      "rec:  0.0811965811965812\n",
      "ma F1:  0.5257440212275413\n",
      "mi F1:  0.9021061999406704\n",
      "we F1:  0.8895733268566501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3215968608856201\n",
      "Eval Loss:  0.3236236274242401\n",
      "Eval Loss:  0.34229540824890137\n",
      "Eval Loss:  0.17577005922794342\n",
      "Eval Loss:  0.2133457213640213\n",
      "Eval Loss:  0.20851238071918488\n",
      "Eval Loss:  0.2650611102581024\n",
      "Eval Loss:  0.3134515583515167\n",
      "Eval Loss:  0.30225643515586853\n",
      "Eval Loss:  0.28981733322143555\n",
      "Eval Loss:  0.29291489720344543\n",
      "Eval Loss:  0.2960807681083679\n",
      "Eval Loss:  0.26776060461997986\n",
      "Eval Loss:  0.25975531339645386\n",
      "Eval Loss:  0.29775455594062805\n",
      "Eval Loss:  0.3095419108867645\n",
      "Eval Loss:  0.28112974762916565\n",
      "Eval Loss:  0.3021691143512726\n",
      "Eval Loss:  0.29393911361694336\n",
      "Eval Loss:  0.3546580374240875\n",
      "Eval Loss:  0.21479512751102448\n",
      "Eval Loss:  0.2580578029155731\n",
      "Eval Loss:  0.29435503482818604\n",
      "Eval Loss:  0.2866523265838623\n",
      "Eval Loss:  0.29309916496276855\n",
      "Eval Loss:  0.33899033069610596\n",
      "Eval Loss:  0.38745924830436707\n",
      "Eval Loss:  0.2867063283920288\n",
      "[[16214   813]\n",
      " [ 2632  9861]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     17027\n",
      "           1       0.92      0.79      0.85     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.89      0.87      0.88     29520\n",
      "weighted avg       0.89      0.88      0.88     29520\n",
      "\n",
      "acc:  0.88329945799458\n",
      "pre:  0.9238336143901068\n",
      "rec:  0.7893220203313855\n",
      "ma F1:  0.8776319376527548\n",
      "mi F1:  0.88329945799458\n",
      "we F1:  0.8816767255057117\n",
      "29520 462\n",
      "Loss:  0.07198009639978409\n",
      "Loss:  0.0683140978217125\n",
      "Loss:  0.06558743864297867\n",
      "21 **********\n",
      "Epoch:  1249.017380475998  fold:  4  kers:  64\n",
      "epoch:  22\n",
      "29520 462\n",
      "Loss:  0.059129998087882996\n",
      "Loss:  0.04039875417947769\n",
      "Loss:  0.1149728000164032\n",
      "22 **********\n",
      "Epoch:  1292.9020419120789  fold:  4  kers:  64\n",
      "epoch:  23\n",
      "29520 462\n",
      "Loss:  0.06771529465913773\n",
      "Loss:  0.0663389042019844\n",
      "Loss:  0.0794101357460022\n",
      "23 **********\n",
      "Epoch:  1336.776730298996  fold:  4  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.12748569250106812\n",
      "Eval Loss:  0.20656690001487732\n",
      "Eval Loss:  0.0154167665168643\n",
      "[[3023  114]\n",
      " [ 213   21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      3137\n",
      "           1       0.16      0.09      0.11       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.54      0.53      0.53      3371\n",
      "weighted avg       0.88      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9029961435775734\n",
      "pre:  0.15555555555555556\n",
      "rec:  0.08974358974358974\n",
      "ma F1:  0.53125546162099\n",
      "mi F1:  0.9029961435775734\n",
      "we F1:  0.8907368739194449\n",
      "Eval Loss:  0.3053351640701294\n",
      "Eval Loss:  0.3198375105857849\n",
      "Eval Loss:  0.3206334710121155\n",
      "Eval Loss:  0.1696714162826538\n",
      "Eval Loss:  0.21385912597179413\n",
      "Eval Loss:  0.179867684841156\n",
      "Eval Loss:  0.24776576459407806\n",
      "Eval Loss:  0.29216882586479187\n",
      "Eval Loss:  0.2964032292366028\n",
      "Eval Loss:  0.2954767644405365\n",
      "Eval Loss:  0.2627793848514557\n",
      "Eval Loss:  0.2901877760887146\n",
      "Eval Loss:  0.25839585065841675\n",
      "Eval Loss:  0.2431352138519287\n",
      "Eval Loss:  0.2901696562767029\n",
      "Eval Loss:  0.3031800091266632\n",
      "Eval Loss:  0.2511439025402069\n",
      "Eval Loss:  0.2930207848548889\n",
      "Eval Loss:  0.26649707555770874\n",
      "Eval Loss:  0.3292996883392334\n",
      "Eval Loss:  0.21489745378494263\n",
      "Eval Loss:  0.23784488439559937\n",
      "Eval Loss:  0.28903016448020935\n",
      "Eval Loss:  0.28679805994033813\n",
      "Eval Loss:  0.292863130569458\n",
      "Eval Loss:  0.3280523419380188\n",
      "Eval Loss:  0.36817222833633423\n",
      "Eval Loss:  0.2576363980770111\n",
      "[[16309   718]\n",
      " [ 2609  9884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     17027\n",
      "           1       0.93      0.79      0.86     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.90      0.87      0.88     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8872967479674797\n",
      "pre:  0.9322769288813432\n",
      "rec:  0.7911630513087329\n",
      "ma F1:  0.8816923849675198\n",
      "mi F1:  0.8872967479674797\n",
      "we F1:  0.8856472770829779\n",
      "29520 462\n",
      "Loss:  0.09049487859010696\n",
      "Loss:  0.07572849094867706\n",
      "Loss:  0.06834302097558975\n",
      "24 **********\n",
      "Epoch:  1419.3060631752014  fold:  4  kers:  64\n",
      "epoch:  25\n",
      "29520 462\n",
      "Loss:  0.025754038244485855\n",
      "Loss:  0.07845506817102432\n",
      "Loss:  0.07533962279558182\n",
      "25 **********\n",
      "Epoch:  1463.1657910346985  fold:  4  kers:  64\n",
      "epoch:  26\n",
      "29520 462\n",
      "Loss:  0.042683571577072144\n",
      "Loss:  0.06810033321380615\n",
      "Loss:  0.05374116450548172\n",
      "26 **********\n",
      "Epoch:  1507.003577709198  fold:  4  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.14906106889247894\n",
      "Eval Loss:  0.3580366373062134\n",
      "Eval Loss:  0.018067138269543648\n",
      "[[2862  275]\n",
      " [ 205   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      3137\n",
      "           1       0.10      0.12      0.11       234\n",
      "\n",
      "    accuracy                           0.86      3371\n",
      "   macro avg       0.51      0.52      0.52      3371\n",
      "weighted avg       0.88      0.86      0.87      3371\n",
      "\n",
      "acc:  0.8576090180955206\n",
      "pre:  0.09539473684210527\n",
      "rec:  0.12393162393162394\n",
      "ma F1:  0.5152186261891236\n",
      "mi F1:  0.8576090180955206\n",
      "we F1:  0.8660690701369776\n",
      "Eval Loss:  0.31409940123558044\n",
      "Eval Loss:  0.26880520582199097\n",
      "Eval Loss:  0.28428906202316284\n",
      "Eval Loss:  0.1427554488182068\n",
      "Eval Loss:  0.16415826976299286\n",
      "Eval Loss:  0.16506412625312805\n",
      "Eval Loss:  0.2273973673582077\n",
      "Eval Loss:  0.24985966086387634\n",
      "Eval Loss:  0.2471933513879776\n",
      "Eval Loss:  0.2727646827697754\n",
      "Eval Loss:  0.20183473825454712\n",
      "Eval Loss:  0.2749131917953491\n",
      "Eval Loss:  0.2094218134880066\n",
      "Eval Loss:  0.23157528042793274\n",
      "Eval Loss:  0.2169044315814972\n",
      "Eval Loss:  0.25489550828933716\n",
      "Eval Loss:  0.192731574177742\n",
      "Eval Loss:  0.2493702620267868\n",
      "Eval Loss:  0.223963662981987\n",
      "Eval Loss:  0.25411689281463623\n",
      "Eval Loss:  0.17775863409042358\n",
      "Eval Loss:  0.25311577320098877\n",
      "Eval Loss:  0.2432849109172821\n",
      "Eval Loss:  0.2261078655719757\n",
      "Eval Loss:  0.26044222712516785\n",
      "Eval Loss:  0.2670348584651947\n",
      "Eval Loss:  0.3076227307319641\n",
      "Eval Loss:  0.2294071912765503\n",
      "[[15934  1093]\n",
      " [ 1774 10719]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17027\n",
      "           1       0.91      0.86      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.90      0.90     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.902879403794038\n",
      "pre:  0.9074669827294277\n",
      "rec:  0.8580004802689506\n",
      "ma F1:  0.8997507533973024\n",
      "mi F1:  0.902879403794038\n",
      "we F1:  0.9024708494469282\n",
      "29520 462\n",
      "Loss:  0.0900241881608963\n",
      "Loss:  0.08272220194339752\n",
      "Loss:  0.09710019826889038\n",
      "27 **********\n",
      "Epoch:  1589.286570072174  fold:  4  kers:  64\n",
      "epoch:  28\n",
      "29520 462\n",
      "Loss:  0.07422693073749542\n",
      "Loss:  0.06956350803375244\n",
      "Loss:  0.07880379259586334\n",
      "28 **********\n",
      "Epoch:  1633.143306016922  fold:  4  kers:  64\n",
      "epoch:  29\n",
      "29520 462\n",
      "Loss:  0.045120932161808014\n",
      "Loss:  0.06498395651578903\n",
      "Loss:  0.04848335310816765\n",
      "29 **********\n",
      "Epoch:  1676.92125248909  fold:  4  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.3649345636367798\n",
      "Eval Loss:  0.16013053059577942\n",
      "Eval Loss:  0.042939670383930206\n",
      "[[2936  201]\n",
      " [ 189   45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.18      0.19      0.19       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.56      0.56      0.56      3371\n",
      "weighted avg       0.89      0.88      0.89      3371\n",
      "\n",
      "acc:  0.8843073272026105\n",
      "pre:  0.18292682926829268\n",
      "rec:  0.19230769230769232\n",
      "ma F1:  0.5626097892047269\n",
      "mi F1:  0.8843073272026106\n",
      "we F1:  0.8856426334827816\n",
      "Eval Loss:  0.28591105341911316\n",
      "Eval Loss:  0.25547492504119873\n",
      "Eval Loss:  0.262301504611969\n",
      "Eval Loss:  0.13872180879116058\n",
      "Eval Loss:  0.15710145235061646\n",
      "Eval Loss:  0.15218183398246765\n",
      "Eval Loss:  0.1964126080274582\n",
      "Eval Loss:  0.24274636805057526\n",
      "Eval Loss:  0.21187306940555573\n",
      "Eval Loss:  0.25116270780563354\n",
      "Eval Loss:  0.17665143311023712\n",
      "Eval Loss:  0.26441052556037903\n",
      "Eval Loss:  0.18364468216896057\n",
      "Eval Loss:  0.24118494987487793\n",
      "Eval Loss:  0.2034132331609726\n",
      "Eval Loss:  0.2831990718841553\n",
      "Eval Loss:  0.1822705864906311\n",
      "Eval Loss:  0.22566218674182892\n",
      "Eval Loss:  0.22689709067344666\n",
      "Eval Loss:  0.26130664348602295\n",
      "Eval Loss:  0.19261981546878815\n",
      "Eval Loss:  0.2200162559747696\n",
      "Eval Loss:  0.2287108451128006\n",
      "Eval Loss:  0.21887636184692383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2792501747608185\n",
      "Eval Loss:  0.2758850157260895\n",
      "Eval Loss:  0.2965700924396515\n",
      "Eval Loss:  0.22797439992427826\n",
      "[[15815  1212]\n",
      " [ 1514 10979]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     17027\n",
      "           1       0.90      0.88      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9076558265582656\n",
      "pre:  0.9005823968501353\n",
      "rec:  0.8788121347954855\n",
      "ma F1:  0.9051092076993258\n",
      "mi F1:  0.9076558265582656\n",
      "we F1:  0.907496794528613\n",
      "29520 462\n",
      "Loss:  0.06829817593097687\n",
      "Loss:  0.08719103783369064\n",
      "Loss:  0.054463282227516174\n",
      "30 **********\n",
      "Epoch:  1759.2301754951477  fold:  4  kers:  64\n",
      "epoch:  31\n",
      "29520 462\n",
      "Loss:  0.06687184423208237\n",
      "Loss:  0.058086905628442764\n",
      "Loss:  0.06805546581745148\n",
      "31 **********\n",
      "Epoch:  1803.1278021335602  fold:  4  kers:  64\n",
      "epoch:  32\n",
      "29520 462\n",
      "Loss:  0.07251253724098206\n",
      "Loss:  0.03328999876976013\n",
      "Loss:  0.048299990594387054\n",
      "32 **********\n",
      "Epoch:  1846.9127295017242  fold:  4  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.14055320620536804\n",
      "Eval Loss:  0.24663348495960236\n",
      "Eval Loss:  0.025644227862358093\n",
      "[[2936  201]\n",
      " [ 196   38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.16      0.16      0.16       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.55      0.55      0.55      3371\n",
      "weighted avg       0.88      0.88      0.88      3371\n",
      "\n",
      "acc:  0.8822307920498369\n",
      "pre:  0.1589958158995816\n",
      "rec:  0.1623931623931624\n",
      "ma F1:  0.5486745241611378\n",
      "mi F1:  0.8822307920498369\n",
      "we F1:  0.882806285955787\n",
      "Eval Loss:  0.2598555088043213\n",
      "Eval Loss:  0.2727925479412079\n",
      "Eval Loss:  0.27054330706596375\n",
      "Eval Loss:  0.1321789175271988\n",
      "Eval Loss:  0.16389627754688263\n",
      "Eval Loss:  0.15409217774868011\n",
      "Eval Loss:  0.2050132155418396\n",
      "Eval Loss:  0.25662267208099365\n",
      "Eval Loss:  0.233559712767601\n",
      "Eval Loss:  0.24975818395614624\n",
      "Eval Loss:  0.20811286568641663\n",
      "Eval Loss:  0.26431575417518616\n",
      "Eval Loss:  0.20908886194229126\n",
      "Eval Loss:  0.24637532234191895\n",
      "Eval Loss:  0.21687909960746765\n",
      "Eval Loss:  0.2591656744480133\n",
      "Eval Loss:  0.19720084965229034\n",
      "Eval Loss:  0.24987460672855377\n",
      "Eval Loss:  0.2217656522989273\n",
      "Eval Loss:  0.3104843199253082\n",
      "Eval Loss:  0.17302197217941284\n",
      "Eval Loss:  0.21927513182163239\n",
      "Eval Loss:  0.24523109197616577\n",
      "Eval Loss:  0.22691288590431213\n",
      "Eval Loss:  0.2882891893386841\n",
      "Eval Loss:  0.26835355162620544\n",
      "Eval Loss:  0.322549432516098\n",
      "Eval Loss:  0.22717581689357758\n",
      "[[16034   993]\n",
      " [ 1801 10692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17027\n",
      "           1       0.92      0.86      0.88     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.91      0.90     29520\n",
      "\n",
      "acc:  0.9053523035230352\n",
      "pre:  0.9150192554557125\n",
      "rec:  0.8558392699911951\n",
      "ma F1:  0.9021479151725177\n",
      "mi F1:  0.9053523035230352\n",
      "we F1:  0.904867626288438\n",
      "29520 462\n",
      "Loss:  0.03411509096622467\n",
      "Loss:  0.060732390731573105\n",
      "Loss:  0.04506058618426323\n",
      "33 **********\n",
      "Epoch:  1929.3064255714417  fold:  4  kers:  64\n",
      "epoch:  34\n",
      "29520 462\n",
      "Loss:  0.06774025410413742\n",
      "Loss:  0.05402100086212158\n",
      "Loss:  0.058429840952157974\n",
      "34 **********\n",
      "Epoch:  1973.0574445724487  fold:  4  kers:  64\n",
      "epoch:  35\n",
      "29520 462\n",
      "Loss:  0.06718737632036209\n",
      "Loss:  0.05606813728809357\n",
      "Loss:  0.0684199407696724\n",
      "35 **********\n",
      "Epoch:  2016.818436384201  fold:  4  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.2691406309604645\n",
      "Eval Loss:  0.30352041125297546\n",
      "Eval Loss:  0.033529527485370636\n",
      "[[2842  295]\n",
      " [ 186   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92      3137\n",
      "           1       0.14      0.21      0.17       234\n",
      "\n",
      "    accuracy                           0.86      3371\n",
      "   macro avg       0.54      0.56      0.54      3371\n",
      "weighted avg       0.88      0.86      0.87      3371\n",
      "\n",
      "acc:  0.8573123702165529\n",
      "pre:  0.13994169096209913\n",
      "rec:  0.20512820512820512\n",
      "ma F1:  0.5441783647554751\n",
      "mi F1:  0.8573123702165529\n",
      "we F1:  0.8695284069364017\n",
      "Eval Loss:  0.29099905490875244\n",
      "Eval Loss:  0.22126027941703796\n",
      "Eval Loss:  0.2750360071659088\n",
      "Eval Loss:  0.14039726555347443\n",
      "Eval Loss:  0.14663511514663696\n",
      "Eval Loss:  0.16077172756195068\n",
      "Eval Loss:  0.18838030099868774\n",
      "Eval Loss:  0.2413598597049713\n",
      "Eval Loss:  0.21195802092552185\n",
      "Eval Loss:  0.24355432391166687\n",
      "Eval Loss:  0.17874833941459656\n",
      "Eval Loss:  0.2507341504096985\n",
      "Eval Loss:  0.1865391582250595\n",
      "Eval Loss:  0.2298763245344162\n",
      "Eval Loss:  0.1766652911901474\n",
      "Eval Loss:  0.25707823038101196\n",
      "Eval Loss:  0.17987008392810822\n",
      "Eval Loss:  0.22396588325500488\n",
      "Eval Loss:  0.2141585648059845\n",
      "Eval Loss:  0.26444026827812195\n",
      "Eval Loss:  0.16779956221580505\n",
      "Eval Loss:  0.2490323930978775\n",
      "Eval Loss:  0.23565849661827087\n",
      "Eval Loss:  0.20549792051315308\n",
      "Eval Loss:  0.3005218207836151\n",
      "Eval Loss:  0.27567431330680847\n",
      "Eval Loss:  0.28600189089775085\n",
      "Eval Loss:  0.2290143072605133\n",
      "[[15583  1444]\n",
      " [ 1251 11242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     17027\n",
      "           1       0.89      0.90      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.91      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9087059620596206\n",
      "pre:  0.8861737348257922\n",
      "rec:  0.8998639237973265\n",
      "ma F1:  0.9066881359817213\n",
      "mi F1:  0.9087059620596206\n",
      "we F1:  0.9087956742072905\n",
      "29520 462\n",
      "Loss:  0.09636621177196503\n",
      "Loss:  0.043729282915592194\n",
      "Loss:  0.08115119487047195\n",
      "36 **********\n",
      "Epoch:  2099.2580094337463  fold:  4  kers:  64\n",
      "epoch:  37\n",
      "29520 462\n",
      "Loss:  0.03998792916536331\n",
      "Loss:  0.0575757697224617\n",
      "Loss:  0.07573968917131424\n",
      "37 **********\n",
      "Epoch:  2143.066873550415  fold:  4  kers:  64\n",
      "epoch:  38\n",
      "29520 462\n",
      "Loss:  0.04446565359830856\n",
      "Loss:  0.06374132633209229\n",
      "Loss:  0.09160715341567993\n",
      "38 **********\n",
      "Epoch:  2187.003396511078  fold:  4  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.21011671423912048\n",
      "Eval Loss:  0.18628133833408356\n",
      "Eval Loss:  0.011016018688678741\n",
      "[[2985  152]\n",
      " [ 216   18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3137\n",
      "           1       0.11      0.08      0.09       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.52      0.51      0.52      3371\n",
      "weighted avg       0.88      0.89      0.88      3371\n",
      "\n",
      "acc:  0.8908335805398991\n",
      "pre:  0.10588235294117647\n",
      "rec:  0.07692307692307693\n",
      "ma F1:  0.5155232153066995\n",
      "mi F1:  0.8908335805398991\n",
      "we F1:  0.8827379070060518\n",
      "Eval Loss:  0.2604914605617523\n",
      "Eval Loss:  0.24517476558685303\n",
      "Eval Loss:  0.2831744849681854\n",
      "Eval Loss:  0.1358024626970291\n",
      "Eval Loss:  0.15897926688194275\n",
      "Eval Loss:  0.15483367443084717\n",
      "Eval Loss:  0.20937784016132355\n",
      "Eval Loss:  0.239876851439476\n",
      "Eval Loss:  0.25705453753471375\n",
      "Eval Loss:  0.24533896148204803\n",
      "Eval Loss:  0.2179652899503708\n",
      "Eval Loss:  0.24687768518924713\n",
      "Eval Loss:  0.18669509887695312\n",
      "Eval Loss:  0.23142534494400024\n",
      "Eval Loss:  0.217690572142601\n",
      "Eval Loss:  0.27441835403442383\n",
      "Eval Loss:  0.1897914558649063\n",
      "Eval Loss:  0.23354865610599518\n",
      "Eval Loss:  0.20559565722942352\n",
      "Eval Loss:  0.2721807360649109\n",
      "Eval Loss:  0.15858103334903717\n",
      "Eval Loss:  0.2345009446144104\n",
      "Eval Loss:  0.23231276869773865\n",
      "Eval Loss:  0.22638307511806488\n",
      "Eval Loss:  0.260267049074173\n",
      "Eval Loss:  0.2309088259935379\n",
      "Eval Loss:  0.3153945505619049\n",
      "Eval Loss:  0.2099360227584839\n",
      "[[16051   976]\n",
      " [ 1757 10736]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17027\n",
      "           1       0.92      0.86      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9074186991869919\n",
      "pre:  0.9166666666666666\n",
      "rec:  0.8593612422956856\n",
      "ma F1:  0.904316934020734\n",
      "mi F1:  0.9074186991869919\n",
      "we F1:  0.9069629177016021\n",
      "29520 462\n",
      "Loss:  0.051960062235593796\n",
      "Loss:  0.06900463253259659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.045735765248537064\n",
      "39 **********\n",
      "Epoch:  2269.352212905884  fold:  4  kers:  64\n",
      "epoch:  40\n",
      "29520 462\n",
      "Loss:  0.06351427733898163\n",
      "Loss:  0.043403178453445435\n",
      "Loss:  0.08737774193286896\n",
      "40 **********\n",
      "Epoch:  2313.131156206131  fold:  4  kers:  64\n",
      "epoch:  41\n",
      "29520 462\n",
      "Loss:  0.05123113840818405\n",
      "Loss:  0.07422217726707458\n",
      "Loss:  0.042864106595516205\n",
      "41 **********\n",
      "Epoch:  2362.080276966095  fold:  4  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.44376853108406067\n",
      "Eval Loss:  0.10062451660633087\n",
      "Eval Loss:  0.008255836553871632\n",
      "[[2991  146]\n",
      " [ 208   26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3137\n",
      "           1       0.15      0.11      0.13       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.54      0.53      0.54      3371\n",
      "weighted avg       0.88      0.89      0.89      3371\n",
      "\n",
      "acc:  0.8949866508454465\n",
      "pre:  0.1511627906976744\n",
      "rec:  0.1111111111111111\n",
      "ma F1:  0.536103802806389\n",
      "mi F1:  0.8949866508454465\n",
      "we F1:  0.8874821865694189\n",
      "Eval Loss:  0.22504691779613495\n",
      "Eval Loss:  0.22947187721729279\n",
      "Eval Loss:  0.261711061000824\n",
      "Eval Loss:  0.14541302621364594\n",
      "Eval Loss:  0.16095058619976044\n",
      "Eval Loss:  0.15375837683677673\n",
      "Eval Loss:  0.1853826344013214\n",
      "Eval Loss:  0.24765227735042572\n",
      "Eval Loss:  0.23358197510242462\n",
      "Eval Loss:  0.23323984444141388\n",
      "Eval Loss:  0.19712142646312714\n",
      "Eval Loss:  0.24891676008701324\n",
      "Eval Loss:  0.1781318485736847\n",
      "Eval Loss:  0.22644081711769104\n",
      "Eval Loss:  0.21402066946029663\n",
      "Eval Loss:  0.2815329432487488\n",
      "Eval Loss:  0.1818181872367859\n",
      "Eval Loss:  0.22148892283439636\n",
      "Eval Loss:  0.21959781646728516\n",
      "Eval Loss:  0.2699580490589142\n",
      "Eval Loss:  0.15039226412773132\n",
      "Eval Loss:  0.21032515168190002\n",
      "Eval Loss:  0.23411203920841217\n",
      "Eval Loss:  0.22006455063819885\n",
      "Eval Loss:  0.24767139554023743\n",
      "Eval Loss:  0.23211297392845154\n",
      "Eval Loss:  0.305622935295105\n",
      "Eval Loss:  0.18104422092437744\n",
      "[[16223   804]\n",
      " [ 1856 10637]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17027\n",
      "           1       0.93      0.85      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9098915989159891\n",
      "pre:  0.9297264225155144\n",
      "rec:  0.8514368046105819\n",
      "ma F1:  0.9065452554771734\n",
      "mi F1:  0.9098915989159891\n",
      "we F1:  0.909261388873448\n",
      "29520 462\n",
      "Loss:  0.07321063429117203\n",
      "Loss:  0.03709039092063904\n",
      "Loss:  0.0485922135412693\n",
      "42 **********\n",
      "Epoch:  2444.554756164551  fold:  4  kers:  64\n",
      "epoch:  43\n",
      "29520 462\n",
      "Loss:  0.04300064966082573\n",
      "Loss:  0.06977908313274384\n",
      "Loss:  0.04342563450336456\n",
      "43 **********\n",
      "Epoch:  2488.501252412796  fold:  4  kers:  64\n",
      "epoch:  44\n",
      "29520 462\n",
      "Loss:  0.05999595671892166\n",
      "Loss:  0.05048098787665367\n",
      "Loss:  0.09369491785764694\n",
      "44 **********\n",
      "Epoch:  2532.3131086826324  fold:  4  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.875900387763977\n",
      "Eval Loss:  0.21187250316143036\n",
      "Eval Loss:  0.021526746451854706\n",
      "[[2652  485]\n",
      " [ 169   65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      3137\n",
      "           1       0.12      0.28      0.17       234\n",
      "\n",
      "    accuracy                           0.81      3371\n",
      "   macro avg       0.53      0.56      0.53      3371\n",
      "weighted avg       0.88      0.81      0.84      3371\n",
      "\n",
      "acc:  0.8059922871551468\n",
      "pre:  0.11818181818181818\n",
      "rec:  0.2777777777777778\n",
      "ma F1:  0.5280239739400292\n",
      "mi F1:  0.8059922871551467\n",
      "we F1:  0.8399458963457063\n",
      "Eval Loss:  0.24925872683525085\n",
      "Eval Loss:  0.2201436460018158\n",
      "Eval Loss:  0.2311767190694809\n",
      "Eval Loss:  0.15111689269542694\n",
      "Eval Loss:  0.152618870139122\n",
      "Eval Loss:  0.1628330498933792\n",
      "Eval Loss:  0.19761709868907928\n",
      "Eval Loss:  0.2391069531440735\n",
      "Eval Loss:  0.19240374863147736\n",
      "Eval Loss:  0.1985311359167099\n",
      "Eval Loss:  0.17067673802375793\n",
      "Eval Loss:  0.24023640155792236\n",
      "Eval Loss:  0.15316608548164368\n",
      "Eval Loss:  0.2138918787240982\n",
      "Eval Loss:  0.18805046379566193\n",
      "Eval Loss:  0.24768945574760437\n",
      "Eval Loss:  0.18324773013591766\n",
      "Eval Loss:  0.2038067877292633\n",
      "Eval Loss:  0.19099022448062897\n",
      "Eval Loss:  0.22220835089683533\n",
      "Eval Loss:  0.13546551764011383\n",
      "Eval Loss:  0.2210540622472763\n",
      "Eval Loss:  0.2110617756843567\n",
      "Eval Loss:  0.2254582792520523\n",
      "Eval Loss:  0.25539103150367737\n",
      "Eval Loss:  0.23351481556892395\n",
      "Eval Loss:  0.29080331325531006\n",
      "Eval Loss:  0.1860155463218689\n",
      "[[15975  1052]\n",
      " [ 1432 11061]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17027\n",
      "           1       0.91      0.89      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9158536585365854\n",
      "pre:  0.9131511599108396\n",
      "rec:  0.8853758104538542\n",
      "ma F1:  0.9134555046497781\n",
      "mi F1:  0.9158536585365854\n",
      "we F1:  0.915668209111069\n",
      "29520 462\n",
      "Loss:  0.043238088488578796\n",
      "Loss:  0.060224611312150955\n",
      "Loss:  0.06919322162866592\n",
      "45 **********\n",
      "Epoch:  2614.849422931671  fold:  4  kers:  64\n",
      "epoch:  46\n",
      "29520 462\n",
      "Loss:  0.10151712596416473\n",
      "Loss:  0.0328235924243927\n",
      "Loss:  0.07813020795583725\n",
      "46 **********\n",
      "Epoch:  2658.661279439926  fold:  4  kers:  64\n",
      "epoch:  47\n",
      "29520 462\n",
      "Loss:  0.04304143413901329\n",
      "Loss:  0.05253273993730545\n",
      "Loss:  0.047890182584524155\n",
      "47 **********\n",
      "Epoch:  2702.4013271331787  fold:  4  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.6007222533226013\n",
      "Eval Loss:  0.2730741500854492\n",
      "Eval Loss:  0.00995727814733982\n",
      "[[2755  382]\n",
      " [ 200   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      3137\n",
      "           1       0.08      0.15      0.10       234\n",
      "\n",
      "    accuracy                           0.83      3371\n",
      "   macro avg       0.51      0.51      0.50      3371\n",
      "weighted avg       0.87      0.83      0.85      3371\n",
      "\n",
      "acc:  0.8273509344408188\n",
      "pre:  0.08173076923076923\n",
      "rec:  0.1452991452991453\n",
      "ma F1:  0.5045401282893075\n",
      "mi F1:  0.8273509344408188\n",
      "we F1:  0.8489428369470939\n",
      "Eval Loss:  0.19590872526168823\n",
      "Eval Loss:  0.2159743756055832\n",
      "Eval Loss:  0.22296619415283203\n",
      "Eval Loss:  0.12446506321430206\n",
      "Eval Loss:  0.1471792608499527\n",
      "Eval Loss:  0.14046849310398102\n",
      "Eval Loss:  0.1841287910938263\n",
      "Eval Loss:  0.22400863468647003\n",
      "Eval Loss:  0.19719912111759186\n",
      "Eval Loss:  0.2039068192243576\n",
      "Eval Loss:  0.1657850444316864\n",
      "Eval Loss:  0.2246565818786621\n",
      "Eval Loss:  0.15534645318984985\n",
      "Eval Loss:  0.2387365847826004\n",
      "Eval Loss:  0.17077675461769104\n",
      "Eval Loss:  0.23599663376808167\n",
      "Eval Loss:  0.1803504079580307\n",
      "Eval Loss:  0.21815671026706696\n",
      "Eval Loss:  0.19190427660942078\n",
      "Eval Loss:  0.2402903288602829\n",
      "Eval Loss:  0.14125323295593262\n",
      "Eval Loss:  0.20707722008228302\n",
      "Eval Loss:  0.22728069126605988\n",
      "Eval Loss:  0.2126542180776596\n",
      "Eval Loss:  0.23700998723506927\n",
      "Eval Loss:  0.23631563782691956\n",
      "Eval Loss:  0.26721933484077454\n",
      "Eval Loss:  0.18522411584854126\n",
      "[[16010  1017]\n",
      " [ 1481 11012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17027\n",
      "           1       0.92      0.88      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9153794037940379\n",
      "pre:  0.9154543187297365\n",
      "rec:  0.8814536140238534\n",
      "ma F1:  0.9128821247547741\n",
      "mi F1:  0.9153794037940379\n",
      "we F1:  0.9151475635631018\n",
      "29520 462\n",
      "Loss:  0.04598198086023331\n",
      "Loss:  0.0713580921292305\n",
      "Loss:  0.05356523394584656\n",
      "48 **********\n",
      "Epoch:  2786.4426176548004  fold:  4  kers:  64\n",
      "epoch:  49\n",
      "29520 462\n",
      "Loss:  0.0724213719367981\n",
      "Loss:  0.05083019658923149\n",
      "Loss:  0.05994633212685585\n",
      "49 **********\n",
      "Epoch:  2830.207598924637  fold:  4  kers:  64\n",
      "epoch:  50\n",
      "29520 462\n",
      "Loss:  0.05053011327981949\n",
      "Loss:  0.05431753769516945\n",
      "Loss:  0.07541370391845703\n",
      "50 **********\n",
      "Epoch:  2874.011476755142  fold:  4  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.5677588582038879\n",
      "Eval Loss:  0.21134760975837708\n",
      "Eval Loss:  0.010923254303634167\n",
      "[[2785  352]\n",
      " [ 181   53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      3137\n",
      "           1       0.13      0.23      0.17       234\n",
      "\n",
      "    accuracy                           0.84      3371\n",
      "   macro avg       0.53      0.56      0.54      3371\n",
      "weighted avg       0.88      0.84      0.86      3371\n",
      "\n",
      "acc:  0.8418866805102343\n",
      "pre:  0.1308641975308642\n",
      "rec:  0.2264957264957265\n",
      "ma F1:  0.5392750480343053\n",
      "mi F1:  0.8418866805102343\n",
      "we F1:  0.8608275989411948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21341009438037872\n",
      "Eval Loss:  0.21887412667274475\n",
      "Eval Loss:  0.25953707098960876\n",
      "Eval Loss:  0.10713644325733185\n",
      "Eval Loss:  0.14438965916633606\n",
      "Eval Loss:  0.15289069712162018\n",
      "Eval Loss:  0.19590139389038086\n",
      "Eval Loss:  0.20753519237041473\n",
      "Eval Loss:  0.20306028425693512\n",
      "Eval Loss:  0.2109704464673996\n",
      "Eval Loss:  0.15669456124305725\n",
      "Eval Loss:  0.2216007113456726\n",
      "Eval Loss:  0.17404651641845703\n",
      "Eval Loss:  0.1853492110967636\n",
      "Eval Loss:  0.1808653622865677\n",
      "Eval Loss:  0.2408372163772583\n",
      "Eval Loss:  0.16922946274280548\n",
      "Eval Loss:  0.20358404517173767\n",
      "Eval Loss:  0.21384815871715546\n",
      "Eval Loss:  0.22924929857254028\n",
      "Eval Loss:  0.1339985728263855\n",
      "Eval Loss:  0.23268745839595795\n",
      "Eval Loss:  0.25340113043785095\n",
      "Eval Loss:  0.23556575179100037\n",
      "Eval Loss:  0.23290447890758514\n",
      "Eval Loss:  0.22740766406059265\n",
      "Eval Loss:  0.26033830642700195\n",
      "Eval Loss:  0.2136242538690567\n",
      "[[15597  1430]\n",
      " [ 1118 11375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     17027\n",
      "           1       0.89      0.91      0.90     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.91      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9136856368563686\n",
      "pre:  0.8883248730964467\n",
      "rec:  0.9105098855359001\n",
      "ma F1:  0.9118831897910039\n",
      "mi F1:  0.9136856368563685\n",
      "we F1:  0.9138188352183755\n",
      "29520 462\n",
      "Loss:  0.04481138661503792\n",
      "Loss:  0.03723626211285591\n",
      "Loss:  0.03133688122034073\n",
      "51 **********\n",
      "Epoch:  2956.404175043106  fold:  4  kers:  64\n",
      "epoch:  52\n",
      "29520 462\n",
      "Loss:  0.05054092034697533\n",
      "Loss:  0.05778336524963379\n",
      "Loss:  0.03605017811059952\n",
      "52 **********\n",
      "Epoch:  3000.1851143836975  fold:  4  kers:  64\n",
      "epoch:  53\n",
      "29520 462\n",
      "Loss:  0.06516684591770172\n",
      "Loss:  0.034176453948020935\n",
      "Loss:  0.059560880064964294\n",
      "53 **********\n",
      "Epoch:  3044.0598015785217  fold:  4  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.845279335975647\n",
      "Eval Loss:  0.20906555652618408\n",
      "Eval Loss:  0.01504434086382389\n",
      "[[2663  474]\n",
      " [ 170   64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      3137\n",
      "           1       0.12      0.27      0.17       234\n",
      "\n",
      "    accuracy                           0.81      3371\n",
      "   macro avg       0.53      0.56      0.53      3371\n",
      "weighted avg       0.88      0.81      0.84      3371\n",
      "\n",
      "acc:  0.8089587659448235\n",
      "pre:  0.11895910780669144\n",
      "rec:  0.27350427350427353\n",
      "ma F1:  0.5289652059954348\n",
      "mi F1:  0.8089587659448235\n",
      "we F1:  0.8417090707638362\n",
      "Eval Loss:  0.20268650352954865\n",
      "Eval Loss:  0.18455128371715546\n",
      "Eval Loss:  0.24050283432006836\n",
      "Eval Loss:  0.13622750341892242\n",
      "Eval Loss:  0.1237705796957016\n",
      "Eval Loss:  0.14910393953323364\n",
      "Eval Loss:  0.1982627511024475\n",
      "Eval Loss:  0.20816494524478912\n",
      "Eval Loss:  0.15474669635295868\n",
      "Eval Loss:  0.18641239404678345\n",
      "Eval Loss:  0.13885588943958282\n",
      "Eval Loss:  0.2020251452922821\n",
      "Eval Loss:  0.13906291127204895\n",
      "Eval Loss:  0.19733771681785583\n",
      "Eval Loss:  0.15611116588115692\n",
      "Eval Loss:  0.21983091533184052\n",
      "Eval Loss:  0.16317471861839294\n",
      "Eval Loss:  0.1959414780139923\n",
      "Eval Loss:  0.18540634214878082\n",
      "Eval Loss:  0.20378495752811432\n",
      "Eval Loss:  0.12003511190414429\n",
      "Eval Loss:  0.21715398132801056\n",
      "Eval Loss:  0.22956536710262299\n",
      "Eval Loss:  0.2077220231294632\n",
      "Eval Loss:  0.23811905086040497\n",
      "Eval Loss:  0.2276776134967804\n",
      "Eval Loss:  0.2652736008167267\n",
      "Eval Loss:  0.17588749527931213\n",
      "[[15630  1397]\n",
      " [  940 11553]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     17027\n",
      "           1       0.89      0.92      0.91     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.92      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9208333333333333\n",
      "pre:  0.8921235521235521\n",
      "rec:  0.9247578644040663\n",
      "ma F1:  0.9192939209887638\n",
      "mi F1:  0.9208333333333333\n",
      "we F1:  0.9210058894877283\n",
      "29520 462\n",
      "Loss:  0.06967512518167496\n",
      "Loss:  0.047202207148075104\n",
      "Loss:  0.0752895176410675\n",
      "54 **********\n",
      "Epoch:  3126.489401817322  fold:  4  kers:  64\n",
      "epoch:  55\n",
      "29520 462\n",
      "Loss:  0.05519704148173332\n",
      "Loss:  0.05157237499952316\n",
      "Loss:  0.06261284649372101\n",
      "55 **********\n",
      "Epoch:  3170.2843029499054  fold:  4  kers:  64\n",
      "epoch:  56\n",
      "29520 462\n",
      "Loss:  0.04710351675748825\n",
      "Loss:  0.03280014544725418\n",
      "Loss:  0.05589986965060234\n",
      "56 **********\n",
      "Epoch:  3214.175945997238  fold:  4  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.6580700278282166\n",
      "Eval Loss:  0.22735975682735443\n",
      "Eval Loss:  0.006252319552004337\n",
      "[[2723  414]\n",
      " [ 192   42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      3137\n",
      "           1       0.09      0.18      0.12       234\n",
      "\n",
      "    accuracy                           0.82      3371\n",
      "   macro avg       0.51      0.52      0.51      3371\n",
      "weighted avg       0.88      0.82      0.85      3371\n",
      "\n",
      "acc:  0.8202313853455948\n",
      "pre:  0.09210526315789473\n",
      "rec:  0.1794871794871795\n",
      "ma F1:  0.5108034713641196\n",
      "mi F1:  0.8202313853455948\n",
      "we F1:  0.845853540102733\n",
      "Eval Loss:  0.20103493332862854\n",
      "Eval Loss:  0.21767988801002502\n",
      "Eval Loss:  0.22618070244789124\n",
      "Eval Loss:  0.13256369531154633\n",
      "Eval Loss:  0.14953748881816864\n",
      "Eval Loss:  0.14646100997924805\n",
      "Eval Loss:  0.18233630061149597\n",
      "Eval Loss:  0.22641146183013916\n",
      "Eval Loss:  0.1849759817123413\n",
      "Eval Loss:  0.20224183797836304\n",
      "Eval Loss:  0.1704808473587036\n",
      "Eval Loss:  0.21644502878189087\n",
      "Eval Loss:  0.1628844290971756\n",
      "Eval Loss:  0.23043332993984222\n",
      "Eval Loss:  0.16973088681697845\n",
      "Eval Loss:  0.24100010097026825\n",
      "Eval Loss:  0.1748621016740799\n",
      "Eval Loss:  0.2395671308040619\n",
      "Eval Loss:  0.1934177577495575\n",
      "Eval Loss:  0.21182259917259216\n",
      "Eval Loss:  0.12264156341552734\n",
      "Eval Loss:  0.21959324181079865\n",
      "Eval Loss:  0.2129204124212265\n",
      "Eval Loss:  0.23385487496852875\n",
      "Eval Loss:  0.23954513669013977\n",
      "Eval Loss:  0.23136818408966064\n",
      "Eval Loss:  0.2743189334869385\n",
      "Eval Loss:  0.17715197801589966\n",
      "[[15873  1154]\n",
      " [ 1278 11215]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17027\n",
      "           1       0.91      0.90      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9176151761517615\n",
      "pre:  0.9067022394696419\n",
      "rec:  0.897702713519571\n",
      "ma F1:  0.9155115746204436\n",
      "mi F1:  0.9176151761517615\n",
      "we F1:  0.9175591764544916\n",
      "29520 462\n",
      "Loss:  0.06342722475528717\n",
      "Loss:  0.04819279536604881\n",
      "Loss:  0.08398587256669998\n",
      "57 **********\n",
      "Epoch:  3296.4549486637115  fold:  4  kers:  64\n",
      "epoch:  58\n",
      "29520 462\n",
      "Loss:  0.05739264562726021\n",
      "Loss:  0.05053731054067612\n",
      "Loss:  0.04609246924519539\n",
      "58 **********\n",
      "Epoch:  3340.2578287124634  fold:  4  kers:  64\n",
      "epoch:  59\n",
      "29520 462\n",
      "Loss:  0.04203806817531586\n",
      "Loss:  0.06501977890729904\n",
      "Loss:  0.05867624282836914\n",
      "59 **********\n",
      "Epoch:  3384.0956151485443  fold:  4  kers:  64\n",
      "Eval Loss:  0.5932939052581787\n",
      "Eval Loss:  0.2073180228471756\n",
      "Eval Loss:  0.007319762837141752\n",
      "[[2750  387]\n",
      " [ 187   47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91      3137\n",
      "           1       0.11      0.20      0.14       234\n",
      "\n",
      "    accuracy                           0.83      3371\n",
      "   macro avg       0.52      0.54      0.52      3371\n",
      "weighted avg       0.88      0.83      0.85      3371\n",
      "\n",
      "acc:  0.82972411747256\n",
      "pre:  0.10829493087557604\n",
      "rec:  0.20085470085470086\n",
      "ma F1:  0.5231087052105864\n",
      "mi F1:  0.82972411747256\n",
      "we F1:  0.8524111624050036\n",
      "update!  Acc:  0.9204983684366657\n",
      "Epoch:  3388.0659992694855  fold:  4  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29673 3218\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29673 464\n",
      "Loss:  0.17235806584358215\n",
      "Loss:  0.16676412522792816\n",
      "Loss:  0.16057267785072327\n",
      "0 **********\n",
      "Epoch:  56.784170627593994  fold:  5  kers:  64\n",
      "epoch:  1\n",
      "29673 464\n",
      "Loss:  0.14415952563285828\n",
      "Loss:  0.13740554451942444\n",
      "Loss:  0.13467629253864288\n",
      "1 **********\n",
      "Epoch:  101.20340275764465  fold:  5  kers:  64\n",
      "epoch:  2\n",
      "29673 464\n",
      "Loss:  0.11939196288585663\n",
      "Loss:  0.11684621870517731\n",
      "Loss:  0.10780768096446991\n",
      "2 **********\n",
      "Epoch:  145.44510889053345  fold:  5  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.18914064764976501\n",
      "Eval Loss:  0.37808099389076233\n",
      "Eval Loss:  0.36928999423980713\n",
      "[[2675  422]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      3097\n",
      "           1       0.17      0.74      0.28       121\n",
      "\n",
      "    accuracy                           0.86      3218\n",
      "   macro avg       0.58      0.80      0.60      3218\n",
      "weighted avg       0.96      0.86      0.90      3218\n",
      "\n",
      "acc:  0.8589185829707893\n",
      "pre:  0.17416829745596868\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.601711826850099\n",
      "mi F1:  0.8589185829707894\n",
      "we F1:  0.8977084649843504\n",
      "update!  Acc:  0.8589185829707893\n",
      "Eval Loss:  0.4161264896392822\n",
      "Eval Loss:  0.49205124378204346\n",
      "Eval Loss:  0.45099395513534546\n",
      "Eval Loss:  0.3892708122730255\n",
      "Eval Loss:  0.4295863211154938\n",
      "Eval Loss:  0.35860466957092285\n",
      "Eval Loss:  0.36330482363700867\n",
      "Eval Loss:  0.43211278319358826\n",
      "Eval Loss:  0.3087009787559509\n",
      "Eval Loss:  0.4122677743434906\n",
      "Eval Loss:  0.4306473433971405\n",
      "Eval Loss:  0.43104657530784607\n",
      "Eval Loss:  0.43215468525886536\n",
      "Eval Loss:  0.38009771704673767\n",
      "Eval Loss:  0.4153183400630951\n",
      "Eval Loss:  0.38512590527534485\n",
      "Eval Loss:  0.46560734510421753\n",
      "Eval Loss:  0.3939751088619232\n",
      "Eval Loss:  0.4276300370693207\n",
      "Eval Loss:  0.41225022077560425\n",
      "Eval Loss:  0.41565120220184326\n",
      "Eval Loss:  0.448385626077652\n",
      "Eval Loss:  0.4271288812160492\n",
      "Eval Loss:  0.4033127427101135\n",
      "Eval Loss:  0.3932133615016937\n",
      "Eval Loss:  0.5072442889213562\n",
      "Eval Loss:  0.4950999915599823\n",
      "Eval Loss:  0.36848774552345276\n",
      "Eval Loss:  0.45103999972343445\n",
      "[[13870  3197]\n",
      " [ 2449 10157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83     17067\n",
      "           1       0.76      0.81      0.78     12606\n",
      "\n",
      "    accuracy                           0.81     29673\n",
      "   macro avg       0.81      0.81      0.81     29673\n",
      "weighted avg       0.81      0.81      0.81     29673\n",
      "\n",
      "acc:  0.8097260135476696\n",
      "pre:  0.7605960760820728\n",
      "rec:  0.8057274313818816\n",
      "ma F1:  0.8066993772335856\n",
      "mi F1:  0.8097260135476696\n",
      "we F1:  0.8103357425977461\n",
      "29673 464\n",
      "Loss:  0.0934634804725647\n",
      "Loss:  0.11946815997362137\n",
      "Loss:  0.09960778057575226\n",
      "3 **********\n",
      "Epoch:  228.53693842887878  fold:  5  kers:  64\n",
      "epoch:  4\n",
      "29673 464\n",
      "Loss:  0.15383458137512207\n",
      "Loss:  0.07543180137872696\n",
      "Loss:  0.1342843919992447\n",
      "4 **********\n",
      "Epoch:  272.80956268310547  fold:  5  kers:  64\n",
      "epoch:  5\n",
      "29673 464\n",
      "Loss:  0.1044490858912468\n",
      "Loss:  0.12162013351917267\n",
      "Loss:  0.08674993366003036\n",
      "5 **********\n",
      "Epoch:  317.10412788391113  fold:  5  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.1104460135102272\n",
      "Eval Loss:  0.2449118196964264\n",
      "Eval Loss:  0.15781371295452118\n",
      "[[2971  126]\n",
      " [  38   83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      3097\n",
      "           1       0.40      0.69      0.50       121\n",
      "\n",
      "    accuracy                           0.95      3218\n",
      "   macro avg       0.69      0.82      0.74      3218\n",
      "weighted avg       0.97      0.95      0.96      3218\n",
      "\n",
      "acc:  0.9490366687383468\n",
      "pre:  0.39712918660287083\n",
      "rec:  0.6859504132231405\n",
      "ma F1:  0.7380857378237006\n",
      "mi F1:  0.9490366687383468\n",
      "we F1:  0.9554645364393473\n",
      "update!  Acc:  0.9490366687383468\n",
      "Eval Loss:  0.41844016313552856\n",
      "Eval Loss:  0.4977864623069763\n",
      "Eval Loss:  0.4227932095527649\n",
      "Eval Loss:  0.36188918352127075\n",
      "Eval Loss:  0.40851059556007385\n",
      "Eval Loss:  0.3143872022628784\n",
      "Eval Loss:  0.3117084801197052\n",
      "Eval Loss:  0.43725258111953735\n",
      "Eval Loss:  0.28459441661834717\n",
      "Eval Loss:  0.3770555853843689\n",
      "Eval Loss:  0.4249686300754547\n",
      "Eval Loss:  0.33546707034111023\n",
      "Eval Loss:  0.3640632629394531\n",
      "Eval Loss:  0.3654109537601471\n",
      "Eval Loss:  0.3534518778324127\n",
      "Eval Loss:  0.37184107303619385\n",
      "Eval Loss:  0.4288340210914612\n",
      "Eval Loss:  0.38963913917541504\n",
      "Eval Loss:  0.4063721001148224\n",
      "Eval Loss:  0.3841988146305084\n",
      "Eval Loss:  0.4096774756908417\n",
      "Eval Loss:  0.4552350342273712\n",
      "Eval Loss:  0.3839464783668518\n",
      "Eval Loss:  0.44041532278060913\n",
      "Eval Loss:  0.34686821699142456\n",
      "Eval Loss:  0.44690436124801636\n",
      "Eval Loss:  0.5050531625747681\n",
      "Eval Loss:  0.3728163540363312\n",
      "Eval Loss:  0.4388427436351776\n",
      "[[15814  1253]\n",
      " [ 3655  8951]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87     17067\n",
      "           1       0.88      0.71      0.78     12606\n",
      "\n",
      "    accuracy                           0.83     29673\n",
      "   macro avg       0.84      0.82      0.83     29673\n",
      "weighted avg       0.84      0.83      0.83     29673\n",
      "\n",
      "acc:  0.8345971084824588\n",
      "pre:  0.8772050176401411\n",
      "rec:  0.7100587022052991\n",
      "ma F1:  0.825248977016849\n",
      "mi F1:  0.8345971084824588\n",
      "we F1:  0.8313253305747809\n",
      "29673 464\n",
      "Loss:  0.06706727296113968\n",
      "Loss:  0.05151347815990448\n",
      "Loss:  0.07594173401594162\n",
      "6 **********\n",
      "Epoch:  400.3884425163269  fold:  5  kers:  64\n",
      "epoch:  7\n",
      "29673 464\n",
      "Loss:  0.09788648784160614\n",
      "Loss:  0.11691553890705109\n",
      "Loss:  0.08710704743862152\n",
      "7 **********\n",
      "Epoch:  444.6670503616333  fold:  5  kers:  64\n",
      "epoch:  8\n",
      "29673 464\n",
      "Loss:  0.10660106688737869\n",
      "Loss:  0.11263402551412582\n",
      "Loss:  0.08705515414476395\n",
      "8 **********\n",
      "Epoch:  489.4473171234131  fold:  5  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.07842651754617691\n",
      "Eval Loss:  0.15587761998176575\n",
      "Eval Loss:  0.1030062735080719\n",
      "[[3038   59]\n",
      " [  46   75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.56      0.62      0.59       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.80      0.79      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9673710379117464\n",
      "pre:  0.5597014925373134\n",
      "rec:  0.6198347107438017\n",
      "ma F1:  0.7856238758243954\n",
      "mi F1:  0.9673710379117464\n",
      "we F1:  0.9681684436178333\n",
      "update!  Acc:  0.9673710379117464\n",
      "Eval Loss:  0.46127593517303467\n",
      "Eval Loss:  0.5249825716018677\n",
      "Eval Loss:  0.45856693387031555\n",
      "Eval Loss:  0.3885883092880249\n",
      "Eval Loss:  0.4245997369289398\n",
      "Eval Loss:  0.3762684166431427\n",
      "Eval Loss:  0.3219660818576813\n",
      "Eval Loss:  0.44665855169296265\n",
      "Eval Loss:  0.26720118522644043\n",
      "Eval Loss:  0.37281113862991333\n",
      "Eval Loss:  0.49729210138320923\n",
      "Eval Loss:  0.34383049607276917\n",
      "Eval Loss:  0.4021366238594055\n",
      "Eval Loss:  0.40657976269721985\n",
      "Eval Loss:  0.3855019807815552\n",
      "Eval Loss:  0.35717537999153137\n",
      "Eval Loss:  0.44405609369277954\n",
      "Eval Loss:  0.4261033236980438\n",
      "Eval Loss:  0.4274289011955261\n",
      "Eval Loss:  0.36849161982536316\n",
      "Eval Loss:  0.47489243745803833\n",
      "Eval Loss:  0.48815733194351196\n",
      "Eval Loss:  0.43210625648498535\n",
      "Eval Loss:  0.4974793791770935\n",
      "Eval Loss:  0.35229989886283875\n",
      "Eval Loss:  0.45917177200317383\n",
      "Eval Loss:  0.5396478176116943\n",
      "Eval Loss:  0.45134177803993225\n",
      "Eval Loss:  0.46422117948532104\n",
      "[[16327   740]\n",
      " [ 4446  8160]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.86     17067\n",
      "           1       0.92      0.65      0.76     12606\n",
      "\n",
      "    accuracy                           0.83     29673\n",
      "   macro avg       0.85      0.80      0.81     29673\n",
      "weighted avg       0.84      0.83      0.82     29673\n",
      "\n",
      "acc:  0.8252283220436086\n",
      "pre:  0.9168539325842696\n",
      "rec:  0.6473108043788672\n",
      "ma F1:  0.8109036265802414\n",
      "mi F1:  0.8252283220436086\n",
      "we F1:  0.8187280990257026\n",
      "29673 464\n",
      "Loss:  0.07696060836315155\n",
      "Loss:  0.06193551793694496\n",
      "Loss:  0.09396273642778397\n",
      "9 **********\n",
      "Epoch:  572.6777760982513  fold:  5  kers:  64\n",
      "epoch:  10\n",
      "29673 464\n",
      "Loss:  0.06780228018760681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09533381462097168\n",
      "Loss:  0.11050553619861603\n",
      "10 **********\n",
      "Epoch:  616.9503998756409  fold:  5  kers:  64\n",
      "epoch:  11\n",
      "29673 464\n",
      "Loss:  0.09431234002113342\n",
      "Loss:  0.10704310983419418\n",
      "Loss:  0.10671138018369675\n",
      "11 **********\n",
      "Epoch:  661.2369866371155  fold:  5  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.08300606906414032\n",
      "Eval Loss:  0.2569347620010376\n",
      "Eval Loss:  0.07102564722299576\n",
      "[[3015   82]\n",
      " [  26   95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.54      0.79      0.64       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.76      0.88      0.81      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.966438781852082\n",
      "pre:  0.536723163841808\n",
      "rec:  0.7851239669421488\n",
      "ma F1:  0.8099942923497806\n",
      "mi F1:  0.9664387818520821\n",
      "we F1:  0.9694390871302083\n",
      "Eval Loss:  0.2924477756023407\n",
      "Eval Loss:  0.3706435561180115\n",
      "Eval Loss:  0.3064173460006714\n",
      "Eval Loss:  0.310897558927536\n",
      "Eval Loss:  0.3106446862220764\n",
      "Eval Loss:  0.28260478377342224\n",
      "Eval Loss:  0.26441311836242676\n",
      "Eval Loss:  0.3101395070552826\n",
      "Eval Loss:  0.2375527322292328\n",
      "Eval Loss:  0.2932904362678528\n",
      "Eval Loss:  0.28249144554138184\n",
      "Eval Loss:  0.2461957484483719\n",
      "Eval Loss:  0.30428656935691833\n",
      "Eval Loss:  0.3122695982456207\n",
      "Eval Loss:  0.26873844861984253\n",
      "Eval Loss:  0.30711913108825684\n",
      "Eval Loss:  0.3782171607017517\n",
      "Eval Loss:  0.3494715392589569\n",
      "Eval Loss:  0.3213651180267334\n",
      "Eval Loss:  0.2951798439025879\n",
      "Eval Loss:  0.3010413348674774\n",
      "Eval Loss:  0.32206258177757263\n",
      "Eval Loss:  0.29686102271080017\n",
      "Eval Loss:  0.3257765471935272\n",
      "Eval Loss:  0.2974759042263031\n",
      "Eval Loss:  0.3074454367160797\n",
      "Eval Loss:  0.39941906929016113\n",
      "Eval Loss:  0.317481130361557\n",
      "Eval Loss:  0.34078994393348694\n",
      "[[15605  1462]\n",
      " [ 2459 10147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89     17067\n",
      "           1       0.87      0.80      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.87      0.86      0.86     29673\n",
      "weighted avg       0.87      0.87      0.87     29673\n",
      "\n",
      "acc:  0.867859670407441\n",
      "pre:  0.8740632268067878\n",
      "rec:  0.8049341583372996\n",
      "ma F1:  0.8632323724741694\n",
      "mi F1:  0.8678596704074412\n",
      "we F1:  0.8670144127966914\n",
      "29673 464\n",
      "Loss:  0.10798336565494537\n",
      "Loss:  0.06486920267343521\n",
      "Loss:  0.06844304502010345\n",
      "12 **********\n",
      "Epoch:  744.2809436321259  fold:  5  kers:  64\n",
      "epoch:  13\n",
      "29673 464\n",
      "Loss:  0.07146988809108734\n",
      "Loss:  0.11565892398357391\n",
      "Loss:  0.11057212948799133\n",
      "13 **********\n",
      "Epoch:  788.4887413978577  fold:  5  kers:  64\n",
      "epoch:  14\n",
      "29673 464\n",
      "Loss:  0.07073444873094559\n",
      "Loss:  0.09858015924692154\n",
      "Loss:  0.07996785640716553\n",
      "14 **********\n",
      "Epoch:  832.7972691059113  fold:  5  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.07464292645454407\n",
      "Eval Loss:  0.20212778449058533\n",
      "Eval Loss:  0.06127386540174484\n",
      "[[3026   71]\n",
      " [  34   87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.55      0.72      0.62       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.85      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9673710379117464\n",
      "pre:  0.5506329113924051\n",
      "rec:  0.71900826446281\n",
      "ma F1:  0.803301077015234\n",
      "mi F1:  0.9673710379117464\n",
      "we F1:  0.969436566510988\n",
      "Eval Loss:  0.2857593297958374\n",
      "Eval Loss:  0.35523244738578796\n",
      "Eval Loss:  0.2856276333332062\n",
      "Eval Loss:  0.274580717086792\n",
      "Eval Loss:  0.2971346080303192\n",
      "Eval Loss:  0.2492356151342392\n",
      "Eval Loss:  0.22586412727832794\n",
      "Eval Loss:  0.28526151180267334\n",
      "Eval Loss:  0.21355953812599182\n",
      "Eval Loss:  0.28839242458343506\n",
      "Eval Loss:  0.2736184000968933\n",
      "Eval Loss:  0.21813727915287018\n",
      "Eval Loss:  0.28136804699897766\n",
      "Eval Loss:  0.2739448547363281\n",
      "Eval Loss:  0.2474815994501114\n",
      "Eval Loss:  0.2750694751739502\n",
      "Eval Loss:  0.3401179313659668\n",
      "Eval Loss:  0.31082239747047424\n",
      "Eval Loss:  0.2712692618370056\n",
      "Eval Loss:  0.24512751400470734\n",
      "Eval Loss:  0.2582055926322937\n",
      "Eval Loss:  0.28029415011405945\n",
      "Eval Loss:  0.28036704659461975\n",
      "Eval Loss:  0.3408806324005127\n",
      "Eval Loss:  0.2534613311290741\n",
      "Eval Loss:  0.2914572060108185\n",
      "Eval Loss:  0.37984517216682434\n",
      "Eval Loss:  0.2882649004459381\n",
      "Eval Loss:  0.2738676965236664\n",
      "[[15864  1203]\n",
      " [ 2429 10177]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     17067\n",
      "           1       0.89      0.81      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.88      0.87      0.87     29673\n",
      "weighted avg       0.88      0.88      0.88     29673\n",
      "\n",
      "acc:  0.877599164223368\n",
      "pre:  0.8942882249560633\n",
      "rec:  0.8073139774710455\n",
      "ma F1:  0.8729317026183826\n",
      "mi F1:  0.877599164223368\n",
      "we F1:  0.876592955690273\n",
      "29673 464\n",
      "Loss:  0.0867767408490181\n",
      "Loss:  0.07931279391050339\n",
      "Loss:  0.07932235300540924\n",
      "15 **********\n",
      "Epoch:  915.9200160503387  fold:  5  kers:  64\n",
      "epoch:  16\n",
      "29673 464\n",
      "Loss:  0.08469461649656296\n",
      "Loss:  0.08027821034193039\n",
      "Loss:  0.08326106518507004\n",
      "16 **********\n",
      "Epoch:  960.1028802394867  fold:  5  kers:  64\n",
      "epoch:  17\n",
      "29673 464\n",
      "Loss:  0.08182338625192642\n",
      "Loss:  0.06529337912797928\n",
      "Loss:  0.06772615015506744\n",
      "17 **********\n",
      "Epoch:  1004.1590821743011  fold:  5  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.07019577920436859\n",
      "Eval Loss:  0.08565375208854675\n",
      "Eval Loss:  0.03472430258989334\n",
      "[[3070   27]\n",
      " [  34   87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.76      0.72      0.74       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.86      0.87      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9810441267868241\n",
      "pre:  0.7631578947368421\n",
      "rec:  0.71900826446281\n",
      "ma F1:  0.8652942044351117\n",
      "mi F1:  0.981044126786824\n",
      "we F1:  0.9807725044413793\n",
      "update!  Acc:  0.9810441267868241\n",
      "Eval Loss:  0.26868268847465515\n",
      "Eval Loss:  0.3764628767967224\n",
      "Eval Loss:  0.27783459424972534\n",
      "Eval Loss:  0.31717607378959656\n",
      "Eval Loss:  0.2947457730770111\n",
      "Eval Loss:  0.27727919816970825\n",
      "Eval Loss:  0.2619650363922119\n",
      "Eval Loss:  0.28800448775291443\n",
      "Eval Loss:  0.22196178138256073\n",
      "Eval Loss:  0.3112926781177521\n",
      "Eval Loss:  0.31943395733833313\n",
      "Eval Loss:  0.20992319285869598\n",
      "Eval Loss:  0.3021107316017151\n",
      "Eval Loss:  0.2869042754173279\n",
      "Eval Loss:  0.25764837861061096\n",
      "Eval Loss:  0.28885146975517273\n",
      "Eval Loss:  0.3295072913169861\n",
      "Eval Loss:  0.3192993104457855\n",
      "Eval Loss:  0.272096186876297\n",
      "Eval Loss:  0.2584752142429352\n",
      "Eval Loss:  0.3007649779319763\n",
      "Eval Loss:  0.2853398025035858\n",
      "Eval Loss:  0.3006599545478821\n",
      "Eval Loss:  0.35792669653892517\n",
      "Eval Loss:  0.2812441885471344\n",
      "Eval Loss:  0.3252784013748169\n",
      "Eval Loss:  0.3487018942832947\n",
      "Eval Loss:  0.3442313075065613\n",
      "Eval Loss:  0.2974125146865845\n",
      "[[16224   843]\n",
      " [ 2994  9612]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     17067\n",
      "           1       0.92      0.76      0.83     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.86      0.86     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8706905267414822\n",
      "pre:  0.9193687230989956\n",
      "rec:  0.7624940504521657\n",
      "ma F1:  0.8639345091891826\n",
      "mi F1:  0.8706905267414822\n",
      "we F1:  0.8684926752963829\n",
      "29673 464\n",
      "Loss:  0.06009269505739212\n",
      "Loss:  0.08285519480705261\n",
      "Loss:  0.09535367786884308\n",
      "18 **********\n",
      "Epoch:  1087.0863518714905  fold:  5  kers:  64\n",
      "epoch:  19\n",
      "29673 464\n",
      "Loss:  0.09434313327074051\n",
      "Loss:  0.09240169823169708\n",
      "Loss:  0.06719063222408295\n",
      "19 **********\n",
      "Epoch:  1131.2562503814697  fold:  5  kers:  64\n",
      "epoch:  20\n",
      "29673 464\n",
      "Loss:  0.06016652658581734\n",
      "Loss:  0.09255807101726532\n",
      "Loss:  0.06990201026201248\n",
      "20 **********\n",
      "Epoch:  1175.3403782844543  fold:  5  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.06686548888683319\n",
      "Eval Loss:  0.07837947458028793\n",
      "Eval Loss:  0.041648395359516144\n",
      "[[3062   35]\n",
      " [  39   82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.70      0.68      0.69       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.84      0.83      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9770043505282784\n",
      "pre:  0.7008547008547008\n",
      "rec:  0.6776859504132231\n",
      "ma F1:  0.8385681474913296\n",
      "mi F1:  0.9770043505282784\n",
      "we F1:  0.9768185301215174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24194954335689545\n",
      "Eval Loss:  0.4003955125808716\n",
      "Eval Loss:  0.25158655643463135\n",
      "Eval Loss:  0.30205461382865906\n",
      "Eval Loss:  0.3101499676704407\n",
      "Eval Loss:  0.23931309580802917\n",
      "Eval Loss:  0.2561119496822357\n",
      "Eval Loss:  0.2544957995414734\n",
      "Eval Loss:  0.21705099940299988\n",
      "Eval Loss:  0.29615968465805054\n",
      "Eval Loss:  0.29194915294647217\n",
      "Eval Loss:  0.18703186511993408\n",
      "Eval Loss:  0.30307701230049133\n",
      "Eval Loss:  0.2650615870952606\n",
      "Eval Loss:  0.2501607835292816\n",
      "Eval Loss:  0.2576942443847656\n",
      "Eval Loss:  0.33393752574920654\n",
      "Eval Loss:  0.3232649862766266\n",
      "Eval Loss:  0.23836730420589447\n",
      "Eval Loss:  0.2551954686641693\n",
      "Eval Loss:  0.28722888231277466\n",
      "Eval Loss:  0.2689197063446045\n",
      "Eval Loss:  0.23504437506198883\n",
      "Eval Loss:  0.35299572348594666\n",
      "Eval Loss:  0.24388793110847473\n",
      "Eval Loss:  0.3184169828891754\n",
      "Eval Loss:  0.33598560094833374\n",
      "Eval Loss:  0.29483404755592346\n",
      "Eval Loss:  0.2620186507701874\n",
      "[[16144   923]\n",
      " [ 2623  9983]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     17067\n",
      "           1       0.92      0.79      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.87      0.88     29673\n",
      "weighted avg       0.88      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8804974218986957\n",
      "pre:  0.9153676875114616\n",
      "rec:  0.7919244804061558\n",
      "ma F1:  0.8751135486126788\n",
      "mi F1:  0.8804974218986957\n",
      "we F1:  0.8790118538762596\n",
      "29673 464\n",
      "Loss:  0.1013089045882225\n",
      "Loss:  0.07001277059316635\n",
      "Loss:  0.0849342867732048\n",
      "21 **********\n",
      "Epoch:  1258.374362707138  fold:  5  kers:  64\n",
      "epoch:  22\n",
      "29673 464\n",
      "Loss:  0.08183848857879639\n",
      "Loss:  0.07803846150636673\n",
      "Loss:  0.08434804528951645\n",
      "22 **********\n",
      "Epoch:  1302.4943945407867  fold:  5  kers:  64\n",
      "epoch:  23\n",
      "29673 464\n",
      "Loss:  0.08539353311061859\n",
      "Loss:  0.08277249336242676\n",
      "Loss:  0.0612618550658226\n",
      "23 **********\n",
      "Epoch:  1346.6253969669342  fold:  5  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.0691351667046547\n",
      "Eval Loss:  0.07401304692029953\n",
      "Eval Loss:  0.040126558393239975\n",
      "[[3062   35]\n",
      " [  34   87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.71      0.72      0.72       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.85      0.85      0.85      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9785581106277191\n",
      "pre:  0.7131147540983607\n",
      "rec:  0.71900826446281\n",
      "ma F1:  0.8524538856095991\n",
      "mi F1:  0.9785581106277191\n",
      "we F1:  0.9786004986025151\n",
      "Eval Loss:  0.2238309234380722\n",
      "Eval Loss:  0.3446376323699951\n",
      "Eval Loss:  0.24809233844280243\n",
      "Eval Loss:  0.2988573908805847\n",
      "Eval Loss:  0.2813555598258972\n",
      "Eval Loss:  0.24951781332492828\n",
      "Eval Loss:  0.24036581814289093\n",
      "Eval Loss:  0.25123992562294006\n",
      "Eval Loss:  0.22110024094581604\n",
      "Eval Loss:  0.28757813572883606\n",
      "Eval Loss:  0.27474427223205566\n",
      "Eval Loss:  0.18156057596206665\n",
      "Eval Loss:  0.3093577027320862\n",
      "Eval Loss:  0.25905540585517883\n",
      "Eval Loss:  0.2275109887123108\n",
      "Eval Loss:  0.25795772671699524\n",
      "Eval Loss:  0.303532212972641\n",
      "Eval Loss:  0.30070653557777405\n",
      "Eval Loss:  0.24071907997131348\n",
      "Eval Loss:  0.2509317696094513\n",
      "Eval Loss:  0.2655685245990753\n",
      "Eval Loss:  0.25347310304641724\n",
      "Eval Loss:  0.22835612297058105\n",
      "Eval Loss:  0.3527003228664398\n",
      "Eval Loss:  0.25667819380760193\n",
      "Eval Loss:  0.32742297649383545\n",
      "Eval Loss:  0.31692227721214294\n",
      "Eval Loss:  0.2923488914966583\n",
      "Eval Loss:  0.2506497800350189\n",
      "[[16115   952]\n",
      " [ 2517 10089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     17067\n",
      "           1       0.91      0.80      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.87      0.88     29673\n",
      "weighted avg       0.89      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8830923735382334\n",
      "pre:  0.913775926093651\n",
      "rec:  0.8003331746787244\n",
      "ma F1:  0.8780635199022115\n",
      "mi F1:  0.8830923735382334\n",
      "we F1:  0.8817863403586161\n",
      "29673 464\n",
      "Loss:  0.06966263800859451\n",
      "Loss:  0.04859701544046402\n",
      "Loss:  0.0870150774717331\n",
      "24 **********\n",
      "Epoch:  1429.556655883789  fold:  5  kers:  64\n",
      "epoch:  25\n",
      "29673 464\n",
      "Loss:  0.06486447900533676\n",
      "Loss:  0.04174753278493881\n",
      "Loss:  0.0803527981042862\n",
      "25 **********\n",
      "Epoch:  1473.7824053764343  fold:  5  kers:  64\n",
      "epoch:  26\n",
      "29673 464\n",
      "Loss:  0.07288624346256256\n",
      "Loss:  0.07365015149116516\n",
      "Loss:  0.061243023723363876\n",
      "26 **********\n",
      "Epoch:  1518.1009063720703  fold:  5  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.07390419393777847\n",
      "Eval Loss:  0.07297894358634949\n",
      "Eval Loss:  0.03889767825603485\n",
      "[[3048   49]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.64      0.74      0.69       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.82      0.86      0.84      3218\n",
      "weighted avg       0.98      0.97      0.98      3218\n",
      "\n",
      "acc:  0.9748290863890615\n",
      "pre:  0.644927536231884\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.8370727627648462\n",
      "mi F1:  0.9748290863890615\n",
      "we F1:  0.9756205218407721\n",
      "Eval Loss:  0.20257245004177094\n",
      "Eval Loss:  0.3216512203216553\n",
      "Eval Loss:  0.21046145260334015\n",
      "Eval Loss:  0.2690357565879822\n",
      "Eval Loss:  0.27344366908073425\n",
      "Eval Loss:  0.22240892052650452\n",
      "Eval Loss:  0.2392868548631668\n",
      "Eval Loss:  0.23540547490119934\n",
      "Eval Loss:  0.22136738896369934\n",
      "Eval Loss:  0.2324649840593338\n",
      "Eval Loss:  0.2396533489227295\n",
      "Eval Loss:  0.16352541744709015\n",
      "Eval Loss:  0.2504947781562805\n",
      "Eval Loss:  0.2449406236410141\n",
      "Eval Loss:  0.1996922641992569\n",
      "Eval Loss:  0.2457616925239563\n",
      "Eval Loss:  0.2923462986946106\n",
      "Eval Loss:  0.276187002658844\n",
      "Eval Loss:  0.21725261211395264\n",
      "Eval Loss:  0.24288378655910492\n",
      "Eval Loss:  0.2177339643239975\n",
      "Eval Loss:  0.2420298010110855\n",
      "Eval Loss:  0.19633769989013672\n",
      "Eval Loss:  0.3092193305492401\n",
      "Eval Loss:  0.2228976935148239\n",
      "Eval Loss:  0.2763761579990387\n",
      "Eval Loss:  0.28357744216918945\n",
      "Eval Loss:  0.26004666090011597\n",
      "Eval Loss:  0.24461735785007477\n",
      "[[15846  1221]\n",
      " [ 1917 10689]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     17067\n",
      "           1       0.90      0.85      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8942472955211809\n",
      "pre:  0.8974811083123426\n",
      "rec:  0.8479295573536412\n",
      "ma F1:  0.8909536059981711\n",
      "mi F1:  0.8942472955211809\n",
      "we F1:  0.8938027719788084\n",
      "29673 464\n",
      "Loss:  0.06691835820674896\n",
      "Loss:  0.05343945696949959\n",
      "Loss:  0.08919332176446915\n",
      "27 **********\n",
      "Epoch:  1601.115941286087  fold:  5  kers:  64\n",
      "epoch:  28\n",
      "29673 464\n",
      "Loss:  0.05299587920308113\n",
      "Loss:  0.0794014260172844\n",
      "Loss:  0.09939359873533249\n",
      "28 **********\n",
      "Epoch:  1645.3586449623108  fold:  5  kers:  64\n",
      "epoch:  29\n",
      "29673 464\n",
      "Loss:  0.0753927156329155\n",
      "Loss:  0.05136152356863022\n",
      "Loss:  0.0956934243440628\n",
      "29 **********\n",
      "Epoch:  1689.592372894287  fold:  5  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.06360022723674774\n",
      "Eval Loss:  0.05058698728680611\n",
      "Eval Loss:  0.03941071778535843\n",
      "[[3071   26]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.77      0.73      0.75       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.86      0.87      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9816656308266004\n",
      "pre:  0.7719298245614035\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.8697107878962556\n",
      "mi F1:  0.9816656308266004\n",
      "we F1:  0.9814029141318258\n",
      "update!  Acc:  0.9816656308266004\n",
      "Eval Loss:  0.2037733644247055\n",
      "Eval Loss:  0.34453684091567993\n",
      "Eval Loss:  0.24809430539608002\n",
      "Eval Loss:  0.2694454491138458\n",
      "Eval Loss:  0.29126155376434326\n",
      "Eval Loss:  0.25029826164245605\n",
      "Eval Loss:  0.25730040669441223\n",
      "Eval Loss:  0.2360086441040039\n",
      "Eval Loss:  0.2370540201663971\n",
      "Eval Loss:  0.2811024487018585\n",
      "Eval Loss:  0.2651231586933136\n",
      "Eval Loss:  0.1729220747947693\n",
      "Eval Loss:  0.30174973607063293\n",
      "Eval Loss:  0.2589939534664154\n",
      "Eval Loss:  0.21537905931472778\n",
      "Eval Loss:  0.237363800406456\n",
      "Eval Loss:  0.2831494212150574\n",
      "Eval Loss:  0.30638059973716736\n",
      "Eval Loss:  0.20694230496883392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.27157723903656006\n",
      "Eval Loss:  0.2891134023666382\n",
      "Eval Loss:  0.2641669809818268\n",
      "Eval Loss:  0.2224135398864746\n",
      "Eval Loss:  0.33679935336112976\n",
      "Eval Loss:  0.27122005820274353\n",
      "Eval Loss:  0.33217093348503113\n",
      "Eval Loss:  0.30111056566238403\n",
      "Eval Loss:  0.26287174224853516\n",
      "Eval Loss:  0.24799847602844238\n",
      "[[16108   959]\n",
      " [ 2474 10132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     17067\n",
      "           1       0.91      0.80      0.86     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.87      0.88     29673\n",
      "weighted avg       0.89      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8843055976813938\n",
      "pre:  0.9135334956270851\n",
      "rec:  0.8037442487704268\n",
      "ma F1:  0.879414652400083\n",
      "mi F1:  0.8843055976813938\n",
      "we F1:  0.8830656743043548\n",
      "29673 464\n",
      "Loss:  0.07062843441963196\n",
      "Loss:  0.06279628723859787\n",
      "Loss:  0.0715327337384224\n",
      "30 **********\n",
      "Epoch:  1772.4059462547302  fold:  5  kers:  64\n",
      "epoch:  31\n",
      "29673 464\n",
      "Loss:  0.10277774184942245\n",
      "Loss:  0.07150276005268097\n",
      "Loss:  0.07782412320375443\n",
      "31 **********\n",
      "Epoch:  1816.8281707763672  fold:  5  kers:  64\n",
      "epoch:  32\n",
      "29673 464\n",
      "Loss:  0.04371698945760727\n",
      "Loss:  0.08739803731441498\n",
      "Loss:  0.0879807248711586\n",
      "32 **********\n",
      "Epoch:  1861.0030562877655  fold:  5  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.08253839612007141\n",
      "Eval Loss:  0.11092683672904968\n",
      "Eval Loss:  0.05537792667746544\n",
      "[[3034   63]\n",
      " [  22   99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.61      0.82      0.70       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.80      0.90      0.84      3218\n",
      "weighted avg       0.98      0.97      0.98      3218\n",
      "\n",
      "acc:  0.973586078309509\n",
      "pre:  0.6111111111111112\n",
      "rec:  0.8181818181818182\n",
      "ma F1:  0.8429161218148062\n",
      "mi F1:  0.973586078309509\n",
      "we F1:  0.9754114507852443\n",
      "Eval Loss:  0.1945156306028366\n",
      "Eval Loss:  0.3286679685115814\n",
      "Eval Loss:  0.28016558289527893\n",
      "Eval Loss:  0.2832396924495697\n",
      "Eval Loss:  0.2582972049713135\n",
      "Eval Loss:  0.21640631556510925\n",
      "Eval Loss:  0.2699224054813385\n",
      "Eval Loss:  0.2206352800130844\n",
      "Eval Loss:  0.26255184412002563\n",
      "Eval Loss:  0.27226370573043823\n",
      "Eval Loss:  0.206820547580719\n",
      "Eval Loss:  0.17549161612987518\n",
      "Eval Loss:  0.2737600803375244\n",
      "Eval Loss:  0.24144163727760315\n",
      "Eval Loss:  0.23184996843338013\n",
      "Eval Loss:  0.25389331579208374\n",
      "Eval Loss:  0.26341861486434937\n",
      "Eval Loss:  0.3159092664718628\n",
      "Eval Loss:  0.24970422685146332\n",
      "Eval Loss:  0.29004374146461487\n",
      "Eval Loss:  0.2369118332862854\n",
      "Eval Loss:  0.2738398015499115\n",
      "Eval Loss:  0.18302059173583984\n",
      "Eval Loss:  0.3247741162776947\n",
      "Eval Loss:  0.27499040961265564\n",
      "Eval Loss:  0.31939107179641724\n",
      "Eval Loss:  0.28342920541763306\n",
      "Eval Loss:  0.24849002063274384\n",
      "Eval Loss:  0.30371132493019104\n",
      "[[15274  1793]\n",
      " [ 1527 11079]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     17067\n",
      "           1       0.86      0.88      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.88      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8881137734640919\n",
      "pre:  0.8607054070851461\n",
      "rec:  0.8788672060923369\n",
      "ma F1:  0.8858319309202753\n",
      "mi F1:  0.8881137734640919\n",
      "we F1:  0.8882584624072757\n",
      "29673 464\n",
      "Loss:  0.056494034826755524\n",
      "Loss:  0.11306525021791458\n",
      "Loss:  0.061433494091033936\n",
      "33 **********\n",
      "Epoch:  1943.8585171699524  fold:  5  kers:  64\n",
      "epoch:  34\n",
      "29673 464\n",
      "Loss:  0.05628303810954094\n",
      "Loss:  0.09091831743717194\n",
      "Loss:  0.08734124153852463\n",
      "34 **********\n",
      "Epoch:  1988.024426460266  fold:  5  kers:  64\n",
      "epoch:  35\n",
      "29673 464\n",
      "Loss:  0.06465370208024979\n",
      "Loss:  0.06580144166946411\n",
      "Loss:  0.08144359290599823\n",
      "35 **********\n",
      "Epoch:  2032.1464531421661  fold:  5  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.061012767255306244\n",
      "Eval Loss:  0.05290040746331215\n",
      "Eval Loss:  0.035831380635499954\n",
      "[[3063   34]\n",
      " [  49   72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.68      0.60      0.63       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.83      0.79      0.81      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9742075823492853\n",
      "pre:  0.6792452830188679\n",
      "rec:  0.5950413223140496\n",
      "ma F1:  0.8104967707101316\n",
      "mi F1:  0.9742075823492853\n",
      "we F1:  0.9733865652397611\n",
      "Eval Loss:  0.2259671986103058\n",
      "Eval Loss:  0.3127845823764801\n",
      "Eval Loss:  0.2220199853181839\n",
      "Eval Loss:  0.22384920716285706\n",
      "Eval Loss:  0.28000906109809875\n",
      "Eval Loss:  0.24534910917282104\n",
      "Eval Loss:  0.25643303990364075\n",
      "Eval Loss:  0.2529987692832947\n",
      "Eval Loss:  0.2096114605665207\n",
      "Eval Loss:  0.2100965827703476\n",
      "Eval Loss:  0.253888338804245\n",
      "Eval Loss:  0.2022121101617813\n",
      "Eval Loss:  0.24169465899467468\n",
      "Eval Loss:  0.2624590992927551\n",
      "Eval Loss:  0.18087749183177948\n",
      "Eval Loss:  0.2230553925037384\n",
      "Eval Loss:  0.2867719829082489\n",
      "Eval Loss:  0.2864201068878174\n",
      "Eval Loss:  0.20371600985527039\n",
      "Eval Loss:  0.2464916855096817\n",
      "Eval Loss:  0.25424909591674805\n",
      "Eval Loss:  0.22612349689006805\n",
      "Eval Loss:  0.23205381631851196\n",
      "Eval Loss:  0.3141724467277527\n",
      "Eval Loss:  0.2462424337863922\n",
      "Eval Loss:  0.2950116693973541\n",
      "Eval Loss:  0.24552412331104279\n",
      "Eval Loss:  0.3059947192668915\n",
      "Eval Loss:  0.24592633545398712\n",
      "[[16292   775]\n",
      " [ 2449 10157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17067\n",
      "           1       0.93      0.81      0.86     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.88      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8913490378458532\n",
      "pre:  0.9291072081961215\n",
      "rec:  0.8057274313818816\n",
      "ma F1:  0.8864971239251025\n",
      "mi F1:  0.8913490378458532\n",
      "we F1:  0.8900251415290908\n",
      "29673 464\n",
      "Loss:  0.08038032054901123\n",
      "Loss:  0.09837792068719864\n",
      "Loss:  0.06225276738405228\n",
      "36 **********\n",
      "Epoch:  2115.1056373119354  fold:  5  kers:  64\n",
      "epoch:  37\n",
      "29673 464\n",
      "Loss:  0.06815162301063538\n",
      "Loss:  0.07040594518184662\n",
      "Loss:  0.0500212162733078\n",
      "37 **********\n",
      "Epoch:  2159.243621110916  fold:  5  kers:  64\n",
      "epoch:  38\n",
      "29673 464\n",
      "Loss:  0.08037082850933075\n",
      "Loss:  0.0767747014760971\n",
      "Loss:  0.04302208125591278\n",
      "38 **********\n",
      "Epoch:  2203.3097970485687  fold:  5  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.06258415430784225\n",
      "Eval Loss:  0.03190388157963753\n",
      "Eval Loss:  0.02000836841762066\n",
      "[[3075   22]\n",
      " [  31   90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.80      0.74      0.77       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.90      0.87      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9835301429459291\n",
      "pre:  0.8035714285714286\n",
      "rec:  0.743801652892562\n",
      "ma F1:  0.8819939680301445\n",
      "mi F1:  0.9835301429459291\n",
      "we F1:  0.9832240037250775\n",
      "update!  Acc:  0.9835301429459291\n",
      "Eval Loss:  0.19779880344867706\n",
      "Eval Loss:  0.3502538204193115\n",
      "Eval Loss:  0.28734952211380005\n",
      "Eval Loss:  0.3048762381076813\n",
      "Eval Loss:  0.2938312590122223\n",
      "Eval Loss:  0.28137609362602234\n",
      "Eval Loss:  0.26013943552970886\n",
      "Eval Loss:  0.26139575242996216\n",
      "Eval Loss:  0.24615271389484406\n",
      "Eval Loss:  0.2865948975086212\n",
      "Eval Loss:  0.30262479186058044\n",
      "Eval Loss:  0.17812925577163696\n",
      "Eval Loss:  0.31223684549331665\n",
      "Eval Loss:  0.26923665404319763\n",
      "Eval Loss:  0.22955548763275146\n",
      "Eval Loss:  0.27442073822021484\n",
      "Eval Loss:  0.2896687686443329\n",
      "Eval Loss:  0.32973843812942505\n",
      "Eval Loss:  0.22129403054714203\n",
      "Eval Loss:  0.28742584586143494\n",
      "Eval Loss:  0.2996264100074768\n",
      "Eval Loss:  0.2818984091281891\n",
      "Eval Loss:  0.2229640632867813\n",
      "Eval Loss:  0.37667879462242126\n",
      "Eval Loss:  0.27445635199546814\n",
      "Eval Loss:  0.359443724155426\n",
      "Eval Loss:  0.2646152973175049\n",
      "Eval Loss:  0.3085904121398926\n",
      "Eval Loss:  0.26773664355278015\n",
      "[[16238   829]\n",
      " [ 2794  9812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     17067\n",
      "           1       0.92      0.78      0.84     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.86      0.87     29673\n",
      "weighted avg       0.88      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8779024702591581\n",
      "pre:  0.9220937881778029\n",
      "rec:  0.7783595113438045\n",
      "ma F1:  0.8718945213220104\n",
      "mi F1:  0.8779024702591581\n",
      "we F1:  0.8760653056682003\n",
      "29673 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07354282587766647\n",
      "Loss:  0.04447600618004799\n",
      "Loss:  0.05996239557862282\n",
      "39 **********\n",
      "Epoch:  2286.0904586315155  fold:  5  kers:  64\n",
      "epoch:  40\n",
      "29673 464\n",
      "Loss:  0.05806427821516991\n",
      "Loss:  0.07855504006147385\n",
      "Loss:  0.04286777228116989\n",
      "40 **********\n",
      "Epoch:  2330.2194669246674  fold:  5  kers:  64\n",
      "epoch:  41\n",
      "29673 464\n",
      "Loss:  0.07698094844818115\n",
      "Loss:  0.0695393979549408\n",
      "Loss:  0.08803999423980713\n",
      "41 **********\n",
      "Epoch:  2374.467157125473  fold:  5  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.06634119153022766\n",
      "Eval Loss:  0.04175695776939392\n",
      "Eval Loss:  0.033291351050138474\n",
      "[[3072   25]\n",
      " [  24   97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.80      0.80      0.80       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.89      0.90      0.90      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9847731510254817\n",
      "pre:  0.7950819672131147\n",
      "rec:  0.8016528925619835\n",
      "ma F1:  0.895220875287976\n",
      "mi F1:  0.9847731510254817\n",
      "we F1:  0.9848032526307715\n",
      "update!  Acc:  0.9847731510254817\n",
      "Eval Loss:  0.17183750867843628\n",
      "Eval Loss:  0.29097819328308105\n",
      "Eval Loss:  0.26314449310302734\n",
      "Eval Loss:  0.2549017071723938\n",
      "Eval Loss:  0.24166159331798553\n",
      "Eval Loss:  0.23092208802700043\n",
      "Eval Loss:  0.24453218281269073\n",
      "Eval Loss:  0.22443747520446777\n",
      "Eval Loss:  0.20318923890590668\n",
      "Eval Loss:  0.2502366900444031\n",
      "Eval Loss:  0.22859889268875122\n",
      "Eval Loss:  0.1774027943611145\n",
      "Eval Loss:  0.2760234773159027\n",
      "Eval Loss:  0.22502633929252625\n",
      "Eval Loss:  0.1969245970249176\n",
      "Eval Loss:  0.2289573848247528\n",
      "Eval Loss:  0.22679166495800018\n",
      "Eval Loss:  0.29875147342681885\n",
      "Eval Loss:  0.21819594502449036\n",
      "Eval Loss:  0.2519973814487457\n",
      "Eval Loss:  0.2500247657299042\n",
      "Eval Loss:  0.23721760511398315\n",
      "Eval Loss:  0.2059394270181656\n",
      "Eval Loss:  0.3134397864341736\n",
      "Eval Loss:  0.254210889339447\n",
      "Eval Loss:  0.3237096071243286\n",
      "Eval Loss:  0.22438107430934906\n",
      "Eval Loss:  0.26806774735450745\n",
      "Eval Loss:  0.23853476345539093\n",
      "[[16047  1020]\n",
      " [ 2150 10456]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     17067\n",
      "           1       0.91      0.83      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.88      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8931688740605938\n",
      "pre:  0.9111188567445103\n",
      "rec:  0.8294462954148818\n",
      "ma F1:  0.8892365195345124\n",
      "mi F1:  0.8931688740605938\n",
      "we F1:  0.8923741037843513\n",
      "29673 464\n",
      "Loss:  0.06089198589324951\n",
      "Loss:  0.08634022623300552\n",
      "Loss:  0.06143280863761902\n",
      "42 **********\n",
      "Epoch:  2457.112181186676  fold:  5  kers:  64\n",
      "epoch:  43\n",
      "29673 464\n",
      "Loss:  0.08591555058956146\n",
      "Loss:  0.07387879490852356\n",
      "Loss:  0.06466876715421677\n",
      "43 **********\n",
      "Epoch:  2501.176362991333  fold:  5  kers:  64\n",
      "epoch:  44\n",
      "29673 464\n",
      "Loss:  0.07468299567699432\n",
      "Loss:  0.05630524083971977\n",
      "Loss:  0.07343249768018723\n",
      "44 **********\n",
      "Epoch:  2550.38977599144  fold:  5  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.06185777485370636\n",
      "Eval Loss:  0.04120240733027458\n",
      "Eval Loss:  0.03249133378267288\n",
      "[[3069   28]\n",
      " [  23   98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.78      0.81      0.79       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.89      0.90      0.89      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9841516469857055\n",
      "pre:  0.7777777777777778\n",
      "rec:  0.8099173553719008\n",
      "ma F1:  0.8926409203216101\n",
      "mi F1:  0.9841516469857055\n",
      "we F1:  0.984305653594026\n",
      "Eval Loss:  0.16653257608413696\n",
      "Eval Loss:  0.3106229603290558\n",
      "Eval Loss:  0.256579726934433\n",
      "Eval Loss:  0.24781741201877594\n",
      "Eval Loss:  0.24120129644870758\n",
      "Eval Loss:  0.2379794418811798\n",
      "Eval Loss:  0.23304733633995056\n",
      "Eval Loss:  0.20896898210048676\n",
      "Eval Loss:  0.22859053313732147\n",
      "Eval Loss:  0.24321173131465912\n",
      "Eval Loss:  0.2123311161994934\n",
      "Eval Loss:  0.1691047102212906\n",
      "Eval Loss:  0.26379474997520447\n",
      "Eval Loss:  0.2521972358226776\n",
      "Eval Loss:  0.18513397872447968\n",
      "Eval Loss:  0.21703161299228668\n",
      "Eval Loss:  0.24348093569278717\n",
      "Eval Loss:  0.2989352345466614\n",
      "Eval Loss:  0.2153029888868332\n",
      "Eval Loss:  0.26594388484954834\n",
      "Eval Loss:  0.2614281475543976\n",
      "Eval Loss:  0.24409110844135284\n",
      "Eval Loss:  0.18645840883255005\n",
      "Eval Loss:  0.30381253361701965\n",
      "Eval Loss:  0.25467365980148315\n",
      "Eval Loss:  0.313894659280777\n",
      "Eval Loss:  0.2378261387348175\n",
      "Eval Loss:  0.2700243592262268\n",
      "Eval Loss:  0.2522348165512085\n",
      "[[16088   979]\n",
      " [ 2247 10359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     17067\n",
      "           1       0.91      0.82      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.88      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8912816365045665\n",
      "pre:  0.9136532016228611\n",
      "rec:  0.8217515468824369\n",
      "ma F1:  0.8870720828497384\n",
      "mi F1:  0.8912816365045665\n",
      "we F1:  0.8903499356781879\n",
      "29673 464\n",
      "Loss:  0.04741393029689789\n",
      "Loss:  0.06920316070318222\n",
      "Loss:  0.07900717854499817\n",
      "45 **********\n",
      "Epoch:  2633.0537490844727  fold:  5  kers:  64\n",
      "epoch:  46\n",
      "29673 464\n",
      "Loss:  0.05097595229744911\n",
      "Loss:  0.08823348581790924\n",
      "Loss:  0.0452582910656929\n",
      "46 **********\n",
      "Epoch:  2677.303434610367  fold:  5  kers:  64\n",
      "epoch:  47\n",
      "29673 464\n",
      "Loss:  0.050561726093292236\n",
      "Loss:  0.06670092791318893\n",
      "Loss:  0.06719661504030228\n",
      "47 **********\n",
      "Epoch:  2724.667792081833  fold:  5  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.06049889326095581\n",
      "Eval Loss:  0.05352550372481346\n",
      "Eval Loss:  0.04266266152262688\n",
      "[[3062   35]\n",
      " [  25   96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.73      0.79      0.76       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.89      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9813548788067122\n",
      "pre:  0.732824427480916\n",
      "rec:  0.7933884297520661\n",
      "ma F1:  0.8761011519743733\n",
      "mi F1:  0.9813548788067122\n",
      "we F1:  0.9817097463954929\n",
      "Eval Loss:  0.147734597325325\n",
      "Eval Loss:  0.3032681941986084\n",
      "Eval Loss:  0.2108227014541626\n",
      "Eval Loss:  0.23499950766563416\n",
      "Eval Loss:  0.24580737948417664\n",
      "Eval Loss:  0.20874449610710144\n",
      "Eval Loss:  0.22216929495334625\n",
      "Eval Loss:  0.19690018892288208\n",
      "Eval Loss:  0.21993952989578247\n",
      "Eval Loss:  0.23153790831565857\n",
      "Eval Loss:  0.1745540350675583\n",
      "Eval Loss:  0.15820610523223877\n",
      "Eval Loss:  0.2106899917125702\n",
      "Eval Loss:  0.21944347023963928\n",
      "Eval Loss:  0.17593681812286377\n",
      "Eval Loss:  0.21089383959770203\n",
      "Eval Loss:  0.2383747100830078\n",
      "Eval Loss:  0.2670820653438568\n",
      "Eval Loss:  0.1962362825870514\n",
      "Eval Loss:  0.24243924021720886\n",
      "Eval Loss:  0.21442411839962006\n",
      "Eval Loss:  0.22483867406845093\n",
      "Eval Loss:  0.1583082526922226\n",
      "Eval Loss:  0.2696596682071686\n",
      "Eval Loss:  0.20734064280986786\n",
      "Eval Loss:  0.28241869807243347\n",
      "Eval Loss:  0.19539588689804077\n",
      "Eval Loss:  0.2169216275215149\n",
      "Eval Loss:  0.23391924798488617\n",
      "[[15856  1211]\n",
      " [ 1693 10913]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     17067\n",
      "           1       0.90      0.87      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.90      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9021332524517238\n",
      "pre:  0.9001154734411085\n",
      "rec:  0.8656988735522767\n",
      "ma F1:  0.8993399666245228\n",
      "mi F1:  0.9021332524517238\n",
      "we F1:  0.901860874590362\n",
      "29673 464\n",
      "Loss:  0.07712613791227341\n",
      "Loss:  0.04567796736955643\n",
      "Loss:  0.07462234795093536\n",
      "48 **********\n",
      "Epoch:  2807.6618835926056  fold:  5  kers:  64\n",
      "epoch:  49\n",
      "29673 464\n",
      "Loss:  0.053990237414836884\n",
      "Loss:  0.04699325188994408\n",
      "Loss:  0.06675803661346436\n",
      "49 **********\n",
      "Epoch:  2851.7809171676636  fold:  5  kers:  64\n",
      "epoch:  50\n",
      "29673 464\n",
      "Loss:  0.03108043037354946\n",
      "Loss:  0.04570944979786873\n",
      "Loss:  0.07708881795406342\n",
      "50 **********\n",
      "Epoch:  2895.805205345154  fold:  5  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.05440777912735939\n",
      "Eval Loss:  0.026855051517486572\n",
      "Eval Loss:  0.02000342682003975\n",
      "[[3079   18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.83      0.74      0.78       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.91      0.86      0.89      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9844623990055935\n",
      "pre:  0.8317757009345794\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.8863238153373123\n",
      "mi F1:  0.9844623990055935\n",
      "we F1:  0.9840028872425982\n",
      "Eval Loss:  0.16859538853168488\n",
      "Eval Loss:  0.3208196461200714\n",
      "Eval Loss:  0.23820525407791138\n",
      "Eval Loss:  0.2277810126543045\n",
      "Eval Loss:  0.2580246925354004\n",
      "Eval Loss:  0.23890002071857452\n",
      "Eval Loss:  0.2214640974998474\n",
      "Eval Loss:  0.2241542786359787\n",
      "Eval Loss:  0.2205570936203003\n",
      "Eval Loss:  0.23286172747612\n",
      "Eval Loss:  0.22751855850219727\n",
      "Eval Loss:  0.1749367117881775\n",
      "Eval Loss:  0.2500179708003998\n",
      "Eval Loss:  0.24451959133148193\n",
      "Eval Loss:  0.17909584939479828\n",
      "Eval Loss:  0.20161695778369904\n",
      "Eval Loss:  0.2266346961259842\n",
      "Eval Loss:  0.27281516790390015\n",
      "Eval Loss:  0.19264176487922668\n",
      "Eval Loss:  0.22564707696437836\n",
      "Eval Loss:  0.2850559949874878\n",
      "Eval Loss:  0.21658392250537872\n",
      "Eval Loss:  0.19415424764156342\n",
      "Eval Loss:  0.2898204028606415\n",
      "Eval Loss:  0.23684141039848328\n",
      "Eval Loss:  0.28629541397094727\n",
      "Eval Loss:  0.20958396792411804\n",
      "Eval Loss:  0.2647012770175934\n",
      "Eval Loss:  0.22969618439674377\n",
      "[[16283   784]\n",
      " [ 2322 10284]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     17067\n",
      "           1       0.93      0.82      0.87     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.88      0.89     29673\n",
      "weighted avg       0.90      0.90      0.89     29673\n",
      "\n",
      "acc:  0.8953257169817679\n",
      "pre:  0.9291651608239971\n",
      "rec:  0.8158019990480724\n",
      "ma F1:  0.8908650621756622\n",
      "mi F1:  0.8953257169817679\n",
      "we F1:  0.8941821118656168\n",
      "29673 464\n",
      "Loss:  0.053334806114435196\n",
      "Loss:  0.05614173784852028\n",
      "Loss:  0.05024639517068863\n",
      "51 **********\n",
      "Epoch:  2978.6127943992615  fold:  5  kers:  64\n",
      "epoch:  52\n",
      "29673 464\n",
      "Loss:  0.07953671365976334\n",
      "Loss:  0.07165563106536865\n",
      "Loss:  0.0704362615942955\n",
      "52 **********\n",
      "Epoch:  3022.776709318161  fold:  5  kers:  64\n",
      "epoch:  53\n",
      "29673 464\n",
      "Loss:  0.04064178094267845\n",
      "Loss:  0.07636156678199768\n",
      "Loss:  0.07441335916519165\n",
      "53 **********\n",
      "Epoch:  3066.953588962555  fold:  5  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.060588449239730835\n",
      "Eval Loss:  0.04765165224671364\n",
      "Eval Loss:  0.037727173417806625\n",
      "[[3066   31]\n",
      " [  18  103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.77      0.85      0.81       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.92      0.90      3218\n",
      "weighted avg       0.99      0.98      0.99      3218\n",
      "\n",
      "acc:  0.9847731510254817\n",
      "pre:  0.7686567164179104\n",
      "rec:  0.8512396694214877\n",
      "ma F1:  0.8999578087180513\n",
      "mi F1:  0.9847731510254817\n",
      "we F1:  0.9851452736883224\n",
      "Eval Loss:  0.15648049116134644\n",
      "Eval Loss:  0.2767709493637085\n",
      "Eval Loss:  0.23743203282356262\n",
      "Eval Loss:  0.2402665615081787\n",
      "Eval Loss:  0.22954995930194855\n",
      "Eval Loss:  0.22395867109298706\n",
      "Eval Loss:  0.21783149242401123\n",
      "Eval Loss:  0.21317876875400543\n",
      "Eval Loss:  0.20819522440433502\n",
      "Eval Loss:  0.22624997794628143\n",
      "Eval Loss:  0.1808864176273346\n",
      "Eval Loss:  0.15877525508403778\n",
      "Eval Loss:  0.21697776019573212\n",
      "Eval Loss:  0.21680980920791626\n",
      "Eval Loss:  0.18635903298854828\n",
      "Eval Loss:  0.2155657261610031\n",
      "Eval Loss:  0.23203974962234497\n",
      "Eval Loss:  0.26466405391693115\n",
      "Eval Loss:  0.22020074725151062\n",
      "Eval Loss:  0.23273730278015137\n",
      "Eval Loss:  0.21341091394424438\n",
      "Eval Loss:  0.22127965092658997\n",
      "Eval Loss:  0.1719338446855545\n",
      "Eval Loss:  0.2713139057159424\n",
      "Eval Loss:  0.223302960395813\n",
      "Eval Loss:  0.28636425733566284\n",
      "Eval Loss:  0.2120378464460373\n",
      "Eval Loss:  0.20641936361789703\n",
      "Eval Loss:  0.22912397980690002\n",
      "[[15749  1318]\n",
      " [ 1604 11002]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     17067\n",
      "           1       0.89      0.87      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.90      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9015266403801435\n",
      "pre:  0.8930194805194805\n",
      "rec:  0.872759003649056\n",
      "ma F1:  0.8989402518730283\n",
      "mi F1:  0.9015266403801435\n",
      "we F1:  0.9013708141503068\n",
      "29673 464\n",
      "Loss:  0.042179256677627563\n",
      "Loss:  0.0652146190404892\n",
      "Loss:  0.052995018661022186\n",
      "54 **********\n",
      "Epoch:  3149.5746777057648  fold:  5  kers:  64\n",
      "epoch:  55\n",
      "29673 464\n",
      "Loss:  0.04236570745706558\n",
      "Loss:  0.09873314201831818\n",
      "Loss:  0.060836195945739746\n",
      "55 **********\n",
      "Epoch:  3193.6318774223328  fold:  5  kers:  64\n",
      "epoch:  56\n",
      "29673 464\n",
      "Loss:  0.06040464714169502\n",
      "Loss:  0.03555138409137726\n",
      "Loss:  0.03810853138566017\n",
      "56 **********\n",
      "Epoch:  3237.781829357147  fold:  5  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.06446433812379837\n",
      "Eval Loss:  0.0552109070122242\n",
      "Eval Loss:  0.03490719944238663\n",
      "[[3067   30]\n",
      " [  21  100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.77      0.83      0.80       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.91      0.89      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9841516469857055\n",
      "pre:  0.7692307692307693\n",
      "rec:  0.8264462809917356\n",
      "ma F1:  0.8942834965715151\n",
      "mi F1:  0.9841516469857055\n",
      "we F1:  0.9844242500708849\n",
      "Eval Loss:  0.14018888771533966\n",
      "Eval Loss:  0.3013332784175873\n",
      "Eval Loss:  0.2527196705341339\n",
      "Eval Loss:  0.24220500886440277\n",
      "Eval Loss:  0.2427169382572174\n",
      "Eval Loss:  0.22089152038097382\n",
      "Eval Loss:  0.22659102082252502\n",
      "Eval Loss:  0.20462389290332794\n",
      "Eval Loss:  0.22533316910266876\n",
      "Eval Loss:  0.27109575271606445\n",
      "Eval Loss:  0.17678146064281464\n",
      "Eval Loss:  0.16485905647277832\n",
      "Eval Loss:  0.24336722493171692\n",
      "Eval Loss:  0.24047590792179108\n",
      "Eval Loss:  0.18707890808582306\n",
      "Eval Loss:  0.19762393832206726\n",
      "Eval Loss:  0.22838333249092102\n",
      "Eval Loss:  0.27979278564453125\n",
      "Eval Loss:  0.21251828968524933\n",
      "Eval Loss:  0.2463679313659668\n",
      "Eval Loss:  0.23264490067958832\n",
      "Eval Loss:  0.245012104511261\n",
      "Eval Loss:  0.17690809071063995\n",
      "Eval Loss:  0.28027811646461487\n",
      "Eval Loss:  0.22920414805412292\n",
      "Eval Loss:  0.2842300236225128\n",
      "Eval Loss:  0.19639912247657776\n",
      "Eval Loss:  0.19411282241344452\n",
      "Eval Loss:  0.24941296875476837\n",
      "[[15780  1287]\n",
      " [ 1719 10887]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17067\n",
      "           1       0.89      0.86      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.8986957840461025\n",
      "pre:  0.8942828979793002\n",
      "rec:  0.8636363636363636\n",
      "ma F1:  0.8958642126043325\n",
      "mi F1:  0.8986957840461025\n",
      "we F1:  0.898445786322243\n",
      "29673 464\n",
      "Loss:  0.053247515112161636\n",
      "Loss:  0.04235999286174774\n",
      "Loss:  0.07600168883800507\n",
      "57 **********\n",
      "Epoch:  3320.3091678619385  fold:  5  kers:  64\n",
      "epoch:  58\n",
      "29673 464\n",
      "Loss:  0.04615098237991333\n",
      "Loss:  0.07226946949958801\n",
      "Loss:  0.07642531394958496\n",
      "58 **********\n",
      "Epoch:  3364.440170764923  fold:  5  kers:  64\n",
      "epoch:  59\n",
      "29673 464\n",
      "Loss:  0.05419649928808212\n",
      "Loss:  0.07925167679786682\n",
      "Loss:  0.08504758775234222\n",
      "59 **********\n",
      "Epoch:  3408.485402584076  fold:  5  kers:  64\n",
      "Eval Loss:  0.05512841045856476\n",
      "Eval Loss:  0.0313245952129364\n",
      "Eval Loss:  0.03344395384192467\n",
      "[[3074   23]\n",
      " [  26   95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.81      0.79      0.79       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.90      0.89      0.89      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9847731510254817\n",
      "pre:  0.8050847457627118\n",
      "rec:  0.7851239669421488\n",
      "ma F1:  0.8935360138493252\n",
      "mi F1:  0.9847731510254817\n",
      "we F1:  0.9846812707262108\n",
      "update!  Acc:  0.9847731510254817\n",
      "Epoch:  3412.2493386268616  fold:  5  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29479 3412\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29479 461\n",
      "Loss:  0.16218788921833038\n",
      "Loss:  0.16561228036880493\n",
      "Loss:  0.1693512350320816\n",
      "0 **********\n",
      "Epoch:  56.21668744087219  fold:  6  kers:  64\n",
      "epoch:  1\n",
      "29479 461\n",
      "Loss:  0.15241201221942902\n",
      "Loss:  0.14492011070251465\n",
      "Loss:  0.12130666524171829\n",
      "1 **********\n",
      "Epoch:  100.33472490310669  fold:  6  kers:  64\n",
      "epoch:  2\n",
      "29479 461\n",
      "Loss:  0.13046830892562866\n",
      "Loss:  0.09905118495225906\n",
      "Loss:  0.11520390957593918\n",
      "2 **********\n",
      "Epoch:  144.43580770492554  fold:  6  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.1267150342464447\n",
      "Eval Loss:  0.2947532534599304\n",
      "Eval Loss:  0.5765506625175476\n",
      "[[1848  384]\n",
      " [ 111 1069]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88      2232\n",
      "           1       0.74      0.91      0.81      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.84      0.87      0.85      3412\n",
      "weighted avg       0.87      0.85      0.86      3412\n",
      "\n",
      "acc:  0.8549237983587339\n",
      "pre:  0.735719201651755\n",
      "rec:  0.9059322033898305\n",
      "ma F1:  0.8469456414795853\n",
      "mi F1:  0.8549237983587339\n",
      "we F1:  0.8577197378041864\n",
      "update!  Acc:  0.8549237983587339\n",
      "Eval Loss:  0.3763364851474762\n",
      "Eval Loss:  0.3670770227909088\n",
      "Eval Loss:  0.39620041847229004\n",
      "Eval Loss:  0.3801296651363373\n",
      "Eval Loss:  0.37969353795051575\n",
      "Eval Loss:  0.41661974787712097\n",
      "Eval Loss:  0.4654240012168884\n",
      "Eval Loss:  0.3481326103210449\n",
      "Eval Loss:  0.5015045404434204\n",
      "Eval Loss:  0.4709647595882416\n",
      "Eval Loss:  0.38056236505508423\n",
      "Eval Loss:  0.46591320633888245\n",
      "Eval Loss:  0.41930535435676575\n",
      "Eval Loss:  0.4506703317165375\n",
      "Eval Loss:  0.4010656774044037\n",
      "Eval Loss:  0.35045960545539856\n",
      "Eval Loss:  0.44586172699928284\n",
      "Eval Loss:  0.44343289732933044\n",
      "Eval Loss:  0.3893715739250183\n",
      "Eval Loss:  0.36107441782951355\n",
      "Eval Loss:  0.35331404209136963\n",
      "Eval Loss:  0.36525630950927734\n",
      "Eval Loss:  0.3965379595756531\n",
      "Eval Loss:  0.37317395210266113\n",
      "Eval Loss:  0.3486746549606323\n",
      "Eval Loss:  0.39322808384895325\n",
      "Eval Loss:  0.3660745322704315\n",
      "Eval Loss:  0.36948221921920776\n",
      "[[15746  2186]\n",
      " [ 3216  8331]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85     17932\n",
      "           1       0.79      0.72      0.76     11547\n",
      "\n",
      "    accuracy                           0.82     29479\n",
      "   macro avg       0.81      0.80      0.80     29479\n",
      "weighted avg       0.82      0.82      0.82     29479\n",
      "\n",
      "acc:  0.8167509074256251\n",
      "pre:  0.7921460492535894\n",
      "rec:  0.7214861002857885\n",
      "ma F1:  0.8043736577631633\n",
      "mi F1:  0.8167509074256251\n",
      "we F1:  0.8150316131367059\n",
      "29479 461\n",
      "Loss:  0.13023312389850616\n",
      "Loss:  0.1020338386297226\n",
      "Loss:  0.14441847801208496\n",
      "3 **********\n",
      "Epoch:  227.60542917251587  fold:  6  kers:  64\n",
      "epoch:  4\n",
      "29479 461\n",
      "Loss:  0.1054433286190033\n",
      "Loss:  0.06715225428342819\n",
      "Loss:  0.10264021903276443\n",
      "4 **********\n",
      "Epoch:  271.8690767288208  fold:  6  kers:  64\n",
      "epoch:  5\n",
      "29479 461\n",
      "Loss:  0.09463652968406677\n",
      "Loss:  0.11475596576929092\n",
      "Loss:  0.08812475949525833\n",
      "5 **********\n",
      "Epoch:  316.1576581001282  fold:  6  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.058009542524814606\n",
      "Eval Loss:  0.28576359152793884\n",
      "Eval Loss:  0.4773365557193756\n",
      "[[2060  172]\n",
      " [ 230  950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2232\n",
      "           1       0.85      0.81      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8821805392731535\n",
      "pre:  0.8467023172905526\n",
      "rec:  0.8050847457627118\n",
      "ma F1:  0.8682352633769224\n",
      "mi F1:  0.8821805392731535\n",
      "we F1:  0.8814518671992964\n",
      "update!  Acc:  0.8821805392731535\n",
      "Eval Loss:  0.39513862133026123\n",
      "Eval Loss:  0.35583552718162537\n",
      "Eval Loss:  0.4117463529109955\n",
      "Eval Loss:  0.38736000657081604\n",
      "Eval Loss:  0.30927878618240356\n",
      "Eval Loss:  0.39405620098114014\n",
      "Eval Loss:  0.49674201011657715\n",
      "Eval Loss:  0.28424498438835144\n",
      "Eval Loss:  0.5222353935241699\n",
      "Eval Loss:  0.4844678044319153\n",
      "Eval Loss:  0.346737802028656\n",
      "Eval Loss:  0.49036383628845215\n",
      "Eval Loss:  0.43242648243904114\n",
      "Eval Loss:  0.4152589738368988\n",
      "Eval Loss:  0.3655953109264374\n",
      "Eval Loss:  0.3523528575897217\n",
      "Eval Loss:  0.4360258877277374\n",
      "Eval Loss:  0.5116528272628784\n",
      "Eval Loss:  0.459710955619812\n",
      "Eval Loss:  0.42866402864456177\n",
      "Eval Loss:  0.29943686723709106\n",
      "Eval Loss:  0.34644368290901184\n",
      "Eval Loss:  0.39372968673706055\n",
      "Eval Loss:  0.37152206897735596\n",
      "Eval Loss:  0.3027908205986023\n",
      "Eval Loss:  0.4170112609863281\n",
      "Eval Loss:  0.3384253978729248\n",
      "Eval Loss:  0.38006874918937683\n",
      "[[17170   762]\n",
      " [ 4188  7359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87     17932\n",
      "           1       0.91      0.64      0.75     11547\n",
      "\n",
      "    accuracy                           0.83     29479\n",
      "   macro avg       0.86      0.80      0.81     29479\n",
      "weighted avg       0.84      0.83      0.82     29479\n",
      "\n",
      "acc:  0.8320838563044879\n",
      "pre:  0.9061691909863318\n",
      "rec:  0.6373083917900754\n",
      "ma F1:  0.8111679458031058\n",
      "mi F1:  0.8320838563044879\n",
      "we F1:  0.8247800229156657\n",
      "29479 461\n",
      "Loss:  0.1130712553858757\n",
      "Loss:  0.06704949587583542\n",
      "Loss:  0.08197057247161865\n",
      "6 **********\n",
      "Epoch:  399.35719990730286  fold:  6  kers:  64\n",
      "epoch:  7\n",
      "29479 461\n",
      "Loss:  0.09909963607788086\n",
      "Loss:  0.08245152235031128\n",
      "Loss:  0.07944735139608383\n",
      "7 **********\n",
      "Epoch:  443.3326184749603  fold:  6  kers:  64\n",
      "epoch:  8\n",
      "29479 461\n",
      "Loss:  0.0933477059006691\n",
      "Loss:  0.06915992498397827\n",
      "Loss:  0.07088392227888107\n",
      "8 **********\n",
      "Epoch:  487.3329699039459  fold:  6  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.04751167446374893\n",
      "Eval Loss:  0.23807576298713684\n",
      "Eval Loss:  0.43163424730300903\n",
      "[[2003  229]\n",
      " [ 168 1012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      2232\n",
      "           1       0.82      0.86      0.84      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.88      0.87      3412\n",
      "weighted avg       0.89      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8836459554513482\n",
      "pre:  0.8154713940370669\n",
      "rec:  0.8576271186440678\n",
      "ma F1:  0.8729261891299941\n",
      "mi F1:  0.8836459554513482\n",
      "we F1:  0.8843057997960532\n",
      "update!  Acc:  0.8836459554513482\n",
      "Eval Loss:  0.343190461397171\n",
      "Eval Loss:  0.27258411049842834\n",
      "Eval Loss:  0.3334861099720001\n",
      "Eval Loss:  0.32449907064437866\n",
      "Eval Loss:  0.2532654106616974\n",
      "Eval Loss:  0.31371840834617615\n",
      "Eval Loss:  0.4196290671825409\n",
      "Eval Loss:  0.2597918212413788\n",
      "Eval Loss:  0.40572699904441833\n",
      "Eval Loss:  0.39455878734588623\n",
      "Eval Loss:  0.28144943714141846\n",
      "Eval Loss:  0.43672123551368713\n",
      "Eval Loss:  0.34832537174224854\n",
      "Eval Loss:  0.34511467814445496\n",
      "Eval Loss:  0.2799733579158783\n",
      "Eval Loss:  0.2847329378128052\n",
      "Eval Loss:  0.3639703392982483\n",
      "Eval Loss:  0.4248083829879761\n",
      "Eval Loss:  0.382367879152298\n",
      "Eval Loss:  0.35476118326187134\n",
      "Eval Loss:  0.24871069192886353\n",
      "Eval Loss:  0.2795274555683136\n",
      "Eval Loss:  0.35866206884384155\n",
      "Eval Loss:  0.27814343571662903\n",
      "Eval Loss:  0.2888110280036926\n",
      "Eval Loss:  0.31566667556762695\n",
      "Eval Loss:  0.24781689047813416\n",
      "Eval Loss:  0.32229354977607727\n",
      "[[17019   913]\n",
      " [ 3276  8271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     17932\n",
      "           1       0.90      0.72      0.80     11547\n",
      "\n",
      "    accuracy                           0.86     29479\n",
      "   macro avg       0.87      0.83      0.84     29479\n",
      "weighted avg       0.86      0.86      0.85     29479\n",
      "\n",
      "acc:  0.8578988432443434\n",
      "pre:  0.9005879790940766\n",
      "rec:  0.7162899454403742\n",
      "ma F1:  0.8441766132604906\n",
      "mi F1:  0.8578988432443434\n",
      "we F1:  0.8541922097907718\n",
      "29479 461\n",
      "Loss:  0.08989649266004562\n",
      "Loss:  0.06991890072822571\n",
      "Loss:  0.11851039528846741\n",
      "9 **********\n",
      "Epoch:  570.0767304897308  fold:  6  kers:  64\n",
      "epoch:  10\n",
      "29479 461\n",
      "Loss:  0.06902620196342468\n",
      "Loss:  0.07705402374267578\n",
      "Loss:  0.06576047092676163\n",
      "10 **********\n",
      "Epoch:  613.9863247871399  fold:  6  kers:  64\n",
      "epoch:  11\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07225978374481201\n",
      "Loss:  0.09262873232364655\n",
      "Loss:  0.10361611098051071\n",
      "11 **********\n",
      "Epoch:  658.0036323070526  fold:  6  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.029867656528949738\n",
      "Eval Loss:  0.254341721534729\n",
      "Eval Loss:  0.428371399641037\n",
      "[[2075  157]\n",
      " [ 226  954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      2232\n",
      "           1       0.86      0.81      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.87      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8877491207502931\n",
      "pre:  0.8586858685868587\n",
      "rec:  0.8084745762711865\n",
      "ma F1:  0.8741662937767686\n",
      "mi F1:  0.8877491207502931\n",
      "we F1:  0.8869130680641439\n",
      "update!  Acc:  0.8877491207502931\n",
      "Eval Loss:  0.3457990884780884\n",
      "Eval Loss:  0.29158011078834534\n",
      "Eval Loss:  0.34183841943740845\n",
      "Eval Loss:  0.328107625246048\n",
      "Eval Loss:  0.254756897687912\n",
      "Eval Loss:  0.3273022770881653\n",
      "Eval Loss:  0.44317835569381714\n",
      "Eval Loss:  0.2721294164657593\n",
      "Eval Loss:  0.4072832763195038\n",
      "Eval Loss:  0.4001944065093994\n",
      "Eval Loss:  0.2737133204936981\n",
      "Eval Loss:  0.44637012481689453\n",
      "Eval Loss:  0.35011571645736694\n",
      "Eval Loss:  0.3811040222644806\n",
      "Eval Loss:  0.29351741075515747\n",
      "Eval Loss:  0.2896807789802551\n",
      "Eval Loss:  0.38478177785873413\n",
      "Eval Loss:  0.4536532461643219\n",
      "Eval Loss:  0.4168414771556854\n",
      "Eval Loss:  0.35643821954727173\n",
      "Eval Loss:  0.22942613065242767\n",
      "Eval Loss:  0.3054850995540619\n",
      "Eval Loss:  0.36096760630607605\n",
      "Eval Loss:  0.3191367983818054\n",
      "Eval Loss:  0.26830536127090454\n",
      "Eval Loss:  0.3348032236099243\n",
      "Eval Loss:  0.26470857858657837\n",
      "Eval Loss:  0.3462800979614258\n",
      "[[17315   617]\n",
      " [ 3755  7792]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     17932\n",
      "           1       0.93      0.67      0.78     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.87      0.82      0.83     29479\n",
      "weighted avg       0.86      0.85      0.85     29479\n",
      "\n",
      "acc:  0.8516910342956002\n",
      "pre:  0.9266262337971222\n",
      "rec:  0.6748073092578158\n",
      "ma F1:  0.8344106020476472\n",
      "mi F1:  0.8516910342956002\n",
      "we F1:  0.8459968206660637\n",
      "29479 461\n",
      "Loss:  0.10937575995922089\n",
      "Loss:  0.09566141664981842\n",
      "Loss:  0.0609746053814888\n",
      "12 **********\n",
      "Epoch:  740.7992532253265  fold:  6  kers:  64\n",
      "epoch:  13\n",
      "29479 461\n",
      "Loss:  0.1167704313993454\n",
      "Loss:  0.06198970228433609\n",
      "Loss:  0.05794167518615723\n",
      "13 **********\n",
      "Epoch:  784.6958818435669  fold:  6  kers:  64\n",
      "epoch:  14\n",
      "29479 461\n",
      "Loss:  0.09900324046611786\n",
      "Loss:  0.0697389766573906\n",
      "Loss:  0.0656084418296814\n",
      "14 **********\n",
      "Epoch:  828.5955038070679  fold:  6  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.032519496977329254\n",
      "Eval Loss:  0.19108082354068756\n",
      "Eval Loss:  0.3929014205932617\n",
      "[[2022  210]\n",
      " [ 184  996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      2232\n",
      "           1       0.83      0.84      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.87      0.87      3412\n",
      "weighted avg       0.89      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8845252051582649\n",
      "pre:  0.8258706467661692\n",
      "rec:  0.8440677966101695\n",
      "ma F1:  0.8730456731413945\n",
      "mi F1:  0.8845252051582649\n",
      "we F1:  0.8848161094783806\n",
      "Eval Loss:  0.26987358927726746\n",
      "Eval Loss:  0.2127423733472824\n",
      "Eval Loss:  0.2748572528362274\n",
      "Eval Loss:  0.3139612376689911\n",
      "Eval Loss:  0.23861268162727356\n",
      "Eval Loss:  0.27807730436325073\n",
      "Eval Loss:  0.3649839758872986\n",
      "Eval Loss:  0.24362625181674957\n",
      "Eval Loss:  0.3231102228164673\n",
      "Eval Loss:  0.3432950973510742\n",
      "Eval Loss:  0.22838594019412994\n",
      "Eval Loss:  0.360684871673584\n",
      "Eval Loss:  0.2571965456008911\n",
      "Eval Loss:  0.29661810398101807\n",
      "Eval Loss:  0.23056542873382568\n",
      "Eval Loss:  0.23324428498744965\n",
      "Eval Loss:  0.3117801249027252\n",
      "Eval Loss:  0.3528706729412079\n",
      "Eval Loss:  0.3192947506904602\n",
      "Eval Loss:  0.30736613273620605\n",
      "Eval Loss:  0.21457237005233765\n",
      "Eval Loss:  0.2538307309150696\n",
      "Eval Loss:  0.3090191185474396\n",
      "Eval Loss:  0.2623092532157898\n",
      "Eval Loss:  0.26840317249298096\n",
      "Eval Loss:  0.2522781193256378\n",
      "Eval Loss:  0.18916800618171692\n",
      "Eval Loss:  0.27099502086639404\n",
      "[[17004   928]\n",
      " [ 2710  8837]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     17932\n",
      "           1       0.90      0.77      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.88      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.87     29479\n",
      "\n",
      "acc:  0.8765901149971166\n",
      "pre:  0.9049667178699436\n",
      "rec:  0.7653070061487832\n",
      "ma F1:  0.8663304775649048\n",
      "mi F1:  0.8765901149971166\n",
      "we F1:  0.8743515116049039\n",
      "29479 461\n",
      "Loss:  0.0772646814584732\n",
      "Loss:  0.08690811693668365\n",
      "Loss:  0.08659395575523376\n",
      "15 **********\n",
      "Epoch:  910.9343461990356  fold:  6  kers:  64\n",
      "epoch:  16\n",
      "29479 461\n",
      "Loss:  0.09169162064790726\n",
      "Loss:  0.04793296754360199\n",
      "Loss:  0.05035259947180748\n",
      "16 **********\n",
      "Epoch:  954.9087677001953  fold:  6  kers:  64\n",
      "epoch:  17\n",
      "29479 461\n",
      "Loss:  0.10304287821054459\n",
      "Loss:  0.050011008977890015\n",
      "Loss:  0.05635085329413414\n",
      "17 **********\n",
      "Epoch:  998.6268737316132  fold:  6  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.03425498306751251\n",
      "Eval Loss:  0.21942608058452606\n",
      "Eval Loss:  0.3914552330970764\n",
      "[[2045  187]\n",
      " [ 208  972]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      2232\n",
      "           1       0.84      0.82      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.87      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.884232121922626\n",
      "pre:  0.8386540120793787\n",
      "rec:  0.823728813559322\n",
      "ma F1:  0.8715265316005134\n",
      "mi F1:  0.884232121922626\n",
      "we F1:  0.8839834570607767\n",
      "Eval Loss:  0.23535007238388062\n",
      "Eval Loss:  0.22438766062259674\n",
      "Eval Loss:  0.2675158679485321\n",
      "Eval Loss:  0.30998629331588745\n",
      "Eval Loss:  0.2275286614894867\n",
      "Eval Loss:  0.27550843358039856\n",
      "Eval Loss:  0.3410302698612213\n",
      "Eval Loss:  0.25429537892341614\n",
      "Eval Loss:  0.30454960465431213\n",
      "Eval Loss:  0.3253987729549408\n",
      "Eval Loss:  0.23603543639183044\n",
      "Eval Loss:  0.3223337233066559\n",
      "Eval Loss:  0.26023173332214355\n",
      "Eval Loss:  0.2815331220626831\n",
      "Eval Loss:  0.2278764396905899\n",
      "Eval Loss:  0.22367477416992188\n",
      "Eval Loss:  0.30227336287498474\n",
      "Eval Loss:  0.3418307602405548\n",
      "Eval Loss:  0.2971348762512207\n",
      "Eval Loss:  0.28624677658081055\n",
      "Eval Loss:  0.1999373883008957\n",
      "Eval Loss:  0.24985100328922272\n",
      "Eval Loss:  0.30166175961494446\n",
      "Eval Loss:  0.2656487226486206\n",
      "Eval Loss:  0.2510634660720825\n",
      "Eval Loss:  0.23227329552173615\n",
      "Eval Loss:  0.19248315691947937\n",
      "Eval Loss:  0.25762489438056946\n",
      "[[17042   890]\n",
      " [ 2593  8954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17932\n",
      "           1       0.91      0.78      0.84     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.89      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8818480952542488\n",
      "pre:  0.9095895977245022\n",
      "rec:  0.7754395080973413\n",
      "ma F1:  0.8722300811424082\n",
      "mi F1:  0.8818480952542488\n",
      "we F1:  0.8798229372383655\n",
      "29479 461\n",
      "Loss:  0.08197356760501862\n",
      "Loss:  0.09212329983711243\n",
      "Loss:  0.08425086736679077\n",
      "18 **********\n",
      "Epoch:  1081.1412477493286  fold:  6  kers:  64\n",
      "epoch:  19\n",
      "29479 461\n",
      "Loss:  0.07111603766679764\n",
      "Loss:  0.06113017350435257\n",
      "Loss:  0.058498725295066833\n",
      "19 **********\n",
      "Epoch:  1124.9720525741577  fold:  6  kers:  64\n",
      "epoch:  20\n",
      "29479 461\n",
      "Loss:  0.06940864771604538\n",
      "Loss:  0.059121835976839066\n",
      "Loss:  0.06707790493965149\n",
      "20 **********\n",
      "Epoch:  1168.7958767414093  fold:  6  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.022596241906285286\n",
      "Eval Loss:  0.2195940464735031\n",
      "Eval Loss:  0.36659112572669983\n",
      "[[2090  142]\n",
      " [ 264  916]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      2232\n",
      "           1       0.87      0.78      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.88      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8810082063305978\n",
      "pre:  0.8657844990548205\n",
      "rec:  0.7762711864406779\n",
      "ma F1:  0.8650288576921562\n",
      "mi F1:  0.8810082063305978\n",
      "we F1:  0.8793476607310322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2526490092277527\n",
      "Eval Loss:  0.2039966881275177\n",
      "Eval Loss:  0.25637394189834595\n",
      "Eval Loss:  0.30767154693603516\n",
      "Eval Loss:  0.2157008945941925\n",
      "Eval Loss:  0.29252439737319946\n",
      "Eval Loss:  0.36485177278518677\n",
      "Eval Loss:  0.266028493642807\n",
      "Eval Loss:  0.3121984899044037\n",
      "Eval Loss:  0.3615986704826355\n",
      "Eval Loss:  0.22661486268043518\n",
      "Eval Loss:  0.32978442311286926\n",
      "Eval Loss:  0.287246435880661\n",
      "Eval Loss:  0.31158357858657837\n",
      "Eval Loss:  0.1907075047492981\n",
      "Eval Loss:  0.23127350211143494\n",
      "Eval Loss:  0.3247464895248413\n",
      "Eval Loss:  0.36675962805747986\n",
      "Eval Loss:  0.301780641078949\n",
      "Eval Loss:  0.28893008828163147\n",
      "Eval Loss:  0.20009535551071167\n",
      "Eval Loss:  0.24020230770111084\n",
      "Eval Loss:  0.2918888330459595\n",
      "Eval Loss:  0.2744447588920593\n",
      "Eval Loss:  0.23929129540920258\n",
      "Eval Loss:  0.25008273124694824\n",
      "Eval Loss:  0.20277385413646698\n",
      "Eval Loss:  0.28015127778053284\n",
      "[[17223   709]\n",
      " [ 2795  8752]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     17932\n",
      "           1       0.93      0.76      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.89      0.86      0.87     29479\n",
      "weighted avg       0.89      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8811357237355405\n",
      "pre:  0.9250607758165099\n",
      "rec:  0.7579457867844461\n",
      "ma F1:  0.8704371908762782\n",
      "mi F1:  0.8811357237355405\n",
      "we F1:  0.8785011894958497\n",
      "29479 461\n",
      "Loss:  0.06482981890439987\n",
      "Loss:  0.07904262840747833\n",
      "Loss:  0.052590250968933105\n",
      "21 **********\n",
      "Epoch:  1251.3112473487854  fold:  6  kers:  64\n",
      "epoch:  22\n",
      "29479 461\n",
      "Loss:  0.07786813378334045\n",
      "Loss:  0.05776922032237053\n",
      "Loss:  0.07016660273075104\n",
      "22 **********\n",
      "Epoch:  1295.289657831192  fold:  6  kers:  64\n",
      "epoch:  23\n",
      "29479 461\n",
      "Loss:  0.053250085562467575\n",
      "Loss:  0.07576638460159302\n",
      "Loss:  0.05924205854535103\n",
      "23 **********\n",
      "Epoch:  1339.078575372696  fold:  6  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.01888674683868885\n",
      "Eval Loss:  0.20047365128993988\n",
      "Eval Loss:  0.3445885181427002\n",
      "[[2057  175]\n",
      " [ 241  939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2232\n",
      "           1       0.84      0.80      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.86      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8780773739742087\n",
      "pre:  0.8429084380610413\n",
      "rec:  0.7957627118644067\n",
      "ma F1:  0.8634125687319449\n",
      "mi F1:  0.8780773739742087\n",
      "we F1:  0.8772116520189408\n",
      "Eval Loss:  0.20254352688789368\n",
      "Eval Loss:  0.17588496208190918\n",
      "Eval Loss:  0.24266135692596436\n",
      "Eval Loss:  0.28716522455215454\n",
      "Eval Loss:  0.20635701715946198\n",
      "Eval Loss:  0.232443705201149\n",
      "Eval Loss:  0.34414345026016235\n",
      "Eval Loss:  0.2629075050354004\n",
      "Eval Loss:  0.3123738169670105\n",
      "Eval Loss:  0.3126791715621948\n",
      "Eval Loss:  0.23793047666549683\n",
      "Eval Loss:  0.2759980261325836\n",
      "Eval Loss:  0.2749706506729126\n",
      "Eval Loss:  0.29685086011886597\n",
      "Eval Loss:  0.17502760887145996\n",
      "Eval Loss:  0.20509441196918488\n",
      "Eval Loss:  0.2715376615524292\n",
      "Eval Loss:  0.2997574210166931\n",
      "Eval Loss:  0.26692670583724976\n",
      "Eval Loss:  0.2701743543148041\n",
      "Eval Loss:  0.20598459243774414\n",
      "Eval Loss:  0.228716179728508\n",
      "Eval Loss:  0.2714296877384186\n",
      "Eval Loss:  0.2239001840353012\n",
      "Eval Loss:  0.24381990730762482\n",
      "Eval Loss:  0.19810032844543457\n",
      "Eval Loss:  0.16326822340488434\n",
      "Eval Loss:  0.261949747800827\n",
      "[[17148   784]\n",
      " [ 2435  9112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91     17932\n",
      "           1       0.92      0.79      0.85     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.90      0.87      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8908036229180094\n",
      "pre:  0.9207760711398545\n",
      "rec:  0.7891227158569325\n",
      "ma F1:  0.8820377011719214\n",
      "mi F1:  0.8908036229180094\n",
      "we F1:  0.8890026601501161\n",
      "29479 461\n",
      "Loss:  0.060457177460193634\n",
      "Loss:  0.046048250049352646\n",
      "Loss:  0.05566902458667755\n",
      "24 **********\n",
      "Epoch:  1421.759503364563  fold:  6  kers:  64\n",
      "epoch:  25\n",
      "29479 461\n",
      "Loss:  0.0631486028432846\n",
      "Loss:  0.055017031729221344\n",
      "Loss:  0.04843636229634285\n",
      "25 **********\n",
      "Epoch:  1465.6631140708923  fold:  6  kers:  64\n",
      "epoch:  26\n",
      "29479 461\n",
      "Loss:  0.06781472265720367\n",
      "Loss:  0.06297376751899719\n",
      "Loss:  0.062438003718853\n",
      "26 **********\n",
      "Epoch:  1509.6943833827972  fold:  6  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.024729367345571518\n",
      "Eval Loss:  0.1860654503107071\n",
      "Eval Loss:  0.3886629343032837\n",
      "[[2056  176]\n",
      " [ 225  955]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2232\n",
      "           1       0.84      0.81      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.87      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8824736225087925\n",
      "pre:  0.8443854995579133\n",
      "rec:  0.809322033898305\n",
      "ma F1:  0.8688138109215332\n",
      "mi F1:  0.8824736225087925\n",
      "we F1:  0.8818656926561352\n",
      "Eval Loss:  0.1827317327260971\n",
      "Eval Loss:  0.17919941246509552\n",
      "Eval Loss:  0.2430604249238968\n",
      "Eval Loss:  0.2960248589515686\n",
      "Eval Loss:  0.21129216253757477\n",
      "Eval Loss:  0.2727758586406708\n",
      "Eval Loss:  0.32598212361335754\n",
      "Eval Loss:  0.28679171204566956\n",
      "Eval Loss:  0.29377302527427673\n",
      "Eval Loss:  0.2722465395927429\n",
      "Eval Loss:  0.22859002649784088\n",
      "Eval Loss:  0.24401740729808807\n",
      "Eval Loss:  0.2523939907550812\n",
      "Eval Loss:  0.27460744976997375\n",
      "Eval Loss:  0.16430062055587769\n",
      "Eval Loss:  0.18692733347415924\n",
      "Eval Loss:  0.26541954278945923\n",
      "Eval Loss:  0.2791978418827057\n",
      "Eval Loss:  0.22785836458206177\n",
      "Eval Loss:  0.2498415857553482\n",
      "Eval Loss:  0.22296755015850067\n",
      "Eval Loss:  0.23085828125476837\n",
      "Eval Loss:  0.2691531479358673\n",
      "Eval Loss:  0.22787585854530334\n",
      "Eval Loss:  0.22854426503181458\n",
      "Eval Loss:  0.18117070198059082\n",
      "Eval Loss:  0.16551563143730164\n",
      "Eval Loss:  0.2502993941307068\n",
      "[[16723  1209]\n",
      " [ 1959  9588]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     17932\n",
      "           1       0.89      0.83      0.86     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.89      0.88      0.89     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8925336680348723\n",
      "pre:  0.8880244512364546\n",
      "rec:  0.8303455442972201\n",
      "ma F1:  0.8858463453344987\n",
      "mi F1:  0.8925336680348723\n",
      "we F1:  0.8918307259150012\n",
      "29479 461\n",
      "Loss:  0.0725117102265358\n",
      "Loss:  0.06405198574066162\n",
      "Loss:  0.06637930124998093\n",
      "27 **********\n",
      "Epoch:  1592.1648745536804  fold:  6  kers:  64\n",
      "epoch:  28\n",
      "29479 461\n",
      "Loss:  0.06132551655173302\n",
      "Loss:  0.06585051119327545\n",
      "Loss:  0.0753556564450264\n",
      "28 **********\n",
      "Epoch:  1636.0854394435883  fold:  6  kers:  64\n",
      "epoch:  29\n",
      "29479 461\n",
      "Loss:  0.09581587463617325\n",
      "Loss:  0.08390944451093674\n",
      "Loss:  0.06238672882318497\n",
      "29 **********\n",
      "Epoch:  1679.9581325054169  fold:  6  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.009796480648219585\n",
      "Eval Loss:  0.2911894619464874\n",
      "Eval Loss:  0.3767131268978119\n",
      "[[2143   89]\n",
      " [ 351  829]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      2232\n",
      "           1       0.90      0.70      0.79      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.88      0.83      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8710433763188745\n",
      "pre:  0.9030501089324618\n",
      "rec:  0.7025423728813559\n",
      "ma F1:  0.8485872323842267\n",
      "mi F1:  0.8710433763188745\n",
      "we F1:  0.8665658194612812\n",
      "Eval Loss:  0.20738081634044647\n",
      "Eval Loss:  0.19888168573379517\n",
      "Eval Loss:  0.24778969585895538\n",
      "Eval Loss:  0.2992783188819885\n",
      "Eval Loss:  0.20276810228824615\n",
      "Eval Loss:  0.2744441032409668\n",
      "Eval Loss:  0.380874902009964\n",
      "Eval Loss:  0.30278313159942627\n",
      "Eval Loss:  0.3186374604701996\n",
      "Eval Loss:  0.3186844289302826\n",
      "Eval Loss:  0.23188522458076477\n",
      "Eval Loss:  0.27340173721313477\n",
      "Eval Loss:  0.2800505459308624\n",
      "Eval Loss:  0.3166190981864929\n",
      "Eval Loss:  0.16368235647678375\n",
      "Eval Loss:  0.2171895056962967\n",
      "Eval Loss:  0.2924773395061493\n",
      "Eval Loss:  0.32896333932876587\n",
      "Eval Loss:  0.26376137137413025\n",
      "Eval Loss:  0.2853401005268097\n",
      "Eval Loss:  0.19176200032234192\n",
      "Eval Loss:  0.23592887818813324\n",
      "Eval Loss:  0.2634090781211853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.27053102850914\n",
      "Eval Loss:  0.2158854901790619\n",
      "Eval Loss:  0.2205594778060913\n",
      "Eval Loss:  0.196188822388649\n",
      "Eval Loss:  0.3050477206707001\n",
      "[[17284   648]\n",
      " [ 2663  8884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17932\n",
      "           1       0.93      0.77      0.84     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.90      0.87      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.887682757217002\n",
      "pre:  0.9320184641208561\n",
      "rec:  0.7693773274443578\n",
      "ma F1:  0.8777571634440823\n",
      "mi F1:  0.887682757217002\n",
      "we F1:  0.8853017963298075\n",
      "29479 461\n",
      "Loss:  0.05841042101383209\n",
      "Loss:  0.07292488217353821\n",
      "Loss:  0.07421821355819702\n",
      "30 **********\n",
      "Epoch:  1762.6091403961182  fold:  6  kers:  64\n",
      "epoch:  31\n",
      "29479 461\n",
      "Loss:  0.051382988691329956\n",
      "Loss:  0.07581949979066849\n",
      "Loss:  0.0655740350484848\n",
      "31 **********\n",
      "Epoch:  1806.5666074752808  fold:  6  kers:  64\n",
      "epoch:  32\n",
      "29479 461\n",
      "Loss:  0.04623200744390488\n",
      "Loss:  0.06040766462683678\n",
      "Loss:  0.07424379885196686\n",
      "32 **********\n",
      "Epoch:  1850.4283299446106  fold:  6  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.015445582568645477\n",
      "Eval Loss:  0.13700737059116364\n",
      "Eval Loss:  0.3950764238834381\n",
      "[[2037  195]\n",
      " [ 216  964]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      2232\n",
      "           1       0.83      0.82      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8795427901524033\n",
      "pre:  0.8317515099223468\n",
      "rec:  0.8169491525423729\n",
      "ma F1:  0.8663225430071164\n",
      "mi F1:  0.8795427901524033\n",
      "we F1:  0.8792840527898208\n",
      "Eval Loss:  0.146856427192688\n",
      "Eval Loss:  0.14939160645008087\n",
      "Eval Loss:  0.21027474105358124\n",
      "Eval Loss:  0.2736922800540924\n",
      "Eval Loss:  0.20511886477470398\n",
      "Eval Loss:  0.24450328946113586\n",
      "Eval Loss:  0.310971736907959\n",
      "Eval Loss:  0.2812022864818573\n",
      "Eval Loss:  0.25422102212905884\n",
      "Eval Loss:  0.26395195722579956\n",
      "Eval Loss:  0.22715847194194794\n",
      "Eval Loss:  0.21890059113502502\n",
      "Eval Loss:  0.2111310362815857\n",
      "Eval Loss:  0.25536128878593445\n",
      "Eval Loss:  0.1371578425168991\n",
      "Eval Loss:  0.19302304089069366\n",
      "Eval Loss:  0.2123156487941742\n",
      "Eval Loss:  0.2222076803445816\n",
      "Eval Loss:  0.20123881101608276\n",
      "Eval Loss:  0.23243644833564758\n",
      "Eval Loss:  0.20853321254253387\n",
      "Eval Loss:  0.21826006472110748\n",
      "Eval Loss:  0.22814562916755676\n",
      "Eval Loss:  0.21561110019683838\n",
      "Eval Loss:  0.22387973964214325\n",
      "Eval Loss:  0.1616521030664444\n",
      "Eval Loss:  0.1477223038673401\n",
      "Eval Loss:  0.23675549030303955\n",
      "[[16544  1388]\n",
      " [ 1446 10101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     17932\n",
      "           1       0.88      0.87      0.88     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9038637674276604\n",
      "pre:  0.8791887892766994\n",
      "rec:  0.8747726682255131\n",
      "ma F1:  0.8990410059518221\n",
      "mi F1:  0.9038637674276603\n",
      "we F1:  0.9038203528435228\n",
      "29479 461\n",
      "Loss:  0.04577161371707916\n",
      "Loss:  0.04461107403039932\n",
      "Loss:  0.05271681770682335\n",
      "33 **********\n",
      "Epoch:  1932.987583398819  fold:  6  kers:  64\n",
      "epoch:  34\n",
      "29479 461\n",
      "Loss:  0.0734109878540039\n",
      "Loss:  0.039676010608673096\n",
      "Loss:  0.06123388558626175\n",
      "34 **********\n",
      "Epoch:  1976.936074256897  fold:  6  kers:  64\n",
      "epoch:  35\n",
      "29479 461\n",
      "Loss:  0.05943041294813156\n",
      "Loss:  0.056576453149318695\n",
      "Loss:  0.07917002588510513\n",
      "35 **********\n",
      "Epoch:  2020.83669257164  fold:  6  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.009746888652443886\n",
      "Eval Loss:  0.19253382086753845\n",
      "Eval Loss:  0.2925953269004822\n",
      "[[2102  130]\n",
      " [ 249  931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      2232\n",
      "           1       0.88      0.79      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.87      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8889214536928488\n",
      "pre:  0.8774740810556079\n",
      "rec:  0.7889830508474577\n",
      "ma F1:  0.8740910742151577\n",
      "mi F1:  0.8889214536928488\n",
      "we F1:  0.8874143527894797\n",
      "update!  Acc:  0.8889214536928488\n",
      "Eval Loss:  0.1728169023990631\n",
      "Eval Loss:  0.1694781482219696\n",
      "Eval Loss:  0.19928300380706787\n",
      "Eval Loss:  0.2640005350112915\n",
      "Eval Loss:  0.1902620494365692\n",
      "Eval Loss:  0.2405480444431305\n",
      "Eval Loss:  0.30114975571632385\n",
      "Eval Loss:  0.27510759234428406\n",
      "Eval Loss:  0.23932014405727386\n",
      "Eval Loss:  0.2748388946056366\n",
      "Eval Loss:  0.2118045687675476\n",
      "Eval Loss:  0.23320944607257843\n",
      "Eval Loss:  0.23858201503753662\n",
      "Eval Loss:  0.25947389006614685\n",
      "Eval Loss:  0.13020607829093933\n",
      "Eval Loss:  0.16419552266597748\n",
      "Eval Loss:  0.24844862520694733\n",
      "Eval Loss:  0.2706824541091919\n",
      "Eval Loss:  0.23339489102363586\n",
      "Eval Loss:  0.24453669786453247\n",
      "Eval Loss:  0.1898828148841858\n",
      "Eval Loss:  0.23162993788719177\n",
      "Eval Loss:  0.24387314915657043\n",
      "Eval Loss:  0.2365722805261612\n",
      "Eval Loss:  0.18397092819213867\n",
      "Eval Loss:  0.17961104214191437\n",
      "Eval Loss:  0.1534091830253601\n",
      "Eval Loss:  0.2514699101448059\n",
      "[[17044   888]\n",
      " [ 1928  9619]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17932\n",
      "           1       0.92      0.83      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.91      0.89      0.90     29479\n",
      "weighted avg       0.91      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9044743715865532\n",
      "pre:  0.9154849148186923\n",
      "rec:  0.8330302243006842\n",
      "ma F1:  0.8980036605261379\n",
      "mi F1:  0.9044743715865531\n",
      "we F1:  0.9035680362999766\n",
      "29479 461\n",
      "Loss:  0.0578332357108593\n",
      "Loss:  0.07193498313426971\n",
      "Loss:  0.043468404561281204\n",
      "36 **********\n",
      "Epoch:  2103.2912261486053  fold:  6  kers:  64\n",
      "epoch:  37\n",
      "29479 461\n",
      "Loss:  0.07616480439901352\n",
      "Loss:  0.06933488696813583\n",
      "Loss:  0.058004558086395264\n",
      "37 **********\n",
      "Epoch:  2147.0711677074432  fold:  6  kers:  64\n",
      "epoch:  38\n",
      "29479 461\n",
      "Loss:  0.05687876045703888\n",
      "Loss:  0.04999164119362831\n",
      "Loss:  0.0743701234459877\n",
      "38 **********\n",
      "Epoch:  2190.797252893448  fold:  6  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.008412865921854973\n",
      "Eval Loss:  0.1665886640548706\n",
      "Eval Loss:  0.3479642868041992\n",
      "[[2083  149]\n",
      " [ 288  892]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      2232\n",
      "           1       0.86      0.76      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8719226260257913\n",
      "pre:  0.8568683957732949\n",
      "rec:  0.7559322033898305\n",
      "ma F1:  0.8541518495611431\n",
      "mi F1:  0.8719226260257913\n",
      "we F1:  0.8698486227272304\n",
      "Eval Loss:  0.16272836923599243\n",
      "Eval Loss:  0.15239378809928894\n",
      "Eval Loss:  0.22032496333122253\n",
      "Eval Loss:  0.2674778699874878\n",
      "Eval Loss:  0.2027149200439453\n",
      "Eval Loss:  0.21872515976428986\n",
      "Eval Loss:  0.29402801394462585\n",
      "Eval Loss:  0.2678249478340149\n",
      "Eval Loss:  0.2478264719247818\n",
      "Eval Loss:  0.25002321600914\n",
      "Eval Loss:  0.20503708720207214\n",
      "Eval Loss:  0.2119639813899994\n",
      "Eval Loss:  0.22501042485237122\n",
      "Eval Loss:  0.2619480788707733\n",
      "Eval Loss:  0.1447824090719223\n",
      "Eval Loss:  0.1878356784582138\n",
      "Eval Loss:  0.238576740026474\n",
      "Eval Loss:  0.26842936873435974\n",
      "Eval Loss:  0.22818659245967865\n",
      "Eval Loss:  0.2304433435201645\n",
      "Eval Loss:  0.18306982517242432\n",
      "Eval Loss:  0.22482341527938843\n",
      "Eval Loss:  0.25370100140571594\n",
      "Eval Loss:  0.22559837996959686\n",
      "Eval Loss:  0.19940337538719177\n",
      "Eval Loss:  0.1535884141921997\n",
      "Eval Loss:  0.14533716440200806\n",
      "Eval Loss:  0.2516725957393646\n",
      "[[16855  1077]\n",
      " [ 1769  9778]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     17932\n",
      "           1       0.90      0.85      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.89      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9034566979883986\n",
      "pre:  0.9007830492860432\n",
      "rec:  0.8468000346410323\n",
      "ma F1:  0.8975523074135039\n",
      "mi F1:  0.9034566979883986\n",
      "we F1:  0.9028793575506667\n",
      "29479 461\n",
      "Loss:  0.07942570745944977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05947820842266083\n",
      "Loss:  0.08368421345949173\n",
      "39 **********\n",
      "Epoch:  2273.35351395607  fold:  6  kers:  64\n",
      "epoch:  40\n",
      "29479 461\n",
      "Loss:  0.03583995997905731\n",
      "Loss:  0.03187808394432068\n",
      "Loss:  0.06409360468387604\n",
      "40 **********\n",
      "Epoch:  2317.098548412323  fold:  6  kers:  64\n",
      "epoch:  41\n",
      "29479 461\n",
      "Loss:  0.07648801058530807\n",
      "Loss:  0.03292294591665268\n",
      "Loss:  0.04529667645692825\n",
      "41 **********\n",
      "Epoch:  2360.944313764572  fold:  6  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.010344767943024635\n",
      "Eval Loss:  0.1428743600845337\n",
      "Eval Loss:  0.32444584369659424\n",
      "[[2051  181]\n",
      " [ 219  961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2232\n",
      "           1       0.84      0.81      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.87      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8827667057444314\n",
      "pre:  0.841506129597198\n",
      "rec:  0.8144067796610169\n",
      "ma F1:  0.8694426555945467\n",
      "mi F1:  0.8827667057444314\n",
      "we F1:  0.8823021975740685\n",
      "Eval Loss:  0.1424584537744522\n",
      "Eval Loss:  0.14775784313678741\n",
      "Eval Loss:  0.20764002203941345\n",
      "Eval Loss:  0.2590694725513458\n",
      "Eval Loss:  0.1996726095676422\n",
      "Eval Loss:  0.241859570145607\n",
      "Eval Loss:  0.28228500485420227\n",
      "Eval Loss:  0.25241756439208984\n",
      "Eval Loss:  0.24539096653461456\n",
      "Eval Loss:  0.23721332848072052\n",
      "Eval Loss:  0.2160530388355255\n",
      "Eval Loss:  0.1906024068593979\n",
      "Eval Loss:  0.21232131123542786\n",
      "Eval Loss:  0.24434496462345123\n",
      "Eval Loss:  0.13172578811645508\n",
      "Eval Loss:  0.18346258997917175\n",
      "Eval Loss:  0.21068422496318817\n",
      "Eval Loss:  0.25079110264778137\n",
      "Eval Loss:  0.19818973541259766\n",
      "Eval Loss:  0.23003992438316345\n",
      "Eval Loss:  0.18895064294338226\n",
      "Eval Loss:  0.2002859115600586\n",
      "Eval Loss:  0.21964974701404572\n",
      "Eval Loss:  0.20125335454940796\n",
      "Eval Loss:  0.19972841441631317\n",
      "Eval Loss:  0.14490263164043427\n",
      "Eval Loss:  0.13819120824337006\n",
      "Eval Loss:  0.23568016290664673\n",
      "[[16652  1280]\n",
      " [ 1426 10121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     17932\n",
      "           1       0.89      0.88      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9082058414464534\n",
      "pre:  0.8877291465660907\n",
      "rec:  0.8765047198406513\n",
      "ma F1:  0.9034677171434329\n",
      "mi F1:  0.9082058414464534\n",
      "we F1:  0.9080999210440279\n",
      "29479 461\n",
      "Loss:  0.0794304758310318\n",
      "Loss:  0.05697086080908775\n",
      "Loss:  0.08763352036476135\n",
      "42 **********\n",
      "Epoch:  2443.2133436203003  fold:  6  kers:  64\n",
      "epoch:  43\n",
      "29479 461\n",
      "Loss:  0.07024504989385605\n",
      "Loss:  0.08946622908115387\n",
      "Loss:  0.07767770439386368\n",
      "43 **********\n",
      "Epoch:  2487.0052530765533  fold:  6  kers:  64\n",
      "epoch:  44\n",
      "29479 461\n",
      "Loss:  0.05246797576546669\n",
      "Loss:  0.07326747477054596\n",
      "Loss:  0.08331198990345001\n",
      "44 **********\n",
      "Epoch:  2530.9377863407135  fold:  6  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.011463052593171597\n",
      "Eval Loss:  0.13086307048797607\n",
      "Eval Loss:  0.28906863927841187\n",
      "[[2037  195]\n",
      " [ 192  988]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      2232\n",
      "           1       0.84      0.84      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.87      0.87      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8865767878077374\n",
      "pre:  0.8351648351648352\n",
      "rec:  0.8372881355932204\n",
      "ma F1:  0.8747366440879497\n",
      "mi F1:  0.8865767878077374\n",
      "we F1:  0.8866106490385851\n",
      "Eval Loss:  0.13190314173698425\n",
      "Eval Loss:  0.12694990634918213\n",
      "Eval Loss:  0.1943271905183792\n",
      "Eval Loss:  0.27123573422431946\n",
      "Eval Loss:  0.18774479627609253\n",
      "Eval Loss:  0.20845459401607513\n",
      "Eval Loss:  0.2716578543186188\n",
      "Eval Loss:  0.2235538810491562\n",
      "Eval Loss:  0.21549047529697418\n",
      "Eval Loss:  0.2423635870218277\n",
      "Eval Loss:  0.21227887272834778\n",
      "Eval Loss:  0.19071118533611298\n",
      "Eval Loss:  0.19289229810237885\n",
      "Eval Loss:  0.2332158088684082\n",
      "Eval Loss:  0.11913225054740906\n",
      "Eval Loss:  0.16841185092926025\n",
      "Eval Loss:  0.1745557337999344\n",
      "Eval Loss:  0.19810916483402252\n",
      "Eval Loss:  0.1841202676296234\n",
      "Eval Loss:  0.21642468869686127\n",
      "Eval Loss:  0.17948973178863525\n",
      "Eval Loss:  0.19640572369098663\n",
      "Eval Loss:  0.21844163537025452\n",
      "Eval Loss:  0.19023068249225616\n",
      "Eval Loss:  0.21448732912540436\n",
      "Eval Loss:  0.14186310768127441\n",
      "Eval Loss:  0.11803940683603287\n",
      "Eval Loss:  0.22309014201164246\n",
      "[[16678  1254]\n",
      " [ 1236 10311]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17932\n",
      "           1       0.89      0.89      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9155330913531666\n",
      "pre:  0.8915693904020753\n",
      "rec:  0.8929592101844634\n",
      "ma F1:  0.9113999708224562\n",
      "mi F1:  0.9155330913531666\n",
      "we F1:  0.9155447760036383\n",
      "29479 461\n",
      "Loss:  0.06131777912378311\n",
      "Loss:  0.05950995534658432\n",
      "Loss:  0.07346171140670776\n",
      "45 **********\n",
      "Epoch:  2613.256681919098  fold:  6  kers:  64\n",
      "epoch:  46\n",
      "29479 461\n",
      "Loss:  0.09121159464120865\n",
      "Loss:  0.0419924333691597\n",
      "Loss:  0.03659568727016449\n",
      "46 **********\n",
      "Epoch:  2657.16428232193  fold:  6  kers:  64\n",
      "epoch:  47\n",
      "29479 461\n",
      "Loss:  0.055755168199539185\n",
      "Loss:  0.080538809299469\n",
      "Loss:  0.05534707009792328\n",
      "47 **********\n",
      "Epoch:  2700.864436864853  fold:  6  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.007051187567412853\n",
      "Eval Loss:  0.13741295039653778\n",
      "Eval Loss:  0.27628326416015625\n",
      "[[2073  159]\n",
      " [ 234  946]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      2232\n",
      "           1       0.86      0.80      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.88      0.87      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8848182883939039\n",
      "pre:  0.8561085972850678\n",
      "rec:  0.8016949152542373\n",
      "ma F1:  0.8707129024746869\n",
      "mi F1:  0.8848182883939039\n",
      "we F1:  0.8838795981153401\n",
      "Eval Loss:  0.15475517511367798\n",
      "Eval Loss:  0.1443721055984497\n",
      "Eval Loss:  0.20087896287441254\n",
      "Eval Loss:  0.24211671948432922\n",
      "Eval Loss:  0.1887022852897644\n",
      "Eval Loss:  0.21813136339187622\n",
      "Eval Loss:  0.2794564664363861\n",
      "Eval Loss:  0.21595585346221924\n",
      "Eval Loss:  0.2212371528148651\n",
      "Eval Loss:  0.24503928422927856\n",
      "Eval Loss:  0.20122063159942627\n",
      "Eval Loss:  0.21441030502319336\n",
      "Eval Loss:  0.1923593431711197\n",
      "Eval Loss:  0.2247135192155838\n",
      "Eval Loss:  0.10838542878627777\n",
      "Eval Loss:  0.1687072515487671\n",
      "Eval Loss:  0.18056458234786987\n",
      "Eval Loss:  0.22866447269916534\n",
      "Eval Loss:  0.1955597698688507\n",
      "Eval Loss:  0.2297782152891159\n",
      "Eval Loss:  0.1677369326353073\n",
      "Eval Loss:  0.19561712443828583\n",
      "Eval Loss:  0.2125612199306488\n",
      "Eval Loss:  0.1922859251499176\n",
      "Eval Loss:  0.19235292077064514\n",
      "Eval Loss:  0.14675985276699066\n",
      "Eval Loss:  0.13693778216838837\n",
      "Eval Loss:  0.21378976106643677\n",
      "[[16938   994]\n",
      " [ 1516 10031]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17932\n",
      "           1       0.91      0.87      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9148546422877303\n",
      "pre:  0.9098412698412699\n",
      "rec:  0.8687104875725297\n",
      "ma F1:  0.9099088539105955\n",
      "mi F1:  0.9148546422877303\n",
      "we F1:  0.9144808618428389\n",
      "29479 461\n",
      "Loss:  0.06399103254079819\n",
      "Loss:  0.06017809361219406\n",
      "Loss:  0.06722598522901535\n",
      "48 **********\n",
      "Epoch:  2787.0001277923584  fold:  6  kers:  64\n",
      "epoch:  49\n",
      "29479 461\n",
      "Loss:  0.04619811847805977\n",
      "Loss:  0.05578730255365372\n",
      "Loss:  0.0687255859375\n",
      "49 **********\n",
      "Epoch:  2830.8329272270203  fold:  6  kers:  64\n",
      "epoch:  50\n",
      "29479 461\n",
      "Loss:  0.04139445349574089\n",
      "Loss:  0.05347819998860359\n",
      "Loss:  0.06623359024524689\n",
      "50 **********\n",
      "Epoch:  2874.6786930561066  fold:  6  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.004767158068716526\n",
      "Eval Loss:  0.17940515279769897\n",
      "Eval Loss:  0.3528767228126526\n",
      "[[2113  119]\n",
      " [ 288  892]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      2232\n",
      "           1       0.88      0.76      0.81      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.88      0.85      0.86      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8807151230949589\n",
      "pre:  0.8822947576656776\n",
      "rec:  0.7559322033898305\n",
      "ma F1:  0.8631960132019781\n",
      "mi F1:  0.8807151230949589\n",
      "we F1:  0.8782902831507217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17455324530601501\n",
      "Eval Loss:  0.16225303709506989\n",
      "Eval Loss:  0.22831939160823822\n",
      "Eval Loss:  0.25855669379234314\n",
      "Eval Loss:  0.19704997539520264\n",
      "Eval Loss:  0.21472959220409393\n",
      "Eval Loss:  0.3243960738182068\n",
      "Eval Loss:  0.23698003590106964\n",
      "Eval Loss:  0.24542294442653656\n",
      "Eval Loss:  0.2580643594264984\n",
      "Eval Loss:  0.20618878304958344\n",
      "Eval Loss:  0.2281191498041153\n",
      "Eval Loss:  0.2489992380142212\n",
      "Eval Loss:  0.2525964379310608\n",
      "Eval Loss:  0.11239360272884369\n",
      "Eval Loss:  0.18387672305107117\n",
      "Eval Loss:  0.20109957456588745\n",
      "Eval Loss:  0.2589067816734314\n",
      "Eval Loss:  0.1925320029258728\n",
      "Eval Loss:  0.24589651823043823\n",
      "Eval Loss:  0.17092065513134003\n",
      "Eval Loss:  0.1981215924024582\n",
      "Eval Loss:  0.2063913345336914\n",
      "Eval Loss:  0.21236391365528107\n",
      "Eval Loss:  0.22218605875968933\n",
      "Eval Loss:  0.14984168112277985\n",
      "Eval Loss:  0.13460642099380493\n",
      "Eval Loss:  0.2412944734096527\n",
      "[[17202   730]\n",
      " [ 1956  9591]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     17932\n",
      "           1       0.93      0.83      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.89      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9088842905118898\n",
      "pre:  0.9292704195329909\n",
      "rec:  0.8306053520394908\n",
      "ma F1:  0.9023768410112628\n",
      "mi F1:  0.9088842905118898\n",
      "we F1:  0.9078360533436112\n",
      "29479 461\n",
      "Loss:  0.047572433948516846\n",
      "Loss:  0.07716593891382217\n",
      "Loss:  0.0521630235016346\n",
      "51 **********\n",
      "Epoch:  2961.755866289139  fold:  6  kers:  64\n",
      "epoch:  52\n",
      "29479 461\n",
      "Loss:  0.055521298199892044\n",
      "Loss:  0.08303473889827728\n",
      "Loss:  0.037179604172706604\n",
      "52 **********\n",
      "Epoch:  3005.487935781479  fold:  6  kers:  64\n",
      "epoch:  53\n",
      "29479 461\n",
      "Loss:  0.08002454042434692\n",
      "Loss:  0.05888451635837555\n",
      "Loss:  0.045511502772569656\n",
      "53 **********\n",
      "Epoch:  3049.254911661148  fold:  6  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.007962347939610481\n",
      "Eval Loss:  0.14932425320148468\n",
      "Eval Loss:  0.2884310781955719\n",
      "[[2096  136]\n",
      " [ 234  946]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      2232\n",
      "           1       0.87      0.80      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.87      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.891559202813599\n",
      "pre:  0.8743068391866913\n",
      "rec:  0.8016949152542373\n",
      "ma F1:  0.8776615806351704\n",
      "mi F1:  0.891559202813599\n",
      "we F1:  0.8903748837062198\n",
      "update!  Acc:  0.891559202813599\n",
      "Eval Loss:  0.14664222300052643\n",
      "Eval Loss:  0.14147797226905823\n",
      "Eval Loss:  0.1750354766845703\n",
      "Eval Loss:  0.25452184677124023\n",
      "Eval Loss:  0.17443254590034485\n",
      "Eval Loss:  0.2067493498325348\n",
      "Eval Loss:  0.26054877042770386\n",
      "Eval Loss:  0.2086126208305359\n",
      "Eval Loss:  0.20032431185245514\n",
      "Eval Loss:  0.23907753825187683\n",
      "Eval Loss:  0.20189090073108673\n",
      "Eval Loss:  0.22094173729419708\n",
      "Eval Loss:  0.21606895327568054\n",
      "Eval Loss:  0.21756522357463837\n",
      "Eval Loss:  0.09802449494600296\n",
      "Eval Loss:  0.15955425798892975\n",
      "Eval Loss:  0.16492682695388794\n",
      "Eval Loss:  0.21181489527225494\n",
      "Eval Loss:  0.17524021863937378\n",
      "Eval Loss:  0.19860078394412994\n",
      "Eval Loss:  0.16545046865940094\n",
      "Eval Loss:  0.17947939038276672\n",
      "Eval Loss:  0.19529736042022705\n",
      "Eval Loss:  0.19934241473674774\n",
      "Eval Loss:  0.20278726518154144\n",
      "Eval Loss:  0.14507989585399628\n",
      "Eval Loss:  0.12634143233299255\n",
      "Eval Loss:  0.21371257305145264\n",
      "[[16997   935]\n",
      " [ 1450 10097]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     17932\n",
      "           1       0.92      0.87      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9190949489467078\n",
      "pre:  0.9152465554749819\n",
      "rec:  0.8744262579024855\n",
      "ma F1:  0.9144055373041401\n",
      "mi F1:  0.9190949489467078\n",
      "we F1:  0.9187449421357045\n",
      "29479 461\n",
      "Loss:  0.05718580633401871\n",
      "Loss:  0.043217696249485016\n",
      "Loss:  0.06955815106630325\n",
      "54 **********\n",
      "Epoch:  3131.841092824936  fold:  6  kers:  64\n",
      "epoch:  55\n",
      "29479 461\n",
      "Loss:  0.07939600944519043\n",
      "Loss:  0.04171805456280708\n",
      "Loss:  0.02685748040676117\n",
      "55 **********\n",
      "Epoch:  3175.6310074329376  fold:  6  kers:  64\n",
      "epoch:  56\n",
      "29479 461\n",
      "Loss:  0.06041642278432846\n",
      "Loss:  0.052026260644197464\n",
      "Loss:  0.08078981935977936\n",
      "56 **********\n",
      "Epoch:  3219.499711751938  fold:  6  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.01097298413515091\n",
      "Eval Loss:  0.11174847185611725\n",
      "Eval Loss:  0.4339298903942108\n",
      "[[2003  229]\n",
      " [ 171 1009]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      2232\n",
      "           1       0.82      0.86      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.88      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8827667057444314\n",
      "pre:  0.8150242326332795\n",
      "rec:  0.8550847457627119\n",
      "ma F1:  0.871894367669923\n",
      "mi F1:  0.8827667057444314\n",
      "we F1:  0.8834011077648756\n",
      "Eval Loss:  0.15297742187976837\n",
      "Eval Loss:  0.1502387523651123\n",
      "Eval Loss:  0.18789666891098022\n",
      "Eval Loss:  0.2510284185409546\n",
      "Eval Loss:  0.20081111788749695\n",
      "Eval Loss:  0.2162528932094574\n",
      "Eval Loss:  0.2491508275270462\n",
      "Eval Loss:  0.20657280087471008\n",
      "Eval Loss:  0.24378983676433563\n",
      "Eval Loss:  0.23376934230327606\n",
      "Eval Loss:  0.23667749762535095\n",
      "Eval Loss:  0.20549505949020386\n",
      "Eval Loss:  0.1894739717245102\n",
      "Eval Loss:  0.20288948714733124\n",
      "Eval Loss:  0.13058209419250488\n",
      "Eval Loss:  0.18077029287815094\n",
      "Eval Loss:  0.14158044755458832\n",
      "Eval Loss:  0.22620879113674164\n",
      "Eval Loss:  0.18249550461769104\n",
      "Eval Loss:  0.254306823015213\n",
      "Eval Loss:  0.1757253110408783\n",
      "Eval Loss:  0.1959022730588913\n",
      "Eval Loss:  0.21441201865673065\n",
      "Eval Loss:  0.18565456569194794\n",
      "Eval Loss:  0.20372767746448517\n",
      "Eval Loss:  0.1318686306476593\n",
      "Eval Loss:  0.14653772115707397\n",
      "Eval Loss:  0.18826410174369812\n",
      "[[16627  1305]\n",
      " [ 1125 10422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     17932\n",
      "           1       0.89      0.90      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9175684385494759\n",
      "pre:  0.88871834228703\n",
      "rec:  0.9025720966484801\n",
      "ma F1:  0.9137469502212121\n",
      "mi F1:  0.9175684385494759\n",
      "we F1:  0.9176792955839783\n",
      "29479 461\n",
      "Loss:  0.03499649092555046\n",
      "Loss:  0.03623045235872269\n",
      "Loss:  0.050037581473588943\n",
      "57 **********\n",
      "Epoch:  3301.978180885315  fold:  6  kers:  64\n",
      "epoch:  58\n",
      "29479 461\n",
      "Loss:  0.045367226004600525\n",
      "Loss:  0.06035337969660759\n",
      "Loss:  0.04923725873231888\n",
      "58 **********\n",
      "Epoch:  3345.742164850235  fold:  6  kers:  64\n",
      "epoch:  59\n",
      "29479 461\n",
      "Loss:  0.06463662534952164\n",
      "Loss:  0.05108904466032982\n",
      "Loss:  0.0660417303442955\n",
      "59 **********\n",
      "Epoch:  3389.436335325241  fold:  6  kers:  64\n",
      "Eval Loss:  0.004343084059655666\n",
      "Eval Loss:  0.15163402259349823\n",
      "Eval Loss:  0.2930515706539154\n",
      "[[2125  107]\n",
      " [ 298  882]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      2232\n",
      "           1       0.89      0.75      0.81      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.88      0.85      0.86      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8813012895662368\n",
      "pre:  0.8918099089989889\n",
      "rec:  0.747457627118644\n",
      "ma F1:  0.8631373929785935\n",
      "mi F1:  0.8813012895662368\n",
      "we F1:  0.8785102161565506\n",
      "update!  Acc:  0.891559202813599\n",
      "Epoch:  3393.4336473941803  fold:  6  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.1692022681236267\n",
      "Loss:  0.16186581552028656\n",
      "Loss:  0.14849239587783813\n",
      "0 **********\n",
      "Epoch:  56.30844211578369  fold:  7  kers:  64\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.1291511058807373\n",
      "Loss:  0.1352340430021286\n",
      "Loss:  0.09973757714033127\n",
      "1 **********\n",
      "Epoch:  100.33572220802307  fold:  7  kers:  64\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.0878794938325882\n",
      "Loss:  0.0971841961145401\n",
      "Loss:  0.0978541299700737\n",
      "2 **********\n",
      "Epoch:  144.17550349235535  fold:  7  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.6262997388839722\n",
      "Eval Loss:  0.1570250391960144\n",
      "Eval Loss:  1.6133657693862915\n",
      "[[1695  432]\n",
      " [ 612  692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76      2127\n",
      "           1       0.62      0.53      0.57      1304\n",
      "\n",
      "    accuracy                           0.70      3431\n",
      "   macro avg       0.68      0.66      0.67      3431\n",
      "weighted avg       0.69      0.70      0.69      3431\n",
      "\n",
      "acc:  0.6957155348294958\n",
      "pre:  0.6156583629893239\n",
      "rec:  0.5306748466257669\n",
      "ma F1:  0.667281579586823\n",
      "mi F1:  0.6957155348294958\n",
      "we F1:  0.690612731296414\n",
      "update!  Acc:  0.6957155348294958\n",
      "Eval Loss:  0.44667574763298035\n",
      "Eval Loss:  0.33094221353530884\n",
      "Eval Loss:  0.34978196024894714\n",
      "Eval Loss:  0.4314599633216858\n",
      "Eval Loss:  0.32386982440948486\n",
      "Eval Loss:  0.43051451444625854\n",
      "Eval Loss:  0.4346538186073303\n",
      "Eval Loss:  0.3136425316333771\n",
      "Eval Loss:  0.3365829586982727\n",
      "Eval Loss:  0.3180062174797058\n",
      "Eval Loss:  0.3227747082710266\n",
      "Eval Loss:  0.3100103437900543\n",
      "Eval Loss:  0.41550877690315247\n",
      "Eval Loss:  0.33491677045822144\n",
      "Eval Loss:  0.4304051697254181\n",
      "Eval Loss:  0.3827787935733795\n",
      "Eval Loss:  0.34019792079925537\n",
      "Eval Loss:  0.41539013385772705\n",
      "Eval Loss:  0.3324626684188843\n",
      "Eval Loss:  0.3955722153186798\n",
      "Eval Loss:  0.35732918977737427\n",
      "Eval Loss:  0.38060396909713745\n",
      "Eval Loss:  0.31467071175575256\n",
      "Eval Loss:  0.42867401242256165\n",
      "Eval Loss:  0.2937626838684082\n",
      "Eval Loss:  0.4331592619419098\n",
      "Eval Loss:  0.38458120822906494\n",
      "Eval Loss:  0.3579988479614258\n",
      "[[15763  2274]\n",
      " [ 2349  9074]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87     18037\n",
      "           1       0.80      0.79      0.80     11423\n",
      "\n",
      "    accuracy                           0.84     29460\n",
      "   macro avg       0.83      0.83      0.83     29460\n",
      "weighted avg       0.84      0.84      0.84     29460\n",
      "\n",
      "acc:  0.8430753564154786\n",
      "pre:  0.7996122664786747\n",
      "rec:  0.7943622515976538\n",
      "ma F1:  0.8345456290173725\n",
      "mi F1:  0.8430753564154786\n",
      "we F1:  0.8429797173730421\n",
      "29460 461\n",
      "Loss:  0.09340091049671173\n",
      "Loss:  0.08890575915575027\n",
      "Loss:  0.07797814905643463\n",
      "3 **********\n",
      "Epoch:  226.7168047428131  fold:  7  kers:  64\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.13180899620056152\n",
      "Loss:  0.1339137852191925\n",
      "Loss:  0.08304745703935623\n",
      "4 **********\n",
      "Epoch:  270.5825164318085  fold:  7  kers:  64\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.07885746657848358\n",
      "Loss:  0.13523079454898834\n",
      "Loss:  0.104341059923172\n",
      "5 **********\n",
      "Epoch:  314.3983619213104  fold:  7  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.7932616472244263\n",
      "Eval Loss:  0.05427706241607666\n",
      "Eval Loss:  2.8128836154937744\n",
      "[[2064   63]\n",
      " [ 944  360]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80      2127\n",
      "           1       0.85      0.28      0.42      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.77      0.62      0.61      3431\n",
      "weighted avg       0.75      0.71      0.66      3431\n",
      "\n",
      "acc:  0.7064995628096765\n",
      "pre:  0.851063829787234\n",
      "rec:  0.27607361963190186\n",
      "ma F1:  0.6104013860846885\n",
      "mi F1:  0.7064995628096765\n",
      "we F1:  0.6568150007822618\n",
      "update!  Acc:  0.7064995628096765\n",
      "Eval Loss:  0.48714011907577515\n",
      "Eval Loss:  0.38076457381248474\n",
      "Eval Loss:  0.4209003448486328\n",
      "Eval Loss:  0.5069862008094788\n",
      "Eval Loss:  0.29918959736824036\n",
      "Eval Loss:  0.5011957883834839\n",
      "Eval Loss:  0.5166301131248474\n",
      "Eval Loss:  0.328777015209198\n",
      "Eval Loss:  0.35280609130859375\n",
      "Eval Loss:  0.3308044970035553\n",
      "Eval Loss:  0.30940744280815125\n",
      "Eval Loss:  0.34814202785491943\n",
      "Eval Loss:  0.4194539487361908\n",
      "Eval Loss:  0.3629167675971985\n",
      "Eval Loss:  0.43837985396385193\n",
      "Eval Loss:  0.3859778344631195\n",
      "Eval Loss:  0.3996926248073578\n",
      "Eval Loss:  0.4778386652469635\n",
      "Eval Loss:  0.3187255859375\n",
      "Eval Loss:  0.44509357213974\n",
      "Eval Loss:  0.4205465614795685\n",
      "Eval Loss:  0.41068845987319946\n",
      "Eval Loss:  0.3259526193141937\n",
      "Eval Loss:  0.4133465886116028\n",
      "Eval Loss:  0.3053640127182007\n",
      "Eval Loss:  0.4362829923629761\n",
      "Eval Loss:  0.5126345753669739\n",
      "Eval Loss:  0.3634662628173828\n",
      "[[17320   717]\n",
      " [ 3894  7529]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88     18037\n",
      "           1       0.91      0.66      0.77     11423\n",
      "\n",
      "    accuracy                           0.84     29460\n",
      "   macro avg       0.86      0.81      0.82     29460\n",
      "weighted avg       0.85      0.84      0.84     29460\n",
      "\n",
      "acc:  0.8434826883910387\n",
      "pre:  0.9130487509095319\n",
      "rec:  0.6591088155475795\n",
      "ma F1:  0.8240477362840035\n",
      "mi F1:  0.8434826883910387\n",
      "we F1:  0.8371764027364528\n",
      "29460 461\n",
      "Loss:  0.11524707823991776\n",
      "Loss:  0.08133459836244583\n",
      "Loss:  0.0631062388420105\n",
      "6 **********\n",
      "Epoch:  396.8518981933594  fold:  7  kers:  64\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.08645470440387726\n",
      "Loss:  0.11076609045267105\n",
      "Loss:  0.08056343346834183\n",
      "7 **********\n",
      "Epoch:  440.6637542247772  fold:  7  kers:  64\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.10184656083583832\n",
      "Loss:  0.07523294538259506\n",
      "Loss:  0.10327263176441193\n",
      "8 **********\n",
      "Epoch:  484.4756097793579  fold:  7  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.7947835326194763\n",
      "Eval Loss:  0.05425404757261276\n",
      "Eval Loss:  2.9941747188568115\n",
      "[[2080   47]\n",
      " [ 906  398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.81      2127\n",
      "           1       0.89      0.31      0.46      1304\n",
      "\n",
      "    accuracy                           0.72      3431\n",
      "   macro avg       0.80      0.64      0.63      3431\n",
      "weighted avg       0.77      0.72      0.68      3431\n",
      "\n",
      "acc:  0.7222384144564267\n",
      "pre:  0.8943820224719101\n",
      "rec:  0.3052147239263804\n",
      "ma F1:  0.6343647852417581\n",
      "mi F1:  0.7222384144564268\n",
      "we F1:  0.6773612161832991\n",
      "update!  Acc:  0.7222384144564267\n",
      "Eval Loss:  0.4502394199371338\n",
      "Eval Loss:  0.32064157724380493\n",
      "Eval Loss:  0.3484223783016205\n",
      "Eval Loss:  0.42830801010131836\n",
      "Eval Loss:  0.2909516990184784\n",
      "Eval Loss:  0.45075008273124695\n",
      "Eval Loss:  0.46200305223464966\n",
      "Eval Loss:  0.28595471382141113\n",
      "Eval Loss:  0.3281401991844177\n",
      "Eval Loss:  0.302815318107605\n",
      "Eval Loss:  0.2843594253063202\n",
      "Eval Loss:  0.29673516750335693\n",
      "Eval Loss:  0.39786624908447266\n",
      "Eval Loss:  0.3233622610569\n",
      "Eval Loss:  0.39950454235076904\n",
      "Eval Loss:  0.35946744680404663\n",
      "Eval Loss:  0.34862616658210754\n",
      "Eval Loss:  0.45805904269218445\n",
      "Eval Loss:  0.28248074650764465\n",
      "Eval Loss:  0.4326721429824829\n",
      "Eval Loss:  0.39535000920295715\n",
      "Eval Loss:  0.4042765200138092\n",
      "Eval Loss:  0.2993280589580536\n",
      "Eval Loss:  0.4069541394710541\n",
      "Eval Loss:  0.285503625869751\n",
      "Eval Loss:  0.4166533648967743\n",
      "Eval Loss:  0.49621114134788513\n",
      "Eval Loss:  0.33203285932540894\n",
      "[[17388   649]\n",
      " [ 3582  7841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18037\n",
      "           1       0.92      0.69      0.79     11423\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.88      0.83      0.84     29460\n",
      "weighted avg       0.87      0.86      0.85     29460\n",
      "\n",
      "acc:  0.8563815342837746\n",
      "pre:  0.9235571260306242\n",
      "rec:  0.6864221307887595\n",
      "ma F1:  0.8395290130160387\n",
      "mi F1:  0.8563815342837746\n",
      "we F1:  0.8512041544913509\n",
      "29460 461\n",
      "Loss:  0.06743896007537842\n",
      "Loss:  0.07919346541166306\n",
      "Loss:  0.07048457860946655\n",
      "9 **********\n",
      "Epoch:  566.9311411380768  fold:  7  kers:  64\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.05788973718881607\n",
      "Loss:  0.09660062938928604\n",
      "Loss:  0.06981457024812698\n",
      "10 **********\n",
      "Epoch:  610.6113488674164  fold:  7  kers:  64\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07987810671329498\n",
      "Loss:  0.05568470060825348\n",
      "Loss:  0.09709499031305313\n",
      "11 **********\n",
      "Epoch:  654.324469089508  fold:  7  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.9774326086044312\n",
      "Eval Loss:  0.03588206321001053\n",
      "Eval Loss:  3.209233283996582\n",
      "[[2099   28]\n",
      " [ 972  332]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.99      0.81      2127\n",
      "           1       0.92      0.25      0.40      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.80      0.62      0.60      3431\n",
      "weighted avg       0.77      0.71      0.65      3431\n",
      "\n",
      "acc:  0.7085397843194404\n",
      "pre:  0.9222222222222223\n",
      "rec:  0.254601226993865\n",
      "ma F1:  0.6033283881374494\n",
      "mi F1:  0.7085397843194403\n",
      "we F1:  0.6523317718713366\n",
      "Eval Loss:  0.4485631585121155\n",
      "Eval Loss:  0.33577021956443787\n",
      "Eval Loss:  0.38807353377342224\n",
      "Eval Loss:  0.44145241379737854\n",
      "Eval Loss:  0.2950443923473358\n",
      "Eval Loss:  0.4550859332084656\n",
      "Eval Loss:  0.4930594563484192\n",
      "Eval Loss:  0.31484949588775635\n",
      "Eval Loss:  0.34489744901657104\n",
      "Eval Loss:  0.3244478702545166\n",
      "Eval Loss:  0.3254314959049225\n",
      "Eval Loss:  0.325166791677475\n",
      "Eval Loss:  0.4382964074611664\n",
      "Eval Loss:  0.34602320194244385\n",
      "Eval Loss:  0.3869076073169708\n",
      "Eval Loss:  0.38502275943756104\n",
      "Eval Loss:  0.3794768452644348\n",
      "Eval Loss:  0.4596027135848999\n",
      "Eval Loss:  0.29911574721336365\n",
      "Eval Loss:  0.4582420587539673\n",
      "Eval Loss:  0.39179548621177673\n",
      "Eval Loss:  0.423515647649765\n",
      "Eval Loss:  0.322086364030838\n",
      "Eval Loss:  0.42430737614631653\n",
      "Eval Loss:  0.30148738622665405\n",
      "Eval Loss:  0.4308002293109894\n",
      "Eval Loss:  0.5312354564666748\n",
      "Eval Loss:  0.3649648129940033\n",
      "[[17620   417]\n",
      " [ 4111  7312]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     18037\n",
      "           1       0.95      0.64      0.76     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.88      0.81      0.82     29460\n",
      "weighted avg       0.86      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8463000678886626\n",
      "pre:  0.9460473541208436\n",
      "rec:  0.6401120546266305\n",
      "ma F1:  0.8248576077086701\n",
      "mi F1:  0.8463000678886626\n",
      "we F1:  0.8386158956045248\n",
      "29460 461\n",
      "Loss:  0.10510256886482239\n",
      "Loss:  0.0553804412484169\n",
      "Loss:  0.06254807859659195\n",
      "12 **********\n",
      "Epoch:  736.711183309555  fold:  7  kers:  64\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.05972185358405113\n",
      "Loss:  0.07203920930624008\n",
      "Loss:  0.06400004774332047\n",
      "13 **********\n",
      "Epoch:  780.4412577152252  fold:  7  kers:  64\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.06793942302465439\n",
      "Loss:  0.06348344683647156\n",
      "Loss:  0.09066829830408096\n",
      "14 **********\n",
      "Epoch:  824.3398818969727  fold:  7  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.9872361421585083\n",
      "Eval Loss:  0.023568585515022278\n",
      "Eval Loss:  3.1940958499908447\n",
      "[[2104   23]\n",
      " [ 982  322]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.99      0.81      2127\n",
      "           1       0.93      0.25      0.39      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.81      0.62      0.60      3431\n",
      "weighted avg       0.78      0.71      0.65      3431\n",
      "\n",
      "acc:  0.7070824832410376\n",
      "pre:  0.9333333333333333\n",
      "rec:  0.2469325153374233\n",
      "ma F1:  0.5988762292151787\n",
      "mi F1:  0.7070824832410376\n",
      "we F1:  0.6488502735829015\n",
      "Eval Loss:  0.4374949038028717\n",
      "Eval Loss:  0.32843953371047974\n",
      "Eval Loss:  0.3608507513999939\n",
      "Eval Loss:  0.440784215927124\n",
      "Eval Loss:  0.30813440680503845\n",
      "Eval Loss:  0.4438827931880951\n",
      "Eval Loss:  0.47421887516975403\n",
      "Eval Loss:  0.29766544699668884\n",
      "Eval Loss:  0.3477605879306793\n",
      "Eval Loss:  0.32987672090530396\n",
      "Eval Loss:  0.33888715505599976\n",
      "Eval Loss:  0.318927526473999\n",
      "Eval Loss:  0.43061548471450806\n",
      "Eval Loss:  0.3433372378349304\n",
      "Eval Loss:  0.4010401666164398\n",
      "Eval Loss:  0.38830286264419556\n",
      "Eval Loss:  0.3831966519355774\n",
      "Eval Loss:  0.46224188804626465\n",
      "Eval Loss:  0.3037281036376953\n",
      "Eval Loss:  0.44529032707214355\n",
      "Eval Loss:  0.3816780149936676\n",
      "Eval Loss:  0.4014502167701721\n",
      "Eval Loss:  0.3148452937602997\n",
      "Eval Loss:  0.43822047114372253\n",
      "Eval Loss:  0.29706549644470215\n",
      "Eval Loss:  0.43295902013778687\n",
      "Eval Loss:  0.5225763320922852\n",
      "Eval Loss:  0.35568979382514954\n",
      "[[17671   366]\n",
      " [ 4100  7323]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     18037\n",
      "           1       0.95      0.64      0.77     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.88      0.81      0.83     29460\n",
      "weighted avg       0.87      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8484046164290564\n",
      "pre:  0.9523995317986734\n",
      "rec:  0.6410750240742362\n",
      "ma F1:  0.8270681586390732\n",
      "mi F1:  0.8484046164290564\n",
      "we F1:  0.8407055119269499\n",
      "29460 461\n",
      "Loss:  0.06558939814567566\n",
      "Loss:  0.06023512780666351\n",
      "Loss:  0.0654674768447876\n",
      "15 **********\n",
      "Epoch:  906.6218769550323  fold:  7  kers:  64\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.06314951926469803\n",
      "Loss:  0.05949692055583\n",
      "Loss:  0.06645096093416214\n",
      "16 **********\n",
      "Epoch:  950.3619251251221  fold:  7  kers:  64\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.07421745359897614\n",
      "Loss:  0.08005355298519135\n",
      "Loss:  0.1087648943066597\n",
      "17 **********\n",
      "Epoch:  994.0740473270416  fold:  7  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.6092811822891235\n",
      "Eval Loss:  0.047030095010995865\n",
      "Eval Loss:  2.764784336090088\n",
      "[[2053   74]\n",
      " [ 822  482]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82      2127\n",
      "           1       0.87      0.37      0.52      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.79      0.67      0.67      3431\n",
      "weighted avg       0.77      0.74      0.71      3431\n",
      "\n",
      "acc:  0.7388516467502186\n",
      "pre:  0.8669064748201439\n",
      "rec:  0.3696319018404908\n",
      "ma F1:  0.6695756106159687\n",
      "mi F1:  0.7388516467502185\n",
      "we F1:  0.7058672578078768\n",
      "update!  Acc:  0.7388516467502186\n",
      "Eval Loss:  0.35910260677337646\n",
      "Eval Loss:  0.24380584061145782\n",
      "Eval Loss:  0.20840266346931458\n",
      "Eval Loss:  0.29486098885536194\n",
      "Eval Loss:  0.25874537229537964\n",
      "Eval Loss:  0.3640485405921936\n",
      "Eval Loss:  0.3634723424911499\n",
      "Eval Loss:  0.20251014828681946\n",
      "Eval Loss:  0.260926753282547\n",
      "Eval Loss:  0.2443992644548416\n",
      "Eval Loss:  0.24883438646793365\n",
      "Eval Loss:  0.19669970870018005\n",
      "Eval Loss:  0.3295617699623108\n",
      "Eval Loss:  0.2682998776435852\n",
      "Eval Loss:  0.29855307936668396\n",
      "Eval Loss:  0.32752564549446106\n",
      "Eval Loss:  0.30025482177734375\n",
      "Eval Loss:  0.3587843179702759\n",
      "Eval Loss:  0.2302832454442978\n",
      "Eval Loss:  0.32643768191337585\n",
      "Eval Loss:  0.26385876536369324\n",
      "Eval Loss:  0.3013548254966736\n",
      "Eval Loss:  0.24706654250621796\n",
      "Eval Loss:  0.3322394788265228\n",
      "Eval Loss:  0.1993696391582489\n",
      "Eval Loss:  0.2808853089809418\n",
      "Eval Loss:  0.3900441825389862\n",
      "Eval Loss:  0.2738772928714752\n",
      "[[17363   674]\n",
      " [ 2743  8680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18037\n",
      "           1       0.93      0.76      0.84     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.90      0.86      0.87     29460\n",
      "weighted avg       0.89      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8840122199592668\n",
      "pre:  0.9279452640581569\n",
      "rec:  0.7598704368379585\n",
      "ma F1:  0.8729776820599665\n",
      "mi F1:  0.8840122199592668\n",
      "we F1:  0.881382891511305\n",
      "29460 461\n",
      "Loss:  0.06970174610614777\n",
      "Loss:  0.08661463856697083\n",
      "Loss:  0.05397031456232071\n",
      "18 **********\n",
      "Epoch:  1076.5624904632568  fold:  7  kers:  64\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.04829103872179985\n",
      "Loss:  0.06374780088663101\n",
      "Loss:  0.06550225615501404\n",
      "19 **********\n",
      "Epoch:  1120.5349168777466  fold:  7  kers:  64\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.054939813911914825\n",
      "Loss:  0.06916110217571259\n",
      "Loss:  0.03286342695355415\n",
      "20 **********\n",
      "Epoch:  1164.3387942314148  fold:  7  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.44596412777900696\n",
      "Eval Loss:  0.09346054494380951\n",
      "Eval Loss:  2.088318347930908\n",
      "[[1909  218]\n",
      " [ 619  685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82      2127\n",
      "           1       0.76      0.53      0.62      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.71      0.72      3431\n",
      "weighted avg       0.76      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7560477994753716\n",
      "pre:  0.7585825027685493\n",
      "rec:  0.5253067484662577\n",
      "ma F1:  0.7204727463684779\n",
      "mi F1:  0.7560477994753715\n",
      "we F1:  0.7443929005408417\n",
      "update!  Acc:  0.7560477994753716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.31873878836631775\n",
      "Eval Loss:  0.2189754843711853\n",
      "Eval Loss:  0.1457684487104416\n",
      "Eval Loss:  0.22686639428138733\n",
      "Eval Loss:  0.2660466134548187\n",
      "Eval Loss:  0.28604331612586975\n",
      "Eval Loss:  0.29045233130455017\n",
      "Eval Loss:  0.14855116605758667\n",
      "Eval Loss:  0.238320454955101\n",
      "Eval Loss:  0.2156783938407898\n",
      "Eval Loss:  0.19417254626750946\n",
      "Eval Loss:  0.16240671277046204\n",
      "Eval Loss:  0.23903943598270416\n",
      "Eval Loss:  0.23528936505317688\n",
      "Eval Loss:  0.2517075538635254\n",
      "Eval Loss:  0.2958981394767761\n",
      "Eval Loss:  0.24610857665538788\n",
      "Eval Loss:  0.30508682131767273\n",
      "Eval Loss:  0.23527057468891144\n",
      "Eval Loss:  0.2807103097438812\n",
      "Eval Loss:  0.19271966814994812\n",
      "Eval Loss:  0.2520277798175812\n",
      "Eval Loss:  0.18841597437858582\n",
      "Eval Loss:  0.25584545731544495\n",
      "Eval Loss:  0.18010573089122772\n",
      "Eval Loss:  0.2501424252986908\n",
      "Eval Loss:  0.28748396039009094\n",
      "Eval Loss:  0.2478754222393036\n",
      "[[16737  1300]\n",
      " [ 1572  9851]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18037\n",
      "           1       0.88      0.86      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9025118805159539\n",
      "pre:  0.8834185274863241\n",
      "rec:  0.8623829116694388\n",
      "ma F1:  0.8968778319432298\n",
      "mi F1:  0.9025118805159539\n",
      "we F1:  0.9022893331427646\n",
      "29460 461\n",
      "Loss:  0.06141907721757889\n",
      "Loss:  0.06700533628463745\n",
      "Loss:  0.0737590491771698\n",
      "21 **********\n",
      "Epoch:  1246.819257736206  fold:  7  kers:  64\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.06831084936857224\n",
      "Loss:  0.05473766848444939\n",
      "Loss:  0.08852992206811905\n",
      "22 **********\n",
      "Epoch:  1290.6979358196259  fold:  7  kers:  64\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.0633574053645134\n",
      "Loss:  0.05566320940852165\n",
      "Loss:  0.05451474338769913\n",
      "23 **********\n",
      "Epoch:  1334.4200315475464  fold:  7  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.40204915404319763\n",
      "Eval Loss:  0.04516579210758209\n",
      "Eval Loss:  1.9575127363204956\n",
      "[[1852  275]\n",
      " [ 624  680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.80      2127\n",
      "           1       0.71      0.52      0.60      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.73      0.70      0.70      3431\n",
      "weighted avg       0.73      0.74      0.73      3431\n",
      "\n",
      "acc:  0.7379772661031769\n",
      "pre:  0.7120418848167539\n",
      "rec:  0.5214723926380368\n",
      "ma F1:  0.7033644455177095\n",
      "mi F1:  0.737977266103177\n",
      "we F1:  0.7276702060482895\n",
      "Eval Loss:  0.3530638515949249\n",
      "Eval Loss:  0.2247500717639923\n",
      "Eval Loss:  0.16443407535552979\n",
      "Eval Loss:  0.2082396000623703\n",
      "Eval Loss:  0.2144322693347931\n",
      "Eval Loss:  0.3204716444015503\n",
      "Eval Loss:  0.26250752806663513\n",
      "Eval Loss:  0.15942354500293732\n",
      "Eval Loss:  0.2445075660943985\n",
      "Eval Loss:  0.19637033343315125\n",
      "Eval Loss:  0.23227380216121674\n",
      "Eval Loss:  0.16432130336761475\n",
      "Eval Loss:  0.24378818273544312\n",
      "Eval Loss:  0.23768630623817444\n",
      "Eval Loss:  0.22403866052627563\n",
      "Eval Loss:  0.29490089416503906\n",
      "Eval Loss:  0.24133607745170593\n",
      "Eval Loss:  0.30543380975723267\n",
      "Eval Loss:  0.22489126026630402\n",
      "Eval Loss:  0.2792719304561615\n",
      "Eval Loss:  0.20166295766830444\n",
      "Eval Loss:  0.2468169629573822\n",
      "Eval Loss:  0.18573279678821564\n",
      "Eval Loss:  0.2822057902812958\n",
      "Eval Loss:  0.18996863067150116\n",
      "Eval Loss:  0.2357710897922516\n",
      "Eval Loss:  0.28419676423072815\n",
      "Eval Loss:  0.23245370388031006\n",
      "[[16804  1233]\n",
      " [ 1583  9840]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18037\n",
      "           1       0.89      0.86      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9044127630685675\n",
      "pre:  0.8886480628555947\n",
      "rec:  0.8614199422218332\n",
      "ma F1:  0.8987552639858234\n",
      "mi F1:  0.9044127630685677\n",
      "we F1:  0.9041284258085217\n",
      "29460 461\n",
      "Loss:  0.08181459456682205\n",
      "Loss:  0.05930117890238762\n",
      "Loss:  0.05811271816492081\n",
      "24 **********\n",
      "Epoch:  1416.893513917923  fold:  7  kers:  64\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.054102033376693726\n",
      "Loss:  0.048368796706199646\n",
      "Loss:  0.06937625259160995\n",
      "25 **********\n",
      "Epoch:  1460.5936686992645  fold:  7  kers:  64\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.07390258461236954\n",
      "Loss:  0.06306750327348709\n",
      "Loss:  0.047119420021772385\n",
      "26 **********\n",
      "Epoch:  1504.4324531555176  fold:  7  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.7051055431365967\n",
      "Eval Loss:  0.027256302535533905\n",
      "Eval Loss:  2.3410072326660156\n",
      "[[1972  155]\n",
      " [ 755  549]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81      2127\n",
      "           1       0.78      0.42      0.55      1304\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.75      0.67      0.68      3431\n",
      "weighted avg       0.74      0.73      0.71      3431\n",
      "\n",
      "acc:  0.7347712037306907\n",
      "pre:  0.7798295454545454\n",
      "rec:  0.4210122699386503\n",
      "ma F1:  0.6796692504805664\n",
      "mi F1:  0.7347712037306907\n",
      "we F1:  0.7115377729857332\n",
      "Eval Loss:  0.3129678964614868\n",
      "Eval Loss:  0.21374934911727905\n",
      "Eval Loss:  0.17942431569099426\n",
      "Eval Loss:  0.27226075530052185\n",
      "Eval Loss:  0.2244720160961151\n",
      "Eval Loss:  0.3347843289375305\n",
      "Eval Loss:  0.3086671233177185\n",
      "Eval Loss:  0.17767275869846344\n",
      "Eval Loss:  0.2611488699913025\n",
      "Eval Loss:  0.2295454740524292\n",
      "Eval Loss:  0.22674871981143951\n",
      "Eval Loss:  0.17793883383274078\n",
      "Eval Loss:  0.29457563161849976\n",
      "Eval Loss:  0.23530684411525726\n",
      "Eval Loss:  0.24853214621543884\n",
      "Eval Loss:  0.30763453245162964\n",
      "Eval Loss:  0.24804766476154327\n",
      "Eval Loss:  0.32055169343948364\n",
      "Eval Loss:  0.19680295884609222\n",
      "Eval Loss:  0.2763504385948181\n",
      "Eval Loss:  0.21928872168064117\n",
      "Eval Loss:  0.26110002398490906\n",
      "Eval Loss:  0.1900240033864975\n",
      "Eval Loss:  0.3156285881996155\n",
      "Eval Loss:  0.19838756322860718\n",
      "Eval Loss:  0.27504605054855347\n",
      "Eval Loss:  0.3095126152038574\n",
      "Eval Loss:  0.25678765773773193\n",
      "[[17329   708]\n",
      " [ 2397  9026]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18037\n",
      "           1       0.93      0.79      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8946028513238289\n",
      "pre:  0.927265255804397\n",
      "rec:  0.7901602030990108\n",
      "ma F1:  0.8855083610420245\n",
      "mi F1:  0.8946028513238289\n",
      "we F1:  0.8927528460141858\n",
      "29460 461\n",
      "Loss:  0.07274018973112106\n",
      "Loss:  0.04030167683959007\n",
      "Loss:  0.03837551176548004\n",
      "27 **********\n",
      "Epoch:  1586.8969600200653  fold:  7  kers:  64\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.05585062503814697\n",
      "Loss:  0.07170501351356506\n",
      "Loss:  0.049171194434165955\n",
      "28 **********\n",
      "Epoch:  1630.649973154068  fold:  7  kers:  64\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.07317933440208435\n",
      "Loss:  0.0683884397149086\n",
      "Loss:  0.07567194104194641\n",
      "29 **********\n",
      "Epoch:  1674.4199407100677  fold:  7  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.3836224675178528\n",
      "Eval Loss:  0.03297659754753113\n",
      "Eval Loss:  1.7403545379638672\n",
      "[[1864  263]\n",
      " [ 564  740]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      2127\n",
      "           1       0.74      0.57      0.64      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.75      0.72      0.73      3431\n",
      "weighted avg       0.76      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7589624016321772\n",
      "pre:  0.7377866400797607\n",
      "rec:  0.5674846625766872\n",
      "ma F1:  0.729983532198335\n",
      "mi F1:  0.7589624016321772\n",
      "we F1:  0.7512020460275629\n",
      "update!  Acc:  0.7589624016321772\n",
      "Eval Loss:  0.29725906252861023\n",
      "Eval Loss:  0.2235601395368576\n",
      "Eval Loss:  0.1413608342409134\n",
      "Eval Loss:  0.1926262527704239\n",
      "Eval Loss:  0.21833649277687073\n",
      "Eval Loss:  0.2936919629573822\n",
      "Eval Loss:  0.24329836666584015\n",
      "Eval Loss:  0.13300177454948425\n",
      "Eval Loss:  0.22734548151493073\n",
      "Eval Loss:  0.1797170341014862\n",
      "Eval Loss:  0.19270335137844086\n",
      "Eval Loss:  0.17291510105133057\n",
      "Eval Loss:  0.21919354796409607\n",
      "Eval Loss:  0.2105841040611267\n",
      "Eval Loss:  0.20430555939674377\n",
      "Eval Loss:  0.2601550221443176\n",
      "Eval Loss:  0.21878460049629211\n",
      "Eval Loss:  0.3103598356246948\n",
      "Eval Loss:  0.24549658596515656\n",
      "Eval Loss:  0.2567794919013977\n",
      "Eval Loss:  0.1673988550901413\n",
      "Eval Loss:  0.2172054499387741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.16940072178840637\n",
      "Eval Loss:  0.22829380631446838\n",
      "Eval Loss:  0.17528437077999115\n",
      "Eval Loss:  0.2493249475955963\n",
      "Eval Loss:  0.2505330741405487\n",
      "Eval Loss:  0.22884082794189453\n",
      "[[16630  1407]\n",
      " [ 1259 10164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     18037\n",
      "           1       0.88      0.89      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.91      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9095044127630686\n",
      "pre:  0.8784029038112523\n",
      "rec:  0.889783769587674\n",
      "ma F1:  0.9049243080149516\n",
      "mi F1:  0.9095044127630686\n",
      "we F1:  0.9096092465865641\n",
      "29460 461\n",
      "Loss:  0.06991731375455856\n",
      "Loss:  0.09555955231189728\n",
      "Loss:  0.044621437788009644\n",
      "30 **********\n",
      "Epoch:  1756.9093811511993  fold:  7  kers:  64\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.0437813475728035\n",
      "Loss:  0.060496460646390915\n",
      "Loss:  0.07484018802642822\n",
      "31 **********\n",
      "Epoch:  1800.7980313301086  fold:  7  kers:  64\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.07880672067403793\n",
      "Loss:  0.06167466938495636\n",
      "Loss:  0.06502851098775864\n",
      "32 **********\n",
      "Epoch:  1844.725578069687  fold:  7  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.5623157024383545\n",
      "Eval Loss:  0.026258056983351707\n",
      "Eval Loss:  2.199633836746216\n",
      "[[1908  219]\n",
      " [ 652  652]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.81      2127\n",
      "           1       0.75      0.50      0.60      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.70      0.71      3431\n",
      "weighted avg       0.75      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7461381521422326\n",
      "pre:  0.748564867967853\n",
      "rec:  0.5\n",
      "ma F1:  0.7068535371742335\n",
      "mi F1:  0.7461381521422326\n",
      "we F1:  0.732594968797373\n",
      "Eval Loss:  0.28725871443748474\n",
      "Eval Loss:  0.21013693511486053\n",
      "Eval Loss:  0.1541547328233719\n",
      "Eval Loss:  0.21459820866584778\n",
      "Eval Loss:  0.20655521750450134\n",
      "Eval Loss:  0.31208840012550354\n",
      "Eval Loss:  0.2467900514602661\n",
      "Eval Loss:  0.13504254817962646\n",
      "Eval Loss:  0.24682210385799408\n",
      "Eval Loss:  0.18193762004375458\n",
      "Eval Loss:  0.20340676605701447\n",
      "Eval Loss:  0.18479451537132263\n",
      "Eval Loss:  0.22936196625232697\n",
      "Eval Loss:  0.22546857595443726\n",
      "Eval Loss:  0.19704602658748627\n",
      "Eval Loss:  0.2584865689277649\n",
      "Eval Loss:  0.22702538967132568\n",
      "Eval Loss:  0.2825232446193695\n",
      "Eval Loss:  0.21171200275421143\n",
      "Eval Loss:  0.24492107331752777\n",
      "Eval Loss:  0.1762058436870575\n",
      "Eval Loss:  0.221948504447937\n",
      "Eval Loss:  0.15952950716018677\n",
      "Eval Loss:  0.2455974668264389\n",
      "Eval Loss:  0.1584402471780777\n",
      "Eval Loss:  0.2514156699180603\n",
      "Eval Loss:  0.2622893154621124\n",
      "Eval Loss:  0.22141773998737335\n",
      "[[16926  1111]\n",
      " [ 1547  9876]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18037\n",
      "           1       0.90      0.86      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9097759674134419\n",
      "pre:  0.8988804951306089\n",
      "rec:  0.8645714785958155\n",
      "ma F1:  0.9042951317733272\n",
      "mi F1:  0.9097759674134419\n",
      "we F1:  0.9094370107695994\n",
      "29460 461\n",
      "Loss:  0.07070564478635788\n",
      "Loss:  0.068025603890419\n",
      "Loss:  0.06358568370342255\n",
      "33 **********\n",
      "Epoch:  1927.0654182434082  fold:  7  kers:  64\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.0818561315536499\n",
      "Loss:  0.05132322013378143\n",
      "Loss:  0.08711657673120499\n",
      "34 **********\n",
      "Epoch:  1971.0129113197327  fold:  7  kers:  64\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.0614003911614418\n",
      "Loss:  0.049365293234586716\n",
      "Loss:  0.06739945709705353\n",
      "35 **********\n",
      "Epoch:  2014.8447139263153  fold:  7  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.5239499807357788\n",
      "Eval Loss:  0.023177234455943108\n",
      "Eval Loss:  2.29994535446167\n",
      "[[1972  155]\n",
      " [ 701  603]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82      2127\n",
      "           1       0.80      0.46      0.58      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.69      0.70      3431\n",
      "weighted avg       0.76      0.75      0.73      3431\n",
      "\n",
      "acc:  0.750510055377441\n",
      "pre:  0.7955145118733509\n",
      "rec:  0.4624233128834356\n",
      "ma F1:  0.7032678629162624\n",
      "mi F1:  0.750510055377441\n",
      "we F1:  0.7316683920583733\n",
      "Eval Loss:  0.29649513959884644\n",
      "Eval Loss:  0.20357021689414978\n",
      "Eval Loss:  0.152991384267807\n",
      "Eval Loss:  0.22599536180496216\n",
      "Eval Loss:  0.19277726113796234\n",
      "Eval Loss:  0.3226756751537323\n",
      "Eval Loss:  0.24491488933563232\n",
      "Eval Loss:  0.14440114796161652\n",
      "Eval Loss:  0.23032449185848236\n",
      "Eval Loss:  0.17894665896892548\n",
      "Eval Loss:  0.19659197330474854\n",
      "Eval Loss:  0.17231078445911407\n",
      "Eval Loss:  0.2351190745830536\n",
      "Eval Loss:  0.23345494270324707\n",
      "Eval Loss:  0.2076473832130432\n",
      "Eval Loss:  0.2612830102443695\n",
      "Eval Loss:  0.20133723318576813\n",
      "Eval Loss:  0.2945113778114319\n",
      "Eval Loss:  0.18156276643276215\n",
      "Eval Loss:  0.25351399183273315\n",
      "Eval Loss:  0.1796148121356964\n",
      "Eval Loss:  0.2155502736568451\n",
      "Eval Loss:  0.15045882761478424\n",
      "Eval Loss:  0.2732177674770355\n",
      "Eval Loss:  0.14979878067970276\n",
      "Eval Loss:  0.24085000157356262\n",
      "Eval Loss:  0.2564818263053894\n",
      "Eval Loss:  0.2299605906009674\n",
      "[[17205   832]\n",
      " [ 1765  9658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18037\n",
      "           1       0.92      0.85      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.911846571622539\n",
      "pre:  0.9206863679694948\n",
      "rec:  0.8454871749978115\n",
      "ma F1:  0.9056549816494341\n",
      "mi F1:  0.911846571622539\n",
      "we F1:  0.9110811345687552\n",
      "29460 461\n",
      "Loss:  0.04446113109588623\n",
      "Loss:  0.04373602196574211\n",
      "Loss:  0.04218783229589462\n",
      "36 **********\n",
      "Epoch:  2097.2703251838684  fold:  7  kers:  64\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.06918545067310333\n",
      "Loss:  0.046001020818948746\n",
      "Loss:  0.05647527053952217\n",
      "37 **********\n",
      "Epoch:  2141.0293221473694  fold:  7  kers:  64\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.054154835641384125\n",
      "Loss:  0.06107156723737717\n",
      "Loss:  0.04209117218852043\n",
      "38 **********\n",
      "Epoch:  2184.8072690963745  fold:  7  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.46925753355026245\n",
      "Eval Loss:  0.04996534064412117\n",
      "Eval Loss:  1.6149622201919556\n",
      "[[1842  285]\n",
      " [ 530  774]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      2127\n",
      "           1       0.73      0.59      0.66      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.75      0.73      0.74      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7624599242203439\n",
      "pre:  0.7308781869688386\n",
      "rec:  0.593558282208589\n",
      "ma F1:  0.7369740414407226\n",
      "mi F1:  0.7624599242203439\n",
      "we F1:  0.75661344362015\n",
      "update!  Acc:  0.7624599242203439\n",
      "Eval Loss:  0.25837603211402893\n",
      "Eval Loss:  0.22108060121536255\n",
      "Eval Loss:  0.12697230279445648\n",
      "Eval Loss:  0.20277787744998932\n",
      "Eval Loss:  0.19830186665058136\n",
      "Eval Loss:  0.292022705078125\n",
      "Eval Loss:  0.22942575812339783\n",
      "Eval Loss:  0.11999628692865372\n",
      "Eval Loss:  0.20358769595623016\n",
      "Eval Loss:  0.1675993949174881\n",
      "Eval Loss:  0.1963464319705963\n",
      "Eval Loss:  0.17895148694515228\n",
      "Eval Loss:  0.21202100813388824\n",
      "Eval Loss:  0.2001745104789734\n",
      "Eval Loss:  0.19645243883132935\n",
      "Eval Loss:  0.255617618560791\n",
      "Eval Loss:  0.20834587514400482\n",
      "Eval Loss:  0.3067033290863037\n",
      "Eval Loss:  0.213430255651474\n",
      "Eval Loss:  0.22370792925357819\n",
      "Eval Loss:  0.15164846181869507\n",
      "Eval Loss:  0.19185782968997955\n",
      "Eval Loss:  0.15667936205863953\n",
      "Eval Loss:  0.23001831769943237\n",
      "Eval Loss:  0.1520056277513504\n",
      "Eval Loss:  0.21878759562969208\n",
      "Eval Loss:  0.21933262050151825\n",
      "Eval Loss:  0.2190956324338913\n",
      "[[16717  1320]\n",
      " [ 1175 10248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18037\n",
      "           1       0.89      0.90      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9153088934147997\n",
      "pre:  0.8858921161825726\n",
      "rec:  0.8971373544602994\n",
      "ma F1:  0.9110183814392885\n",
      "mi F1:  0.9153088934147997\n",
      "we F1:  0.9154050634930884\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.059015754610300064\n",
      "Loss:  0.04414370656013489\n",
      "Loss:  0.03406374156475067\n",
      "39 **********\n",
      "Epoch:  2267.373503923416  fold:  7  kers:  64\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.06491203606128693\n",
      "Loss:  0.04957692325115204\n",
      "Loss:  0.021055176854133606\n",
      "40 **********\n",
      "Epoch:  2311.211290359497  fold:  7  kers:  64\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.04091912880539894\n",
      "Loss:  0.04886394739151001\n",
      "Loss:  0.0629991665482521\n",
      "41 **********\n",
      "Epoch:  2354.9672956466675  fold:  7  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.4613412022590637\n",
      "Eval Loss:  0.04192713275551796\n",
      "Eval Loss:  1.9242182970046997\n",
      "[[1855  272]\n",
      " [ 586  718]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81      2127\n",
      "           1       0.73      0.55      0.63      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.74      0.71      0.72      3431\n",
      "weighted avg       0.75      0.75      0.74      3431\n",
      "\n",
      "acc:  0.7499271349460799\n",
      "pre:  0.7252525252525253\n",
      "rec:  0.5506134969325154\n",
      "ma F1:  0.7190762241253739\n",
      "mi F1:  0.7499271349460799\n",
      "we F1:  0.7414071824415049\n",
      "Eval Loss:  0.24082322418689728\n",
      "Eval Loss:  0.20817194879055023\n",
      "Eval Loss:  0.1447538286447525\n",
      "Eval Loss:  0.19802795350551605\n",
      "Eval Loss:  0.18928971886634827\n",
      "Eval Loss:  0.3001013398170471\n",
      "Eval Loss:  0.21034570038318634\n",
      "Eval Loss:  0.11621313542127609\n",
      "Eval Loss:  0.20134684443473816\n",
      "Eval Loss:  0.173017218708992\n",
      "Eval Loss:  0.19090434908866882\n",
      "Eval Loss:  0.169172003865242\n",
      "Eval Loss:  0.21094749867916107\n",
      "Eval Loss:  0.20260202884674072\n",
      "Eval Loss:  0.1727316677570343\n",
      "Eval Loss:  0.25504380464553833\n",
      "Eval Loss:  0.185904398560524\n",
      "Eval Loss:  0.2892896234989166\n",
      "Eval Loss:  0.20615831017494202\n",
      "Eval Loss:  0.21797636151313782\n",
      "Eval Loss:  0.14584507048130035\n",
      "Eval Loss:  0.1983705312013626\n",
      "Eval Loss:  0.13485540449619293\n",
      "Eval Loss:  0.23281624913215637\n",
      "Eval Loss:  0.13087378442287445\n",
      "Eval Loss:  0.22061099112033844\n",
      "Eval Loss:  0.2199770212173462\n",
      "Eval Loss:  0.22846558690071106\n",
      "[[16936  1101]\n",
      " [ 1262 10161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18037\n",
      "           1       0.90      0.89      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9197895451459607\n",
      "pre:  0.9022376132125732\n",
      "rec:  0.8895211415565087\n",
      "ma F1:  0.9153105300213301\n",
      "mi F1:  0.9197895451459607\n",
      "we F1:  0.919683106557759\n",
      "29460 461\n",
      "Loss:  0.053336724638938904\n",
      "Loss:  0.04926900193095207\n",
      "Loss:  0.06576092541217804\n",
      "42 **********\n",
      "Epoch:  2437.5275464057922  fold:  7  kers:  64\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.05248680338263512\n",
      "Loss:  0.07259167730808258\n",
      "Loss:  0.07121144235134125\n",
      "43 **********\n",
      "Epoch:  2481.3054926395416  fold:  7  kers:  64\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.052866723388433456\n",
      "Loss:  0.06273902952671051\n",
      "Loss:  0.0413823239505291\n",
      "44 **********\n",
      "Epoch:  2525.144276857376  fold:  7  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.6148516535758972\n",
      "Eval Loss:  0.0457952506840229\n",
      "Eval Loss:  2.1747384071350098\n",
      "[[1944  183]\n",
      " [ 626  678]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      2127\n",
      "           1       0.79      0.52      0.63      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.72      0.73      3431\n",
      "weighted avg       0.77      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7642086855144273\n",
      "pre:  0.7874564459930313\n",
      "rec:  0.5199386503067485\n",
      "ma F1:  0.7270451730528209\n",
      "mi F1:  0.7642086855144273\n",
      "we F1:  0.7512043916593787\n",
      "update!  Acc:  0.7642086855144273\n",
      "Eval Loss:  0.2565106749534607\n",
      "Eval Loss:  0.18643918633460999\n",
      "Eval Loss:  0.1441492736339569\n",
      "Eval Loss:  0.23919451236724854\n",
      "Eval Loss:  0.2233293354511261\n",
      "Eval Loss:  0.31860536336898804\n",
      "Eval Loss:  0.24156546592712402\n",
      "Eval Loss:  0.14687493443489075\n",
      "Eval Loss:  0.21774822473526\n",
      "Eval Loss:  0.17228512465953827\n",
      "Eval Loss:  0.1909170001745224\n",
      "Eval Loss:  0.1805056631565094\n",
      "Eval Loss:  0.24051371216773987\n",
      "Eval Loss:  0.19313368201255798\n",
      "Eval Loss:  0.18477267026901245\n",
      "Eval Loss:  0.23654009401798248\n",
      "Eval Loss:  0.213029682636261\n",
      "Eval Loss:  0.29990828037261963\n",
      "Eval Loss:  0.1963229924440384\n",
      "Eval Loss:  0.2009246051311493\n",
      "Eval Loss:  0.15269511938095093\n",
      "Eval Loss:  0.1766285002231598\n",
      "Eval Loss:  0.1492212563753128\n",
      "Eval Loss:  0.21302089095115662\n",
      "Eval Loss:  0.11725640296936035\n",
      "Eval Loss:  0.2509908378124237\n",
      "Eval Loss:  0.259867399930954\n",
      "Eval Loss:  0.22018614411354065\n",
      "[[17107   930]\n",
      " [ 1582  9841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18037\n",
      "           1       0.91      0.86      0.89     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9147318397827563\n",
      "pre:  0.9136570420573763\n",
      "rec:  0.8615074848988882\n",
      "ma F1:  0.9092089234000272\n",
      "mi F1:  0.9147318397827563\n",
      "we F1:  0.9142362519102625\n",
      "29460 461\n",
      "Loss:  0.05722034350037575\n",
      "Loss:  0.05426596850156784\n",
      "Loss:  0.05627664178609848\n",
      "45 **********\n",
      "Epoch:  2607.735444545746  fold:  7  kers:  64\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.06232059374451637\n",
      "Loss:  0.04996475577354431\n",
      "Loss:  0.06253466755151749\n",
      "46 **********\n",
      "Epoch:  2651.59517288208  fold:  7  kers:  64\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.04706032574176788\n",
      "Loss:  0.044812750071287155\n",
      "Loss:  0.05487389117479324\n",
      "47 **********\n",
      "Epoch:  2695.5127460956573  fold:  7  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.5962411165237427\n",
      "Eval Loss:  0.026900209486484528\n",
      "Eval Loss:  1.8715506792068481\n",
      "[[1937  190]\n",
      " [ 633  671]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82      2127\n",
      "           1       0.78      0.51      0.62      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.71      0.72      3431\n",
      "weighted avg       0.76      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7601282424948994\n",
      "pre:  0.7793263646922184\n",
      "rec:  0.5145705521472392\n",
      "ma F1:  0.7223216037360587\n",
      "mi F1:  0.7601282424948994\n",
      "we F1:  0.7468989052356841\n",
      "Eval Loss:  0.2509629428386688\n",
      "Eval Loss:  0.2323806881904602\n",
      "Eval Loss:  0.17773567140102386\n",
      "Eval Loss:  0.22989651560783386\n",
      "Eval Loss:  0.2020537555217743\n",
      "Eval Loss:  0.32162943482398987\n",
      "Eval Loss:  0.23597145080566406\n",
      "Eval Loss:  0.12665584683418274\n",
      "Eval Loss:  0.20978882908821106\n",
      "Eval Loss:  0.1977924108505249\n",
      "Eval Loss:  0.21941781044006348\n",
      "Eval Loss:  0.16703447699546814\n",
      "Eval Loss:  0.21166115999221802\n",
      "Eval Loss:  0.19076195359230042\n",
      "Eval Loss:  0.16074451804161072\n",
      "Eval Loss:  0.24267128109931946\n",
      "Eval Loss:  0.1977018564939499\n",
      "Eval Loss:  0.27434030175209045\n",
      "Eval Loss:  0.2063031941652298\n",
      "Eval Loss:  0.1975541114807129\n",
      "Eval Loss:  0.16165068745613098\n",
      "Eval Loss:  0.1714293211698532\n",
      "Eval Loss:  0.13743937015533447\n",
      "Eval Loss:  0.21293918788433075\n",
      "Eval Loss:  0.1258527636528015\n",
      "Eval Loss:  0.21661856770515442\n",
      "Eval Loss:  0.2191448211669922\n",
      "Eval Loss:  0.21280604600906372\n",
      "[[17162   875]\n",
      " [ 1559  9864]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18037\n",
      "           1       0.92      0.86      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9173794976238968\n",
      "pre:  0.9185212775863675\n",
      "rec:  0.8635209664711547\n",
      "ma F1:  0.9119777445781709\n",
      "mi F1:  0.9173794976238968\n",
      "we F1:  0.9168732220575395\n",
      "29460 461\n",
      "Loss:  0.05298590287566185\n",
      "Loss:  0.03235854208469391\n",
      "Loss:  0.10329945385456085\n",
      "48 **********\n",
      "Epoch:  2777.785764694214  fold:  7  kers:  64\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.05679373815655708\n",
      "Loss:  0.0328705795109272\n",
      "Loss:  0.03197765722870827\n",
      "49 **********\n",
      "Epoch:  2821.6484849452972  fold:  7  kers:  64\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.06717775762081146\n",
      "Loss:  0.05942150950431824\n",
      "Loss:  0.07810244709253311\n",
      "50 **********\n",
      "Epoch:  2865.447375535965  fold:  7  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.5550234317779541\n",
      "Eval Loss:  0.0283499825745821\n",
      "Eval Loss:  2.047102689743042\n",
      "[[1934  193]\n",
      " [ 668  636]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82      2127\n",
      "           1       0.77      0.49      0.60      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.70      0.71      3431\n",
      "weighted avg       0.75      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7490527542990382\n",
      "pre:  0.767189384800965\n",
      "rec:  0.48773006134969327\n",
      "ma F1:  0.7071375440581338\n",
      "mi F1:  0.7490527542990382\n",
      "we F1:  0.7337139832170431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23635242879390717\n",
      "Eval Loss:  0.19338853657245636\n",
      "Eval Loss:  0.14372441172599792\n",
      "Eval Loss:  0.21346484124660492\n",
      "Eval Loss:  0.19764110445976257\n",
      "Eval Loss:  0.2948581278324127\n",
      "Eval Loss:  0.22736099362373352\n",
      "Eval Loss:  0.12105321139097214\n",
      "Eval Loss:  0.21783597767353058\n",
      "Eval Loss:  0.17697389423847198\n",
      "Eval Loss:  0.2042533904314041\n",
      "Eval Loss:  0.17295359075069427\n",
      "Eval Loss:  0.23225602507591248\n",
      "Eval Loss:  0.2102278769016266\n",
      "Eval Loss:  0.16234883666038513\n",
      "Eval Loss:  0.2343972623348236\n",
      "Eval Loss:  0.2046385109424591\n",
      "Eval Loss:  0.32434698939323425\n",
      "Eval Loss:  0.1782512366771698\n",
      "Eval Loss:  0.23880769312381744\n",
      "Eval Loss:  0.1412530243396759\n",
      "Eval Loss:  0.19697795808315277\n",
      "Eval Loss:  0.13596738874912262\n",
      "Eval Loss:  0.24229899048805237\n",
      "Eval Loss:  0.12530674040317535\n",
      "Eval Loss:  0.23089776933193207\n",
      "Eval Loss:  0.22122454643249512\n",
      "Eval Loss:  0.21545624732971191\n",
      "[[17290   747]\n",
      " [ 1654  9769]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     18037\n",
      "           1       0.93      0.86      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9184996605566871\n",
      "pre:  0.9289653860783568\n",
      "rec:  0.8552044121509236\n",
      "ma F1:  0.9128174788704182\n",
      "mi F1:  0.9184996605566871\n",
      "we F1:  0.91781441407491\n",
      "29460 461\n",
      "Loss:  0.08118724822998047\n",
      "Loss:  0.05728708580136299\n",
      "Loss:  0.06041863188147545\n",
      "51 **********\n",
      "Epoch:  2948.0016419887543  fold:  7  kers:  64\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.03735288232564926\n",
      "Loss:  0.031968649476766586\n",
      "Loss:  0.030689556151628494\n",
      "52 **********\n",
      "Epoch:  2991.805519580841  fold:  7  kers:  64\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.06999307125806808\n",
      "Loss:  0.044818878173828125\n",
      "Loss:  0.0337541326880455\n",
      "53 **********\n",
      "Epoch:  3035.613385915756  fold:  7  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.46274691820144653\n",
      "Eval Loss:  0.06209986284375191\n",
      "Eval Loss:  1.4738185405731201\n",
      "[[1837  290]\n",
      " [ 525  779]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      2127\n",
      "           1       0.73      0.60      0.66      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.75      0.73      0.74      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7624599242203439\n",
      "pre:  0.7287184284377923\n",
      "rec:  0.5973926380368099\n",
      "ma F1:  0.7374989873171268\n",
      "mi F1:  0.7624599242203439\n",
      "we F1:  0.7569156707494025\n",
      "Eval Loss:  0.24900886416435242\n",
      "Eval Loss:  0.2172471284866333\n",
      "Eval Loss:  0.12578460574150085\n",
      "Eval Loss:  0.17720219492912292\n",
      "Eval Loss:  0.19149036705493927\n",
      "Eval Loss:  0.27557894587516785\n",
      "Eval Loss:  0.20657280087471008\n",
      "Eval Loss:  0.11540798097848892\n",
      "Eval Loss:  0.19174449145793915\n",
      "Eval Loss:  0.15709084272384644\n",
      "Eval Loss:  0.1800379604101181\n",
      "Eval Loss:  0.1651432067155838\n",
      "Eval Loss:  0.17691177129745483\n",
      "Eval Loss:  0.18790842592716217\n",
      "Eval Loss:  0.15498903393745422\n",
      "Eval Loss:  0.19789846241474152\n",
      "Eval Loss:  0.17856253683567047\n",
      "Eval Loss:  0.30558741092681885\n",
      "Eval Loss:  0.19585788249969482\n",
      "Eval Loss:  0.2123466432094574\n",
      "Eval Loss:  0.13493090867996216\n",
      "Eval Loss:  0.17531758546829224\n",
      "Eval Loss:  0.12324105203151703\n",
      "Eval Loss:  0.22008809447288513\n",
      "Eval Loss:  0.12476038932800293\n",
      "Eval Loss:  0.19714313745498657\n",
      "Eval Loss:  0.20987573266029358\n",
      "Eval Loss:  0.20477822422981262\n",
      "[[16918  1119]\n",
      " [ 1132 10291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18037\n",
      "           1       0.90      0.90      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.923591310251188\n",
      "pre:  0.9019281332164768\n",
      "rec:  0.9009016895736671\n",
      "ma F1:  0.9195187929554192\n",
      "mi F1:  0.923591310251188\n",
      "we F1:  0.9235833213082507\n",
      "29460 461\n",
      "Loss:  0.05635185167193413\n",
      "Loss:  0.03460199758410454\n",
      "Loss:  0.057094819843769073\n",
      "54 **********\n",
      "Epoch:  3118.094847679138  fold:  7  kers:  64\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.08996520191431046\n",
      "Loss:  0.0498025044798851\n",
      "Loss:  0.06754395365715027\n",
      "55 **********\n",
      "Epoch:  3161.8259196281433  fold:  7  kers:  64\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.06624741852283478\n",
      "Loss:  0.0636296346783638\n",
      "Loss:  0.0739930272102356\n",
      "56 **********\n",
      "Epoch:  3205.5490131378174  fold:  7  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.45735102891921997\n",
      "Eval Loss:  0.04551505297422409\n",
      "Eval Loss:  1.5093995332717896\n",
      "[[1817  310]\n",
      " [ 521  783]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81      2127\n",
      "           1       0.72      0.60      0.65      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.75      0.73      0.73      3431\n",
      "weighted avg       0.75      0.76      0.75      3431\n",
      "\n",
      "acc:  0.757796560769455\n",
      "pre:  0.716376944190302\n",
      "rec:  0.6004601226993865\n",
      "ma F1:  0.7336012120413675\n",
      "mi F1:  0.7577965607694549\n",
      "we F1:  0.7528592120444777\n",
      "Eval Loss:  0.24595299363136292\n",
      "Eval Loss:  0.20957747101783752\n",
      "Eval Loss:  0.13903716206550598\n",
      "Eval Loss:  0.18350060284137726\n",
      "Eval Loss:  0.1980394423007965\n",
      "Eval Loss:  0.2718347907066345\n",
      "Eval Loss:  0.21417398750782013\n",
      "Eval Loss:  0.11316300928592682\n",
      "Eval Loss:  0.19773167371749878\n",
      "Eval Loss:  0.17660918831825256\n",
      "Eval Loss:  0.16935314238071442\n",
      "Eval Loss:  0.18316596746444702\n",
      "Eval Loss:  0.17352169752120972\n",
      "Eval Loss:  0.1979290246963501\n",
      "Eval Loss:  0.15209344029426575\n",
      "Eval Loss:  0.20731741189956665\n",
      "Eval Loss:  0.1947479099035263\n",
      "Eval Loss:  0.2732726037502289\n",
      "Eval Loss:  0.19628749787807465\n",
      "Eval Loss:  0.20417097210884094\n",
      "Eval Loss:  0.13017791509628296\n",
      "Eval Loss:  0.15271589159965515\n",
      "Eval Loss:  0.12714937329292297\n",
      "Eval Loss:  0.20650164783000946\n",
      "Eval Loss:  0.11703114211559296\n",
      "Eval Loss:  0.20568792521953583\n",
      "Eval Loss:  0.2019067406654358\n",
      "Eval Loss:  0.19952909648418427\n",
      "[[16890  1147]\n",
      " [ 1074 10349]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18037\n",
      "           1       0.90      0.91      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9246096401900883\n",
      "pre:  0.9002261656228253\n",
      "rec:  0.9059791648428609\n",
      "ma F1:  0.9207003862247336\n",
      "mi F1:  0.9246096401900884\n",
      "we F1:  0.9246532689226169\n",
      "29460 461\n",
      "Loss:  0.048765573650598526\n",
      "Loss:  0.05190188065171242\n",
      "Loss:  0.029797276481986046\n",
      "57 **********\n",
      "Epoch:  3294.8123409748077  fold:  7  kers:  64\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.03834706172347069\n",
      "Loss:  0.04736512526869774\n",
      "Loss:  0.07107751071453094\n",
      "58 **********\n",
      "Epoch:  3338.706975698471  fold:  7  kers:  64\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.027892448008060455\n",
      "Loss:  0.0545811727643013\n",
      "Loss:  0.06804028153419495\n",
      "59 **********\n",
      "Epoch:  3382.5906393527985  fold:  7  kers:  64\n",
      "Eval Loss:  0.5204684138298035\n",
      "Eval Loss:  0.031759291887283325\n",
      "Eval Loss:  1.6252621412277222\n",
      "[[1958  169]\n",
      " [ 634  670]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83      2127\n",
      "           1       0.80      0.51      0.63      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.72      0.73      3431\n",
      "weighted avg       0.77      0.77      0.75      3431\n",
      "\n",
      "acc:  0.7659574468085106\n",
      "pre:  0.798569725864124\n",
      "rec:  0.5138036809815951\n",
      "ma F1:  0.7275642385301742\n",
      "mi F1:  0.7659574468085105\n",
      "we F1:  0.7520965447515026\n",
      "update!  Acc:  0.7659574468085106\n",
      "Epoch:  3386.6996533870697  fold:  7  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA11UlEQVR4nO3deXhU1fnA8e+bhB3CGtYAAQkiiihEQBE3UFlsqdZWrVZra5H+RKWtteDe1rZqrXWplVK01qWiolUUBPcFlSXsOwaIENaw71nP74+ZSSYzd2buTGa9836eh4eZe8+9c24mee+5ZxVjDEoppZwrI9EZUEopFVsa6JVSyuE00CullMNpoFdKKYfTQK+UUg6ngV4ppRwuy04iERkJPAFkAtOMMQ/57O8D/BsYANxtjHnUa98vgZsAA6wEbjTGnAj2ee3atTN5eXlhXIZSSqW3xYsX7zHG5FjtCxnoRSQTeBq4GCgBFonITGPMGq9k+4DbgO/5HNvFvb2vMea4iLwGXA08H+wz8/LyKCwsDJU1pZRSbiLybaB9dqpuBgFFxphNxphyYDow1juBMWa3MWYRUGFxfBbQRESygKbAdts5V0opVW92An0XYKvX+xL3tpCMMduAR4EtwA7goDHmfau0IjJORApFpLC0tNTO6ZVSStlgJ9CLxTZb8yaISGtcpf8eQGegmYhcZ5XWGDPVGFNgjCnIybGsZlJKKRUBO4G+BOjq9T4X+9UvI4DNxphSY0wF8CZwTnhZVEopVR92Av0iIF9EeohIQ1yNqTNtnn8LMEREmoqIAMOBtZFlVSmlVCRC9roxxlSKyARgLq7ulc8ZY1aLyHj3/iki0hEoBLKBahGZiKunzQIRmQEsASqBpcDU2FyKUkopK5KM0xQXFBQY7V6plFL2ichiY0yB1T7HjYx9Z/l2Dh6z6uWplFLpydbI2FRRtPswt76yFICNfxpNZoZVhyGllEovjirRj3js85rXP5jyFRVV1QnMjVJKJQdHBXpvS7Yc4HfvrE50NpRSKuEcG+gBXpq/JdFZUEqphHN0oFdKKaWBXimlHM/xgV4bZJVS6c5RgX7Chb38tr21dFsCcqKUUsnDUYH+qrO6+m37zYwVzFhckoDcKKVUcnBUoO/apqnl9jteXx7nnCilVPJwVKBXSinlL20C/YA/fMCL8wMuqaiUUo6VNoF+39Fy7n1rVaKzoZRScee4QD95VJ9EZ0EppZKK4wL95WfaWrdcKaXShq1ALyIjRWS9iBSJyCSL/X1E5GsRKRORO3z2tRKRGSKyTkTWisjZ0cq8lfbZjWN5eqWUSjkh56MXkUzgaeBiXAuFLxKRmcaYNV7J9gG3Ad+zOMUTwBxjzJXuNWet+0AqpZSKCTsl+kFAkTFmkzGmHJgOjPVOYIzZbYxZBNRZ2klEsoHzgGfd6cqNMQeikXGllFL22An0XYCtXu9L3Nvs6AmUAv8WkaUiMk1EmlklFJFxIlIoIoWlpaU2T6+UUioUO4Heaj0+uyuKZwEDgGeMMWcCRwG/On4AY8xUY0yBMaYgJyfH5umVUkqFYifQlwDek8jkAtttnr8EKDHGLHC/n4Er8CeE6BKySqk0ZCfQLwLyRaSHuzH1amCmnZMbY3YCW0XkZPem4cCaIIfElAAl+49xpKwyZp+x72g5D89ZR1W13YcepZSKrZCB3hhTCUwA5gJrgdeMMatFZLyIjAcQkY4iUgL8CrhHRErcDbEAtwIvi8gK4AzgTzG4jjquCNCXXkQ49+FPuPKZr2L22fe9vYpnPt3Ix+t2x+wzlFIqHCG7VwIYY2YDs322TfF6vRNXlY7VscuAgsizGL5LTu3Im0HmoV+383DMPrus0rXQSbVJvhJ9vwfm0r1tU969dViis6KSzImKKsoqqmnZtEGis6JiwHEjYwEu6dvBcrvTquiNMfzj0yJ2Hz5hK/3hE5Ws2nYoxrlSqeiqf35N/9+/n+hsqBhxZKDPyLAO6ZUOqzdfte0Qj8xZz8TpyxKdFZXilpccTHQWVAw5MtDHypxVO/n5C4VB08Szxqay2lVNdLS8Kn4fqpRKObbq6JXL+JcW207rtGoipVTq0hK9Uko5nAb6JHXdtAX86rVlic6GUsoB0jbQbyw9kugsBDWvaA9vLgncRVQppexybKC//uzuQfd/syvyQB/8JuGsnj0qenYePMENzy3k0ImK0ImViiLHBvrffffUmJ376qnzQ6YRnVhH+Xjy42/4bEMpM5fZnSpKqehwbKCPZaAtq9DujEqp1OHYQO90e4+UsXnP0aBpLv3b5zz+4YY45Ugplay0H30EgtXCx2vA1LkPf8LxEE8W63cdZv2uw0wc0Ts+mVK2aCuOire0LdFXVlezqHgfZZVVFO0O3TC7/cDxsM4f6xr6UEE+2hZu3seGXbGbDC4daKuNSpS0LdE/PGcdW/cdJ799c77ZfYRp1xcwqGcbshtbz973ts0GNKeW1n74z68BKH5oTIJzopQKV9qW6Lfuc5XQv3GX5m96oZCLH/usZv/BYxXkTZrFuyv8A/zhE5VM+2JT0PPHtdNNEk6JrJRKHrYCvYiMFJH1IlIkIn5rvopIHxH5WkTKROQOi/2Z7sXB341GpmNl16GymmqczXtdDZ3/+tw6oD84a63lds8MmX+Zu95v34ZdhzmuE5ApvTGrOAsZ6EUkE3gaGAX0Ba4Rkb4+yfYBtwGPBjjN7bhWp0p6106z7iNvAlTKfLv3KKOf+IL9R8uB2q6XvoubHC2r5JK/fc5t05dGnLcbnlvI3NU7Iz5eJZYOrVCJYqdEPwgoMsZsMsaUA9OBsd4JjDG7jTGLAL8hfyKSC4wBpkUhvzEX7lqvz3y6kTU7DjEnRAAud688tah4X8R5+2xDKTe/aH8GTW///nJzxJ+rlEptdhpjuwBbvd6XAIPD+IzHgTuBFmEckzB7jpSTN2kW3+3fOdFZiarfvZOwNdmVUglmJ9BbPXDaKvaKyGXAbmPMYhG5IETaccA4gG7dutk5fUzNXB69Yer/+aqY5SUHonY+ldq0hl7Fm51AXwJ09XqfC9iNgkOB74rIaKAxkC0iLxljrvNNaIyZCkwFKCgoSJq/hbLKav4ydx2ZFhWsS7fs99tmlfH7Z66OQc5UqhHtSa8SxE4d/SIgX0R6iEhD4Gpgpp2TG2MmG2NyjTF57uM+tgryyWzdzsM8/clGplj0vrn8H1/VvJ785kqKdh/W4locLP52P0Z7rihlW8hAb4ypBCYAc3H1nHnNGLNaRMaLyHgAEekoIiXAr4B7RKRERLJjmfF4q6iqDplm5vIdcchJevtgzS6+/8xXvLxgS6KzolTKsDUy1hgzG5jts22K1+uduKp0gp3jU+DTsHNYD2P6dWLWyugEX8G6sL7r0InaNzZKmQeOVVBRVU2DzLQdq1YvW/YdA5Jr4Zg9R8qYuWw7Nw7NszVrqj6MqHhzdLRplBX7y/tkfWnYx9z39qqwj/l2b/CZKlXi3D59Kb9/d43f2Alf2o9eJYqjA3002e1eH2hglbdP15cyZ9VOToQxMdnKbQcD7lteEnifsmdlyUFWBfkZB3PwuGv4SGWVFtVVcnJ0oL9yYNDapKiz+2e+4+AJxr+0mIfeWxfT/DhZtKs/vvP3eVz21LzonlSpJOHoQH9Or3Zx/byX5n8bVgAq2W9/6uNQ5y2rrGJbgKmUxz79pf1M2XTwWEVC1j51Qu2H9hhS8eboQB9v+48lbtHnO15fwdCHPrasDlq+9UDUP6//79/n9Afej/p5ncwJNymVmjTQO8THa3cBtbNnKqXqOnisgn98WlTzRPVa4Va2untxOZ0G+iiLRZh9ZM46PnQH8mgqLN5H3qRZKdWjJ5l7rthpiHelU4lwz9ureGTOeuYV7aGyqpo7Z6zgyilfhT7QAdJ2halU8o9PN9Z5/1rh1gAp7dl7pIy2zRvxxpISAL4s2kv3ts3qdc548cT5ZKrntju1gZ0+9ip2jrjblCqqqmtutnuPlCcuQ3GkJfok8Nj76zn5nvdsp79zxop6fd7ABz9kzqqdlFWEHu3ra+Tjn3OVe1lBFVtLtuxnfYi++cH85vXl/Oer4uhlSKUsLdFHWSQlzSc/LopBToIb/1Jk89qHGhQUjrxJs7h2cDf+eHm/qJ0zFdj9FbnCPZdSpOv0vr64hNcXl3DDOXkRHa+cw/El+njPK69toeGJdM6aVP4xp3Le082x8sqIB9IlE8cH+nhbFmZXxklv1K8axiNdetvYqef+74ItMRk7UF9aRZ8cwnnovuXlJVz21DyOlVfGLkNx4Piqm2QOf5XV1UxfVL+GVY+yyvDr253qrv+tjMp53lq6jZ45zTg9t5Wt9EnUPqwseBcS7H5Xhd+61pyoSPHpLbREn0CfRjAhWizY7RYYrsqqal5ZuCXsdXiTxcRXl/Hdv4d+MtCSeupKl+/O8YE+mbrhpaI/z15L3qRZER37/FfFTH5zJf9d8G2Uc5XapedAv5P7jpZTnaI3xVRl9/do/9FyPlgT/bEs8eL4QN+2WcNEZyEh3ovSPPz/tFhZy679x1x9lD2zO0aDpwQWq6eQWArW3770cBkD/vABf/twQxxzlL7CLcn/9PlF/PyFwoTM7xQNtgK9iIwUkfUiUiQikyz29xGRr0WkTETu8NreVUQ+EZG1IrJaRG6PZubt6Nqmabw/so6vN+61nTZaTx8bdh3mFy8vCfu4VdsO8tbSbWEdU3q4LOzPqQ+nPml7fo7JUmo8WlbJkbLUboCMCvefZLF79HhVitbVhwz0IpIJPA2MAvoC14hIX59k+4DbgEd9tlcCvzbGnAIMAW6xODamrh3cPZ4f5+fZeZttp928x/XL9MMpkQ9IWrh5Lzf9pzCiYy97ah4TX10W1jE3v2j/s37y74XkTZpFuTYcJ9xTH33DtdPmB9x/2gNzOe3+uXHMUfwYE37VX6qParZToh8EFBljNhljyoHpwFjvBMaY3caYRUCFz/Ydxpgl7teHca052yUqObepScPMeH5cHQs27eWT9bttp682sG7nIRYW74v4M3/6fGHNcnt2zVm1M+LP23fU/hByT+Pzi/OjX2fvkYhucKnYXvDXDzbwZZH10+b6nYeT4pryJs3iT7PXRu18VqE6xeO3bXYCfRfAuw9gCREEaxHJA84EFgTYP05ECkWksLQ0OXqj1NdVU+eH3ePk7WXb67yvzxB4u774Zg/Hy+2vdlVf4aysFYhVIHrw3TX0vc+/FPrzFwo54/d1p1ReWXKQo3GumggWVJKpzeHSxz9PdBZqTK1HG1EyKa+sTmjvMzuB3urXM6wci0hz4A1gojHmkFUaY8xUY0yBMaYgJycnnNOHNO36gqieL3b8f6yeicdirdonci7YtDcqAdnjjcVRuo4g0XJagGqyD9bs4oDXWgGHT1Twnb/P49ZXlsY6SxGcK02KmCkiWqG59z3vcdN/FkXpbOGzE+hLgK5e73OB7QHS+hGRBriC/MvGmDfDy150NIzDIuGpzvsXelPpEa6aOp/7314dtfP/L8xG3ljytBGEO4o5lBUl0T2fSh7RuP1+ksBxM3Yi4CIgX0R6iEhD4Gpgpp2Ti6t48iyw1hjzWOTZrJ9UKSQ9OneDXxXKzoMn4p6PA+7ukOt3xb7aKFLJU9FR616bN8ZkqP9WLunyXYScAsEYUykiE4C5QCbwnDFmtYiMd++fIiIdgUIgG6gWkYm4euicDvwYWCkiy9ynvMsYMzvqV+IAc1b7N4rOXG774aleoj2wrLraMO2Lze5zh66D3lR6hI2lR7m4bwce+2ADJ+U0Y+wZ/k1BtfPRRzW7cZEi5Q3Hi+RXJ9XnkrI11407MM/22TbF6/VOXFU6vuaRBL/fdheGSGfev8bhBtGNpUf435JtLN26n5dvGgLAOyu2hzX/zkV//QxwTcn75EffANQJ9PuOlnPuwx8z6rRO4WUuiGQaNZ1EWfFzoqKKrAwhKzO1q0CtnuxDPe37/o6kSu2AL8dPagap++Ukmt2f23B3kPbmXQX12YbSmsmhIrWoeB/Hyqvq1ThdVW2YuXwbw/Ijb+yvqKomK0Ni1miajL+qfe6dw6C8Nrw2/uxEZyWuKquqKa+qW1ixuiF7Oi00bpC4rtyhpPYt2qZk/ONJNrEsUdY3yANR6Zr2/FfF/PLV5bwa4YyhR8sqyb/7PR7/8Js628P9/UqmrpR21WdsRzQ99v56RjzmX7CIhUsf/9zWrJVn/P59TrlvThxyFLm0CPQa6eMv2qHMf2BW+J+w54hrmoH97nOFewZPI/XrEa7ZmwxPlsMe+ZihD31c877Pve+x90jsprEoq6xiQ5BG/XEvFDJrhf15mZ78uIii3UeCppnw3yXMtWjvCtfG0qO20p2oqE7qqjdIk0CvdfQ2mIBv7B8GTP18IxVV1bwXZLTt+p2HOXisfpND2RngVenz2L1ws6tU6h1wq6tNvUYGp5qt+46z7cDxmvcnKqpZsDl2pfV731rFJX/7nN2HrXuPvb9mF7f8N/x5mYJ5d8UObn5xccA2mGRqm4mXtAj0KjSr6oRIbo9/mr2OH0z5ms83BO4zPHP5di5/xnqe90ABYd3OuuPs9tqYemHnobrnWmxRhfRq4dY66+cGm6RtQpQDkpU1OyzHE/qZsbiEzzeUcsA9Q+iRskomv7ki7qN9Qyksdv3MD5+If77e9XpS2HbgOB+urZ2OJBWrz+pDA70CIq+j33fEP+DaGYi0yeux+Py/fFLz+p7/rfJL+9bSbbw0P7K1Za3864vaEbS+4xSsnhSqqw3//nIzS7cciMrn2/lZl+wPPl/RHa8v5/rnFnLG7z/gREUVUz/byCsLt/JcGJPoxUrxnqMxH/8x+okvWFkSfC3XrV4/w6iNzK6n3YdPUJiA9o60CPS5rZskOgspxROI7MwjfzgKJchv99b+Qb7vM03vt3uPWs6o6R0sjTHc81Z0lg+08s6K7fzunTU17yPpcbNg096gN4rrn1tY8/rtZds49+FPAqb19dL8b5NqUfoLHv2UIX/+iB0Hj4dOHKE1Ow5FdcKzWCjafYQek2dRvKe2UHPZk/O4sh6z00YqLQJ9u+aNEp2FpPeuxUIldhujYilQX3zvR+/Sw2UBS/zbDwQONgeOVdiaNO6ZTzcGT2Aj8F81dX7Q3kfejc3hPjn4zlN0rLwyrOmxY8W7+i4W1eJfb9ob8epnkQrnHv/mkhKMgVlef1u747x+g0daBPp0q4+LxL1v+VeZJFrepFm88HWx5b4vi/Yy7oVCdh48wfwgjYnXTbOcLLWG1Wjkr4r2cNGjn9a8XxflGUQ3lgbvNVJfj8xZzx/eXRM6YTxoP4ikkBYDplR4kum2GKxu/v01u1iweV/QKqY9EXQdfOCd1WzaE/hpZtuB4xhjLKtwAm339lphCY9c2T/sfAEcPFYRcjm7cJdudGonlFj0tkvVn1V6lOhT9MtJlFT6eUVzPVqw/2geqEpJRDhWXknepFlhL8toJw+XPP4Zwx7xr7/Xp9bAjpZV8tgHddfijfR3PNhhXxbtsZ023tIi0KvwJGM1TrwMe+QTNuwKs2rFJ2rscPc48czZE8r7PtVHwYLQrkPBn1CsbhJllVVR7Tt+rLzS1oCkuh+ZuLA3y6f9qdrAVxtdQTncUv+Pn3VVBb5euJU/v1e3Mdh3ZTc7P/K3lm5j9BNfhJWHSGigV36SeXriZHOioorlIbr5WfnjrDU1M5M+OCt475FwFqwoq6zmsE/Vzsn3zOG8v3wStdXK7v7fKm5+cTFrtofu8x+NypNor3724vxifvp8ZOsqr3Zf829mrOCfn9lb/SrYE9rEV5fZHjtRH2lRR98gxWfdU5GL2eRj7tO+srBuG8KdM5ZzvCL0rJ2evvzf7d85ZFrvgT6BFLu7qD71cZHl/q37jttaItAzACuYre6S65EIutZO+2ITS7bs5x/XDrR9zLkPf8ziey8OO+AH+uqL99SWvGNZ5ZVM1WlpEQEbZmWw9N6LE50N5UCVPpNevVZYwjvukvqmPUfJmzQr7AXLw703CRLWfDHBPDxnXcB9S7bsZ9W2g/Was+fBWWuZvTK8KSf2Hi1n/qa9AScOO+XeOTWrhiWjZJiCxVagF5GRIrJeRIpEZJLF/j4i8rWIlInIHeEcGy+tmzVM1EerBCmvrI56Y61HOH+8T35kXcoOJJGN4cFmCb3iH19x2VPzat576v2PlFVyrLzSrx2gPmsc+FoYpAvt8Yoqy55IiQ+vga3adpCyyuhWSQUTMtCLSCbwNDAK16pR14hIX59k+4DbgEcjOFapmPj5C5HVw0ZboLEAgXyz278ufd3OQ9z3dmwayb2rGHb6NPZ+4DNSGWBRcd2BX6fdP5e+983ln5/711kncrHz1zyzjPrcZEI1TO84eDzok41t7o+x+hFc9tQ8HpgZv7EOduroBwFFxphNACIyHRgL1OTSGLMb2C0iY8I9VqlYieXI3nDi17EQdcu+vTW+LNrrl+ayJ+fFZTk738nogt0sf/fOmjqT0D303jrO7dUuos/NmzSL4X3a8+xPzgL8g7Fv90g7NpYe5fkvN9O0YeAwZzXf/AV/+TSs1dEC8Zw50K9KPBeTt1N10wXwnoC7xL3Njvocq1TSilb1ytvL7PW1Dxbkq+qZmQn/XRrRcWt2HGKPz6R2KyLogeTx0brQjc7heuCd8MuU0QjyycZOoLe6Idn9zbJ9rIiME5FCESksLQ08xa1SySBadf+3T19W73NM85qNM1kZ6naTPHSiwnKemsMnKiKqu/5wza6AN813Vmz3y4u3HQeP87PnF0XUiyiYZJr33k6gLwG6er3PBbYHSBvxscaYqcaYAmNMQU5O5Gt6KhVPB46H7o4Ya5FM8xAPxtQt6T36/vqa11v2Wk/D3O+B9/lBBLM7TnpzZcCb5hff1B2x6jsJ3F/f38BH63Yze+WOOnMcRWLVtoNcN21BnZuVnWq+WM9/ZKeOfhGQLyI9gG3A1cCPbJ6/PscqlbQOnajgrD9+mOhsJJ1Ay/xd8re6ffgXBZmTvT7VP3YEG10cbI6jUP63ZBuT33RNl33yPXPo0sr+9OjD//oZxQ/5NnFGT8gSvTGmEpgAzAXWAq8ZY1aLyHgRGQ8gIh1FpAT4FXCPiJSISHagY2N1MUrFy0+ftz9aNZ0896W9aqTfRVB3nozmrKodv+C7gLpnycZAC4z7lvRjuaSlrZGxxpjZwGyfbVO8Xu/EVS1j61ilUt23AaoeVK1EjAx9+pPwxiyAf1VOOKwWxfH1l7nrLbf7PlmMf2kxL/1sMOfmR9ZzKZi0GBmrlIq/1wrjv3xfoKAazJtLXI243+4Nv9rmhI3pLgKxWp/4mc/Cv1HZoYFeKRUTq7bFtq492nbYXOe2sip23S+txlBEgwZ6pVRMVFWbpO0RZMV33qJAet39XoxzEn1pFehfHTck0VlQKq3sPxbZeIOvN8WmZBuMZ9poJ0qrQD+4Z9tEZ0EpZcOP/hV8rV8VnrQK9AAtmzRIdBaUUiqu0i7QK6VUutFAr5RSDpd2gb5fl5aJzoJSSsVV2gX6Z64bkOgsKKVUXKVdoG/RWBtjlVLpJe0CvVJKpZu0DPQTLuyV6CwopVTcpGWg79amaaKzoJRScZOWgV4ppdKJBnqllHI4W4FeREaKyHoRKRKRSRb7RUSedO9fISIDvPb9UkRWi8gqEXlFRBpH8wIikYgFEZRSKlFCBnoRyQSeBkYBfYFrRKSvT7JRQL773zjgGfexXYDbgAJjzGlAJq51Y5VSSsWJnRL9IKDIGLPJGFMOTAfG+qQZC7xgXOYDrUSkk3tfFtBERLKApoBz5wJVSqkkZCfQdwG2er0vcW8LmcYYsw14FNgC7AAOGmPet/oQERknIoUiUlhaWmo3/xGpxxKRSimVcuwEerHY5hsqLdOISGtcpf0eQGegmYhcZ/UhxpipxpgCY0xBTk6OjWwppZSyw06gLwG6er3Pxb/6JVCaEcBmY0ypMaYCeBM4J/LsRocW6JVS6cROoF8E5ItIDxFpiKsxdaZPmpnA9e7eN0NwVdHswFVlM0REmoqIAMOBtVHMv1JKqRCyQiUwxlSKyARgLq5eM88ZY1aLyHj3/inAbGA0UAQcA25071sgIjOAJUAlsBSYGosLUUopZS1koAcwxszGFcy9t03xem2AWwIcez9wfz3yGHU5zRslOgtKKRU3aTkydvgp7XnuJwWJzoZSSsVFWgZ6EeGiPh1q3vftlJ3A3CilVGylZaD3JVadQ5VSyiE00AODe7RNdBaUUipmNNADrZrq8oJKKefSQK+UUg6ngR6d+0Yp5Wwa6JVSyuE00CullMNpoFdKKYfTQK+UUg6ngR5dQ1Yp5Wy2JjVzqjd+cTYl+4+zec/RRGdFKaViJq1L9AO7t2HsGb6rIiqllLOkdaAPZMzpnUInUkqpFKGBXimlHM5WoBeRkSKyXkSKRGSSxX4RkSfd+1eIyACvfa1EZIaIrBORtSJydjQvQCmlVHAhA72IZAJPA6OAvsA1ItLXJ9koIN/9bxzwjNe+J4A5xpg+QH+ScM3YAd1aA9CvS8sE50QppaLPTol+EFBkjNlkjCkHpgNjfdKMBV4wLvOBViLSSUSygfOAZwGMMeXGmAPRy350nNc7hyX3Xsz5vXP89g3s3joBOVJKqeixE+i7AFu93pe4t9lJ0xMoBf4tIktFZJqINLP6EBEZJyKFIlJYWlpq+wKipU2zhrWvm7pe/+zcHrzxi3PinhellIomO4Heav0l3xFGgdJkAQOAZ4wxZwJHAb86fgBjzFRjTIExpiAnx79kHQ8ntXfdg87q0YZ5v72QyaP6JCQfSikVTXYGTJUAXb3e5wLbbaYxQIkxZoF7+wwCBPpk8L0zupDXthlndG2F6PqCSimHsFOiXwTki0gPEWkIXA3M9EkzE7je3ftmCHDQGLPDGLMT2CoiJ7vTDQfWRCvz0SYinNmttQZ5pZSjhCzRG2MqRWQCMBfIBJ4zxqwWkfHu/VOA2cBooAg4BtzodYpbgZfdN4lNPvuUUkrFmK25bowxs3EFc+9tU7xeG+CWAMcuAwoiz2Jy6tSyMTsOnkh0NpRSKiQdGRuhrycPT3QWlFLKFg30SinlcBrolVLK4TTQK6WUw2mgV0oph9NAb8NvLj2Z127WSTeVUqkprZcStOuWC3slOgtKKRUxLdGH4ZRO2XXe/3xYD0b365ig3CillD0a6MMw/edD6ry/e0xf/nHtwJr3fX1uBAB9OraIeb6UUioYDfRhaNm0QdD915/dnXcmnFtn21u3DPVLd5nFmrQPfu+0+mVOKaUC0EAfZf1yW7LygUuCphl+Snu/bQaYddu5/oltuHFoXkTHKaXSgwb6KOqX61qKsEXjuiX/YfntbB1/aufIljJs0iAzouOUUulBA30UBQrUY8/wXZDLgvFdy8W+yI9USqUDDfQx0r5FIwAyM/zntheLBbl65jSP+LPqcY9QSqUB7UcfI1/89kL2HCmnQWbtvXRYfjvGn38SpYfL6qT96Nfnc1I9Ar1W3SilgrFVoheRkSKyXkSKRMRvKUD3ylJPuvevEJEBPvsz3YuDvxutjCe7RlmZdGnVBKhdUDeneSOG9vKvr/cO8p4nAY9/XV9AK4vePr8c0bvmtVXjrlJKeYQM9CKSCTwNjAL6AteISF+fZKOAfPe/ccAzPvtvB9bWO7cpylN941miMNhKhe/cei5XDsyteZ/dOMuvaubawd24fUR+zXvf8w3t1Tbg+W8+v6fldrsNxkqp1GOnRD8IKDLGbDLGlAPTgbE+acYCLxiX+UArEekEICK5wBhgWhTznVJG9+vET87J4+4xp/jtu+OS3nXed8huzDWDulme5/bhruDuG9jDqaOfPMo/D00bZtK1TVP7J1FKpRQ7gb4LsNXrfYl7m900jwN3AtXBPkRExolIoYgUlpaW2shW6miYlcED3z2VNs0a1tn+nf6dmXBRvl/6gd1b07yRq/nEAO2aN6w5j7fTcyPrjmlFG3SVci47gd6qosE3LFimEZHLgN3GmMWhPsQYM9UYU2CMKcjJybGRreTRIDNIXUyE+naunU7hpZsG88j3T6dF47pt56/8fAjzfnuh37E/LOgawSdqpFfKqewE+hLAO3LkAtttphkKfFdEinFV+VwkIi9FnNskNWfiefz1B/1jdv5OLZvww7Nqf7ye7pnNGmWR27q2yuXUztkU3jPCXr99L8ZQ8wQRDY2ytNeuUsnEzl/kIiBfRHqISEPgamCmT5qZwPXu3jdDgIPGmB3GmMnGmFxjTJ77uI+NMddF8wKSwUk5zfm+VwNqKFkZrh+7nScBO1Uq3mnaNXf12unRrlmdNDcOzavpBeRR0L01AN3aNCW/vWvyNat5eHx1bdMk6H6rsQOBrAgxXYRSqv5CBnpjTCUwAZiLq+fMa8aY1SIyXkTGu5PNBjYBRcC/gP+LUX4d4dJTO3Dz+T257zLfzku1rEJlq6auuvocny6YNcd4HfTJHRfU2XfbRfl8OemiOttuHNoDgJ45tTeFJg0y+eCX5wXJPcy5/TwW3T2C924fFjLvH/7qPM7s1irgubIbB58oTilVf7ae140xs3EFc+9tU7xeG+CWEOf4FPg07Bw6UFZmhmXvl1C+c3onqqqruez0znW2mwjq168cmBuwm2d+hxb0z23J8pKDfvvat2hEs0ZZNGuUFfCGMyw/hzmrdwLQq71O06xUounI2CT10PdP59G56xnorl4BVz/8y88MXEVkNbWCleKHxgAwe+UOILweN6GSvvizQQzu0Zbe97xXs817dLDH4B5tImw0VkqFS1vNklSPds14+toBfl0qrTRt6JoCIbd14LpzqwAd7Lbwy4tr+/cP6dmm9jw+J7qoT91RuXltm/nl+Ymrz/DrMTTytI4B2zU6ZFs/KSilIqOB3gF6tW/BM9cO4JErT4/aOS84uT3FD41h4d3DecVnZS1vvlM2eAZevX3LUOZMdNXhd2rZhEmj+tj+7GYN7T1o3v+dwG0cgVxwcmp13VUqGjTQO8Sofp385sH3ZmzWz/imat+icc3UDdYprPXv2oo+HWvHAnjydnpuS87u2ZYrglRB2ayBqmlMDkegU//igpPCPpdSqUIDvYM9f+NZQfdnuLtBZmWK7eAaqcv6deJPl/fj9fFn88q4IZbLMl43pBvP3lAQk6xcFaI9wNMtNRwTLuwVaXaUiisN9A52wcnt/aZd8Da8T3vGndeT33331JDnymvrqpJp2aRugL5uSPea1w0tGl09MjKEHw3uRqOswFMqF3Rvw/BTOoTMSzDv3T6Mty3W6b30tMDn/dtVkQ12u3qQNiar1KCBPk1YVbhkZWZw1+hTaGujNDvrtmGM6deJl24aXGf7aV1asv7BkfXK29gz6nYXlWDTewZR/NAYTumUTf+urVj3B/t5uvzMXMunCN9BZ75ERBuOVUrQQO9wngBW30nLmjXK4ulrB9CppX/Pnkx3YD4/Sg2d44bVnUp54oj8sKdoaNwgs2bO/i/u9J8PKJRLT+3Au7cGX6xdgI7Zjets2/Sn0X7ptIpHJZoGeoezWzge0sM1h/33B9ifysEjKzODL+68kKeuOTPsY614z+sDMHFEbz769fkAnJXX2uoQS7ePyKf4oTF0bdO05gbVv2srW8e2a+4aGBaM1c82w2L6h0ADy6x0bll74wjUq8iqaipVxWJCQOVPB0w53GM/PIPHPthAa4vGT2/d2jatGUgVifrMZ3/XaNco4ZGndQyYpkN2Y76480I6tWxM8d5jFBbvC+szTumUzdyJ59GrfXMe//Abv/12boiPfP907nxjRe0xCF1aN7EcQeytY8vGQffXzUdtRnzbQwAmj+pj+2aVCr7542jyJs1KdDYcT0v0Dnde7xzeumUoWUEaShOtQ3Zjnrj6TBpbrH1b9MdRNa+7tmlKVmYGvdo35+oAi7MEc3LHFmRmCH++op9f///BPequyuWJtz85J69mm++Thkjo3jrFD42pGdBmxVPaH39+bffOtkEa0C/r72rP+Pmw2q6loW7ikVr9u0ttp7W6Kankkbx//UqB7RvUgruG2z7nNYO6sfDuEXW29e2czbu3nlvTu8jjpPZ1F20f0692ds9gPZrsuOLMLjVtJxf3re0V5NucEmrxd6sbpMeAIBPKBZOVISGrrlT0/dens0O0aKAPU6gpelV8/femwTxz7QA6ZNuvHgnktC4t+dm5rpKyZ94gT48gz5iEp6+tXfe+QWZG0EbupfdeDATudnrJqd5dPl0n8q5C8rwu8GqXCFbat/L6+HNqViiLpQg7SgXk2xMrUuHma+SpgasP46F9jHpxaaAP0+zbhvH15ItCJ1RxcU6vdozqF3oOfStWN+0rB3blqoKu/Nq9lm924wYUPzSGC05u75c2lNbuoDyoRxsmj+pT09D964t78/uxp3LpqR35yTmucQjNG7mqPkTgDHcdfM92rqeJs0+qrVbylN7tdkHNzBC/BvaC7vYbtANZeNdwXh9/dr3PE8hpne0vkxloHMj3LG4WMycMrVmC8wGLxu4pPx7IPRZrO4dyTZKPqdBAH6YWjRtYdjFUqefjX1/gNwagScNMHr7y9Jq5/6383wUnBa2b/+ePB9YZlSwi3Hz+SbRy16U3aZjJ9WfnISJMuMjVM8hTz35STnOeuuZMZk4YSv+urfhq0kX84vz6Tc/w25F15xma8Ytz6nW+Ph1b0D67MWfltQmdOAbO651Tp4fXDV7tKN4ev/pMnv7RgDrbTs9tFfIm6b2M53gbP/sZ48/mz1eEN8/U7NuG2RqoGC1aCaeS0hu/OIeyiqqYfobV9Ml23DmyD3eO9J+k7VP3Yi+XRvD43z67MS/8dBBndGtFs0ZZnJ7bCoDOrUIXKi7q056XF2wJuN+qy6fH+b1z+GxDadDzn9o5m9XbDwHuBe0txgV0zG7MgWMVftsv7tuBD9bssjyv5waU27oJJfuPB80DuMZTXNy3A306ZlNRVR0yPbhWTwvEU+t2em5LVnj1nPKe7nvSqD5M+Wyj37FjTu/ErBWuab4jqbbq2zmbcpvXEA22ftNFZKSIrBeRIhGZZLFfRORJ9/4VIjLAvb2riHwiImtFZLWI3B7tC1DONLB7a87p1S7R2QhLXoiRtKGc1zsnohW3+nbOpvihMcydGHhlsEgbZYsfGsMTV59R8/6pa87k5I61i8l4qr8e/UF/GmZl8NOhPZj32wtp4W7IPa+3axBd/9yW/Ntn7qXB7umvQ1XTeNo48tu34NTOLcnMkKAN0N7sBGHfEr6dlTD7dbFftZQMQgZ6EckEngZGAX2Ba0TEt3JrFJDv/jcOeMa9vRL4tTHmFGAIcIvFsUqlhavO6opIZCV+X55Y1Kppg5oJ27Lcg4+sGn/f/D/rQVaBnhh8u5IGcmlf17V0bd2UDQ+O4r7v9CW3dVM6tWpcJ59ZmRlcGKCdI9QKaSP6ht8+EsxjP+zPFQO61NTV+wZ2O1Wz44b19Fp3wXWCP1/Rj7dsDGarz3iVSNmpuhkEFBljNgGIyHRgLLDGK81Y4AX3koLzRaSViHQyxuwAdgAYYw6LyFqgi8+xSqUsOwvDePTu0ILNf47OH/ktF/Xi0IkK7r2sr18X1NzWTdi052jQ4z/7zQUcr6gir20zhvZqy8DurbnhuYVs2HWEf//kLM7vbW86i8mjT+EXF5zkNxuppzdSsBK1J413z6W2zRqy92g5ACflNGNjafDr8PXazWcz7YtN/Giw/zgLT4A9Kac5j/3wDKqrDT8d2oMbh+Yx7JFPatJ1a+tf3VPQvTWF3+4HXOMWMjKEUztns3TLgZo010QwtiNe7AT6LsBWr/clgG9nT6s0XXAHeQARyQPOBBZYfYiIjMP1NEC3bsn7A1PK28QR+Tw7b3PMP6d726Z1+u1nN24QdgNg3fPVVjN51iAe3a8TG3Z9Q492zerU63dr04wO2Y249aJ8v/NkZojlpHie2N3a3ajdK8fVg6h9i0bsPlxmmXbKdQMpLN7HNPfPc8b4c9i6/xiNG2SycfdRzs0PXZU3qEcbBvXwbyQ+pVO237aMDOE+d8+bR3/Qn74+aa44swsA8ycPp2WTBpxy3xwAXr3Z1duovvNHxZOdQG91T/a9xKBpRKQ58AYw0RhzyOpDjDFTgakABQUFKfQjVOks2GIv0fTZb8KfmM1Xu+YNg04lfdtF+Vw5MJfc1nVLtA2zMlhw14gAR1nzLHST3745/71pMAPcXToX3j2Cy//xZZ2ScKDSf+tmDWu6qM79pX/7w29H9uEcr66nLSwGeHmqYay6Wnq70mdZy3V/GFnTWO87hUXvDnUXvPfN9z1jTuHBWWsB+NPl/bjrfysB19xFVj2VurRqQuMGGWE/vYTDTqAvAbwr7HKB7XbTiEgDXEH+ZWPMm5FnVanktPCu4XHtQRGpRXcHD9YZGeIX5CPlKamJEKRRvW55LtzOK96rgq144BKyLFpR2zRryIYHR4U9eZpVY2+zhpkcLQ/dE+ymYT05Xl7FXz/YwI8Gd6sJ9L4ronly1LZ5Q46WVYaVv3DZCfSLgHwR6QFsA64GfuSTZiYwwV1/Pxg4aIzZIa7m7GeBtcaYx6KYb6WSRvsojMqNh0jn+Y9I7fO8fz583k8adTL7j5UztFc7Fm4Ob7I6j2C9lcJpRwlmzsTzWLujtkLi+wO6sGzrAbpa3BxvHZ7PrcNdVV3L77/E7gqcMRMy0BtjKkVkAjAXyASeM8asFpHx7v1TgNnAaKAIOAbc6D58KPBjYKWILHNvu8sYMzuqV6GU8mNVLx0v3iV6X3eNPoVfv768Jn+92rfgjXoO4oqHrm2a1pml9boh3bl2cPeg4xQgOSZ8szVgyh2YZ/tsm+L12gC3WBw3j5ivRqqU8vXVpIsSGmA8dfRWf/wFeW0CtjlccHJ7ps3bzFkWDarJRkSiPsdPrOjIWKUcokurJjTMyuA3l55sa0RtLEVaTXRufjuK/jgqqafVjoWB3VuzsfRozBr3NdAr5RCNG2Sy4cFRoRPGwbQbCnhp/rch1921ki5BPtNd5dMoK4M/fO80bhzaIyqzsFoRk4SdQQsKCkxhYWGis6GUUjFjjOFvH37DjwZ1C2sVskBEZLExpsBqn5bolVIqAUSEX13cOy6flR7PSEoplcY00CullMNpoFdKKYfTQK+UUg6ngV4ppRxOA71SSjmcBnqllHI4DfRKKeVwSTkyVkRKgW8jPLwdsCeK2Ukmem2pSa8tNaXatXU3xliuAZmUgb4+RKQw0DDgVKfXlpr02lKTk65Nq26UUsrhNNArpZTDOTHQT010BmJIry016bWlJsdcm+Pq6JVSStXlxBK9UkopLxrolVLK4RwT6EVkpIisF5EiEZmU6PzYJSLFIrJSRJaJSKF7WxsR+UBEvnH/39or/WT3Na4XkUu9tg90n6dIRJ6USBftrN+1PCciu0Vklde2qF2LiDQSkVfd2xeISF6Cr+0BEdnm/u6WicjoFL22riLyiYisFZHVInK7e3vKf3dBrs0R351txpiU/wdkAhuBnkBDYDnQN9H5spn3YqCdz7ZHgEnu15OAh92v+7qvrRHQw33Nme59C4GzAQHeA0Yl4FrOAwYAq2JxLcD/AVPcr68GXk3wtT0A3GGRNtWurRMwwP26BbDBfQ0p/90FuTZHfHd2/zmlRD8IKDLGbDLGlAPTgbEJzlN9jAX+4379H+B7XtunG2PKjDGbgSJgkIh0ArKNMV8b12/bC17HxI0x5nNgn8/maF6L97lmAMPj9eQS4NoCSbVr22GMWeJ+fRhYC3TBAd9dkGsLJGWuLRxOCfRdgK1e70sI/mUmEwO8LyKLRWSce1sHY8wOcP2iAu3d2wNdZxf3a9/tySCa11JzjDGmEjgItI1Zzu2ZICIr3FU7nqqNlL02d7XDmcACHPbd+VwbOOy7C8Ypgd7q7pkq/UaHGmMGAKOAW0TkvCBpA11nKl5/JNeSbNf5DHAScAawA/ire3tKXpuINAfeACYaYw4FS2qxLamvz+LaHPXdheKUQF8CdPV6nwtsT1BewmKM2e7+fzfwP1zVULvcj4q4/9/tTh7oOkvcr323J4NoXkvNMSKSBbTEfnVK1Bljdhljqowx1cC/cH13kILXJiINcAXCl40xb7o3O+K7s7o2J313djgl0C8C8kWkh4g0xNUgMjPBeQpJRJqJSAvPa+ASYBWuvN/gTnYD8Lb79Uzgancrfw8gH1jofqw+LCJD3HWD13sdk2jRvBbvc10JfOyuL00ITxB0uxzXdwcpdm3uvDwLrDXGPOa1K+W/u0DX5pTvzrZEtwZH6x8wGleL+kbg7kTnx2aee+Jq4V8OrPbkG1f93kfAN+7/23gdc7f7Gtfj1bMGKMD1y7oR+DvuUc9xvp5XcD0GV+Aq5fwsmtcCNAZex9VAthDomeBrexFYCazA9cfeKUWv7VxcVQ0rgGXuf6Od8N0FuTZHfHd2/+kUCEop5XBOqbpRSikVgAZ6pZRyOA30SinlcBrolVLK4TTQK6WUw2mgV0oph9NAr5RSDvf/WttzfsifNtEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29817 3074\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29817 466\n",
      "Loss:  0.16914746165275574\n",
      "Loss:  0.17134691774845123\n",
      "Loss:  0.15388666093349457\n",
      "0 **********\n",
      "Epoch:  56.9716694355011  fold:  8  kers:  64\n",
      "epoch:  1\n",
      "29817 466\n",
      "Loss:  0.13265635073184967\n",
      "Loss:  0.12116890400648117\n",
      "Loss:  0.12353431433439255\n",
      "1 **********\n",
      "Epoch:  101.55047464370728  fold:  8  kers:  64\n",
      "epoch:  2\n",
      "29817 466\n",
      "Loss:  0.12687326967716217\n",
      "Loss:  0.1181505024433136\n",
      "Loss:  0.09802384674549103\n",
      "2 **********\n",
      "Epoch:  146.13526368141174  fold:  8  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.24969588220119476\n",
      "Eval Loss:  1.1867276430130005\n",
      "Eval Loss:  0.2430168241262436\n",
      "[[1903  170]\n",
      " [ 430  571]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.86      2073\n",
      "           1       0.77      0.57      0.66      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.79      0.74      0.76      3074\n",
      "weighted avg       0.80      0.80      0.80      3074\n",
      "\n",
      "acc:  0.8048145738451529\n",
      "pre:  0.7705802968960864\n",
      "rec:  0.5704295704295704\n",
      "ma F1:  0.7596951865554382\n",
      "mi F1:  0.8048145738451529\n",
      "we F1:  0.7960074862360496\n",
      "update!  Acc:  0.8048145738451529\n",
      "Eval Loss:  0.29789790511131287\n",
      "Eval Loss:  0.3875229060649872\n",
      "Eval Loss:  0.4335089921951294\n",
      "Eval Loss:  0.4201566278934479\n",
      "Eval Loss:  0.4205012619495392\n",
      "Eval Loss:  0.5099398493766785\n",
      "Eval Loss:  0.47621938586235046\n",
      "Eval Loss:  0.5119091272354126\n",
      "Eval Loss:  0.4453483819961548\n",
      "Eval Loss:  0.348297655582428\n",
      "Eval Loss:  0.37647390365600586\n",
      "Eval Loss:  0.3697395920753479\n",
      "Eval Loss:  0.41621604561805725\n",
      "Eval Loss:  0.4088800847530365\n",
      "Eval Loss:  0.4147365689277649\n",
      "Eval Loss:  0.39351657032966614\n",
      "Eval Loss:  0.36803188920021057\n",
      "Eval Loss:  0.46518149971961975\n",
      "Eval Loss:  0.36247119307518005\n",
      "Eval Loss:  0.35725295543670654\n",
      "Eval Loss:  0.5315605998039246\n",
      "Eval Loss:  0.4657638370990753\n",
      "Eval Loss:  0.41129541397094727\n",
      "Eval Loss:  0.38941094279289246\n",
      "Eval Loss:  0.4737550616264343\n",
      "Eval Loss:  0.43803146481513977\n",
      "Eval Loss:  0.43750622868537903\n",
      "Eval Loss:  0.41923123598098755\n",
      "Eval Loss:  0.3754768669605255\n",
      "[[16099  1992]\n",
      " [ 3213  8513]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86     18091\n",
      "           1       0.81      0.73      0.77     11726\n",
      "\n",
      "    accuracy                           0.83     29817\n",
      "   macro avg       0.82      0.81      0.81     29817\n",
      "weighted avg       0.82      0.83      0.82     29817\n",
      "\n",
      "acc:  0.8254351544420968\n",
      "pre:  0.8103760114231319\n",
      "rec:  0.7259935186764455\n",
      "ma F1:  0.8133537609567463\n",
      "mi F1:  0.8254351544420969\n",
      "we F1:  0.8234906011273574\n",
      "29817 466\n",
      "Loss:  0.1244935616850853\n",
      "Loss:  0.09928533434867859\n",
      "Loss:  0.08531364053487778\n",
      "3 **********\n",
      "Epoch:  229.51831483840942  fold:  8  kers:  64\n",
      "epoch:  4\n",
      "29817 466\n",
      "Loss:  0.09139057248830795\n",
      "Loss:  0.09515003114938736\n",
      "Loss:  0.08973400294780731\n",
      "4 **********\n",
      "Epoch:  274.1330235004425  fold:  8  kers:  64\n",
      "epoch:  5\n",
      "29817 466\n",
      "Loss:  0.05996807664632797\n",
      "Loss:  0.116908498108387\n",
      "Loss:  0.06645350903272629\n",
      "5 **********\n",
      "Epoch:  318.62605834007263  fold:  8  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.27573174238204956\n",
      "Eval Loss:  1.7473852634429932\n",
      "Eval Loss:  0.1373845636844635\n",
      "[[1924  149]\n",
      " [ 477  524]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      2073\n",
      "           1       0.78      0.52      0.63      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.79      0.73      0.74      3074\n",
      "weighted avg       0.79      0.80      0.78      3074\n",
      "\n",
      "acc:  0.7963565387117761\n",
      "pre:  0.7786032689450223\n",
      "rec:  0.5234765234765235\n",
      "ma F1:  0.743062932573654\n",
      "mi F1:  0.7963565387117761\n",
      "we F1:  0.7838706081308446\n",
      "Eval Loss:  0.29749369621276855\n",
      "Eval Loss:  0.28040069341659546\n",
      "Eval Loss:  0.40226662158966064\n",
      "Eval Loss:  0.4251554608345032\n",
      "Eval Loss:  0.338768869638443\n",
      "Eval Loss:  0.4282534718513489\n",
      "Eval Loss:  0.436453640460968\n",
      "Eval Loss:  0.428509384393692\n",
      "Eval Loss:  0.40149858593940735\n",
      "Eval Loss:  0.30724191665649414\n",
      "Eval Loss:  0.3052569031715393\n",
      "Eval Loss:  0.33666709065437317\n",
      "Eval Loss:  0.3475075364112854\n",
      "Eval Loss:  0.33013948798179626\n",
      "Eval Loss:  0.3844093382358551\n",
      "Eval Loss:  0.3437967300415039\n",
      "Eval Loss:  0.33151116967201233\n",
      "Eval Loss:  0.39679116010665894\n",
      "Eval Loss:  0.29448848962783813\n",
      "Eval Loss:  0.31551164388656616\n",
      "Eval Loss:  0.4702809751033783\n",
      "Eval Loss:  0.4836631417274475\n",
      "Eval Loss:  0.3614826798439026\n",
      "Eval Loss:  0.34594467282295227\n",
      "Eval Loss:  0.44117435812950134\n",
      "Eval Loss:  0.3398649990558624\n",
      "Eval Loss:  0.40438446402549744\n",
      "Eval Loss:  0.35141250491142273\n",
      "Eval Loss:  0.34194955229759216\n",
      "[[16943  1148]\n",
      " [ 3061  8665]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     18091\n",
      "           1       0.88      0.74      0.80     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.86      0.84      0.85     29817\n",
      "weighted avg       0.86      0.86      0.86     29817\n",
      "\n",
      "acc:  0.8588389173961163\n",
      "pre:  0.8830123305818812\n",
      "rec:  0.7389561657854341\n",
      "ma F1:  0.84705004381903\n",
      "mi F1:  0.8588389173961163\n",
      "we F1:  0.8561145739371933\n",
      "29817 466\n",
      "Loss:  0.11059010028839111\n",
      "Loss:  0.09108003228902817\n",
      "Loss:  0.0728369653224945\n",
      "6 **********\n",
      "Epoch:  401.8166239261627  fold:  8  kers:  64\n",
      "epoch:  7\n",
      "29817 466\n",
      "Loss:  0.09415782988071442\n",
      "Loss:  0.06332966685295105\n",
      "Loss:  0.08707558363676071\n",
      "7 **********\n",
      "Epoch:  446.46125316619873  fold:  8  kers:  64\n",
      "epoch:  8\n",
      "29817 466\n",
      "Loss:  0.06418877840042114\n",
      "Loss:  0.06067969650030136\n",
      "Loss:  0.08632466197013855\n",
      "8 **********\n",
      "Epoch:  490.9862027168274  fold:  8  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.20634189248085022\n",
      "Eval Loss:  1.695849061012268\n",
      "Eval Loss:  0.11978138238191605\n",
      "[[1895  178]\n",
      " [ 501  500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85      2073\n",
      "           1       0.74      0.50      0.60      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.76      0.71      0.72      3074\n",
      "weighted avg       0.77      0.78      0.77      3074\n",
      "\n",
      "acc:  0.7791151594014314\n",
      "pre:  0.7374631268436578\n",
      "rec:  0.4995004995004995\n",
      "ma F1:  0.7218285292993851\n",
      "mi F1:  0.7791151594014315\n",
      "we F1:  0.7658509432559397\n",
      "Eval Loss:  0.26670363545417786\n",
      "Eval Loss:  0.2914053499698639\n",
      "Eval Loss:  0.3757498562335968\n",
      "Eval Loss:  0.3927781283855438\n",
      "Eval Loss:  0.34314465522766113\n",
      "Eval Loss:  0.4010060727596283\n",
      "Eval Loss:  0.42262592911720276\n",
      "Eval Loss:  0.3919094502925873\n",
      "Eval Loss:  0.38854750990867615\n",
      "Eval Loss:  0.28989142179489136\n",
      "Eval Loss:  0.2647494077682495\n",
      "Eval Loss:  0.30876395106315613\n",
      "Eval Loss:  0.3366647958755493\n",
      "Eval Loss:  0.30628514289855957\n",
      "Eval Loss:  0.34952086210250854\n",
      "Eval Loss:  0.33629652857780457\n",
      "Eval Loss:  0.31657862663269043\n",
      "Eval Loss:  0.37930816411972046\n",
      "Eval Loss:  0.2917526662349701\n",
      "Eval Loss:  0.30644071102142334\n",
      "Eval Loss:  0.486541211605072\n",
      "Eval Loss:  0.49361011385917664\n",
      "Eval Loss:  0.32393109798431396\n",
      "Eval Loss:  0.3271671235561371\n",
      "Eval Loss:  0.450587660074234\n",
      "Eval Loss:  0.3175194561481476\n",
      "Eval Loss:  0.39222341775894165\n",
      "Eval Loss:  0.34603285789489746\n",
      "Eval Loss:  0.317277729511261\n",
      "[[17231   860]\n",
      " [ 3236  8490]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18091\n",
      "           1       0.91      0.72      0.81     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.87      0.84      0.85     29817\n",
      "weighted avg       0.87      0.86      0.86     29817\n",
      "\n",
      "acc:  0.8626287017473253\n",
      "pre:  0.9080213903743316\n",
      "rec:  0.7240320654954802\n",
      "ma F1:  0.8497130729627912\n",
      "mi F1:  0.8626287017473253\n",
      "we F1:  0.8591179439402035\n",
      "29817 466\n",
      "Loss:  0.0792044848203659\n",
      "Loss:  0.09319400042295456\n",
      "Loss:  0.09579534083604813\n",
      "9 **********\n",
      "Epoch:  574.4231090545654  fold:  8  kers:  64\n",
      "epoch:  10\n",
      "29817 466\n",
      "Loss:  0.08169938623905182\n",
      "Loss:  0.08753853291273117\n",
      "Loss:  0.09888511896133423\n",
      "10 **********\n",
      "Epoch:  618.9301066398621  fold:  8  kers:  64\n",
      "epoch:  11\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.064642995595932\n",
      "Loss:  0.07376603037118912\n",
      "Loss:  0.12884438037872314\n",
      "11 **********\n",
      "Epoch:  663.3523309230804  fold:  8  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.140415221452713\n",
      "Eval Loss:  1.8945566415786743\n",
      "Eval Loss:  0.0929667204618454\n",
      "[[2043   30]\n",
      " [ 650  351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86      2073\n",
      "           1       0.92      0.35      0.51      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.84      0.67      0.68      3074\n",
      "weighted avg       0.81      0.78      0.74      3074\n",
      "\n",
      "acc:  0.77878985035784\n",
      "pre:  0.9212598425196851\n",
      "rec:  0.35064935064935066\n",
      "ma F1:  0.6826410907458949\n",
      "mi F1:  0.77878985035784\n",
      "we F1:  0.7435580353700113\n",
      "Eval Loss:  0.3161126375198364\n",
      "Eval Loss:  0.37568214535713196\n",
      "Eval Loss:  0.45966964960098267\n",
      "Eval Loss:  0.446002721786499\n",
      "Eval Loss:  0.44478461146354675\n",
      "Eval Loss:  0.5280474424362183\n",
      "Eval Loss:  0.5303286910057068\n",
      "Eval Loss:  0.45494553446769714\n",
      "Eval Loss:  0.45390400290489197\n",
      "Eval Loss:  0.3673861622810364\n",
      "Eval Loss:  0.3518739938735962\n",
      "Eval Loss:  0.2962453365325928\n",
      "Eval Loss:  0.41047340631484985\n",
      "Eval Loss:  0.4014909267425537\n",
      "Eval Loss:  0.4126671850681305\n",
      "Eval Loss:  0.40045252442359924\n",
      "Eval Loss:  0.3714609742164612\n",
      "Eval Loss:  0.46209579706192017\n",
      "Eval Loss:  0.3818245828151703\n",
      "Eval Loss:  0.3929997682571411\n",
      "Eval Loss:  0.6302288770675659\n",
      "Eval Loss:  0.6110728979110718\n",
      "Eval Loss:  0.43503496050834656\n",
      "Eval Loss:  0.36481600999832153\n",
      "Eval Loss:  0.5931627750396729\n",
      "Eval Loss:  0.5242769122123718\n",
      "Eval Loss:  0.4827641546726227\n",
      "Eval Loss:  0.4333513081073761\n",
      "Eval Loss:  0.412932813167572\n",
      "[[17755   336]\n",
      " [ 4880  6846]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87     18091\n",
      "           1       0.95      0.58      0.72     11726\n",
      "\n",
      "    accuracy                           0.83     29817\n",
      "   macro avg       0.87      0.78      0.80     29817\n",
      "weighted avg       0.85      0.83      0.81     29817\n",
      "\n",
      "acc:  0.8250662373813596\n",
      "pre:  0.9532163742690059\n",
      "rec:  0.5838308033429984\n",
      "ma F1:  0.7980312500529188\n",
      "mi F1:  0.8250662373813598\n",
      "we F1:  0.8138051701505927\n",
      "29817 466\n",
      "Loss:  0.10562943667173386\n",
      "Loss:  0.09708931297063828\n",
      "Loss:  0.057340092957019806\n",
      "12 **********\n",
      "Epoch:  746.3773384094238  fold:  8  kers:  64\n",
      "epoch:  13\n",
      "29817 466\n",
      "Loss:  0.0894278734922409\n",
      "Loss:  0.02920844592154026\n",
      "Loss:  0.05179144814610481\n",
      "13 **********\n",
      "Epoch:  790.6250295639038  fold:  8  kers:  64\n",
      "epoch:  14\n",
      "29817 466\n",
      "Loss:  0.06875132024288177\n",
      "Loss:  0.05812498927116394\n",
      "Loss:  0.061907317489385605\n",
      "14 **********\n",
      "Epoch:  834.8128800392151  fold:  8  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.239287331700325\n",
      "Eval Loss:  1.5370961427688599\n",
      "Eval Loss:  0.09510490298271179\n",
      "[[1886  187]\n",
      " [ 462  539]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85      2073\n",
      "           1       0.74      0.54      0.62      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.77      0.72      0.74      3074\n",
      "weighted avg       0.78      0.79      0.78      3074\n",
      "\n",
      "acc:  0.7888744307091737\n",
      "pre:  0.7424242424242424\n",
      "rec:  0.5384615384615384\n",
      "ma F1:  0.738702227498462\n",
      "mi F1:  0.7888744307091737\n",
      "we F1:  0.7786314048124062\n",
      "Eval Loss:  0.22532938420772552\n",
      "Eval Loss:  0.2925632894039154\n",
      "Eval Loss:  0.34410640597343445\n",
      "Eval Loss:  0.36239680647850037\n",
      "Eval Loss:  0.30237439274787903\n",
      "Eval Loss:  0.3640914559364319\n",
      "Eval Loss:  0.398653119802475\n",
      "Eval Loss:  0.3210243582725525\n",
      "Eval Loss:  0.3569473922252655\n",
      "Eval Loss:  0.2663426101207733\n",
      "Eval Loss:  0.23205631971359253\n",
      "Eval Loss:  0.26842185854911804\n",
      "Eval Loss:  0.31546658277511597\n",
      "Eval Loss:  0.2608603239059448\n",
      "Eval Loss:  0.3144404888153076\n",
      "Eval Loss:  0.2845827341079712\n",
      "Eval Loss:  0.27918773889541626\n",
      "Eval Loss:  0.3478560447692871\n",
      "Eval Loss:  0.2639700472354889\n",
      "Eval Loss:  0.2746289074420929\n",
      "Eval Loss:  0.443582683801651\n",
      "Eval Loss:  0.43773603439331055\n",
      "Eval Loss:  0.27929219603538513\n",
      "Eval Loss:  0.2887272536754608\n",
      "Eval Loss:  0.4560612440109253\n",
      "Eval Loss:  0.3008482754230499\n",
      "Eval Loss:  0.34493178129196167\n",
      "Eval Loss:  0.3262993395328522\n",
      "Eval Loss:  0.2685336768627167\n",
      "[[17330   761]\n",
      " [ 2981  8745]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     18091\n",
      "           1       0.92      0.75      0.82     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.89      0.85      0.86     29817\n",
      "weighted avg       0.88      0.87      0.87     29817\n",
      "\n",
      "acc:  0.8745011235201395\n",
      "pre:  0.9199452977067115\n",
      "rec:  0.7457786116322702\n",
      "ma F1:  0.8631568761509885\n",
      "mi F1:  0.8745011235201395\n",
      "we F1:  0.8715676081841448\n",
      "29817 466\n",
      "Loss:  0.07725412398576736\n",
      "Loss:  0.06873032450675964\n",
      "Loss:  0.07724282890558243\n",
      "15 **********\n",
      "Epoch:  917.63343501091  fold:  8  kers:  64\n",
      "epoch:  16\n",
      "29817 466\n",
      "Loss:  0.04881015792489052\n",
      "Loss:  0.08273568004369736\n",
      "Loss:  0.07624176144599915\n",
      "16 **********\n",
      "Epoch:  961.8332533836365  fold:  8  kers:  64\n",
      "epoch:  17\n",
      "29817 466\n",
      "Loss:  0.06894364207983017\n",
      "Loss:  0.053718000650405884\n",
      "Loss:  0.05511998012661934\n",
      "17 **********\n",
      "Epoch:  1006.1437754631042  fold:  8  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.32517385482788086\n",
      "Eval Loss:  1.4301480054855347\n",
      "Eval Loss:  0.09257222712039948\n",
      "[[1940  133]\n",
      " [ 481  520]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      2073\n",
      "           1       0.80      0.52      0.63      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.80      0.73      0.75      3074\n",
      "weighted avg       0.80      0.80      0.79      3074\n",
      "\n",
      "acc:  0.8002602472348731\n",
      "pre:  0.7963246554364471\n",
      "rec:  0.5194805194805194\n",
      "ma F1:  0.7460760524983197\n",
      "mi F1:  0.8002602472348731\n",
      "we F1:  0.7869813037360557\n",
      "Eval Loss:  0.2225821316242218\n",
      "Eval Loss:  0.2933555245399475\n",
      "Eval Loss:  0.3384748101234436\n",
      "Eval Loss:  0.35608258843421936\n",
      "Eval Loss:  0.3188099265098572\n",
      "Eval Loss:  0.37521088123321533\n",
      "Eval Loss:  0.4091060757637024\n",
      "Eval Loss:  0.3040231466293335\n",
      "Eval Loss:  0.3503279685974121\n",
      "Eval Loss:  0.2598908245563507\n",
      "Eval Loss:  0.23034222424030304\n",
      "Eval Loss:  0.2262462079524994\n",
      "Eval Loss:  0.31557461619377136\n",
      "Eval Loss:  0.2543318569660187\n",
      "Eval Loss:  0.3113964796066284\n",
      "Eval Loss:  0.26696640253067017\n",
      "Eval Loss:  0.27753615379333496\n",
      "Eval Loss:  0.3466513752937317\n",
      "Eval Loss:  0.2604162395000458\n",
      "Eval Loss:  0.27798452973365784\n",
      "Eval Loss:  0.44657060503959656\n",
      "Eval Loss:  0.43290454149246216\n",
      "Eval Loss:  0.2777951657772064\n",
      "Eval Loss:  0.2682516872882843\n",
      "Eval Loss:  0.45978763699531555\n",
      "Eval Loss:  0.3229367136955261\n",
      "Eval Loss:  0.33913013339042664\n",
      "Eval Loss:  0.32636910676956177\n",
      "Eval Loss:  0.2554393708705902\n",
      "[[17502   589]\n",
      " [ 3191  8535]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90     18091\n",
      "           1       0.94      0.73      0.82     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.89      0.85      0.86     29817\n",
      "weighted avg       0.88      0.87      0.87     29817\n",
      "\n",
      "acc:  0.8732266827648657\n",
      "pre:  0.9354449802718106\n",
      "rec:  0.7278696912843254\n",
      "ma F1:  0.8606210823420472\n",
      "mi F1:  0.8732266827648657\n",
      "we F1:  0.8695688515726973\n",
      "29817 466\n",
      "Loss:  0.06665470451116562\n",
      "Loss:  0.07431674003601074\n",
      "Loss:  0.06939626485109329\n",
      "18 **********\n",
      "Epoch:  1089.1139307022095  fold:  8  kers:  64\n",
      "epoch:  19\n",
      "29817 466\n",
      "Loss:  0.06574155390262604\n",
      "Loss:  0.03787444904446602\n",
      "Loss:  0.06428747624158859\n",
      "19 **********\n",
      "Epoch:  1133.4503836631775  fold:  8  kers:  64\n",
      "epoch:  20\n",
      "29817 466\n",
      "Loss:  0.07526139169931412\n",
      "Loss:  0.07295001298189163\n",
      "Loss:  0.05283045768737793\n",
      "20 **********\n",
      "Epoch:  1177.585375547409  fold:  8  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.43869534134864807\n",
      "Eval Loss:  1.2951679229736328\n",
      "Eval Loss:  0.09401874989271164\n",
      "[[1862  211]\n",
      " [ 436  565]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85      2073\n",
      "           1       0.73      0.56      0.64      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.77      0.73      0.74      3074\n",
      "weighted avg       0.78      0.79      0.78      3074\n",
      "\n",
      "acc:  0.7895250487963565\n",
      "pre:  0.7280927835051546\n",
      "rec:  0.5644355644355644\n",
      "ma F1:  0.7439410799191015\n",
      "mi F1:  0.7895250487963565\n",
      "we F1:  0.7816172669942113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21530704200267792\n",
      "Eval Loss:  0.27365460991859436\n",
      "Eval Loss:  0.2999684810638428\n",
      "Eval Loss:  0.3416154980659485\n",
      "Eval Loss:  0.27002668380737305\n",
      "Eval Loss:  0.34815239906311035\n",
      "Eval Loss:  0.39520254731178284\n",
      "Eval Loss:  0.27780529856681824\n",
      "Eval Loss:  0.310676634311676\n",
      "Eval Loss:  0.23574872314929962\n",
      "Eval Loss:  0.20579908788204193\n",
      "Eval Loss:  0.21689561009407043\n",
      "Eval Loss:  0.29313239455223083\n",
      "Eval Loss:  0.22501514852046967\n",
      "Eval Loss:  0.28532788157463074\n",
      "Eval Loss:  0.2538353204727173\n",
      "Eval Loss:  0.2484634518623352\n",
      "Eval Loss:  0.3069674074649811\n",
      "Eval Loss:  0.2292211651802063\n",
      "Eval Loss:  0.2561163008213043\n",
      "Eval Loss:  0.3992362916469574\n",
      "Eval Loss:  0.37601807713508606\n",
      "Eval Loss:  0.24647632241249084\n",
      "Eval Loss:  0.2661033570766449\n",
      "Eval Loss:  0.4192737936973572\n",
      "Eval Loss:  0.2970251441001892\n",
      "Eval Loss:  0.29537779092788696\n",
      "Eval Loss:  0.2980310618877411\n",
      "Eval Loss:  0.22940140962600708\n",
      "[[17455   636]\n",
      " [ 2798  8928]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18091\n",
      "           1       0.93      0.76      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.90      0.86      0.87     29817\n",
      "weighted avg       0.89      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8848308012207801\n",
      "pre:  0.9335006273525721\n",
      "rec:  0.7613849565069077\n",
      "ma F1:  0.8745729642130173\n",
      "mi F1:  0.8848308012207801\n",
      "we F1:  0.8822299517296597\n",
      "29817 466\n",
      "Loss:  0.07130230963230133\n",
      "Loss:  0.13763217628002167\n",
      "Loss:  0.05913811922073364\n",
      "21 **********\n",
      "Epoch:  1260.374016046524  fold:  8  kers:  64\n",
      "epoch:  22\n",
      "29817 466\n",
      "Loss:  0.045513007789850235\n",
      "Loss:  0.06856229156255722\n",
      "Loss:  0.07095099240541458\n",
      "22 **********\n",
      "Epoch:  1304.6316797733307  fold:  8  kers:  64\n",
      "epoch:  23\n",
      "29817 466\n",
      "Loss:  0.06731640547513962\n",
      "Loss:  0.08069931715726852\n",
      "Loss:  0.06953596323728561\n",
      "23 **********\n",
      "Epoch:  1348.8394775390625  fold:  8  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.633407473564148\n",
      "Eval Loss:  1.1474850177764893\n",
      "Eval Loss:  0.09514596313238144\n",
      "[[1783  290]\n",
      " [ 380  621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      2073\n",
      "           1       0.68      0.62      0.65      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.75      0.74      0.75      3074\n",
      "weighted avg       0.78      0.78      0.78      3074\n",
      "\n",
      "acc:  0.782042940793754\n",
      "pre:  0.681668496158068\n",
      "rec:  0.6203796203796204\n",
      "ma F1:  0.7457067534304487\n",
      "mi F1:  0.782042940793754\n",
      "we F1:  0.7792286061442725\n",
      "Eval Loss:  0.21730731427669525\n",
      "Eval Loss:  0.24137096107006073\n",
      "Eval Loss:  0.2798384130001068\n",
      "Eval Loss:  0.30626946687698364\n",
      "Eval Loss:  0.23819485306739807\n",
      "Eval Loss:  0.2975778579711914\n",
      "Eval Loss:  0.3622688353061676\n",
      "Eval Loss:  0.2412905991077423\n",
      "Eval Loss:  0.28159573674201965\n",
      "Eval Loss:  0.2107430100440979\n",
      "Eval Loss:  0.1915755420923233\n",
      "Eval Loss:  0.21342015266418457\n",
      "Eval Loss:  0.2752918303012848\n",
      "Eval Loss:  0.2149566113948822\n",
      "Eval Loss:  0.25861549377441406\n",
      "Eval Loss:  0.24134321510791779\n",
      "Eval Loss:  0.22804702818393707\n",
      "Eval Loss:  0.27840912342071533\n",
      "Eval Loss:  0.21743719279766083\n",
      "Eval Loss:  0.23942364752292633\n",
      "Eval Loss:  0.3656729757785797\n",
      "Eval Loss:  0.3373991847038269\n",
      "Eval Loss:  0.2332632839679718\n",
      "Eval Loss:  0.2555384337902069\n",
      "Eval Loss:  0.3726940155029297\n",
      "Eval Loss:  0.25920185446739197\n",
      "Eval Loss:  0.2761304974555969\n",
      "Eval Loss:  0.2595944106578827\n",
      "Eval Loss:  0.20182901620864868\n",
      "[[17348   743]\n",
      " [ 2342  9384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18091\n",
      "           1       0.93      0.80      0.86     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.88      0.89     29817\n",
      "weighted avg       0.90      0.90      0.89     29817\n",
      "\n",
      "acc:  0.8965355334205319\n",
      "pre:  0.9266317764392219\n",
      "rec:  0.8002728978338735\n",
      "ma F1:  0.8885873256510755\n",
      "mi F1:  0.8965355334205319\n",
      "we F1:  0.8949397041609436\n",
      "29817 466\n",
      "Loss:  0.058384958654642105\n",
      "Loss:  0.07221556454896927\n",
      "Loss:  0.0628255158662796\n",
      "24 **********\n",
      "Epoch:  1431.7408156394958  fold:  8  kers:  64\n",
      "epoch:  25\n",
      "29817 466\n",
      "Loss:  0.06820834428071976\n",
      "Loss:  0.06880512833595276\n",
      "Loss:  0.07896547019481659\n",
      "25 **********\n",
      "Epoch:  1475.9246771335602  fold:  8  kers:  64\n",
      "epoch:  26\n",
      "29817 466\n",
      "Loss:  0.07502928376197815\n",
      "Loss:  0.08445286750793457\n",
      "Loss:  0.05149131268262863\n",
      "26 **********\n",
      "Epoch:  1520.0377280712128  fold:  8  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.4536226987838745\n",
      "Eval Loss:  1.1715537309646606\n",
      "Eval Loss:  0.08726091682910919\n",
      "[[1941  132]\n",
      " [ 410  591]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      2073\n",
      "           1       0.82      0.59      0.69      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.82      0.76      0.78      3074\n",
      "weighted avg       0.82      0.82      0.82      3074\n",
      "\n",
      "acc:  0.8236824983734548\n",
      "pre:  0.8174273858921162\n",
      "rec:  0.5904095904095904\n",
      "ma F1:  0.7815506434004775\n",
      "mi F1:  0.8236824983734548\n",
      "we F1:  0.8150064571271677\n",
      "update!  Acc:  0.8236824983734548\n",
      "Eval Loss:  0.22322703897953033\n",
      "Eval Loss:  0.2689874470233917\n",
      "Eval Loss:  0.2894461452960968\n",
      "Eval Loss:  0.3021528124809265\n",
      "Eval Loss:  0.25235626101493835\n",
      "Eval Loss:  0.32474184036254883\n",
      "Eval Loss:  0.36820459365844727\n",
      "Eval Loss:  0.2854624092578888\n",
      "Eval Loss:  0.2968699634075165\n",
      "Eval Loss:  0.2093101143836975\n",
      "Eval Loss:  0.2069234848022461\n",
      "Eval Loss:  0.19822080433368683\n",
      "Eval Loss:  0.2743978500366211\n",
      "Eval Loss:  0.21359291672706604\n",
      "Eval Loss:  0.2650846540927887\n",
      "Eval Loss:  0.2695188522338867\n",
      "Eval Loss:  0.2180253118276596\n",
      "Eval Loss:  0.30971217155456543\n",
      "Eval Loss:  0.2210543304681778\n",
      "Eval Loss:  0.24937903881072998\n",
      "Eval Loss:  0.37246954441070557\n",
      "Eval Loss:  0.34520575404167175\n",
      "Eval Loss:  0.2341541200876236\n",
      "Eval Loss:  0.24680550396442413\n",
      "Eval Loss:  0.3737564980983734\n",
      "Eval Loss:  0.2990947365760803\n",
      "Eval Loss:  0.2894395887851715\n",
      "Eval Loss:  0.2984714210033417\n",
      "Eval Loss:  0.21887680888175964\n",
      "[[17505   586]\n",
      " [ 2650  9076]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     18091\n",
      "           1       0.94      0.77      0.85     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.87      0.88     29817\n",
      "weighted avg       0.90      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8914713083140491\n",
      "pre:  0.9393500310494721\n",
      "rec:  0.7740064813235545\n",
      "ma F1:  0.882045025206238\n",
      "mi F1:  0.8914713083140491\n",
      "we F1:  0.8891631046914932\n",
      "29817 466\n",
      "Loss:  0.07902468740940094\n",
      "Loss:  0.07811962068080902\n",
      "Loss:  0.0653855949640274\n",
      "27 **********\n",
      "Epoch:  1603.1096107959747  fold:  8  kers:  64\n",
      "epoch:  28\n",
      "29817 466\n",
      "Loss:  0.08459250628948212\n",
      "Loss:  0.048315465450286865\n",
      "Loss:  0.032858170568943024\n",
      "28 **********\n",
      "Epoch:  1647.301450252533  fold:  8  kers:  64\n",
      "epoch:  29\n",
      "29817 466\n",
      "Loss:  0.03030797839164734\n",
      "Loss:  0.09012465178966522\n",
      "Loss:  0.04698192700743675\n",
      "29 **********\n",
      "Epoch:  1691.6688220500946  fold:  8  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.4480611979961395\n",
      "Eval Loss:  1.0286043882369995\n",
      "Eval Loss:  0.08663002401590347\n",
      "[[1979   94]\n",
      " [ 418  583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      2073\n",
      "           1       0.86      0.58      0.69      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.84      0.77      0.79      3074\n",
      "weighted avg       0.84      0.83      0.82      3074\n",
      "\n",
      "acc:  0.8334417696811971\n",
      "pre:  0.8611521418020679\n",
      "rec:  0.5824175824175825\n",
      "ma F1:  0.7901667319942511\n",
      "mi F1:  0.8334417696811971\n",
      "we F1:  0.8233979930260606\n",
      "update!  Acc:  0.8334417696811971\n",
      "Eval Loss:  0.2229379415512085\n",
      "Eval Loss:  0.24881456792354584\n",
      "Eval Loss:  0.3039686679840088\n",
      "Eval Loss:  0.3122277855873108\n",
      "Eval Loss:  0.25007936358451843\n",
      "Eval Loss:  0.33273595571517944\n",
      "Eval Loss:  0.35993054509162903\n",
      "Eval Loss:  0.26819342374801636\n",
      "Eval Loss:  0.31043651700019836\n",
      "Eval Loss:  0.22399958968162537\n",
      "Eval Loss:  0.2056155800819397\n",
      "Eval Loss:  0.210005521774292\n",
      "Eval Loss:  0.2739960253238678\n",
      "Eval Loss:  0.22673465311527252\n",
      "Eval Loss:  0.27911376953125\n",
      "Eval Loss:  0.2651981711387634\n",
      "Eval Loss:  0.23113569617271423\n",
      "Eval Loss:  0.28482264280319214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23385818302631378\n",
      "Eval Loss:  0.26403605937957764\n",
      "Eval Loss:  0.3749249279499054\n",
      "Eval Loss:  0.37741389870643616\n",
      "Eval Loss:  0.25288069248199463\n",
      "Eval Loss:  0.24368497729301453\n",
      "Eval Loss:  0.38205596804618835\n",
      "Eval Loss:  0.29621416330337524\n",
      "Eval Loss:  0.28510624170303345\n",
      "Eval Loss:  0.2889552414417267\n",
      "Eval Loss:  0.2280072122812271\n",
      "[[17587   504]\n",
      " [ 2909  8817]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     18091\n",
      "           1       0.95      0.75      0.84     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.86      0.87     29817\n",
      "weighted avg       0.89      0.89      0.88     29817\n",
      "\n",
      "acc:  0.8855350974276419\n",
      "pre:  0.9459285484390086\n",
      "rec:  0.7519188128944226\n",
      "ma F1:  0.8746948220808601\n",
      "mi F1:  0.8855350974276419\n",
      "we F1:  0.8825623651347103\n",
      "29817 466\n",
      "Loss:  0.06336189806461334\n",
      "Loss:  0.04598833993077278\n",
      "Loss:  0.05582272261381149\n",
      "30 **********\n",
      "Epoch:  1774.6150398254395  fold:  8  kers:  64\n",
      "epoch:  31\n",
      "29817 466\n",
      "Loss:  0.04345136135816574\n",
      "Loss:  0.08680721372365952\n",
      "Loss:  0.027392080053687096\n",
      "31 **********\n",
      "Epoch:  1818.7799518108368  fold:  8  kers:  64\n",
      "epoch:  32\n",
      "29817 466\n",
      "Loss:  0.06228877976536751\n",
      "Loss:  0.06202264502644539\n",
      "Loss:  0.0823318213224411\n",
      "32 **********\n",
      "Epoch:  1863.0645451545715  fold:  8  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.7821767926216125\n",
      "Eval Loss:  0.946139395236969\n",
      "Eval Loss:  0.09652594476938248\n",
      "[[1839  234]\n",
      " [ 286  715]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      2073\n",
      "           1       0.75      0.71      0.73      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.80      0.80      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8308392973324659\n",
      "pre:  0.7534246575342466\n",
      "rec:  0.7142857142857143\n",
      "ma F1:  0.8047324122598063\n",
      "mi F1:  0.8308392973324659\n",
      "we F1:  0.8296315054963641\n",
      "Eval Loss:  0.24564006924629211\n",
      "Eval Loss:  0.2366785705089569\n",
      "Eval Loss:  0.2596566677093506\n",
      "Eval Loss:  0.26536208391189575\n",
      "Eval Loss:  0.16941338777542114\n",
      "Eval Loss:  0.26077771186828613\n",
      "Eval Loss:  0.32264772057533264\n",
      "Eval Loss:  0.20489418506622314\n",
      "Eval Loss:  0.2648494243621826\n",
      "Eval Loss:  0.18420185148715973\n",
      "Eval Loss:  0.16124911606311798\n",
      "Eval Loss:  0.2287256419658661\n",
      "Eval Loss:  0.25436311960220337\n",
      "Eval Loss:  0.19361713528633118\n",
      "Eval Loss:  0.22524340450763702\n",
      "Eval Loss:  0.23322045803070068\n",
      "Eval Loss:  0.19917260110378265\n",
      "Eval Loss:  0.2409440279006958\n",
      "Eval Loss:  0.19787655770778656\n",
      "Eval Loss:  0.21590019762516022\n",
      "Eval Loss:  0.2632088363170624\n",
      "Eval Loss:  0.2659327983856201\n",
      "Eval Loss:  0.18648087978363037\n",
      "Eval Loss:  0.2502419650554657\n",
      "Eval Loss:  0.31443318724632263\n",
      "Eval Loss:  0.19972363114356995\n",
      "Eval Loss:  0.2265537977218628\n",
      "Eval Loss:  0.21953193843364716\n",
      "Eval Loss:  0.17369699478149414\n",
      "[[17037  1054]\n",
      " [ 1648 10078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18091\n",
      "           1       0.91      0.86      0.88     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.90      0.90     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9093805547171077\n",
      "pre:  0.9053180021559468\n",
      "rec:  0.8594576155551765\n",
      "ma F1:  0.904160051674264\n",
      "mi F1:  0.9093805547171077\n",
      "we F1:  0.9089349477610149\n",
      "29817 466\n",
      "Loss:  0.07039299607276917\n",
      "Loss:  0.0443904809653759\n",
      "Loss:  0.07700131088495255\n",
      "33 **********\n",
      "Epoch:  1945.8312423229218  fold:  8  kers:  64\n",
      "epoch:  34\n",
      "29817 466\n",
      "Loss:  0.04647905379533768\n",
      "Loss:  0.05275030434131622\n",
      "Loss:  0.06085696443915367\n",
      "34 **********\n",
      "Epoch:  1990.2245435714722  fold:  8  kers:  64\n",
      "epoch:  35\n",
      "29817 466\n",
      "Loss:  0.053750041872262955\n",
      "Loss:  0.06778742372989655\n",
      "Loss:  0.08354158699512482\n",
      "35 **********\n",
      "Epoch:  2034.4423143863678  fold:  8  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.687408447265625\n",
      "Eval Loss:  1.0935760736465454\n",
      "Eval Loss:  0.09257259964942932\n",
      "[[1874  199]\n",
      " [ 340  661]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      2073\n",
      "           1       0.77      0.66      0.71      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.81      0.78      0.79      3074\n",
      "weighted avg       0.82      0.82      0.82      3074\n",
      "\n",
      "acc:  0.824658425504229\n",
      "pre:  0.7686046511627908\n",
      "rec:  0.6603396603396603\n",
      "ma F1:  0.7923209102109059\n",
      "mi F1:  0.8246584255042291\n",
      "we F1:  0.8208994892665056\n",
      "Eval Loss:  0.2122604101896286\n",
      "Eval Loss:  0.20860053598880768\n",
      "Eval Loss:  0.249566912651062\n",
      "Eval Loss:  0.27401047945022583\n",
      "Eval Loss:  0.18317174911499023\n",
      "Eval Loss:  0.27167966961860657\n",
      "Eval Loss:  0.32785794138908386\n",
      "Eval Loss:  0.20734767615795135\n",
      "Eval Loss:  0.25140315294265747\n",
      "Eval Loss:  0.18325665593147278\n",
      "Eval Loss:  0.17001068592071533\n",
      "Eval Loss:  0.1948401927947998\n",
      "Eval Loss:  0.2474350929260254\n",
      "Eval Loss:  0.1901906430721283\n",
      "Eval Loss:  0.22811484336853027\n",
      "Eval Loss:  0.2488127052783966\n",
      "Eval Loss:  0.20051446557044983\n",
      "Eval Loss:  0.2531830966472626\n",
      "Eval Loss:  0.1943502426147461\n",
      "Eval Loss:  0.21648959815502167\n",
      "Eval Loss:  0.3148248493671417\n",
      "Eval Loss:  0.27844831347465515\n",
      "Eval Loss:  0.2067853957414627\n",
      "Eval Loss:  0.24184530973434448\n",
      "Eval Loss:  0.30508846044540405\n",
      "Eval Loss:  0.24012327194213867\n",
      "Eval Loss:  0.23881331086158752\n",
      "Eval Loss:  0.2150527387857437\n",
      "Eval Loss:  0.18458208441734314\n",
      "[[17366   725]\n",
      " [ 2000  9726]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18091\n",
      "           1       0.93      0.83      0.88     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.89      0.90     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9086091826810209\n",
      "pre:  0.9306286479762702\n",
      "rec:  0.8294388538290978\n",
      "ma F1:  0.9021874312528049\n",
      "mi F1:  0.9086091826810209\n",
      "we F1:  0.9075374898706837\n",
      "29817 466\n",
      "Loss:  0.05265168473124504\n",
      "Loss:  0.052802715450525284\n",
      "Loss:  0.047568704932928085\n",
      "36 **********\n",
      "Epoch:  2117.209013223648  fold:  8  kers:  64\n",
      "epoch:  37\n",
      "29817 466\n",
      "Loss:  0.08098868280649185\n",
      "Loss:  0.08555905520915985\n",
      "Loss:  0.04855255410075188\n",
      "37 **********\n",
      "Epoch:  2161.4537119865417  fold:  8  kers:  64\n",
      "epoch:  38\n",
      "29817 466\n",
      "Loss:  0.08581601828336716\n",
      "Loss:  0.07061388343572617\n",
      "Loss:  0.048280902206897736\n",
      "38 **********\n",
      "Epoch:  2205.6106452941895  fold:  8  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.8635663390159607\n",
      "Eval Loss:  0.9241403937339783\n",
      "Eval Loss:  0.10820750892162323\n",
      "[[1796  277]\n",
      " [ 235  766]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      2073\n",
      "           1       0.73      0.77      0.75      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.82      0.81      3074\n",
      "weighted avg       0.84      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8334417696811971\n",
      "pre:  0.7344199424736337\n",
      "rec:  0.7652347652347652\n",
      "ma F1:  0.8123772139633711\n",
      "mi F1:  0.8334417696811971\n",
      "we F1:  0.8343007127298852\n",
      "Eval Loss:  0.22646276652812958\n",
      "Eval Loss:  0.21064478158950806\n",
      "Eval Loss:  0.2487606257200241\n",
      "Eval Loss:  0.2260618656873703\n",
      "Eval Loss:  0.14887961745262146\n",
      "Eval Loss:  0.24390365183353424\n",
      "Eval Loss:  0.30538785457611084\n",
      "Eval Loss:  0.1897825002670288\n",
      "Eval Loss:  0.24077537655830383\n",
      "Eval Loss:  0.173415869474411\n",
      "Eval Loss:  0.1434532105922699\n",
      "Eval Loss:  0.21031935513019562\n",
      "Eval Loss:  0.2496946007013321\n",
      "Eval Loss:  0.1691211611032486\n",
      "Eval Loss:  0.22093500196933746\n",
      "Eval Loss:  0.24362991750240326\n",
      "Eval Loss:  0.1910950094461441\n",
      "Eval Loss:  0.23298747837543488\n",
      "Eval Loss:  0.1806037575006485\n",
      "Eval Loss:  0.21020404994487762\n",
      "Eval Loss:  0.25778770446777344\n",
      "Eval Loss:  0.24050502479076385\n",
      "Eval Loss:  0.18168801069259644\n",
      "Eval Loss:  0.2579534947872162\n",
      "Eval Loss:  0.28504014015197754\n",
      "Eval Loss:  0.21985875070095062\n",
      "Eval Loss:  0.21692168712615967\n",
      "Eval Loss:  0.18644645810127258\n",
      "Eval Loss:  0.1796439290046692\n",
      "[[17068  1023]\n",
      " [ 1480 10246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18091\n",
      "           1       0.91      0.87      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9160545997249891\n",
      "pre:  0.9092199840269767\n",
      "rec:  0.8737847518335323\n",
      "ma F1:  0.9114175333898535\n",
      "mi F1:  0.9160545997249891\n",
      "we F1:  0.915743966579994\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05335625261068344\n",
      "Loss:  0.0716388002038002\n",
      "Loss:  0.07054267823696136\n",
      "39 **********\n",
      "Epoch:  2288.4292056560516  fold:  8  kers:  64\n",
      "epoch:  40\n",
      "29817 466\n",
      "Loss:  0.03439490869641304\n",
      "Loss:  0.08527223765850067\n",
      "Loss:  0.030447686091065407\n",
      "40 **********\n",
      "Epoch:  2332.631019115448  fold:  8  kers:  64\n",
      "epoch:  41\n",
      "29817 466\n",
      "Loss:  0.06362055987119675\n",
      "Loss:  0.10323615372180939\n",
      "Loss:  0.054792068898677826\n",
      "41 **********\n",
      "Epoch:  2376.836821079254  fold:  8  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.9247264266014099\n",
      "Eval Loss:  1.0029829740524292\n",
      "Eval Loss:  0.10458069294691086\n",
      "[[1803  270]\n",
      " [ 230  771]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      2073\n",
      "           1       0.74      0.77      0.76      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.81      0.82      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8373454782042941\n",
      "pre:  0.7406340057636888\n",
      "rec:  0.7702297702297702\n",
      "ma F1:  0.8166845012649604\n",
      "mi F1:  0.8373454782042941\n",
      "we F1:  0.8381462912639581\n",
      "update!  Acc:  0.8373454782042941\n",
      "Eval Loss:  0.22601835429668427\n",
      "Eval Loss:  0.2011519819498062\n",
      "Eval Loss:  0.2441709339618683\n",
      "Eval Loss:  0.23672588169574738\n",
      "Eval Loss:  0.1542034149169922\n",
      "Eval Loss:  0.2502114474773407\n",
      "Eval Loss:  0.2902681231498718\n",
      "Eval Loss:  0.2093728482723236\n",
      "Eval Loss:  0.24973346292972565\n",
      "Eval Loss:  0.1671765297651291\n",
      "Eval Loss:  0.15627090632915497\n",
      "Eval Loss:  0.20951935648918152\n",
      "Eval Loss:  0.22657062113285065\n",
      "Eval Loss:  0.1673664003610611\n",
      "Eval Loss:  0.2251947671175003\n",
      "Eval Loss:  0.23908774554729462\n",
      "Eval Loss:  0.1936015784740448\n",
      "Eval Loss:  0.23357003927230835\n",
      "Eval Loss:  0.17604054510593414\n",
      "Eval Loss:  0.19937439262866974\n",
      "Eval Loss:  0.2705155909061432\n",
      "Eval Loss:  0.24438658356666565\n",
      "Eval Loss:  0.19308605790138245\n",
      "Eval Loss:  0.23785464465618134\n",
      "Eval Loss:  0.260429322719574\n",
      "Eval Loss:  0.19953671097755432\n",
      "Eval Loss:  0.21835169196128845\n",
      "Eval Loss:  0.20326437056064606\n",
      "Eval Loss:  0.16471701860427856\n",
      "[[17087  1004]\n",
      " [ 1450 10276]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18091\n",
      "           1       0.91      0.88      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9176979575410001\n",
      "pre:  0.9109929078014184\n",
      "rec:  0.8763431690260959\n",
      "ma F1:  0.9131671245653936\n",
      "mi F1:  0.9176979575410001\n",
      "we F1:  0.9174012681404539\n",
      "29817 466\n",
      "Loss:  0.034562043845653534\n",
      "Loss:  0.09884089231491089\n",
      "Loss:  0.044272247701883316\n",
      "42 **********\n",
      "Epoch:  2459.7620961666107  fold:  8  kers:  64\n",
      "epoch:  43\n",
      "29817 466\n",
      "Loss:  0.047938887029886246\n",
      "Loss:  0.04785585775971413\n",
      "Loss:  0.06474842876195908\n",
      "43 **********\n",
      "Epoch:  2504.0656378269196  fold:  8  kers:  64\n",
      "epoch:  44\n",
      "29817 466\n",
      "Loss:  0.07499399781227112\n",
      "Loss:  0.055357132107019424\n",
      "Loss:  0.050635628402233124\n",
      "44 **********\n",
      "Epoch:  2548.3532214164734  fold:  8  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.7002880573272705\n",
      "Eval Loss:  0.9818408489227295\n",
      "Eval Loss:  0.09040165692567825\n",
      "[[1860  213]\n",
      " [ 318  683]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      2073\n",
      "           1       0.76      0.68      0.72      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.79      0.80      3074\n",
      "weighted avg       0.82      0.83      0.82      3074\n",
      "\n",
      "acc:  0.8272608978529603\n",
      "pre:  0.7622767857142857\n",
      "rec:  0.6823176823176823\n",
      "ma F1:  0.7975862791191678\n",
      "mi F1:  0.8272608978529603\n",
      "we F1:  0.8246136294017723\n",
      "Eval Loss:  0.20678147673606873\n",
      "Eval Loss:  0.1932830661535263\n",
      "Eval Loss:  0.24852721393108368\n",
      "Eval Loss:  0.22731859982013702\n",
      "Eval Loss:  0.160218745470047\n",
      "Eval Loss:  0.24739310145378113\n",
      "Eval Loss:  0.29474204778671265\n",
      "Eval Loss:  0.19086194038391113\n",
      "Eval Loss:  0.2410484105348587\n",
      "Eval Loss:  0.18809175491333008\n",
      "Eval Loss:  0.13585270941257477\n",
      "Eval Loss:  0.1749121993780136\n",
      "Eval Loss:  0.23179733753204346\n",
      "Eval Loss:  0.16391876339912415\n",
      "Eval Loss:  0.20206955075263977\n",
      "Eval Loss:  0.23716017603874207\n",
      "Eval Loss:  0.17599110305309296\n",
      "Eval Loss:  0.22434283792972565\n",
      "Eval Loss:  0.16894137859344482\n",
      "Eval Loss:  0.21815210580825806\n",
      "Eval Loss:  0.2703191339969635\n",
      "Eval Loss:  0.2409907579421997\n",
      "Eval Loss:  0.17309562861919403\n",
      "Eval Loss:  0.23165158927440643\n",
      "Eval Loss:  0.2776777446269989\n",
      "Eval Loss:  0.22037194669246674\n",
      "Eval Loss:  0.21086245775222778\n",
      "Eval Loss:  0.19519904255867004\n",
      "Eval Loss:  0.18845829367637634\n",
      "[[17314   777]\n",
      " [ 1647 10079]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18091\n",
      "           1       0.93      0.86      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9187040949793742\n",
      "pre:  0.9284266764922623\n",
      "rec:  0.859542896128262\n",
      "ma F1:  0.9136181497067178\n",
      "mi F1:  0.9187040949793742\n",
      "we F1:  0.9180925162112731\n",
      "29817 466\n",
      "Loss:  0.04446901008486748\n",
      "Loss:  0.03414857015013695\n",
      "Loss:  0.04467464238405228\n",
      "45 **********\n",
      "Epoch:  2631.3064210414886  fold:  8  kers:  64\n",
      "epoch:  46\n",
      "29817 466\n",
      "Loss:  0.0528007410466671\n",
      "Loss:  0.08287440985441208\n",
      "Loss:  0.05987490341067314\n",
      "46 **********\n",
      "Epoch:  2675.7077009677887  fold:  8  kers:  64\n",
      "epoch:  47\n",
      "29817 466\n",
      "Loss:  0.04851192608475685\n",
      "Loss:  0.03578292205929756\n",
      "Loss:  0.07213734835386276\n",
      "47 **********\n",
      "Epoch:  2720.0940215587616  fold:  8  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.9026301503181458\n",
      "Eval Loss:  0.927335798740387\n",
      "Eval Loss:  0.1009182259440422\n",
      "[[1754  319]\n",
      " [ 226  775]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      2073\n",
      "           1       0.71      0.77      0.74      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.80      0.81      0.80      3074\n",
      "weighted avg       0.83      0.82      0.82      3074\n",
      "\n",
      "acc:  0.8227065712426805\n",
      "pre:  0.7084095063985375\n",
      "rec:  0.7742257742257742\n",
      "ma F1:  0.8026942534096255\n",
      "mi F1:  0.8227065712426805\n",
      "we F1:  0.8246076392288645\n",
      "Eval Loss:  0.2175578773021698\n",
      "Eval Loss:  0.20110367238521576\n",
      "Eval Loss:  0.24436038732528687\n",
      "Eval Loss:  0.23262108862400055\n",
      "Eval Loss:  0.1475261002779007\n",
      "Eval Loss:  0.23040618002414703\n",
      "Eval Loss:  0.28183281421661377\n",
      "Eval Loss:  0.18929119408130646\n",
      "Eval Loss:  0.24395215511322021\n",
      "Eval Loss:  0.16918125748634338\n",
      "Eval Loss:  0.14007601141929626\n",
      "Eval Loss:  0.2092415690422058\n",
      "Eval Loss:  0.2679435908794403\n",
      "Eval Loss:  0.15992437303066254\n",
      "Eval Loss:  0.19886545836925507\n",
      "Eval Loss:  0.22874592244625092\n",
      "Eval Loss:  0.19731372594833374\n",
      "Eval Loss:  0.22950083017349243\n",
      "Eval Loss:  0.16171175241470337\n",
      "Eval Loss:  0.22017668187618256\n",
      "Eval Loss:  0.25831499695777893\n",
      "Eval Loss:  0.2382974475622177\n",
      "Eval Loss:  0.17931774258613586\n",
      "Eval Loss:  0.24235035479068756\n",
      "Eval Loss:  0.27340760827064514\n",
      "Eval Loss:  0.19646626710891724\n",
      "Eval Loss:  0.22402025759220123\n",
      "Eval Loss:  0.20395734906196594\n",
      "Eval Loss:  0.17730197310447693\n",
      "[[16983  1108]\n",
      " [ 1311 10415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18091\n",
      "           1       0.90      0.89      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9188717845524366\n",
      "pre:  0.9038444849431572\n",
      "rec:  0.8881971686849736\n",
      "ma F1:  0.9147345365541011\n",
      "mi F1:  0.9188717845524366\n",
      "we F1:  0.9187439128496864\n",
      "29817 466\n",
      "Loss:  0.04962952435016632\n",
      "Loss:  0.06908614188432693\n",
      "Loss:  0.05507148429751396\n",
      "48 **********\n",
      "Epoch:  2802.871690750122  fold:  8  kers:  64\n",
      "epoch:  49\n",
      "29817 466\n",
      "Loss:  0.06308905780315399\n",
      "Loss:  0.038262687623500824\n",
      "Loss:  0.04390973970293999\n",
      "49 **********\n",
      "Epoch:  2847.1911890506744  fold:  8  kers:  64\n",
      "epoch:  50\n",
      "29817 466\n",
      "Loss:  0.03101537562906742\n",
      "Loss:  0.04504438489675522\n",
      "Loss:  0.05875575914978981\n",
      "50 **********\n",
      "Epoch:  2891.4229221343994  fold:  8  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.7822409272193909\n",
      "Eval Loss:  1.0643032789230347\n",
      "Eval Loss:  0.14253179728984833\n",
      "[[1714  359]\n",
      " [ 221  780]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      2073\n",
      "           1       0.68      0.78      0.73      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.79      0.80      0.79      3074\n",
      "weighted avg       0.82      0.81      0.81      3074\n",
      "\n",
      "acc:  0.8113207547169812\n",
      "pre:  0.684811237928007\n",
      "rec:  0.7792207792207793\n",
      "ma F1:  0.7921306918872535\n",
      "mi F1:  0.8113207547169812\n",
      "we F1:  0.8141561173192321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19991028308868408\n",
      "Eval Loss:  0.18775944411754608\n",
      "Eval Loss:  0.2364421784877777\n",
      "Eval Loss:  0.20131585001945496\n",
      "Eval Loss:  0.13424398005008698\n",
      "Eval Loss:  0.22235244512557983\n",
      "Eval Loss:  0.2630925476551056\n",
      "Eval Loss:  0.21043069660663605\n",
      "Eval Loss:  0.24734313786029816\n",
      "Eval Loss:  0.16645663976669312\n",
      "Eval Loss:  0.13284774124622345\n",
      "Eval Loss:  0.21529535949230194\n",
      "Eval Loss:  0.231378972530365\n",
      "Eval Loss:  0.14914561808109283\n",
      "Eval Loss:  0.2074553519487381\n",
      "Eval Loss:  0.25176554918289185\n",
      "Eval Loss:  0.18302351236343384\n",
      "Eval Loss:  0.2407272756099701\n",
      "Eval Loss:  0.1760396659374237\n",
      "Eval Loss:  0.19574256241321564\n",
      "Eval Loss:  0.23451782763004303\n",
      "Eval Loss:  0.21773555874824524\n",
      "Eval Loss:  0.16045768558979034\n",
      "Eval Loss:  0.23557573556900024\n",
      "Eval Loss:  0.24330487847328186\n",
      "Eval Loss:  0.1842012107372284\n",
      "Eval Loss:  0.21217934787273407\n",
      "Eval Loss:  0.17946602404117584\n",
      "Eval Loss:  0.1558743119239807\n",
      "[[16952  1139]\n",
      " [ 1150 10576]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18091\n",
      "           1       0.90      0.90      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.92      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9232317134520576\n",
      "pre:  0.9027742210840802\n",
      "rec:  0.9019273409517312\n",
      "ma F1:  0.919553154279224\n",
      "mi F1:  0.9232317134520575\n",
      "we F1:  0.9232253671297709\n",
      "29817 466\n",
      "Loss:  0.04769028350710869\n",
      "Loss:  0.05817190185189247\n",
      "Loss:  0.05944264307618141\n",
      "51 **********\n",
      "Epoch:  2974.345205307007  fold:  8  kers:  64\n",
      "epoch:  52\n",
      "29817 466\n",
      "Loss:  0.06421476602554321\n",
      "Loss:  0.06816975772380829\n",
      "Loss:  0.058964915573596954\n",
      "52 **********\n",
      "Epoch:  3018.7105810642242  fold:  8  kers:  64\n",
      "epoch:  53\n",
      "29817 466\n",
      "Loss:  0.06418196111917496\n",
      "Loss:  0.03854232653975487\n",
      "Loss:  0.04452637583017349\n",
      "53 **********\n",
      "Epoch:  3062.981210708618  fold:  8  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  1.042611002922058\n",
      "Eval Loss:  1.054722785949707\n",
      "Eval Loss:  0.1057034507393837\n",
      "[[1598  475]\n",
      " [ 207  794]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.82      2073\n",
      "           1       0.63      0.79      0.70      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.76      0.78      0.76      3074\n",
      "weighted avg       0.80      0.78      0.78      3074\n",
      "\n",
      "acc:  0.7781392322706572\n",
      "pre:  0.6256895193065406\n",
      "rec:  0.7932067932067932\n",
      "ma F1:  0.7618478120108234\n",
      "mi F1:  0.7781392322706572\n",
      "we F1:  0.7835697056906016\n",
      "Eval Loss:  0.20913705229759216\n",
      "Eval Loss:  0.20757989585399628\n",
      "Eval Loss:  0.22669772803783417\n",
      "Eval Loss:  0.23998446762561798\n",
      "Eval Loss:  0.13648441433906555\n",
      "Eval Loss:  0.22642548382282257\n",
      "Eval Loss:  0.2672227919101715\n",
      "Eval Loss:  0.18816310167312622\n",
      "Eval Loss:  0.20557361841201782\n",
      "Eval Loss:  0.17544278502464294\n",
      "Eval Loss:  0.12659874558448792\n",
      "Eval Loss:  0.19674700498580933\n",
      "Eval Loss:  0.2303084135055542\n",
      "Eval Loss:  0.15085580945014954\n",
      "Eval Loss:  0.20798301696777344\n",
      "Eval Loss:  0.24826940894126892\n",
      "Eval Loss:  0.1874975711107254\n",
      "Eval Loss:  0.23206909000873566\n",
      "Eval Loss:  0.171165332198143\n",
      "Eval Loss:  0.1924048215150833\n",
      "Eval Loss:  0.26581114530563354\n",
      "Eval Loss:  0.24237141013145447\n",
      "Eval Loss:  0.16990980505943298\n",
      "Eval Loss:  0.25984564423561096\n",
      "Eval Loss:  0.24109402298927307\n",
      "Eval Loss:  0.19705870747566223\n",
      "Eval Loss:  0.2149190604686737\n",
      "Eval Loss:  0.19184203445911407\n",
      "Eval Loss:  0.1448441743850708\n",
      "[[17004  1087]\n",
      " [ 1237 10489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18091\n",
      "           1       0.91      0.89      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.92      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9220578864406211\n",
      "pre:  0.9060988251554941\n",
      "rec:  0.894507931093297\n",
      "ma F1:  0.918150210733119\n",
      "mi F1:  0.9220578864406213\n",
      "we F1:  0.9219679169308551\n",
      "29817 466\n",
      "Loss:  0.06535814702510834\n",
      "Loss:  0.05626457929611206\n",
      "Loss:  0.07490981370210648\n",
      "54 **********\n",
      "Epoch:  3146.758207798004  fold:  8  kers:  64\n",
      "epoch:  55\n",
      "29817 466\n",
      "Loss:  0.056555915623903275\n",
      "Loss:  0.08624265342950821\n",
      "Loss:  0.07751695811748505\n",
      "55 **********\n",
      "Epoch:  3191.159487724304  fold:  8  kers:  64\n",
      "epoch:  56\n",
      "29817 466\n",
      "Loss:  0.030424244701862335\n",
      "Loss:  0.04175274074077606\n",
      "Loss:  0.11317960172891617\n",
      "56 **********\n",
      "Epoch:  3235.5208752155304  fold:  8  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.47746652364730835\n",
      "Eval Loss:  0.8828960657119751\n",
      "Eval Loss:  0.09238185733556747\n",
      "[[1821  252]\n",
      " [ 273  728]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      2073\n",
      "           1       0.74      0.73      0.73      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.80      0.80      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8292127521145087\n",
      "pre:  0.7428571428571429\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.8044962056745708\n",
      "mi F1:  0.8292127521145087\n",
      "we F1:  0.8287378687885815\n",
      "Eval Loss:  0.18836398422718048\n",
      "Eval Loss:  0.19146737456321716\n",
      "Eval Loss:  0.2286704033613205\n",
      "Eval Loss:  0.2121848165988922\n",
      "Eval Loss:  0.1473393440246582\n",
      "Eval Loss:  0.24340441823005676\n",
      "Eval Loss:  0.2857639491558075\n",
      "Eval Loss:  0.21770203113555908\n",
      "Eval Loss:  0.2173701673746109\n",
      "Eval Loss:  0.16715139150619507\n",
      "Eval Loss:  0.11781744658946991\n",
      "Eval Loss:  0.17620748281478882\n",
      "Eval Loss:  0.23375767469406128\n",
      "Eval Loss:  0.15127524733543396\n",
      "Eval Loss:  0.1783042550086975\n",
      "Eval Loss:  0.23358795046806335\n",
      "Eval Loss:  0.18146079778671265\n",
      "Eval Loss:  0.23420417308807373\n",
      "Eval Loss:  0.14069072902202606\n",
      "Eval Loss:  0.20355373620986938\n",
      "Eval Loss:  0.275463730096817\n",
      "Eval Loss:  0.1859155297279358\n",
      "Eval Loss:  0.1566949188709259\n",
      "Eval Loss:  0.23497594892978668\n",
      "Eval Loss:  0.28810960054397583\n",
      "Eval Loss:  0.2003054916858673\n",
      "Eval Loss:  0.21656963229179382\n",
      "Eval Loss:  0.18771781027317047\n",
      "Eval Loss:  0.19081588089466095\n",
      "[[17229   862]\n",
      " [ 1477 10249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18091\n",
      "           1       0.92      0.87      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9215548177214341\n",
      "pre:  0.9224192241922419\n",
      "rec:  0.8740405935527886\n",
      "ma F1:  0.9170067632550407\n",
      "mi F1:  0.9215548177214341\n",
      "we F1:  0.9211540937247533\n",
      "29817 466\n",
      "Loss:  0.050983965396881104\n",
      "Loss:  0.04540780559182167\n",
      "Loss:  0.04467306658625603\n",
      "57 **********\n",
      "Epoch:  3318.7313866615295  fold:  8  kers:  64\n",
      "epoch:  58\n",
      "29817 466\n",
      "Loss:  0.05733054131269455\n",
      "Loss:  0.060481078922748566\n",
      "Loss:  0.07332034409046173\n",
      "58 **********\n",
      "Epoch:  3362.9820692539215  fold:  8  kers:  64\n",
      "epoch:  59\n",
      "29817 466\n",
      "Loss:  0.04561389237642288\n",
      "Loss:  0.05138534680008888\n",
      "Loss:  0.05084862932562828\n",
      "59 **********\n",
      "Epoch:  3407.2856109142303  fold:  8  kers:  64\n",
      "Eval Loss:  0.892096221446991\n",
      "Eval Loss:  0.9785785675048828\n",
      "Eval Loss:  0.1381484866142273\n",
      "[[1626  447]\n",
      " [ 190  811]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.84      2073\n",
      "           1       0.64      0.81      0.72      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.77      0.80      0.78      3074\n",
      "weighted avg       0.81      0.79      0.80      3074\n",
      "\n",
      "acc:  0.7927781392322707\n",
      "pre:  0.6446740858505564\n",
      "rec:  0.8101898101898102\n",
      "ma F1:  0.7771107507343842\n",
      "mi F1:  0.7927781392322707\n",
      "we F1:  0.797718653151236\n",
      "update!  Acc:  0.8373454782042941\n",
      "Epoch:  3410.9508106708527  fold:  8  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29483 3408\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29483 461\n",
      "Loss:  0.1675654649734497\n",
      "Loss:  0.15439236164093018\n",
      "Loss:  0.15719708800315857\n",
      "0 **********\n",
      "Epoch:  56.39421200752258  fold:  9  kers:  64\n",
      "epoch:  1\n",
      "29483 461\n",
      "Loss:  0.142460435628891\n",
      "Loss:  0.12325633317232132\n",
      "Loss:  0.13751891255378723\n",
      "1 **********\n",
      "Epoch:  100.41351318359375  fold:  9  kers:  64\n",
      "epoch:  2\n",
      "29483 461\n",
      "Loss:  0.113263338804245\n",
      "Loss:  0.12398607283830643\n",
      "Loss:  0.10491663217544556\n",
      "2 **********\n",
      "Epoch:  144.31313490867615  fold:  9  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.20646759867668152\n",
      "Eval Loss:  1.0156183242797852\n",
      "Eval Loss:  0.3696807622909546\n",
      "[[1528  214]\n",
      " [ 403 1263]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83      1742\n",
      "           1       0.86      0.76      0.80      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.82      0.82      0.82      3408\n",
      "weighted avg       0.82      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8189553990610329\n",
      "pre:  0.8551117129316181\n",
      "rec:  0.7581032412965186\n",
      "ma F1:  0.8178540828893096\n",
      "mi F1:  0.8189553990610329\n",
      "we F1:  0.8181699320555398\n",
      "update!  Acc:  0.8189553990610329\n",
      "Eval Loss:  0.48303842544555664\n",
      "Eval Loss:  0.4185558259487152\n",
      "Eval Loss:  0.4234533905982971\n",
      "Eval Loss:  0.386871337890625\n",
      "Eval Loss:  0.47166675329208374\n",
      "Eval Loss:  0.47910580039024353\n",
      "Eval Loss:  0.4201938509941101\n",
      "Eval Loss:  0.5687458515167236\n",
      "Eval Loss:  0.376223623752594\n",
      "Eval Loss:  0.5298171639442444\n",
      "Eval Loss:  0.4282684326171875\n",
      "Eval Loss:  0.3799397647380829\n",
      "Eval Loss:  0.44436022639274597\n",
      "Eval Loss:  0.5230274796485901\n",
      "Eval Loss:  0.5539478063583374\n",
      "Eval Loss:  0.5268304944038391\n",
      "Eval Loss:  0.4080383777618408\n",
      "Eval Loss:  0.5293564200401306\n",
      "Eval Loss:  0.4789975881576538\n",
      "Eval Loss:  0.39736759662628174\n",
      "Eval Loss:  0.4129968583583832\n",
      "Eval Loss:  0.37503185868263245\n",
      "Eval Loss:  0.39157959818840027\n",
      "Eval Loss:  0.4518638551235199\n",
      "Eval Loss:  0.4421989321708679\n",
      "Eval Loss:  0.5088005661964417\n",
      "Eval Loss:  0.5140851736068726\n",
      "Eval Loss:  0.4129663407802582\n",
      "[[16273  2149]\n",
      " [ 3699  7362]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85     18422\n",
      "           1       0.77      0.67      0.72     11061\n",
      "\n",
      "    accuracy                           0.80     29483\n",
      "   macro avg       0.79      0.77      0.78     29483\n",
      "weighted avg       0.80      0.80      0.80     29483\n",
      "\n",
      "acc:  0.8016484075568971\n",
      "pre:  0.7740510987277889\n",
      "rec:  0.6655817737998373\n",
      "ma F1:  0.7817073263247969\n",
      "mi F1:  0.8016484075568971\n",
      "we F1:  0.7981798096543323\n",
      "29483 461\n",
      "Loss:  0.15439754724502563\n",
      "Loss:  0.0887833833694458\n",
      "Loss:  0.11640819907188416\n",
      "3 **********\n",
      "Epoch:  231.02428698539734  fold:  9  kers:  64\n",
      "epoch:  4\n",
      "29483 461\n",
      "Loss:  0.09432049095630646\n",
      "Loss:  0.09584257751703262\n",
      "Loss:  0.08739412575960159\n",
      "4 **********\n",
      "Epoch:  274.90994572639465  fold:  9  kers:  64\n",
      "epoch:  5\n",
      "29483 461\n",
      "Loss:  0.08265766501426697\n",
      "Loss:  0.07966360449790955\n",
      "Loss:  0.09182649850845337\n",
      "5 **********\n",
      "Epoch:  318.7337691783905  fold:  9  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.1021805927157402\n",
      "Eval Loss:  1.3654848337173462\n",
      "Eval Loss:  0.2211134284734726\n",
      "[[1601  141]\n",
      " [ 474 1192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1742\n",
      "           1       0.89      0.72      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.83      0.82      0.82      3408\n",
      "weighted avg       0.83      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8195422535211268\n",
      "pre:  0.8942235558889723\n",
      "rec:  0.7154861944777912\n",
      "ma F1:  0.8169051722157321\n",
      "mi F1:  0.8195422535211268\n",
      "we F1:  0.8173951922138006\n",
      "update!  Acc:  0.8195422535211268\n",
      "Eval Loss:  0.35186752676963806\n",
      "Eval Loss:  0.3288886547088623\n",
      "Eval Loss:  0.31100866198539734\n",
      "Eval Loss:  0.32579901814460754\n",
      "Eval Loss:  0.3797461986541748\n",
      "Eval Loss:  0.26398903131484985\n",
      "Eval Loss:  0.3828718364238739\n",
      "Eval Loss:  0.4507371783256531\n",
      "Eval Loss:  0.28866317868232727\n",
      "Eval Loss:  0.41461312770843506\n",
      "Eval Loss:  0.37729132175445557\n",
      "Eval Loss:  0.3604081869125366\n",
      "Eval Loss:  0.3618030548095703\n",
      "Eval Loss:  0.3422097861766815\n",
      "Eval Loss:  0.40732938051223755\n",
      "Eval Loss:  0.4470367729663849\n",
      "Eval Loss:  0.32166802883148193\n",
      "Eval Loss:  0.4287344813346863\n",
      "Eval Loss:  0.37042006850242615\n",
      "Eval Loss:  0.3670147657394409\n",
      "Eval Loss:  0.35224467515945435\n",
      "Eval Loss:  0.2509419322013855\n",
      "Eval Loss:  0.2614540457725525\n",
      "Eval Loss:  0.3464891314506531\n",
      "Eval Loss:  0.36847105622291565\n",
      "Eval Loss:  0.4174307584762573\n",
      "Eval Loss:  0.3174690306186676\n",
      "Eval Loss:  0.28415384888648987\n",
      "[[17002  1420]\n",
      " [ 2597  8464]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89     18422\n",
      "           1       0.86      0.77      0.81     11061\n",
      "\n",
      "    accuracy                           0.86     29483\n",
      "   macro avg       0.86      0.84      0.85     29483\n",
      "weighted avg       0.86      0.86      0.86     29483\n",
      "\n",
      "acc:  0.8637519926737441\n",
      "pre:  0.8563334682314853\n",
      "rec:  0.7652111020703373\n",
      "ma F1:  0.8512799220799747\n",
      "mi F1:  0.8637519926737441\n",
      "we F1:  0.8620326641320637\n",
      "29483 461\n",
      "Loss:  0.06249071657657623\n",
      "Loss:  0.07881597429513931\n",
      "Loss:  0.10465869307518005\n",
      "6 **********\n",
      "Epoch:  401.12946033477783  fold:  9  kers:  64\n",
      "epoch:  7\n",
      "29483 461\n",
      "Loss:  0.09767569601535797\n",
      "Loss:  0.07448838651180267\n",
      "Loss:  0.07167204469442368\n",
      "7 **********\n",
      "Epoch:  445.0350651741028  fold:  9  kers:  64\n",
      "epoch:  8\n",
      "29483 461\n",
      "Loss:  0.09976831078529358\n",
      "Loss:  0.08215542137622833\n",
      "Loss:  0.09534002095460892\n",
      "8 **********\n",
      "Epoch:  488.8080253601074  fold:  9  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.0717901960015297\n",
      "Eval Loss:  1.5860925912857056\n",
      "Eval Loss:  0.25082671642303467\n",
      "[[1652   90]\n",
      " [ 564 1102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.83      1742\n",
      "           1       0.92      0.66      0.77      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.83      0.80      0.80      3408\n",
      "weighted avg       0.83      0.81      0.80      3408\n",
      "\n",
      "acc:  0.8080985915492958\n",
      "pre:  0.924496644295302\n",
      "rec:  0.6614645858343338\n",
      "ma F1:  0.8029668411250248\n",
      "mi F1:  0.8080985915492958\n",
      "we F1:  0.8036759557291059\n",
      "Eval Loss:  0.39175283908843994\n",
      "Eval Loss:  0.36074259877204895\n",
      "Eval Loss:  0.3723960518836975\n",
      "Eval Loss:  0.3414745628833771\n",
      "Eval Loss:  0.36595770716667175\n",
      "Eval Loss:  0.2743825316429138\n",
      "Eval Loss:  0.36827415227890015\n",
      "Eval Loss:  0.4512454867362976\n",
      "Eval Loss:  0.29133519530296326\n",
      "Eval Loss:  0.3984440267086029\n",
      "Eval Loss:  0.3570835590362549\n",
      "Eval Loss:  0.34649449586868286\n",
      "Eval Loss:  0.348194420337677\n",
      "Eval Loss:  0.39686650037765503\n",
      "Eval Loss:  0.4376036822795868\n",
      "Eval Loss:  0.4594659209251404\n",
      "Eval Loss:  0.3029734194278717\n",
      "Eval Loss:  0.4096778631210327\n",
      "Eval Loss:  0.38199570775032043\n",
      "Eval Loss:  0.32126808166503906\n",
      "Eval Loss:  0.35332047939300537\n",
      "Eval Loss:  0.24563269317150116\n",
      "Eval Loss:  0.25603777170181274\n",
      "Eval Loss:  0.34350812435150146\n",
      "Eval Loss:  0.3568631410598755\n",
      "Eval Loss:  0.41642293334007263\n",
      "Eval Loss:  0.30443111062049866\n",
      "Eval Loss:  0.27134281396865845\n",
      "[[17611   811]\n",
      " [ 3137  7924]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     18422\n",
      "           1       0.91      0.72      0.80     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.88      0.84      0.85     29483\n",
      "weighted avg       0.87      0.87      0.86     29483\n",
      "\n",
      "acc:  0.8660923243903267\n",
      "pre:  0.9071551230681167\n",
      "rec:  0.7163909230630142\n",
      "ma F1:  0.8498871744280814\n",
      "mi F1:  0.8660923243903267\n",
      "we F1:  0.8622012147782504\n",
      "29483 461\n",
      "Loss:  0.08758138865232468\n",
      "Loss:  0.10580775886774063\n",
      "Loss:  0.06770893931388855\n",
      "9 **********\n",
      "Epoch:  571.2446069717407  fold:  9  kers:  64\n",
      "epoch:  10\n",
      "29483 461\n",
      "Loss:  0.08404923230409622\n",
      "Loss:  0.05504538118839264\n",
      "Loss:  0.05699555575847626\n",
      "10 **********\n",
      "Epoch:  614.9886441230774  fold:  9  kers:  64\n",
      "epoch:  11\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06035253405570984\n",
      "Loss:  0.08977827429771423\n",
      "Loss:  0.07063096016645432\n",
      "11 **********\n",
      "Epoch:  658.7117373943329  fold:  9  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.063871830701828\n",
      "Eval Loss:  1.456841230392456\n",
      "Eval Loss:  0.2124846875667572\n",
      "[[1646   96]\n",
      " [ 546 1120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.84      1742\n",
      "           1       0.92      0.67      0.78      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.81      0.81      3408\n",
      "weighted avg       0.83      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8116197183098591\n",
      "pre:  0.9210526315789473\n",
      "rec:  0.6722689075630253\n",
      "ma F1:  0.807022674969756\n",
      "mi F1:  0.8116197183098591\n",
      "we F1:  0.8076868865550182\n",
      "Eval Loss:  0.35060223937034607\n",
      "Eval Loss:  0.3251705765724182\n",
      "Eval Loss:  0.3270430564880371\n",
      "Eval Loss:  0.2984015941619873\n",
      "Eval Loss:  0.29774588346481323\n",
      "Eval Loss:  0.21051901578903198\n",
      "Eval Loss:  0.31142982840538025\n",
      "Eval Loss:  0.3815171718597412\n",
      "Eval Loss:  0.26818540692329407\n",
      "Eval Loss:  0.3512929081916809\n",
      "Eval Loss:  0.30970582365989685\n",
      "Eval Loss:  0.32883694767951965\n",
      "Eval Loss:  0.300714910030365\n",
      "Eval Loss:  0.30721500515937805\n",
      "Eval Loss:  0.3601209223270416\n",
      "Eval Loss:  0.347761869430542\n",
      "Eval Loss:  0.2885531187057495\n",
      "Eval Loss:  0.29437458515167236\n",
      "Eval Loss:  0.2963710427284241\n",
      "Eval Loss:  0.2959021031856537\n",
      "Eval Loss:  0.3435153067111969\n",
      "Eval Loss:  0.20217309892177582\n",
      "Eval Loss:  0.23519185185432434\n",
      "Eval Loss:  0.3075597882270813\n",
      "Eval Loss:  0.31731563806533813\n",
      "Eval Loss:  0.35960492491722107\n",
      "Eval Loss:  0.26993808150291443\n",
      "Eval Loss:  0.25461217761039734\n",
      "[[17482   940]\n",
      " [ 2532  8529]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18422\n",
      "           1       0.90      0.77      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.89      0.86      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.882237221449649\n",
      "pre:  0.9007286936318513\n",
      "rec:  0.7710876050989964\n",
      "ma F1:  0.870274828097157\n",
      "mi F1:  0.882237221449649\n",
      "we F1:  0.8801100986732424\n",
      "29483 461\n",
      "Loss:  0.058989353477954865\n",
      "Loss:  0.07000148296356201\n",
      "Loss:  0.10756821930408478\n",
      "12 **********\n",
      "Epoch:  741.1961908340454  fold:  9  kers:  64\n",
      "epoch:  13\n",
      "29483 461\n",
      "Loss:  0.07705557346343994\n",
      "Loss:  0.06143268197774887\n",
      "Loss:  0.06933925300836563\n",
      "13 **********\n",
      "Epoch:  784.964164018631  fold:  9  kers:  64\n",
      "epoch:  14\n",
      "29483 461\n",
      "Loss:  0.07832827419042587\n",
      "Loss:  0.07881761342287064\n",
      "Loss:  0.044865336269140244\n",
      "14 **********\n",
      "Epoch:  828.7441058158875  fold:  9  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.06535957753658295\n",
      "Eval Loss:  0.9315341114997864\n",
      "Eval Loss:  0.20393261313438416\n",
      "[[1637  105]\n",
      " [ 454 1212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      1742\n",
      "           1       0.92      0.73      0.81      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.84      0.83      3408\n",
      "\n",
      "acc:  0.8359741784037559\n",
      "pre:  0.9202733485193622\n",
      "rec:  0.7274909963985594\n",
      "ma F1:  0.8333829958599206\n",
      "mi F1:  0.8359741784037559\n",
      "we F1:  0.8338463602677595\n",
      "update!  Acc:  0.8359741784037559\n",
      "Eval Loss:  0.3090146481990814\n",
      "Eval Loss:  0.3098198473453522\n",
      "Eval Loss:  0.31208348274230957\n",
      "Eval Loss:  0.2837579548358917\n",
      "Eval Loss:  0.27050238847732544\n",
      "Eval Loss:  0.19846197962760925\n",
      "Eval Loss:  0.28027817606925964\n",
      "Eval Loss:  0.33958202600479126\n",
      "Eval Loss:  0.2533763349056244\n",
      "Eval Loss:  0.27718883752822876\n",
      "Eval Loss:  0.28065329790115356\n",
      "Eval Loss:  0.3351022005081177\n",
      "Eval Loss:  0.26201266050338745\n",
      "Eval Loss:  0.29051274061203003\n",
      "Eval Loss:  0.31926795840263367\n",
      "Eval Loss:  0.2837303876876831\n",
      "Eval Loss:  0.2515917122364044\n",
      "Eval Loss:  0.2662801444530487\n",
      "Eval Loss:  0.26152855157852173\n",
      "Eval Loss:  0.2885581851005554\n",
      "Eval Loss:  0.3291217088699341\n",
      "Eval Loss:  0.18602126836776733\n",
      "Eval Loss:  0.2159176766872406\n",
      "Eval Loss:  0.26059651374816895\n",
      "Eval Loss:  0.3078843355178833\n",
      "Eval Loss:  0.3451544940471649\n",
      "Eval Loss:  0.2431129366159439\n",
      "Eval Loss:  0.22331959009170532\n",
      "[[17347  1075]\n",
      " [ 2086  8975]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     18422\n",
      "           1       0.89      0.81      0.85     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.88      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8927856730997524\n",
      "pre:  0.8930348258706468\n",
      "rec:  0.8114094566494892\n",
      "ma F1:  0.8833823966020791\n",
      "mi F1:  0.8927856730997524\n",
      "we F1:  0.8916501364849473\n",
      "29483 461\n",
      "Loss:  0.07069461047649384\n",
      "Loss:  0.08856420964002609\n",
      "Loss:  0.05488238483667374\n",
      "15 **********\n",
      "Epoch:  911.2215769290924  fold:  9  kers:  64\n",
      "epoch:  16\n",
      "29483 461\n",
      "Loss:  0.060824956744909286\n",
      "Loss:  0.08128514885902405\n",
      "Loss:  0.04015422612428665\n",
      "16 **********\n",
      "Epoch:  955.083300113678  fold:  9  kers:  64\n",
      "epoch:  17\n",
      "29483 461\n",
      "Loss:  0.052254412323236465\n",
      "Loss:  0.0828162282705307\n",
      "Loss:  0.08791224658489227\n",
      "17 **********\n",
      "Epoch:  998.962975025177  fold:  9  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.04481717571616173\n",
      "Eval Loss:  1.2823395729064941\n",
      "Eval Loss:  0.20509546995162964\n",
      "[[1670   72]\n",
      " [ 577 1089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.84      1742\n",
      "           1       0.94      0.65      0.77      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.81      0.80      3408\n",
      "weighted avg       0.84      0.81      0.80      3408\n",
      "\n",
      "acc:  0.8095657276995305\n",
      "pre:  0.937984496124031\n",
      "rec:  0.6536614645858343\n",
      "ma F1:  0.8038652988324897\n",
      "mi F1:  0.8095657276995305\n",
      "we F1:  0.8046109659476276\n",
      "Eval Loss:  0.33781689405441284\n",
      "Eval Loss:  0.3015793561935425\n",
      "Eval Loss:  0.31605467200279236\n",
      "Eval Loss:  0.27733269333839417\n",
      "Eval Loss:  0.27353712916374207\n",
      "Eval Loss:  0.20415863394737244\n",
      "Eval Loss:  0.27951130270957947\n",
      "Eval Loss:  0.3368743658065796\n",
      "Eval Loss:  0.26880839467048645\n",
      "Eval Loss:  0.31302160024642944\n",
      "Eval Loss:  0.25863248109817505\n",
      "Eval Loss:  0.31202319264411926\n",
      "Eval Loss:  0.2607029676437378\n",
      "Eval Loss:  0.2592550814151764\n",
      "Eval Loss:  0.3155580163002014\n",
      "Eval Loss:  0.3145705461502075\n",
      "Eval Loss:  0.24606110155582428\n",
      "Eval Loss:  0.27635300159454346\n",
      "Eval Loss:  0.2507278025150299\n",
      "Eval Loss:  0.2753715515136719\n",
      "Eval Loss:  0.3343011736869812\n",
      "Eval Loss:  0.19539767503738403\n",
      "Eval Loss:  0.22345036268234253\n",
      "Eval Loss:  0.26439541578292847\n",
      "Eval Loss:  0.3093843162059784\n",
      "Eval Loss:  0.32209232449531555\n",
      "Eval Loss:  0.23923569917678833\n",
      "Eval Loss:  0.21464188396930695\n",
      "[[17575   847]\n",
      " [ 2361  8700]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     18422\n",
      "           1       0.91      0.79      0.84     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.90      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8911915341043991\n",
      "pre:  0.9112810306902692\n",
      "rec:  0.7865473284513155\n",
      "ma F1:  0.8803495788613258\n",
      "mi F1:  0.8911915341043992\n",
      "we F1:  0.8893419881620878\n",
      "29483 461\n",
      "Loss:  0.07964762300252914\n",
      "Loss:  0.06890688836574554\n",
      "Loss:  0.042334362864494324\n",
      "18 **********\n",
      "Epoch:  1081.4494228363037  fold:  9  kers:  64\n",
      "epoch:  19\n",
      "29483 461\n",
      "Loss:  0.07503973692655563\n",
      "Loss:  0.05151345580816269\n",
      "Loss:  0.08828862756490707\n",
      "19 **********\n",
      "Epoch:  1125.2902014255524  fold:  9  kers:  64\n",
      "epoch:  20\n",
      "29483 461\n",
      "Loss:  0.07968948781490326\n",
      "Loss:  0.09335354715585709\n",
      "Loss:  0.048695240169763565\n",
      "20 **********\n",
      "Epoch:  1169.1269903182983  fold:  9  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.0443277433514595\n",
      "Eval Loss:  0.9167624711990356\n",
      "Eval Loss:  0.1965767741203308\n",
      "[[1654   88]\n",
      " [ 507 1159]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85      1742\n",
      "           1       0.93      0.70      0.80      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.82      0.82      3408\n",
      "weighted avg       0.85      0.83      0.82      3408\n",
      "\n",
      "acc:  0.8254107981220657\n",
      "pre:  0.9294306335204491\n",
      "rec:  0.6956782713085234\n",
      "ma F1:  0.8216481921403509\n",
      "mi F1:  0.8254107981220657\n",
      "we F1:  0.8222258851799676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.33181580901145935\n",
      "Eval Loss:  0.2869437336921692\n",
      "Eval Loss:  0.27905935049057007\n",
      "Eval Loss:  0.2666451930999756\n",
      "Eval Loss:  0.2646024525165558\n",
      "Eval Loss:  0.18822085857391357\n",
      "Eval Loss:  0.26519060134887695\n",
      "Eval Loss:  0.29127630591392517\n",
      "Eval Loss:  0.2601896822452545\n",
      "Eval Loss:  0.23137864470481873\n",
      "Eval Loss:  0.2621168792247772\n",
      "Eval Loss:  0.31577828526496887\n",
      "Eval Loss:  0.23916947841644287\n",
      "Eval Loss:  0.23893976211547852\n",
      "Eval Loss:  0.31486934423446655\n",
      "Eval Loss:  0.2697738707065582\n",
      "Eval Loss:  0.2624695301055908\n",
      "Eval Loss:  0.2593719959259033\n",
      "Eval Loss:  0.22429485619068146\n",
      "Eval Loss:  0.2735334038734436\n",
      "Eval Loss:  0.32058534026145935\n",
      "Eval Loss:  0.1990630030632019\n",
      "Eval Loss:  0.19666804373264313\n",
      "Eval Loss:  0.25908002257347107\n",
      "Eval Loss:  0.2897169291973114\n",
      "Eval Loss:  0.30106088519096375\n",
      "Eval Loss:  0.22820793092250824\n",
      "Eval Loss:  0.20544973015785217\n",
      "[[17531   891]\n",
      " [ 2018  9043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18422\n",
      "           1       0.91      0.82      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.901332971542923\n",
      "pre:  0.9103080330179183\n",
      "rec:  0.8175571828948558\n",
      "ma F1:  0.8924160514094595\n",
      "mi F1:  0.901332971542923\n",
      "we F1:  0.9001490213791138\n",
      "29483 461\n",
      "Loss:  0.060070931911468506\n",
      "Loss:  0.07078810036182404\n",
      "Loss:  0.05434423312544823\n",
      "21 **********\n",
      "Epoch:  1251.4010066986084  fold:  9  kers:  64\n",
      "epoch:  22\n",
      "29483 461\n",
      "Loss:  0.06479296088218689\n",
      "Loss:  0.06624036282300949\n",
      "Loss:  0.05501239374279976\n",
      "22 **********\n",
      "Epoch:  1295.2617321014404  fold:  9  kers:  64\n",
      "epoch:  23\n",
      "29483 461\n",
      "Loss:  0.05980418249964714\n",
      "Loss:  0.05643277242779732\n",
      "Loss:  0.04786216467618942\n",
      "23 **********\n",
      "Epoch:  1339.0317006111145  fold:  9  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.0389825701713562\n",
      "Eval Loss:  1.1128605604171753\n",
      "Eval Loss:  0.2328156679868698\n",
      "[[1669   73]\n",
      " [ 576 1090]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.84      1742\n",
      "           1       0.94      0.65      0.77      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.81      0.80      3408\n",
      "weighted avg       0.84      0.81      0.80      3408\n",
      "\n",
      "acc:  0.8095657276995305\n",
      "pre:  0.937231298366294\n",
      "rec:  0.6542617046818727\n",
      "ma F1:  0.8039056413726371\n",
      "mi F1:  0.8095657276995305\n",
      "we F1:  0.804648588800692\n",
      "Eval Loss:  0.33812829852104187\n",
      "Eval Loss:  0.3001421093940735\n",
      "Eval Loss:  0.3208356201648712\n",
      "Eval Loss:  0.2593063712120056\n",
      "Eval Loss:  0.2703806757926941\n",
      "Eval Loss:  0.19893333315849304\n",
      "Eval Loss:  0.2980545461177826\n",
      "Eval Loss:  0.30800774693489075\n",
      "Eval Loss:  0.2616984248161316\n",
      "Eval Loss:  0.22439901530742645\n",
      "Eval Loss:  0.25569766759872437\n",
      "Eval Loss:  0.3027655780315399\n",
      "Eval Loss:  0.25847673416137695\n",
      "Eval Loss:  0.2408386766910553\n",
      "Eval Loss:  0.3361189365386963\n",
      "Eval Loss:  0.2575570046901703\n",
      "Eval Loss:  0.259761780500412\n",
      "Eval Loss:  0.25612691044807434\n",
      "Eval Loss:  0.2508363127708435\n",
      "Eval Loss:  0.2765883505344391\n",
      "Eval Loss:  0.3256741464138031\n",
      "Eval Loss:  0.20092634856700897\n",
      "Eval Loss:  0.212736576795578\n",
      "Eval Loss:  0.259131520986557\n",
      "Eval Loss:  0.30002880096435547\n",
      "Eval Loss:  0.31452199816703796\n",
      "Eval Loss:  0.23050974309444427\n",
      "Eval Loss:  0.19811509549617767\n",
      "[[17727   695]\n",
      " [ 2326  8735]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18422\n",
      "           1       0.93      0.79      0.85     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8975341722348472\n",
      "pre:  0.9262990455991517\n",
      "rec:  0.7897115993129011\n",
      "ma F1:  0.8870254511013868\n",
      "mi F1:  0.8975341722348472\n",
      "we F1:  0.8956280641200035\n",
      "29483 461\n",
      "Loss:  0.07354399561882019\n",
      "Loss:  0.04933217540383339\n",
      "Loss:  0.1034378781914711\n",
      "24 **********\n",
      "Epoch:  1421.4972043037415  fold:  9  kers:  64\n",
      "epoch:  25\n",
      "29483 461\n",
      "Loss:  0.05580320954322815\n",
      "Loss:  0.05826364830136299\n",
      "Loss:  0.05044987052679062\n",
      "25 **********\n",
      "Epoch:  1465.3439676761627  fold:  9  kers:  64\n",
      "epoch:  26\n",
      "29483 461\n",
      "Loss:  0.04341014474630356\n",
      "Loss:  0.058856409043073654\n",
      "Loss:  0.05925881862640381\n",
      "26 **********\n",
      "Epoch:  1509.1288948059082  fold:  9  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.04204843193292618\n",
      "Eval Loss:  1.3716812133789062\n",
      "Eval Loss:  0.2371131032705307\n",
      "[[1694   48]\n",
      " [ 645 1021]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.83      1742\n",
      "           1       0.96      0.61      0.75      1666\n",
      "\n",
      "    accuracy                           0.80      3408\n",
      "   macro avg       0.84      0.79      0.79      3408\n",
      "weighted avg       0.84      0.80      0.79      3408\n",
      "\n",
      "acc:  0.7966549295774648\n",
      "pre:  0.9550982226379794\n",
      "rec:  0.6128451380552221\n",
      "ma F1:  0.7884032975751095\n",
      "mi F1:  0.7966549295774646\n",
      "we F1:  0.7893351312039045\n",
      "Eval Loss:  0.3722323775291443\n",
      "Eval Loss:  0.30536362528800964\n",
      "Eval Loss:  0.316672682762146\n",
      "Eval Loss:  0.27778857946395874\n",
      "Eval Loss:  0.28901636600494385\n",
      "Eval Loss:  0.24114400148391724\n",
      "Eval Loss:  0.30423712730407715\n",
      "Eval Loss:  0.3275698125362396\n",
      "Eval Loss:  0.26453080773353577\n",
      "Eval Loss:  0.29569321870803833\n",
      "Eval Loss:  0.28186121582984924\n",
      "Eval Loss:  0.2969864308834076\n",
      "Eval Loss:  0.275911420583725\n",
      "Eval Loss:  0.2838296890258789\n",
      "Eval Loss:  0.3492765426635742\n",
      "Eval Loss:  0.3185953199863434\n",
      "Eval Loss:  0.2570016086101532\n",
      "Eval Loss:  0.3252740800380707\n",
      "Eval Loss:  0.27077579498291016\n",
      "Eval Loss:  0.2841070890426636\n",
      "Eval Loss:  0.3306615650653839\n",
      "Eval Loss:  0.24814727902412415\n",
      "Eval Loss:  0.2414976805448532\n",
      "Eval Loss:  0.2572362720966339\n",
      "Eval Loss:  0.32265520095825195\n",
      "Eval Loss:  0.3222227394580841\n",
      "Eval Loss:  0.2516806423664093\n",
      "Eval Loss:  0.20453159511089325\n",
      "[[17840   582]\n",
      " [ 2708  8353]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     18422\n",
      "           1       0.93      0.76      0.84     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.90      0.86      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8884102703252722\n",
      "pre:  0.9348628987129267\n",
      "rec:  0.7551758430521652\n",
      "ma F1:  0.8755215887929959\n",
      "mi F1:  0.8884102703252722\n",
      "we F1:  0.8855219666531293\n",
      "29483 461\n",
      "Loss:  0.04941331967711449\n",
      "Loss:  0.0986061543226242\n",
      "Loss:  0.055812329053878784\n",
      "27 **********\n",
      "Epoch:  1591.637284040451  fold:  9  kers:  64\n",
      "epoch:  28\n",
      "29483 461\n",
      "Loss:  0.10461939126253128\n",
      "Loss:  0.0668778121471405\n",
      "Loss:  0.06281262636184692\n",
      "28 **********\n",
      "Epoch:  1635.4192197322845  fold:  9  kers:  64\n",
      "epoch:  29\n",
      "29483 461\n",
      "Loss:  0.08575235307216644\n",
      "Loss:  0.056745126843452454\n",
      "Loss:  0.046036362648010254\n",
      "29 **********\n",
      "Epoch:  1679.2839353084564  fold:  9  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.04206203669309616\n",
      "Eval Loss:  1.2940303087234497\n",
      "Eval Loss:  0.2118718922138214\n",
      "[[1656   86]\n",
      " [ 522 1144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84      1742\n",
      "           1       0.93      0.69      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.85      0.82      0.82      3408\n",
      "weighted avg       0.84      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8215962441314554\n",
      "pre:  0.9300813008130081\n",
      "rec:  0.6866746698679472\n",
      "ma F1:  0.817476603901229\n",
      "mi F1:  0.8215962441314554\n",
      "we F1:  0.8180881129979033\n",
      "Eval Loss:  0.31551361083984375\n",
      "Eval Loss:  0.2510736584663391\n",
      "Eval Loss:  0.29499292373657227\n",
      "Eval Loss:  0.22362595796585083\n",
      "Eval Loss:  0.24331124126911163\n",
      "Eval Loss:  0.18408550322055817\n",
      "Eval Loss:  0.25671032071113586\n",
      "Eval Loss:  0.25204360485076904\n",
      "Eval Loss:  0.2272179126739502\n",
      "Eval Loss:  0.20699205994606018\n",
      "Eval Loss:  0.23114736378192902\n",
      "Eval Loss:  0.2544257640838623\n",
      "Eval Loss:  0.23398184776306152\n",
      "Eval Loss:  0.18734490871429443\n",
      "Eval Loss:  0.3107048273086548\n",
      "Eval Loss:  0.21461504697799683\n",
      "Eval Loss:  0.211528018116951\n",
      "Eval Loss:  0.21684977412223816\n",
      "Eval Loss:  0.21792365610599518\n",
      "Eval Loss:  0.25317931175231934\n",
      "Eval Loss:  0.30659568309783936\n",
      "Eval Loss:  0.19236238300800323\n",
      "Eval Loss:  0.20426534116268158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22697587311267853\n",
      "Eval Loss:  0.25426676869392395\n",
      "Eval Loss:  0.2973986268043518\n",
      "Eval Loss:  0.22819547355175018\n",
      "Eval Loss:  0.19368265569210052\n",
      "[[17535   887]\n",
      " [ 1827  9234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18422\n",
      "           1       0.91      0.83      0.87     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.89      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9079469524810908\n",
      "pre:  0.9123604386918289\n",
      "rec:  0.8348250610252238\n",
      "ma F1:  0.9000214993442893\n",
      "mi F1:  0.9079469524810907\n",
      "we F1:  0.9070494791708157\n",
      "29483 461\n",
      "Loss:  0.05677727982401848\n",
      "Loss:  0.07772419601678848\n",
      "Loss:  0.06622234731912613\n",
      "30 **********\n",
      "Epoch:  1761.7643988132477  fold:  9  kers:  64\n",
      "epoch:  31\n",
      "29483 461\n",
      "Loss:  0.11241790652275085\n",
      "Loss:  0.07362350076436996\n",
      "Loss:  0.05704222619533539\n",
      "31 **********\n",
      "Epoch:  1805.5543131828308  fold:  9  kers:  64\n",
      "epoch:  32\n",
      "29483 461\n",
      "Loss:  0.06986501812934875\n",
      "Loss:  0.07762947678565979\n",
      "Loss:  0.09336618334054947\n",
      "32 **********\n",
      "Epoch:  1849.4678974151611  fold:  9  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.04745715111494064\n",
      "Eval Loss:  1.2829158306121826\n",
      "Eval Loss:  0.24149423837661743\n",
      "[[1678   64]\n",
      " [ 572 1094]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84      1742\n",
      "           1       0.94      0.66      0.77      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.85      0.81      0.81      3408\n",
      "weighted avg       0.84      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8133802816901409\n",
      "pre:  0.9447322970639033\n",
      "rec:  0.6566626650660264\n",
      "ma F1:  0.807734449068108\n",
      "mi F1:  0.8133802816901409\n",
      "we F1:  0.8084691807107012\n",
      "Eval Loss:  0.311454713344574\n",
      "Eval Loss:  0.2526589334011078\n",
      "Eval Loss:  0.2888615131378174\n",
      "Eval Loss:  0.2234499305486679\n",
      "Eval Loss:  0.24373728036880493\n",
      "Eval Loss:  0.18710444867610931\n",
      "Eval Loss:  0.2766260802745819\n",
      "Eval Loss:  0.26104360818862915\n",
      "Eval Loss:  0.22392798960208893\n",
      "Eval Loss:  0.20976845920085907\n",
      "Eval Loss:  0.22649645805358887\n",
      "Eval Loss:  0.25874462723731995\n",
      "Eval Loss:  0.22762452065944672\n",
      "Eval Loss:  0.20929887890815735\n",
      "Eval Loss:  0.31356653571128845\n",
      "Eval Loss:  0.23079128563404083\n",
      "Eval Loss:  0.2284308522939682\n",
      "Eval Loss:  0.24902841448783875\n",
      "Eval Loss:  0.2239714413881302\n",
      "Eval Loss:  0.26670560240745544\n",
      "Eval Loss:  0.30177295207977295\n",
      "Eval Loss:  0.2061510682106018\n",
      "Eval Loss:  0.21694804728031158\n",
      "Eval Loss:  0.2165822833776474\n",
      "Eval Loss:  0.2577058672904968\n",
      "Eval Loss:  0.2917582094669342\n",
      "Eval Loss:  0.21441909670829773\n",
      "Eval Loss:  0.189236581325531\n",
      "[[17737   685]\n",
      " [ 2063  8998]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18422\n",
      "           1       0.93      0.81      0.87     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.89      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9067937455482821\n",
      "pre:  0.9292574615305174\n",
      "rec:  0.8134888346442456\n",
      "ma F1:  0.8978160965280816\n",
      "mi F1:  0.9067937455482821\n",
      "we F1:  0.9053781144291795\n",
      "29483 461\n",
      "Loss:  0.05885857343673706\n",
      "Loss:  0.07639104872941971\n",
      "Loss:  0.04823776334524155\n",
      "33 **********\n",
      "Epoch:  1931.970302581787  fold:  9  kers:  64\n",
      "epoch:  34\n",
      "29483 461\n",
      "Loss:  0.07596403360366821\n",
      "Loss:  0.06099320948123932\n",
      "Loss:  0.08560366183519363\n",
      "34 **********\n",
      "Epoch:  1975.8370118141174  fold:  9  kers:  64\n",
      "epoch:  35\n",
      "29483 461\n",
      "Loss:  0.046745315194129944\n",
      "Loss:  0.03495596721768379\n",
      "Loss:  0.0778006911277771\n",
      "35 **********\n",
      "Epoch:  2019.7196791172028  fold:  9  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.04423299431800842\n",
      "Eval Loss:  1.037289023399353\n",
      "Eval Loss:  0.23375757038593292\n",
      "[[1656   86]\n",
      " [ 552 1114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84      1742\n",
      "           1       0.93      0.67      0.78      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.81      0.81      3408\n",
      "weighted avg       0.84      0.81      0.81      3408\n",
      "\n",
      "acc:  0.812793427230047\n",
      "pre:  0.9283333333333333\n",
      "rec:  0.6686674669867947\n",
      "ma F1:  0.8079355516884998\n",
      "mi F1:  0.8127934272300471\n",
      "we F1:  0.8086167298087168\n",
      "Eval Loss:  0.3196471929550171\n",
      "Eval Loss:  0.2719508707523346\n",
      "Eval Loss:  0.2914969027042389\n",
      "Eval Loss:  0.21415452659130096\n",
      "Eval Loss:  0.23872634768486023\n",
      "Eval Loss:  0.17204013466835022\n",
      "Eval Loss:  0.25162196159362793\n",
      "Eval Loss:  0.2468031346797943\n",
      "Eval Loss:  0.22453522682189941\n",
      "Eval Loss:  0.20481830835342407\n",
      "Eval Loss:  0.22986388206481934\n",
      "Eval Loss:  0.24833564460277557\n",
      "Eval Loss:  0.22579261660575867\n",
      "Eval Loss:  0.18604199588298798\n",
      "Eval Loss:  0.31765368580818176\n",
      "Eval Loss:  0.22290414571762085\n",
      "Eval Loss:  0.23915013670921326\n",
      "Eval Loss:  0.24668535590171814\n",
      "Eval Loss:  0.22024670243263245\n",
      "Eval Loss:  0.2394910603761673\n",
      "Eval Loss:  0.2839556634426117\n",
      "Eval Loss:  0.194865420460701\n",
      "Eval Loss:  0.2144516259431839\n",
      "Eval Loss:  0.21163755655288696\n",
      "Eval Loss:  0.23156045377254486\n",
      "Eval Loss:  0.3195827901363373\n",
      "Eval Loss:  0.2131710946559906\n",
      "Eval Loss:  0.18842387199401855\n",
      "[[17698   724]\n",
      " [ 1907  9154]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18422\n",
      "           1       0.93      0.83      0.87     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.89      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9107621341111827\n",
      "pre:  0.9267058108928933\n",
      "rec:  0.8275924419130277\n",
      "ma F1:  0.9025808089562339\n",
      "mi F1:  0.9107621341111827\n",
      "we F1:  0.9096293499751452\n",
      "29483 461\n",
      "Loss:  0.05193537473678589\n",
      "Loss:  0.052958209067583084\n",
      "Loss:  0.04798964411020279\n",
      "36 **********\n",
      "Epoch:  2102.1482815742493  fold:  9  kers:  64\n",
      "epoch:  37\n",
      "29483 461\n",
      "Loss:  0.02462557889521122\n",
      "Loss:  0.05171982944011688\n",
      "Loss:  0.08476652950048447\n",
      "37 **********\n",
      "Epoch:  2146.139658689499  fold:  9  kers:  64\n",
      "epoch:  38\n",
      "29483 461\n",
      "Loss:  0.044475145637989044\n",
      "Loss:  0.03805117681622505\n",
      "Loss:  0.054117362946271896\n",
      "38 **********\n",
      "Epoch:  2190.02431845665  fold:  9  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.03813614696264267\n",
      "Eval Loss:  1.4078426361083984\n",
      "Eval Loss:  0.2236449271440506\n",
      "[[1645   97]\n",
      " [ 551 1115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.84      1742\n",
      "           1       0.92      0.67      0.77      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.83      0.81      0.81      3408\n",
      "weighted avg       0.83      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8098591549295775\n",
      "pre:  0.91996699669967\n",
      "rec:  0.6692677070828331\n",
      "ma F1:  0.8051465540760172\n",
      "mi F1:  0.8098591549295775\n",
      "we F1:  0.8058223232550183\n",
      "Eval Loss:  0.3235967755317688\n",
      "Eval Loss:  0.23244841396808624\n",
      "Eval Loss:  0.24413609504699707\n",
      "Eval Loss:  0.19622109830379486\n",
      "Eval Loss:  0.20806102454662323\n",
      "Eval Loss:  0.15707258880138397\n",
      "Eval Loss:  0.21663127839565277\n",
      "Eval Loss:  0.20357729494571686\n",
      "Eval Loss:  0.22628352046012878\n",
      "Eval Loss:  0.1813894361257553\n",
      "Eval Loss:  0.22631022334098816\n",
      "Eval Loss:  0.24154780805110931\n",
      "Eval Loss:  0.19670426845550537\n",
      "Eval Loss:  0.1745578944683075\n",
      "Eval Loss:  0.31675010919570923\n",
      "Eval Loss:  0.20409241318702698\n",
      "Eval Loss:  0.20478500425815582\n",
      "Eval Loss:  0.23668977618217468\n",
      "Eval Loss:  0.21095457673072815\n",
      "Eval Loss:  0.2677866816520691\n",
      "Eval Loss:  0.2766697108745575\n",
      "Eval Loss:  0.1812213957309723\n",
      "Eval Loss:  0.1912308633327484\n",
      "Eval Loss:  0.1702652871608734\n",
      "Eval Loss:  0.22561681270599365\n",
      "Eval Loss:  0.3035956025123596\n",
      "Eval Loss:  0.20821741223335266\n",
      "Eval Loss:  0.18999403715133667\n",
      "[[17595   827]\n",
      " [ 1664  9397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18422\n",
      "           1       0.92      0.85      0.88     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.90      0.91     29483\n",
      "weighted avg       0.92      0.92      0.91     29483\n",
      "\n",
      "acc:  0.9155106332462775\n",
      "pre:  0.9191118935837246\n",
      "rec:  0.8495615224663231\n",
      "ma F1:  0.9084308198885096\n",
      "mi F1:  0.9155106332462775\n",
      "we F1:  0.9147877979473689\n",
      "29483 461\n",
      "Loss:  0.04193291440606117\n",
      "Loss:  0.039962347596883774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.058578524738550186\n",
      "39 **********\n",
      "Epoch:  2272.5775883197784  fold:  9  kers:  64\n",
      "epoch:  40\n",
      "29483 461\n",
      "Loss:  0.06481415033340454\n",
      "Loss:  0.05648966506123543\n",
      "Loss:  0.04670620709657669\n",
      "40 **********\n",
      "Epoch:  2316.3565323352814  fold:  9  kers:  64\n",
      "epoch:  41\n",
      "29483 461\n",
      "Loss:  0.05776338279247284\n",
      "Loss:  0.05734708160161972\n",
      "Loss:  0.08487141877412796\n",
      "41 **********\n",
      "Epoch:  2360.14844083786  fold:  9  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.04540110379457474\n",
      "Eval Loss:  0.9552433490753174\n",
      "Eval Loss:  0.17018263041973114\n",
      "[[1635  107]\n",
      " [ 456 1210]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      1742\n",
      "           1       0.92      0.73      0.81      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8348004694835681\n",
      "pre:  0.9187547456340167\n",
      "rec:  0.7262905162064826\n",
      "ma F1:  0.8321907453830686\n",
      "mi F1:  0.8348004694835681\n",
      "we F1:  0.8326574254575109\n",
      "Eval Loss:  0.3253040313720703\n",
      "Eval Loss:  0.243946835398674\n",
      "Eval Loss:  0.23020552098751068\n",
      "Eval Loss:  0.21209779381752014\n",
      "Eval Loss:  0.21882790327072144\n",
      "Eval Loss:  0.16243049502372742\n",
      "Eval Loss:  0.19389191269874573\n",
      "Eval Loss:  0.1986442655324936\n",
      "Eval Loss:  0.20047158002853394\n",
      "Eval Loss:  0.192372128367424\n",
      "Eval Loss:  0.22101271152496338\n",
      "Eval Loss:  0.25364816188812256\n",
      "Eval Loss:  0.18997560441493988\n",
      "Eval Loss:  0.17522543668746948\n",
      "Eval Loss:  0.30543792247772217\n",
      "Eval Loss:  0.20821192860603333\n",
      "Eval Loss:  0.2142290323972702\n",
      "Eval Loss:  0.21857857704162598\n",
      "Eval Loss:  0.20010225474834442\n",
      "Eval Loss:  0.2655682861804962\n",
      "Eval Loss:  0.2500092089176178\n",
      "Eval Loss:  0.19151757657527924\n",
      "Eval Loss:  0.19598472118377686\n",
      "Eval Loss:  0.1727007031440735\n",
      "Eval Loss:  0.23880542814731598\n",
      "Eval Loss:  0.2910342514514923\n",
      "Eval Loss:  0.20724298059940338\n",
      "Eval Loss:  0.1832563579082489\n",
      "[[17521   901]\n",
      " [ 1543  9518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18422\n",
      "           1       0.91      0.86      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9171047722416308\n",
      "pre:  0.9135233707649486\n",
      "rec:  0.8605008588735196\n",
      "ma F1:  0.9105110327470736\n",
      "mi F1:  0.9171047722416308\n",
      "we F1:  0.916575823003157\n",
      "29483 461\n",
      "Loss:  0.05110296607017517\n",
      "Loss:  0.047049958258867264\n",
      "Loss:  0.10355310887098312\n",
      "42 **********\n",
      "Epoch:  2442.6837587356567  fold:  9  kers:  64\n",
      "epoch:  43\n",
      "29483 461\n",
      "Loss:  0.11227133870124817\n",
      "Loss:  0.046933289617300034\n",
      "Loss:  0.03290940448641777\n",
      "43 **********\n",
      "Epoch:  2486.4926228523254  fold:  9  kers:  64\n",
      "epoch:  44\n",
      "29483 461\n",
      "Loss:  0.046527571976184845\n",
      "Loss:  0.06503526866436005\n",
      "Loss:  0.07573459297418594\n",
      "44 **********\n",
      "Epoch:  2530.235663175583  fold:  9  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.03483708202838898\n",
      "Eval Loss:  0.9449576139450073\n",
      "Eval Loss:  0.17083793878555298\n",
      "[[1634  108]\n",
      " [ 455 1211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      1742\n",
      "           1       0.92      0.73      0.81      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8348004694835681\n",
      "pre:  0.9181197877179682\n",
      "rec:  0.726890756302521\n",
      "ma F1:  0.8322156331120494\n",
      "mi F1:  0.8348004694835681\n",
      "we F1:  0.8326800481575232\n",
      "Eval Loss:  0.3412100672721863\n",
      "Eval Loss:  0.22528967261314392\n",
      "Eval Loss:  0.23219943046569824\n",
      "Eval Loss:  0.20247144997119904\n",
      "Eval Loss:  0.20350873470306396\n",
      "Eval Loss:  0.14917829632759094\n",
      "Eval Loss:  0.21901771426200867\n",
      "Eval Loss:  0.18243034183979034\n",
      "Eval Loss:  0.2029939591884613\n",
      "Eval Loss:  0.15795205533504486\n",
      "Eval Loss:  0.2281365990638733\n",
      "Eval Loss:  0.2734377682209015\n",
      "Eval Loss:  0.173259437084198\n",
      "Eval Loss:  0.15845686197280884\n",
      "Eval Loss:  0.27851608395576477\n",
      "Eval Loss:  0.18217237293720245\n",
      "Eval Loss:  0.21687376499176025\n",
      "Eval Loss:  0.2296811044216156\n",
      "Eval Loss:  0.19040100276470184\n",
      "Eval Loss:  0.23777532577514648\n",
      "Eval Loss:  0.2310829758644104\n",
      "Eval Loss:  0.17624959349632263\n",
      "Eval Loss:  0.17622816562652588\n",
      "Eval Loss:  0.16209490597248077\n",
      "Eval Loss:  0.2094384878873825\n",
      "Eval Loss:  0.27951979637145996\n",
      "Eval Loss:  0.20026853680610657\n",
      "Eval Loss:  0.17649467289447784\n",
      "[[17354  1068]\n",
      " [ 1324  9737]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18422\n",
      "           1       0.90      0.88      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9188685004918088\n",
      "pre:  0.9011568718186025\n",
      "rec:  0.8803001536931562\n",
      "ma F1:  0.9130660136982349\n",
      "mi F1:  0.9188685004918088\n",
      "we F1:  0.9186734845250036\n",
      "29483 461\n",
      "Loss:  0.07501009106636047\n",
      "Loss:  0.0846535861492157\n",
      "Loss:  0.06329088658094406\n",
      "45 **********\n",
      "Epoch:  2612.891657590866  fold:  9  kers:  64\n",
      "epoch:  46\n",
      "29483 461\n",
      "Loss:  0.06291573494672775\n",
      "Loss:  0.04239591211080551\n",
      "Loss:  0.07111771404743195\n",
      "46 **********\n",
      "Epoch:  2656.693540096283  fold:  9  kers:  64\n",
      "epoch:  47\n",
      "29483 461\n",
      "Loss:  0.04930669814348221\n",
      "Loss:  0.04345868527889252\n",
      "Loss:  0.06570849567651749\n",
      "47 **********\n",
      "Epoch:  2700.5901696681976  fold:  9  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.03437673673033714\n",
      "Eval Loss:  1.4421886205673218\n",
      "Eval Loss:  0.194563627243042\n",
      "[[1657   85]\n",
      " [ 537 1129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84      1742\n",
      "           1       0.93      0.68      0.78      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.84      0.81      0.81      3408\n",
      "weighted avg       0.84      0.82      0.81      3408\n",
      "\n",
      "acc:  0.8174882629107981\n",
      "pre:  0.9299835255354201\n",
      "rec:  0.6776710684273709\n",
      "ma F1:  0.8129996612466124\n",
      "mi F1:  0.8174882629107981\n",
      "we F1:  0.8136457478497907\n",
      "Eval Loss:  0.3290403187274933\n",
      "Eval Loss:  0.2234906107187271\n",
      "Eval Loss:  0.25680387020111084\n",
      "Eval Loss:  0.19132225215435028\n",
      "Eval Loss:  0.23185069859027863\n",
      "Eval Loss:  0.15766021609306335\n",
      "Eval Loss:  0.21611343324184418\n",
      "Eval Loss:  0.21280856430530548\n",
      "Eval Loss:  0.19355683028697968\n",
      "Eval Loss:  0.1738111674785614\n",
      "Eval Loss:  0.2206977903842926\n",
      "Eval Loss:  0.2569281756877899\n",
      "Eval Loss:  0.18214097619056702\n",
      "Eval Loss:  0.17820139229297638\n",
      "Eval Loss:  0.30511873960494995\n",
      "Eval Loss:  0.20605380833148956\n",
      "Eval Loss:  0.2154828906059265\n",
      "Eval Loss:  0.2328772395849228\n",
      "Eval Loss:  0.19239240884780884\n",
      "Eval Loss:  0.23040889203548431\n",
      "Eval Loss:  0.23320554196834564\n",
      "Eval Loss:  0.17756387591362\n",
      "Eval Loss:  0.1895543783903122\n",
      "Eval Loss:  0.18271729350090027\n",
      "Eval Loss:  0.20724636316299438\n",
      "Eval Loss:  0.30392977595329285\n",
      "Eval Loss:  0.20414450764656067\n",
      "Eval Loss:  0.18229185044765472\n",
      "[[17690   732]\n",
      " [ 1638  9423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18422\n",
      "           1       0.93      0.85      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.919614693213038\n",
      "pre:  0.9279172821270311\n",
      "rec:  0.8519121236777868\n",
      "ma F1:  0.9127551991249888\n",
      "mi F1:  0.919614693213038\n",
      "we F1:  0.9188629451008121\n",
      "29483 461\n",
      "Loss:  0.05645346641540527\n",
      "Loss:  0.04621805250644684\n",
      "Loss:  0.06313431262969971\n",
      "48 **********\n",
      "Epoch:  2783.0776147842407  fold:  9  kers:  64\n",
      "epoch:  49\n",
      "29483 461\n",
      "Loss:  0.037908703088760376\n",
      "Loss:  0.03891507163643837\n",
      "Loss:  0.06098759174346924\n",
      "49 **********\n",
      "Epoch:  2826.9094173908234  fold:  9  kers:  64\n",
      "epoch:  50\n",
      "29483 461\n",
      "Loss:  0.043927550315856934\n",
      "Loss:  0.04778415337204933\n",
      "Loss:  0.11048774421215057\n",
      "50 **********\n",
      "Epoch:  2870.7841053009033  fold:  9  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.04004158824682236\n",
      "Eval Loss:  0.8876630067825317\n",
      "Eval Loss:  0.11833767592906952\n",
      "[[1602  140]\n",
      " [ 410 1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.85      1742\n",
      "           1       0.90      0.75      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8386150234741784\n",
      "pre:  0.8997134670487106\n",
      "rec:  0.7539015606242497\n",
      "ma F1:  0.8369342242213575\n",
      "mi F1:  0.8386150234741784\n",
      "we F1:  0.837303417120821\n",
      "update!  Acc:  0.8386150234741784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3053707480430603\n",
      "Eval Loss:  0.23532085120677948\n",
      "Eval Loss:  0.23446018993854523\n",
      "Eval Loss:  0.18401552736759186\n",
      "Eval Loss:  0.20253244042396545\n",
      "Eval Loss:  0.14171220362186432\n",
      "Eval Loss:  0.19529740512371063\n",
      "Eval Loss:  0.18897242844104767\n",
      "Eval Loss:  0.21063002943992615\n",
      "Eval Loss:  0.1897251158952713\n",
      "Eval Loss:  0.21854765713214874\n",
      "Eval Loss:  0.27827802300453186\n",
      "Eval Loss:  0.1538093388080597\n",
      "Eval Loss:  0.16326725482940674\n",
      "Eval Loss:  0.26795732975006104\n",
      "Eval Loss:  0.19812804460525513\n",
      "Eval Loss:  0.22541970014572144\n",
      "Eval Loss:  0.20654414594173431\n",
      "Eval Loss:  0.15076935291290283\n",
      "Eval Loss:  0.25520238280296326\n",
      "Eval Loss:  0.23349817097187042\n",
      "Eval Loss:  0.16114144027233124\n",
      "Eval Loss:  0.1643855720758438\n",
      "Eval Loss:  0.1533309370279312\n",
      "Eval Loss:  0.2060486376285553\n",
      "Eval Loss:  0.28887808322906494\n",
      "Eval Loss:  0.18137116730213165\n",
      "Eval Loss:  0.16977134346961975\n",
      "[[17325  1097]\n",
      " [ 1160  9901]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18422\n",
      "           1       0.90      0.90      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9234474103720788\n",
      "pre:  0.9002545917439534\n",
      "rec:  0.8951270228731579\n",
      "ma F1:  0.918264887260297\n",
      "mi F1:  0.9234474103720789\n",
      "we F1:  0.9234034315256292\n",
      "29483 461\n",
      "Loss:  0.04877984896302223\n",
      "Loss:  0.05604228749871254\n",
      "Loss:  0.04809490591287613\n",
      "51 **********\n",
      "Epoch:  2953.0990118980408  fold:  9  kers:  64\n",
      "epoch:  52\n",
      "29483 461\n",
      "Loss:  0.11179213970899582\n",
      "Loss:  0.06998232752084732\n",
      "Loss:  0.04423615336418152\n",
      "52 **********\n",
      "Epoch:  2996.9667189121246  fold:  9  kers:  64\n",
      "epoch:  53\n",
      "29483 461\n",
      "Loss:  0.08148420602083206\n",
      "Loss:  0.05864621698856354\n",
      "Loss:  0.10375501215457916\n",
      "53 **********\n",
      "Epoch:  3040.7027773857117  fold:  9  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.05342105031013489\n",
      "Eval Loss:  1.0677590370178223\n",
      "Eval Loss:  0.20928719639778137\n",
      "[[1605  137]\n",
      " [ 511 1155]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83      1742\n",
      "           1       0.89      0.69      0.78      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.83      0.81      0.81      3408\n",
      "weighted avg       0.82      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8098591549295775\n",
      "pre:  0.8939628482972136\n",
      "rec:  0.6932773109243697\n",
      "ma F1:  0.8064851939596023\n",
      "mi F1:  0.8098591549295775\n",
      "we F1:  0.8070550184789759\n",
      "Eval Loss:  0.32152533531188965\n",
      "Eval Loss:  0.2529904842376709\n",
      "Eval Loss:  0.23867887258529663\n",
      "Eval Loss:  0.18847966194152832\n",
      "Eval Loss:  0.21110887825489044\n",
      "Eval Loss:  0.14695623517036438\n",
      "Eval Loss:  0.205244779586792\n",
      "Eval Loss:  0.1595340222120285\n",
      "Eval Loss:  0.219635009765625\n",
      "Eval Loss:  0.16200876235961914\n",
      "Eval Loss:  0.19913309812545776\n",
      "Eval Loss:  0.24001194536685944\n",
      "Eval Loss:  0.1622353494167328\n",
      "Eval Loss:  0.18134193122386932\n",
      "Eval Loss:  0.2887899875640869\n",
      "Eval Loss:  0.1860201507806778\n",
      "Eval Loss:  0.21311910450458527\n",
      "Eval Loss:  0.1995469182729721\n",
      "Eval Loss:  0.17823529243469238\n",
      "Eval Loss:  0.25031083822250366\n",
      "Eval Loss:  0.21199098229408264\n",
      "Eval Loss:  0.15205131471157074\n",
      "Eval Loss:  0.17206257581710815\n",
      "Eval Loss:  0.15960364043712616\n",
      "Eval Loss:  0.20712162554264069\n",
      "Eval Loss:  0.30151379108428955\n",
      "Eval Loss:  0.1778392791748047\n",
      "Eval Loss:  0.17650415003299713\n",
      "[[17356  1066]\n",
      " [ 1215  9846]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18422\n",
      "           1       0.90      0.89      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9226333819489198\n",
      "pre:  0.9023093841642229\n",
      "rec:  0.8901545972335232\n",
      "ma F1:  0.917265232739828\n",
      "mi F1:  0.9226333819489198\n",
      "we F1:  0.922526876724931\n",
      "29483 461\n",
      "Loss:  0.04678348824381828\n",
      "Loss:  0.07438521087169647\n",
      "Loss:  0.040822774171829224\n",
      "54 **********\n",
      "Epoch:  3123.1453428268433  fold:  9  kers:  64\n",
      "epoch:  55\n",
      "29483 461\n",
      "Loss:  0.04608754441142082\n",
      "Loss:  0.037918660789728165\n",
      "Loss:  0.040218450129032135\n",
      "55 **********\n",
      "Epoch:  3166.8684363365173  fold:  9  kers:  64\n",
      "epoch:  56\n",
      "29483 461\n",
      "Loss:  0.06139461696147919\n",
      "Loss:  0.08867815881967545\n",
      "Loss:  0.050040341913700104\n",
      "56 **********\n",
      "Epoch:  3210.6044948101044  fold:  9  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.04600660130381584\n",
      "Eval Loss:  0.9883352518081665\n",
      "Eval Loss:  0.14360730350017548\n",
      "[[1568  174]\n",
      " [ 435 1231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84      1742\n",
      "           1       0.88      0.74      0.80      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.83      0.82      0.82      3408\n",
      "weighted avg       0.83      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8213028169014085\n",
      "pre:  0.8761565836298932\n",
      "rec:  0.7388955582232893\n",
      "ma F1:  0.8195382185473392\n",
      "mi F1:  0.8213028169014085\n",
      "we F1:  0.8199361695114618\n",
      "Eval Loss:  0.2789449691772461\n",
      "Eval Loss:  0.22586145997047424\n",
      "Eval Loss:  0.2386971414089203\n",
      "Eval Loss:  0.18643435835838318\n",
      "Eval Loss:  0.18824495375156403\n",
      "Eval Loss:  0.1269483119249344\n",
      "Eval Loss:  0.21364694833755493\n",
      "Eval Loss:  0.18612584471702576\n",
      "Eval Loss:  0.19108127057552338\n",
      "Eval Loss:  0.1797441691160202\n",
      "Eval Loss:  0.20720374584197998\n",
      "Eval Loss:  0.2701484262943268\n",
      "Eval Loss:  0.1512955278158188\n",
      "Eval Loss:  0.16838209331035614\n",
      "Eval Loss:  0.2701247036457062\n",
      "Eval Loss:  0.1858149766921997\n",
      "Eval Loss:  0.24366475641727448\n",
      "Eval Loss:  0.18531712889671326\n",
      "Eval Loss:  0.1490841507911682\n",
      "Eval Loss:  0.26097819209098816\n",
      "Eval Loss:  0.2188396006822586\n",
      "Eval Loss:  0.14378800988197327\n",
      "Eval Loss:  0.16835930943489075\n",
      "Eval Loss:  0.1524382084608078\n",
      "Eval Loss:  0.19360601902008057\n",
      "Eval Loss:  0.30455803871154785\n",
      "Eval Loss:  0.1829368770122528\n",
      "Eval Loss:  0.17388460040092468\n",
      "[[17219  1203]\n",
      " [ 1028 10033]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18422\n",
      "           1       0.89      0.91      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9243292744971678\n",
      "pre:  0.892933428266287\n",
      "rec:  0.9070608444082814\n",
      "ma F1:  0.9195500566919731\n",
      "mi F1:  0.9243292744971678\n",
      "we F1:  0.9244456623507595\n",
      "29483 461\n",
      "Loss:  0.05917086824774742\n",
      "Loss:  0.05171322822570801\n",
      "Loss:  0.07406213879585266\n",
      "57 **********\n",
      "Epoch:  3292.966276407242  fold:  9  kers:  64\n",
      "epoch:  58\n",
      "29483 461\n",
      "Loss:  0.042467862367630005\n",
      "Loss:  0.04576116427779198\n",
      "Loss:  0.07217825949192047\n",
      "58 **********\n",
      "Epoch:  3336.695353746414  fold:  9  kers:  64\n",
      "epoch:  59\n",
      "29483 461\n",
      "Loss:  0.0432053878903389\n",
      "Loss:  0.08983366191387177\n",
      "Loss:  0.08483123034238815\n",
      "59 **********\n",
      "Epoch:  3380.4752950668335  fold:  9  kers:  64\n",
      "Eval Loss:  0.044676076620817184\n",
      "Eval Loss:  0.7116761207580566\n",
      "Eval Loss:  0.15916617214679718\n",
      "[[1630  112]\n",
      " [ 420 1246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      1742\n",
      "           1       0.92      0.75      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8438967136150235\n",
      "pre:  0.9175257731958762\n",
      "rec:  0.7478991596638656\n",
      "ma F1:  0.8418893577121426\n",
      "mi F1:  0.8438967136150235\n",
      "we F1:  0.8422866469012544\n",
      "update!  Acc:  0.8438967136150235\n",
      "Epoch:  3384.51549243927  fold:  9  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29871 3020\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29871 467\n",
      "Loss:  0.16605782508850098\n",
      "Loss:  0.16819368302822113\n",
      "Loss:  0.16304314136505127\n",
      "0 **********\n",
      "Epoch:  56.9367618560791  fold:  10  kers:  64\n",
      "epoch:  1\n",
      "29871 467\n",
      "Loss:  0.13011249899864197\n",
      "Loss:  0.1553448587656021\n",
      "Loss:  0.1350085437297821\n",
      "1 **********\n",
      "Epoch:  101.38092708587646  fold:  10  kers:  64\n",
      "epoch:  2\n",
      "29871 467\n",
      "Loss:  0.09544163197278976\n",
      "Loss:  0.12015610933303833\n",
      "Loss:  0.12054431438446045\n",
      "2 **********\n",
      "Epoch:  145.94776463508606  fold:  10  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.7118579745292664\n",
      "Eval Loss:  0.2347063422203064\n",
      "Eval Loss:  0.07994268834590912\n",
      "[[1611  140]\n",
      " [ 280  989]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      1751\n",
      "           1       0.88      0.78      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.86      0.85      0.85      3020\n",
      "weighted avg       0.86      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8609271523178808\n",
      "pre:  0.8759964570416298\n",
      "rec:  0.7793538219070134\n",
      "ma F1:  0.8547663964891117\n",
      "mi F1:  0.8609271523178808\n",
      "we F1:  0.859540487018801\n",
      "update!  Acc:  0.8609271523178808\n",
      "Eval Loss:  0.5117082595825195\n",
      "Eval Loss:  0.48878559470176697\n",
      "Eval Loss:  0.5503029227256775\n",
      "Eval Loss:  0.48220691084861755\n",
      "Eval Loss:  0.5390508770942688\n",
      "Eval Loss:  0.4837489128112793\n",
      "Eval Loss:  0.5051735639572144\n",
      "Eval Loss:  0.543893575668335\n",
      "Eval Loss:  0.5482369065284729\n",
      "Eval Loss:  0.6158485412597656\n",
      "Eval Loss:  0.5763794183731079\n",
      "Eval Loss:  0.644449770450592\n",
      "Eval Loss:  0.38094303011894226\n",
      "Eval Loss:  0.5227708220481873\n",
      "Eval Loss:  0.5880892872810364\n",
      "Eval Loss:  0.5858571529388428\n",
      "Eval Loss:  0.47236937284469604\n",
      "Eval Loss:  0.5704081058502197\n",
      "Eval Loss:  0.4980575144290924\n",
      "Eval Loss:  0.6218588352203369\n",
      "Eval Loss:  0.4873516261577606\n",
      "Eval Loss:  0.5087029933929443\n",
      "Eval Loss:  0.5970011949539185\n",
      "Eval Loss:  0.583931028842926\n",
      "Eval Loss:  0.5316212773323059\n",
      "Eval Loss:  0.5084744691848755\n",
      "Eval Loss:  0.4264376759529114\n",
      "Eval Loss:  0.5099674463272095\n",
      "Eval Loss:  0.6774056553840637\n",
      "[[16646  1767]\n",
      " [ 5018  6440]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83     18413\n",
      "           1       0.78      0.56      0.65     11458\n",
      "\n",
      "    accuracy                           0.77     29871\n",
      "   macro avg       0.78      0.73      0.74     29871\n",
      "weighted avg       0.77      0.77      0.76     29871\n",
      "\n",
      "acc:  0.772856616785511\n",
      "pre:  0.7846959912270013\n",
      "rec:  0.5620527142607785\n",
      "ma F1:  0.7428358304999718\n",
      "mi F1:  0.772856616785511\n",
      "we F1:  0.7632938521162687\n",
      "29871 467\n",
      "Loss:  0.1032266840338707\n",
      "Loss:  0.12503300607204437\n",
      "Loss:  0.10185250639915466\n",
      "3 **********\n",
      "Epoch:  229.51432466506958  fold:  10  kers:  64\n",
      "epoch:  4\n",
      "29871 467\n",
      "Loss:  0.1148512065410614\n",
      "Loss:  0.08361567556858063\n",
      "Loss:  0.07807864993810654\n",
      "4 **********\n",
      "Epoch:  274.01633501052856  fold:  10  kers:  64\n",
      "epoch:  5\n",
      "29871 467\n",
      "Loss:  0.10003647953271866\n",
      "Loss:  0.09439084678888321\n",
      "Loss:  0.05603537708520889\n",
      "5 **********\n",
      "Epoch:  318.6499938964844  fold:  10  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.57125324010849\n",
      "Eval Loss:  0.14594422280788422\n",
      "Eval Loss:  0.1000058725476265\n",
      "[[1650  101]\n",
      " [ 247 1022]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1751\n",
      "           1       0.91      0.81      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.89      0.87      0.88      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8847682119205298\n",
      "pre:  0.9100623330365093\n",
      "rec:  0.8053585500394012\n",
      "ma F1:  0.8795601566625595\n",
      "mi F1:  0.8847682119205298\n",
      "we F1:  0.883557422003868\n",
      "update!  Acc:  0.8847682119205298\n",
      "Eval Loss:  0.3958035409450531\n",
      "Eval Loss:  0.3492433726787567\n",
      "Eval Loss:  0.40328851342201233\n",
      "Eval Loss:  0.3450072407722473\n",
      "Eval Loss:  0.4706287980079651\n",
      "Eval Loss:  0.38616320490837097\n",
      "Eval Loss:  0.42839154601097107\n",
      "Eval Loss:  0.4026744067668915\n",
      "Eval Loss:  0.4435479938983917\n",
      "Eval Loss:  0.46568763256073\n",
      "Eval Loss:  0.39606478810310364\n",
      "Eval Loss:  0.45376670360565186\n",
      "Eval Loss:  0.3297443389892578\n",
      "Eval Loss:  0.4237529933452606\n",
      "Eval Loss:  0.49218782782554626\n",
      "Eval Loss:  0.5624127984046936\n",
      "Eval Loss:  0.4027068316936493\n",
      "Eval Loss:  0.49788469076156616\n",
      "Eval Loss:  0.4288736879825592\n",
      "Eval Loss:  0.45601576566696167\n",
      "Eval Loss:  0.3861270248889923\n",
      "Eval Loss:  0.45145851373672485\n",
      "Eval Loss:  0.49123841524124146\n",
      "Eval Loss:  0.456243634223938\n",
      "Eval Loss:  0.4230394959449768\n",
      "Eval Loss:  0.3765539824962616\n",
      "Eval Loss:  0.31576094031333923\n",
      "Eval Loss:  0.4700474739074707\n",
      "Eval Loss:  0.5331757068634033\n",
      "[[17373  1040]\n",
      " [ 4008  7450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87     18413\n",
      "           1       0.88      0.65      0.75     11458\n",
      "\n",
      "    accuracy                           0.83     29871\n",
      "   macro avg       0.85      0.80      0.81     29871\n",
      "weighted avg       0.84      0.83      0.82     29871\n",
      "\n",
      "acc:  0.8310066619798466\n",
      "pre:  0.8775029446407538\n",
      "rec:  0.650200733112236\n",
      "ma F1:  0.8100443774308755\n",
      "mi F1:  0.8310066619798466\n",
      "we F1:  0.8247367778176633\n",
      "29871 467\n",
      "Loss:  0.07164724916219711\n",
      "Loss:  0.09159482270479202\n",
      "Loss:  0.10504709184169769\n",
      "6 **********\n",
      "Epoch:  402.224534034729  fold:  10  kers:  64\n",
      "epoch:  7\n",
      "29871 467\n",
      "Loss:  0.08996656537055969\n",
      "Loss:  0.08512096852064133\n",
      "Loss:  0.1010095551609993\n",
      "7 **********\n",
      "Epoch:  448.0450179576874  fold:  10  kers:  64\n",
      "epoch:  8\n",
      "29871 467\n",
      "Loss:  0.08217064291238785\n",
      "Loss:  0.08366391807794571\n",
      "Loss:  0.06282645463943481\n",
      "8 **********\n",
      "Epoch:  492.7125861644745  fold:  10  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.4820616841316223\n",
      "Eval Loss:  0.11096286028623581\n",
      "Eval Loss:  0.10168260335922241\n",
      "[[1672   79]\n",
      " [ 238 1031]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1751\n",
      "           1       0.93      0.81      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.88      0.89      3020\n",
      "weighted avg       0.90      0.90      0.89      3020\n",
      "\n",
      "acc:  0.8950331125827815\n",
      "pre:  0.9288288288288288\n",
      "rec:  0.8124507486209613\n",
      "ma F1:  0.8900811858840885\n",
      "mi F1:  0.8950331125827815\n",
      "we F1:  0.8938047875514363\n",
      "update!  Acc:  0.8950331125827815\n",
      "Eval Loss:  0.3791378438472748\n",
      "Eval Loss:  0.31398969888687134\n",
      "Eval Loss:  0.3981713354587555\n",
      "Eval Loss:  0.3099711239337921\n",
      "Eval Loss:  0.4143027067184448\n",
      "Eval Loss:  0.36920657753944397\n",
      "Eval Loss:  0.41577965021133423\n",
      "Eval Loss:  0.3701319694519043\n",
      "Eval Loss:  0.4363822937011719\n",
      "Eval Loss:  0.4817003011703491\n",
      "Eval Loss:  0.33580663800239563\n",
      "Eval Loss:  0.4584771394729614\n",
      "Eval Loss:  0.3088322877883911\n",
      "Eval Loss:  0.3747847378253937\n",
      "Eval Loss:  0.4860076606273651\n",
      "Eval Loss:  0.5310850143432617\n",
      "Eval Loss:  0.37979888916015625\n",
      "Eval Loss:  0.4688051640987396\n",
      "Eval Loss:  0.43644338846206665\n",
      "Eval Loss:  0.4368567168712616\n",
      "Eval Loss:  0.35717812180519104\n",
      "Eval Loss:  0.4346137046813965\n",
      "Eval Loss:  0.45135217905044556\n",
      "Eval Loss:  0.4130614399909973\n",
      "Eval Loss:  0.4092877209186554\n",
      "Eval Loss:  0.3877968192100525\n",
      "Eval Loss:  0.28684383630752563\n",
      "Eval Loss:  0.4213100075721741\n",
      "Eval Loss:  0.4866200387477875\n",
      "[[17658   755]\n",
      " [ 3967  7491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88     18413\n",
      "           1       0.91      0.65      0.76     11458\n",
      "\n",
      "    accuracy                           0.84     29871\n",
      "   macro avg       0.86      0.81      0.82     29871\n",
      "weighted avg       0.85      0.84      0.84     29871\n",
      "\n",
      "acc:  0.8419202571055538\n",
      "pre:  0.9084404559786563\n",
      "rec:  0.653779019026008\n",
      "ma F1:  0.8212076344160014\n",
      "mi F1:  0.8419202571055538\n",
      "we F1:  0.8353766410852094\n",
      "29871 467\n",
      "Loss:  0.10493487864732742\n",
      "Loss:  0.07949880510568619\n",
      "Loss:  0.08695584535598755\n",
      "9 **********\n",
      "Epoch:  575.9949061870575  fold:  10  kers:  64\n",
      "epoch:  10\n",
      "29871 467\n",
      "Loss:  0.064925916492939\n",
      "Loss:  0.07703998684883118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0994143933057785\n",
      "10 **********\n",
      "Epoch:  620.4779672622681  fold:  10  kers:  64\n",
      "epoch:  11\n",
      "29871 467\n",
      "Loss:  0.07290081679821014\n",
      "Loss:  0.07160283625125885\n",
      "Loss:  0.073926642537117\n",
      "11 **********\n",
      "Epoch:  664.9121594429016  fold:  10  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.5625830292701721\n",
      "Eval Loss:  0.09277006983757019\n",
      "Eval Loss:  0.07237983494997025\n",
      "[[1686   65]\n",
      " [ 283  986]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      1751\n",
      "           1       0.94      0.78      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.90      0.87      0.88      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8847682119205298\n",
      "pre:  0.9381541389153187\n",
      "rec:  0.77698975571316\n",
      "ma F1:  0.8782258064516129\n",
      "mi F1:  0.8847682119205298\n",
      "we F1:  0.8827307199316385\n",
      "Eval Loss:  0.35854315757751465\n",
      "Eval Loss:  0.29930180311203003\n",
      "Eval Loss:  0.37670743465423584\n",
      "Eval Loss:  0.2845286726951599\n",
      "Eval Loss:  0.3939068913459778\n",
      "Eval Loss:  0.3398415446281433\n",
      "Eval Loss:  0.38563525676727295\n",
      "Eval Loss:  0.3620021641254425\n",
      "Eval Loss:  0.41965430974960327\n",
      "Eval Loss:  0.44936949014663696\n",
      "Eval Loss:  0.3282022178173065\n",
      "Eval Loss:  0.440155953168869\n",
      "Eval Loss:  0.28221815824508667\n",
      "Eval Loss:  0.35913851857185364\n",
      "Eval Loss:  0.4857802391052246\n",
      "Eval Loss:  0.52542644739151\n",
      "Eval Loss:  0.3723294138908386\n",
      "Eval Loss:  0.4280077815055847\n",
      "Eval Loss:  0.3907390534877777\n",
      "Eval Loss:  0.38899433612823486\n",
      "Eval Loss:  0.3394629955291748\n",
      "Eval Loss:  0.38933274149894714\n",
      "Eval Loss:  0.438375860452652\n",
      "Eval Loss:  0.4039250314235687\n",
      "Eval Loss:  0.39279237389564514\n",
      "Eval Loss:  0.3807438611984253\n",
      "Eval Loss:  0.27937039732933044\n",
      "Eval Loss:  0.4069497287273407\n",
      "Eval Loss:  0.47656533122062683\n",
      "[[17846   567]\n",
      " [ 4053  7405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89     18413\n",
      "           1       0.93      0.65      0.76     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.87      0.81      0.82     29871\n",
      "weighted avg       0.86      0.85      0.84     29871\n",
      "\n",
      "acc:  0.8453349402430451\n",
      "pre:  0.9288760662318113\n",
      "rec:  0.6462733461337057\n",
      "ma F1:  0.8238086466477583\n",
      "mi F1:  0.8453349402430451\n",
      "we F1:  0.8381478260324169\n",
      "29871 467\n",
      "Loss:  0.08450460433959961\n",
      "Loss:  0.08259397000074387\n",
      "Loss:  0.054321661591529846\n",
      "12 **********\n",
      "Epoch:  748.0  fold:  10  kers:  64\n",
      "epoch:  13\n",
      "29871 467\n",
      "Loss:  0.06345141679048538\n",
      "Loss:  0.06680349260568619\n",
      "Loss:  0.07426445186138153\n",
      "13 **********\n",
      "Epoch:  792.4052686691284  fold:  10  kers:  64\n",
      "epoch:  14\n",
      "29871 467\n",
      "Loss:  0.05653570219874382\n",
      "Loss:  0.06948070228099823\n",
      "Loss:  0.05556346848607063\n",
      "14 **********\n",
      "Epoch:  836.7337431907654  fold:  10  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.5284609794616699\n",
      "Eval Loss:  0.07686300575733185\n",
      "Eval Loss:  0.06243047118186951\n",
      "[[1687   64]\n",
      " [ 264 1005]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      1751\n",
      "           1       0.94      0.79      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.88      0.89      3020\n",
      "weighted avg       0.90      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8913907284768212\n",
      "pre:  0.9401309635173059\n",
      "rec:  0.7919621749408984\n",
      "ma F1:  0.8855541983872033\n",
      "mi F1:  0.8913907284768212\n",
      "we F1:  0.8896791360751737\n",
      "Eval Loss:  0.35043099522590637\n",
      "Eval Loss:  0.26526281237602234\n",
      "Eval Loss:  0.3282133638858795\n",
      "Eval Loss:  0.2660244405269623\n",
      "Eval Loss:  0.384919136762619\n",
      "Eval Loss:  0.3089349865913391\n",
      "Eval Loss:  0.33524271845817566\n",
      "Eval Loss:  0.3215602934360504\n",
      "Eval Loss:  0.38135579228401184\n",
      "Eval Loss:  0.4207996726036072\n",
      "Eval Loss:  0.307101309299469\n",
      "Eval Loss:  0.41412240266799927\n",
      "Eval Loss:  0.2672581970691681\n",
      "Eval Loss:  0.3229706883430481\n",
      "Eval Loss:  0.4644504189491272\n",
      "Eval Loss:  0.4911395311355591\n",
      "Eval Loss:  0.3273000717163086\n",
      "Eval Loss:  0.4078828692436218\n",
      "Eval Loss:  0.3589901328086853\n",
      "Eval Loss:  0.3550635874271393\n",
      "Eval Loss:  0.31468674540519714\n",
      "Eval Loss:  0.3541536033153534\n",
      "Eval Loss:  0.4098939895629883\n",
      "Eval Loss:  0.3887408673763275\n",
      "Eval Loss:  0.3399152159690857\n",
      "Eval Loss:  0.3314487934112549\n",
      "Eval Loss:  0.25341856479644775\n",
      "Eval Loss:  0.3835262358188629\n",
      "Eval Loss:  0.4354740381240845\n",
      "[[17811   602]\n",
      " [ 3680  7778]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89     18413\n",
      "           1       0.93      0.68      0.78     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.88      0.82      0.84     29871\n",
      "weighted avg       0.87      0.86      0.85     29871\n",
      "\n",
      "acc:  0.8566502627966924\n",
      "pre:  0.928162291169451\n",
      "rec:  0.6788270204224123\n",
      "ma F1:  0.838422045048453\n",
      "mi F1:  0.8566502627966924\n",
      "we F1:  0.8510580716047178\n",
      "29871 467\n",
      "Loss:  0.06304517388343811\n",
      "Loss:  0.08165939152240753\n",
      "Loss:  0.06007261201739311\n",
      "15 **********\n",
      "Epoch:  920.0449862480164  fold:  10  kers:  64\n",
      "epoch:  16\n",
      "29871 467\n",
      "Loss:  0.07854338735342026\n",
      "Loss:  0.08441162109375\n",
      "Loss:  0.07526605576276779\n",
      "16 **********\n",
      "Epoch:  964.5888843536377  fold:  10  kers:  64\n",
      "epoch:  17\n",
      "29871 467\n",
      "Loss:  0.07302962243556976\n",
      "Loss:  0.08732377737760544\n",
      "Loss:  0.056564316153526306\n",
      "17 **********\n",
      "Epoch:  1009.1198182106018  fold:  10  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.5578522682189941\n",
      "Eval Loss:  0.07173098623752594\n",
      "Eval Loss:  0.03691665455698967\n",
      "[[1699   52]\n",
      " [ 292  977]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91      1751\n",
      "           1       0.95      0.77      0.85      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.87      0.88      3020\n",
      "weighted avg       0.89      0.89      0.88      3020\n",
      "\n",
      "acc:  0.8860927152317881\n",
      "pre:  0.9494655004859086\n",
      "rec:  0.7698975571315997\n",
      "ma F1:  0.8791875816072257\n",
      "mi F1:  0.8860927152317881\n",
      "we F1:  0.8837973799549251\n",
      "Eval Loss:  0.3641449809074402\n",
      "Eval Loss:  0.3013814687728882\n",
      "Eval Loss:  0.37043318152427673\n",
      "Eval Loss:  0.2779802680015564\n",
      "Eval Loss:  0.377031147480011\n",
      "Eval Loss:  0.34072279930114746\n",
      "Eval Loss:  0.35908734798431396\n",
      "Eval Loss:  0.3574404716491699\n",
      "Eval Loss:  0.3873910903930664\n",
      "Eval Loss:  0.4468120336532593\n",
      "Eval Loss:  0.33825913071632385\n",
      "Eval Loss:  0.5072145462036133\n",
      "Eval Loss:  0.26341065764427185\n",
      "Eval Loss:  0.3097136914730072\n",
      "Eval Loss:  0.5125645995140076\n",
      "Eval Loss:  0.4900725483894348\n",
      "Eval Loss:  0.34663915634155273\n",
      "Eval Loss:  0.4361375868320465\n",
      "Eval Loss:  0.40200817584991455\n",
      "Eval Loss:  0.38123026490211487\n",
      "Eval Loss:  0.3417779803276062\n",
      "Eval Loss:  0.37704598903656006\n",
      "Eval Loss:  0.4190276861190796\n",
      "Eval Loss:  0.3980087339878082\n",
      "Eval Loss:  0.3385581970214844\n",
      "Eval Loss:  0.33267202973365784\n",
      "Eval Loss:  0.25315386056900024\n",
      "Eval Loss:  0.36779671907424927\n",
      "Eval Loss:  0.4554879367351532\n",
      "[[17965   448]\n",
      " [ 4140  7318]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     18413\n",
      "           1       0.94      0.64      0.76     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.88      0.81      0.82     29871\n",
      "weighted avg       0.86      0.85      0.84     29871\n",
      "\n",
      "acc:  0.8464062133842188\n",
      "pre:  0.9423126448622199\n",
      "rec:  0.6386803979752138\n",
      "ma F1:  0.8240531835575736\n",
      "mi F1:  0.8464062133842188\n",
      "we F1:  0.8386549795981783\n",
      "29871 467\n",
      "Loss:  0.07194498926401138\n",
      "Loss:  0.08143045753240585\n",
      "Loss:  0.08266028761863708\n",
      "18 **********\n",
      "Epoch:  1092.4978821277618  fold:  10  kers:  64\n",
      "epoch:  19\n",
      "29871 467\n",
      "Loss:  0.06555245816707611\n",
      "Loss:  0.08815506845712662\n",
      "Loss:  0.07498914003372192\n",
      "19 **********\n",
      "Epoch:  1137.0697059631348  fold:  10  kers:  64\n",
      "epoch:  20\n",
      "29871 467\n",
      "Loss:  0.07782579213380814\n",
      "Loss:  0.05797528848052025\n",
      "Loss:  0.08112876117229462\n",
      "20 **********\n",
      "Epoch:  1181.5687255859375  fold:  10  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.3147268295288086\n",
      "Eval Loss:  0.08559578657150269\n",
      "Eval Loss:  0.03502773120999336\n",
      "[[1673   78]\n",
      " [ 200 1069]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      1751\n",
      "           1       0.93      0.84      0.88      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9079470198675497\n",
      "pre:  0.9319965126416739\n",
      "rec:  0.8423955870764381\n",
      "ma F1:  0.9041114790286975\n",
      "mi F1:  0.9079470198675497\n",
      "we F1:  0.9071722914199669\n",
      "update!  Acc:  0.9079470198675497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.27090251445770264\n",
      "Eval Loss:  0.23045621812343597\n",
      "Eval Loss:  0.26722896099090576\n",
      "Eval Loss:  0.21548080444335938\n",
      "Eval Loss:  0.31963178515434265\n",
      "Eval Loss:  0.2413056194782257\n",
      "Eval Loss:  0.27923232316970825\n",
      "Eval Loss:  0.2463492751121521\n",
      "Eval Loss:  0.31000813841819763\n",
      "Eval Loss:  0.32344523072242737\n",
      "Eval Loss:  0.253688246011734\n",
      "Eval Loss:  0.36695539951324463\n",
      "Eval Loss:  0.19280019402503967\n",
      "Eval Loss:  0.2592114806175232\n",
      "Eval Loss:  0.35640114545822144\n",
      "Eval Loss:  0.3976309597492218\n",
      "Eval Loss:  0.27173087000846863\n",
      "Eval Loss:  0.33199048042297363\n",
      "Eval Loss:  0.2620854377746582\n",
      "Eval Loss:  0.23473288118839264\n",
      "Eval Loss:  0.2219962179660797\n",
      "Eval Loss:  0.285704106092453\n",
      "Eval Loss:  0.282518208026886\n",
      "Eval Loss:  0.3334989845752716\n",
      "Eval Loss:  0.2364252209663391\n",
      "Eval Loss:  0.22483526170253754\n",
      "Eval Loss:  0.22130563855171204\n",
      "Eval Loss:  0.33652952313423157\n",
      "Eval Loss:  0.3202623128890991\n",
      "[[17583   830]\n",
      " [ 2578  8880]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18413\n",
      "           1       0.91      0.78      0.84     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.86      0.88     29871\n",
      "weighted avg       0.89      0.89      0.88     29871\n",
      "\n",
      "acc:  0.8859094104649995\n",
      "pre:  0.9145211122554068\n",
      "rec:  0.7750043637633095\n",
      "ma F1:  0.8753263009979229\n",
      "mi F1:  0.8859094104649995\n",
      "we F1:  0.8837837899492635\n",
      "29871 467\n",
      "Loss:  0.07341141253709793\n",
      "Loss:  0.08982732146978378\n",
      "Loss:  0.08479668200016022\n",
      "21 **********\n",
      "Epoch:  1264.8670020103455  fold:  10  kers:  64\n",
      "epoch:  22\n",
      "29871 467\n",
      "Loss:  0.08874505013227463\n",
      "Loss:  0.07832454144954681\n",
      "Loss:  0.05286505073308945\n",
      "22 **********\n",
      "Epoch:  1309.5056476593018  fold:  10  kers:  64\n",
      "epoch:  23\n",
      "29871 467\n",
      "Loss:  0.04918604716658592\n",
      "Loss:  0.05111004039645195\n",
      "Loss:  0.09912054985761642\n",
      "23 **********\n",
      "Epoch:  1353.9827241897583  fold:  10  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.6454252600669861\n",
      "Eval Loss:  0.07142697274684906\n",
      "Eval Loss:  0.02312656119465828\n",
      "[[1701   50]\n",
      " [ 313  956]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      1751\n",
      "           1       0.95      0.75      0.84      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.90      0.86      0.87      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8798013245033113\n",
      "pre:  0.9502982107355865\n",
      "rec:  0.7533490937746257\n",
      "ma F1:  0.8720126089050392\n",
      "mi F1:  0.8798013245033113\n",
      "we F1:  0.877051751077344\n",
      "Eval Loss:  0.29605820775032043\n",
      "Eval Loss:  0.26824942231178284\n",
      "Eval Loss:  0.323544979095459\n",
      "Eval Loss:  0.24151970446109772\n",
      "Eval Loss:  0.3598065674304962\n",
      "Eval Loss:  0.2754306495189667\n",
      "Eval Loss:  0.30808162689208984\n",
      "Eval Loss:  0.30934369564056396\n",
      "Eval Loss:  0.32149022817611694\n",
      "Eval Loss:  0.3910953998565674\n",
      "Eval Loss:  0.3025108575820923\n",
      "Eval Loss:  0.47590819001197815\n",
      "Eval Loss:  0.2177630066871643\n",
      "Eval Loss:  0.2867605984210968\n",
      "Eval Loss:  0.4595542550086975\n",
      "Eval Loss:  0.4677641689777374\n",
      "Eval Loss:  0.30360862612724304\n",
      "Eval Loss:  0.3862440288066864\n",
      "Eval Loss:  0.3277934789657593\n",
      "Eval Loss:  0.2899948060512543\n",
      "Eval Loss:  0.2691170275211334\n",
      "Eval Loss:  0.3249603509902954\n",
      "Eval Loss:  0.3383650481700897\n",
      "Eval Loss:  0.37807345390319824\n",
      "Eval Loss:  0.30023446679115295\n",
      "Eval Loss:  0.2767326831817627\n",
      "Eval Loss:  0.22260014712810516\n",
      "Eval Loss:  0.3195352852344513\n",
      "Eval Loss:  0.3800913989543915\n",
      "[[17937   476]\n",
      " [ 3596  7862]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     18413\n",
      "           1       0.94      0.69      0.79     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.89      0.83      0.85     29871\n",
      "weighted avg       0.88      0.86      0.86     29871\n",
      "\n",
      "acc:  0.863680492785645\n",
      "pre:  0.9429119692971936\n",
      "rec:  0.6861581427823354\n",
      "ma F1:  0.846182131693102\n",
      "mi F1:  0.863680492785645\n",
      "we F1:  0.8582616454795671\n",
      "29871 467\n",
      "Loss:  0.08949505537748337\n",
      "Loss:  0.06017329543828964\n",
      "Loss:  0.07639048993587494\n",
      "24 **********\n",
      "Epoch:  1437.4824633598328  fold:  10  kers:  64\n",
      "epoch:  25\n",
      "29871 467\n",
      "Loss:  0.050263769924640656\n",
      "Loss:  0.051121052354574203\n",
      "Loss:  0.06008702889084816\n",
      "25 **********\n",
      "Epoch:  1482.0064153671265  fold:  10  kers:  64\n",
      "epoch:  26\n",
      "29871 467\n",
      "Loss:  0.04023084416985512\n",
      "Loss:  0.08818667382001877\n",
      "Loss:  0.05576397106051445\n",
      "26 **********\n",
      "Epoch:  1526.584223985672  fold:  10  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.1990508884191513\n",
      "Eval Loss:  0.12037193775177002\n",
      "Eval Loss:  0.04730774089694023\n",
      "[[1650  101]\n",
      " [ 132 1137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1751\n",
      "           1       0.92      0.90      0.91      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.92      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9228476821192053\n",
      "pre:  0.9184168012924071\n",
      "rec:  0.8959810874704491\n",
      "ma F1:  0.9205553067318668\n",
      "mi F1:  0.9228476821192053\n",
      "we F1:  0.9227091565110035\n",
      "update!  Acc:  0.9228476821192053\n",
      "Eval Loss:  0.25351396203041077\n",
      "Eval Loss:  0.21345779299736023\n",
      "Eval Loss:  0.22991305589675903\n",
      "Eval Loss:  0.19314615428447723\n",
      "Eval Loss:  0.31000441312789917\n",
      "Eval Loss:  0.23355798423290253\n",
      "Eval Loss:  0.25687628984451294\n",
      "Eval Loss:  0.22679075598716736\n",
      "Eval Loss:  0.2798515558242798\n",
      "Eval Loss:  0.32080018520355225\n",
      "Eval Loss:  0.19554546475410461\n",
      "Eval Loss:  0.31226322054862976\n",
      "Eval Loss:  0.15746058523654938\n",
      "Eval Loss:  0.23521968722343445\n",
      "Eval Loss:  0.3436446487903595\n",
      "Eval Loss:  0.3338664472103119\n",
      "Eval Loss:  0.281809002161026\n",
      "Eval Loss:  0.29102185368537903\n",
      "Eval Loss:  0.22096647322177887\n",
      "Eval Loss:  0.1944505274295807\n",
      "Eval Loss:  0.20532900094985962\n",
      "Eval Loss:  0.27408236265182495\n",
      "Eval Loss:  0.23704396188259125\n",
      "Eval Loss:  0.3179037868976593\n",
      "Eval Loss:  0.19814114272594452\n",
      "Eval Loss:  0.20279060304164886\n",
      "Eval Loss:  0.20032118260860443\n",
      "Eval Loss:  0.29383715987205505\n",
      "Eval Loss:  0.26213449239730835\n",
      "[[17317  1096]\n",
      " [ 1834  9624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18413\n",
      "           1       0.90      0.84      0.87     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9019115530112819\n",
      "pre:  0.8977611940298508\n",
      "rec:  0.8399371618083435\n",
      "ma F1:  0.8949434411749108\n",
      "mi F1:  0.9019115530112819\n",
      "we F1:  0.9012430925231445\n",
      "29871 467\n",
      "Loss:  0.058607667684555054\n",
      "Loss:  0.055028047412633896\n",
      "Loss:  0.0687812939286232\n",
      "27 **********\n",
      "Epoch:  1610.1567673683167  fold:  10  kers:  64\n",
      "epoch:  28\n",
      "29871 467\n",
      "Loss:  0.07826288789510727\n",
      "Loss:  0.060498084872961044\n",
      "Loss:  0.048156607896089554\n",
      "28 **********\n",
      "Epoch:  1654.6906926631927  fold:  10  kers:  64\n",
      "epoch:  29\n",
      "29871 467\n",
      "Loss:  0.06645596772432327\n",
      "Loss:  0.07699556648731232\n",
      "Loss:  0.062069304287433624\n",
      "29 **********\n",
      "Epoch:  1699.2385804653168  fold:  10  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.27945676445961\n",
      "Eval Loss:  0.11192773282527924\n",
      "Eval Loss:  0.033692941069602966\n",
      "[[1675   76]\n",
      " [ 161 1108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      1751\n",
      "           1       0.94      0.87      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.921523178807947\n",
      "pre:  0.9358108108108109\n",
      "rec:  0.8731284475965327\n",
      "ma F1:  0.9186558427514495\n",
      "mi F1:  0.921523178807947\n",
      "we F1:  0.9210933312509765\n",
      "Eval Loss:  0.24460363388061523\n",
      "Eval Loss:  0.22168637812137604\n",
      "Eval Loss:  0.2628324627876282\n",
      "Eval Loss:  0.19561466574668884\n",
      "Eval Loss:  0.303968608379364\n",
      "Eval Loss:  0.23260904848575592\n",
      "Eval Loss:  0.23833370208740234\n",
      "Eval Loss:  0.2411077618598938\n",
      "Eval Loss:  0.25628551840782166\n",
      "Eval Loss:  0.3182560205459595\n",
      "Eval Loss:  0.19337326288223267\n",
      "Eval Loss:  0.32020509243011475\n",
      "Eval Loss:  0.14916835725307465\n",
      "Eval Loss:  0.23801401257514954\n",
      "Eval Loss:  0.33639347553253174\n",
      "Eval Loss:  0.3418518602848053\n",
      "Eval Loss:  0.285549521446228\n",
      "Eval Loss:  0.2772336006164551\n",
      "Eval Loss:  0.21763353049755096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19606731832027435\n",
      "Eval Loss:  0.19842347502708435\n",
      "Eval Loss:  0.2574337124824524\n",
      "Eval Loss:  0.24101662635803223\n",
      "Eval Loss:  0.3112131357192993\n",
      "Eval Loss:  0.20471890270709991\n",
      "Eval Loss:  0.19004473090171814\n",
      "Eval Loss:  0.2074330896139145\n",
      "Eval Loss:  0.2724422812461853\n",
      "Eval Loss:  0.2786673307418823\n",
      "[[17514   899]\n",
      " [ 2061  9397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18413\n",
      "           1       0.91      0.82      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9009072344414315\n",
      "pre:  0.9126845376845377\n",
      "rec:  0.820125676383313\n",
      "ma F1:  0.8930068634149325\n",
      "mi F1:  0.9009072344414315\n",
      "we F1:  0.8997762462521016\n",
      "29871 467\n",
      "Loss:  0.07526931911706924\n",
      "Loss:  0.0828995481133461\n",
      "Loss:  0.06642251461744308\n",
      "30 **********\n",
      "Epoch:  1782.6874554157257  fold:  10  kers:  64\n",
      "epoch:  31\n",
      "29871 467\n",
      "Loss:  0.05345287173986435\n",
      "Loss:  0.05968521535396576\n",
      "Loss:  0.07790663838386536\n",
      "31 **********\n",
      "Epoch:  1827.1485748291016  fold:  10  kers:  64\n",
      "epoch:  32\n",
      "29871 467\n",
      "Loss:  0.08392897248268127\n",
      "Loss:  0.059080444276332855\n",
      "Loss:  0.05648750066757202\n",
      "32 **********\n",
      "Epoch:  1871.8211302757263  fold:  10  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.378925621509552\n",
      "Eval Loss:  0.10248956084251404\n",
      "Eval Loss:  0.026392817497253418\n",
      "[[1673   78]\n",
      " [ 175 1094]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      1751\n",
      "           1       0.93      0.86      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.91      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9162251655629139\n",
      "pre:  0.9334470989761092\n",
      "rec:  0.8620961386918834\n",
      "ma F1:  0.9130283242454689\n",
      "mi F1:  0.9162251655629139\n",
      "we F1:  0.9156895980192313\n",
      "Eval Loss:  0.2690127491950989\n",
      "Eval Loss:  0.21684032678604126\n",
      "Eval Loss:  0.29778316617012024\n",
      "Eval Loss:  0.18816964328289032\n",
      "Eval Loss:  0.3041136860847473\n",
      "Eval Loss:  0.24435722827911377\n",
      "Eval Loss:  0.27321696281433105\n",
      "Eval Loss:  0.25601813197135925\n",
      "Eval Loss:  0.2641589641571045\n",
      "Eval Loss:  0.3422531187534332\n",
      "Eval Loss:  0.21183845400810242\n",
      "Eval Loss:  0.3563035726547241\n",
      "Eval Loss:  0.1719939261674881\n",
      "Eval Loss:  0.2480332851409912\n",
      "Eval Loss:  0.3854655921459198\n",
      "Eval Loss:  0.39564624428749084\n",
      "Eval Loss:  0.3077291250228882\n",
      "Eval Loss:  0.32681262493133545\n",
      "Eval Loss:  0.2465120106935501\n",
      "Eval Loss:  0.20106908679008484\n",
      "Eval Loss:  0.21852731704711914\n",
      "Eval Loss:  0.2662939429283142\n",
      "Eval Loss:  0.2709847390651703\n",
      "Eval Loss:  0.32660195231437683\n",
      "Eval Loss:  0.2348058819770813\n",
      "Eval Loss:  0.22298720479011536\n",
      "Eval Loss:  0.18956802785396576\n",
      "Eval Loss:  0.2731322646141052\n",
      "Eval Loss:  0.2942921221256256\n",
      "[[17689   724]\n",
      " [ 2477  8981]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18413\n",
      "           1       0.93      0.78      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.90      0.87      0.88     29871\n",
      "weighted avg       0.90      0.89      0.89     29871\n",
      "\n",
      "acc:  0.892839208596967\n",
      "pre:  0.9253992787223081\n",
      "rec:  0.7838191656484552\n",
      "ma F1:  0.8828864251467857\n",
      "mi F1:  0.892839208596967\n",
      "we F1:  0.8908356223098555\n",
      "29871 467\n",
      "Loss:  0.047411128878593445\n",
      "Loss:  0.07067157328128815\n",
      "Loss:  0.04505980387330055\n",
      "33 **********\n",
      "Epoch:  1955.0356316566467  fold:  10  kers:  64\n",
      "epoch:  34\n",
      "29871 467\n",
      "Loss:  0.05817004665732384\n",
      "Loss:  0.04263283312320709\n",
      "Loss:  0.08387148380279541\n",
      "34 **********\n",
      "Epoch:  1999.7460844516754  fold:  10  kers:  64\n",
      "epoch:  35\n",
      "29871 467\n",
      "Loss:  0.04997885972261429\n",
      "Loss:  0.058145489543676376\n",
      "Loss:  0.06251305341720581\n",
      "35 **********\n",
      "Epoch:  2044.3328688144684  fold:  10  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.1530241072177887\n",
      "Eval Loss:  0.16115130484104156\n",
      "Eval Loss:  0.03532026335597038\n",
      "[[1657   94]\n",
      " [ 118 1151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1751\n",
      "           1       0.92      0.91      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9298013245033112\n",
      "pre:  0.9244979919678715\n",
      "rec:  0.9070133963750985\n",
      "ma F1:  0.92777372409346\n",
      "mi F1:  0.9298013245033112\n",
      "we F1:  0.9297051537328835\n",
      "update!  Acc:  0.9298013245033112\n",
      "Eval Loss:  0.2341596633195877\n",
      "Eval Loss:  0.2295202910900116\n",
      "Eval Loss:  0.24602779746055603\n",
      "Eval Loss:  0.16367073357105255\n",
      "Eval Loss:  0.29560962319374084\n",
      "Eval Loss:  0.2206890881061554\n",
      "Eval Loss:  0.23147858679294586\n",
      "Eval Loss:  0.20951393246650696\n",
      "Eval Loss:  0.2664082646369934\n",
      "Eval Loss:  0.267859548330307\n",
      "Eval Loss:  0.19577531516551971\n",
      "Eval Loss:  0.28255030512809753\n",
      "Eval Loss:  0.13305625319480896\n",
      "Eval Loss:  0.21912424266338348\n",
      "Eval Loss:  0.3033285439014435\n",
      "Eval Loss:  0.33641767501831055\n",
      "Eval Loss:  0.2910320460796356\n",
      "Eval Loss:  0.2742297351360321\n",
      "Eval Loss:  0.18674027919769287\n",
      "Eval Loss:  0.17429332435131073\n",
      "Eval Loss:  0.16770006716251373\n",
      "Eval Loss:  0.24415762722492218\n",
      "Eval Loss:  0.21804805099964142\n",
      "Eval Loss:  0.3008057475090027\n",
      "Eval Loss:  0.17479082942008972\n",
      "Eval Loss:  0.16335070133209229\n",
      "Eval Loss:  0.21486912667751312\n",
      "Eval Loss:  0.29940369725227356\n",
      "Eval Loss:  0.2270381599664688\n",
      "[[17353  1060]\n",
      " [ 1655  9803]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18413\n",
      "           1       0.90      0.86      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9091091694285427\n",
      "pre:  0.9024210623216423\n",
      "rec:  0.8555594344562751\n",
      "ma F1:  0.9029064099806725\n",
      "mi F1:  0.9091091694285427\n",
      "we F1:  0.908620342690598\n",
      "29871 467\n",
      "Loss:  0.0814240425825119\n",
      "Loss:  0.0637519508600235\n",
      "Loss:  0.052952490746974945\n",
      "36 **********\n",
      "Epoch:  2127.4994978904724  fold:  10  kers:  64\n",
      "epoch:  37\n",
      "29871 467\n",
      "Loss:  0.0458727665245533\n",
      "Loss:  0.05766081064939499\n",
      "Loss:  0.07189667224884033\n",
      "37 **********\n",
      "Epoch:  2171.9675993919373  fold:  10  kers:  64\n",
      "epoch:  38\n",
      "29871 467\n",
      "Loss:  0.03873258829116821\n",
      "Loss:  0.07108637690544128\n",
      "Loss:  0.07622241228818893\n",
      "38 **********\n",
      "Epoch:  2216.4466712474823  fold:  10  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.28849953413009644\n",
      "Eval Loss:  0.12891657650470734\n",
      "Eval Loss:  0.02610999345779419\n",
      "[[1662   89]\n",
      " [ 139 1130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94      1751\n",
      "           1       0.93      0.89      0.91      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.92      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9245033112582781\n",
      "pre:  0.9269893355209188\n",
      "rec:  0.8904649330181245\n",
      "ma F1:  0.922085469714087\n",
      "mi F1:  0.9245033112582781\n",
      "we F1:  0.9242760705116436\n",
      "Eval Loss:  0.24692699313163757\n",
      "Eval Loss:  0.20855765044689178\n",
      "Eval Loss:  0.2626839876174927\n",
      "Eval Loss:  0.1739908754825592\n",
      "Eval Loss:  0.3024938702583313\n",
      "Eval Loss:  0.22221148014068604\n",
      "Eval Loss:  0.2539784908294678\n",
      "Eval Loss:  0.2219851315021515\n",
      "Eval Loss:  0.2597648501396179\n",
      "Eval Loss:  0.27696511149406433\n",
      "Eval Loss:  0.1742808073759079\n",
      "Eval Loss:  0.2990990877151489\n",
      "Eval Loss:  0.12836802005767822\n",
      "Eval Loss:  0.23451772332191467\n",
      "Eval Loss:  0.3435724079608917\n",
      "Eval Loss:  0.35347700119018555\n",
      "Eval Loss:  0.2845015823841095\n",
      "Eval Loss:  0.29808202385902405\n",
      "Eval Loss:  0.1838545948266983\n",
      "Eval Loss:  0.1667243093252182\n",
      "Eval Loss:  0.19317422807216644\n",
      "Eval Loss:  0.2517467737197876\n",
      "Eval Loss:  0.21732649207115173\n",
      "Eval Loss:  0.2965083122253418\n",
      "Eval Loss:  0.17382200062274933\n",
      "Eval Loss:  0.17232094705104828\n",
      "Eval Loss:  0.20898862183094025\n",
      "Eval Loss:  0.2755228579044342\n",
      "Eval Loss:  0.25064992904663086\n",
      "[[17362  1051]\n",
      " [ 1660  9798]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18413\n",
      "           1       0.90      0.86      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9092430785711895\n",
      "pre:  0.9031247119550189\n",
      "rec:  0.8551230581253273\n",
      "ma F1:  0.9030248913870278\n",
      "mi F1:  0.9092430785711895\n",
      "we F1:  0.9087424339393605\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04191093519330025\n",
      "Loss:  0.057572510093450546\n",
      "Loss:  0.06862857937812805\n",
      "39 **********\n",
      "Epoch:  2299.6392323970795  fold:  10  kers:  64\n",
      "epoch:  40\n",
      "29871 467\n",
      "Loss:  0.08399897813796997\n",
      "Loss:  0.06615039706230164\n",
      "Loss:  0.028766470029950142\n",
      "40 **********\n",
      "Epoch:  2344.1083302497864  fold:  10  kers:  64\n",
      "epoch:  41\n",
      "29871 467\n",
      "Loss:  0.03933565691113472\n",
      "Loss:  0.06908755749464035\n",
      "Loss:  0.058769598603248596\n",
      "41 **********\n",
      "Epoch:  2388.5624690055847  fold:  10  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.2757006585597992\n",
      "Eval Loss:  0.1251494586467743\n",
      "Eval Loss:  0.018879365175962448\n",
      "[[1688   63]\n",
      " [ 149 1120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1751\n",
      "           1       0.95      0.88      0.91      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.92      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9298013245033112\n",
      "pre:  0.9467455621301775\n",
      "rec:  0.8825847123719465\n",
      "ma F1:  0.9272270628395176\n",
      "mi F1:  0.9298013245033112\n",
      "we F1:  0.9294115595330888\n",
      "Eval Loss:  0.25212350487709045\n",
      "Eval Loss:  0.24430030584335327\n",
      "Eval Loss:  0.27942392230033875\n",
      "Eval Loss:  0.16178706288337708\n",
      "Eval Loss:  0.26068368554115295\n",
      "Eval Loss:  0.22254887223243713\n",
      "Eval Loss:  0.2641306519508362\n",
      "Eval Loss:  0.24088317155838013\n",
      "Eval Loss:  0.29405808448791504\n",
      "Eval Loss:  0.314104825258255\n",
      "Eval Loss:  0.20289547741413116\n",
      "Eval Loss:  0.3348434865474701\n",
      "Eval Loss:  0.15318766236305237\n",
      "Eval Loss:  0.21364063024520874\n",
      "Eval Loss:  0.3473382890224457\n",
      "Eval Loss:  0.3809031844139099\n",
      "Eval Loss:  0.2944336235523224\n",
      "Eval Loss:  0.322674423456192\n",
      "Eval Loss:  0.2450292706489563\n",
      "Eval Loss:  0.1849597990512848\n",
      "Eval Loss:  0.18739540874958038\n",
      "Eval Loss:  0.23607295751571655\n",
      "Eval Loss:  0.24542298913002014\n",
      "Eval Loss:  0.29939085245132446\n",
      "Eval Loss:  0.1838042140007019\n",
      "Eval Loss:  0.20672127604484558\n",
      "Eval Loss:  0.20023521780967712\n",
      "Eval Loss:  0.3050270676612854\n",
      "Eval Loss:  0.27257677912712097\n",
      "[[17683   730]\n",
      " [ 2173  9285]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18413\n",
      "           1       0.93      0.81      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.91      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9028154397241471\n",
      "pre:  0.927109335996006\n",
      "rec:  0.810350846570082\n",
      "ma F1:  0.8944746115114295\n",
      "mi F1:  0.9028154397241471\n",
      "we F1:  0.9013822633594234\n",
      "29871 467\n",
      "Loss:  0.07722586393356323\n",
      "Loss:  0.060290172696113586\n",
      "Loss:  0.06478951871395111\n",
      "42 **********\n",
      "Epoch:  2471.9235780239105  fold:  10  kers:  64\n",
      "epoch:  43\n",
      "29871 467\n",
      "Loss:  0.042275670915842056\n",
      "Loss:  0.051482051610946655\n",
      "Loss:  0.04966118186712265\n",
      "43 **********\n",
      "Epoch:  2516.392676591873  fold:  10  kers:  64\n",
      "epoch:  44\n",
      "29871 467\n",
      "Loss:  0.055683474987745285\n",
      "Loss:  0.04792192950844765\n",
      "Loss:  0.0563928596675396\n",
      "44 **********\n",
      "Epoch:  2560.898676633835  fold:  10  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.17791254818439484\n",
      "Eval Loss:  0.17405983805656433\n",
      "Eval Loss:  0.017438601702451706\n",
      "[[1661   90]\n",
      " [ 111 1158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      1751\n",
      "           1       0.93      0.91      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9334437086092715\n",
      "pre:  0.9278846153846154\n",
      "rec:  0.9125295508274232\n",
      "ma F1:  0.9315446899770179\n",
      "mi F1:  0.9334437086092715\n",
      "we F1:  0.9333644255252211\n",
      "update!  Acc:  0.9334437086092715\n",
      "Eval Loss:  0.22061938047409058\n",
      "Eval Loss:  0.21845339238643646\n",
      "Eval Loss:  0.2733461558818817\n",
      "Eval Loss:  0.135607048869133\n",
      "Eval Loss:  0.26387104392051697\n",
      "Eval Loss:  0.19507011771202087\n",
      "Eval Loss:  0.2277631014585495\n",
      "Eval Loss:  0.21239639818668365\n",
      "Eval Loss:  0.2515701949596405\n",
      "Eval Loss:  0.2776350677013397\n",
      "Eval Loss:  0.1754312962293625\n",
      "Eval Loss:  0.3031541109085083\n",
      "Eval Loss:  0.12329143285751343\n",
      "Eval Loss:  0.20662693679332733\n",
      "Eval Loss:  0.32472333312034607\n",
      "Eval Loss:  0.34535861015319824\n",
      "Eval Loss:  0.28698286414146423\n",
      "Eval Loss:  0.277224063873291\n",
      "Eval Loss:  0.2198273092508316\n",
      "Eval Loss:  0.17054198682308197\n",
      "Eval Loss:  0.15995411574840546\n",
      "Eval Loss:  0.2590519189834595\n",
      "Eval Loss:  0.2189129889011383\n",
      "Eval Loss:  0.28481531143188477\n",
      "Eval Loss:  0.1715434491634369\n",
      "Eval Loss:  0.16703416407108307\n",
      "Eval Loss:  0.19543911516666412\n",
      "Eval Loss:  0.2781982421875\n",
      "Eval Loss:  0.23537684977054596\n",
      "[[17587   826]\n",
      " [ 1802  9656]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18413\n",
      "           1       0.92      0.84      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.91     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9120216932811087\n",
      "pre:  0.9211982446098073\n",
      "rec:  0.8427299703264095\n",
      "ma F1:  0.9053493236383966\n",
      "mi F1:  0.9120216932811087\n",
      "we F1:  0.9112005821007675\n",
      "29871 467\n",
      "Loss:  0.02874462679028511\n",
      "Loss:  0.05950067192316055\n",
      "Loss:  0.044279757887125015\n",
      "45 **********\n",
      "Epoch:  2644.546020746231  fold:  10  kers:  64\n",
      "epoch:  46\n",
      "29871 467\n",
      "Loss:  0.053554974496364594\n",
      "Loss:  0.06738069653511047\n",
      "Loss:  0.0556894987821579\n",
      "46 **********\n",
      "Epoch:  2689.06897521019  fold:  10  kers:  64\n",
      "epoch:  47\n",
      "29871 467\n",
      "Loss:  0.037342797964811325\n",
      "Loss:  0.05274062603712082\n",
      "Loss:  0.04852169379591942\n",
      "47 **********\n",
      "Epoch:  2733.581956386566  fold:  10  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.3987239897251129\n",
      "Eval Loss:  0.11942218244075775\n",
      "Eval Loss:  0.023603295907378197\n",
      "[[1671   80]\n",
      " [ 154 1115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      1751\n",
      "           1       0.93      0.88      0.91      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.92      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9225165562913907\n",
      "pre:  0.9330543933054394\n",
      "rec:  0.8786446020488574\n",
      "ma F1:  0.9197981129608647\n",
      "mi F1:  0.9225165562913907\n",
      "we F1:  0.9221547490855294\n",
      "Eval Loss:  0.1949886530637741\n",
      "Eval Loss:  0.2263675332069397\n",
      "Eval Loss:  0.2593185305595398\n",
      "Eval Loss:  0.1484537124633789\n",
      "Eval Loss:  0.2745773196220398\n",
      "Eval Loss:  0.21975970268249512\n",
      "Eval Loss:  0.2566643953323364\n",
      "Eval Loss:  0.21586748957633972\n",
      "Eval Loss:  0.24853675067424774\n",
      "Eval Loss:  0.2512708008289337\n",
      "Eval Loss:  0.16551971435546875\n",
      "Eval Loss:  0.3065463900566101\n",
      "Eval Loss:  0.11494635045528412\n",
      "Eval Loss:  0.1976257860660553\n",
      "Eval Loss:  0.3284398913383484\n",
      "Eval Loss:  0.3196941912174225\n",
      "Eval Loss:  0.29239755868911743\n",
      "Eval Loss:  0.2944769859313965\n",
      "Eval Loss:  0.2586950957775116\n",
      "Eval Loss:  0.16331373155117035\n",
      "Eval Loss:  0.17254005372524261\n",
      "Eval Loss:  0.2519099712371826\n",
      "Eval Loss:  0.2522808313369751\n",
      "Eval Loss:  0.2720108926296234\n",
      "Eval Loss:  0.14966535568237305\n",
      "Eval Loss:  0.17622005939483643\n",
      "Eval Loss:  0.19834110140800476\n",
      "Eval Loss:  0.2589004933834076\n",
      "Eval Loss:  0.23333217203617096\n",
      "[[17468   945]\n",
      " [ 1708  9750]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18413\n",
      "           1       0.91      0.85      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9111847611395668\n",
      "pre:  0.9116409537166901\n",
      "rec:  0.8509338453482284\n",
      "ma F1:  0.9048313974446374\n",
      "mi F1:  0.9111847611395667\n",
      "we F1:  0.910556668823004\n",
      "29871 467\n",
      "Loss:  0.056228555738925934\n",
      "Loss:  0.07106855511665344\n",
      "Loss:  0.03479287400841713\n",
      "48 **********\n",
      "Epoch:  2816.9809646606445  fold:  10  kers:  64\n",
      "epoch:  49\n",
      "29871 467\n",
      "Loss:  0.05570473521947861\n",
      "Loss:  0.06208629906177521\n",
      "Loss:  0.07319384068250656\n",
      "49 **********\n",
      "Epoch:  2861.4560475349426  fold:  10  kers:  64\n",
      "epoch:  50\n",
      "29871 467\n",
      "Loss:  0.05935763940215111\n",
      "Loss:  0.09297607094049454\n",
      "Loss:  0.07319196313619614\n",
      "50 **********\n",
      "Epoch:  2907.4720101356506  fold:  10  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.35440659523010254\n",
      "Eval Loss:  0.14458665251731873\n",
      "Eval Loss:  0.02068997547030449\n",
      "[[1658   93]\n",
      " [ 151 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      1751\n",
      "           1       0.92      0.88      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.919205298013245\n",
      "pre:  0.9232039636663915\n",
      "rec:  0.8810086682427108\n",
      "ma F1:  0.9165367886915549\n",
      "mi F1:  0.919205298013245\n",
      "we F1:  0.9189186803453597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20493166148662567\n",
      "Eval Loss:  0.2241005003452301\n",
      "Eval Loss:  0.26292794942855835\n",
      "Eval Loss:  0.13729940354824066\n",
      "Eval Loss:  0.24654431641101837\n",
      "Eval Loss:  0.2070959061384201\n",
      "Eval Loss:  0.23736535012722015\n",
      "Eval Loss:  0.2154388278722763\n",
      "Eval Loss:  0.23577502369880676\n",
      "Eval Loss:  0.23769375681877136\n",
      "Eval Loss:  0.15508371591567993\n",
      "Eval Loss:  0.2756982147693634\n",
      "Eval Loss:  0.12113776057958603\n",
      "Eval Loss:  0.1886121779680252\n",
      "Eval Loss:  0.2895374894142151\n",
      "Eval Loss:  0.3092426061630249\n",
      "Eval Loss:  0.2855108380317688\n",
      "Eval Loss:  0.2733054459095001\n",
      "Eval Loss:  0.20514348149299622\n",
      "Eval Loss:  0.1508912295103073\n",
      "Eval Loss:  0.16675499081611633\n",
      "Eval Loss:  0.24017375707626343\n",
      "Eval Loss:  0.22736050188541412\n",
      "Eval Loss:  0.2223445177078247\n",
      "Eval Loss:  0.1793491095304489\n",
      "Eval Loss:  0.18363629281520844\n",
      "Eval Loss:  0.18786418437957764\n",
      "Eval Loss:  0.22091691195964813\n",
      "Eval Loss:  0.20384925603866577\n",
      "[[17532   881]\n",
      " [ 1668  9790]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18413\n",
      "           1       0.92      0.85      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.92      0.90      0.91     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9146663988483814\n",
      "pre:  0.9174397900852779\n",
      "rec:  0.8544248559958108\n",
      "ma F1:  0.9085213315310097\n",
      "mi F1:  0.9146663988483814\n",
      "we F1:  0.9140417323566774\n",
      "29871 467\n",
      "Loss:  0.11260931193828583\n",
      "Loss:  0.06909727305173874\n",
      "Loss:  0.06099522113800049\n",
      "51 **********\n",
      "Epoch:  2992.7440097332  fold:  10  kers:  64\n",
      "epoch:  52\n",
      "29871 467\n",
      "Loss:  0.05080137029290199\n",
      "Loss:  0.039325326681137085\n",
      "Loss:  0.04687538743019104\n",
      "52 **********\n",
      "Epoch:  3038.5535249710083  fold:  10  kers:  64\n",
      "epoch:  53\n",
      "29871 467\n",
      "Loss:  0.07346711307764053\n",
      "Loss:  0.04225633665919304\n",
      "Loss:  0.08412981033325195\n",
      "53 **********\n",
      "Epoch:  3084.324143409729  fold:  10  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.23268908262252808\n",
      "Eval Loss:  0.1853107362985611\n",
      "Eval Loss:  0.01156061515212059\n",
      "[[1671   80]\n",
      " [ 130 1139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1751\n",
      "           1       0.93      0.90      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9304635761589404\n",
      "pre:  0.9343724364232978\n",
      "rec:  0.8975571315996848\n",
      "ma F1:  0.9282366168419223\n",
      "mi F1:  0.9304635761589404\n",
      "we F1:  0.9302542754712506\n",
      "Eval Loss:  0.19023831188678741\n",
      "Eval Loss:  0.20320814847946167\n",
      "Eval Loss:  0.24995647370815277\n",
      "Eval Loss:  0.13811932504177094\n",
      "Eval Loss:  0.24463410675525665\n",
      "Eval Loss:  0.2214156687259674\n",
      "Eval Loss:  0.2104712426662445\n",
      "Eval Loss:  0.20490768551826477\n",
      "Eval Loss:  0.2253197729587555\n",
      "Eval Loss:  0.25344952940940857\n",
      "Eval Loss:  0.15912240743637085\n",
      "Eval Loss:  0.2716871201992035\n",
      "Eval Loss:  0.10294310003519058\n",
      "Eval Loss:  0.19458584487438202\n",
      "Eval Loss:  0.289834201335907\n",
      "Eval Loss:  0.315355122089386\n",
      "Eval Loss:  0.2771458029747009\n",
      "Eval Loss:  0.27261462807655334\n",
      "Eval Loss:  0.21675720810890198\n",
      "Eval Loss:  0.1463913768529892\n",
      "Eval Loss:  0.15104062855243683\n",
      "Eval Loss:  0.23327839374542236\n",
      "Eval Loss:  0.22354057431221008\n",
      "Eval Loss:  0.24686096608638763\n",
      "Eval Loss:  0.15450972318649292\n",
      "Eval Loss:  0.16545827686786652\n",
      "Eval Loss:  0.18772976100444794\n",
      "Eval Loss:  0.24110695719718933\n",
      "Eval Loss:  0.2131798416376114\n",
      "[[17645   768]\n",
      " [ 1734  9724]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18413\n",
      "           1       0.93      0.85      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.90      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9162398312744803\n",
      "pre:  0.9268013724742661\n",
      "rec:  0.8486646884272997\n",
      "ma F1:  0.9099045898518494\n",
      "mi F1:  0.9162398312744803\n",
      "we F1:  0.9154672213496904\n",
      "29871 467\n",
      "Loss:  0.06657533347606659\n",
      "Loss:  0.046981483697891235\n",
      "Loss:  0.10257613658905029\n",
      "54 **********\n",
      "Epoch:  3168.971812725067  fold:  10  kers:  64\n",
      "epoch:  55\n",
      "29871 467\n",
      "Loss:  0.09626799821853638\n",
      "Loss:  0.06776578724384308\n",
      "Loss:  0.02658304199576378\n",
      "55 **********\n",
      "Epoch:  3214.6157701015472  fold:  10  kers:  64\n",
      "epoch:  56\n",
      "29871 467\n",
      "Loss:  0.04771355167031288\n",
      "Loss:  0.06443700194358826\n",
      "Loss:  0.061736658215522766\n",
      "56 **********\n",
      "Epoch:  3260.054276227951  fold:  10  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.37528181076049805\n",
      "Eval Loss:  0.14632384479045868\n",
      "Eval Loss:  0.02585759572684765\n",
      "[[1620  131]\n",
      " [ 135 1134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      1751\n",
      "           1       0.90      0.89      0.90      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9119205298013245\n",
      "pre:  0.8964426877470356\n",
      "rec:  0.8936170212765957\n",
      "ma F1:  0.9095788435294823\n",
      "mi F1:  0.9119205298013245\n",
      "we F1:  0.9119012566632847\n",
      "Eval Loss:  0.20943616330623627\n",
      "Eval Loss:  0.23000501096248627\n",
      "Eval Loss:  0.2535771429538727\n",
      "Eval Loss:  0.16636435687541962\n",
      "Eval Loss:  0.26125815510749817\n",
      "Eval Loss:  0.23906749486923218\n",
      "Eval Loss:  0.24918438494205475\n",
      "Eval Loss:  0.18278080224990845\n",
      "Eval Loss:  0.2265872061252594\n",
      "Eval Loss:  0.21540704369544983\n",
      "Eval Loss:  0.13989722728729248\n",
      "Eval Loss:  0.26900431513786316\n",
      "Eval Loss:  0.08786438405513763\n",
      "Eval Loss:  0.21627038717269897\n",
      "Eval Loss:  0.29638931155204773\n",
      "Eval Loss:  0.2965952455997467\n",
      "Eval Loss:  0.3055455982685089\n",
      "Eval Loss:  0.2921695411205292\n",
      "Eval Loss:  0.24717368185520172\n",
      "Eval Loss:  0.13623972237110138\n",
      "Eval Loss:  0.1876869648694992\n",
      "Eval Loss:  0.24825900793075562\n",
      "Eval Loss:  0.23073425889015198\n",
      "Eval Loss:  0.23210185766220093\n",
      "Eval Loss:  0.14372766017913818\n",
      "Eval Loss:  0.1903344839811325\n",
      "Eval Loss:  0.1980576366186142\n",
      "Eval Loss:  0.22694863379001617\n",
      "Eval Loss:  0.2135789394378662\n",
      "[[17145  1268]\n",
      " [ 1237 10221]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18413\n",
      "           1       0.89      0.89      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9161393994174952\n",
      "pre:  0.8896335625380799\n",
      "rec:  0.892040495723512\n",
      "ma F1:  0.911377750580038\n",
      "mi F1:  0.9161393994174952\n",
      "we F1:  0.9161607181803435\n",
      "29871 467\n",
      "Loss:  0.05886651948094368\n",
      "Loss:  0.046732623130083084\n",
      "Loss:  0.04398122802376747\n",
      "57 **********\n",
      "Epoch:  3345.7631084918976  fold:  10  kers:  64\n",
      "epoch:  58\n",
      "29871 467\n",
      "Loss:  0.06531251221895218\n",
      "Loss:  0.05313152074813843\n",
      "Loss:  0.07872478663921356\n",
      "58 **********\n",
      "Epoch:  3391.114846944809  fold:  10  kers:  64\n",
      "epoch:  59\n",
      "29871 467\n",
      "Loss:  0.0736212283372879\n",
      "Loss:  0.05384242534637451\n",
      "Loss:  0.04837048798799515\n",
      "59 **********\n",
      "Epoch:  3436.502489566803  fold:  10  kers:  64\n",
      "Eval Loss:  0.15960416197776794\n",
      "Eval Loss:  0.31001657247543335\n",
      "Eval Loss:  0.017422303557395935\n",
      "[[1620  131]\n",
      " [  81 1188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1751\n",
      "           1       0.90      0.94      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9298013245033112\n",
      "pre:  0.9006823351023503\n",
      "rec:  0.9361702127659575\n",
      "ma F1:  0.9283348944500063\n",
      "mi F1:  0.9298013245033112\n",
      "we F1:  0.9299710502039252\n",
      "update!  Acc:  0.9334437086092715\n",
      "Epoch:  3440.0699515342712  fold:  10  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0nklEQVR4nO3deXwTdfoH8M/TlnLfLYcUKJRyVEHAghyKIh4cKuqKIrse7K7ICrurq+uiqIvHKqLorory875FPFAU5JBDAQFbkKtCoWCBlkI522KBXs/vj0zKJJkkM8kkk2Se9+vVV5PJHN8hZZ6Z7/F8iZkhhBDCfuKsLoAQQghrSAAQQgibkgAghBA2JQFACCFsSgKAEELYVILVBTAiKSmJU1NTrS6GEEJElQ0bNhxh5mT35VEVAFJTU5GdnW11MYQQIqoQ0V6t5VIFJIQQNiUBQAghbEoCgBBC2JQEACGEsCkJAEIIYVMSAIQQwqYkAAghhE3ZMgBs3n8CWwtKrC6GEEJYKqoGgpll9Kw1AID86aMsLokQQlhH1xMAEQ0nolwiyiOiKRqfdyeitUR0hojuVy3vRkSbVD+lRHSP8tk0IipUfTbStLPSqbK6Bj3/vRhfbSoM96GFEMJyfgMAEcUDmAVgBIAMALcQUYbbascA/A3Ac+qFzJzLzL2ZuTeACwCUA5inWuUF5+fMvDDw0wjMifJKlJ2pwhPf/BLuQwshhOX0PAH0B5DHzHuYuQLAHACj1SswczEzZwGo9LGfYQB2M7NmTopw+XrzASsPL4QQEUNPG0A7APtV7wsAXBjAscYC+Nht2WQiug1ANoD7mPl4APvV5bMNBZj3cwHW5B2tXXbgxKlQHU4IISKenicA0lhmaCZ5IkoEcC2AT1WLXwWQBqA3gCIAM71sO4GIsoko+/Dhw0YO6+L+Tze7XPyBs43BQghhR3oCQAGA9qr3KQCM1qOMALCRmQ85FzDzIWauZuYaAK/DUdXkgZlfY+ZMZs5MTvZIZ63Ly8t3BbSdEELEMj0BIAtAOhF1Uu7kxwKYb/A4t8Ct+oeI2qreXg9gm8F96vbckp1+1tB6yBFCiNjmtw2AmauIaDKAxQDiAbzFzDlENFH5fDYRtYGjHr8JgBqlq2cGM5cSUQMAVwC4y23XM4ioNxzVSfkan4dN6WlfbddCCBGbdA0EU7poLnRbNlv1+iAcVUNa25YDaKmx/FZDJQ2hiqoaq4sghBBhZ8tUEEIIISQACCGEbUkAEEIIm5IAIIQQNiUBQAghbMoWAWDuXQOtLoIQQkQcWwSA/p1aWF0EIYSIOLYIAEIIITxJABBCCJuyTQCom2CbUxVCCF1sc1W88+LOhrepqWG8v24vTldWG9puW2EJdhwsNXw8IYQIJ9sEgHuv6Op3nUXbDqLvE0txpspxwV+UcxCPfLkNM5fkeqy7/1g5Kqu1cwhd/dJqDP/vquAKLIQQIWabABAf5z/l8+Nf5+DYbxU4crICAHDydBUA4Hi5a7bQE+UVuHjGCjz6VY75BRVCiDCxTQDQ40DJaZf3rEx85h46ypTAsGpX4DOUCSGE1SQAKKo0qnNYmfiSZL4YIUQMkgCg+Djr7Lz3Ow+VuXxGJswY9vXmA0idsgCHSk/7X1kIIcJAAoBi1c6z1Tnj384CAKUCyDv2t4LKJ0qAcQ8uQghhFVsFgMyOzb1+tuSXQ14/O1VZjZJTvqeNnPBeNv79VcimNRZCCNPZKgAYuGF3rK9sMH/zAZz/2BKf6y755RDeXbs3sIIJIYQF7BUADNTZVFXX1PYCEkKIWGSrAGBEl6nfGqrjF0KIaGOrAHD/Vd1M2U8w3UKfXrjDcGoJIYQIBV0BgIiGE1EuEeUR0RSNz7sT0VoiOkNE97t9lk9EW4loExFlq5a3IKKlRLRL+e29hdYkg9KSkD99lO71jVQZ+eMMGr8UleKNVXtM268wz7bCEpSU+27sFyKW+A0ARBQPYBaAEQAyANxCRBluqx0D8DcAz3nZzVBm7s3MmaplUwAsY+Z0AMuU9xHlkRCleqislrqlSHT1S6tx0/+ttboYQoSNnieA/gDymHkPM1cAmANgtHoFZi5m5iwARm6fRgN4V3n9LoDrDGwbEcx8QjDTmapq7DtabnUxolKujNMQNqInALQDsF/1vkBZphcDWEJEG4hogmp5a2YuAgDldyutjYloAhFlE1H24cPW5t75fEOBs0yGtzUjVjAzNuw97jfwdHt4EYY8uwK/nakK/qAxKvdgGTbtP2F1MYSwlJ4AoHW1M3I5G8zMfeGoQppEREMMbAtmfo2ZM5k5Mzk52cimppu1Mg/lFdZdVOf9XIjfvfoj5m8+oGt9aWz27qr//oDrZq2xuhhCWEpPACgA0F71PgWAvisQAGY+oPwuBjAPjiolADhERG0BQPldrHefVtlz+Dfc9uZPte8PlJzG3qO/he34vx5xHGuvVO8IIUygJwBkAUgnok5ElAhgLID5enZORA2JqLHzNYArATjzJcwHcLvy+nYAXxkpuFWy9x7HGdWd9ZUv/GB4H8yMx77OQVHJKTOLJoQQhiT4W4GZq4hoMoDFAOIBvMXMOUQ0Ufl8NhG1AZANoAmAGiK6B44eQ0kA5il15gkAPmLmRcqupwOYS0R/ArAPwBhTzyyEXlm5u/b1mSrtWcHUSk5VYnXekdr3WfnHsXbPUeQeLMNHdw5wWbemhnGmqgb1E+PNK7BFVu86gnk/F2LmTedbXRQhhAa/AQAAmHkhgIVuy2arXh+Eo2rIXSkAzf/9zHwUwDDdJY0gpyqM1a2/sjLP5b0zxUR1jWdTyvRFO/DaD3uw/fHhXoNAhHY+8vCHN9cDgAQAISKUrUYCO31054VBbX/iVIWh9Y+U6V//M6WnkVZjs8xLI4Qwky0DwKC0pKC2Lzf4BHC6SnrjRLvTldVInbIAX20qtLooQpjGlgEgWD/vO6F73W2FJTjkNtewc4axUNfk6B2vsP9YOZ5ZtCNiB7ZFgsNlZwAAzy7OtbgkQphHAkCIXf3SamTvPe6yLNg5hvWmqe77xFIUHPffZfQvH27Aqyt3yyhYIWxGAoCVjN5wK5Ej/8hvOOk2ynf/sXIUa8w3vNTHTGdOlVVy5y+EHUkAMMGMRTsMra/nCcDXJfnLTQcw7vV1LssunrEC/Z9aZqgcQgh7kwBgAvW4gOO/Gesh5E5v7dCWgpKgjmMFZsaH6/damk4jUOFoHik4Xi7pqEVYSQAw2ZJfDupeN5KnnMw5UIJDGlVKwViddwRT523DE9/8AgDYXlSK1CkLsPvwSVOPE0rBtt/4ctEzKzDs+e9DdwAh3EgAsACFsUd/oHeuo15cjYueWW5qWX474+gOe/Sk4ynpS6VL5ZIc/+0UseDXI79h2vwc1GgMAHQ6cvJMGEsk7E4CgAVCeRcZCG+9f2TiGnNNfH8D3vkxHzuLpbeViAy2DQD9U1tYXQRLUjqsyC1GzoGz7QfbCqOjLaGmhlFV7T/vklkueXYFXl6+y9R9Oqv8wvkEKIQvtg0AI3q2Ccl+jVzUQ3H9d89T5H6M8W9nYdSLq2vfHw2y0Tpc/v7JJnSZ+q3u9bcVliAr/1jAx9t7tBzPLdlZ+15ve03qlAW4abZMKymig20DwB2DUkOyX/VlInXKAs11jpf7v+i6B5Lxb/+EF5f5vyPt8egil/fBju7VSlhnha91ToLjdPVLqzFGuRCfqarGM4t2mNL7SM/d+09BBB4tJacqNcd4CBEs2waAQKZ11GOPjh4t2wpLvX7mrVgrckM/HaZWrEh7aCHmZp2dEbS49HTQU02GO6R8uG4fXl25G6+s2O1/5Qg0RGOMx8rcYlToSEUuhC+2DQChEs0NpyP+t8qlfcBJPQVl/6eWBTyVolWN3xVK20GliW0IOw6WYkmO/i6/ZacrsfNQYN1dS065jg34cP1e3PF2luEBiEK4kwBgsnd+zA/7MfNM7FWyUseTxq5ix4WMmW2bQG74f1dhwvsbdK9/x9tZta+DDYRT5zkm1dtccCK4HQnbkwBgoQ17j6PwxNlpIfv95zscUfrIv/tjPrYXea8qUrv8eePTUjoFei06XVmNTg8uxAtLd/pfWWCDW0JAM0RTb6InvvnFa5uYsI4EAIsNm7kSADD5o421KYcB4OUVeRjxv1UAgAnvZQe8/0+zC4IqnzfOORHeX7c3JPs3UzAPKacrq3H05JmomYUtUr25+leriyA0SACw2OnKGhSeOIVvthR5XWeJjoye3uQeKkPZaf35ZYxOd+lePx3RArhhvvXN9bjgye/O7iJ6brqF8MvWAeD3F3awuggAfF90fdWx7zl8Ep9v8H+H33PaEuQf+U1XWV5eked/JQBPKvl8AuklGul30+reNVn5rlU3zI6gEBEiJBgVl53G5I82Rl2SvyMnz2CXzefAsHkA6Gh1EQD47mv/wnfe+/5f/vz3uO/TzbqOEUwdtNZd7xc/G58aMUKuV379Y+4mj2Xqf4NVu46ErzBu/vKB/obnQBSVnPKYawJwjGl5Y9UezW2eW5yLb7YUaY7VKDlViVIDT6DhNPTZlbjihcDbz2KBrgBARMOJKJeI8ohoisbn3YloLRGdIaL7VcvbE9EKItpORDlE9HfVZ9OIqJCINik/I805Jf0yzmmCG/q0C/dhPfjqzvfReu917Ebuvu/7dDMe/nKrx3I9VRrO5G128e02/d07AxFMIFSXLRQBdeDTy712831ywXbD+zv/sSXoNW2J3/Wqaxib958wvP9glAU5niUW+A0ARBQPYBaAEQAyANxCRBluqx0D8DcAz7ktrwJwHzP3ADAAwCS3bV9g5t7Kz8JATyIYCfHW35f+7OMP/4iJF98P1u0LaLsanXU2pyqqcdULP+DnfTqfNrzsdkVuMRYb6GPv/zDB1zlFerWVmfKKw5+e+3/f7cToWWuwNQrnuYhmep4A+gPIY+Y9zFwBYA6A0eoVmLmYmbMAVLotL2LmjcrrMgDbAVh/y60SCZkOjkV4Pp4dB/XVk24tLEHuobLafP96uT+FjH87C3cZ6GPvyw2vrMGRMse/rxndJiOpEdi9LNU1jA/W7TV1wFu45BxwdHn2NwfFn9/Nwh/fyfK5jtBPTwBoB2C/6n0BAriIE1EqgD4A1C1ok4loCxG9RUTNvWw3gYiyiSj78GHz0yHY6c4u1HYcdPwn3rjvBN5bm697O2bjOYfKTlfidKVr4/mRk2c8Gs037juBT7ICe/KJNp9k7cfDX27DG6tit8vld9uLsXxHsdXFiBl6AoDWPY+h/61E1AjA5wDuYWbn6KZXAaQB6A2gCMBMrW2Z+TVmzmTmzOTkZCOH1cWuI1nN9NePfwYAPPpVTu0y9Wt3320/5FLNMCdrH9IeWoiDJfoTnvWctgQ3vPJj7fvtRaXIfPI7fPzTfh9bxRb3P11nl9wTpyL7iVJ4x8yYuSTXZYBoKOkJAAUA2qvepwDQnZqRiOrAcfH/kJm/cC5n5kPMXM3MNQBeh6OqSYSZVsObnoR2av4yde496uiCqk7Ad7lq6sO9R8td1tPrF9VIaWdAWbPbs4eO8zo5f1MhBj29zOeMXEDoeysFWo3k3pU3kqqjAHmaNsP2ojK8tDwPkz7cGJbj6QkAWQDSiagTESUCGAtgvp6dk+N//JsAtjPz826ftVW9vR7ANn1FNpdd/2Y/21CA1CkLXHLeO2nl0T9TZWyAmNolz64EAOw/Vh7wPrzRU3XkvDAdKDmNAyWna5PDGWHu30lgV+7fv+E6/iBSUkFESjligbPDRbgyvfoNAMxcBWAygMVwNOLOZeYcIppIRBMBgIjaEFEBgH8AeJiICoioCYDBAG4FcJlGd88ZRLSViLYAGArgXvNPz79eKU2tOKzlvvTRj/9fn3t2Fw327o6Z8bjBxmFv1XPq/EP/nu//vuFUZeDBy52Vlzq956F18fho/T6MfU0mqnEyksk1lukaB8DMC5m5KzOnMfN/lGWzmXm28vogM6cwcxNmbqa8LmXm1cxMzNzLvbsnM9/KzD2Vz65lZu+5EELo0m6trDhs1Ak2AHyw3n9DrPscDd6O+T/VxDjzNnoGshVBNhL6qlo5Xu59UNND8zwDZ7D8VVdpeXtNvkfV3kPztmLdHtcnux0HS3H1S6s0B34ZYUY323AqOVVpKJNrLLP1SGBAGoH1CvY/+VqNunkz1Elw/RP+Me8IxvvpJujvK/c1p4Ov3Ecf6QhyRnV+yPvwGF+BSs9YjGcX5WJbYSnW7T6quzzLd3jPSxVpbRLemDm3dHb+sYCCdKSQAGB1AaLEuz/u9ZlPKJg2Aif3C8i6X4+ixMcdNwAkxMWhqrqmNt2Arzt0p8qa6OsnD4RuvMjCrUW6ckoBwKFSVcba5buwfo/+4GEUM+OzDQUe3X0jxapdh3Hj7LV4Y7V2ioxghCuYSgCQCKDLM4t24NLnVnr9/NY3fzK8zy83eVbfqO+mxr2+Huc/vgTbCr2PDi2vqMLUedtqJ0nRY9n2s3ex/gKMk5lPih9EWArtL34u1J1TSu25JTtx82vrat+b/X9p+Y5i3P/pZjy7ONfcHZvkgNJV04qR02axfQCw6zPARr3pGnT66VffE6Ev3OrZ6Ka+mwQcDawLt3k2BV390mqv+y2vqMY8g4np1A8A5z++RFef6x92mjcI0axZ44iA0tOVpvUYme+nO683oeqzXnba0TZx5OQZP2sGb/WuIxg2c6UpT7KBOlNVHfannYSwHi0C2fUJoNxg3v9weH3VHgwNQ6P8PrfuqP/7bicGprX0uc20r431YAIcjaxzftqva84EdUrwB7/Ygh93H8X3/xzqcxsCode0JRjQuQXmTBhouHzu1Qx/Uwb0GbUmL3TVQKHg3tkAAB79ahv2HPkNBcdPIS25kQWlAobMWOFxUxRqtg8AUdx+E3MW5xxCy0Z1Q34cdS8iAJibXYC5IZg5bexr63DCRxUTM2PG4lz8YUBHvKlK32B0NLN77x4RvE37T2DTvuO4Y3An3dtUVNVg//HygAOI+uIvbQDClqp99MDxKkJ7n/jrHZJzoBSvrtyNSR9uxLHfjN/5+eqZVVnN+rOyRigru5deN2uN36c+99qDqfO2YtjM77021pdXVOF4hCV+tH0A6NiygdVFEDEo50AJSk/77l/vvIBU1dSgKoBHUV8jcJ/6djuuf+VHbCss8RGIvG9fXKY/L5PZKqtrXGYXi/RqWuf3sFbpEbXvWLnLCPUtBSew72g5hs38Hn2eWGpJGb2xfQCoVyceu/4zwupiCEUgqYzDNWzeiFEvem+41mI0Gyrgu5rAedG8+qXV+NfnWwzve8R/VwFwzASmTu+t92Fr7GtrdXctVcvKP4b0qd8i49HFtcsCbZz25ouN3sulFWz8Ncy6P6lcN2uNyyRP1768BkOeXYEiA8kOw8X2AQAA6sTLP0OkCGSqyVjga/BZsD51uxAXlZxCt4e/rU3freWoqqrizdX60kvvOFiG1CkLkFdchnV7jgXUtXRFbuhTPWvObOYlsi3JOYjujyzS7Irsa2rQpb8cwucbCrBhr+/2GWbGgi1FHr2PwpVfyfaNwCK6ROqgoGBVBzk4reC4vkR7T37zC1bkFuNMVQ0KjpvbfdOZFXZxjvfRwv6o78AjoerHGZC2FJTgvHZn84Zl5R/Dgq2+s9foCYCr845g0kcbcefF+hubzSS3viKqdH9kkdVFCBsjKQv2H9N3MX9j9a/YfdhY2m2rGJ1ZLpzU82TPzS4wVHX59ppfsVtJue7sJXbAouohCQBCWOBwmf9eP2sM5OiJJCfKffd02XGwVNfkP3rSerjLPViGBz7bHFCbioPrdnqfQnLdpk311aj/2Ne/4PpZawyXLBQkAAhhgk0aE+v4kp1/zKXxUOtycftbxtNrhNoBHaN+X/czJeXw/67CgKeXmVUkF3e9n4252QUeg/38cda4exsgabRfvr8quWAzsJpFAoAQQTj+WwW+/LkQ1wVxRxdog5+6EfLN1XtqJxMJpReX55m6P2ZG7sEyLAsihXdesaPxuevD39YuU3cj1cM5SdCd72Wj7LT/Jw9/ASHYAaYyEEyIKNDniaW455NNAW3rnAqTwUH3+fhue7HfqTnNlDplgSn7+XxjIa767w9B7ePy5x3bV1TV1PamMtwNV9nuUOkZ9Jy2pHa5M6au33MUx3+r8JkOOxpJLyAhLMAA/qrKvWPGvXs09JByDxzu3Su9/TvU1LDHXfGJ8grNvD5G6fl3+3LTAew9Vo6f953AlmlXBn3MSCEBQAiLRWJivkjT+aGFuLBTC5dlvR83Z1Ttxz95n8hH3U6zR+k9Fc0TwLiTKiAhLLYnSrpl+nPUYJ4brbp2X/MurPeTcjxQ1TVs+EnC7Cr6BVtcxxSEK72VPAEIYYG7P9zo8t6M9lszqkPCSV3X7qR3jMK419f5XynMImHgmlHyBCCEiDo/mjhGgoi8PnmE6qIeKcFaVwAgouFElEtEeUQ0RePz7kS0lojOENH9erYlohZEtJSIdim/mwd/OkIIs+w7aqwvfSQI5Lp6qqLK60jcM6pEg3om9jFi/7Fyy+cj9BsAiCgewCwAIwBkALiFiDLcVjsG4G8AnjOw7RQAy5g5HcAy5b0QtmTGhaDMT/ppo6xMCR0o9zt2ZsbK3GKfDbfPLdnp9TOtJHAE8riDNxp4qmsYF89Ygfe8TQ8apicEPW0A/QHkMfMeACCiOQBGA6hN1MHMxQCKiWiUgW1HA7hUWe9dACsB/CvQExHC7sIxdy7gf/7nSPHSsl2YudRxcb/70jScrqzBgq3GxkpohY3TJs4bnL1Xe9KeXB+ZWs2kpwqoHQD1HHUFyjI9fG3bmpmLAED5rTkZLBFNIKJsIso+fNi8ibndTbsmA11bWzMXqBAbvVwIrHTj7LWay2/6P+3lkcZ58QeAV1buxltrfjVlzt1/zN3ksSzw3EPaTleGZ44LPQFA61lE79kGs61jZebXmDmTmTOTk5ONbGrIHYM74a+XpYds/0L4Eim5YYR/WfmewfqBz4xPugP4rul55MttSJ2yAD/sDN2Nr54AUACgvep9CgC9z1G+tj1ERG0BQPkd+pkg/LC6QUYIEVl8jUtQ2+GWDVT//r1/9v66vQA8J/Qxk54AkAUgnYg6EVEigLEA5uvcv69t5wO4XXl9O4Cv9Bc7NPR+2UKIyGQ0CVwgKqpqsPdobAze89sIzMxVRDQZwGIA8QDeYuYcIpqofD6biNoAyAbQBEANEd0DIIOZS7W2VXY9HcBcIvoTgH0Axph8bkIImwlkDgFfvN0Sak0rWagjVXYgjv0WusZ9XSOBmXkhgIVuy2arXh+Eo3pH17bK8qMAhhkprBBC2M2avNBNDCQjgYUQwqYkAAghhBd7I2Q09GaDM87pJQFACCEi3LYDniOSzSABQAghItwJkxu3nSQAqDSqK9mxhRD2IQFA5bLurXDXJZ2tLoYQQoSFBAAVIsKYCzR7swohRMyRAOAmLkImahBCiFCTAOCmU1JDPDSyu9XFEEKIWqG6L5UA4IaIMGFImtXFEEKIWjMW5eJEeYXp+5UA4EWvlKZWF0EIIWp9+XOh6fuUAOBFpEzaLIQQoSIBwAu5/AshYp0EAC8S4iQECCEix8JtB03fpwQAL566oafVRRBCiFpbCk6Yvk8JAF4kN6prdRGEECKkJAAIIUQUOF1ZY/o+JQB40VASwwkhYpwEAC8SE+Jwabdkq4shhBAhIwHAh3fG97e6CEIIETISAIQQwqZ0BQAiGk5EuUSUR0RTND4nInpR+XwLEfVVlncjok2qn1Iiukf5bBoRFao+G2nqmQkhhPDJb0snEcUDmAXgCgAFALKIaD4z/6JabQSAdOXnQgCvAriQmXMB9FbtpxDAPNV2LzDzcyachxBCCIP0PAH0B5DHzHuYuQLAHACj3dYZDeA9dlgHoBkRtXVbZxiA3cy8N+hSCyGECJqeANAOwH7V+wJlmdF1xgL42G3ZZKXK6C0iaq51cCKaQETZRJR9+PBhHcUNjQdHyBwBQojYoicAaCXFYSPrEFEigGsBfKr6/FUAaXBUERUBmKl1cGZ+jZkzmTkzOTn83TKbNagDABiT2T7sxxZCiFDSEwAKAKivfikADhhcZwSAjcx8yLmAmQ8xczUz1wB4HY6qpoglqeGEELFGTwDIApBORJ2UO/mxAOa7rTMfwG1Kb6ABAEqYuUj1+S1wq/5xayO4HsA2w6UXQggRML8BgJmrAEwGsBjAdgBzmTmHiCYS0URltYUA9gDIg+Nu/m7n9kTUAI4eRF+47XoGEW0loi0AhgK4N9iTCYXJQ7sAkNQQQojYQ8zu1fmRKzMzk7Ozsy07/vIdh/DHd6w7vhDC3vKnjwpoOyLawMyZ7stlJLABl3VvjaX3DrG6GEIIYQoJAAalJjW0ughCCGEKCQAG1YmXfzIhRGyQq5kQQtiUBIAAzL1roNVFEEKIoEkACECDxPja10vuHYJ/XNHVwtIIIURgJAAEoHubxhjVqy0W3XMxurZujCSZQF4IEYVkdFMAEuLjMGtc39r3Q7omWVgaIYQIjDwBmCCleYOAB2gIIYRVJAAIIYRNSQAQQgibkgAghBA2JQHAROsfGmZ1EYQQQjcJACZq3aSe1UUQQgjdJACEyAPDu1ldBCGE8EkCQIhc0+scq4sghBA+SQAQQgibkgAQIuc0q48rM1rjqet7Gt42Pk6moBdChJ4EAJP17dAMgOMi/tptmRh3YQfD+7jvSkkuJ4QIPQkAJnv/Txdi1QNDda3buol2Erkm9er43Xb2Hy4wVC4hhHAnAcBkDesmoH2LBrrW/c91xquHnC5OlwR0Qojg6AoARDSciHKJKI+Ipmh8TkT0ovL5FiLqq/osn4i2EtEmIspWLW9BREuJaJfyu7k5pxRbnr5BO0g0rCuJXIUQwfEbAIgoHsAsACMAZAC4hYgy3FYbASBd+ZkA4FW3z4cyc29mzlQtmwJgGTOnA1imvLeN5fddUvu6eQPvVT5j+7UPR3GEEDak5wmgP4A8Zt7DzBUA5gAY7bbOaADvscM6AM2IqK2f/Y4G8K7y+l0A1+kvdnTbOu1KdE5uhJ4pTQHAo6GYlE5AifFxICJc1r1VuIsohLABPQGgHYD9qvcFyjK96zCAJUS0gYgmqNZpzcxFAKD81rzKEdEEIsomouzDhw/rKG7ka6w08rZuUg/500d5XOCZgWX3XYIfH7wMANC7fbNwF1EIYQN6AoBWp3Q2sM5gZu4LRzXRJCIaYqB8YObXmDmTmTOTk5ONbBpxvPX60ZKW3Mhjqsm7hnQ2u0hCCBvT05JYAEBdEZ0C4IDedZjZ+buYiObBUaX0A4BDRNSWmYuU6qLiwE4henw5aTB+OVDqsZzdw6kXiQnSaUsIYR49V5QsAOlE1ImIEgGMBTDfbZ35AG5TegMNAFCiXNgbElFjACCihgCuBLBNtc3tyuvbAXwV5LlErIGdW2LaNRlo27Q+hvVobXh7ZxVQH2WQmZZHrs7AHwboG3QmbQpCCEDHEwAzVxHRZACLAcQDeIuZc4hoovL5bAALAYwEkAegHMB4ZfPWAOaRo1UzAcBHzLxI+Ww6gLlE9CcA+wCMMe2sIszHEwYEtf2QrsnIfvhyjyohtfGDUpFzoBQfrNuHsf3aY07Wfq/rDklPwvIdMf/AJYTwQ1dncmZeCMdFXr1stuo1A5iksd0eAOd72edRADKDCjwbVLRqhHxd/AEgLo7QM6UpVv9rKNo1q+8zAGhp1bguisvO6Fp306NXoPfjSzU/S2qUiCMnKwwdWwhhDalUjmKtGnsGhZTmDUB0tk2+X6rn+LourRp7LFtyr6G2eSFEDJDhpFGsUd0Er3ftD43sjgs6NkePtk2Q8ehil88uSk/C3LsGomHdeIx6cXU4iiqEiEDyBBAB9PYCcjcwrSUA4NXf9/X4bMKQNFzQsQUaJLrG+F7K4LP+nVrg3HOaau437z8jsFTHE0EjjXQUzEC7ZvX9biuEsJ48AUSxadeeiz9f3Bmdkhrq3qZtU9/zFjepl4CE+Dikt/asJhJCWGdUT3/JFYyTJ4AIktqyAa46tzWu7+M+0Fpbnfg4Qxd/Lc5jkeZYPoeMtk1c3jetXwe3DeyID/58YVDHFkLoNyYzxfR9SgCIAM5kcBelJ+H/bs3UrFoJlRdu7o386aN8rvP2+H4u74kIj48+D+ed08TLFuHTOcgAKES0UHfuMIsEgAiQ3roxPp04EI9c7Z5kNTK0bqJdbaT1BznUzyCz4ee2MaVMTh/8+UKMH5xq6j6FiERdWjUyfZ8SACJEv9QWqJsQH/LjGAkyyY3roq6P9BPxcYTJQ7u4LGvRMBG+blRuG9hR9/H1IAL+fc25+Nfw7qbuV4hI06Se+TUD0ghsIxd1SUJKc32zlQHA2imXaQ5KU7v/qm54eUWey7IEX5Pah2i++0Yh+M8hRKyTJwAbubqXsV4ECfFxqBNv7E/koi5JeHt8f3Ro0QAzbuzl8Xl7twB0SdezGV4fHtXD0LGAwLvQChFt6tcxv4ZAAoBNZLRtgpt9zC7WqF4CurdpjGfHaGbu0CX3yeEY0jUZnZIa4ocHhuKmTM/juc+X3L9TCwDABI1U10O6Rnf6byHMlGDwZkzXPk3fo4g4Gx+5Ag0S4332IoiPIyy6J7h0EHrbMMZd2AEfrd/ncXx1+d79Y38MTmuJLlO/1dxH26b1UFRyuraKKqW58cFnCXGEqhp5hNDSuF4Cyk5XWV0MEWLyBBBlPp04EF9PvsjQNi0aJqJeCB4fAzUk/eyd/dBujl5DV2a4psmuXyfe6x3PoLSWHk0Jzv0YEe+rrcKLBomOf8dv/ur7Oxhzgfl9tsNJ/R2J2CUBIMr0S21RO5dwtOmf6qjuGX5eG7RsmIiJl6Qh45wmyJ8+Cn06eCat0/LyuD5474/9a9+zqhGgTrz2Bf2V3/d1uWDPGtcXD44IrteQvwF4z445H/dd0TWoY1gqRI31IrJIABBhMXVkD5d5ETY8cgWmuF2EL+qSVPvaWRu056mRWKvMjQwA6a0aIyE+TrM663d9HXfd7oGgTdN6OK/d2aA5qldb3HVJmtey3nlxJx1n5Mm9m95fh6Ub2t7IlKF6PXndeabvU8QOCQAiLO4c0tlvlUu3No2R2dHxJOC8sY+LI7RtWh9v39EPz97YC93aOHIUzbixF85PaeoySO3uS7ugV0pTDD9PX2+nxqoLtrqH1H1XdsPfLuuCWeP64vmbXBvF3/tjf9zQt11tVZDjuGn45q8X4cVb+ngcw8jgzadv6AkAeOzac3G+hU95Zo/VEJFLAoCIKN4umEO7t8IYVa+iwV2S8NXki1y6qXZo2QDzJ1+EB67qhl4pTdGxpe8xD59OHIQeSp4jdRtJvTrx+MeV3TCqV9vaXkpOmakt8PxNvUFEOK+dY9vkxnVxXrumaFq/jscxcp8YgYaJ+tpfLuveGt//81LcPigVyY19J+3Ty1sTt6/pRevrLK/T/Vd29dsmIiKTBABhSF8fFw4tjeslBF3fblT7Fo5A0LxBos/1OiU1dEkjoTXq2VfPqdsGOrZNS27kdd3EhDjU8TGa2l3Hls62hdD1ThrVqy3iTMwrM/mydJcqNjvwNUI+msTGWYiw+eLuwZrLE738h9g67Sqf9e3h5O+at/6hYS7tDf6MuSAFS+8d4ne8QiCXWvcBboO7tHR538ZLfiZ3vVOaubyfOeZ8zBrX12eZbh3QEVP8pNaY/QfPOSisMKBzC/8rhcCXk7T/H0QbCQAiaD9OuQzrHzRneucHR/ZAl1aNaqtXgnHHoFQAQCflrnrbtKuwddqVXtdv1iARbZu6jidQXyjdu98Skcu8Cc6xCP++xne+JT29g9zv/98Z3x+fTRxY+/7cc5pg3t2D0KGF92qu/43tjZ4pTbH98eEe+3U+tbh79sZeSGneAMka042qabWzeLsJCCWjCdIeHtXDlOlPiYDl910S9H6sJgFABO2cZvXRvKHv6ha9+nZoju/+cYnHTGaBuK5PO+RPH1VbtoZ1E9C4nmc9vR5tmtTz2/02qVFd7H5qZG3gcXKvGmqlo7cPuz0C1ImPQ2ZqC5eeU306NMcPDwzFf67X7ukzurdjrgetOv3HRp+rmXpjpJdJR0b1bIvz2zfzWeZebtVAU0d67t/f09KdF3fC9/+81Oc6ancM8t5jK9VLG1DX1o1x7+XBd9FNbRn9qch1BQAiGk5EuUSUR0RTND4nInpR+XwLEfVVlrcnohVEtJ2Icojo76ptphFRIRFtUn5Gmndawmyr/zU0Ju543Dl78zTxEhiMVpW7j2gOlLcU3Fp37r+/0LPXjr85JerVicfFBgZ7NWtQx2/ipTfvODtvxIwbe3mk/QD8tyHVT0xQtYP456vr7Ir7L8XUkT1w7fnn1C5zPrH9/fJ0fP6Xgd42xTo/T7QEQlwAAwkjjd8AQETxAGYBGAEgA8AtROT+jDsCQLryMwHAq8ryKgD3MXMPAAMATHLb9gVm7q38LAzuVEQopTRvgM5eqg2i2cjz2uKRqzPwz6u6hewYWpcJdePzrHF98czverp8/ug1GXhuzPm4wcvscO4xZt7dg2pff//PS/HDA0MDK6uy37oJcZh4iaN767RrMjB1VA+PaqkpI7q7HFfdC+oqt3kfXrylDx4Y3g2T3NKHB8vXEx0R4c4hnV268qqTD17Q0Xv7QZum9fD5XwZ5/dyfUEzfGAp6nrP7A8hj5j0AQERzAIwG8ItqndEA3mPHc+s6ImpGRG2ZuQhAEQAwcxkRbQfQzm1bISwTF0f400X+B36xib1y+nZojpv7dcA/r+qG0lNVaKMxT3ODxATceEEKbujTTjOrqjv1SGpfd9C92+vrrUNEtdVNzh4+nZMaYktBCdKSHfufqNG437huAsrOeOYQUt+Fh1sokqj5esi7pX8HPHp1BhZsLQLgGCBYGqF5lfT8y7QDsF/1vkBZZmgdIkoF0AfAetXiyUqV0VtEpJkLgIgmEFE2EWUfPnxYR3GFMI+vuZL1cp+sxlkN0SAxQfPirxYXRy4XMPe2Ab3yp49C/vRR6NKqsc/1fJ2vs1pqjEaWV4/96PhnW6V6SnGOx1BvFh9HuMbCwBGop2/oifqJ8Zg01BEgzagSDFVvJz0BQKv07n+FPtchokYAPgdwDzOXKotfBZAGoDccTwkztQ7OzK8xcyYzZyYnS4IqEV5N6jseksf1D3x07E392vudd9k4z/9yztHSehl9qnEOuvM14U+qkiMpnshrcHti9Lno2LIB2rdogLfuyMQdg1I9kgHO+F0vLL5nSG3Ae3z0uRjazfH/370d4YY+7TDmghQ8du25pla9dG3tvcrTyCXd/dy0vHCzdhp2ZyoPb21CwdJTBVQAQB3yUwAc0LsOEdWB4+L/ITN/4VyBmQ85XxPR6wC+MVRyIcKgQWIC9jw10nBjsBX8zcfsTbfWjfGnizvhqYXbfXblvHtoGiqra/CHAd6D4Tvj+2HT/hNoWDcBvb30Grp1YCpuVQbRXda9NS7r3hp5xSfxv2W7au/4b3Kbu6JZA0fywO93Hkbv9s2xcd+J2s+ev7l37evbB6ViwZQFvk9Yp8b16iB/+iikKvtLb9UIu4pPuqzz1aTBKK+oxi2vrwOgPcK6Q4sGLvvRcn2fFNz7yWYAQM5jV+HoyQrsP16Ow2VnTDkXb/QEgCwA6UTUCUAhgLEAxrmtMx+O6pw5AC4EUMLMReR49nkTwHZmfl69gaqNAACuB7AtiPMQImTM6u1xeY9W2H/sVFD7aKF0afWX5kKP1JYNkZbcEP++JgODuiRpTuCj1iAxAQ9qdO1Ua9moLob1OHvH+5dL0zCgc0sfWzh0adVI8ynp5n7t8c2WIlzQsTnaNauPPU+PwsvLdwE4m/wvXNQ3Ac7X7l1ju7X2rGIzevPQsG4CGtZNQIeWDbAytxgA/FYVBspvAGDmKiKaDGAxgHgAbzFzDhFNVD6fDWAhgJEA8gCUAxivbD4YwK0AthLRJmXZQ0qPnxlE1BuOqqJ8AHeZdE5CRKQ3bu/nfyU/MlNb4O07+mGwKnNqoOrVicey+y4Nej++uLd/GHVxerJHYHDWqYcie6ov6l5OTev7H/firbnm4zsHYFdxGR79KgcAfA66u6RrMmaN64srdFQjBULXaBvlgr3Qbdls1WsGMElju9XwUl3GzLcaKqkQAkDgVT2xYmTPtnh2cS6u89JF1myXdW+F5TuK8dItfTHg6WUAPC/ak4d2wcsr8jTv9p0Ba/oNPdGmaT0MTGvpMk7DV1oPIsIog3N5GyFTQgohokqnpIamNap/dOeFyD1Yhse+9t4zfda4vig8ccpnNcw5zTynJHV/ABjbv0Pta/Wocme7y5gLUvDphgKdJTeHpIIQQsSUn6YOQ/bDl+tad1BaEsYP9j0OpH5ivN+cQ4GME+nlllrkmd/1ws4nRxjeTzAkAAghYkqrxvWQ1Ci87QNnna0DmnhJGn7XNwW3u+WGcnpitKOLp3Niorg4CntCPakCEkIIFfdkfnpoNfg2rV8HM2/S7t8POJ4Apo7sgRv6hqctQ4sEACGE7b1w8/loUq+OSxdWLZv/faXPuXqMdPl05iqykgQAIYTtXd9H35gCrWk/AaCV0iuoffPgx2eEkwQAIYQI0hUZrfH2Hf38zncQaSQACCFi3pwJA1B4PLhR2L4QUVSOz5AAIISIeXrSUdiRdAMVQgibkgAghBA2JQFACCFsSgKAEELYlAQAIYSwKQkAQghhUxIAhBDCpiQACCGETRF7m7csAhHRYQB7A9w8CcARE4sTKWL1vIDYPTc5r+gT7efWkZk98lREVQAIBhFlM3Om1eUwW6yeFxC75ybnFX1i9dykCkgIIWxKAoAQQtiUnQLAa1YXIERi9byA2D03Oa/oE5PnZps2ACGEEK7s9AQghBBCRQKAEELYlC0CABENJ6JcIsojoilWl0cPIsonoq1EtImIspVlLYhoKRHtUn43V63/oHJ+uUR0lWr5Bcp+8ojoRSIj01abch5vEVExEW1TLTPtPIioLhF9oixfT0SpFp7XNCIqVL6zTUQ0MgrPqz0RrSCi7USUQ0R/V5bHwnfm7dyi/nsLGDPH9A+AeAC7AXQGkAhgM4AMq8ulo9z5AJLcls0AMEV5PQXAM8rrDOW86gLopJxvvPLZTwAGAiAA3wIYEebzGAKgL4BtoTgPAHcDmK28HgvgEwvPaxqA+zXWjabzagugr/K6MYCdSvlj4Tvzdm5R/70F+mOHJ4D+APKYeQ8zVwCYA2C0xWUK1GgA7yqv3wVwnWr5HGY+w8y/AsgD0J+I2gJowsxr2fEX+Z5qm7Bg5h8AHHNbbOZ5qPf1GYBh4XjK8XJe3kTTeRUx80bldRmA7QDaITa+M2/n5k3UnFug7BAA2gHYr3pfAN9feqRgAEuIaAMRTVCWtWbmIsDxxwzAOQu1t3Nsp7x2X241M8+jdhtmrgJQAsDKCWAnE9EWpYrIWU0SleelVF/0AbAeMfaduZ0bEEPfmxF2CABa0Tca+r4OZua+AEYAmEREQ3ys6+0co+3cAzmPSDrHVwGkAegNoAjATGV51J0XETUC8DmAe5i51NeqGsui7dxi5nszyg4BoABAe9X7FAAHLCqLbsx8QPldDGAeHFVZh5THTyi/i5XVvZ1jgfLafbnVzDyP2m2IKAFAU+ivmjEVMx9i5mpmrgHwOhzfmUsZFRF9XkRUB44L5IfM/IWyOCa+M61zi5XvLRB2CABZANKJqBMRJcLRMDPf4jL5REQNiaix8zWAKwFsg6Pctyur3Q7gK+X1fABjlR4InQCkA/hJeVQvI6IBSj3kbaptrGTmeaj3dSOA5Uq9bNg5L5CK6+H4zoAoOi+lHG8C2M7Mz6s+ivrvzNu5xcL3FjCrW6HD8QNgJBwt/rsBTLW6PDrK2xmO3gebAeQ4ywxHXeIyALuU3y1U20xVzi8Xqp4+ADLh+IPeDeBlKKO/w3guH8PxWF0Jx93Rn8w8DwD1AHwKRwPdTwA6W3he7wPYCmALHBeCtlF4XhfBUWWxBcAm5WdkjHxn3s4t6r+3QH8kFYQQQtiUHaqAhBBCaJAAIIQQNiUBQAghbEoCgBBC2JQEACGEsCkJAEIIYVMSAIQQwqb+H22WtMARK1xWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "  \n",
      "kernel: 32\n",
      "  \n",
      "*********\n",
      "29459 3432\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29459 461\n",
      "Loss:  0.1695123016834259\n",
      "Loss:  0.16481846570968628\n",
      "Loss:  0.15159659087657928\n",
      "0 **********\n",
      "Epoch:  52.95441007614136  fold:  1  kers:  32\n",
      "epoch:  1\n",
      "29459 461\n",
      "Loss:  0.152180477976799\n",
      "Loss:  0.12236005812883377\n",
      "Loss:  0.16918213665485382\n",
      "1 **********\n",
      "Epoch:  93.41821956634521  fold:  1  kers:  32\n",
      "epoch:  2\n",
      "29459 461\n",
      "Loss:  0.10341968387365341\n",
      "Loss:  0.09778666496276855\n",
      "Loss:  0.11633370071649551\n",
      "2 **********\n",
      "Epoch:  133.82019186019897  fold:  1  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.3586723804473877\n",
      "Eval Loss:  0.6129983067512512\n",
      "Eval Loss:  0.2733783721923828\n",
      "[[ 828  211]\n",
      " [ 736 1657]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.80      0.64      1039\n",
      "           1       0.89      0.69      0.78      2393\n",
      "\n",
      "    accuracy                           0.72      3432\n",
      "   macro avg       0.71      0.74      0.71      3432\n",
      "weighted avg       0.78      0.72      0.73      3432\n",
      "\n",
      "acc:  0.7240675990675991\n",
      "pre:  0.8870449678800857\n",
      "rec:  0.6924362724613455\n",
      "ma F1:  0.7069703570781029\n",
      "mi F1:  0.7240675990675991\n",
      "we F1:  0.7348951648631183\n",
      "update!  Acc:  0.7240675990675991\n",
      "Eval Loss:  0.3883915841579437\n",
      "Eval Loss:  0.3702752888202667\n",
      "Eval Loss:  0.30251064896583557\n",
      "Eval Loss:  0.42335692048072815\n",
      "Eval Loss:  0.33592110872268677\n",
      "Eval Loss:  0.43205899000167847\n",
      "Eval Loss:  0.46433717012405396\n",
      "Eval Loss:  0.4099844992160797\n",
      "Eval Loss:  0.43902266025543213\n",
      "Eval Loss:  0.4666067957878113\n",
      "Eval Loss:  0.37792325019836426\n",
      "Eval Loss:  0.4648924767971039\n",
      "Eval Loss:  0.4833836257457733\n",
      "Eval Loss:  0.42323991656303406\n",
      "Eval Loss:  0.3100641369819641\n",
      "Eval Loss:  0.4853469431400299\n",
      "Eval Loss:  0.39819782972335815\n",
      "Eval Loss:  0.5043113231658936\n",
      "Eval Loss:  0.4804533123970032\n",
      "Eval Loss:  0.4726361036300659\n",
      "Eval Loss:  0.4148828387260437\n",
      "Eval Loss:  0.3842868506908417\n",
      "Eval Loss:  0.359835684299469\n",
      "Eval Loss:  0.4376210868358612\n",
      "Eval Loss:  0.43929776549339294\n",
      "Eval Loss:  0.44086092710494995\n",
      "Eval Loss:  0.2941526770591736\n",
      "Eval Loss:  0.4701334834098816\n",
      "[[16911  2214]\n",
      " [ 3180  7154]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86     19125\n",
      "           1       0.76      0.69      0.73     10334\n",
      "\n",
      "    accuracy                           0.82     29459\n",
      "   macro avg       0.80      0.79      0.79     29459\n",
      "weighted avg       0.81      0.82      0.81     29459\n",
      "\n",
      "acc:  0.8168980617128891\n",
      "pre:  0.763663535439795\n",
      "rec:  0.6922779175537063\n",
      "ma F1:  0.7943373943110983\n",
      "mi F1:  0.8168980617128891\n",
      "we F1:  0.8146644238416039\n",
      "29459 461\n",
      "Loss:  0.12230757623910904\n",
      "Loss:  0.1276005357503891\n",
      "Loss:  0.07601334899663925\n",
      "3 **********\n",
      "Epoch:  212.57062911987305  fold:  1  kers:  32\n",
      "epoch:  4\n",
      "29459 461\n",
      "Loss:  0.11391136050224304\n",
      "Loss:  0.07173001766204834\n",
      "Loss:  0.06623756140470505\n",
      "4 **********\n",
      "Epoch:  252.96861267089844  fold:  1  kers:  32\n",
      "epoch:  5\n",
      "29459 461\n",
      "Loss:  0.08672267198562622\n",
      "Loss:  0.06921184062957764\n",
      "Loss:  0.0875992551445961\n",
      "5 **********\n",
      "Epoch:  293.42543959617615  fold:  1  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.386711061000824\n",
      "Eval Loss:  0.4577361047267914\n",
      "Eval Loss:  0.15289531648159027\n",
      "[[ 851  188]\n",
      " [ 576 1817]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.69      1039\n",
      "           1       0.91      0.76      0.83      2393\n",
      "\n",
      "    accuracy                           0.78      3432\n",
      "   macro avg       0.75      0.79      0.76      3432\n",
      "weighted avg       0.81      0.78      0.79      3432\n",
      "\n",
      "acc:  0.7773892773892774\n",
      "pre:  0.9062344139650873\n",
      "rec:  0.759297952361053\n",
      "ma F1:  0.7582356058770354\n",
      "mi F1:  0.7773892773892774\n",
      "we F1:  0.785082470501855\n",
      "update!  Acc:  0.7773892773892774\n",
      "Eval Loss:  0.39981192350387573\n",
      "Eval Loss:  0.2772979438304901\n",
      "Eval Loss:  0.27592888474464417\n",
      "Eval Loss:  0.40117359161376953\n",
      "Eval Loss:  0.30903464555740356\n",
      "Eval Loss:  0.4001835584640503\n",
      "Eval Loss:  0.40532320737838745\n",
      "Eval Loss:  0.3457099497318268\n",
      "Eval Loss:  0.3407875895500183\n",
      "Eval Loss:  0.40854522585868835\n",
      "Eval Loss:  0.29262280464172363\n",
      "Eval Loss:  0.35326820611953735\n",
      "Eval Loss:  0.4005663990974426\n",
      "Eval Loss:  0.4006485939025879\n",
      "Eval Loss:  0.21710368990898132\n",
      "Eval Loss:  0.45518699288368225\n",
      "Eval Loss:  0.35631805658340454\n",
      "Eval Loss:  0.4376659691333771\n",
      "Eval Loss:  0.4341370761394501\n",
      "Eval Loss:  0.37235191464424133\n",
      "Eval Loss:  0.37312665581703186\n",
      "Eval Loss:  0.35920387506484985\n",
      "Eval Loss:  0.3087879717350006\n",
      "Eval Loss:  0.3847409188747406\n",
      "Eval Loss:  0.36687880754470825\n",
      "Eval Loss:  0.42992761731147766\n",
      "Eval Loss:  0.2859783470630646\n",
      "Eval Loss:  0.39080575108528137\n",
      "[[17941  1184]\n",
      " [ 3243  7091]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     19125\n",
      "           1       0.86      0.69      0.76     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.85      0.81      0.83     29459\n",
      "weighted avg       0.85      0.85      0.85     29459\n",
      "\n",
      "acc:  0.8497233443090397\n",
      "pre:  0.8569184290030212\n",
      "rec:  0.6861815366750532\n",
      "ma F1:  0.8261388842554584\n",
      "mi F1:  0.8497233443090397\n",
      "we F1:  0.8452477311062448\n",
      "29459 461\n",
      "Loss:  0.061138033866882324\n",
      "Loss:  0.1299326866865158\n",
      "Loss:  0.07867337763309479\n",
      "6 **********\n",
      "Epoch:  377.36300802230835  fold:  1  kers:  32\n",
      "epoch:  7\n",
      "29459 461\n",
      "Loss:  0.0779813900589943\n",
      "Loss:  0.09600549936294556\n",
      "Loss:  0.08544150739908218\n",
      "7 **********\n",
      "Epoch:  417.81883668899536  fold:  1  kers:  32\n",
      "epoch:  8\n",
      "29459 461\n",
      "Loss:  0.06432420015335083\n",
      "Loss:  0.08492975682020187\n",
      "Loss:  0.10950057208538055\n",
      "8 **********\n",
      "Epoch:  458.2008635997772  fold:  1  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.47256097197532654\n",
      "Eval Loss:  0.7485381364822388\n",
      "Eval Loss:  0.11401297152042389\n",
      "[[ 897  142]\n",
      " [ 829 1564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.86      0.65      1039\n",
      "           1       0.92      0.65      0.76      2393\n",
      "\n",
      "    accuracy                           0.72      3432\n",
      "   macro avg       0.72      0.76      0.71      3432\n",
      "weighted avg       0.80      0.72      0.73      3432\n",
      "\n",
      "acc:  0.7170745920745921\n",
      "pre:  0.9167643610785463\n",
      "rec:  0.6535729210196406\n",
      "ma F1:  0.7059687737537537\n",
      "mi F1:  0.7170745920745921\n",
      "we F1:  0.7285134184410328\n",
      "Eval Loss:  0.4192240834236145\n",
      "Eval Loss:  0.3015536665916443\n",
      "Eval Loss:  0.2801777422428131\n",
      "Eval Loss:  0.4079609215259552\n",
      "Eval Loss:  0.33964765071868896\n",
      "Eval Loss:  0.4150185286998749\n",
      "Eval Loss:  0.39336860179901123\n",
      "Eval Loss:  0.3345075845718384\n",
      "Eval Loss:  0.3357664942741394\n",
      "Eval Loss:  0.42044010758399963\n",
      "Eval Loss:  0.3031606376171112\n",
      "Eval Loss:  0.3578844964504242\n",
      "Eval Loss:  0.42113369703292847\n",
      "Eval Loss:  0.43688395619392395\n",
      "Eval Loss:  0.18824538588523865\n",
      "Eval Loss:  0.47017431259155273\n",
      "Eval Loss:  0.33486688137054443\n",
      "Eval Loss:  0.4397446811199188\n",
      "Eval Loss:  0.4734403192996979\n",
      "Eval Loss:  0.3984975516796112\n",
      "Eval Loss:  0.38161328434944153\n",
      "Eval Loss:  0.3924444019794464\n",
      "Eval Loss:  0.3207370936870575\n",
      "Eval Loss:  0.39329612255096436\n",
      "Eval Loss:  0.37961381673812866\n",
      "Eval Loss:  0.43084007501602173\n",
      "Eval Loss:  0.2865740656852722\n",
      "Eval Loss:  0.39042043685913086\n",
      "[[18368   757]\n",
      " [ 3705  6629]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     19125\n",
      "           1       0.90      0.64      0.75     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.86      0.80      0.82     29459\n",
      "weighted avg       0.86      0.85      0.84     29459\n",
      "\n",
      "acc:  0.8485352523846702\n",
      "pre:  0.8975088004332521\n",
      "rec:  0.6414747435649313\n",
      "ma F1:  0.819943951233908\n",
      "mi F1:  0.8485352523846702\n",
      "we F1:  0.8413551556309052\n",
      "29459 461\n",
      "Loss:  0.10225778818130493\n",
      "Loss:  0.0713898167014122\n",
      "Loss:  0.07741355150938034\n",
      "9 **********\n",
      "Epoch:  537.4439830780029  fold:  1  kers:  32\n",
      "epoch:  10\n",
      "29459 461\n",
      "Loss:  0.07888946682214737\n",
      "Loss:  0.1030443012714386\n",
      "Loss:  0.07576534152030945\n",
      "10 **********\n",
      "Epoch:  578.3077223300934  fold:  1  kers:  32\n",
      "epoch:  11\n",
      "29459 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08942991495132446\n",
      "Loss:  0.07705748081207275\n",
      "Loss:  0.1025942713022232\n",
      "11 **********\n",
      "Epoch:  620.3273701667786  fold:  1  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.5114045739173889\n",
      "Eval Loss:  0.638573408126831\n",
      "Eval Loss:  0.09567651152610779\n",
      "[[ 868  171]\n",
      " [ 686 1707]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.84      0.67      1039\n",
      "           1       0.91      0.71      0.80      2393\n",
      "\n",
      "    accuracy                           0.75      3432\n",
      "   macro avg       0.73      0.77      0.73      3432\n",
      "weighted avg       0.80      0.75      0.76      3432\n",
      "\n",
      "acc:  0.7502913752913752\n",
      "pre:  0.9089456869009584\n",
      "rec:  0.7133305474300041\n",
      "ma F1:  0.7344196047514773\n",
      "mi F1:  0.7502913752913752\n",
      "we F1:  0.7600338804499538\n",
      "Eval Loss:  0.399188756942749\n",
      "Eval Loss:  0.2679652273654938\n",
      "Eval Loss:  0.24416305124759674\n",
      "Eval Loss:  0.3595583438873291\n",
      "Eval Loss:  0.27105891704559326\n",
      "Eval Loss:  0.38048043847084045\n",
      "Eval Loss:  0.3240828216075897\n",
      "Eval Loss:  0.28595638275146484\n",
      "Eval Loss:  0.2822180986404419\n",
      "Eval Loss:  0.3625190258026123\n",
      "Eval Loss:  0.26277580857276917\n",
      "Eval Loss:  0.3243412971496582\n",
      "Eval Loss:  0.3667633831501007\n",
      "Eval Loss:  0.3546755611896515\n",
      "Eval Loss:  0.1813991367816925\n",
      "Eval Loss:  0.41355469822883606\n",
      "Eval Loss:  0.3112046718597412\n",
      "Eval Loss:  0.3696236312389374\n",
      "Eval Loss:  0.4189079999923706\n",
      "Eval Loss:  0.3350832760334015\n",
      "Eval Loss:  0.32570409774780273\n",
      "Eval Loss:  0.3415137827396393\n",
      "Eval Loss:  0.28008756041526794\n",
      "Eval Loss:  0.3202512264251709\n",
      "Eval Loss:  0.3060464859008789\n",
      "Eval Loss:  0.4134303033351898\n",
      "Eval Loss:  0.25175273418426514\n",
      "Eval Loss:  0.33511191606521606\n",
      "[[18204   921]\n",
      " [ 3070  7264]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     19125\n",
      "           1       0.89      0.70      0.78     10334\n",
      "\n",
      "    accuracy                           0.86     29459\n",
      "   macro avg       0.87      0.83      0.84     29459\n",
      "weighted avg       0.87      0.86      0.86     29459\n",
      "\n",
      "acc:  0.8645235751383279\n",
      "pre:  0.887477092241906\n",
      "rec:  0.7029223921037352\n",
      "ma F1:  0.84285101460948\n",
      "mi F1:  0.8645235751383279\n",
      "we F1:  0.8602663235317015\n",
      "29459 461\n",
      "Loss:  0.0978647843003273\n",
      "Loss:  0.065819650888443\n",
      "Loss:  0.06699205935001373\n",
      "12 **********\n",
      "Epoch:  699.2373805046082  fold:  1  kers:  32\n",
      "epoch:  13\n",
      "29459 461\n",
      "Loss:  0.08730551600456238\n",
      "Loss:  0.07904152572154999\n",
      "Loss:  0.05974280834197998\n",
      "13 **********\n",
      "Epoch:  739.5715358257294  fold:  1  kers:  32\n",
      "epoch:  14\n",
      "29459 461\n",
      "Loss:  0.08464930951595306\n",
      "Loss:  0.08354929834604263\n",
      "Loss:  0.0887090414762497\n",
      "14 **********\n",
      "Epoch:  779.8308899402618  fold:  1  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.7334937453269958\n",
      "Eval Loss:  0.43784719705581665\n",
      "Eval Loss:  0.0722314715385437\n",
      "[[ 776  263]\n",
      " [ 452 1941]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.68      1039\n",
      "           1       0.88      0.81      0.84      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.76      0.78      0.76      3432\n",
      "weighted avg       0.81      0.79      0.80      3432\n",
      "\n",
      "acc:  0.7916666666666666\n",
      "pre:  0.8806715063520871\n",
      "rec:  0.8111157542833264\n",
      "ma F1:  0.7645344929217277\n",
      "mi F1:  0.7916666666666666\n",
      "we F1:  0.7960683669566182\n",
      "update!  Acc:  0.7916666666666666\n",
      "Eval Loss:  0.39678290486335754\n",
      "Eval Loss:  0.24759818613529205\n",
      "Eval Loss:  0.24698056280612946\n",
      "Eval Loss:  0.3922352194786072\n",
      "Eval Loss:  0.23614601790905\n",
      "Eval Loss:  0.3577168583869934\n",
      "Eval Loss:  0.3022969365119934\n",
      "Eval Loss:  0.2869614362716675\n",
      "Eval Loss:  0.218470960855484\n",
      "Eval Loss:  0.33414971828460693\n",
      "Eval Loss:  0.22684839367866516\n",
      "Eval Loss:  0.3200848400592804\n",
      "Eval Loss:  0.33273422718048096\n",
      "Eval Loss:  0.26278582215309143\n",
      "Eval Loss:  0.20257170498371124\n",
      "Eval Loss:  0.38677075505256653\n",
      "Eval Loss:  0.30055686831474304\n",
      "Eval Loss:  0.3146306574344635\n",
      "Eval Loss:  0.3723522126674652\n",
      "Eval Loss:  0.28335040807724\n",
      "Eval Loss:  0.3028481602668762\n",
      "Eval Loss:  0.3110799491405487\n",
      "Eval Loss:  0.2655172646045685\n",
      "Eval Loss:  0.2592698335647583\n",
      "Eval Loss:  0.26791563630104065\n",
      "Eval Loss:  0.3907807469367981\n",
      "Eval Loss:  0.26807019114494324\n",
      "Eval Loss:  0.2876746654510498\n",
      "[[17555  1570]\n",
      " [ 2076  8258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91     19125\n",
      "           1       0.84      0.80      0.82     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.87      0.86      0.86     29459\n",
      "weighted avg       0.88      0.88      0.88     29459\n",
      "\n",
      "acc:  0.8762347669642554\n",
      "pre:  0.8402523402523403\n",
      "rec:  0.7991097348558157\n",
      "ma F1:  0.8625445046941427\n",
      "mi F1:  0.8762347669642554\n",
      "we F1:  0.8754896585735188\n",
      "29459 461\n",
      "Loss:  0.06639079004526138\n",
      "Loss:  0.09706829488277435\n",
      "Loss:  0.04374225437641144\n",
      "15 **********\n",
      "Epoch:  858.8705542087555  fold:  1  kers:  32\n",
      "epoch:  16\n",
      "29459 461\n",
      "Loss:  0.08719205856323242\n",
      "Loss:  0.09469246864318848\n",
      "Loss:  0.08903417736291885\n",
      "16 **********\n",
      "Epoch:  899.190746307373  fold:  1  kers:  32\n",
      "epoch:  17\n",
      "29459 461\n",
      "Loss:  0.07449615746736526\n",
      "Loss:  0.0636005774140358\n",
      "Loss:  0.04833093285560608\n",
      "17 **********\n",
      "Epoch:  939.5019624233246  fold:  1  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.6562855839729309\n",
      "Eval Loss:  0.5604144930839539\n",
      "Eval Loss:  0.06699647009372711\n",
      "[[ 858  181]\n",
      " [ 646 1747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.83      0.67      1039\n",
      "           1       0.91      0.73      0.81      2393\n",
      "\n",
      "    accuracy                           0.76      3432\n",
      "   macro avg       0.74      0.78      0.74      3432\n",
      "weighted avg       0.80      0.76      0.77      3432\n",
      "\n",
      "acc:  0.759032634032634\n",
      "pre:  0.9061203319502075\n",
      "rec:  0.730045967404931\n",
      "ma F1:  0.7417013345918837\n",
      "mi F1:  0.759032634032634\n",
      "we F1:  0.7680979368897193\n",
      "Eval Loss:  0.38572099804878235\n",
      "Eval Loss:  0.28040188550949097\n",
      "Eval Loss:  0.22669419646263123\n",
      "Eval Loss:  0.3432855010032654\n",
      "Eval Loss:  0.26402777433395386\n",
      "Eval Loss:  0.35504040122032166\n",
      "Eval Loss:  0.2836631238460541\n",
      "Eval Loss:  0.2706586718559265\n",
      "Eval Loss:  0.23676170408725739\n",
      "Eval Loss:  0.3384554088115692\n",
      "Eval Loss:  0.22926443815231323\n",
      "Eval Loss:  0.32041680812835693\n",
      "Eval Loss:  0.35553815960884094\n",
      "Eval Loss:  0.3030705451965332\n",
      "Eval Loss:  0.16490191221237183\n",
      "Eval Loss:  0.4089619517326355\n",
      "Eval Loss:  0.292684942483902\n",
      "Eval Loss:  0.3380785584449768\n",
      "Eval Loss:  0.4071393609046936\n",
      "Eval Loss:  0.3181190490722656\n",
      "Eval Loss:  0.30501243472099304\n",
      "Eval Loss:  0.327732115983963\n",
      "Eval Loss:  0.2596401870250702\n",
      "Eval Loss:  0.2854999899864197\n",
      "Eval Loss:  0.29156947135925293\n",
      "Eval Loss:  0.37633273005485535\n",
      "Eval Loss:  0.26032912731170654\n",
      "Eval Loss:  0.31304657459259033\n",
      "[[18152   973]\n",
      " [ 2718  7616]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     19125\n",
      "           1       0.89      0.74      0.80     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.88      0.84      0.86     29459\n",
      "weighted avg       0.88      0.87      0.87     29459\n",
      "\n",
      "acc:  0.8747072202043518\n",
      "pre:  0.8867155664221679\n",
      "rec:  0.7369847106638281\n",
      "ma F1:  0.8563299128767992\n",
      "mi F1:  0.8747072202043518\n",
      "we F1:  0.8716635222842133\n",
      "29459 461\n",
      "Loss:  0.07770330458879471\n",
      "Loss:  0.06973502039909363\n",
      "Loss:  0.06719840317964554\n",
      "18 **********\n",
      "Epoch:  1018.1516687870026  fold:  1  kers:  32\n",
      "epoch:  19\n",
      "29459 461\n",
      "Loss:  0.09968976676464081\n",
      "Loss:  0.10379094630479813\n",
      "Loss:  0.07503139972686768\n",
      "19 **********\n",
      "Epoch:  1058.3711304664612  fold:  1  kers:  32\n",
      "epoch:  20\n",
      "29459 461\n",
      "Loss:  0.0728183314204216\n",
      "Loss:  0.06427475064992905\n",
      "Loss:  0.06505855172872543\n",
      "20 **********\n",
      "Epoch:  1098.6294875144958  fold:  1  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.7247226238250732\n",
      "Eval Loss:  0.6230175495147705\n",
      "Eval Loss:  0.0763159766793251\n",
      "[[ 861  178]\n",
      " [ 645 1748]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.83      0.68      1039\n",
      "           1       0.91      0.73      0.81      2393\n",
      "\n",
      "    accuracy                           0.76      3432\n",
      "   macro avg       0.74      0.78      0.74      3432\n",
      "weighted avg       0.81      0.76      0.77      3432\n",
      "\n",
      "acc:  0.7601981351981352\n",
      "pre:  0.9075804776739356\n",
      "rec:  0.7304638529043043\n",
      "ma F1:  0.7430337281559847\n",
      "mi F1:  0.7601981351981352\n",
      "we F1:  0.7692350890748931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.36767926812171936\n",
      "Eval Loss:  0.28821074962615967\n",
      "Eval Loss:  0.21910563111305237\n",
      "Eval Loss:  0.317564457654953\n",
      "Eval Loss:  0.2566879093647003\n",
      "Eval Loss:  0.34638068079948425\n",
      "Eval Loss:  0.27647092938423157\n",
      "Eval Loss:  0.2704722285270691\n",
      "Eval Loss:  0.23810738325119019\n",
      "Eval Loss:  0.3159959316253662\n",
      "Eval Loss:  0.23639345169067383\n",
      "Eval Loss:  0.3229014575481415\n",
      "Eval Loss:  0.32784751057624817\n",
      "Eval Loss:  0.2877843379974365\n",
      "Eval Loss:  0.16370433568954468\n",
      "Eval Loss:  0.3902096450328827\n",
      "Eval Loss:  0.2870916426181793\n",
      "Eval Loss:  0.3090827167034149\n",
      "Eval Loss:  0.3897625505924225\n",
      "Eval Loss:  0.31886374950408936\n",
      "Eval Loss:  0.28517967462539673\n",
      "Eval Loss:  0.3219735622406006\n",
      "Eval Loss:  0.25564083456993103\n",
      "Eval Loss:  0.26044079661369324\n",
      "Eval Loss:  0.2865397036075592\n",
      "Eval Loss:  0.3566872477531433\n",
      "Eval Loss:  0.247263103723526\n",
      "Eval Loss:  0.3098176121711731\n",
      "[[18198   927]\n",
      " [ 2589  7745]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     19125\n",
      "           1       0.89      0.75      0.82     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.88      0.85      0.86     29459\n",
      "weighted avg       0.88      0.88      0.88     29459\n",
      "\n",
      "acc:  0.8806476798261991\n",
      "pre:  0.8931042435424354\n",
      "rec:  0.7494677762724985\n",
      "ma F1:  0.8634559906359919\n",
      "mi F1:  0.8806476798261991\n",
      "we F1:  0.8779142456509266\n",
      "29459 461\n",
      "Loss:  0.06520354002714157\n",
      "Loss:  0.07012220472097397\n",
      "Loss:  0.11284789443016052\n",
      "21 **********\n",
      "Epoch:  1177.39488530159  fold:  1  kers:  32\n",
      "epoch:  22\n",
      "29459 461\n",
      "Loss:  0.0572294220328331\n",
      "Loss:  0.08856864273548126\n",
      "Loss:  0.052357785403728485\n",
      "22 **********\n",
      "Epoch:  1217.7170724868774  fold:  1  kers:  32\n",
      "epoch:  23\n",
      "29459 461\n",
      "Loss:  0.07294880598783493\n",
      "Loss:  0.06826718151569366\n",
      "Loss:  0.06903424859046936\n",
      "23 **********\n",
      "Epoch:  1258.9817385673523  fold:  1  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.6174415946006775\n",
      "Eval Loss:  0.6491972208023071\n",
      "Eval Loss:  0.08043338358402252\n",
      "[[ 895  144]\n",
      " [ 699 1694]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.86      0.68      1039\n",
      "           1       0.92      0.71      0.80      2393\n",
      "\n",
      "    accuracy                           0.75      3432\n",
      "   macro avg       0.74      0.78      0.74      3432\n",
      "weighted avg       0.81      0.75      0.76      3432\n",
      "\n",
      "acc:  0.7543706293706294\n",
      "pre:  0.9216539717083787\n",
      "rec:  0.7078980359381529\n",
      "ma F1:  0.7402946063108431\n",
      "mi F1:  0.7543706293706294\n",
      "we F1:  0.7641480921968888\n",
      "Eval Loss:  0.3850065767765045\n",
      "Eval Loss:  0.29345059394836426\n",
      "Eval Loss:  0.22247201204299927\n",
      "Eval Loss:  0.3074791133403778\n",
      "Eval Loss:  0.29130879044532776\n",
      "Eval Loss:  0.3719973564147949\n",
      "Eval Loss:  0.2942814826965332\n",
      "Eval Loss:  0.26780858635902405\n",
      "Eval Loss:  0.26374730467796326\n",
      "Eval Loss:  0.3442811369895935\n",
      "Eval Loss:  0.24463532865047455\n",
      "Eval Loss:  0.3334183692932129\n",
      "Eval Loss:  0.37561890482902527\n",
      "Eval Loss:  0.32512766122817993\n",
      "Eval Loss:  0.16449232399463654\n",
      "Eval Loss:  0.3961515724658966\n",
      "Eval Loss:  0.27892500162124634\n",
      "Eval Loss:  0.3494279384613037\n",
      "Eval Loss:  0.4086177349090576\n",
      "Eval Loss:  0.34377285838127136\n",
      "Eval Loss:  0.3080677390098572\n",
      "Eval Loss:  0.3357018530368805\n",
      "Eval Loss:  0.27125704288482666\n",
      "Eval Loss:  0.2822571396827698\n",
      "Eval Loss:  0.32683464884757996\n",
      "Eval Loss:  0.3573150634765625\n",
      "Eval Loss:  0.23912954330444336\n",
      "Eval Loss:  0.3346344530582428\n",
      "[[18452   673]\n",
      " [ 3066  7268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     19125\n",
      "           1       0.92      0.70      0.80     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.89      0.83      0.85     29459\n",
      "weighted avg       0.88      0.87      0.87     29459\n",
      "\n",
      "acc:  0.8730778369937879\n",
      "pre:  0.9152499685178189\n",
      "rec:  0.7033094639055545\n",
      "ma F1:  0.851703697535442\n",
      "mi F1:  0.8730778369937879\n",
      "we F1:  0.868504489736651\n",
      "29459 461\n",
      "Loss:  0.0702151358127594\n",
      "Loss:  0.0799880176782608\n",
      "Loss:  0.03940943628549576\n",
      "24 **********\n",
      "Epoch:  1341.9339413642883  fold:  1  kers:  32\n",
      "epoch:  25\n",
      "29459 461\n",
      "Loss:  0.059421539306640625\n",
      "Loss:  0.06819912791252136\n",
      "Loss:  0.05216849967837334\n",
      "25 **********\n",
      "Epoch:  1383.1158289909363  fold:  1  kers:  32\n",
      "epoch:  26\n",
      "29459 461\n",
      "Loss:  0.06284905970096588\n",
      "Loss:  0.07560427486896515\n",
      "Loss:  0.04079810902476311\n",
      "26 **********\n",
      "Epoch:  1424.993855714798  fold:  1  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  1.0963850021362305\n",
      "Eval Loss:  0.40561142563819885\n",
      "Eval Loss:  0.1070847362279892\n",
      "[[ 739  300]\n",
      " [ 394 1999]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68      1039\n",
      "           1       0.87      0.84      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.77      0.77      3432\n",
      "weighted avg       0.80      0.80      0.80      3432\n",
      "\n",
      "acc:  0.7977855477855478\n",
      "pre:  0.8695084819486734\n",
      "rec:  0.8353531132469704\n",
      "ma F1:  0.7662837414571882\n",
      "mi F1:  0.7977855477855478\n",
      "we F1:  0.8001356825433779\n",
      "update!  Acc:  0.7977855477855478\n",
      "Eval Loss:  0.32211408019065857\n",
      "Eval Loss:  0.25799432396888733\n",
      "Eval Loss:  0.211589053273201\n",
      "Eval Loss:  0.31029143929481506\n",
      "Eval Loss:  0.23765140771865845\n",
      "Eval Loss:  0.31449803709983826\n",
      "Eval Loss:  0.2556619942188263\n",
      "Eval Loss:  0.24716320633888245\n",
      "Eval Loss:  0.2227444052696228\n",
      "Eval Loss:  0.2748125493526459\n",
      "Eval Loss:  0.23262478411197662\n",
      "Eval Loss:  0.31340286135673523\n",
      "Eval Loss:  0.30090588331222534\n",
      "Eval Loss:  0.23054903745651245\n",
      "Eval Loss:  0.187626451253891\n",
      "Eval Loss:  0.3353612422943115\n",
      "Eval Loss:  0.2644076347351074\n",
      "Eval Loss:  0.2766970992088318\n",
      "Eval Loss:  0.3373606204986572\n",
      "Eval Loss:  0.26625528931617737\n",
      "Eval Loss:  0.24210329353809357\n",
      "Eval Loss:  0.2974735200405121\n",
      "Eval Loss:  0.2251550555229187\n",
      "Eval Loss:  0.21267330646514893\n",
      "Eval Loss:  0.26146626472473145\n",
      "Eval Loss:  0.33237913250923157\n",
      "Eval Loss:  0.26187360286712646\n",
      "Eval Loss:  0.2876299023628235\n",
      "[[17683  1442]\n",
      " [ 1837  8497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     19125\n",
      "           1       0.85      0.82      0.84     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.88      0.87      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.888692759428358\n",
      "pre:  0.8549149813864574\n",
      "rec:  0.8222372750145152\n",
      "ma F1:  0.8767042561492606\n",
      "mi F1:  0.888692759428358\n",
      "we F1:  0.8881772511771885\n",
      "29459 461\n",
      "Loss:  0.08538861572742462\n",
      "Loss:  0.07678121328353882\n",
      "Loss:  0.0823860615491867\n",
      "27 **********\n",
      "Epoch:  1503.279535293579  fold:  1  kers:  32\n",
      "epoch:  28\n",
      "29459 461\n",
      "Loss:  0.08282872289419174\n",
      "Loss:  0.09004979580640793\n",
      "Loss:  0.09647229313850403\n",
      "28 **********\n",
      "Epoch:  1543.4002630710602  fold:  1  kers:  32\n",
      "epoch:  29\n",
      "29459 461\n",
      "Loss:  0.06409358233213425\n",
      "Loss:  0.09416856616735458\n",
      "Loss:  0.07150287926197052\n",
      "29 **********\n",
      "Epoch:  1584.8813490867615  fold:  1  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.9284766912460327\n",
      "Eval Loss:  0.327991783618927\n",
      "Eval Loss:  0.08239046484231949\n",
      "[[ 735  304]\n",
      " [ 350 2043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69      1039\n",
      "           1       0.87      0.85      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.78      0.78      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8094405594405595\n",
      "pre:  0.8704729441840647\n",
      "rec:  0.8537400752193899\n",
      "ma F1:  0.7770578559679611\n",
      "mi F1:  0.8094405594405595\n",
      "we F1:  0.8105794006941829\n",
      "update!  Acc:  0.8094405594405595\n",
      "Eval Loss:  0.33734241127967834\n",
      "Eval Loss:  0.2553783059120178\n",
      "Eval Loss:  0.21491865813732147\n",
      "Eval Loss:  0.2872588038444519\n",
      "Eval Loss:  0.2241210639476776\n",
      "Eval Loss:  0.31149911880493164\n",
      "Eval Loss:  0.2514924108982086\n",
      "Eval Loss:  0.2260294109582901\n",
      "Eval Loss:  0.1968221366405487\n",
      "Eval Loss:  0.27566277980804443\n",
      "Eval Loss:  0.21423286199569702\n",
      "Eval Loss:  0.3086164593696594\n",
      "Eval Loss:  0.2881484925746918\n",
      "Eval Loss:  0.22518357634544373\n",
      "Eval Loss:  0.18367040157318115\n",
      "Eval Loss:  0.3460421562194824\n",
      "Eval Loss:  0.2578206956386566\n",
      "Eval Loss:  0.2740188539028168\n",
      "Eval Loss:  0.32710322737693787\n",
      "Eval Loss:  0.2721017599105835\n",
      "Eval Loss:  0.24234554171562195\n",
      "Eval Loss:  0.30212974548339844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22220510244369507\n",
      "Eval Loss:  0.20051182806491852\n",
      "Eval Loss:  0.2532286047935486\n",
      "Eval Loss:  0.3462589383125305\n",
      "Eval Loss:  0.2520201802253723\n",
      "Eval Loss:  0.2878022789955139\n",
      "[[17738  1387]\n",
      " [ 1786  8548]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     19125\n",
      "           1       0.86      0.83      0.84     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.88      0.88      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8922909806850199\n",
      "pre:  0.8603925515853045\n",
      "rec:  0.8271724404877104\n",
      "ma F1:  0.8806788340791618\n",
      "mi F1:  0.8922909806850198\n",
      "we F1:  0.8917868189335795\n",
      "29459 461\n",
      "Loss:  0.049963176250457764\n",
      "Loss:  0.05502123013138771\n",
      "Loss:  0.08349441736936569\n",
      "30 **********\n",
      "Epoch:  1665.2923464775085  fold:  1  kers:  32\n",
      "epoch:  31\n",
      "29459 461\n",
      "Loss:  0.06673333048820496\n",
      "Loss:  0.08560891449451447\n",
      "Loss:  0.0820816159248352\n",
      "31 **********\n",
      "Epoch:  1706.16406583786  fold:  1  kers:  32\n",
      "epoch:  32\n",
      "29459 461\n",
      "Loss:  0.07112425565719604\n",
      "Loss:  0.0771988108754158\n",
      "Loss:  0.03565054014325142\n",
      "32 **********\n",
      "Epoch:  1746.2518768310547  fold:  1  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  1.4350087642669678\n",
      "Eval Loss:  0.3167881369590759\n",
      "Eval Loss:  0.08563224971294403\n",
      "[[ 691  348]\n",
      " [ 324 2069]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67      1039\n",
      "           1       0.86      0.86      0.86      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.77      0.76      0.77      3432\n",
      "weighted avg       0.80      0.80      0.80      3432\n",
      "\n",
      "acc:  0.8041958041958042\n",
      "pre:  0.8560198593297477\n",
      "rec:  0.8646050982030924\n",
      "ma F1:  0.766562277954683\n",
      "mi F1:  0.8041958041958042\n",
      "we F1:  0.80354035816548\n",
      "Eval Loss:  0.32099273800849915\n",
      "Eval Loss:  0.2756008207798004\n",
      "Eval Loss:  0.22395281493663788\n",
      "Eval Loss:  0.2767099142074585\n",
      "Eval Loss:  0.21563036739826202\n",
      "Eval Loss:  0.3069213628768921\n",
      "Eval Loss:  0.2556326985359192\n",
      "Eval Loss:  0.23852187395095825\n",
      "Eval Loss:  0.19401006400585175\n",
      "Eval Loss:  0.28401708602905273\n",
      "Eval Loss:  0.21528001129627228\n",
      "Eval Loss:  0.30468815565109253\n",
      "Eval Loss:  0.28840094804763794\n",
      "Eval Loss:  0.20489512383937836\n",
      "Eval Loss:  0.18408694863319397\n",
      "Eval Loss:  0.3329208791255951\n",
      "Eval Loss:  0.25398972630500793\n",
      "Eval Loss:  0.2711150348186493\n",
      "Eval Loss:  0.32115498185157776\n",
      "Eval Loss:  0.2690342664718628\n",
      "Eval Loss:  0.24026936292648315\n",
      "Eval Loss:  0.2881290316581726\n",
      "Eval Loss:  0.22363968193531036\n",
      "Eval Loss:  0.21314242482185364\n",
      "Eval Loss:  0.2460407316684723\n",
      "Eval Loss:  0.33245959877967834\n",
      "Eval Loss:  0.25607040524482727\n",
      "Eval Loss:  0.2839525640010834\n",
      "[[17545  1580]\n",
      " [ 1556  8778]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     19125\n",
      "           1       0.85      0.85      0.85     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.88      0.88      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8935469635764961\n",
      "pre:  0.8474608997876037\n",
      "rec:  0.8494290690923166\n",
      "ma F1:  0.8832027199250212\n",
      "mi F1:  0.8935469635764961\n",
      "we F1:  0.8935752813417107\n",
      "29459 461\n",
      "Loss:  0.06522336602210999\n",
      "Loss:  0.0678214281797409\n",
      "Loss:  0.05051956698298454\n",
      "33 **********\n",
      "Epoch:  1824.188490152359  fold:  1  kers:  32\n",
      "epoch:  34\n",
      "29459 461\n",
      "Loss:  0.07166089117527008\n",
      "Loss:  0.07491801679134369\n",
      "Loss:  0.05997060611844063\n",
      "34 **********\n",
      "Epoch:  1864.2483780384064  fold:  1  kers:  32\n",
      "epoch:  35\n",
      "29459 461\n",
      "Loss:  0.09130828082561493\n",
      "Loss:  0.06861453503370285\n",
      "Loss:  0.06836682558059692\n",
      "35 **********\n",
      "Epoch:  1904.2135195732117  fold:  1  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  1.3057658672332764\n",
      "Eval Loss:  0.3086533844470978\n",
      "Eval Loss:  0.07489272207021713\n",
      "[[ 702  337]\n",
      " [ 346 2047]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67      1039\n",
      "           1       0.86      0.86      0.86      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.77      0.76      3432\n",
      "weighted avg       0.80      0.80      0.80      3432\n",
      "\n",
      "acc:  0.800990675990676\n",
      "pre:  0.8586409395973155\n",
      "rec:  0.8554116172168825\n",
      "ma F1:  0.7648796105038929\n",
      "mi F1:  0.8009906759906759\n",
      "we F1:  0.8012323113731155\n",
      "Eval Loss:  0.3242252469062805\n",
      "Eval Loss:  0.25671130418777466\n",
      "Eval Loss:  0.2037801444530487\n",
      "Eval Loss:  0.2684040069580078\n",
      "Eval Loss:  0.2183464914560318\n",
      "Eval Loss:  0.2969340980052948\n",
      "Eval Loss:  0.24769948422908783\n",
      "Eval Loss:  0.23956826329231262\n",
      "Eval Loss:  0.1823638528585434\n",
      "Eval Loss:  0.2835392653942108\n",
      "Eval Loss:  0.21195974946022034\n",
      "Eval Loss:  0.29953107237815857\n",
      "Eval Loss:  0.29752933979034424\n",
      "Eval Loss:  0.2073572874069214\n",
      "Eval Loss:  0.15969689190387726\n",
      "Eval Loss:  0.357465922832489\n",
      "Eval Loss:  0.23337969183921814\n",
      "Eval Loss:  0.2695275545120239\n",
      "Eval Loss:  0.31217509508132935\n",
      "Eval Loss:  0.2539462447166443\n",
      "Eval Loss:  0.2352437973022461\n",
      "Eval Loss:  0.2928624451160431\n",
      "Eval Loss:  0.23109710216522217\n",
      "Eval Loss:  0.19766727089881897\n",
      "Eval Loss:  0.2490602284669876\n",
      "Eval Loss:  0.3229764401912689\n",
      "Eval Loss:  0.24598470330238342\n",
      "Eval Loss:  0.26783645153045654\n",
      "[[17866  1259]\n",
      " [ 1782  8552]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     19125\n",
      "           1       0.87      0.83      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.89      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.8967717845140704\n",
      "pre:  0.8716746509020488\n",
      "rec:  0.8275595122895297\n",
      "ma F1:  0.8853067805287071\n",
      "mi F1:  0.8967717845140704\n",
      "we F1:  0.8961280012754678\n",
      "29459 461\n",
      "Loss:  0.09755758196115494\n",
      "Loss:  0.06503019481897354\n",
      "Loss:  0.050629276782274246\n",
      "36 **********\n",
      "Epoch:  1982.2289221286774  fold:  1  kers:  32\n",
      "epoch:  37\n",
      "29459 461\n",
      "Loss:  0.0438557043671608\n",
      "Loss:  0.051716674119234085\n",
      "Loss:  0.03878241777420044\n",
      "37 **********\n",
      "Epoch:  2022.2798342704773  fold:  1  kers:  32\n",
      "epoch:  38\n",
      "29459 461\n",
      "Loss:  0.04802907630801201\n",
      "Loss:  0.049728892743587494\n",
      "Loss:  0.10441141575574875\n",
      "38 **********\n",
      "Epoch:  2062.2499623298645  fold:  1  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  1.4260153770446777\n",
      "Eval Loss:  0.2711552381515503\n",
      "Eval Loss:  0.0687350183725357\n",
      "[[ 564  475]\n",
      " [ 252 2141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.54      0.61      1039\n",
      "           1       0.82      0.89      0.85      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.75      0.72      0.73      3432\n",
      "weighted avg       0.78      0.79      0.78      3432\n",
      "\n",
      "acc:  0.7881701631701632\n",
      "pre:  0.8184250764525994\n",
      "rec:  0.8946928541579607\n",
      "ma F1:  0.7314737515598608\n",
      "mi F1:  0.7881701631701632\n",
      "we F1:  0.780152851953234\n",
      "Eval Loss:  0.3264721930027008\n",
      "Eval Loss:  0.26888611912727356\n",
      "Eval Loss:  0.2178504914045334\n",
      "Eval Loss:  0.30175888538360596\n",
      "Eval Loss:  0.22479230165481567\n",
      "Eval Loss:  0.3089515268802643\n",
      "Eval Loss:  0.2674630880355835\n",
      "Eval Loss:  0.2562035620212555\n",
      "Eval Loss:  0.19276848435401917\n",
      "Eval Loss:  0.28404396772384644\n",
      "Eval Loss:  0.2261323630809784\n",
      "Eval Loss:  0.3161073327064514\n",
      "Eval Loss:  0.3065060079097748\n",
      "Eval Loss:  0.2005845159292221\n",
      "Eval Loss:  0.2128598541021347\n",
      "Eval Loss:  0.35460466146469116\n",
      "Eval Loss:  0.2593916356563568\n",
      "Eval Loss:  0.2917209267616272\n",
      "Eval Loss:  0.31156066060066223\n",
      "Eval Loss:  0.26447194814682007\n",
      "Eval Loss:  0.28643301129341125\n",
      "Eval Loss:  0.31105098128318787\n",
      "Eval Loss:  0.2489977329969406\n",
      "Eval Loss:  0.21051307022571564\n",
      "Eval Loss:  0.2498844414949417\n",
      "Eval Loss:  0.3555721044540405\n",
      "Eval Loss:  0.2787148952484131\n",
      "Eval Loss:  0.2722278833389282\n",
      "[[17223  1902]\n",
      " [ 1349  8985]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91     19125\n",
      "           1       0.83      0.87      0.85     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.88      0.89      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8896432329678536\n",
      "pre:  0.825296224855332\n",
      "rec:  0.8694600348364622\n",
      "ma F1:  0.8802812055352156\n",
      "mi F1:  0.8896432329678536\n",
      "we F1:  0.8902716866180417\n",
      "29459 461\n",
      "Loss:  0.05229755491018295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06735371053218842\n",
      "Loss:  0.07021297514438629\n",
      "39 **********\n",
      "Epoch:  2141.290623188019  fold:  1  kers:  32\n",
      "epoch:  40\n",
      "29459 461\n",
      "Loss:  0.08471467345952988\n",
      "Loss:  0.08128940314054489\n",
      "Loss:  0.07916563749313354\n",
      "40 **********\n",
      "Epoch:  2181.1261115074158  fold:  1  kers:  32\n",
      "epoch:  41\n",
      "29459 461\n",
      "Loss:  0.07231704890727997\n",
      "Loss:  0.08289316296577454\n",
      "Loss:  0.051704294979572296\n",
      "41 **********\n",
      "Epoch:  2220.9745650291443  fold:  1  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  1.4156230688095093\n",
      "Eval Loss:  0.2680659890174866\n",
      "Eval Loss:  0.10176968574523926\n",
      "[[ 638  401]\n",
      " [ 257 2136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66      1039\n",
      "           1       0.84      0.89      0.87      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.75      0.76      3432\n",
      "weighted avg       0.80      0.81      0.80      3432\n",
      "\n",
      "acc:  0.8082750582750583\n",
      "pre:  0.841939298383918\n",
      "rec:  0.8926034266610948\n",
      "ma F1:  0.7631519662031627\n",
      "mi F1:  0.8082750582750583\n",
      "we F1:  0.8039374579690817\n",
      "Eval Loss:  0.31676676869392395\n",
      "Eval Loss:  0.28194931149482727\n",
      "Eval Loss:  0.2147025316953659\n",
      "Eval Loss:  0.26469483971595764\n",
      "Eval Loss:  0.23610423505306244\n",
      "Eval Loss:  0.303448885679245\n",
      "Eval Loss:  0.2711615264415741\n",
      "Eval Loss:  0.2290574610233307\n",
      "Eval Loss:  0.19777101278305054\n",
      "Eval Loss:  0.2663654386997223\n",
      "Eval Loss:  0.22505153715610504\n",
      "Eval Loss:  0.31017088890075684\n",
      "Eval Loss:  0.29268568754196167\n",
      "Eval Loss:  0.202286496758461\n",
      "Eval Loss:  0.1810830980539322\n",
      "Eval Loss:  0.33880919218063354\n",
      "Eval Loss:  0.24283331632614136\n",
      "Eval Loss:  0.26701855659484863\n",
      "Eval Loss:  0.30168312788009644\n",
      "Eval Loss:  0.246967613697052\n",
      "Eval Loss:  0.23729990422725677\n",
      "Eval Loss:  0.29768839478492737\n",
      "Eval Loss:  0.2404797524213791\n",
      "Eval Loss:  0.1933436393737793\n",
      "Eval Loss:  0.23263685405254364\n",
      "Eval Loss:  0.3230254054069519\n",
      "Eval Loss:  0.26738089323043823\n",
      "Eval Loss:  0.2743649184703827\n",
      "[[17512  1613]\n",
      " [ 1454  8880]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     19125\n",
      "           1       0.85      0.86      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.88      0.89      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.8958892019416816\n",
      "pre:  0.8462784713618603\n",
      "rec:  0.8592994000387072\n",
      "ma F1:  0.8861107625658895\n",
      "mi F1:  0.8958892019416818\n",
      "we F1:  0.8960693191637333\n",
      "29459 461\n",
      "Loss:  0.04880985617637634\n",
      "Loss:  0.062316544353961945\n",
      "Loss:  0.054865725338459015\n",
      "42 **********\n",
      "Epoch:  2298.882255554199  fold:  1  kers:  32\n",
      "epoch:  43\n",
      "29459 461\n",
      "Loss:  0.05327482894062996\n",
      "Loss:  0.07974380254745483\n",
      "Loss:  0.08595865964889526\n",
      "43 **********\n",
      "Epoch:  2338.8424105644226  fold:  1  kers:  32\n",
      "epoch:  44\n",
      "29459 461\n",
      "Loss:  0.09525537490844727\n",
      "Loss:  0.079649418592453\n",
      "Loss:  0.04749497026205063\n",
      "44 **********\n",
      "Epoch:  2378.8394660949707  fold:  1  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  1.3879191875457764\n",
      "Eval Loss:  0.2922762930393219\n",
      "Eval Loss:  0.1286994218826294\n",
      "[[ 683  356]\n",
      " [ 264 2129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69      1039\n",
      "           1       0.86      0.89      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.77      0.78      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8193473193473193\n",
      "pre:  0.8567404426559356\n",
      "rec:  0.8896782281654827\n",
      "ma F1:  0.7803567159538665\n",
      "mi F1:  0.8193473193473193\n",
      "we F1:  0.816866589394209\n",
      "update!  Acc:  0.8193473193473193\n",
      "Eval Loss:  0.30672866106033325\n",
      "Eval Loss:  0.28202754259109497\n",
      "Eval Loss:  0.21669098734855652\n",
      "Eval Loss:  0.2599314749240875\n",
      "Eval Loss:  0.22571992874145508\n",
      "Eval Loss:  0.29482319951057434\n",
      "Eval Loss:  0.27002838253974915\n",
      "Eval Loss:  0.20947758853435516\n",
      "Eval Loss:  0.20455114543437958\n",
      "Eval Loss:  0.2604444622993469\n",
      "Eval Loss:  0.23613683879375458\n",
      "Eval Loss:  0.2973417341709137\n",
      "Eval Loss:  0.2881133556365967\n",
      "Eval Loss:  0.2037171870470047\n",
      "Eval Loss:  0.17295783758163452\n",
      "Eval Loss:  0.2962774634361267\n",
      "Eval Loss:  0.22322970628738403\n",
      "Eval Loss:  0.2586178183555603\n",
      "Eval Loss:  0.30140620470046997\n",
      "Eval Loss:  0.24011453986167908\n",
      "Eval Loss:  0.21613633632659912\n",
      "Eval Loss:  0.27125799655914307\n",
      "Eval Loss:  0.2215728461742401\n",
      "Eval Loss:  0.19787460565567017\n",
      "Eval Loss:  0.21772617101669312\n",
      "Eval Loss:  0.3104354441165924\n",
      "Eval Loss:  0.22840894758701324\n",
      "Eval Loss:  0.26742029190063477\n",
      "[[17687  1438]\n",
      " [ 1473  8861]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     19125\n",
      "           1       0.86      0.86      0.86     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.89      0.89      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9011846973760141\n",
      "pre:  0.8603747936692883\n",
      "rec:  0.8574608089800658\n",
      "ma F1:  0.8914401645792349\n",
      "mi F1:  0.9011846973760141\n",
      "we F1:  0.9011460548824852\n",
      "29459 461\n",
      "Loss:  0.05671152099967003\n",
      "Loss:  0.09061299264431\n",
      "Loss:  0.0834437906742096\n",
      "45 **********\n",
      "Epoch:  2456.9206924438477  fold:  1  kers:  32\n",
      "epoch:  46\n",
      "29459 461\n",
      "Loss:  0.09019973129034042\n",
      "Loss:  0.06216531991958618\n",
      "Loss:  0.054188672453165054\n",
      "46 **********\n",
      "Epoch:  2496.883840084076  fold:  1  kers:  32\n",
      "epoch:  47\n",
      "29459 461\n",
      "Loss:  0.07094952464103699\n",
      "Loss:  0.0586576908826828\n",
      "Loss:  0.07167810201644897\n",
      "47 **********\n",
      "Epoch:  2536.939738035202  fold:  1  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  1.4484022855758667\n",
      "Eval Loss:  0.26148074865341187\n",
      "Eval Loss:  0.11528053134679794\n",
      "[[ 632  407]\n",
      " [ 242 2151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.61      0.66      1039\n",
      "           1       0.84      0.90      0.87      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.75      0.76      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8108974358974359\n",
      "pre:  0.8408913213448006\n",
      "rec:  0.8988717091516925\n",
      "ma F1:  0.7648288301148432\n",
      "mi F1:  0.8108974358974358\n",
      "we F1:  0.8058932752956401\n",
      "Eval Loss:  0.2882842421531677\n",
      "Eval Loss:  0.2880989909172058\n",
      "Eval Loss:  0.2087251842021942\n",
      "Eval Loss:  0.2782048285007477\n",
      "Eval Loss:  0.21298375725746155\n",
      "Eval Loss:  0.29048952460289\n",
      "Eval Loss:  0.2651238739490509\n",
      "Eval Loss:  0.2257942259311676\n",
      "Eval Loss:  0.18653541803359985\n",
      "Eval Loss:  0.2506919205188751\n",
      "Eval Loss:  0.23373445868492126\n",
      "Eval Loss:  0.3141123354434967\n",
      "Eval Loss:  0.3035854697227478\n",
      "Eval Loss:  0.19065330922603607\n",
      "Eval Loss:  0.17581245303153992\n",
      "Eval Loss:  0.3260870575904846\n",
      "Eval Loss:  0.21982170641422272\n",
      "Eval Loss:  0.2660333812236786\n",
      "Eval Loss:  0.30202582478523254\n",
      "Eval Loss:  0.2259903848171234\n",
      "Eval Loss:  0.23143355548381805\n",
      "Eval Loss:  0.2805829644203186\n",
      "Eval Loss:  0.23658882081508636\n",
      "Eval Loss:  0.19218255579471588\n",
      "Eval Loss:  0.23177511990070343\n",
      "Eval Loss:  0.3204231560230255\n",
      "Eval Loss:  0.24450209736824036\n",
      "Eval Loss:  0.252301961183548\n",
      "[[17526  1599]\n",
      " [ 1390  8944]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     19125\n",
      "           1       0.85      0.87      0.86     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.89      0.89      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.8985369496588479\n",
      "pre:  0.8483353884093712\n",
      "rec:  0.865492548867815\n",
      "ma F1:  0.8891274849247173\n",
      "mi F1:  0.898536949658848\n",
      "we F1:  0.8987661011537714\n",
      "29459 461\n",
      "Loss:  0.06470127403736115\n",
      "Loss:  0.04443485289812088\n",
      "Loss:  0.03678674250841141\n",
      "48 **********\n",
      "Epoch:  2615.0439038276672  fold:  1  kers:  32\n",
      "epoch:  49\n",
      "29459 461\n",
      "Loss:  0.07895679026842117\n",
      "Loss:  0.042532023042440414\n",
      "Loss:  0.06307642161846161\n",
      "49 **********\n",
      "Epoch:  2655.1167571544647  fold:  1  kers:  32\n",
      "epoch:  50\n",
      "29459 461\n",
      "Loss:  0.05303865671157837\n",
      "Loss:  0.08566401153802872\n",
      "Loss:  0.07768188416957855\n",
      "50 **********\n",
      "Epoch:  2695.227509021759  fold:  1  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  1.4080065488815308\n",
      "Eval Loss:  0.27610844373703003\n",
      "Eval Loss:  0.08644307404756546\n",
      "[[ 633  406]\n",
      " [ 241 2152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.61      0.66      1039\n",
      "           1       0.84      0.90      0.87      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.75      0.77      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8114801864801865\n",
      "pre:  0.8412822517591869\n",
      "rec:  0.8992895946510656\n",
      "ma F1:  0.7655535486661071\n",
      "mi F1:  0.8114801864801866\n",
      "we F1:  0.8064914470204609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3070710599422455\n",
      "Eval Loss:  0.28011780977249146\n",
      "Eval Loss:  0.21780388057231903\n",
      "Eval Loss:  0.2592089772224426\n",
      "Eval Loss:  0.20653273165225983\n",
      "Eval Loss:  0.29598963260650635\n",
      "Eval Loss:  0.2592410147190094\n",
      "Eval Loss:  0.22901056706905365\n",
      "Eval Loss:  0.18969307839870453\n",
      "Eval Loss:  0.27210673689842224\n",
      "Eval Loss:  0.22885288298130035\n",
      "Eval Loss:  0.2985284924507141\n",
      "Eval Loss:  0.29649221897125244\n",
      "Eval Loss:  0.18520419299602509\n",
      "Eval Loss:  0.1735050231218338\n",
      "Eval Loss:  0.3131623864173889\n",
      "Eval Loss:  0.21913544833660126\n",
      "Eval Loss:  0.2602398693561554\n",
      "Eval Loss:  0.29879507422447205\n",
      "Eval Loss:  0.2254631668329239\n",
      "Eval Loss:  0.2391098290681839\n",
      "Eval Loss:  0.2828913927078247\n",
      "Eval Loss:  0.23098638653755188\n",
      "Eval Loss:  0.19339615106582642\n",
      "Eval Loss:  0.21917738020420074\n",
      "Eval Loss:  0.3130594789981842\n",
      "Eval Loss:  0.24735750257968903\n",
      "Eval Loss:  0.25837603211402893\n",
      "[[17427  1698]\n",
      " [ 1253  9081]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     19125\n",
      "           1       0.84      0.88      0.86     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.89      0.89      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.8998268780338776\n",
      "pre:  0.8424714723072642\n",
      "rec:  0.8787497580801239\n",
      "ma F1:  0.891084918743552\n",
      "mi F1:  0.8998268780338776\n",
      "we F1:  0.9002929901695348\n",
      "29459 461\n",
      "Loss:  0.05881704390048981\n",
      "Loss:  0.0671389251947403\n",
      "Loss:  0.07541967928409576\n",
      "51 **********\n",
      "Epoch:  2773.210997104645  fold:  1  kers:  32\n",
      "epoch:  52\n",
      "29459 461\n",
      "Loss:  0.08161809295415878\n",
      "Loss:  0.03851896896958351\n",
      "Loss:  0.06663504987955093\n",
      "52 **********\n",
      "Epoch:  2813.225007534027  fold:  1  kers:  32\n",
      "epoch:  53\n",
      "29459 461\n",
      "Loss:  0.07636700570583344\n",
      "Loss:  0.09003662317991257\n",
      "Loss:  0.07819380611181259\n",
      "53 **********\n",
      "Epoch:  2853.408565044403  fold:  1  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  1.336409330368042\n",
      "Eval Loss:  0.29262810945510864\n",
      "Eval Loss:  0.089792899787426\n",
      "[[ 600  439]\n",
      " [ 267 2126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63      1039\n",
      "           1       0.83      0.89      0.86      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.76      0.73      0.74      3432\n",
      "weighted avg       0.79      0.79      0.79      3432\n",
      "\n",
      "acc:  0.7942890442890443\n",
      "pre:  0.8288499025341131\n",
      "rec:  0.8884245716673631\n",
      "ma F1:  0.7435973192656722\n",
      "mi F1:  0.7942890442890443\n",
      "we F1:  0.7885754291487953\n",
      "Eval Loss:  0.272955983877182\n",
      "Eval Loss:  0.27734196186065674\n",
      "Eval Loss:  0.21500757336616516\n",
      "Eval Loss:  0.25450772047042847\n",
      "Eval Loss:  0.20183901488780975\n",
      "Eval Loss:  0.2904665470123291\n",
      "Eval Loss:  0.2558450698852539\n",
      "Eval Loss:  0.23019647598266602\n",
      "Eval Loss:  0.1858355551958084\n",
      "Eval Loss:  0.2718093991279602\n",
      "Eval Loss:  0.22569583356380463\n",
      "Eval Loss:  0.2905004918575287\n",
      "Eval Loss:  0.28767573833465576\n",
      "Eval Loss:  0.18255797028541565\n",
      "Eval Loss:  0.15655803680419922\n",
      "Eval Loss:  0.32301825284957886\n",
      "Eval Loss:  0.21611985564231873\n",
      "Eval Loss:  0.2742486894130707\n",
      "Eval Loss:  0.28703781962394714\n",
      "Eval Loss:  0.20095577836036682\n",
      "Eval Loss:  0.24790126085281372\n",
      "Eval Loss:  0.28302985429763794\n",
      "Eval Loss:  0.24634872376918793\n",
      "Eval Loss:  0.191812202334404\n",
      "Eval Loss:  0.22860394418239594\n",
      "Eval Loss:  0.3068104088306427\n",
      "Eval Loss:  0.24945566058158875\n",
      "Eval Loss:  0.24125666916370392\n",
      "[[17394  1731]\n",
      " [ 1200  9134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92     19125\n",
      "           1       0.84      0.88      0.86     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.89      0.90      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9005057877049458\n",
      "pre:  0.8406810860561436\n",
      "rec:  0.8838784594542287\n",
      "ma F1:  0.8920162827229458\n",
      "mi F1:  0.9005057877049458\n",
      "we F1:  0.9010515415966458\n",
      "29459 461\n",
      "Loss:  0.0812709853053093\n",
      "Loss:  0.061723146587610245\n",
      "Loss:  0.06545330584049225\n",
      "54 **********\n",
      "Epoch:  2931.3312158584595  fold:  1  kers:  32\n",
      "epoch:  55\n",
      "29459 461\n",
      "Loss:  0.07436122745275497\n",
      "Loss:  0.07757420837879181\n",
      "Loss:  0.0691264346241951\n",
      "55 **********\n",
      "Epoch:  2971.5307314395905  fold:  1  kers:  32\n",
      "epoch:  56\n",
      "29459 461\n",
      "Loss:  0.09373040497303009\n",
      "Loss:  0.07984312623739243\n",
      "Loss:  0.07629001885652542\n",
      "56 **********\n",
      "Epoch:  3011.7432103157043  fold:  1  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  1.1793149709701538\n",
      "Eval Loss:  0.303216814994812\n",
      "Eval Loss:  0.10741200298070908\n",
      "[[ 703  336]\n",
      " [ 331 2062]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68      1039\n",
      "           1       0.86      0.86      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.77      0.77      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8056526806526807\n",
      "pre:  0.859883236030025\n",
      "rec:  0.8616798997074802\n",
      "ma F1:  0.7695123605191959\n",
      "mi F1:  0.8056526806526807\n",
      "we F1:  0.8055197140591064\n",
      "Eval Loss:  0.30806946754455566\n",
      "Eval Loss:  0.2762709856033325\n",
      "Eval Loss:  0.20773252844810486\n",
      "Eval Loss:  0.22161966562271118\n",
      "Eval Loss:  0.21005338430404663\n",
      "Eval Loss:  0.2856541574001312\n",
      "Eval Loss:  0.24022381007671356\n",
      "Eval Loss:  0.20319893956184387\n",
      "Eval Loss:  0.19230900704860687\n",
      "Eval Loss:  0.26690763235092163\n",
      "Eval Loss:  0.23385804891586304\n",
      "Eval Loss:  0.2681899070739746\n",
      "Eval Loss:  0.29628658294677734\n",
      "Eval Loss:  0.1900148093700409\n",
      "Eval Loss:  0.13310328125953674\n",
      "Eval Loss:  0.34816455841064453\n",
      "Eval Loss:  0.18732613325119019\n",
      "Eval Loss:  0.2742622494697571\n",
      "Eval Loss:  0.2981319725513458\n",
      "Eval Loss:  0.2018744796514511\n",
      "Eval Loss:  0.220154270529747\n",
      "Eval Loss:  0.2738264799118042\n",
      "Eval Loss:  0.23861894011497498\n",
      "Eval Loss:  0.18004187941551208\n",
      "Eval Loss:  0.21758833527565002\n",
      "Eval Loss:  0.28866490721702576\n",
      "Eval Loss:  0.23474791646003723\n",
      "Eval Loss:  0.23337200284004211\n",
      "[[18021  1104]\n",
      " [ 1635  8699]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     19125\n",
      "           1       0.89      0.84      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.89      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9070233205472011\n",
      "pre:  0.8873814138529021\n",
      "rec:  0.8417844010063867\n",
      "ma F1:  0.896677178055008\n",
      "mi F1:  0.9070233205472011\n",
      "we F1:  0.9064339833166333\n",
      "29459 461\n",
      "Loss:  0.053032778203487396\n",
      "Loss:  0.06273818016052246\n",
      "Loss:  0.06236576661467552\n",
      "57 **********\n",
      "Epoch:  3089.9092106819153  fold:  1  kers:  32\n",
      "epoch:  58\n",
      "29459 461\n",
      "Loss:  0.08080977201461792\n",
      "Loss:  0.12102554738521576\n",
      "Loss:  0.07318048924207687\n",
      "58 **********\n",
      "Epoch:  3130.034922361374  fold:  1  kers:  32\n",
      "epoch:  59\n",
      "29459 461\n",
      "Loss:  0.08798165619373322\n",
      "Loss:  0.05476629361510277\n",
      "Loss:  0.0667414665222168\n",
      "59 **********\n",
      "Epoch:  3170.097802400589  fold:  1  kers:  32\n",
      "Eval Loss:  1.4933274984359741\n",
      "Eval Loss:  0.275330126285553\n",
      "Eval Loss:  0.07331671565771103\n",
      "[[ 650  389]\n",
      " [ 246 2147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.67      1039\n",
      "           1       0.85      0.90      0.87      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.79      0.76      0.77      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8149766899766899\n",
      "pre:  0.8466088328075709\n",
      "rec:  0.8972001671541997\n",
      "ma F1:  0.771502624083694\n",
      "mi F1:  0.8149766899766899\n",
      "we F1:  0.8108238566949942\n",
      "update!  Acc:  0.8193473193473193\n",
      "Epoch:  3174.0582132339478  fold:  1  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29797 3094\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29797 466\n",
      "Loss:  0.1690984070301056\n",
      "Loss:  0.16431060433387756\n",
      "Loss:  0.15625819563865662\n",
      "0 **********\n",
      "Epoch:  52.95042133331299  fold:  2  kers:  32\n",
      "epoch:  1\n",
      "29797 466\n",
      "Loss:  0.13672767579555511\n",
      "Loss:  0.14572565257549286\n",
      "Loss:  0.11728215962648392\n",
      "1 **********\n",
      "Epoch:  93.61967968940735  fold:  2  kers:  32\n",
      "epoch:  2\n",
      "29797 466\n",
      "Loss:  0.11041399836540222\n",
      "Loss:  0.10108497738838196\n",
      "Loss:  0.09581494331359863\n",
      "2 **********\n",
      "Epoch:  134.12437868118286  fold:  2  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.7582769989967346\n",
      "Eval Loss:  0.19716675579547882\n",
      "Eval Loss:  0.7391063570976257\n",
      "[[1108  322]\n",
      " [ 551 1113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.72      1430\n",
      "           1       0.78      0.67      0.72      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.72      0.72      0.72      3094\n",
      "weighted avg       0.73      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7178409825468649\n",
      "pre:  0.775609756097561\n",
      "rec:  0.6688701923076923\n",
      "ma F1:  0.7178402456707857\n",
      "mi F1:  0.7178409825468649\n",
      "we F1:  0.7178747314712909\n",
      "update!  Acc:  0.7178409825468649\n",
      "Eval Loss:  0.43548011779785156\n",
      "Eval Loss:  0.4323589503765106\n",
      "Eval Loss:  0.34627094864845276\n",
      "Eval Loss:  0.3108299672603607\n",
      "Eval Loss:  0.38218140602111816\n",
      "Eval Loss:  0.36924654245376587\n",
      "Eval Loss:  0.42482060194015503\n",
      "Eval Loss:  0.37811046838760376\n",
      "Eval Loss:  0.4204155504703522\n",
      "Eval Loss:  0.331833153963089\n",
      "Eval Loss:  0.3272005021572113\n",
      "Eval Loss:  0.36125361919403076\n",
      "Eval Loss:  0.3649432957172394\n",
      "Eval Loss:  0.4866693317890167\n",
      "Eval Loss:  0.3556925654411316\n",
      "Eval Loss:  0.39011824131011963\n",
      "Eval Loss:  0.3948928415775299\n",
      "Eval Loss:  0.39336827397346497\n",
      "Eval Loss:  0.36354920268058777\n",
      "Eval Loss:  0.33369314670562744\n",
      "Eval Loss:  0.34707289934158325\n",
      "Eval Loss:  0.38473284244537354\n",
      "Eval Loss:  0.42905712127685547\n",
      "Eval Loss:  0.34219983220100403\n",
      "Eval Loss:  0.34849977493286133\n",
      "Eval Loss:  0.44054973125457764\n",
      "Eval Loss:  0.3900025188922882\n",
      "Eval Loss:  0.3607858121395111\n",
      "Eval Loss:  0.4026704430580139\n",
      "[[16131  2603]\n",
      " [ 2342  8721]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87     18734\n",
      "           1       0.77      0.79      0.78     11063\n",
      "\n",
      "    accuracy                           0.83     29797\n",
      "   macro avg       0.82      0.82      0.82     29797\n",
      "weighted avg       0.83      0.83      0.83     29797\n",
      "\n",
      "acc:  0.8340436956740611\n",
      "pre:  0.7701342281879194\n",
      "rec:  0.7883033535207449\n",
      "ma F1:  0.8231038897532946\n",
      "mi F1:  0.8340436956740611\n",
      "we F1:  0.8344290248704607\n",
      "29797 466\n",
      "Loss:  0.09664109349250793\n",
      "Loss:  0.08130185306072235\n",
      "Loss:  0.07191379368305206\n",
      "3 **********\n",
      "Epoch:  212.92169094085693  fold:  2  kers:  32\n",
      "epoch:  4\n",
      "29797 466\n",
      "Loss:  0.08849813789129257\n",
      "Loss:  0.09316572546958923\n",
      "Loss:  0.09542457014322281\n",
      "4 **********\n",
      "Epoch:  253.58097553253174  fold:  2  kers:  32\n",
      "epoch:  5\n",
      "29797 466\n",
      "Loss:  0.05642376467585564\n",
      "Loss:  0.06338716298341751\n",
      "Loss:  0.05366455391049385\n",
      "5 **********\n",
      "Epoch:  294.1395308971405  fold:  2  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.917206883430481\n",
      "Eval Loss:  0.05860010161995888\n",
      "Eval Loss:  0.8506557941436768\n",
      "[[1310  120]\n",
      " [ 845  819]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.73      1430\n",
      "           1       0.87      0.49      0.63      1664\n",
      "\n",
      "    accuracy                           0.69      3094\n",
      "   macro avg       0.74      0.70      0.68      3094\n",
      "weighted avg       0.75      0.69      0.68      3094\n",
      "\n",
      "acc:  0.6881060116354234\n",
      "pre:  0.8722044728434505\n",
      "rec:  0.4921875\n",
      "ma F1:  0.6800483938980395\n",
      "mi F1:  0.6881060116354234\n",
      "we F1:  0.6762083072370462\n",
      "Eval Loss:  0.4145027697086334\n",
      "Eval Loss:  0.4571060538291931\n",
      "Eval Loss:  0.32104915380477905\n",
      "Eval Loss:  0.26296117901802063\n",
      "Eval Loss:  0.3863186836242676\n",
      "Eval Loss:  0.42013615369796753\n",
      "Eval Loss:  0.49696964025497437\n",
      "Eval Loss:  0.45160239934921265\n",
      "Eval Loss:  0.35209935903549194\n",
      "Eval Loss:  0.2599515914916992\n",
      "Eval Loss:  0.3062566816806793\n",
      "Eval Loss:  0.3550536632537842\n",
      "Eval Loss:  0.43762341141700745\n",
      "Eval Loss:  0.448137104511261\n",
      "Eval Loss:  0.36348599195480347\n",
      "Eval Loss:  0.3798309862613678\n",
      "Eval Loss:  0.35396644473075867\n",
      "Eval Loss:  0.3981400430202484\n",
      "Eval Loss:  0.38930603861808777\n",
      "Eval Loss:  0.2822345495223999\n",
      "Eval Loss:  0.3946956992149353\n",
      "Eval Loss:  0.3147536814212799\n",
      "Eval Loss:  0.4787934422492981\n",
      "Eval Loss:  0.3662794530391693\n",
      "Eval Loss:  0.33678799867630005\n",
      "Eval Loss:  0.47752949595451355\n",
      "Eval Loss:  0.3699857294559479\n",
      "Eval Loss:  0.3400723338127136\n",
      "Eval Loss:  0.48639461398124695\n",
      "[[17767   967]\n",
      " [ 3509  7554]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18734\n",
      "           1       0.89      0.68      0.77     11063\n",
      "\n",
      "    accuracy                           0.85     29797\n",
      "   macro avg       0.86      0.82      0.83     29797\n",
      "weighted avg       0.85      0.85      0.84     29797\n",
      "\n",
      "acc:  0.849783535255227\n",
      "pre:  0.8865156671752141\n",
      "rec:  0.6828165958600741\n",
      "ma F1:  0.8297870232196852\n",
      "mi F1:  0.849783535255227\n",
      "we F1:  0.8448064341493475\n",
      "29797 466\n",
      "Loss:  0.09401971846818924\n",
      "Loss:  0.0733327865600586\n",
      "Loss:  0.08566956222057343\n",
      "6 **********\n",
      "Epoch:  372.78524804115295  fold:  2  kers:  32\n",
      "epoch:  7\n",
      "29797 466\n",
      "Loss:  0.08178780972957611\n",
      "Loss:  0.10861360281705856\n",
      "Loss:  0.09904725104570389\n",
      "7 **********\n",
      "Epoch:  413.1642825603485  fold:  2  kers:  32\n",
      "epoch:  8\n",
      "29797 466\n",
      "Loss:  0.0762554481625557\n",
      "Loss:  0.08469799160957336\n",
      "Loss:  0.08185058832168579\n",
      "8 **********\n",
      "Epoch:  453.49943590164185  fold:  2  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.751716136932373\n",
      "Eval Loss:  0.10245931148529053\n",
      "Eval Loss:  0.5751038193702698\n",
      "[[1287  143]\n",
      " [ 703  961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.90      0.75      1430\n",
      "           1       0.87      0.58      0.69      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.76      0.74      0.72      3094\n",
      "weighted avg       0.77      0.73      0.72      3094\n",
      "\n",
      "acc:  0.7265675500969618\n",
      "pre:  0.8704710144927537\n",
      "rec:  0.5775240384615384\n",
      "ma F1:  0.7234978703985397\n",
      "mi F1:  0.7265675500969618\n",
      "we F1:  0.7212944806763594\n",
      "update!  Acc:  0.7265675500969618\n",
      "Eval Loss:  0.35198697447776794\n",
      "Eval Loss:  0.38935157656669617\n",
      "Eval Loss:  0.2695721983909607\n",
      "Eval Loss:  0.26972880959510803\n",
      "Eval Loss:  0.36347055435180664\n",
      "Eval Loss:  0.34241679310798645\n",
      "Eval Loss:  0.3946509063243866\n",
      "Eval Loss:  0.3667701482772827\n",
      "Eval Loss:  0.2719745337963104\n",
      "Eval Loss:  0.22010642290115356\n",
      "Eval Loss:  0.2545298635959625\n",
      "Eval Loss:  0.2527107000350952\n",
      "Eval Loss:  0.39549264311790466\n",
      "Eval Loss:  0.4318970739841461\n",
      "Eval Loss:  0.30923140048980713\n",
      "Eval Loss:  0.35230496525764465\n",
      "Eval Loss:  0.31943637132644653\n",
      "Eval Loss:  0.30603933334350586\n",
      "Eval Loss:  0.3393147885799408\n",
      "Eval Loss:  0.26518556475639343\n",
      "Eval Loss:  0.31701362133026123\n",
      "Eval Loss:  0.30425024032592773\n",
      "Eval Loss:  0.45459339022636414\n",
      "Eval Loss:  0.2862430214881897\n",
      "Eval Loss:  0.29288697242736816\n",
      "Eval Loss:  0.3754269480705261\n",
      "Eval Loss:  0.29755720496177673\n",
      "Eval Loss:  0.28542107343673706\n",
      "Eval Loss:  0.38214218616485596\n",
      "[[17475  1259]\n",
      " [ 2698  8365]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     18734\n",
      "           1       0.87      0.76      0.81     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.87      0.84      0.85     29797\n",
      "weighted avg       0.87      0.87      0.87     29797\n",
      "\n",
      "acc:  0.8672013961137027\n",
      "pre:  0.8691812136325852\n",
      "rec:  0.7561240169935822\n",
      "ma F1:  0.8535081944609704\n",
      "mi F1:  0.8672013961137027\n",
      "we F1:  0.8650384414289298\n",
      "29797 466\n",
      "Loss:  0.10670740902423859\n",
      "Loss:  0.12609267234802246\n",
      "Loss:  0.06030896678566933\n",
      "9 **********\n",
      "Epoch:  531.814037322998  fold:  2  kers:  32\n",
      "epoch:  10\n",
      "29797 466\n",
      "Loss:  0.08637961745262146\n",
      "Loss:  0.06544401496648788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07949399948120117\n",
      "10 **********\n",
      "Epoch:  572.1691365242004  fold:  2  kers:  32\n",
      "epoch:  11\n",
      "29797 466\n",
      "Loss:  0.05890010669827461\n",
      "Loss:  0.07743387669324875\n",
      "Loss:  0.07552444934844971\n",
      "11 **********\n",
      "Epoch:  612.4434506893158  fold:  2  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.8113768100738525\n",
      "Eval Loss:  0.1518775075674057\n",
      "Eval Loss:  0.7802050113677979\n",
      "[[1280  150]\n",
      " [ 725  939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75      1430\n",
      "           1       0.86      0.56      0.68      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.75      0.73      0.71      3094\n",
      "weighted avg       0.76      0.72      0.71      3094\n",
      "\n",
      "acc:  0.7171945701357466\n",
      "pre:  0.8622589531680441\n",
      "rec:  0.5643028846153846\n",
      "ma F1:  0.7137170988800889\n",
      "mi F1:  0.7171945701357465\n",
      "we F1:  0.7113307989568517\n",
      "Eval Loss:  0.3419007956981659\n",
      "Eval Loss:  0.38500261306762695\n",
      "Eval Loss:  0.2868098020553589\n",
      "Eval Loss:  0.2564031183719635\n",
      "Eval Loss:  0.3405800461769104\n",
      "Eval Loss:  0.37109997868537903\n",
      "Eval Loss:  0.4205498993396759\n",
      "Eval Loss:  0.3639267385005951\n",
      "Eval Loss:  0.27473971247673035\n",
      "Eval Loss:  0.21428298950195312\n",
      "Eval Loss:  0.23269572854042053\n",
      "Eval Loss:  0.24927139282226562\n",
      "Eval Loss:  0.3784213364124298\n",
      "Eval Loss:  0.4233788549900055\n",
      "Eval Loss:  0.274323046207428\n",
      "Eval Loss:  0.360525906085968\n",
      "Eval Loss:  0.31294694542884827\n",
      "Eval Loss:  0.34879350662231445\n",
      "Eval Loss:  0.3146732449531555\n",
      "Eval Loss:  0.24356311559677124\n",
      "Eval Loss:  0.3179430663585663\n",
      "Eval Loss:  0.29412344098091125\n",
      "Eval Loss:  0.4494892656803131\n",
      "Eval Loss:  0.2768881916999817\n",
      "Eval Loss:  0.28865525126457214\n",
      "Eval Loss:  0.35716691613197327\n",
      "Eval Loss:  0.3080291152000427\n",
      "Eval Loss:  0.29305046796798706\n",
      "Eval Loss:  0.4257776439189911\n",
      "[[17688  1046]\n",
      " [ 2820  8243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     18734\n",
      "           1       0.89      0.75      0.81     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.87      0.84      0.86     29797\n",
      "weighted avg       0.87      0.87      0.87     29797\n",
      "\n",
      "acc:  0.8702553948384065\n",
      "pre:  0.8873936914630208\n",
      "rec:  0.7450962668353973\n",
      "ma F1:  0.8557631719151827\n",
      "mi F1:  0.8702553948384065\n",
      "we F1:  0.8675334040003124\n",
      "29797 466\n",
      "Loss:  0.07545972615480423\n",
      "Loss:  0.08782161772251129\n",
      "Loss:  0.08440890163183212\n",
      "12 **********\n",
      "Epoch:  694.1838934421539  fold:  2  kers:  32\n",
      "epoch:  13\n",
      "29797 466\n",
      "Loss:  0.11736395210027695\n",
      "Loss:  0.073503777384758\n",
      "Loss:  0.04800776392221451\n",
      "13 **********\n",
      "Epoch:  734.6427147388458  fold:  2  kers:  32\n",
      "epoch:  14\n",
      "29797 466\n",
      "Loss:  0.08439221978187561\n",
      "Loss:  0.09488701820373535\n",
      "Loss:  0.12660492956638336\n",
      "14 **********\n",
      "Epoch:  775.1743414402008  fold:  2  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.5737401843070984\n",
      "Eval Loss:  0.28229978680610657\n",
      "Eval Loss:  0.5557666420936584\n",
      "[[1226  204]\n",
      " [ 587 1077]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76      1430\n",
      "           1       0.84      0.65      0.73      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.76      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.74      3094\n",
      "\n",
      "acc:  0.744343891402715\n",
      "pre:  0.8407494145199064\n",
      "rec:  0.6472355769230769\n",
      "ma F1:  0.7437496040839169\n",
      "mi F1:  0.744343891402715\n",
      "we F1:  0.7428162937980194\n",
      "update!  Acc:  0.744343891402715\n",
      "Eval Loss:  0.3124871850013733\n",
      "Eval Loss:  0.35541850328445435\n",
      "Eval Loss:  0.25352466106414795\n",
      "Eval Loss:  0.2793771028518677\n",
      "Eval Loss:  0.3316633999347687\n",
      "Eval Loss:  0.31036463379859924\n",
      "Eval Loss:  0.3737415671348572\n",
      "Eval Loss:  0.30641865730285645\n",
      "Eval Loss:  0.24915839731693268\n",
      "Eval Loss:  0.1991482824087143\n",
      "Eval Loss:  0.1868734359741211\n",
      "Eval Loss:  0.2162400782108307\n",
      "Eval Loss:  0.35303983092308044\n",
      "Eval Loss:  0.4128464162349701\n",
      "Eval Loss:  0.25083157420158386\n",
      "Eval Loss:  0.32989779114723206\n",
      "Eval Loss:  0.30322548747062683\n",
      "Eval Loss:  0.27638447284698486\n",
      "Eval Loss:  0.2863806486129761\n",
      "Eval Loss:  0.224265918135643\n",
      "Eval Loss:  0.26589953899383545\n",
      "Eval Loss:  0.28003475069999695\n",
      "Eval Loss:  0.4208478331565857\n",
      "Eval Loss:  0.2280389368534088\n",
      "Eval Loss:  0.28245511651039124\n",
      "Eval Loss:  0.3079882264137268\n",
      "Eval Loss:  0.27372655272483826\n",
      "Eval Loss:  0.263001412153244\n",
      "Eval Loss:  0.3406110405921936\n",
      "[[17278  1456]\n",
      " [ 2142  8921]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91     18734\n",
      "           1       0.86      0.81      0.83     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.87      0.86      0.87     29797\n",
      "weighted avg       0.88      0.88      0.88     29797\n",
      "\n",
      "acc:  0.8792495888847871\n",
      "pre:  0.8596896983713983\n",
      "rec:  0.806381632468589\n",
      "ma F1:  0.8689403983581072\n",
      "mi F1:  0.8792495888847871\n",
      "we F1:  0.8784033396684052\n",
      "29797 466\n",
      "Loss:  0.07960566878318787\n",
      "Loss:  0.10360606014728546\n",
      "Loss:  0.06798022240400314\n",
      "15 **********\n",
      "Epoch:  854.2888052463531  fold:  2  kers:  32\n",
      "epoch:  16\n",
      "29797 466\n",
      "Loss:  0.06098736822605133\n",
      "Loss:  0.06878110766410828\n",
      "Loss:  0.06616310775279999\n",
      "16 **********\n",
      "Epoch:  894.7057390213013  fold:  2  kers:  32\n",
      "epoch:  17\n",
      "29797 466\n",
      "Loss:  0.10673339664936066\n",
      "Loss:  0.08770108222961426\n",
      "Loss:  0.0778794139623642\n",
      "17 **********\n",
      "Epoch:  935.2752637863159  fold:  2  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.5544173717498779\n",
      "Eval Loss:  0.2637272775173187\n",
      "Eval Loss:  0.40229541063308716\n",
      "[[1244  186]\n",
      " [ 612 1052]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76      1430\n",
      "           1       0.85      0.63      0.73      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.76      0.75      0.74      3094\n",
      "weighted avg       0.77      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7420814479638009\n",
      "pre:  0.8497576736672051\n",
      "rec:  0.6322115384615384\n",
      "ma F1:  0.7410843907679259\n",
      "mi F1:  0.7420814479638009\n",
      "we F1:  0.7398692273104531\n",
      "Eval Loss:  0.29586392641067505\n",
      "Eval Loss:  0.3493671119213104\n",
      "Eval Loss:  0.22994369268417358\n",
      "Eval Loss:  0.26151686906814575\n",
      "Eval Loss:  0.3255203664302826\n",
      "Eval Loss:  0.3060857951641083\n",
      "Eval Loss:  0.3682313561439514\n",
      "Eval Loss:  0.29457324743270874\n",
      "Eval Loss:  0.22416038811206818\n",
      "Eval Loss:  0.20131716132164001\n",
      "Eval Loss:  0.17714832723140717\n",
      "Eval Loss:  0.2126988172531128\n",
      "Eval Loss:  0.35106760263442993\n",
      "Eval Loss:  0.41258183121681213\n",
      "Eval Loss:  0.23822733759880066\n",
      "Eval Loss:  0.33266687393188477\n",
      "Eval Loss:  0.2879661023616791\n",
      "Eval Loss:  0.24694013595581055\n",
      "Eval Loss:  0.25640392303466797\n",
      "Eval Loss:  0.2026304006576538\n",
      "Eval Loss:  0.2515983283519745\n",
      "Eval Loss:  0.2772735059261322\n",
      "Eval Loss:  0.3988112509250641\n",
      "Eval Loss:  0.23464186489582062\n",
      "Eval Loss:  0.27899739146232605\n",
      "Eval Loss:  0.3132603168487549\n",
      "Eval Loss:  0.2538091540336609\n",
      "Eval Loss:  0.24240458011627197\n",
      "Eval Loss:  0.31500038504600525\n",
      "[[17408  1326]\n",
      " [ 2133  8930]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18734\n",
      "           1       0.87      0.81      0.84     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.88      0.87      0.87     29797\n",
      "weighted avg       0.88      0.88      0.88     29797\n",
      "\n",
      "acc:  0.8839144880357083\n",
      "pre:  0.8707098283931357\n",
      "rec:  0.807195155021242\n",
      "ma F1:  0.8736890289214667\n",
      "mi F1:  0.8839144880357082\n",
      "we F1:  0.8829411516939775\n",
      "29797 466\n",
      "Loss:  0.0648612380027771\n",
      "Loss:  0.04769517853856087\n",
      "Loss:  0.06797660142183304\n",
      "18 **********\n",
      "Epoch:  1016.4093282222748  fold:  2  kers:  32\n",
      "epoch:  19\n",
      "29797 466\n",
      "Loss:  0.08715422451496124\n",
      "Loss:  0.08742889761924744\n",
      "Loss:  0.08761419355869293\n",
      "19 **********\n",
      "Epoch:  1057.0815787315369  fold:  2  kers:  32\n",
      "epoch:  20\n",
      "29797 466\n",
      "Loss:  0.03301773965358734\n",
      "Loss:  0.07788929343223572\n",
      "Loss:  0.06162205711007118\n",
      "20 **********\n",
      "Epoch:  1097.7199201583862  fold:  2  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.7419166564941406\n",
      "Eval Loss:  0.2717445194721222\n",
      "Eval Loss:  0.9777557849884033\n",
      "[[1274  156]\n",
      " [ 731  933]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.89      0.74      1430\n",
      "           1       0.86      0.56      0.68      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.75      0.73      0.71      3094\n",
      "weighted avg       0.75      0.71      0.71      3094\n",
      "\n",
      "acc:  0.7133160956690369\n",
      "pre:  0.8567493112947658\n",
      "rec:  0.5606971153846154\n",
      "ma F1:  0.709790933379016\n",
      "mi F1:  0.7133160956690369\n",
      "we F1:  0.7073719070568315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3162219524383545\n",
      "Eval Loss:  0.37156912684440613\n",
      "Eval Loss:  0.272294819355011\n",
      "Eval Loss:  0.23746134340763092\n",
      "Eval Loss:  0.31475743651390076\n",
      "Eval Loss:  0.35643622279167175\n",
      "Eval Loss:  0.44016602635383606\n",
      "Eval Loss:  0.3230508863925934\n",
      "Eval Loss:  0.2523438036441803\n",
      "Eval Loss:  0.211417555809021\n",
      "Eval Loss:  0.19016972184181213\n",
      "Eval Loss:  0.22719842195510864\n",
      "Eval Loss:  0.3381022810935974\n",
      "Eval Loss:  0.3911032974720001\n",
      "Eval Loss:  0.24434591829776764\n",
      "Eval Loss:  0.3377082645893097\n",
      "Eval Loss:  0.28767260909080505\n",
      "Eval Loss:  0.3311619460582733\n",
      "Eval Loss:  0.26955360174179077\n",
      "Eval Loss:  0.18330888450145721\n",
      "Eval Loss:  0.28018417954444885\n",
      "Eval Loss:  0.2637978792190552\n",
      "Eval Loss:  0.3889639675617218\n",
      "Eval Loss:  0.2540768086910248\n",
      "Eval Loss:  0.2886628210544586\n",
      "Eval Loss:  0.3358503580093384\n",
      "Eval Loss:  0.2831975519657135\n",
      "Eval Loss:  0.2805751860141754\n",
      "Eval Loss:  0.4128580689430237\n",
      "[[17827   907]\n",
      " [ 2653  8410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18734\n",
      "           1       0.90      0.76      0.83     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.89      0.86      0.87     29797\n",
      "weighted avg       0.88      0.88      0.88     29797\n",
      "\n",
      "acc:  0.8805248850555425\n",
      "pre:  0.9026510679403241\n",
      "rec:  0.7601916297568472\n",
      "ma F1:  0.8672675182147651\n",
      "mi F1:  0.8805248850555425\n",
      "we F1:  0.8780668450742325\n",
      "29797 466\n",
      "Loss:  0.09384364634752274\n",
      "Loss:  0.07821643352508545\n",
      "Loss:  0.04566654562950134\n",
      "21 **********\n",
      "Epoch:  1176.2619149684906  fold:  2  kers:  32\n",
      "epoch:  22\n",
      "29797 466\n",
      "Loss:  0.0751969963312149\n",
      "Loss:  0.08267989009618759\n",
      "Loss:  0.07841364294290543\n",
      "22 **********\n",
      "Epoch:  1216.7815737724304  fold:  2  kers:  32\n",
      "epoch:  23\n",
      "29797 466\n",
      "Loss:  0.04408886283636093\n",
      "Loss:  0.06222746893763542\n",
      "Loss:  0.06194022297859192\n",
      "23 **********\n",
      "Epoch:  1257.2872705459595  fold:  2  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.590004563331604\n",
      "Eval Loss:  0.4700859487056732\n",
      "Eval Loss:  0.5105155110359192\n",
      "[[1213  217]\n",
      " [ 558 1106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76      1430\n",
      "           1       0.84      0.66      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.77      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7495151906916613\n",
      "pre:  0.8359788359788359\n",
      "rec:  0.6646634615384616\n",
      "ma F1:  0.7492152550670734\n",
      "mi F1:  0.7495151906916613\n",
      "we F1:  0.7485593210843299\n",
      "update!  Acc:  0.7495151906916613\n",
      "Eval Loss:  0.25799089670181274\n",
      "Eval Loss:  0.30085766315460205\n",
      "Eval Loss:  0.23901817202568054\n",
      "Eval Loss:  0.2567642331123352\n",
      "Eval Loss:  0.30494052171707153\n",
      "Eval Loss:  0.27983522415161133\n",
      "Eval Loss:  0.3422428071498871\n",
      "Eval Loss:  0.25523242354393005\n",
      "Eval Loss:  0.21582946181297302\n",
      "Eval Loss:  0.18937629461288452\n",
      "Eval Loss:  0.1444602906703949\n",
      "Eval Loss:  0.19556431472301483\n",
      "Eval Loss:  0.3180435299873352\n",
      "Eval Loss:  0.36884719133377075\n",
      "Eval Loss:  0.25477132201194763\n",
      "Eval Loss:  0.31106799840927124\n",
      "Eval Loss:  0.284556120634079\n",
      "Eval Loss:  0.23387634754180908\n",
      "Eval Loss:  0.22607789933681488\n",
      "Eval Loss:  0.1684766411781311\n",
      "Eval Loss:  0.22687557339668274\n",
      "Eval Loss:  0.26092100143432617\n",
      "Eval Loss:  0.3602595925331116\n",
      "Eval Loss:  0.21394681930541992\n",
      "Eval Loss:  0.2789915204048157\n",
      "Eval Loss:  0.2969740331172943\n",
      "Eval Loss:  0.24354788661003113\n",
      "Eval Loss:  0.23762716352939606\n",
      "Eval Loss:  0.28814443945884705\n",
      "[[17437  1297]\n",
      " [ 1928  9135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     18734\n",
      "           1       0.88      0.83      0.85     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.89      0.88      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8917676276135181\n",
      "pre:  0.8756710122699386\n",
      "rec:  0.8257253909427823\n",
      "ma F1:  0.8826586085719639\n",
      "mi F1:  0.8917676276135181\n",
      "we F1:  0.8910752895003863\n",
      "29797 466\n",
      "Loss:  0.07888946682214737\n",
      "Loss:  0.07374674081802368\n",
      "Loss:  0.05833179131150246\n",
      "24 **********\n",
      "Epoch:  1335.5909016132355  fold:  2  kers:  32\n",
      "epoch:  25\n",
      "29797 466\n",
      "Loss:  0.06205279752612114\n",
      "Loss:  0.07883326709270477\n",
      "Loss:  0.044641606509685516\n",
      "25 **********\n",
      "Epoch:  1376.0816371440887  fold:  2  kers:  32\n",
      "epoch:  26\n",
      "29797 466\n",
      "Loss:  0.07558633387088776\n",
      "Loss:  0.0717998817563057\n",
      "Loss:  0.06766259670257568\n",
      "26 **********\n",
      "Epoch:  1416.4566826820374  fold:  2  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.5343775153160095\n",
      "Eval Loss:  0.3247116506099701\n",
      "Eval Loss:  0.4841404855251312\n",
      "[[1224  206]\n",
      " [ 559 1105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.76      1430\n",
      "           1       0.84      0.66      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.77      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7527472527472527\n",
      "pre:  0.8428680396643783\n",
      "rec:  0.6640625\n",
      "ma F1:  0.7523809523809524\n",
      "mi F1:  0.7527472527472527\n",
      "we F1:  0.7516606642657063\n",
      "update!  Acc:  0.7527472527472527\n",
      "Eval Loss:  0.24245309829711914\n",
      "Eval Loss:  0.3029988706111908\n",
      "Eval Loss:  0.24025525152683258\n",
      "Eval Loss:  0.2560938000679016\n",
      "Eval Loss:  0.3006301522254944\n",
      "Eval Loss:  0.2937760353088379\n",
      "Eval Loss:  0.3383389115333557\n",
      "Eval Loss:  0.2583497166633606\n",
      "Eval Loss:  0.21282252669334412\n",
      "Eval Loss:  0.19355438649654388\n",
      "Eval Loss:  0.12847740948200226\n",
      "Eval Loss:  0.18042248487472534\n",
      "Eval Loss:  0.30783048272132874\n",
      "Eval Loss:  0.3702560067176819\n",
      "Eval Loss:  0.24238671362400055\n",
      "Eval Loss:  0.3005174994468689\n",
      "Eval Loss:  0.2665458619594574\n",
      "Eval Loss:  0.22819238901138306\n",
      "Eval Loss:  0.21836501359939575\n",
      "Eval Loss:  0.16284723579883575\n",
      "Eval Loss:  0.21564456820487976\n",
      "Eval Loss:  0.24263501167297363\n",
      "Eval Loss:  0.354037880897522\n",
      "Eval Loss:  0.21033315360546112\n",
      "Eval Loss:  0.27604594826698303\n",
      "Eval Loss:  0.27121344208717346\n",
      "Eval Loss:  0.22801625728607178\n",
      "Eval Loss:  0.2205725759267807\n",
      "Eval Loss:  0.2889287769794464\n",
      "[[17432  1302]\n",
      " [ 1846  9217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     18734\n",
      "           1       0.88      0.83      0.85     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.89      0.88      0.89     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8943517803805753\n",
      "pre:  0.8762239756630859\n",
      "rec:  0.8331374853113983\n",
      "ma F1:  0.885660877245862\n",
      "mi F1:  0.8943517803805753\n",
      "we F1:  0.893776265918581\n",
      "29797 466\n",
      "Loss:  0.06194410100579262\n",
      "Loss:  0.05882523953914642\n",
      "Loss:  0.04783269390463829\n",
      "27 **********\n",
      "Epoch:  1494.7982137203217  fold:  2  kers:  32\n",
      "epoch:  28\n",
      "29797 466\n",
      "Loss:  0.08667602390050888\n",
      "Loss:  0.07697165757417679\n",
      "Loss:  0.13484208285808563\n",
      "28 **********\n",
      "Epoch:  1535.3747200965881  fold:  2  kers:  32\n",
      "epoch:  29\n",
      "29797 466\n",
      "Loss:  0.07833634316921234\n",
      "Loss:  0.052712589502334595\n",
      "Loss:  0.07615078240633011\n",
      "29 **********\n",
      "Epoch:  1575.9183146953583  fold:  2  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.5317579507827759\n",
      "Eval Loss:  0.5583500862121582\n",
      "Eval Loss:  0.4114806056022644\n",
      "[[1151  279]\n",
      " [ 476 1188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75      1430\n",
      "           1       0.81      0.71      0.76      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.76      0.76      0.76      3094\n",
      "weighted avg       0.76      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7559793148028442\n",
      "pre:  0.8098159509202454\n",
      "rec:  0.7139423076923077\n",
      "ma F1:  0.7559444127007907\n",
      "mi F1:  0.7559793148028442\n",
      "we F1:  0.7561651449137772\n",
      "update!  Acc:  0.7559793148028442\n",
      "Eval Loss:  0.22733992338180542\n",
      "Eval Loss:  0.2801301181316376\n",
      "Eval Loss:  0.23990894854068756\n",
      "Eval Loss:  0.26611027121543884\n",
      "Eval Loss:  0.28474318981170654\n",
      "Eval Loss:  0.27036887407302856\n",
      "Eval Loss:  0.3270951509475708\n",
      "Eval Loss:  0.23539936542510986\n",
      "Eval Loss:  0.19861377775669098\n",
      "Eval Loss:  0.197566956281662\n",
      "Eval Loss:  0.12185930460691452\n",
      "Eval Loss:  0.1919897198677063\n",
      "Eval Loss:  0.2982780635356903\n",
      "Eval Loss:  0.35332363843917847\n",
      "Eval Loss:  0.24168896675109863\n",
      "Eval Loss:  0.28593942523002625\n",
      "Eval Loss:  0.2501140236854553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20624804496765137\n",
      "Eval Loss:  0.2060263603925705\n",
      "Eval Loss:  0.1561707705259323\n",
      "Eval Loss:  0.20178447663784027\n",
      "Eval Loss:  0.24042415618896484\n",
      "Eval Loss:  0.35294780135154724\n",
      "Eval Loss:  0.1879173368215561\n",
      "Eval Loss:  0.27135998010635376\n",
      "Eval Loss:  0.2502851188182831\n",
      "Eval Loss:  0.21915516257286072\n",
      "Eval Loss:  0.22519782185554504\n",
      "Eval Loss:  0.2707417905330658\n",
      "[[17302  1432]\n",
      " [ 1590  9473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     18734\n",
      "           1       0.87      0.86      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.89      0.89      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.8985803939993959\n",
      "pre:  0.8686840898670335\n",
      "rec:  0.8562776823646389\n",
      "ma F1:  0.8910597343641558\n",
      "mi F1:  0.8985803939993959\n",
      "we F1:  0.8984286167325204\n",
      "29797 466\n",
      "Loss:  0.1145050972700119\n",
      "Loss:  0.07437979429960251\n",
      "Loss:  0.055948406457901\n",
      "30 **********\n",
      "Epoch:  1654.6448156833649  fold:  2  kers:  32\n",
      "epoch:  31\n",
      "29797 466\n",
      "Loss:  0.05523184686899185\n",
      "Loss:  0.07056962698698044\n",
      "Loss:  0.04886482656002045\n",
      "31 **********\n",
      "Epoch:  1695.139541387558  fold:  2  kers:  32\n",
      "epoch:  32\n",
      "29797 466\n",
      "Loss:  0.08100106567144394\n",
      "Loss:  0.06785959750413895\n",
      "Loss:  0.07620102167129517\n",
      "32 **********\n",
      "Epoch:  1735.6432430744171  fold:  2  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.67750084400177\n",
      "Eval Loss:  0.47799617052078247\n",
      "Eval Loss:  0.5299681425094604\n",
      "[[1214  216]\n",
      " [ 554 1110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1430\n",
      "           1       0.84      0.67      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.77      0.75      0.75      3094\n",
      "\n",
      "acc:  0.751131221719457\n",
      "pre:  0.8371040723981901\n",
      "rec:  0.6670673076923077\n",
      "ma F1:  0.7508497158550181\n",
      "mi F1:  0.751131221719457\n",
      "we F1:  0.7502163276600305\n",
      "Eval Loss:  0.24193164706230164\n",
      "Eval Loss:  0.28712406754493713\n",
      "Eval Loss:  0.23184219002723694\n",
      "Eval Loss:  0.23390614986419678\n",
      "Eval Loss:  0.2751978039741516\n",
      "Eval Loss:  0.268724650144577\n",
      "Eval Loss:  0.3454418480396271\n",
      "Eval Loss:  0.23513610661029816\n",
      "Eval Loss:  0.2065742462873459\n",
      "Eval Loss:  0.18536493182182312\n",
      "Eval Loss:  0.12057001888751984\n",
      "Eval Loss:  0.1811247020959854\n",
      "Eval Loss:  0.30303674936294556\n",
      "Eval Loss:  0.3410596549510956\n",
      "Eval Loss:  0.2460205852985382\n",
      "Eval Loss:  0.2740750014781952\n",
      "Eval Loss:  0.24505440890789032\n",
      "Eval Loss:  0.2193642407655716\n",
      "Eval Loss:  0.19685660302639008\n",
      "Eval Loss:  0.1608140468597412\n",
      "Eval Loss:  0.18815650045871735\n",
      "Eval Loss:  0.2339768409729004\n",
      "Eval Loss:  0.33870336413383484\n",
      "Eval Loss:  0.20170190930366516\n",
      "Eval Loss:  0.24705100059509277\n",
      "Eval Loss:  0.26499831676483154\n",
      "Eval Loss:  0.22220966219902039\n",
      "Eval Loss:  0.22326304018497467\n",
      "Eval Loss:  0.292906254529953\n",
      "[[17560  1174]\n",
      " [ 1795  9268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     18734\n",
      "           1       0.89      0.84      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.89      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9003590965533443\n",
      "pre:  0.8875694311434591\n",
      "rec:  0.8377474464430986\n",
      "ma F1:  0.8919950348914508\n",
      "mi F1:  0.9003590965533443\n",
      "we F1:  0.8997326997501561\n",
      "29797 466\n",
      "Loss:  0.06803454458713531\n",
      "Loss:  0.0621301643550396\n",
      "Loss:  0.06765525043010712\n",
      "33 **********\n",
      "Epoch:  1814.1523253917694  fold:  2  kers:  32\n",
      "epoch:  34\n",
      "29797 466\n",
      "Loss:  0.07346240431070328\n",
      "Loss:  0.06420756131410599\n",
      "Loss:  0.04383327439427376\n",
      "34 **********\n",
      "Epoch:  1854.8884055614471  fold:  2  kers:  32\n",
      "epoch:  35\n",
      "29797 466\n",
      "Loss:  0.07096640020608902\n",
      "Loss:  0.08378326892852783\n",
      "Loss:  0.04974757879972458\n",
      "35 **********\n",
      "Epoch:  1895.4738879203796  fold:  2  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.554002583026886\n",
      "Eval Loss:  0.4594755470752716\n",
      "Eval Loss:  0.3841535151004791\n",
      "[[1195  235]\n",
      " [ 501 1163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1430\n",
      "           1       0.83      0.70      0.76      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.77      0.76      3094\n",
      "weighted avg       0.77      0.76      0.76      3094\n",
      "\n",
      "acc:  0.762120232708468\n",
      "pre:  0.8319027181688126\n",
      "rec:  0.6989182692307693\n",
      "ma F1:  0.7620947841432739\n",
      "mi F1:  0.762120232708468\n",
      "we F1:  0.7619086915102931\n",
      "update!  Acc:  0.762120232708468\n",
      "Eval Loss:  0.22628037631511688\n",
      "Eval Loss:  0.26669222116470337\n",
      "Eval Loss:  0.21541626751422882\n",
      "Eval Loss:  0.24929961562156677\n",
      "Eval Loss:  0.27367809414863586\n",
      "Eval Loss:  0.24856536090373993\n",
      "Eval Loss:  0.31612488627433777\n",
      "Eval Loss:  0.2224871963262558\n",
      "Eval Loss:  0.18733811378479004\n",
      "Eval Loss:  0.18080830574035645\n",
      "Eval Loss:  0.10957608371973038\n",
      "Eval Loss:  0.1869042068719864\n",
      "Eval Loss:  0.2958999276161194\n",
      "Eval Loss:  0.3184734284877777\n",
      "Eval Loss:  0.24039508402347565\n",
      "Eval Loss:  0.2623243033885956\n",
      "Eval Loss:  0.23427025973796844\n",
      "Eval Loss:  0.2017764449119568\n",
      "Eval Loss:  0.19748573005199432\n",
      "Eval Loss:  0.1572255641222\n",
      "Eval Loss:  0.1935766637325287\n",
      "Eval Loss:  0.23901167511940002\n",
      "Eval Loss:  0.3419116139411926\n",
      "Eval Loss:  0.1946696639060974\n",
      "Eval Loss:  0.24162183701992035\n",
      "Eval Loss:  0.23945915699005127\n",
      "Eval Loss:  0.21639534831047058\n",
      "Eval Loss:  0.20992596447467804\n",
      "Eval Loss:  0.2600618302822113\n",
      "[[17394  1340]\n",
      " [ 1516  9547]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     18734\n",
      "           1       0.88      0.86      0.87     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.90      0.90     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9041514246400645\n",
      "pre:  0.8769174244511803\n",
      "rec:  0.8629666455753412\n",
      "ma F1:  0.8970087202273112\n",
      "mi F1:  0.9041514246400645\n",
      "we F1:  0.9039912212532103\n",
      "29797 466\n",
      "Loss:  0.039636287838220596\n",
      "Loss:  0.10017244517803192\n",
      "Loss:  0.05919884145259857\n",
      "36 **********\n",
      "Epoch:  1973.9111626148224  fold:  2  kers:  32\n",
      "epoch:  37\n",
      "29797 466\n",
      "Loss:  0.06561528891324997\n",
      "Loss:  0.04120072349905968\n",
      "Loss:  0.07270830124616623\n",
      "37 **********\n",
      "Epoch:  2014.2423255443573  fold:  2  kers:  32\n",
      "epoch:  38\n",
      "29797 466\n",
      "Loss:  0.09403331577777863\n",
      "Loss:  0.0693640410900116\n",
      "Loss:  0.07070998847484589\n",
      "38 **********\n",
      "Epoch:  2054.596426963806  fold:  2  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.5331908464431763\n",
      "Eval Loss:  0.6762107610702515\n",
      "Eval Loss:  0.2314639687538147\n",
      "[[1074  356]\n",
      " [ 367 1297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1430\n",
      "           1       0.78      0.78      0.78      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.76      0.77      0.77      3094\n",
      "weighted avg       0.77      0.77      0.77      3094\n",
      "\n",
      "acc:  0.766321913380737\n",
      "pre:  0.7846339987900787\n",
      "rec:  0.7794471153846154\n",
      "ma F1:  0.7651016627241509\n",
      "mi F1:  0.7663219133807371\n",
      "we F1:  0.7663821051171604\n",
      "update!  Acc:  0.766321913380737\n",
      "Eval Loss:  0.21636256575584412\n",
      "Eval Loss:  0.2579842209815979\n",
      "Eval Loss:  0.23714563250541687\n",
      "Eval Loss:  0.27011972665786743\n",
      "Eval Loss:  0.2884982228279114\n",
      "Eval Loss:  0.23647962510585785\n",
      "Eval Loss:  0.32800033688545227\n",
      "Eval Loss:  0.21302515268325806\n",
      "Eval Loss:  0.20601212978363037\n",
      "Eval Loss:  0.1899077147245407\n",
      "Eval Loss:  0.11827359348535538\n",
      "Eval Loss:  0.20051845908164978\n",
      "Eval Loss:  0.2942523658275604\n",
      "Eval Loss:  0.33092209696769714\n",
      "Eval Loss:  0.25996869802474976\n",
      "Eval Loss:  0.24369892477989197\n",
      "Eval Loss:  0.23153163492679596\n",
      "Eval Loss:  0.20901161432266235\n",
      "Eval Loss:  0.22166119515895844\n",
      "Eval Loss:  0.1687323898077011\n",
      "Eval Loss:  0.19329102337360382\n",
      "Eval Loss:  0.24564924836158752\n",
      "Eval Loss:  0.36055508255958557\n",
      "Eval Loss:  0.19754518568515778\n",
      "Eval Loss:  0.24463482201099396\n",
      "Eval Loss:  0.23480893671512604\n",
      "Eval Loss:  0.21428215503692627\n",
      "Eval Loss:  0.21647171676158905\n",
      "Eval Loss:  0.24762055277824402\n",
      "[[16966  1768]\n",
      " [ 1180  9883]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     18734\n",
      "           1       0.85      0.89      0.87     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.89      0.90      0.90     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9010638654898144\n",
      "pre:  0.8482533688095443\n",
      "rec:  0.8933381542077194\n",
      "ma F1:  0.8951386399245012\n",
      "mi F1:  0.9010638654898144\n",
      "we F1:  0.9015557520678751\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05454837158322334\n",
      "Loss:  0.08508460968732834\n",
      "Loss:  0.07957000285387039\n",
      "39 **********\n",
      "Epoch:  2132.9788477420807  fold:  2  kers:  32\n",
      "epoch:  40\n",
      "29797 466\n",
      "Loss:  0.04686131328344345\n",
      "Loss:  0.08819380402565002\n",
      "Loss:  0.09269357472658157\n",
      "40 **********\n",
      "Epoch:  2173.3060224056244  fold:  2  kers:  32\n",
      "epoch:  41\n",
      "29797 466\n",
      "Loss:  0.062274251133203506\n",
      "Loss:  0.07609068602323532\n",
      "Loss:  0.0716235488653183\n",
      "41 **********\n",
      "Epoch:  2213.6710934638977  fold:  2  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.6229444742202759\n",
      "Eval Loss:  0.5738768577575684\n",
      "Eval Loss:  0.44580790400505066\n",
      "[[1152  278]\n",
      " [ 459 1205]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76      1430\n",
      "           1       0.81      0.72      0.77      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.76      0.76      0.76      3094\n",
      "weighted avg       0.77      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7617970265029088\n",
      "pre:  0.8125421443020904\n",
      "rec:  0.7241586538461539\n",
      "ma F1:  0.7617271090248754\n",
      "mi F1:  0.7617970265029087\n",
      "we F1:  0.7620358012863823\n",
      "Eval Loss:  0.22008304297924042\n",
      "Eval Loss:  0.24262970685958862\n",
      "Eval Loss:  0.24504704773426056\n",
      "Eval Loss:  0.24605944752693176\n",
      "Eval Loss:  0.27572914958000183\n",
      "Eval Loss:  0.22736355662345886\n",
      "Eval Loss:  0.32935819029808044\n",
      "Eval Loss:  0.19890324771404266\n",
      "Eval Loss:  0.20269659161567688\n",
      "Eval Loss:  0.18350130319595337\n",
      "Eval Loss:  0.11176850646734238\n",
      "Eval Loss:  0.18656742572784424\n",
      "Eval Loss:  0.27754679322242737\n",
      "Eval Loss:  0.32984453439712524\n",
      "Eval Loss:  0.23721472918987274\n",
      "Eval Loss:  0.2329183667898178\n",
      "Eval Loss:  0.2099916934967041\n",
      "Eval Loss:  0.19809669256210327\n",
      "Eval Loss:  0.20804144442081451\n",
      "Eval Loss:  0.1580498218536377\n",
      "Eval Loss:  0.17401368916034698\n",
      "Eval Loss:  0.23348040878772736\n",
      "Eval Loss:  0.36176979541778564\n",
      "Eval Loss:  0.1912919282913208\n",
      "Eval Loss:  0.2367221713066101\n",
      "Eval Loss:  0.22555281221866608\n",
      "Eval Loss:  0.21398726105690002\n",
      "Eval Loss:  0.22426792979240417\n",
      "Eval Loss:  0.2673652768135071\n",
      "[[17274  1460]\n",
      " [ 1373  9690]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     18734\n",
      "           1       0.87      0.88      0.87     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.90      0.90     29797\n",
      "weighted avg       0.91      0.90      0.90     29797\n",
      "\n",
      "acc:  0.904923314427627\n",
      "pre:  0.8690582959641255\n",
      "rec:  0.8758926150230498\n",
      "ma F1:  0.8983374535787212\n",
      "mi F1:  0.904923314427627\n",
      "we F1:  0.9049988642554032\n",
      "29797 466\n",
      "Loss:  0.05551331117749214\n",
      "Loss:  0.04986920952796936\n",
      "Loss:  0.07323437184095383\n",
      "42 **********\n",
      "Epoch:  2292.134298324585  fold:  2  kers:  32\n",
      "epoch:  43\n",
      "29797 466\n",
      "Loss:  0.0776095911860466\n",
      "Loss:  0.07152609527111053\n",
      "Loss:  0.051779430359601974\n",
      "43 **********\n",
      "Epoch:  2332.671909093857  fold:  2  kers:  32\n",
      "epoch:  44\n",
      "29797 466\n",
      "Loss:  0.06046802178025246\n",
      "Loss:  0.06328471750020981\n",
      "Loss:  0.07994627952575684\n",
      "44 **********\n",
      "Epoch:  2373.2803313732147  fold:  2  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.7214228510856628\n",
      "Eval Loss:  0.3611217737197876\n",
      "Eval Loss:  0.6557365655899048\n",
      "[[1219  211]\n",
      " [ 555 1109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1430\n",
      "           1       0.84      0.67      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.77      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7524240465416936\n",
      "pre:  0.8401515151515152\n",
      "rec:  0.6664663461538461\n",
      "ma F1:  0.7521107161624377\n",
      "mi F1:  0.7524240465416936\n",
      "we F1:  0.7514441769920207\n",
      "Eval Loss:  0.21980969607830048\n",
      "Eval Loss:  0.246381938457489\n",
      "Eval Loss:  0.23087641596794128\n",
      "Eval Loss:  0.21021857857704163\n",
      "Eval Loss:  0.258360892534256\n",
      "Eval Loss:  0.24158234894275665\n",
      "Eval Loss:  0.3260968327522278\n",
      "Eval Loss:  0.2110801339149475\n",
      "Eval Loss:  0.18364733457565308\n",
      "Eval Loss:  0.17918139696121216\n",
      "Eval Loss:  0.11308261752128601\n",
      "Eval Loss:  0.18377764523029327\n",
      "Eval Loss:  0.26319512724876404\n",
      "Eval Loss:  0.3035459816455841\n",
      "Eval Loss:  0.20887984335422516\n",
      "Eval Loss:  0.22923323512077332\n",
      "Eval Loss:  0.1755613088607788\n",
      "Eval Loss:  0.21438799798488617\n",
      "Eval Loss:  0.20958389341831207\n",
      "Eval Loss:  0.14677275717258453\n",
      "Eval Loss:  0.16220183670520782\n",
      "Eval Loss:  0.23447884619235992\n",
      "Eval Loss:  0.35965481400489807\n",
      "Eval Loss:  0.17531085014343262\n",
      "Eval Loss:  0.222855344414711\n",
      "Eval Loss:  0.22043295204639435\n",
      "Eval Loss:  0.21377408504486084\n",
      "Eval Loss:  0.2286805957555771\n",
      "Eval Loss:  0.27846357226371765\n",
      "[[17685  1049]\n",
      " [ 1617  9446]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18734\n",
      "           1       0.90      0.85      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9105279054938417\n",
      "pre:  0.9000476417341591\n",
      "rec:  0.8538371147066799\n",
      "ma F1:  0.9031210596909032\n",
      "mi F1:  0.9105279054938417\n",
      "we F1:  0.9100172745415332\n",
      "29797 466\n",
      "Loss:  0.02654929645359516\n",
      "Loss:  0.07452736049890518\n",
      "Loss:  0.0460854209959507\n",
      "45 **********\n",
      "Epoch:  2453.2834186553955  fold:  2  kers:  32\n",
      "epoch:  46\n",
      "29797 466\n",
      "Loss:  0.05537624657154083\n",
      "Loss:  0.03901631385087967\n",
      "Loss:  0.04607425630092621\n",
      "46 **********\n",
      "Epoch:  2493.8270134925842  fold:  2  kers:  32\n",
      "epoch:  47\n",
      "29797 466\n",
      "Loss:  0.10753235220909119\n",
      "Loss:  0.04794757813215256\n",
      "Loss:  0.040355220437049866\n",
      "47 **********\n",
      "Epoch:  2534.291818857193  fold:  2  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.7503672242164612\n",
      "Eval Loss:  0.46054592728614807\n",
      "Eval Loss:  0.48185423016548157\n",
      "[[1160  270]\n",
      " [ 466 1198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1430\n",
      "           1       0.82      0.72      0.77      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.76      0.77      0.76      3094\n",
      "weighted avg       0.77      0.76      0.76      3094\n",
      "\n",
      "acc:  0.762120232708468\n",
      "pre:  0.8160762942779292\n",
      "rec:  0.7199519230769231\n",
      "ma F1:  0.7620843446804813\n",
      "mi F1:  0.762120232708468\n",
      "we F1:  0.7623053393791371\n",
      "Eval Loss:  0.2265559881925583\n",
      "Eval Loss:  0.22008052468299866\n",
      "Eval Loss:  0.2431378811597824\n",
      "Eval Loss:  0.21677333116531372\n",
      "Eval Loss:  0.28303471207618713\n",
      "Eval Loss:  0.1944509893655777\n",
      "Eval Loss:  0.306657612323761\n",
      "Eval Loss:  0.19950182735919952\n",
      "Eval Loss:  0.17828334867954254\n",
      "Eval Loss:  0.18156540393829346\n",
      "Eval Loss:  0.1256827414035797\n",
      "Eval Loss:  0.19637612998485565\n",
      "Eval Loss:  0.25425371527671814\n",
      "Eval Loss:  0.3016148805618286\n",
      "Eval Loss:  0.22460313141345978\n",
      "Eval Loss:  0.23645567893981934\n",
      "Eval Loss:  0.16969287395477295\n",
      "Eval Loss:  0.21664787828922272\n",
      "Eval Loss:  0.214940145611763\n",
      "Eval Loss:  0.14283859729766846\n",
      "Eval Loss:  0.18370914459228516\n",
      "Eval Loss:  0.22547006607055664\n",
      "Eval Loss:  0.3813464641571045\n",
      "Eval Loss:  0.1874447762966156\n",
      "Eval Loss:  0.19369693100452423\n",
      "Eval Loss:  0.2190353274345398\n",
      "Eval Loss:  0.20226958394050598\n",
      "Eval Loss:  0.23131893575191498\n",
      "Eval Loss:  0.2598329484462738\n",
      "[[17506  1228]\n",
      " [ 1368  9695]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18734\n",
      "           1       0.89      0.88      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.91      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9128771352820754\n",
      "pre:  0.8875766730751625\n",
      "rec:  0.8763445719967459\n",
      "ma F1:  0.9064484974319776\n",
      "mi F1:  0.9128771352820754\n",
      "we F1:  0.9127619119689255\n",
      "29797 466\n",
      "Loss:  0.04153453931212425\n",
      "Loss:  0.08374516665935516\n",
      "Loss:  0.04962282255291939\n",
      "48 **********\n",
      "Epoch:  2612.6044268608093  fold:  2  kers:  32\n",
      "epoch:  49\n",
      "29797 466\n",
      "Loss:  0.09042622894048691\n",
      "Loss:  0.04772808402776718\n",
      "Loss:  0.04744384437799454\n",
      "49 **********\n",
      "Epoch:  2653.1749494075775  fold:  2  kers:  32\n",
      "epoch:  50\n",
      "29797 466\n",
      "Loss:  0.06439194828271866\n",
      "Loss:  0.0766683891415596\n",
      "Loss:  0.04429484158754349\n",
      "50 **********\n",
      "Epoch:  2693.6726665496826  fold:  2  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.6832593679428101\n",
      "Eval Loss:  0.4632846415042877\n",
      "Eval Loss:  0.40146878361701965\n",
      "[[1204  226]\n",
      " [ 498 1166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      1430\n",
      "           1       0.84      0.70      0.76      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.77      0.77      0.77      3094\n",
      "weighted avg       0.78      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7659987071751778\n",
      "pre:  0.8376436781609196\n",
      "rec:  0.7007211538461539\n",
      "ma F1:  0.7659634042780818\n",
      "mi F1:  0.7659987071751778\n",
      "we F1:  0.7657460127538607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22550562024116516\n",
      "Eval Loss:  0.20988360047340393\n",
      "Eval Loss:  0.2368190437555313\n",
      "Eval Loss:  0.21087738871574402\n",
      "Eval Loss:  0.2722356617450714\n",
      "Eval Loss:  0.19598513841629028\n",
      "Eval Loss:  0.29360756278038025\n",
      "Eval Loss:  0.2062232792377472\n",
      "Eval Loss:  0.16421329975128174\n",
      "Eval Loss:  0.16753876209259033\n",
      "Eval Loss:  0.13843227922916412\n",
      "Eval Loss:  0.18904241919517517\n",
      "Eval Loss:  0.26280948519706726\n",
      "Eval Loss:  0.26742592453956604\n",
      "Eval Loss:  0.2224465012550354\n",
      "Eval Loss:  0.23251715302467346\n",
      "Eval Loss:  0.17205536365509033\n",
      "Eval Loss:  0.2253791093826294\n",
      "Eval Loss:  0.2002469003200531\n",
      "Eval Loss:  0.13728342950344086\n",
      "Eval Loss:  0.19190067052841187\n",
      "Eval Loss:  0.23278814554214478\n",
      "Eval Loss:  0.37156620621681213\n",
      "Eval Loss:  0.19643551111221313\n",
      "Eval Loss:  0.18732640147209167\n",
      "Eval Loss:  0.21931204199790955\n",
      "Eval Loss:  0.20201840996742249\n",
      "Eval Loss:  0.22028177976608276\n",
      "Eval Loss:  0.23803094029426575\n",
      "[[17635  1099]\n",
      " [ 1486  9577]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18734\n",
      "           1       0.90      0.87      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9132462999630835\n",
      "pre:  0.8970588235294118\n",
      "rec:  0.8656783874175179\n",
      "ma F1:  0.9064012011862324\n",
      "mi F1:  0.9132462999630835\n",
      "we F1:  0.9129175517344112\n",
      "29797 466\n",
      "Loss:  0.05357721075415611\n",
      "Loss:  0.06085483357310295\n",
      "Loss:  0.06966883689165115\n",
      "51 **********\n",
      "Epoch:  2772.0780267715454  fold:  2  kers:  32\n",
      "epoch:  52\n",
      "29797 466\n",
      "Loss:  0.0980461910367012\n",
      "Loss:  0.04181944206357002\n",
      "Loss:  0.05103544890880585\n",
      "52 **********\n",
      "Epoch:  2812.6385765075684  fold:  2  kers:  32\n",
      "epoch:  53\n",
      "29797 466\n",
      "Loss:  0.07110834866762161\n",
      "Loss:  0.07241726666688919\n",
      "Loss:  0.07870073616504669\n",
      "53 **********\n",
      "Epoch:  2853.1043791770935  fold:  2  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.6690547466278076\n",
      "Eval Loss:  0.2773817777633667\n",
      "Eval Loss:  0.4532918930053711\n",
      "[[1207  223]\n",
      " [ 496 1168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      1430\n",
      "           1       0.84      0.70      0.76      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.77      0.77      0.77      3094\n",
      "weighted avg       0.78      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7676147382029735\n",
      "pre:  0.8396836808051761\n",
      "rec:  0.7019230769230769\n",
      "ma F1:  0.7675778093187822\n",
      "mi F1:  0.7676147382029735\n",
      "we F1:  0.7673562360136346\n",
      "update!  Acc:  0.7676147382029735\n",
      "Eval Loss:  0.20754800736904144\n",
      "Eval Loss:  0.22057586908340454\n",
      "Eval Loss:  0.23243564367294312\n",
      "Eval Loss:  0.21002915501594543\n",
      "Eval Loss:  0.2907986044883728\n",
      "Eval Loss:  0.2207440286874771\n",
      "Eval Loss:  0.32135093212127686\n",
      "Eval Loss:  0.2154669463634491\n",
      "Eval Loss:  0.16918687522411346\n",
      "Eval Loss:  0.16967397928237915\n",
      "Eval Loss:  0.10259322077035904\n",
      "Eval Loss:  0.18159081041812897\n",
      "Eval Loss:  0.2651474177837372\n",
      "Eval Loss:  0.2794005274772644\n",
      "Eval Loss:  0.22148504853248596\n",
      "Eval Loss:  0.229932963848114\n",
      "Eval Loss:  0.16240529716014862\n",
      "Eval Loss:  0.21436303853988647\n",
      "Eval Loss:  0.21065083146095276\n",
      "Eval Loss:  0.14847424626350403\n",
      "Eval Loss:  0.1799030303955078\n",
      "Eval Loss:  0.24417661130428314\n",
      "Eval Loss:  0.37873131036758423\n",
      "Eval Loss:  0.17269794642925262\n",
      "Eval Loss:  0.2212170958518982\n",
      "Eval Loss:  0.18571743369102478\n",
      "Eval Loss:  0.1943780928850174\n",
      "Eval Loss:  0.2017012983560562\n",
      "Eval Loss:  0.24901096522808075\n",
      "[[17536  1198]\n",
      " [ 1399  9664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18734\n",
      "           1       0.89      0.87      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9128435748565292\n",
      "pre:  0.8897072362364206\n",
      "rec:  0.8735424387598301\n",
      "ma F1:  0.906304054645347\n",
      "mi F1:  0.9128435748565292\n",
      "we F1:  0.9126765977779663\n",
      "29797 466\n",
      "Loss:  0.04888870567083359\n",
      "Loss:  0.04404153302311897\n",
      "Loss:  0.0514356903731823\n",
      "54 **********\n",
      "Epoch:  2931.516720533371  fold:  2  kers:  32\n",
      "epoch:  55\n",
      "29797 466\n",
      "Loss:  0.06030356138944626\n",
      "Loss:  0.05653655529022217\n",
      "Loss:  0.0610790029168129\n",
      "55 **********\n",
      "Epoch:  2971.9645702838898  fold:  2  kers:  32\n",
      "epoch:  56\n",
      "29797 466\n",
      "Loss:  0.07022977620363235\n",
      "Loss:  0.06580933928489685\n",
      "Loss:  0.06694145500659943\n",
      "56 **********\n",
      "Epoch:  3012.4154136180878  fold:  2  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.6863434910774231\n",
      "Eval Loss:  0.35354378819465637\n",
      "Eval Loss:  0.3869740962982178\n",
      "[[1206  224]\n",
      " [ 500 1164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      1430\n",
      "           1       0.84      0.70      0.76      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.77      0.77      0.77      3094\n",
      "weighted avg       0.78      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7659987071751778\n",
      "pre:  0.8386167146974063\n",
      "rec:  0.6995192307692307\n",
      "ma F1:  0.7659555794794982\n",
      "mi F1:  0.7659987071751778\n",
      "we F1:  0.7657152966035694\n",
      "Eval Loss:  0.23471885919570923\n",
      "Eval Loss:  0.22213156521320343\n",
      "Eval Loss:  0.2360628992319107\n",
      "Eval Loss:  0.18042407929897308\n",
      "Eval Loss:  0.30450642108917236\n",
      "Eval Loss:  0.19738426804542542\n",
      "Eval Loss:  0.33091360330581665\n",
      "Eval Loss:  0.2137620747089386\n",
      "Eval Loss:  0.16644857823848724\n",
      "Eval Loss:  0.17375491559505463\n",
      "Eval Loss:  0.1391533762216568\n",
      "Eval Loss:  0.17993482947349548\n",
      "Eval Loss:  0.2559978663921356\n",
      "Eval Loss:  0.27429044246673584\n",
      "Eval Loss:  0.22932523488998413\n",
      "Eval Loss:  0.23772792518138885\n",
      "Eval Loss:  0.15221932530403137\n",
      "Eval Loss:  0.22845463454723358\n",
      "Eval Loss:  0.20423270761966705\n",
      "Eval Loss:  0.14436204731464386\n",
      "Eval Loss:  0.17461149394512177\n",
      "Eval Loss:  0.22363808751106262\n",
      "Eval Loss:  0.37274742126464844\n",
      "Eval Loss:  0.198177769780159\n",
      "Eval Loss:  0.17967617511749268\n",
      "Eval Loss:  0.22985930740833282\n",
      "Eval Loss:  0.1982029527425766\n",
      "Eval Loss:  0.21000726521015167\n",
      "Eval Loss:  0.27215540409088135\n",
      "[[17787   947]\n",
      " [ 1577  9486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18734\n",
      "           1       0.91      0.86      0.88     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.92      0.92      0.91     29797\n",
      "\n",
      "acc:  0.9152934859214015\n",
      "pre:  0.9092303268475032\n",
      "rec:  0.8574527704962488\n",
      "ma F1:  0.9081663046213668\n",
      "mi F1:  0.9152934859214015\n",
      "we F1:  0.914752572270152\n",
      "29797 466\n",
      "Loss:  0.0637737587094307\n",
      "Loss:  0.0778801217675209\n",
      "Loss:  0.0952877476811409\n",
      "57 **********\n",
      "Epoch:  3090.906544446945  fold:  2  kers:  32\n",
      "epoch:  58\n",
      "29797 466\n",
      "Loss:  0.04704267159104347\n",
      "Loss:  0.04791943356394768\n",
      "Loss:  0.052052613347768784\n",
      "58 **********\n",
      "Epoch:  3131.3234770298004  fold:  2  kers:  32\n",
      "epoch:  59\n",
      "29797 466\n",
      "Loss:  0.06627530604600906\n",
      "Loss:  0.09138355404138565\n",
      "Loss:  0.05958975479006767\n",
      "59 **********\n",
      "Epoch:  3171.8461277484894  fold:  2  kers:  32\n",
      "Eval Loss:  0.596065104007721\n",
      "Eval Loss:  0.4695626497268677\n",
      "Eval Loss:  0.49810922145843506\n",
      "[[1108  322]\n",
      " [ 401 1263]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75      1430\n",
      "           1       0.80      0.76      0.78      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.77      0.77      0.77      3094\n",
      "weighted avg       0.77      0.77      0.77      3094\n",
      "\n",
      "acc:  0.766321913380737\n",
      "pre:  0.7968454258675078\n",
      "rec:  0.7590144230769231\n",
      "ma F1:  0.7657339746278359\n",
      "mi F1:  0.7663219133807371\n",
      "we F1:  0.7666215724870542\n",
      "update!  Acc:  0.7676147382029735\n",
      "Epoch:  3175.409600019455  fold:  2  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.1675872653722763\n",
      "Loss:  0.1671246588230133\n",
      "Loss:  0.15941473841667175\n",
      "0 **********\n",
      "Epoch:  52.67814922332764  fold:  3  kers:  32\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.14541420340538025\n",
      "Loss:  0.1323988288640976\n",
      "Loss:  0.11256350576877594\n",
      "1 **********\n",
      "Epoch:  92.92553520202637  fold:  3  kers:  32\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.13562969863414764\n",
      "Loss:  0.11308057606220245\n",
      "Loss:  0.10611945390701294\n",
      "2 **********\n",
      "Epoch:  133.18788170814514  fold:  3  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.7272236347198486\n",
      "Eval Loss:  0.673554003238678\n",
      "Eval Loss:  0.3889491558074951\n",
      "[[1270  266]\n",
      " [ 473 1422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.77      1536\n",
      "           1       0.84      0.75      0.79      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.79      0.79      0.78      3431\n",
      "weighted avg       0.79      0.78      0.79      3431\n",
      "\n",
      "acc:  0.7846109006120664\n",
      "pre:  0.8424170616113744\n",
      "rec:  0.7503957783641161\n",
      "ma F1:  0.7841873330713458\n",
      "mi F1:  0.7846109006120663\n",
      "we F1:  0.7851877327234422\n",
      "update!  Acc:  0.7846109006120664\n",
      "Eval Loss:  0.32793569564819336\n",
      "Eval Loss:  0.4034428000450134\n",
      "Eval Loss:  0.3594297766685486\n",
      "Eval Loss:  0.4607536494731903\n",
      "Eval Loss:  0.37275075912475586\n",
      "Eval Loss:  0.4850578010082245\n",
      "Eval Loss:  0.26667389273643494\n",
      "Eval Loss:  0.4534704089164734\n",
      "Eval Loss:  0.3045838177204132\n",
      "Eval Loss:  0.46652889251708984\n",
      "Eval Loss:  0.31818869709968567\n",
      "Eval Loss:  0.3524129092693329\n",
      "Eval Loss:  0.3415229618549347\n",
      "Eval Loss:  0.3866574168205261\n",
      "Eval Loss:  0.3831197917461395\n",
      "Eval Loss:  0.4214899241924286\n",
      "Eval Loss:  0.3265979290008545\n",
      "Eval Loss:  0.42784416675567627\n",
      "Eval Loss:  0.45601552724838257\n",
      "Eval Loss:  0.3979637324810028\n",
      "Eval Loss:  0.4405755400657654\n",
      "Eval Loss:  0.34709903597831726\n",
      "Eval Loss:  0.38487255573272705\n",
      "Eval Loss:  0.3515453636646271\n",
      "Eval Loss:  0.3681463599205017\n",
      "Eval Loss:  0.34486302733421326\n",
      "Eval Loss:  0.4522048234939575\n",
      "Eval Loss:  0.42639032006263733\n",
      "[[16219  2409]\n",
      " [ 2520  8312]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87     18628\n",
      "           1       0.78      0.77      0.77     10832\n",
      "\n",
      "    accuracy                           0.83     29460\n",
      "   macro avg       0.82      0.82      0.82     29460\n",
      "weighted avg       0.83      0.83      0.83     29460\n",
      "\n",
      "acc:  0.8326883910386965\n",
      "pre:  0.7753008114914653\n",
      "rec:  0.7673559822747416\n",
      "ma F1:  0.8197000527276281\n",
      "mi F1:  0.8326883910386965\n",
      "we F1:  0.8325060582256791\n",
      "29460 461\n",
      "Loss:  0.0913853570818901\n",
      "Loss:  0.09231675416231155\n",
      "Loss:  0.09246964752674103\n",
      "3 **********\n",
      "Epoch:  211.69895911216736  fold:  3  kers:  32\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.09742888808250427\n",
      "Loss:  0.10903345048427582\n",
      "Loss:  0.07529537379741669\n",
      "4 **********\n",
      "Epoch:  251.94834160804749  fold:  3  kers:  32\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.0857723280787468\n",
      "Loss:  0.10193999856710434\n",
      "Loss:  0.08853364735841751\n",
      "5 **********\n",
      "Epoch:  292.27351927757263  fold:  3  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.9962058067321777\n",
      "Eval Loss:  0.6304603815078735\n",
      "Eval Loss:  0.590947687625885\n",
      "[[1413  123]\n",
      " [ 671 1224]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.78      1536\n",
      "           1       0.91      0.65      0.76      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.78      0.77      3431\n",
      "weighted avg       0.81      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7685805887496356\n",
      "pre:  0.9086859688195991\n",
      "rec:  0.645910290237467\n",
      "ma F1:  0.7678762171908071\n",
      "mi F1:  0.7685805887496356\n",
      "we F1:  0.7665382839123973\n",
      "Eval Loss:  0.3292950391769409\n",
      "Eval Loss:  0.3607634902000427\n",
      "Eval Loss:  0.3927929401397705\n",
      "Eval Loss:  0.40316706895828247\n",
      "Eval Loss:  0.41725900769233704\n",
      "Eval Loss:  0.47674253582954407\n",
      "Eval Loss:  0.2255484163761139\n",
      "Eval Loss:  0.4645291268825531\n",
      "Eval Loss:  0.28376084566116333\n",
      "Eval Loss:  0.47316527366638184\n",
      "Eval Loss:  0.30273422598838806\n",
      "Eval Loss:  0.39011871814727783\n",
      "Eval Loss:  0.3729938566684723\n",
      "Eval Loss:  0.32394126057624817\n",
      "Eval Loss:  0.43658387660980225\n",
      "Eval Loss:  0.38559648394584656\n",
      "Eval Loss:  0.34108880162239075\n",
      "Eval Loss:  0.3797141909599304\n",
      "Eval Loss:  0.4658551812171936\n",
      "Eval Loss:  0.4079238176345825\n",
      "Eval Loss:  0.4572902321815491\n",
      "Eval Loss:  0.3348408341407776\n",
      "Eval Loss:  0.39820045232772827\n",
      "Eval Loss:  0.3290800452232361\n",
      "Eval Loss:  0.3876926302909851\n",
      "Eval Loss:  0.31291747093200684\n",
      "Eval Loss:  0.4387191832065582\n",
      "Eval Loss:  0.5174267888069153\n",
      "[[17764   864]\n",
      " [ 3610  7222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     18628\n",
      "           1       0.89      0.67      0.76     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.86      0.81      0.83     29460\n",
      "weighted avg       0.85      0.85      0.84     29460\n",
      "\n",
      "acc:  0.848133061778683\n",
      "pre:  0.8931486519910957\n",
      "rec:  0.6667282127031019\n",
      "ma F1:  0.8258306241046971\n",
      "mi F1:  0.848133061778683\n",
      "we F1:  0.8423236808402684\n",
      "29460 461\n",
      "Loss:  0.09212429821491241\n",
      "Loss:  0.11477555334568024\n",
      "Loss:  0.07052300125360489\n",
      "6 **********\n",
      "Epoch:  370.7187728881836  fold:  3  kers:  32\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.10907153785228729\n",
      "Loss:  0.10825435817241669\n",
      "Loss:  0.07052470743656158\n",
      "7 **********\n",
      "Epoch:  410.85944414138794  fold:  3  kers:  32\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.06883975118398666\n",
      "Loss:  0.10304046422243118\n",
      "Loss:  0.08061481267213821\n",
      "8 **********\n",
      "Epoch:  451.05796122550964  fold:  3  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  1.0610427856445312\n",
      "Eval Loss:  0.5443219542503357\n",
      "Eval Loss:  0.5987956523895264\n",
      "[[1430  106]\n",
      " [ 699 1196]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.93      0.78      1536\n",
      "           1       0.92      0.63      0.75      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.80      0.78      0.76      3431\n",
      "weighted avg       0.81      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7653745263771495\n",
      "pre:  0.9185867895545314\n",
      "rec:  0.6311345646437995\n",
      "ma F1:  0.7642780727668887\n",
      "mi F1:  0.7653745263771495\n",
      "we F1:  0.7625959067579846\n",
      "Eval Loss:  0.32356923818588257\n",
      "Eval Loss:  0.36494210362434387\n",
      "Eval Loss:  0.38309985399246216\n",
      "Eval Loss:  0.39770761132240295\n",
      "Eval Loss:  0.41801342368125916\n",
      "Eval Loss:  0.46491605043411255\n",
      "Eval Loss:  0.2137136161327362\n",
      "Eval Loss:  0.45155104994773865\n",
      "Eval Loss:  0.293986976146698\n",
      "Eval Loss:  0.46875354647636414\n",
      "Eval Loss:  0.30241990089416504\n",
      "Eval Loss:  0.3925797939300537\n",
      "Eval Loss:  0.3854467272758484\n",
      "Eval Loss:  0.3186469078063965\n",
      "Eval Loss:  0.4332481324672699\n",
      "Eval Loss:  0.3876519799232483\n",
      "Eval Loss:  0.338456392288208\n",
      "Eval Loss:  0.360886812210083\n",
      "Eval Loss:  0.46792876720428467\n",
      "Eval Loss:  0.4093635380268097\n",
      "Eval Loss:  0.42890727519989014\n",
      "Eval Loss:  0.3342519700527191\n",
      "Eval Loss:  0.40844637155532837\n",
      "Eval Loss:  0.3208354413509369\n",
      "Eval Loss:  0.39443859457969666\n",
      "Eval Loss:  0.31265416741371155\n",
      "Eval Loss:  0.42473137378692627\n",
      "Eval Loss:  0.5335780382156372\n",
      "[[17962   666]\n",
      " [ 3729  7103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18628\n",
      "           1       0.91      0.66      0.76     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.87      0.81      0.83     29460\n",
      "weighted avg       0.86      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8508146639511202\n",
      "pre:  0.914274681426181\n",
      "rec:  0.6557422451994092\n",
      "ma F1:  0.8273583504064094\n",
      "mi F1:  0.8508146639511202\n",
      "we F1:  0.8441983375502131\n",
      "29460 461\n",
      "Loss:  0.09079909324645996\n",
      "Loss:  0.08053435385227203\n",
      "Loss:  0.07406890392303467\n",
      "9 **********\n",
      "Epoch:  529.5411162376404  fold:  3  kers:  32\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.08209024369716644\n",
      "Loss:  0.11919476836919785\n",
      "Loss:  0.07541096955537796\n",
      "10 **********\n",
      "Epoch:  569.7555885314941  fold:  3  kers:  32\n",
      "epoch:  11\n",
      "29460 461\n",
      "Loss:  0.1092744991183281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07455454766750336\n",
      "Loss:  0.12604494392871857\n",
      "11 **********\n",
      "Epoch:  610.1705274581909  fold:  3  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.7934590578079224\n",
      "Eval Loss:  0.2689953148365021\n",
      "Eval Loss:  0.5806889533996582\n",
      "[[1345  191]\n",
      " [ 551 1344]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.78      1536\n",
      "           1       0.88      0.71      0.78      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.79      0.79      0.78      3431\n",
      "weighted avg       0.80      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7837365199650248\n",
      "pre:  0.8755700325732899\n",
      "rec:  0.7092348284960422\n",
      "ma F1:  0.7837365015936444\n",
      "mi F1:  0.7837365199650248\n",
      "we F1:  0.7837299062681083\n",
      "Eval Loss:  0.24444381892681122\n",
      "Eval Loss:  0.2892440855503082\n",
      "Eval Loss:  0.3346048593521118\n",
      "Eval Loss:  0.3058546781539917\n",
      "Eval Loss:  0.3655315935611725\n",
      "Eval Loss:  0.3961889445781708\n",
      "Eval Loss:  0.1646624356508255\n",
      "Eval Loss:  0.34586790204048157\n",
      "Eval Loss:  0.22370721399784088\n",
      "Eval Loss:  0.34822022914886475\n",
      "Eval Loss:  0.2702782154083252\n",
      "Eval Loss:  0.3219720721244812\n",
      "Eval Loss:  0.3054402470588684\n",
      "Eval Loss:  0.27722683548927307\n",
      "Eval Loss:  0.34492117166519165\n",
      "Eval Loss:  0.2931949496269226\n",
      "Eval Loss:  0.28034067153930664\n",
      "Eval Loss:  0.29913878440856934\n",
      "Eval Loss:  0.38696929812431335\n",
      "Eval Loss:  0.3439999520778656\n",
      "Eval Loss:  0.3178267776966095\n",
      "Eval Loss:  0.28867509961128235\n",
      "Eval Loss:  0.35093188285827637\n",
      "Eval Loss:  0.26929330825805664\n",
      "Eval Loss:  0.28915712237358093\n",
      "Eval Loss:  0.23039202392101288\n",
      "Eval Loss:  0.333322674036026\n",
      "Eval Loss:  0.4702068567276001\n",
      "[[17571  1057]\n",
      " [ 2692  8140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     18628\n",
      "           1       0.89      0.75      0.81     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.85      0.86     29460\n",
      "weighted avg       0.87      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8727427019687712\n",
      "pre:  0.8850712188757204\n",
      "rec:  0.7514771048744461\n",
      "ma F1:  0.8582118924140183\n",
      "mi F1:  0.8727427019687712\n",
      "we F1:  0.8702235763593956\n",
      "29460 461\n",
      "Loss:  0.08696804195642471\n",
      "Loss:  0.052665747702121735\n",
      "Loss:  0.09463586658239365\n",
      "12 **********\n",
      "Epoch:  688.5599296092987  fold:  3  kers:  32\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.08082612603902817\n",
      "Loss:  0.07450055330991745\n",
      "Loss:  0.09450175613164902\n",
      "13 **********\n",
      "Epoch:  728.6547243595123  fold:  3  kers:  32\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.06868866086006165\n",
      "Loss:  0.11154977232217789\n",
      "Loss:  0.08146658539772034\n",
      "14 **********\n",
      "Epoch:  768.7275774478912  fold:  3  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.8697171211242676\n",
      "Eval Loss:  0.2696635127067566\n",
      "Eval Loss:  0.6194792985916138\n",
      "[[1362  174]\n",
      " [ 590 1305]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.78      1536\n",
      "           1       0.88      0.69      0.77      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.79      0.79      0.78      3431\n",
      "weighted avg       0.80      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7773243952200525\n",
      "pre:  0.8823529411764706\n",
      "rec:  0.6886543535620053\n",
      "ma F1:  0.7772629199001537\n",
      "mi F1:  0.7773243952200525\n",
      "we F1:  0.7768757332362313\n",
      "Eval Loss:  0.26018545031547546\n",
      "Eval Loss:  0.3002818524837494\n",
      "Eval Loss:  0.3204967975616455\n",
      "Eval Loss:  0.30989909172058105\n",
      "Eval Loss:  0.3729732632637024\n",
      "Eval Loss:  0.37230390310287476\n",
      "Eval Loss:  0.1571267545223236\n",
      "Eval Loss:  0.35808148980140686\n",
      "Eval Loss:  0.2298130840063095\n",
      "Eval Loss:  0.3434772789478302\n",
      "Eval Loss:  0.2611539363861084\n",
      "Eval Loss:  0.3253933787345886\n",
      "Eval Loss:  0.31570354104042053\n",
      "Eval Loss:  0.26646915078163147\n",
      "Eval Loss:  0.33830294013023376\n",
      "Eval Loss:  0.29923126101493835\n",
      "Eval Loss:  0.2844695448875427\n",
      "Eval Loss:  0.2796224355697632\n",
      "Eval Loss:  0.39832544326782227\n",
      "Eval Loss:  0.33762767910957336\n",
      "Eval Loss:  0.31362953782081604\n",
      "Eval Loss:  0.28487759828567505\n",
      "Eval Loss:  0.35140469670295715\n",
      "Eval Loss:  0.26083481311798096\n",
      "Eval Loss:  0.2885590195655823\n",
      "Eval Loss:  0.22556017339229584\n",
      "Eval Loss:  0.34769997000694275\n",
      "Eval Loss:  0.46551698446273804\n",
      "[[17777   851]\n",
      " [ 2872  7960]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91     18628\n",
      "           1       0.90      0.73      0.81     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.84      0.86     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8736252545824847\n",
      "pre:  0.9034161843150608\n",
      "rec:  0.7348596750369276\n",
      "ma F1:  0.8578392672365924\n",
      "mi F1:  0.8736252545824849\n",
      "we F1:  0.8703754348385662\n",
      "29460 461\n",
      "Loss:  0.07025071978569031\n",
      "Loss:  0.08040907233953476\n",
      "Loss:  0.05845945328474045\n",
      "15 **********\n",
      "Epoch:  846.6372632980347  fold:  3  kers:  32\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.060982637107372284\n",
      "Loss:  0.07589762657880783\n",
      "Loss:  0.08789294958114624\n",
      "16 **********\n",
      "Epoch:  886.6811935901642  fold:  3  kers:  32\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.05449528247117996\n",
      "Loss:  0.0780135840177536\n",
      "Loss:  0.06829804182052612\n",
      "17 **********\n",
      "Epoch:  926.7360949516296  fold:  3  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.8579656481742859\n",
      "Eval Loss:  0.28332915902137756\n",
      "Eval Loss:  0.7051348686218262\n",
      "[[1343  193]\n",
      " [ 616 1279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77      1536\n",
      "           1       0.87      0.67      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.77      0.76      3431\n",
      "weighted avg       0.79      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7642086855144273\n",
      "pre:  0.8688858695652174\n",
      "rec:  0.674934036939314\n",
      "ma F1:  0.7641266130536517\n",
      "mi F1:  0.7642086855144273\n",
      "we F1:  0.7636662378439886\n",
      "Eval Loss:  0.28616008162498474\n",
      "Eval Loss:  0.30348774790763855\n",
      "Eval Loss:  0.33587440848350525\n",
      "Eval Loss:  0.3165517747402191\n",
      "Eval Loss:  0.3781864643096924\n",
      "Eval Loss:  0.37284472584724426\n",
      "Eval Loss:  0.1512109637260437\n",
      "Eval Loss:  0.37875932455062866\n",
      "Eval Loss:  0.21126237511634827\n",
      "Eval Loss:  0.32659074664115906\n",
      "Eval Loss:  0.25986945629119873\n",
      "Eval Loss:  0.32491135597229004\n",
      "Eval Loss:  0.3174695372581482\n",
      "Eval Loss:  0.24364084005355835\n",
      "Eval Loss:  0.3318936228752136\n",
      "Eval Loss:  0.32499265670776367\n",
      "Eval Loss:  0.2839118540287018\n",
      "Eval Loss:  0.2857740819454193\n",
      "Eval Loss:  0.3949211835861206\n",
      "Eval Loss:  0.3271237015724182\n",
      "Eval Loss:  0.3362826108932495\n",
      "Eval Loss:  0.2822872996330261\n",
      "Eval Loss:  0.3558236062526703\n",
      "Eval Loss:  0.26578181982040405\n",
      "Eval Loss:  0.2863915264606476\n",
      "Eval Loss:  0.22307279706001282\n",
      "Eval Loss:  0.352953165769577\n",
      "Eval Loss:  0.45262014865875244\n",
      "[[17839   789]\n",
      " [ 2967  7865]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.90     18628\n",
      "           1       0.91      0.73      0.81     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.84      0.86     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8725050916496945\n",
      "pre:  0.9088282874971112\n",
      "rec:  0.7260893648449039\n",
      "ma F1:  0.8559992361586989\n",
      "mi F1:  0.8725050916496945\n",
      "we F1:  0.8689007450225251\n",
      "29460 461\n",
      "Loss:  0.09824264794588089\n",
      "Loss:  0.06821098178625107\n",
      "Loss:  0.07347600907087326\n",
      "18 **********\n",
      "Epoch:  1004.668719291687  fold:  3  kers:  32\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.1285083144903183\n",
      "Loss:  0.07300473749637604\n",
      "Loss:  0.07202547788619995\n",
      "19 **********\n",
      "Epoch:  1044.7655081748962  fold:  3  kers:  32\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.09002683311700821\n",
      "Loss:  0.08525219559669495\n",
      "Loss:  0.08977225422859192\n",
      "20 **********\n",
      "Epoch:  1084.760570049286  fold:  3  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.5848941206932068\n",
      "Eval Loss:  0.20826637744903564\n",
      "Eval Loss:  0.6810479760169983\n",
      "[[1248  288]\n",
      " [ 498 1397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1536\n",
      "           1       0.83      0.74      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7709122704750802\n",
      "pre:  0.829080118694362\n",
      "rec:  0.737203166226913\n",
      "ma F1:  0.7704794051862368\n",
      "mi F1:  0.77091227047508\n",
      "we F1:  0.7715223490700944\n",
      "Eval Loss:  0.21960197389125824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2504448890686035\n",
      "Eval Loss:  0.3105735182762146\n",
      "Eval Loss:  0.2552885413169861\n",
      "Eval Loss:  0.3463059365749359\n",
      "Eval Loss:  0.3413129150867462\n",
      "Eval Loss:  0.13514173030853271\n",
      "Eval Loss:  0.32195836305618286\n",
      "Eval Loss:  0.1625760793685913\n",
      "Eval Loss:  0.2798215448856354\n",
      "Eval Loss:  0.25691068172454834\n",
      "Eval Loss:  0.2526373565196991\n",
      "Eval Loss:  0.2515827715396881\n",
      "Eval Loss:  0.2653181552886963\n",
      "Eval Loss:  0.27317410707473755\n",
      "Eval Loss:  0.2689102292060852\n",
      "Eval Loss:  0.26551175117492676\n",
      "Eval Loss:  0.2586556375026703\n",
      "Eval Loss:  0.3646198809146881\n",
      "Eval Loss:  0.29842373728752136\n",
      "Eval Loss:  0.2686706781387329\n",
      "Eval Loss:  0.26563411951065063\n",
      "Eval Loss:  0.3168564736843109\n",
      "Eval Loss:  0.23834440112113953\n",
      "Eval Loss:  0.22239509224891663\n",
      "Eval Loss:  0.1877276450395584\n",
      "Eval Loss:  0.2945851683616638\n",
      "Eval Loss:  0.40614378452301025\n",
      "[[17277  1351]\n",
      " [ 1961  8871]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     18628\n",
      "           1       0.87      0.82      0.84     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.88      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8875763747454175\n",
      "pre:  0.8678340833496381\n",
      "rec:  0.8189623338257016\n",
      "ma F1:  0.87761194825141\n",
      "mi F1:  0.8875763747454175\n",
      "we F1:  0.8868532840766875\n",
      "29460 461\n",
      "Loss:  0.08529001474380493\n",
      "Loss:  0.08009450137615204\n",
      "Loss:  0.07348162680864334\n",
      "21 **********\n",
      "Epoch:  1162.8328206539154  fold:  3  kers:  32\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.08480407297611237\n",
      "Loss:  0.07894737273454666\n",
      "Loss:  0.06698700040578842\n",
      "22 **********\n",
      "Epoch:  1202.9645161628723  fold:  3  kers:  32\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.0693744644522667\n",
      "Loss:  0.03746987506747246\n",
      "Loss:  0.09122248739004135\n",
      "23 **********\n",
      "Epoch:  1243.710569858551  fold:  3  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.9320890307426453\n",
      "Eval Loss:  0.24837353825569153\n",
      "Eval Loss:  0.7439019680023193\n",
      "[[1337  199]\n",
      " [ 622 1273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.77      1536\n",
      "           1       0.86      0.67      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7607111629262606\n",
      "pre:  0.8648097826086957\n",
      "rec:  0.6717678100263852\n",
      "ma F1:  0.7606278730742251\n",
      "mi F1:  0.7607111629262606\n",
      "we F1:  0.7601606690604631\n",
      "Eval Loss:  0.27156034111976624\n",
      "Eval Loss:  0.26626870036125183\n",
      "Eval Loss:  0.2961745858192444\n",
      "Eval Loss:  0.30876022577285767\n",
      "Eval Loss:  0.36944660544395447\n",
      "Eval Loss:  0.3280048072338104\n",
      "Eval Loss:  0.14254309237003326\n",
      "Eval Loss:  0.35563230514526367\n",
      "Eval Loss:  0.21206732094287872\n",
      "Eval Loss:  0.3104313611984253\n",
      "Eval Loss:  0.24481533467769623\n",
      "Eval Loss:  0.2929478883743286\n",
      "Eval Loss:  0.289826363325119\n",
      "Eval Loss:  0.24939975142478943\n",
      "Eval Loss:  0.28918662667274475\n",
      "Eval Loss:  0.31057530641555786\n",
      "Eval Loss:  0.29199865460395813\n",
      "Eval Loss:  0.25032708048820496\n",
      "Eval Loss:  0.36994150280952454\n",
      "Eval Loss:  0.3003748953342438\n",
      "Eval Loss:  0.28148964047431946\n",
      "Eval Loss:  0.2641499638557434\n",
      "Eval Loss:  0.3293526768684387\n",
      "Eval Loss:  0.2535044848918915\n",
      "Eval Loss:  0.25382286310195923\n",
      "Eval Loss:  0.1920127123594284\n",
      "Eval Loss:  0.3307306468486786\n",
      "Eval Loss:  0.43140116333961487\n",
      "[[17934   694]\n",
      " [ 2825  8007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18628\n",
      "           1       0.92      0.74      0.82     10832\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.85      0.87     29460\n",
      "weighted avg       0.88      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8805498981670061\n",
      "pre:  0.9202390529824158\n",
      "rec:  0.739198670605613\n",
      "ma F1:  0.8652495710868273\n",
      "mi F1:  0.8805498981670061\n",
      "we F1:  0.877265421788658\n",
      "29460 461\n",
      "Loss:  0.06810855120420456\n",
      "Loss:  0.06270578503608704\n",
      "Loss:  0.0504787378013134\n",
      "24 **********\n",
      "Epoch:  1322.0620737075806  fold:  3  kers:  32\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.07283259183168411\n",
      "Loss:  0.0783722922205925\n",
      "Loss:  0.06051865965127945\n",
      "25 **********\n",
      "Epoch:  1362.2027461528778  fold:  3  kers:  32\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.08408477157354355\n",
      "Loss:  0.09833501279354095\n",
      "Loss:  0.06003166362643242\n",
      "26 **********\n",
      "Epoch:  1402.3863031864166  fold:  3  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.7318990230560303\n",
      "Eval Loss:  0.20864655077457428\n",
      "Eval Loss:  0.797107458114624\n",
      "[[1286  250]\n",
      " [ 567 1328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1536\n",
      "           1       0.84      0.70      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7618770037889828\n",
      "pre:  0.8415716096324461\n",
      "rec:  0.7007915567282322\n",
      "ma F1:  0.7618413156774806\n",
      "mi F1:  0.7618770037889828\n",
      "we F1:  0.76214636405913\n",
      "Eval Loss:  0.26208916306495667\n",
      "Eval Loss:  0.23832322657108307\n",
      "Eval Loss:  0.2958422005176544\n",
      "Eval Loss:  0.27953195571899414\n",
      "Eval Loss:  0.3370804786682129\n",
      "Eval Loss:  0.3028395175933838\n",
      "Eval Loss:  0.1283407360315323\n",
      "Eval Loss:  0.3354070782661438\n",
      "Eval Loss:  0.17984147369861603\n",
      "Eval Loss:  0.26218608021736145\n",
      "Eval Loss:  0.23599764704704285\n",
      "Eval Loss:  0.26000627875328064\n",
      "Eval Loss:  0.2615375220775604\n",
      "Eval Loss:  0.23909835517406464\n",
      "Eval Loss:  0.2506489157676697\n",
      "Eval Loss:  0.28465908765792847\n",
      "Eval Loss:  0.2745751738548279\n",
      "Eval Loss:  0.23911523818969727\n",
      "Eval Loss:  0.34158122539520264\n",
      "Eval Loss:  0.2785463333129883\n",
      "Eval Loss:  0.25319281220436096\n",
      "Eval Loss:  0.2519925534725189\n",
      "Eval Loss:  0.3054213523864746\n",
      "Eval Loss:  0.23444733023643494\n",
      "Eval Loss:  0.2159777283668518\n",
      "Eval Loss:  0.17652149498462677\n",
      "Eval Loss:  0.30259668827056885\n",
      "Eval Loss:  0.4118310809135437\n",
      "[[17736   892]\n",
      " [ 2321  8511]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     18628\n",
      "           1       0.91      0.79      0.84     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8909368635437882\n",
      "pre:  0.9051366585132404\n",
      "rec:  0.7857274741506647\n",
      "ma F1:  0.8790801337483483\n",
      "mi F1:  0.8909368635437882\n",
      "we F1:  0.8891001950475624\n",
      "29460 461\n",
      "Loss:  0.07113322615623474\n",
      "Loss:  0.046575408428907394\n",
      "Loss:  0.07978761196136475\n",
      "27 **********\n",
      "Epoch:  1484.5306656360626  fold:  3  kers:  32\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.06090382859110832\n",
      "Loss:  0.05931602418422699\n",
      "Loss:  0.049539994448423386\n",
      "28 **********\n",
      "Epoch:  1524.572602033615  fold:  3  kers:  32\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.06980235129594803\n",
      "Loss:  0.05713770166039467\n",
      "Loss:  0.06195805221796036\n",
      "29 **********\n",
      "Epoch:  1564.5975832939148  fold:  3  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.7670907378196716\n",
      "Eval Loss:  0.20089082419872284\n",
      "Eval Loss:  0.8095219135284424\n",
      "[[1298  238]\n",
      " [ 568 1327]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.76      1536\n",
      "           1       0.85      0.70      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7650830661614689\n",
      "pre:  0.8479233226837061\n",
      "rec:  0.700263852242744\n",
      "ma F1:  0.765066281989853\n",
      "mi F1:  0.7650830661614688\n",
      "we F1:  0.7652740584591683\n",
      "Eval Loss:  0.25238609313964844\n",
      "Eval Loss:  0.22350682318210602\n",
      "Eval Loss:  0.2788800597190857\n",
      "Eval Loss:  0.2856822609901428\n",
      "Eval Loss:  0.338060200214386\n",
      "Eval Loss:  0.2864178419113159\n",
      "Eval Loss:  0.12994033098220825\n",
      "Eval Loss:  0.33987852931022644\n",
      "Eval Loss:  0.1824818253517151\n",
      "Eval Loss:  0.2517673671245575\n",
      "Eval Loss:  0.2299903929233551\n",
      "Eval Loss:  0.25797945261001587\n",
      "Eval Loss:  0.2522691786289215\n",
      "Eval Loss:  0.2381533980369568\n",
      "Eval Loss:  0.24334900081157684\n",
      "Eval Loss:  0.2783813774585724\n",
      "Eval Loss:  0.2706300914287567\n",
      "Eval Loss:  0.22833293676376343\n",
      "Eval Loss:  0.3307372033596039\n",
      "Eval Loss:  0.28017985820770264\n",
      "Eval Loss:  0.24274256825447083\n",
      "Eval Loss:  0.23908731341362\n",
      "Eval Loss:  0.28104063868522644\n",
      "Eval Loss:  0.23164166510105133\n",
      "Eval Loss:  0.21993820369243622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.16446027159690857\n",
      "Eval Loss:  0.3068813681602478\n",
      "Eval Loss:  0.40096840262413025\n",
      "[[17815   813]\n",
      " [ 2333  8499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18628\n",
      "           1       0.91      0.78      0.84     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8932111337406653\n",
      "pre:  0.9126932989690721\n",
      "rec:  0.7846196454948301\n",
      "ma F1:  0.8813459022416361\n",
      "mi F1:  0.8932111337406653\n",
      "we F1:  0.8912752007352419\n",
      "29460 461\n",
      "Loss:  0.05779321491718292\n",
      "Loss:  0.053357236087322235\n",
      "Loss:  0.09980518370866776\n",
      "30 **********\n",
      "Epoch:  1642.9002180099487  fold:  3  kers:  32\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.04890536144375801\n",
      "Loss:  0.05996665358543396\n",
      "Loss:  0.06593218445777893\n",
      "31 **********\n",
      "Epoch:  1683.0408897399902  fold:  3  kers:  32\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.08876468241214752\n",
      "Loss:  0.07162179052829742\n",
      "Loss:  0.07414962351322174\n",
      "32 **********\n",
      "Epoch:  1723.2414019107819  fold:  3  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.7806631326675415\n",
      "Eval Loss:  0.20559409260749817\n",
      "Eval Loss:  0.9200494885444641\n",
      "[[1296  240]\n",
      " [ 605 1290]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.84      0.75      1536\n",
      "           1       0.84      0.68      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.77      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7537161177499271\n",
      "pre:  0.8431372549019608\n",
      "rec:  0.6807387862796834\n",
      "ma F1:  0.7537153645706131\n",
      "mi F1:  0.7537161177499271\n",
      "we F1:  0.7536702993416542\n",
      "Eval Loss:  0.2528555989265442\n",
      "Eval Loss:  0.20660904049873352\n",
      "Eval Loss:  0.276119589805603\n",
      "Eval Loss:  0.28389567136764526\n",
      "Eval Loss:  0.33805814385414124\n",
      "Eval Loss:  0.2759406268596649\n",
      "Eval Loss:  0.12700648605823517\n",
      "Eval Loss:  0.3495400547981262\n",
      "Eval Loss:  0.1768149733543396\n",
      "Eval Loss:  0.2510988116264343\n",
      "Eval Loss:  0.24649304151535034\n",
      "Eval Loss:  0.2586917579174042\n",
      "Eval Loss:  0.24214592576026917\n",
      "Eval Loss:  0.2357855588197708\n",
      "Eval Loss:  0.2307700365781784\n",
      "Eval Loss:  0.28213024139404297\n",
      "Eval Loss:  0.2763119339942932\n",
      "Eval Loss:  0.2272426187992096\n",
      "Eval Loss:  0.3236355781555176\n",
      "Eval Loss:  0.2656867504119873\n",
      "Eval Loss:  0.2601716220378876\n",
      "Eval Loss:  0.23614735901355743\n",
      "Eval Loss:  0.28220367431640625\n",
      "Eval Loss:  0.22521063685417175\n",
      "Eval Loss:  0.22252324223518372\n",
      "Eval Loss:  0.1649441123008728\n",
      "Eval Loss:  0.3113047480583191\n",
      "Eval Loss:  0.3920534551143646\n",
      "[[17849   779]\n",
      " [ 2359  8473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18628\n",
      "           1       0.92      0.78      0.84     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.87      0.88     29460\n",
      "weighted avg       0.90      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8934826883910387\n",
      "pre:  0.9158019887591872\n",
      "rec:  0.7822193500738552\n",
      "ma F1:  0.8814774527476923\n",
      "mi F1:  0.8934826883910387\n",
      "we F1:  0.8914596218043827\n",
      "29460 461\n",
      "Loss:  0.0667620450258255\n",
      "Loss:  0.05374536290764809\n",
      "Loss:  0.06677171587944031\n",
      "33 **********\n",
      "Epoch:  1801.4403138160706  fold:  3  kers:  32\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.07243223488330841\n",
      "Loss:  0.08953987807035446\n",
      "Loss:  0.07818040251731873\n",
      "34 **********\n",
      "Epoch:  1841.541092634201  fold:  3  kers:  32\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.09688707441091537\n",
      "Loss:  0.05715242028236389\n",
      "Loss:  0.05089646950364113\n",
      "35 **********\n",
      "Epoch:  1881.6418709754944  fold:  3  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.6095011234283447\n",
      "Eval Loss:  0.16368694603443146\n",
      "Eval Loss:  1.0395700931549072\n",
      "[[1252  284]\n",
      " [ 544 1351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75      1536\n",
      "           1       0.83      0.71      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7586709414164966\n",
      "pre:  0.8262996941896025\n",
      "rec:  0.7129287598944591\n",
      "ma F1:  0.7584698468622577\n",
      "mi F1:  0.7586709414164966\n",
      "we F1:  0.7591990685286396\n",
      "Eval Loss:  0.20590144395828247\n",
      "Eval Loss:  0.18137934803962708\n",
      "Eval Loss:  0.2606274485588074\n",
      "Eval Loss:  0.27466219663619995\n",
      "Eval Loss:  0.30426323413848877\n",
      "Eval Loss:  0.28636810183525085\n",
      "Eval Loss:  0.11008158326148987\n",
      "Eval Loss:  0.3214409053325653\n",
      "Eval Loss:  0.16051310300827026\n",
      "Eval Loss:  0.24798734486103058\n",
      "Eval Loss:  0.23880979418754578\n",
      "Eval Loss:  0.21563582122325897\n",
      "Eval Loss:  0.20898929238319397\n",
      "Eval Loss:  0.24157238006591797\n",
      "Eval Loss:  0.2257082611322403\n",
      "Eval Loss:  0.24920852482318878\n",
      "Eval Loss:  0.2557784914970398\n",
      "Eval Loss:  0.21721313893795013\n",
      "Eval Loss:  0.291944295167923\n",
      "Eval Loss:  0.2497210055589676\n",
      "Eval Loss:  0.25006526708602905\n",
      "Eval Loss:  0.24297301471233368\n",
      "Eval Loss:  0.2778359353542328\n",
      "Eval Loss:  0.23128847777843475\n",
      "Eval Loss:  0.20958393812179565\n",
      "Eval Loss:  0.16547593474388123\n",
      "Eval Loss:  0.2841927111148834\n",
      "Eval Loss:  0.36753231287002563\n",
      "[[17622  1006]\n",
      " [ 1915  8917]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18628\n",
      "           1       0.90      0.82      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9008486082824169\n",
      "pre:  0.8986193691423965\n",
      "rec:  0.8232090103397341\n",
      "ma F1:  0.891363367477489\n",
      "mi F1:  0.9008486082824169\n",
      "we F1:  0.8998581333953773\n",
      "29460 461\n",
      "Loss:  0.022709760814905167\n",
      "Loss:  0.05682622641324997\n",
      "Loss:  0.09232263267040253\n",
      "36 **********\n",
      "Epoch:  1959.6004259586334  fold:  3  kers:  32\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.06307812035083771\n",
      "Loss:  0.07123926281929016\n",
      "Loss:  0.08337752521038055\n",
      "37 **********\n",
      "Epoch:  1999.5097172260284  fold:  3  kers:  32\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.0807068794965744\n",
      "Loss:  0.04961102083325386\n",
      "Loss:  0.09813973307609558\n",
      "38 **********\n",
      "Epoch:  2039.5995247364044  fold:  3  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.5654948353767395\n",
      "Eval Loss:  0.1691884994506836\n",
      "Eval Loss:  1.1077145338058472\n",
      "[[1238  298]\n",
      " [ 525 1370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      1536\n",
      "           1       0.82      0.72      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7601282424948994\n",
      "pre:  0.8213429256594724\n",
      "rec:  0.7229551451187335\n",
      "ma F1:  0.7597726694410754\n",
      "mi F1:  0.7601282424948994\n",
      "we F1:  0.7607397203980669\n",
      "Eval Loss:  0.22981680929660797\n",
      "Eval Loss:  0.17469185590744019\n",
      "Eval Loss:  0.26780080795288086\n",
      "Eval Loss:  0.26400911808013916\n",
      "Eval Loss:  0.30512017011642456\n",
      "Eval Loss:  0.2784196734428406\n",
      "Eval Loss:  0.11199616640806198\n",
      "Eval Loss:  0.34993138909339905\n",
      "Eval Loss:  0.15393668413162231\n",
      "Eval Loss:  0.22507545351982117\n",
      "Eval Loss:  0.246710866689682\n",
      "Eval Loss:  0.20585773885250092\n",
      "Eval Loss:  0.20356205105781555\n",
      "Eval Loss:  0.2465294450521469\n",
      "Eval Loss:  0.20444807410240173\n",
      "Eval Loss:  0.2582547664642334\n",
      "Eval Loss:  0.24961762130260468\n",
      "Eval Loss:  0.22166132926940918\n",
      "Eval Loss:  0.2879783809185028\n",
      "Eval Loss:  0.2345919907093048\n",
      "Eval Loss:  0.2410707175731659\n",
      "Eval Loss:  0.23103700578212738\n",
      "Eval Loss:  0.25074782967567444\n",
      "Eval Loss:  0.22645123302936554\n",
      "Eval Loss:  0.21712061762809753\n",
      "Eval Loss:  0.15228696167469025\n",
      "Eval Loss:  0.27522143721580505\n",
      "Eval Loss:  0.36303532123565674\n",
      "[[17520  1108]\n",
      " [ 1762  9070]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     18628\n",
      "           1       0.89      0.84      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9025797691785472\n",
      "pre:  0.891137748084103\n",
      "rec:  0.8373338257016248\n",
      "ma F1:  0.8938463815763456\n",
      "mi F1:  0.9025797691785472\n",
      "we F1:  0.9019038359842466\n",
      "29460 461\n",
      "Loss:  0.054924480617046356\n",
      "Loss:  0.06773456186056137\n",
      "Loss:  0.06026489660143852\n",
      "39 **********\n",
      "Epoch:  2117.429423570633  fold:  3  kers:  32\n",
      "epoch:  40\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05869140475988388\n",
      "Loss:  0.05794068053364754\n",
      "Loss:  0.08473675698041916\n",
      "40 **********\n",
      "Epoch:  2157.471359014511  fold:  3  kers:  32\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.06119399145245552\n",
      "Loss:  0.06694485992193222\n",
      "Loss:  0.07815401256084442\n",
      "41 **********\n",
      "Epoch:  2197.483375310898  fold:  3  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.6846288442611694\n",
      "Eval Loss:  0.16337396204471588\n",
      "Eval Loss:  1.0725332498550415\n",
      "[[1264  272]\n",
      " [ 529 1366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76      1536\n",
      "           1       0.83      0.72      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7665403672398717\n",
      "pre:  0.833943833943834\n",
      "rec:  0.720844327176781\n",
      "ma F1:  0.7663338507622888\n",
      "mi F1:  0.7665403672398717\n",
      "we F1:  0.7670607077765271\n",
      "Eval Loss:  0.21040578186511993\n",
      "Eval Loss:  0.15167979896068573\n",
      "Eval Loss:  0.2509351372718811\n",
      "Eval Loss:  0.2659391164779663\n",
      "Eval Loss:  0.3016647398471832\n",
      "Eval Loss:  0.28204864263534546\n",
      "Eval Loss:  0.10922442376613617\n",
      "Eval Loss:  0.3375433087348938\n",
      "Eval Loss:  0.15003769099712372\n",
      "Eval Loss:  0.22478629648685455\n",
      "Eval Loss:  0.23430128395557404\n",
      "Eval Loss:  0.218161478638649\n",
      "Eval Loss:  0.2128596305847168\n",
      "Eval Loss:  0.23804941773414612\n",
      "Eval Loss:  0.2064938098192215\n",
      "Eval Loss:  0.24478261172771454\n",
      "Eval Loss:  0.2385721057653427\n",
      "Eval Loss:  0.21417559683322906\n",
      "Eval Loss:  0.29728883504867554\n",
      "Eval Loss:  0.2426547110080719\n",
      "Eval Loss:  0.2311616986989975\n",
      "Eval Loss:  0.21903733909130096\n",
      "Eval Loss:  0.2493365854024887\n",
      "Eval Loss:  0.21240970492362976\n",
      "Eval Loss:  0.22684107720851898\n",
      "Eval Loss:  0.13524648547172546\n",
      "Eval Loss:  0.27047619223594666\n",
      "Eval Loss:  0.3386406898498535\n",
      "[[17647   981]\n",
      " [ 1790  9042]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.90      0.83      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9059402579769179\n",
      "pre:  0.9021251122418438\n",
      "rec:  0.8347488921713442\n",
      "ma F1:  0.8971668261802681\n",
      "mi F1:  0.9059402579769179\n",
      "we F1:  0.9051154228434501\n",
      "29460 461\n",
      "Loss:  0.05566427856683731\n",
      "Loss:  0.04867440462112427\n",
      "Loss:  0.09798973798751831\n",
      "42 **********\n",
      "Epoch:  2275.2713854312897  fold:  3  kers:  32\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.07288965582847595\n",
      "Loss:  0.06619314849376678\n",
      "Loss:  0.07285629957914352\n",
      "43 **********\n",
      "Epoch:  2315.34822845459  fold:  3  kers:  32\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.05719943344593048\n",
      "Loss:  0.07803775370121002\n",
      "Loss:  0.06855815649032593\n",
      "44 **********\n",
      "Epoch:  2355.3422923088074  fold:  3  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.6195975542068481\n",
      "Eval Loss:  0.12981094419956207\n",
      "Eval Loss:  1.2200530767440796\n",
      "[[1259  277]\n",
      " [ 539 1356]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76      1536\n",
      "           1       0.83      0.72      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7621684640046633\n",
      "pre:  0.8303735456215554\n",
      "rec:  0.7155672823218997\n",
      "ma F1:  0.7619782166015776\n",
      "mi F1:  0.7621684640046633\n",
      "we F1:  0.7626823281243382\n",
      "Eval Loss:  0.19903340935707092\n",
      "Eval Loss:  0.14863300323486328\n",
      "Eval Loss:  0.26525813341140747\n",
      "Eval Loss:  0.2919127941131592\n",
      "Eval Loss:  0.3092419505119324\n",
      "Eval Loss:  0.2825429439544678\n",
      "Eval Loss:  0.10535209625959396\n",
      "Eval Loss:  0.34115880727767944\n",
      "Eval Loss:  0.16322065889835358\n",
      "Eval Loss:  0.245977520942688\n",
      "Eval Loss:  0.23659951984882355\n",
      "Eval Loss:  0.2018810510635376\n",
      "Eval Loss:  0.20246973633766174\n",
      "Eval Loss:  0.23969857394695282\n",
      "Eval Loss:  0.19476576149463654\n",
      "Eval Loss:  0.23166488111019135\n",
      "Eval Loss:  0.22993886470794678\n",
      "Eval Loss:  0.19937165081501007\n",
      "Eval Loss:  0.27872326970100403\n",
      "Eval Loss:  0.23767775297164917\n",
      "Eval Loss:  0.21449293196201324\n",
      "Eval Loss:  0.21153832972049713\n",
      "Eval Loss:  0.268969863653183\n",
      "Eval Loss:  0.22571717202663422\n",
      "Eval Loss:  0.2279437780380249\n",
      "Eval Loss:  0.1446920782327652\n",
      "Eval Loss:  0.2673856317996979\n",
      "Eval Loss:  0.35105541348457336\n",
      "[[17682   946]\n",
      " [ 1797  9035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.91      0.83      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9068906992532247\n",
      "pre:  0.9052199178439034\n",
      "rec:  0.834102658788774\n",
      "ma F1:  0.8981129223447826\n",
      "mi F1:  0.9068906992532247\n",
      "we F1:  0.9060268287606742\n",
      "29460 461\n",
      "Loss:  0.0862906351685524\n",
      "Loss:  0.05952394753694534\n",
      "Loss:  0.07606726139783859\n",
      "45 **********\n",
      "Epoch:  2433.244996547699  fold:  3  kers:  32\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.06694919615983963\n",
      "Loss:  0.0651736706495285\n",
      "Loss:  0.0582168884575367\n",
      "46 **********\n",
      "Epoch:  2473.264991044998  fold:  3  kers:  32\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.0695967748761177\n",
      "Loss:  0.08158698678016663\n",
      "Loss:  0.06597296893596649\n",
      "47 **********\n",
      "Epoch:  2513.318895339966  fold:  3  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.7841538190841675\n",
      "Eval Loss:  0.14875559508800507\n",
      "Eval Loss:  1.1485228538513184\n",
      "[[1290  246]\n",
      " [ 563 1332]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1536\n",
      "           1       0.84      0.70      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7642086855144273\n",
      "pre:  0.844106463878327\n",
      "rec:  0.7029023746701847\n",
      "ma F1:  0.7641733468581173\n",
      "mi F1:  0.7642086855144273\n",
      "we F1:  0.7644754082299098\n",
      "Eval Loss:  0.23555251955986023\n",
      "Eval Loss:  0.14591749012470245\n",
      "Eval Loss:  0.2581767439842224\n",
      "Eval Loss:  0.2864532172679901\n",
      "Eval Loss:  0.2992016077041626\n",
      "Eval Loss:  0.28856441378593445\n",
      "Eval Loss:  0.11497227102518082\n",
      "Eval Loss:  0.35629624128341675\n",
      "Eval Loss:  0.17260435223579407\n",
      "Eval Loss:  0.25017601251602173\n",
      "Eval Loss:  0.22558647394180298\n",
      "Eval Loss:  0.22657468914985657\n",
      "Eval Loss:  0.2169259786605835\n",
      "Eval Loss:  0.2393951565027237\n",
      "Eval Loss:  0.20040945708751678\n",
      "Eval Loss:  0.2394167184829712\n",
      "Eval Loss:  0.26025137305259705\n",
      "Eval Loss:  0.20584405958652496\n",
      "Eval Loss:  0.28743940591812134\n",
      "Eval Loss:  0.2496495097875595\n",
      "Eval Loss:  0.22964957356452942\n",
      "Eval Loss:  0.19756241142749786\n",
      "Eval Loss:  0.2675897777080536\n",
      "Eval Loss:  0.22129368782043457\n",
      "Eval Loss:  0.25952062010765076\n",
      "Eval Loss:  0.14322397112846375\n",
      "Eval Loss:  0.28468838334083557\n",
      "Eval Loss:  0.3534758687019348\n",
      "[[17864   764]\n",
      " [ 2028  8804]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18628\n",
      "           1       0.92      0.81      0.86     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.90     29460\n",
      "\n",
      "acc:  0.9052274270196877\n",
      "pre:  0.9201505016722408\n",
      "rec:  0.8127769571639586\n",
      "ma F1:  0.8953277136399731\n",
      "mi F1:  0.9052274270196877\n",
      "we F1:  0.90384627495435\n",
      "29460 461\n",
      "Loss:  0.06096960976719856\n",
      "Loss:  0.06445278972387314\n",
      "Loss:  0.04915250465273857\n",
      "48 **********\n",
      "Epoch:  2591.239551305771  fold:  3  kers:  32\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.08845485001802444\n",
      "Loss:  0.04935046657919884\n",
      "Loss:  0.07625824958086014\n",
      "49 **********\n",
      "Epoch:  2631.2415940761566  fold:  3  kers:  32\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.06330064684152603\n",
      "Loss:  0.0809253603219986\n",
      "Loss:  0.03888816386461258\n",
      "50 **********\n",
      "Epoch:  2671.103012561798  fold:  3  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.6238521337509155\n",
      "Eval Loss:  0.12085170298814774\n",
      "Eval Loss:  1.091752052307129\n",
      "[[1253  283]\n",
      " [ 506 1389]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      1536\n",
      "           1       0.83      0.73      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7700378898280384\n",
      "pre:  0.8307416267942583\n",
      "rec:  0.732981530343008\n",
      "ma F1:  0.7696760006687504\n",
      "mi F1:  0.7700378898280384\n",
      "we F1:  0.770631281611283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17607946693897247\n",
      "Eval Loss:  0.14015834033489227\n",
      "Eval Loss:  0.23690395057201385\n",
      "Eval Loss:  0.2598654329776764\n",
      "Eval Loss:  0.28760388493537903\n",
      "Eval Loss:  0.2692286968231201\n",
      "Eval Loss:  0.10277393460273743\n",
      "Eval Loss:  0.32275864481925964\n",
      "Eval Loss:  0.1348486691713333\n",
      "Eval Loss:  0.22818578779697418\n",
      "Eval Loss:  0.2251461148262024\n",
      "Eval Loss:  0.2002735137939453\n",
      "Eval Loss:  0.1906287521123886\n",
      "Eval Loss:  0.2455805391073227\n",
      "Eval Loss:  0.1928817629814148\n",
      "Eval Loss:  0.21841928362846375\n",
      "Eval Loss:  0.22598600387573242\n",
      "Eval Loss:  0.19385991990566254\n",
      "Eval Loss:  0.27510666847229004\n",
      "Eval Loss:  0.22221046686172485\n",
      "Eval Loss:  0.2263624668121338\n",
      "Eval Loss:  0.212655708193779\n",
      "Eval Loss:  0.22974476218223572\n",
      "Eval Loss:  0.21373431384563446\n",
      "Eval Loss:  0.22231537103652954\n",
      "Eval Loss:  0.14058348536491394\n",
      "Eval Loss:  0.23573070764541626\n",
      "Eval Loss:  0.30352216958999634\n",
      "[[17598  1030]\n",
      " [ 1582  9250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18628\n",
      "           1       0.90      0.85      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9113374066530889\n",
      "pre:  0.8998054474708171\n",
      "rec:  0.8539512555391433\n",
      "ma F1:  0.9035964928879401\n",
      "mi F1:  0.9113374066530889\n",
      "we F1:  0.9108255493940612\n",
      "29460 461\n",
      "Loss:  0.056083884090185165\n",
      "Loss:  0.03936039283871651\n",
      "Loss:  0.06808415055274963\n",
      "51 **********\n",
      "Epoch:  2749.089492559433  fold:  3  kers:  32\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.03790958970785141\n",
      "Loss:  0.10223213583230972\n",
      "Loss:  0.06895943731069565\n",
      "52 **********\n",
      "Epoch:  2789.079567193985  fold:  3  kers:  32\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.06736232340335846\n",
      "Loss:  0.07502371072769165\n",
      "Loss:  0.0694621130824089\n",
      "53 **********\n",
      "Epoch:  2829.0008261203766  fold:  3  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.674664318561554\n",
      "Eval Loss:  0.1270371973514557\n",
      "Eval Loss:  0.9871293902397156\n",
      "[[1271  265]\n",
      " [ 503 1392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      1536\n",
      "           1       0.84      0.73      0.78      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.78      0.78      3431\n",
      "weighted avg       0.78      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7761585543573303\n",
      "pre:  0.84007242003621\n",
      "rec:  0.7345646437994723\n",
      "ma F1:  0.7758798072997469\n",
      "mi F1:  0.7761585543573302\n",
      "we F1:  0.7767068336937337\n",
      "Eval Loss:  0.17566615343093872\n",
      "Eval Loss:  0.1440660059452057\n",
      "Eval Loss:  0.2301734834909439\n",
      "Eval Loss:  0.2710069417953491\n",
      "Eval Loss:  0.2738224267959595\n",
      "Eval Loss:  0.2677571177482605\n",
      "Eval Loss:  0.1071079820394516\n",
      "Eval Loss:  0.31269094347953796\n",
      "Eval Loss:  0.14148297905921936\n",
      "Eval Loss:  0.23471945524215698\n",
      "Eval Loss:  0.19485945999622345\n",
      "Eval Loss:  0.17868368327617645\n",
      "Eval Loss:  0.18223731219768524\n",
      "Eval Loss:  0.23323962092399597\n",
      "Eval Loss:  0.19194722175598145\n",
      "Eval Loss:  0.2272329330444336\n",
      "Eval Loss:  0.22978630661964417\n",
      "Eval Loss:  0.1827230155467987\n",
      "Eval Loss:  0.26604634523391724\n",
      "Eval Loss:  0.2315988689661026\n",
      "Eval Loss:  0.20252251625061035\n",
      "Eval Loss:  0.20362085103988647\n",
      "Eval Loss:  0.23650746047496796\n",
      "Eval Loss:  0.21526449918746948\n",
      "Eval Loss:  0.2229183465242386\n",
      "Eval Loss:  0.14312604069709778\n",
      "Eval Loss:  0.22689902782440186\n",
      "Eval Loss:  0.31582942605018616\n",
      "[[17730   898]\n",
      " [ 1670  9162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.91      0.85      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9128309572301425\n",
      "pre:  0.9107355864811133\n",
      "rec:  0.8458271787296898\n",
      "ma F1:  0.9047764738422133\n",
      "mi F1:  0.9128309572301425\n",
      "we F1:  0.9121052264673647\n",
      "29460 461\n",
      "Loss:  0.03477977588772774\n",
      "Loss:  0.05009615048766136\n",
      "Loss:  0.04468744248151779\n",
      "54 **********\n",
      "Epoch:  2907.029193878174  fold:  3  kers:  32\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.050553277134895325\n",
      "Loss:  0.06657564640045166\n",
      "Loss:  0.03537094220519066\n",
      "55 **********\n",
      "Epoch:  2946.984361886978  fold:  3  kers:  32\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.048491135239601135\n",
      "Loss:  0.09990030527114868\n",
      "Loss:  0.05030471086502075\n",
      "56 **********\n",
      "Epoch:  2986.9564843177795  fold:  3  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.6350407600402832\n",
      "Eval Loss:  0.11037516593933105\n",
      "Eval Loss:  1.0692585706710815\n",
      "[[1262  274]\n",
      " [ 517 1378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      1536\n",
      "           1       0.83      0.73      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7694549693966773\n",
      "pre:  0.8341404358353511\n",
      "rec:  0.7271767810026385\n",
      "ma F1:  0.7691911376682268\n",
      "mi F1:  0.7694549693966773\n",
      "we F1:  0.7700076513795521\n",
      "Eval Loss:  0.1823234260082245\n",
      "Eval Loss:  0.1411925107240677\n",
      "Eval Loss:  0.22985675930976868\n",
      "Eval Loss:  0.25834888219833374\n",
      "Eval Loss:  0.27396997809410095\n",
      "Eval Loss:  0.25607267022132874\n",
      "Eval Loss:  0.1047896295785904\n",
      "Eval Loss:  0.3088706433773041\n",
      "Eval Loss:  0.14516746997833252\n",
      "Eval Loss:  0.22203226387500763\n",
      "Eval Loss:  0.20026656985282898\n",
      "Eval Loss:  0.19477513432502747\n",
      "Eval Loss:  0.17684395611286163\n",
      "Eval Loss:  0.2329072505235672\n",
      "Eval Loss:  0.17251966893672943\n",
      "Eval Loss:  0.21397411823272705\n",
      "Eval Loss:  0.23740226030349731\n",
      "Eval Loss:  0.17921243607997894\n",
      "Eval Loss:  0.2525547444820404\n",
      "Eval Loss:  0.23354873061180115\n",
      "Eval Loss:  0.19740387797355652\n",
      "Eval Loss:  0.20271793007850647\n",
      "Eval Loss:  0.2244051694869995\n",
      "Eval Loss:  0.21695059537887573\n",
      "Eval Loss:  0.22094830870628357\n",
      "Eval Loss:  0.14213570952415466\n",
      "Eval Loss:  0.215164452791214\n",
      "Eval Loss:  0.31180068850517273\n",
      "[[17765   863]\n",
      " [ 1624  9208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18628\n",
      "           1       0.91      0.85      0.88     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.90      0.91     29460\n",
      "weighted avg       0.92      0.92      0.91     29460\n",
      "\n",
      "acc:  0.9155804480651731\n",
      "pre:  0.9143084102869625\n",
      "rec:  0.8500738552437223\n",
      "ma F1:  0.9078018802313165\n",
      "mi F1:  0.9155804480651731\n",
      "we F1:  0.9148886764020241\n",
      "29460 461\n",
      "Loss:  0.06550920754671097\n",
      "Loss:  0.05261531099677086\n",
      "Loss:  0.06044900417327881\n",
      "57 **********\n",
      "Epoch:  3064.886116504669  fold:  3  kers:  32\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.03657148778438568\n",
      "Loss:  0.06365722417831421\n",
      "Loss:  0.07226157188415527\n",
      "58 **********\n",
      "Epoch:  3104.823332309723  fold:  3  kers:  32\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.05185598134994507\n",
      "Loss:  0.07192084193229675\n",
      "Loss:  0.09422614425420761\n",
      "59 **********\n",
      "Epoch:  3144.8004417419434  fold:  3  kers:  32\n",
      "Eval Loss:  0.6511872410774231\n",
      "Eval Loss:  0.11761247366666794\n",
      "Eval Loss:  0.9859495759010315\n",
      "[[1259  277]\n",
      " [ 501 1394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.76      1536\n",
      "           1       0.83      0.74      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.78      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7732439522005247\n",
      "pre:  0.834230999401556\n",
      "rec:  0.7356200527704485\n",
      "ma F1:  0.7728923449079494\n",
      "mi F1:  0.7732439522005248\n",
      "we F1:  0.7738273598563531\n",
      "update!  Acc:  0.7846109006120664\n",
      "Epoch:  3148.798751115799  fold:  3  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29520 3371\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29520 462\n",
      "Loss:  0.17169274389743805\n",
      "Loss:  0.17060309648513794\n",
      "Loss:  0.16269388794898987\n",
      "0 **********\n",
      "Epoch:  52.57442617416382  fold:  4  kers:  32\n",
      "epoch:  1\n",
      "29520 462\n",
      "Loss:  0.15741461515426636\n",
      "Loss:  0.14496074616909027\n",
      "Loss:  0.1459670215845108\n",
      "1 **********\n",
      "Epoch:  92.92852783203125  fold:  4  kers:  32\n",
      "epoch:  2\n",
      "29520 462\n",
      "Loss:  0.12698209285736084\n",
      "Loss:  0.1529650241136551\n",
      "Loss:  0.0959080308675766\n",
      "2 **********\n",
      "Epoch:  133.2058343887329  fold:  4  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.5635963678359985\n",
      "Eval Loss:  0.49351778626441956\n",
      "Eval Loss:  0.10969050228595734\n",
      "[[2593  544]\n",
      " [ 124  110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89      3137\n",
      "           1       0.17      0.47      0.25       234\n",
      "\n",
      "    accuracy                           0.80      3371\n",
      "   macro avg       0.56      0.65      0.57      3371\n",
      "weighted avg       0.90      0.80      0.84      3371\n",
      "\n",
      "acc:  0.8018392168495996\n",
      "pre:  0.16819571865443425\n",
      "rec:  0.4700854700854701\n",
      "ma F1:  0.5668188687491728\n",
      "mi F1:  0.8018392168495996\n",
      "we F1:  0.8415929607892607\n",
      "update!  Acc:  0.8018392168495996\n",
      "Eval Loss:  0.4246636927127838\n",
      "Eval Loss:  0.456030011177063\n",
      "Eval Loss:  0.4327470064163208\n",
      "Eval Loss:  0.4733913838863373\n",
      "Eval Loss:  0.4988088011741638\n",
      "Eval Loss:  0.41955628991127014\n",
      "Eval Loss:  0.41897085309028625\n",
      "Eval Loss:  0.5338634848594666\n",
      "Eval Loss:  0.3904426097869873\n",
      "Eval Loss:  0.40228375792503357\n",
      "Eval Loss:  0.5351420640945435\n",
      "Eval Loss:  0.42992064356803894\n",
      "Eval Loss:  0.4395674467086792\n",
      "Eval Loss:  0.42626821994781494\n",
      "Eval Loss:  0.3559967577457428\n",
      "Eval Loss:  0.4111369252204895\n",
      "Eval Loss:  0.4977816045284271\n",
      "Eval Loss:  0.47249507904052734\n",
      "Eval Loss:  0.41231289505958557\n",
      "Eval Loss:  0.44531336426734924\n",
      "Eval Loss:  0.46070635318756104\n",
      "Eval Loss:  0.499896764755249\n",
      "Eval Loss:  0.49076879024505615\n",
      "Eval Loss:  0.4213530719280243\n",
      "Eval Loss:  0.39113330841064453\n",
      "Eval Loss:  0.39235204458236694\n",
      "Eval Loss:  0.4650559425354004\n",
      "Eval Loss:  0.44166243076324463\n",
      "[[13777  3250]\n",
      " [ 2542  9951]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83     17027\n",
      "           1       0.75      0.80      0.77     12493\n",
      "\n",
      "    accuracy                           0.80     29520\n",
      "   macro avg       0.80      0.80      0.80     29520\n",
      "weighted avg       0.81      0.80      0.80     29520\n",
      "\n",
      "acc:  0.8037940379403794\n",
      "pre:  0.7538065298083478\n",
      "rec:  0.7965260545905707\n",
      "ma F1:  0.800441863072028\n",
      "mi F1:  0.8037940379403793\n",
      "we F1:  0.8044143567607642\n",
      "29520 462\n",
      "Loss:  0.10178688913583755\n",
      "Loss:  0.13433405756950378\n",
      "Loss:  0.10732945054769516\n",
      "3 **********\n",
      "Epoch:  211.42469310760498  fold:  4  kers:  32\n",
      "epoch:  4\n",
      "29520 462\n",
      "Loss:  0.09398984163999557\n",
      "Loss:  0.10047759115695953\n",
      "Loss:  0.1010960265994072\n",
      "4 **********\n",
      "Epoch:  251.41676235198975  fold:  4  kers:  32\n",
      "epoch:  5\n",
      "29520 462\n",
      "Loss:  0.11712511628866196\n",
      "Loss:  0.10386478900909424\n",
      "Loss:  0.12743033468723297\n",
      "5 **********\n",
      "Epoch:  291.48163652420044  fold:  4  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.09359986335039139\n",
      "Eval Loss:  0.1974848061800003\n",
      "Eval Loss:  0.06326647847890854\n",
      "[[3019  118]\n",
      " [ 201   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.22      0.14      0.17       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.58      0.55      0.56      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9053693266093148\n",
      "pre:  0.2185430463576159\n",
      "rec:  0.14102564102564102\n",
      "ma F1:  0.5606238342434662\n",
      "mi F1:  0.9053693266093148\n",
      "we F1:  0.8957866488241957\n",
      "update!  Acc:  0.9053693266093148\n",
      "Eval Loss:  0.35387083888053894\n",
      "Eval Loss:  0.4234665036201477\n",
      "Eval Loss:  0.39078304171562195\n",
      "Eval Loss:  0.43222081661224365\n",
      "Eval Loss:  0.48883602023124695\n",
      "Eval Loss:  0.39927807450294495\n",
      "Eval Loss:  0.39177635312080383\n",
      "Eval Loss:  0.49191370606422424\n",
      "Eval Loss:  0.39361247420310974\n",
      "Eval Loss:  0.33537253737449646\n",
      "Eval Loss:  0.5056869387626648\n",
      "Eval Loss:  0.384640097618103\n",
      "Eval Loss:  0.40356916189193726\n",
      "Eval Loss:  0.3708481788635254\n",
      "Eval Loss:  0.3491402268409729\n",
      "Eval Loss:  0.3911917805671692\n",
      "Eval Loss:  0.44998785853385925\n",
      "Eval Loss:  0.4698827266693115\n",
      "Eval Loss:  0.3711959719657898\n",
      "Eval Loss:  0.3799629509449005\n",
      "Eval Loss:  0.4485442638397217\n",
      "Eval Loss:  0.4803505539894104\n",
      "Eval Loss:  0.4982897639274597\n",
      "Eval Loss:  0.4347904324531555\n",
      "Eval Loss:  0.36668670177459717\n",
      "Eval Loss:  0.33613747358322144\n",
      "Eval Loss:  0.43847933411598206\n",
      "Eval Loss:  0.4493785798549652\n",
      "[[15598  1429]\n",
      " [ 3443  9050]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.86     17027\n",
      "           1       0.86      0.72      0.79     12493\n",
      "\n",
      "    accuracy                           0.83     29520\n",
      "   macro avg       0.84      0.82      0.83     29520\n",
      "weighted avg       0.84      0.83      0.83     29520\n",
      "\n",
      "acc:  0.8349593495934959\n",
      "pre:  0.8636320259566752\n",
      "rec:  0.7244056671736172\n",
      "ma F1:  0.8264187689200682\n",
      "mi F1:  0.8349593495934958\n",
      "we F1:  0.8323324819276006\n",
      "29520 462\n",
      "Loss:  0.10907105356454849\n",
      "Loss:  0.07955031096935272\n",
      "Loss:  0.10553888976573944\n",
      "6 **********\n",
      "Epoch:  369.6396584510803  fold:  4  kers:  32\n",
      "epoch:  7\n",
      "29520 462\n",
      "Loss:  0.12956778705120087\n",
      "Loss:  0.07216604053974152\n",
      "Loss:  0.08803223818540573\n",
      "7 **********\n",
      "Epoch:  409.6626453399658  fold:  4  kers:  32\n",
      "epoch:  8\n",
      "29520 462\n",
      "Loss:  0.10598869621753693\n",
      "Loss:  0.09797147661447525\n",
      "Loss:  0.06062299758195877\n",
      "8 **********\n",
      "Epoch:  449.7933437824249  fold:  4  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.0839003399014473\n",
      "Eval Loss:  0.1526101976633072\n",
      "Eval Loss:  0.052499882876873016\n",
      "[[3043   94]\n",
      " [ 203   31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.25      0.13      0.17       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.59      0.55      0.56      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9118955799466034\n",
      "pre:  0.248\n",
      "rec:  0.13247863247863248\n",
      "ma F1:  0.5630860524801036\n",
      "mi F1:  0.9118955799466034\n",
      "we F1:  0.8992726587999073\n",
      "update!  Acc:  0.9118955799466034\n",
      "Eval Loss:  0.33016300201416016\n",
      "Eval Loss:  0.35957831144332886\n",
      "Eval Loss:  0.3163401186466217\n",
      "Eval Loss:  0.37984105944633484\n",
      "Eval Loss:  0.45487180352211\n",
      "Eval Loss:  0.34870874881744385\n",
      "Eval Loss:  0.3481413424015045\n",
      "Eval Loss:  0.4287232756614685\n",
      "Eval Loss:  0.35907286405563354\n",
      "Eval Loss:  0.30772343277931213\n",
      "Eval Loss:  0.4354393482208252\n",
      "Eval Loss:  0.34423795342445374\n",
      "Eval Loss:  0.35386237502098083\n",
      "Eval Loss:  0.3174326717853546\n",
      "Eval Loss:  0.3095206916332245\n",
      "Eval Loss:  0.3648153245449066\n",
      "Eval Loss:  0.38781973719596863\n",
      "Eval Loss:  0.4171539843082428\n",
      "Eval Loss:  0.31216514110565186\n",
      "Eval Loss:  0.33041438460350037\n",
      "Eval Loss:  0.38892683386802673\n",
      "Eval Loss:  0.4114287793636322\n",
      "Eval Loss:  0.45288658142089844\n",
      "Eval Loss:  0.36714252829551697\n",
      "Eval Loss:  0.3687339425086975\n",
      "Eval Loss:  0.315945029258728\n",
      "Eval Loss:  0.376914381980896\n",
      "Eval Loss:  0.407066285610199\n",
      "[[15713  1314]\n",
      " [ 3033  9460]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88     17027\n",
      "           1       0.88      0.76      0.81     12493\n",
      "\n",
      "    accuracy                           0.85     29520\n",
      "   macro avg       0.86      0.84      0.85     29520\n",
      "weighted avg       0.86      0.85      0.85     29520\n",
      "\n",
      "acc:  0.8527439024390244\n",
      "pre:  0.8780397252645257\n",
      "rec:  0.7572240454654606\n",
      "ma F1:  0.84582631922664\n",
      "mi F1:  0.8527439024390244\n",
      "we F1:  0.8508422031679405\n",
      "29520 462\n",
      "Loss:  0.05724147707223892\n",
      "Loss:  0.08739503473043442\n",
      "Loss:  0.08493688702583313\n",
      "9 **********\n",
      "Epoch:  527.879557132721  fold:  4  kers:  32\n",
      "epoch:  10\n",
      "29520 462\n",
      "Loss:  0.053298939019441605\n",
      "Loss:  0.088866226375103\n",
      "Loss:  0.08397206664085388\n",
      "10 **********\n",
      "Epoch:  567.8845918178558  fold:  4  kers:  32\n",
      "epoch:  11\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.10393727570772171\n",
      "Loss:  0.08914520591497421\n",
      "Loss:  0.10802017152309418\n",
      "11 **********\n",
      "Epoch:  607.90558385849  fold:  4  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.09275508671998978\n",
      "Eval Loss:  0.13558444380760193\n",
      "Eval Loss:  0.04214762896299362\n",
      "[[2993  144]\n",
      " [ 182   52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      3137\n",
      "           1       0.27      0.22      0.24       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.60      0.59      0.60      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.9032927914565411\n",
      "pre:  0.2653061224489796\n",
      "rec:  0.2222222222222222\n",
      "ma F1:  0.5951064049282282\n",
      "mi F1:  0.9032927914565411\n",
      "we F1:  0.8993107844221732\n",
      "Eval Loss:  0.29725414514541626\n",
      "Eval Loss:  0.3342241048812866\n",
      "Eval Loss:  0.27198272943496704\n",
      "Eval Loss:  0.33312663435935974\n",
      "Eval Loss:  0.37837037444114685\n",
      "Eval Loss:  0.3271375596523285\n",
      "Eval Loss:  0.3053835928440094\n",
      "Eval Loss:  0.35043343901634216\n",
      "Eval Loss:  0.3297554552555084\n",
      "Eval Loss:  0.29150789976119995\n",
      "Eval Loss:  0.383985698223114\n",
      "Eval Loss:  0.31046587228775024\n",
      "Eval Loss:  0.3094533383846283\n",
      "Eval Loss:  0.276915580034256\n",
      "Eval Loss:  0.2884523272514343\n",
      "Eval Loss:  0.34124910831451416\n",
      "Eval Loss:  0.3232336938381195\n",
      "Eval Loss:  0.3649192452430725\n",
      "Eval Loss:  0.2715192437171936\n",
      "Eval Loss:  0.283910870552063\n",
      "Eval Loss:  0.34480684995651245\n",
      "Eval Loss:  0.34609103202819824\n",
      "Eval Loss:  0.39856743812561035\n",
      "Eval Loss:  0.3513832092285156\n",
      "Eval Loss:  0.36376330256462097\n",
      "Eval Loss:  0.29366666078567505\n",
      "Eval Loss:  0.3474767506122589\n",
      "Eval Loss:  0.3510035276412964\n",
      "[[15665  1362]\n",
      " [ 2579  9914]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     17027\n",
      "           1       0.88      0.79      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.87      0.86      0.86     29520\n",
      "weighted avg       0.87      0.87      0.87     29520\n",
      "\n",
      "acc:  0.8664972899728998\n",
      "pre:  0.8792124866974105\n",
      "rec:  0.7935643960617946\n",
      "ma F1:  0.8612304741291776\n",
      "mi F1:  0.8664972899728997\n",
      "we F1:  0.865382750782879\n",
      "29520 462\n",
      "Loss:  0.08790690451860428\n",
      "Loss:  0.08802976459264755\n",
      "Loss:  0.06351600587368011\n",
      "12 **********\n",
      "Epoch:  685.8641386032104  fold:  4  kers:  32\n",
      "epoch:  13\n",
      "29520 462\n",
      "Loss:  0.0865163803100586\n",
      "Loss:  0.062056589871644974\n",
      "Loss:  0.05704212561249733\n",
      "13 **********\n",
      "Epoch:  725.867178440094  fold:  4  kers:  32\n",
      "epoch:  14\n",
      "29520 462\n",
      "Loss:  0.0609164759516716\n",
      "Loss:  0.06416911631822586\n",
      "Loss:  0.07044529914855957\n",
      "14 **********\n",
      "Epoch:  765.8891673088074  fold:  4  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.08252541720867157\n",
      "Eval Loss:  0.10960757732391357\n",
      "Eval Loss:  0.02768447808921337\n",
      "[[3076   61]\n",
      " [ 195   39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.39      0.17      0.23       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.67      0.57      0.60      3371\n",
      "weighted avg       0.90      0.92      0.91      3371\n",
      "\n",
      "acc:  0.9240581429842777\n",
      "pre:  0.39\n",
      "rec:  0.16666666666666666\n",
      "ma F1:  0.596791435854882\n",
      "mi F1:  0.9240581429842777\n",
      "we F1:  0.9096183212011565\n",
      "update!  Acc:  0.9240581429842777\n",
      "Eval Loss:  0.2958272099494934\n",
      "Eval Loss:  0.344279408454895\n",
      "Eval Loss:  0.3133792281150818\n",
      "Eval Loss:  0.3541862964630127\n",
      "Eval Loss:  0.3997202515602112\n",
      "Eval Loss:  0.34443244338035583\n",
      "Eval Loss:  0.33752062916755676\n",
      "Eval Loss:  0.4040548801422119\n",
      "Eval Loss:  0.35854145884513855\n",
      "Eval Loss:  0.29024627804756165\n",
      "Eval Loss:  0.4294733703136444\n",
      "Eval Loss:  0.34378835558891296\n",
      "Eval Loss:  0.3564290702342987\n",
      "Eval Loss:  0.31324952840805054\n",
      "Eval Loss:  0.3161841630935669\n",
      "Eval Loss:  0.3390294015407562\n",
      "Eval Loss:  0.3336426913738251\n",
      "Eval Loss:  0.40824374556541443\n",
      "Eval Loss:  0.2916213870048523\n",
      "Eval Loss:  0.3030737042427063\n",
      "Eval Loss:  0.38491252064704895\n",
      "Eval Loss:  0.37174203991889954\n",
      "Eval Loss:  0.4076862037181854\n",
      "Eval Loss:  0.38177376985549927\n",
      "Eval Loss:  0.37889567017555237\n",
      "Eval Loss:  0.32873350381851196\n",
      "Eval Loss:  0.36855438351631165\n",
      "Eval Loss:  0.39834070205688477\n",
      "[[16086   941]\n",
      " [ 3204  9289]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.89     17027\n",
      "           1       0.91      0.74      0.82     12493\n",
      "\n",
      "    accuracy                           0.86     29520\n",
      "   macro avg       0.87      0.84      0.85     29520\n",
      "weighted avg       0.87      0.86      0.86     29520\n",
      "\n",
      "acc:  0.8595867208672087\n",
      "pre:  0.9080156402737047\n",
      "rec:  0.7435363803730088\n",
      "ma F1:  0.8517259147079428\n",
      "mi F1:  0.8595867208672087\n",
      "we F1:  0.8569695361771368\n",
      "29520 462\n",
      "Loss:  0.11038056015968323\n",
      "Loss:  0.08569865673780441\n",
      "Loss:  0.07353533059358597\n",
      "15 **********\n",
      "Epoch:  843.6871519088745  fold:  4  kers:  32\n",
      "epoch:  16\n",
      "29520 462\n",
      "Loss:  0.08113129436969757\n",
      "Loss:  0.1293238252401352\n",
      "Loss:  0.06375999748706818\n",
      "16 **********\n",
      "Epoch:  883.6712422370911  fold:  4  kers:  32\n",
      "epoch:  17\n",
      "29520 462\n",
      "Loss:  0.08168347179889679\n",
      "Loss:  0.08113500475883484\n",
      "Loss:  0.10877034813165665\n",
      "17 **********\n",
      "Epoch:  923.6423678398132  fold:  4  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.09689492732286453\n",
      "Eval Loss:  0.14214082062244415\n",
      "Eval Loss:  0.05418652296066284\n",
      "[[2902  235]\n",
      " [ 155   79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      3137\n",
      "           1       0.25      0.34      0.29       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.60      0.63      0.61      3371\n",
      "weighted avg       0.90      0.88      0.89      3371\n",
      "\n",
      "acc:  0.8843073272026105\n",
      "pre:  0.2515923566878981\n",
      "rec:  0.33760683760683763\n",
      "ma F1:  0.6126785045098978\n",
      "mi F1:  0.8843073272026106\n",
      "we F1:  0.8920049204776432\n",
      "Eval Loss:  0.2763863801956177\n",
      "Eval Loss:  0.31368526816368103\n",
      "Eval Loss:  0.25683361291885376\n",
      "Eval Loss:  0.31304821372032166\n",
      "Eval Loss:  0.3505863845348358\n",
      "Eval Loss:  0.31695008277893066\n",
      "Eval Loss:  0.29858383536338806\n",
      "Eval Loss:  0.3160000145435333\n",
      "Eval Loss:  0.30086761713027954\n",
      "Eval Loss:  0.28176262974739075\n",
      "Eval Loss:  0.35154294967651367\n",
      "Eval Loss:  0.29290953278541565\n",
      "Eval Loss:  0.2666172981262207\n",
      "Eval Loss:  0.2660432457923889\n",
      "Eval Loss:  0.27191027998924255\n",
      "Eval Loss:  0.33232060074806213\n",
      "Eval Loss:  0.295669287443161\n",
      "Eval Loss:  0.339211106300354\n",
      "Eval Loss:  0.248148113489151\n",
      "Eval Loss:  0.2626153528690338\n",
      "Eval Loss:  0.3257780373096466\n",
      "Eval Loss:  0.3145490884780884\n",
      "Eval Loss:  0.3530752658843994\n",
      "Eval Loss:  0.314219206571579\n",
      "Eval Loss:  0.3580490052700043\n",
      "Eval Loss:  0.277030348777771\n",
      "Eval Loss:  0.32882779836654663\n",
      "Eval Loss:  0.28847163915634155\n",
      "[[15544  1483]\n",
      " [ 2187 10306]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89     17027\n",
      "           1       0.87      0.82      0.85     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.88      0.87      0.87     29520\n",
      "weighted avg       0.88      0.88      0.88     29520\n",
      "\n",
      "acc:  0.8756775067750677\n",
      "pre:  0.8742047671558232\n",
      "rec:  0.824941967501801\n",
      "ma F1:  0.8716360171745157\n",
      "mi F1:  0.8756775067750677\n",
      "we F1:  0.8751343206966431\n",
      "29520 462\n",
      "Loss:  0.06172121688723564\n",
      "Loss:  0.06714566797018051\n",
      "Loss:  0.07784958183765411\n",
      "18 **********\n",
      "Epoch:  1001.906106710434  fold:  4  kers:  32\n",
      "epoch:  19\n",
      "29520 462\n",
      "Loss:  0.0638013705611229\n",
      "Loss:  0.08968467265367508\n",
      "Loss:  0.06686002761125565\n",
      "19 **********\n",
      "Epoch:  1041.9490399360657  fold:  4  kers:  32\n",
      "epoch:  20\n",
      "29520 462\n",
      "Loss:  0.08272051811218262\n",
      "Loss:  0.05983918905258179\n",
      "Loss:  0.07580544054508209\n",
      "20 **********\n",
      "Epoch:  1081.9032106399536  fold:  4  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.09008827805519104\n",
      "Eval Loss:  0.13084816932678223\n",
      "Eval Loss:  0.026455355808138847\n",
      "[[2961  176]\n",
      " [ 168   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      3137\n",
      "           1       0.27      0.28      0.28       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.61      0.61      0.61      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.8979531296351231\n",
      "pre:  0.2727272727272727\n",
      "rec:  0.28205128205128205\n",
      "ma F1:  0.6112057334903319\n",
      "mi F1:  0.8979531296351231\n",
      "we F1:  0.8987455231305146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.27534666657447815\n",
      "Eval Loss:  0.31993183493614197\n",
      "Eval Loss:  0.27321746945381165\n",
      "Eval Loss:  0.3213980495929718\n",
      "Eval Loss:  0.35373541712760925\n",
      "Eval Loss:  0.3123942017555237\n",
      "Eval Loss:  0.3025669753551483\n",
      "Eval Loss:  0.33559709787368774\n",
      "Eval Loss:  0.31025782227516174\n",
      "Eval Loss:  0.2783259153366089\n",
      "Eval Loss:  0.37686705589294434\n",
      "Eval Loss:  0.28776341676712036\n",
      "Eval Loss:  0.28281068801879883\n",
      "Eval Loss:  0.28254956007003784\n",
      "Eval Loss:  0.27050670981407166\n",
      "Eval Loss:  0.32637709379196167\n",
      "Eval Loss:  0.2903114855289459\n",
      "Eval Loss:  0.3357449769973755\n",
      "Eval Loss:  0.25297442078590393\n",
      "Eval Loss:  0.2643817365169525\n",
      "Eval Loss:  0.36663201451301575\n",
      "Eval Loss:  0.32051169872283936\n",
      "Eval Loss:  0.34010106325149536\n",
      "Eval Loss:  0.313626229763031\n",
      "Eval Loss:  0.3587580919265747\n",
      "Eval Loss:  0.2899727523326874\n",
      "Eval Loss:  0.3448635935783386\n",
      "Eval Loss:  0.28772035241127014\n",
      "[[15988  1039]\n",
      " [ 2650  9843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     17027\n",
      "           1       0.90      0.79      0.84     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.88      0.86      0.87     29520\n",
      "weighted avg       0.88      0.88      0.87     29520\n",
      "\n",
      "acc:  0.8750338753387534\n",
      "pre:  0.9045212277154935\n",
      "rec:  0.7878812134795485\n",
      "ma F1:  0.8693735391203496\n",
      "mi F1:  0.8750338753387534\n",
      "we F1:  0.8735499369094859\n",
      "29520 462\n",
      "Loss:  0.06354781985282898\n",
      "Loss:  0.07485514879226685\n",
      "Loss:  0.09373119473457336\n",
      "21 **********\n",
      "Epoch:  1159.8837065696716  fold:  4  kers:  32\n",
      "epoch:  22\n",
      "29520 462\n",
      "Loss:  0.0826040580868721\n",
      "Loss:  0.09360799193382263\n",
      "Loss:  0.05034538730978966\n",
      "22 **********\n",
      "Epoch:  1199.8568263053894  fold:  4  kers:  32\n",
      "epoch:  23\n",
      "29520 462\n",
      "Loss:  0.07684074342250824\n",
      "Loss:  0.06022486090660095\n",
      "Loss:  0.09048383682966232\n",
      "23 **********\n",
      "Epoch:  1239.711264371872  fold:  4  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.094349704682827\n",
      "Eval Loss:  0.11802814155817032\n",
      "Eval Loss:  0.022305678576231003\n",
      "[[2940  197]\n",
      " [ 150   84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      3137\n",
      "           1       0.30      0.36      0.33       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.63      0.65      0.64      3371\n",
      "weighted avg       0.91      0.90      0.90      3371\n",
      "\n",
      "acc:  0.8970631859982201\n",
      "pre:  0.298932384341637\n",
      "rec:  0.358974358974359\n",
      "ma F1:  0.6352442619909227\n",
      "mi F1:  0.8970631859982201\n",
      "we F1:  0.9013718307560433\n",
      "Eval Loss:  0.28819504380226135\n",
      "Eval Loss:  0.3014484941959381\n",
      "Eval Loss:  0.26647886633872986\n",
      "Eval Loss:  0.31784743070602417\n",
      "Eval Loss:  0.3260482847690582\n",
      "Eval Loss:  0.302817165851593\n",
      "Eval Loss:  0.3167627155780792\n",
      "Eval Loss:  0.32819950580596924\n",
      "Eval Loss:  0.30275020003318787\n",
      "Eval Loss:  0.26404592394828796\n",
      "Eval Loss:  0.3585442900657654\n",
      "Eval Loss:  0.2802894711494446\n",
      "Eval Loss:  0.2532442808151245\n",
      "Eval Loss:  0.28034326434135437\n",
      "Eval Loss:  0.26056337356567383\n",
      "Eval Loss:  0.3139978051185608\n",
      "Eval Loss:  0.27864301204681396\n",
      "Eval Loss:  0.329373300075531\n",
      "Eval Loss:  0.2606261670589447\n",
      "Eval Loss:  0.2616269290447235\n",
      "Eval Loss:  0.3435945212841034\n",
      "Eval Loss:  0.30027878284454346\n",
      "Eval Loss:  0.3461168110370636\n",
      "Eval Loss:  0.2932223975658417\n",
      "Eval Loss:  0.34147071838378906\n",
      "Eval Loss:  0.2887257933616638\n",
      "Eval Loss:  0.323351114988327\n",
      "Eval Loss:  0.26914194226264954\n",
      "[[16017  1010]\n",
      " [ 2576  9917]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     17027\n",
      "           1       0.91      0.79      0.85     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.88      0.87      0.87     29520\n",
      "weighted avg       0.88      0.88      0.88     29520\n",
      "\n",
      "acc:  0.8785230352303524\n",
      "pre:  0.907568408529331\n",
      "rec:  0.7938045305371008\n",
      "ma F1:  0.8731046136009141\n",
      "mi F1:  0.8785230352303524\n",
      "we F1:  0.8771320109235162\n",
      "29520 462\n",
      "Loss:  0.0706712082028389\n",
      "Loss:  0.0783456489443779\n",
      "Loss:  0.07684896886348724\n",
      "24 **********\n",
      "Epoch:  1317.6807894706726  fold:  4  kers:  32\n",
      "epoch:  25\n",
      "29520 462\n",
      "Loss:  0.08600439876317978\n",
      "Loss:  0.0971544161438942\n",
      "Loss:  0.060173481702804565\n",
      "25 **********\n",
      "Epoch:  1357.707765340805  fold:  4  kers:  32\n",
      "epoch:  26\n",
      "29520 462\n",
      "Loss:  0.07443778961896896\n",
      "Loss:  0.06174197793006897\n",
      "Loss:  0.0656399056315422\n",
      "26 **********\n",
      "Epoch:  1397.7317490577698  fold:  4  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.06426248699426651\n",
      "Eval Loss:  0.10031326860189438\n",
      "Eval Loss:  0.01736970618367195\n",
      "[[3086   51]\n",
      " [ 200   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.40      0.15      0.21       234\n",
      "\n",
      "    accuracy                           0.93      3371\n",
      "   macro avg       0.67      0.56      0.59      3371\n",
      "weighted avg       0.90      0.93      0.91      3371\n",
      "\n",
      "acc:  0.925541382379116\n",
      "pre:  0.4\n",
      "rec:  0.1452991452991453\n",
      "ma F1:  0.5870439159427547\n",
      "mi F1:  0.925541382379116\n",
      "we F1:  0.9090157852300275\n",
      "update!  Acc:  0.925541382379116\n",
      "Eval Loss:  0.29840442538261414\n",
      "Eval Loss:  0.3148859143257141\n",
      "Eval Loss:  0.28703057765960693\n",
      "Eval Loss:  0.347777396440506\n",
      "Eval Loss:  0.3501901924610138\n",
      "Eval Loss:  0.3027558922767639\n",
      "Eval Loss:  0.326843798160553\n",
      "Eval Loss:  0.3668321967124939\n",
      "Eval Loss:  0.31985151767730713\n",
      "Eval Loss:  0.26729193329811096\n",
      "Eval Loss:  0.384037047624588\n",
      "Eval Loss:  0.29306602478027344\n",
      "Eval Loss:  0.2922288775444031\n",
      "Eval Loss:  0.3040447235107422\n",
      "Eval Loss:  0.2870987057685852\n",
      "Eval Loss:  0.3223187029361725\n",
      "Eval Loss:  0.288717657327652\n",
      "Eval Loss:  0.3553234934806824\n",
      "Eval Loss:  0.27331897616386414\n",
      "Eval Loss:  0.28724995255470276\n",
      "Eval Loss:  0.3648242652416229\n",
      "Eval Loss:  0.3424001932144165\n",
      "Eval Loss:  0.3763269782066345\n",
      "Eval Loss:  0.3170774579048157\n",
      "Eval Loss:  0.36054378747940063\n",
      "Eval Loss:  0.32799607515335083\n",
      "Eval Loss:  0.33986514806747437\n",
      "Eval Loss:  0.3126988708972931\n",
      "[[16317   710]\n",
      " [ 3093  9400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     17027\n",
      "           1       0.93      0.75      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.89      0.86      0.86     29520\n",
      "weighted avg       0.88      0.87      0.87     29520\n",
      "\n",
      "acc:  0.8711720867208672\n",
      "pre:  0.9297725024727992\n",
      "rec:  0.7524213559593372\n",
      "ma F1:  0.8636880342106942\n",
      "mi F1:  0.8711720867208672\n",
      "we F1:  0.8685937294660252\n",
      "29520 462\n",
      "Loss:  0.09254427254199982\n",
      "Loss:  0.07209509611129761\n",
      "Loss:  0.052018702030181885\n",
      "27 **********\n",
      "Epoch:  1475.8797976970673  fold:  4  kers:  32\n",
      "epoch:  28\n",
      "29520 462\n",
      "Loss:  0.0768112763762474\n",
      "Loss:  0.05129009112715721\n",
      "Loss:  0.06148608401417732\n",
      "28 **********\n",
      "Epoch:  1515.966612815857  fold:  4  kers:  32\n",
      "epoch:  29\n",
      "29520 462\n",
      "Loss:  0.05721611529588699\n",
      "Loss:  0.07492237538099289\n",
      "Loss:  0.06057225540280342\n",
      "29 **********\n",
      "Epoch:  1556.059413433075  fold:  4  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.09808345139026642\n",
      "Eval Loss:  0.14649878442287445\n",
      "Eval Loss:  0.02898534946143627\n",
      "[[2893  244]\n",
      " [ 133  101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      3137\n",
      "           1       0.29      0.43      0.35       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.62      0.68      0.64      3371\n",
      "weighted avg       0.91      0.89      0.90      3371\n",
      "\n",
      "acc:  0.8881637496291902\n",
      "pre:  0.2927536231884058\n",
      "rec:  0.43162393162393164\n",
      "ma F1:  0.6438529337006712\n",
      "mi F1:  0.8881637496291902\n",
      "we F1:  0.897876679632079\n",
      "Eval Loss:  0.2892040014266968\n",
      "Eval Loss:  0.30046892166137695\n",
      "Eval Loss:  0.22151333093643188\n",
      "Eval Loss:  0.27475184202194214\n",
      "Eval Loss:  0.3043152689933777\n",
      "Eval Loss:  0.26063427329063416\n",
      "Eval Loss:  0.2780565321445465\n",
      "Eval Loss:  0.2837924361228943\n",
      "Eval Loss:  0.2638472318649292\n",
      "Eval Loss:  0.24217535555362701\n",
      "Eval Loss:  0.3146517276763916\n",
      "Eval Loss:  0.22883674502372742\n",
      "Eval Loss:  0.20373648405075073\n",
      "Eval Loss:  0.2553073763847351\n",
      "Eval Loss:  0.2249619960784912\n",
      "Eval Loss:  0.3099684715270996\n",
      "Eval Loss:  0.2893587648868561\n",
      "Eval Loss:  0.2904115617275238\n",
      "Eval Loss:  0.23713302612304688\n",
      "Eval Loss:  0.23764574527740479\n",
      "Eval Loss:  0.28591594099998474\n",
      "Eval Loss:  0.26456886529922485\n",
      "Eval Loss:  0.31335732340812683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23016276955604553\n",
      "Eval Loss:  0.3406358063220978\n",
      "Eval Loss:  0.26663824915885925\n",
      "Eval Loss:  0.2918689250946045\n",
      "Eval Loss:  0.21405363082885742\n",
      "[[15666  1361]\n",
      " [ 1826 10667]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17027\n",
      "           1       0.89      0.85      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8920392953929539\n",
      "pre:  0.8868473561689392\n",
      "rec:  0.8538381493636437\n",
      "ma F1:  0.8888519024952636\n",
      "mi F1:  0.8920392953929539\n",
      "we F1:  0.8917428085561014\n",
      "29520 462\n",
      "Loss:  0.08190654963254929\n",
      "Loss:  0.056709300726652145\n",
      "Loss:  0.06303080916404724\n",
      "30 **********\n",
      "Epoch:  1634.342101573944  fold:  4  kers:  32\n",
      "epoch:  31\n",
      "29520 462\n",
      "Loss:  0.05203050374984741\n",
      "Loss:  0.08380214869976044\n",
      "Loss:  0.07272748649120331\n",
      "31 **********\n",
      "Epoch:  1674.450858592987  fold:  4  kers:  32\n",
      "epoch:  32\n",
      "29520 462\n",
      "Loss:  0.06402622163295746\n",
      "Loss:  0.06575419753789902\n",
      "Loss:  0.10060706734657288\n",
      "32 **********\n",
      "Epoch:  1714.6005065441132  fold:  4  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.0687878429889679\n",
      "Eval Loss:  0.1411132514476776\n",
      "Eval Loss:  0.01768031157553196\n",
      "[[3013  124]\n",
      " [ 161   73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      3137\n",
      "           1       0.37      0.31      0.34       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.66      0.64      0.65      3371\n",
      "weighted avg       0.91      0.92      0.91      3371\n",
      "\n",
      "acc:  0.9154553544942153\n",
      "pre:  0.37055837563451777\n",
      "rec:  0.31196581196581197\n",
      "ma F1:  0.6467939270033062\n",
      "mi F1:  0.9154553544942153\n",
      "we F1:  0.9120742412910985\n",
      "Eval Loss:  0.26836490631103516\n",
      "Eval Loss:  0.2775968313217163\n",
      "Eval Loss:  0.2242373526096344\n",
      "Eval Loss:  0.2636253833770752\n",
      "Eval Loss:  0.295680969953537\n",
      "Eval Loss:  0.2611088156700134\n",
      "Eval Loss:  0.2856937646865845\n",
      "Eval Loss:  0.3013497591018677\n",
      "Eval Loss:  0.26030582189559937\n",
      "Eval Loss:  0.24550242722034454\n",
      "Eval Loss:  0.30756205320358276\n",
      "Eval Loss:  0.22217820584774017\n",
      "Eval Loss:  0.20718416571617126\n",
      "Eval Loss:  0.2650871276855469\n",
      "Eval Loss:  0.22675228118896484\n",
      "Eval Loss:  0.3101891875267029\n",
      "Eval Loss:  0.28799968957901\n",
      "Eval Loss:  0.29422685503959656\n",
      "Eval Loss:  0.22404171526432037\n",
      "Eval Loss:  0.24240446090698242\n",
      "Eval Loss:  0.27766865491867065\n",
      "Eval Loss:  0.24607114493846893\n",
      "Eval Loss:  0.31741607189178467\n",
      "Eval Loss:  0.2256983369588852\n",
      "Eval Loss:  0.32654625177383423\n",
      "Eval Loss:  0.2787582278251648\n",
      "Eval Loss:  0.2794473171234131\n",
      "Eval Loss:  0.22366462647914886\n",
      "[[15713  1314]\n",
      " [ 1899 10594]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91     17027\n",
      "           1       0.89      0.85      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8911585365853658\n",
      "pre:  0.8896540141081626\n",
      "rec:  0.8479948771311935\n",
      "ma F1:  0.8877841746699489\n",
      "mi F1:  0.8911585365853658\n",
      "we F1:  0.8907729140574271\n",
      "29520 462\n",
      "Loss:  0.0712251290678978\n",
      "Loss:  0.08388102054595947\n",
      "Loss:  0.07974657416343689\n",
      "33 **********\n",
      "Epoch:  1796.1444749832153  fold:  4  kers:  32\n",
      "epoch:  34\n",
      "29520 462\n",
      "Loss:  0.05704595521092415\n",
      "Loss:  0.06517530232667923\n",
      "Loss:  0.08463571965694427\n",
      "34 **********\n",
      "Epoch:  1836.301103591919  fold:  4  kers:  32\n",
      "epoch:  35\n",
      "29520 462\n",
      "Loss:  0.04741562157869339\n",
      "Loss:  0.05024472996592522\n",
      "Loss:  0.07720055431127548\n",
      "35 **********\n",
      "Epoch:  1876.872626543045  fold:  4  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.08687423914670944\n",
      "Eval Loss:  0.25063246488571167\n",
      "Eval Loss:  0.04378851503133774\n",
      "[[2866  271]\n",
      " [ 139   95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      3137\n",
      "           1       0.26      0.41      0.32       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.61      0.66      0.62      3371\n",
      "weighted avg       0.91      0.88      0.89      3371\n",
      "\n",
      "acc:  0.8783743696232572\n",
      "pre:  0.25956284153005466\n",
      "rec:  0.405982905982906\n",
      "ma F1:  0.6249565830891133\n",
      "mi F1:  0.8783743696232572\n",
      "we F1:  0.8904462381986837\n",
      "Eval Loss:  0.2996285557746887\n",
      "Eval Loss:  0.3038437068462372\n",
      "Eval Loss:  0.20280617475509644\n",
      "Eval Loss:  0.25435706973075867\n",
      "Eval Loss:  0.28873321413993835\n",
      "Eval Loss:  0.2627311944961548\n",
      "Eval Loss:  0.27118149399757385\n",
      "Eval Loss:  0.28089576959609985\n",
      "Eval Loss:  0.2541182339191437\n",
      "Eval Loss:  0.24998758733272552\n",
      "Eval Loss:  0.31579291820526123\n",
      "Eval Loss:  0.2218676656484604\n",
      "Eval Loss:  0.1828574538230896\n",
      "Eval Loss:  0.26452532410621643\n",
      "Eval Loss:  0.2444489598274231\n",
      "Eval Loss:  0.3291049301624298\n",
      "Eval Loss:  0.2981322109699249\n",
      "Eval Loss:  0.28372183442115784\n",
      "Eval Loss:  0.23819586634635925\n",
      "Eval Loss:  0.2775229513645172\n",
      "Eval Loss:  0.26346707344055176\n",
      "Eval Loss:  0.25000691413879395\n",
      "Eval Loss:  0.3155665993690491\n",
      "Eval Loss:  0.20830920338630676\n",
      "Eval Loss:  0.34246474504470825\n",
      "Eval Loss:  0.2784637212753296\n",
      "Eval Loss:  0.2983541190624237\n",
      "Eval Loss:  0.20373664796352386\n",
      "[[15348  1679]\n",
      " [ 1523 10970]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91     17027\n",
      "           1       0.87      0.88      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8915311653116531\n",
      "pre:  0.867262234168709\n",
      "rec:  0.878091731369567\n",
      "ma F1:  0.8890917677156556\n",
      "mi F1:  0.8915311653116531\n",
      "we F1:  0.8916180876563254\n",
      "29520 462\n",
      "Loss:  0.07047896832227707\n",
      "Loss:  0.07622125744819641\n",
      "Loss:  0.07797598838806152\n",
      "36 **********\n",
      "Epoch:  1955.117413520813  fold:  4  kers:  32\n",
      "epoch:  37\n",
      "29520 462\n",
      "Loss:  0.08144451677799225\n",
      "Loss:  0.06239132583141327\n",
      "Loss:  0.07675350457429886\n",
      "37 **********\n",
      "Epoch:  1995.3777668476105  fold:  4  kers:  32\n",
      "epoch:  38\n",
      "29520 462\n",
      "Loss:  0.09278997778892517\n",
      "Loss:  0.036704085767269135\n",
      "Loss:  0.07056139409542084\n",
      "38 **********\n",
      "Epoch:  2035.6321332454681  fold:  4  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.07245073467493057\n",
      "Eval Loss:  0.2033182829618454\n",
      "Eval Loss:  0.03609136492013931\n",
      "[[2934  203]\n",
      " [ 138   96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      3137\n",
      "           1       0.32      0.41      0.36       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.64      0.67      0.65      3371\n",
      "weighted avg       0.91      0.90      0.90      3371\n",
      "\n",
      "acc:  0.8988430732720261\n",
      "pre:  0.3210702341137124\n",
      "rec:  0.41025641025641024\n",
      "ma F1:  0.6526524318478563\n",
      "mi F1:  0.8988430732720261\n",
      "we F1:  0.904481689090409\n",
      "Eval Loss:  0.30385318398475647\n",
      "Eval Loss:  0.2921678423881531\n",
      "Eval Loss:  0.21445198357105255\n",
      "Eval Loss:  0.2498241364955902\n",
      "Eval Loss:  0.26605576276779175\n",
      "Eval Loss:  0.25742942094802856\n",
      "Eval Loss:  0.2654412090778351\n",
      "Eval Loss:  0.27381712198257446\n",
      "Eval Loss:  0.26616519689559937\n",
      "Eval Loss:  0.2575923800468445\n",
      "Eval Loss:  0.3042418360710144\n",
      "Eval Loss:  0.2096327543258667\n",
      "Eval Loss:  0.18342269957065582\n",
      "Eval Loss:  0.264395147562027\n",
      "Eval Loss:  0.22284212708473206\n",
      "Eval Loss:  0.33816513419151306\n",
      "Eval Loss:  0.29454511404037476\n",
      "Eval Loss:  0.2768135964870453\n",
      "Eval Loss:  0.24062682688236237\n",
      "Eval Loss:  0.2811315059661865\n",
      "Eval Loss:  0.27048271894454956\n",
      "Eval Loss:  0.2440226972103119\n",
      "Eval Loss:  0.3071603775024414\n",
      "Eval Loss:  0.20393742620944977\n",
      "Eval Loss:  0.3272368609905243\n",
      "Eval Loss:  0.2781248390674591\n",
      "Eval Loss:  0.29552358388900757\n",
      "Eval Loss:  0.1993342489004135\n",
      "[[15376  1651]\n",
      " [ 1518 10975]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91     17027\n",
      "           1       0.87      0.88      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8926490514905149\n",
      "pre:  0.8692380801520672\n",
      "rec:  0.8784919554950772\n",
      "ma F1:  0.8902087828981011\n",
      "mi F1:  0.8926490514905149\n",
      "we F1:  0.8927227973943528\n",
      "29520 462\n",
      "Loss:  0.07882646471261978\n",
      "Loss:  0.07866524904966354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.055372439324855804\n",
      "39 **********\n",
      "Epoch:  2113.862960100174  fold:  4  kers:  32\n",
      "epoch:  40\n",
      "29520 462\n",
      "Loss:  0.07681319862604141\n",
      "Loss:  0.04616314172744751\n",
      "Loss:  0.06348969042301178\n",
      "40 **********\n",
      "Epoch:  2153.927834033966  fold:  4  kers:  32\n",
      "epoch:  41\n",
      "29520 462\n",
      "Loss:  0.044179268181324005\n",
      "Loss:  0.06695231795310974\n",
      "Loss:  0.06796777993440628\n",
      "41 **********\n",
      "Epoch:  2193.960794210434  fold:  4  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.0524374358355999\n",
      "Eval Loss:  0.18734188377857208\n",
      "Eval Loss:  0.047544896602630615\n",
      "[[2965  172]\n",
      " [ 165   69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      3137\n",
      "           1       0.29      0.29      0.29       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.62      0.62      0.62      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.9000296647878968\n",
      "pre:  0.2863070539419087\n",
      "rec:  0.2948717948717949\n",
      "ma F1:  0.6183762901749347\n",
      "mi F1:  0.9000296647878968\n",
      "we F1:  0.9007104567845441\n",
      "Eval Loss:  0.29989346861839294\n",
      "Eval Loss:  0.274235337972641\n",
      "Eval Loss:  0.21176499128341675\n",
      "Eval Loss:  0.24871826171875\n",
      "Eval Loss:  0.2691020965576172\n",
      "Eval Loss:  0.22837719321250916\n",
      "Eval Loss:  0.24901442229747772\n",
      "Eval Loss:  0.29441094398498535\n",
      "Eval Loss:  0.23806235194206238\n",
      "Eval Loss:  0.24232596158981323\n",
      "Eval Loss:  0.29276010394096375\n",
      "Eval Loss:  0.20081377029418945\n",
      "Eval Loss:  0.17792725563049316\n",
      "Eval Loss:  0.2526233196258545\n",
      "Eval Loss:  0.21539829671382904\n",
      "Eval Loss:  0.3234596848487854\n",
      "Eval Loss:  0.2800753116607666\n",
      "Eval Loss:  0.2738848924636841\n",
      "Eval Loss:  0.22163020074367523\n",
      "Eval Loss:  0.28290319442749023\n",
      "Eval Loss:  0.2633076608181\n",
      "Eval Loss:  0.2491607666015625\n",
      "Eval Loss:  0.3020991384983063\n",
      "Eval Loss:  0.20348896086215973\n",
      "Eval Loss:  0.31325602531433105\n",
      "Eval Loss:  0.27137434482574463\n",
      "Eval Loss:  0.27066394686698914\n",
      "Eval Loss:  0.202425017952919\n",
      "[[15437  1590]\n",
      " [ 1556 10937]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     17027\n",
      "           1       0.87      0.88      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8934281842818428\n",
      "pre:  0.8730741598148001\n",
      "rec:  0.8754502521411991\n",
      "ma F1:  0.8908927884147708\n",
      "mi F1:  0.8934281842818428\n",
      "we F1:  0.8934473406061719\n",
      "29520 462\n",
      "Loss:  0.06533357501029968\n",
      "Loss:  0.08255653828382492\n",
      "Loss:  0.10279491543769836\n",
      "42 **********\n",
      "Epoch:  2271.9522614479065  fold:  4  kers:  32\n",
      "epoch:  43\n",
      "29520 462\n",
      "Loss:  0.06552812457084656\n",
      "Loss:  0.0754661113023758\n",
      "Loss:  0.05825154483318329\n",
      "43 **********\n",
      "Epoch:  2312.0899415016174  fold:  4  kers:  32\n",
      "epoch:  44\n",
      "29520 462\n",
      "Loss:  0.07115928083658218\n",
      "Loss:  0.0909082293510437\n",
      "Loss:  0.06625217944383621\n",
      "44 **********\n",
      "Epoch:  2352.149829149246  fold:  4  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.044300489127635956\n",
      "Eval Loss:  0.18598929047584534\n",
      "Eval Loss:  0.09487973153591156\n",
      "[[2911  226]\n",
      " [ 184   50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      3137\n",
      "           1       0.18      0.21      0.20       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.56      0.57      0.57      3371\n",
      "weighted avg       0.89      0.88      0.88      3371\n",
      "\n",
      "acc:  0.8783743696232572\n",
      "pre:  0.18115942028985507\n",
      "rec:  0.21367521367521367\n",
      "ma F1:  0.5651444788441693\n",
      "mi F1:  0.8783743696232572\n",
      "we F1:  0.8829726413508776\n",
      "Eval Loss:  0.32121551036834717\n",
      "Eval Loss:  0.29861512780189514\n",
      "Eval Loss:  0.19987784326076508\n",
      "Eval Loss:  0.23560813069343567\n",
      "Eval Loss:  0.291014164686203\n",
      "Eval Loss:  0.22294682264328003\n",
      "Eval Loss:  0.253894180059433\n",
      "Eval Loss:  0.29878711700439453\n",
      "Eval Loss:  0.22133466601371765\n",
      "Eval Loss:  0.2601146697998047\n",
      "Eval Loss:  0.2918403148651123\n",
      "Eval Loss:  0.22851267457008362\n",
      "Eval Loss:  0.20363099873065948\n",
      "Eval Loss:  0.2337009161710739\n",
      "Eval Loss:  0.2367543876171112\n",
      "Eval Loss:  0.35568952560424805\n",
      "Eval Loss:  0.2984853982925415\n",
      "Eval Loss:  0.2597430944442749\n",
      "Eval Loss:  0.22011500597000122\n",
      "Eval Loss:  0.31270289421081543\n",
      "Eval Loss:  0.2438436895608902\n",
      "Eval Loss:  0.26376277208328247\n",
      "Eval Loss:  0.2888566851615906\n",
      "Eval Loss:  0.20812757313251495\n",
      "Eval Loss:  0.36327415704727173\n",
      "Eval Loss:  0.2816903293132782\n",
      "Eval Loss:  0.29066938161849976\n",
      "Eval Loss:  0.2062384933233261\n",
      "[[15144  1883]\n",
      " [ 1335 11158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90     17027\n",
      "           1       0.86      0.89      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8909891598915989\n",
      "pre:  0.8556092324208266\n",
      "rec:  0.8931401584887537\n",
      "ma F1:  0.8889647295529561\n",
      "mi F1:  0.8909891598915989\n",
      "we F1:  0.8912674809717737\n",
      "29520 462\n",
      "Loss:  0.0675184428691864\n",
      "Loss:  0.060415901243686676\n",
      "Loss:  0.06889189034700394\n",
      "45 **********\n",
      "Epoch:  2430.2619726657867  fold:  4  kers:  32\n",
      "epoch:  46\n",
      "29520 462\n",
      "Loss:  0.08430849015712738\n",
      "Loss:  0.06035950034856796\n",
      "Loss:  0.08110794425010681\n",
      "46 **********\n",
      "Epoch:  2470.420597553253  fold:  4  kers:  32\n",
      "epoch:  47\n",
      "29520 462\n",
      "Loss:  0.044936299324035645\n",
      "Loss:  0.0651186928153038\n",
      "Loss:  0.07854267954826355\n",
      "47 **********\n",
      "Epoch:  2510.590192079544  fold:  4  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.04582693800330162\n",
      "Eval Loss:  0.2502609193325043\n",
      "Eval Loss:  0.09902738779783249\n",
      "[[2843  294]\n",
      " [ 158   76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      3137\n",
      "           1       0.21      0.32      0.25       234\n",
      "\n",
      "    accuracy                           0.87      3371\n",
      "   macro avg       0.58      0.62      0.59      3371\n",
      "weighted avg       0.90      0.87      0.88      3371\n",
      "\n",
      "acc:  0.8659151587066153\n",
      "pre:  0.20540540540540542\n",
      "rec:  0.3247863247863248\n",
      "ma F1:  0.589008003556177\n",
      "mi F1:  0.8659151587066153\n",
      "we F1:  0.8795253405282485\n",
      "Eval Loss:  0.3363880217075348\n",
      "Eval Loss:  0.2991693317890167\n",
      "Eval Loss:  0.21882343292236328\n",
      "Eval Loss:  0.24644909799098969\n",
      "Eval Loss:  0.28228437900543213\n",
      "Eval Loss:  0.2381601631641388\n",
      "Eval Loss:  0.2706203758716583\n",
      "Eval Loss:  0.2953573763370514\n",
      "Eval Loss:  0.2509121000766754\n",
      "Eval Loss:  0.28842777013778687\n",
      "Eval Loss:  0.30992209911346436\n",
      "Eval Loss:  0.21978089213371277\n",
      "Eval Loss:  0.1762077957391739\n",
      "Eval Loss:  0.2342432290315628\n",
      "Eval Loss:  0.22627244889736176\n",
      "Eval Loss:  0.34776365756988525\n",
      "Eval Loss:  0.31597191095352173\n",
      "Eval Loss:  0.2565302550792694\n",
      "Eval Loss:  0.23757269978523254\n",
      "Eval Loss:  0.3211551904678345\n",
      "Eval Loss:  0.2503875195980072\n",
      "Eval Loss:  0.25925213098526\n",
      "Eval Loss:  0.3285581171512604\n",
      "Eval Loss:  0.1917635202407837\n",
      "Eval Loss:  0.3727646768093109\n",
      "Eval Loss:  0.28910598158836365\n",
      "Eval Loss:  0.30407842993736267\n",
      "Eval Loss:  0.20851723849773407\n",
      "[[14866  2161]\n",
      " [ 1110 11383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90     17027\n",
      "           1       0.84      0.91      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8891937669376694\n",
      "pre:  0.8404459539279385\n",
      "rec:  0.9111502441367165\n",
      "ma F1:  0.8876294426889033\n",
      "mi F1:  0.8891937669376694\n",
      "we F1:  0.8896658039131082\n",
      "29520 462\n",
      "Loss:  0.057786501944065094\n",
      "Loss:  0.0460120365023613\n",
      "Loss:  0.06841357052326202\n",
      "48 **********\n",
      "Epoch:  2588.6065917015076  fold:  4  kers:  32\n",
      "epoch:  49\n",
      "29520 462\n",
      "Loss:  0.05895106866955757\n",
      "Loss:  0.08537227660417557\n",
      "Loss:  0.045317962765693665\n",
      "49 **********\n",
      "Epoch:  2628.6694712638855  fold:  4  kers:  32\n",
      "epoch:  50\n",
      "29520 462\n",
      "Loss:  0.0680447667837143\n",
      "Loss:  0.07581107318401337\n",
      "Loss:  0.081761434674263\n",
      "50 **********\n",
      "Epoch:  2668.719386816025  fold:  4  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.040036335587501526\n",
      "Eval Loss:  0.20497658848762512\n",
      "Eval Loss:  0.03242190554738045\n",
      "[[2982  155]\n",
      " [ 168   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      3137\n",
      "           1       0.30      0.28      0.29       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.62      0.62      0.62      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.904182735093444\n",
      "pre:  0.2986425339366516\n",
      "rec:  0.28205128205128205\n",
      "ma F1:  0.6193670175855638\n",
      "mi F1:  0.904182735093444\n",
      "we F1:  0.9029129805229356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2962404787540436\n",
      "Eval Loss:  0.2720837891101837\n",
      "Eval Loss:  0.20700816810131073\n",
      "Eval Loss:  0.23987461626529694\n",
      "Eval Loss:  0.2672366797924042\n",
      "Eval Loss:  0.2198927253484726\n",
      "Eval Loss:  0.24987955391407013\n",
      "Eval Loss:  0.2875802218914032\n",
      "Eval Loss:  0.23154747486114502\n",
      "Eval Loss:  0.2442813664674759\n",
      "Eval Loss:  0.29173919558525085\n",
      "Eval Loss:  0.19266191124916077\n",
      "Eval Loss:  0.1686248928308487\n",
      "Eval Loss:  0.21729350090026855\n",
      "Eval Loss:  0.18758529424667358\n",
      "Eval Loss:  0.33118724822998047\n",
      "Eval Loss:  0.2668026387691498\n",
      "Eval Loss:  0.24490775167942047\n",
      "Eval Loss:  0.21627481281757355\n",
      "Eval Loss:  0.29524385929107666\n",
      "Eval Loss:  0.2575145363807678\n",
      "Eval Loss:  0.24461543560028076\n",
      "Eval Loss:  0.3022816777229309\n",
      "Eval Loss:  0.19306610524654388\n",
      "Eval Loss:  0.3389217257499695\n",
      "Eval Loss:  0.2577657103538513\n",
      "Eval Loss:  0.28021544218063354\n",
      "Eval Loss:  0.19601911306381226\n",
      "[[15354  1673]\n",
      " [ 1345 11148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91     17027\n",
      "           1       0.87      0.89      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.89      0.90      0.90     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.8977642276422764\n",
      "pre:  0.8695109585835739\n",
      "rec:  0.8923397102377332\n",
      "ma F1:  0.8956457894010452\n",
      "mi F1:  0.8977642276422764\n",
      "we F1:  0.8979294315754965\n",
      "29520 462\n",
      "Loss:  0.0688086599111557\n",
      "Loss:  0.09021046757698059\n",
      "Loss:  0.056888479739427567\n",
      "51 **********\n",
      "Epoch:  2746.804602622986  fold:  4  kers:  32\n",
      "epoch:  52\n",
      "29520 462\n",
      "Loss:  0.062303125858306885\n",
      "Loss:  0.08661473542451859\n",
      "Loss:  0.09265082329511642\n",
      "52 **********\n",
      "Epoch:  2786.888426542282  fold:  4  kers:  32\n",
      "epoch:  53\n",
      "29520 462\n",
      "Loss:  0.070713110268116\n",
      "Loss:  0.08044134080410004\n",
      "Loss:  0.06956972181797028\n",
      "53 **********\n",
      "Epoch:  2826.939338684082  fold:  4  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.04327680915594101\n",
      "Eval Loss:  0.23087820410728455\n",
      "Eval Loss:  0.04867604374885559\n",
      "[[2967  170]\n",
      " [ 166   68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      3137\n",
      "           1       0.29      0.29      0.29       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.62      0.62      0.62      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.9003263126668645\n",
      "pre:  0.2857142857142857\n",
      "rec:  0.2905982905982906\n",
      "ma F1:  0.6172735382369637\n",
      "mi F1:  0.9003263126668645\n",
      "we F1:  0.9007168649599722\n",
      "Eval Loss:  0.2924409508705139\n",
      "Eval Loss:  0.2767251133918762\n",
      "Eval Loss:  0.20951293408870697\n",
      "Eval Loss:  0.23378083109855652\n",
      "Eval Loss:  0.2669501006603241\n",
      "Eval Loss:  0.23373737931251526\n",
      "Eval Loss:  0.247847780585289\n",
      "Eval Loss:  0.28153786063194275\n",
      "Eval Loss:  0.228720024228096\n",
      "Eval Loss:  0.2634165287017822\n",
      "Eval Loss:  0.28157538175582886\n",
      "Eval Loss:  0.1833707094192505\n",
      "Eval Loss:  0.16563379764556885\n",
      "Eval Loss:  0.2275419980287552\n",
      "Eval Loss:  0.1950555443763733\n",
      "Eval Loss:  0.34832221269607544\n",
      "Eval Loss:  0.29037320613861084\n",
      "Eval Loss:  0.24631114304065704\n",
      "Eval Loss:  0.21000003814697266\n",
      "Eval Loss:  0.3116420805454254\n",
      "Eval Loss:  0.2521890699863434\n",
      "Eval Loss:  0.23645880818367004\n",
      "Eval Loss:  0.30819717049598694\n",
      "Eval Loss:  0.17959558963775635\n",
      "Eval Loss:  0.3567889928817749\n",
      "Eval Loss:  0.2568339705467224\n",
      "Eval Loss:  0.27858662605285645\n",
      "Eval Loss:  0.19187331199645996\n",
      "[[15110  1917]\n",
      " [ 1118 11375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     17027\n",
      "           1       0.86      0.91      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.89      0.90      0.90     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.8971883468834688\n",
      "pre:  0.8557779115257298\n",
      "rec:  0.9105098855359001\n",
      "ma F1:  0.8955157184829375\n",
      "mi F1:  0.8971883468834688\n",
      "we F1:  0.8975461594917753\n",
      "29520 462\n",
      "Loss:  0.059294652193784714\n",
      "Loss:  0.05484146252274513\n",
      "Loss:  0.06459714472293854\n",
      "54 **********\n",
      "Epoch:  2905.0215623378754  fold:  4  kers:  32\n",
      "epoch:  55\n",
      "29520 462\n",
      "Loss:  0.030231241136789322\n",
      "Loss:  0.05632270127534866\n",
      "Loss:  0.06470907479524612\n",
      "55 **********\n",
      "Epoch:  2944.9986715316772  fold:  4  kers:  32\n",
      "epoch:  56\n",
      "29520 462\n",
      "Loss:  0.054718706756830215\n",
      "Loss:  0.0768657699227333\n",
      "Loss:  0.05882463976740837\n",
      "56 **********\n",
      "Epoch:  2985.0465919971466  fold:  4  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.03769728168845177\n",
      "Eval Loss:  0.1634860634803772\n",
      "Eval Loss:  0.025038551539182663\n",
      "[[3056   81]\n",
      " [ 203   31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      3137\n",
      "           1       0.28      0.13      0.18       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.61      0.55      0.57      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.915752002373183\n",
      "pre:  0.2767857142857143\n",
      "rec:  0.13247863247863248\n",
      "ma F1:  0.567393999862631\n",
      "mi F1:  0.915752002373183\n",
      "we F1:  0.9017025226025096\n",
      "Eval Loss:  0.29409703612327576\n",
      "Eval Loss:  0.2632693350315094\n",
      "Eval Loss:  0.2124198079109192\n",
      "Eval Loss:  0.23179662227630615\n",
      "Eval Loss:  0.2581154704093933\n",
      "Eval Loss:  0.19870954751968384\n",
      "Eval Loss:  0.25077763199806213\n",
      "Eval Loss:  0.30306151509284973\n",
      "Eval Loss:  0.23543967306613922\n",
      "Eval Loss:  0.22605237364768982\n",
      "Eval Loss:  0.2858443260192871\n",
      "Eval Loss:  0.2000395655632019\n",
      "Eval Loss:  0.1606094241142273\n",
      "Eval Loss:  0.22699081897735596\n",
      "Eval Loss:  0.18343330919742584\n",
      "Eval Loss:  0.31310731172561646\n",
      "Eval Loss:  0.239717498421669\n",
      "Eval Loss:  0.2495565414428711\n",
      "Eval Loss:  0.20350849628448486\n",
      "Eval Loss:  0.2827375829219818\n",
      "Eval Loss:  0.2714783251285553\n",
      "Eval Loss:  0.25060218572616577\n",
      "Eval Loss:  0.281114786863327\n",
      "Eval Loss:  0.20552964508533478\n",
      "Eval Loss:  0.3193393349647522\n",
      "Eval Loss:  0.2742634117603302\n",
      "Eval Loss:  0.288618803024292\n",
      "Eval Loss:  0.20352773368358612\n",
      "[[15828  1199]\n",
      " [ 1688 10805]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     17027\n",
      "           1       0.90      0.86      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.90      0.90     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9022018970189702\n",
      "pre:  0.9001166277907364\n",
      "rec:  0.8648843352277276\n",
      "ma F1:  0.8992859217772204\n",
      "mi F1:  0.9022018970189702\n",
      "we F1:  0.9019180204724412\n",
      "29520 462\n",
      "Loss:  0.04885919764637947\n",
      "Loss:  0.06661846488714218\n",
      "Loss:  0.07345539331436157\n",
      "57 **********\n",
      "Epoch:  3062.9373276233673  fold:  4  kers:  32\n",
      "epoch:  58\n",
      "29520 462\n",
      "Loss:  0.07904762029647827\n",
      "Loss:  0.06301768124103546\n",
      "Loss:  0.07493322342634201\n",
      "58 **********\n",
      "Epoch:  3103.073013305664  fold:  4  kers:  32\n",
      "epoch:  59\n",
      "29520 462\n",
      "Loss:  0.0647941380739212\n",
      "Loss:  0.05869286507368088\n",
      "Loss:  0.07338104397058487\n",
      "59 **********\n",
      "Epoch:  3143.1807732582092  fold:  4  kers:  32\n",
      "Eval Loss:  0.03272522985935211\n",
      "Eval Loss:  0.2101122885942459\n",
      "Eval Loss:  0.03669704124331474\n",
      "[[3017  120]\n",
      " [ 202   32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.21      0.14      0.17       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.57      0.55      0.56      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9044793829724117\n",
      "pre:  0.21052631578947367\n",
      "rec:  0.13675213675213677\n",
      "ma F1:  0.5575711579283742\n",
      "mi F1:  0.9044793829724117\n",
      "we F1:  0.8949495757852723\n",
      "update!  Acc:  0.925541382379116\n",
      "Epoch:  3147.081344127655  fold:  4  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29673 3218\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29673 464\n",
      "Loss:  0.16830240190029144\n",
      "Loss:  0.16291935741901398\n",
      "Loss:  0.15809711813926697\n",
      "0 **********\n",
      "Epoch:  52.832735538482666  fold:  5  kers:  32\n",
      "epoch:  1\n",
      "29673 464\n",
      "Loss:  0.17036214470863342\n",
      "Loss:  0.14218732714653015\n",
      "Loss:  0.12717944383621216\n",
      "1 **********\n",
      "Epoch:  93.32845830917358  fold:  5  kers:  32\n",
      "epoch:  2\n",
      "29673 464\n",
      "Loss:  0.13240548968315125\n",
      "Loss:  0.11321613937616348\n",
      "Loss:  0.11900549381971359\n",
      "2 **********\n",
      "Epoch:  133.79625582695007  fold:  5  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.18907514214515686\n",
      "Eval Loss:  0.3741367757320404\n",
      "Eval Loss:  0.4294656217098236\n",
      "[[2648  449]\n",
      " [  35   86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      3097\n",
      "           1       0.16      0.71      0.26       121\n",
      "\n",
      "    accuracy                           0.85      3218\n",
      "   macro avg       0.57      0.78      0.59      3218\n",
      "weighted avg       0.96      0.85      0.89      3218\n",
      "\n",
      "acc:  0.8495960223741454\n",
      "pre:  0.16074766355140188\n",
      "rec:  0.7107438016528925\n",
      "ma F1:  0.5892290488648831\n",
      "mi F1:  0.8495960223741454\n",
      "we F1:  0.8916693740653377\n",
      "update!  Acc:  0.8495960223741454\n",
      "Eval Loss:  0.4880529046058655\n",
      "Eval Loss:  0.40099549293518066\n",
      "Eval Loss:  0.5148635506629944\n",
      "Eval Loss:  0.429810106754303\n",
      "Eval Loss:  0.4174513816833496\n",
      "Eval Loss:  0.40267354249954224\n",
      "Eval Loss:  0.4296706020832062\n",
      "Eval Loss:  0.3519798517227173\n",
      "Eval Loss:  0.4177607297897339\n",
      "Eval Loss:  0.5051020383834839\n",
      "Eval Loss:  0.44334205985069275\n",
      "Eval Loss:  0.4273616075515747\n",
      "Eval Loss:  0.3802962601184845\n",
      "Eval Loss:  0.4315124750137329\n",
      "Eval Loss:  0.4419882893562317\n",
      "Eval Loss:  0.42637941241264343\n",
      "Eval Loss:  0.41747164726257324\n",
      "Eval Loss:  0.49280691146850586\n",
      "Eval Loss:  0.49785324931144714\n",
      "Eval Loss:  0.4309624135494232\n",
      "Eval Loss:  0.45910635590553284\n",
      "Eval Loss:  0.5241354703903198\n",
      "Eval Loss:  0.4698321223258972\n",
      "Eval Loss:  0.45431068539619446\n",
      "Eval Loss:  0.477260559797287\n",
      "Eval Loss:  0.3945724368095398\n",
      "Eval Loss:  0.4920414388179779\n",
      "Eval Loss:  0.46692442893981934\n",
      "Eval Loss:  0.377231240272522\n",
      "[[13946  3121]\n",
      " [ 2863  9743]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82     17067\n",
      "           1       0.76      0.77      0.77     12606\n",
      "\n",
      "    accuracy                           0.80     29673\n",
      "   macro avg       0.79      0.80      0.79     29673\n",
      "weighted avg       0.80      0.80      0.80     29673\n",
      "\n",
      "acc:  0.7983351868702188\n",
      "pre:  0.7573849502487562\n",
      "rec:  0.7728859273361891\n",
      "ma F1:  0.7942063489083238\n",
      "mi F1:  0.7983351868702188\n",
      "we F1:  0.7985886344538896\n",
      "29673 464\n",
      "Loss:  0.0933232456445694\n",
      "Loss:  0.12230394780635834\n",
      "Loss:  0.08932971209287643\n",
      "3 **********\n",
      "Epoch:  212.3252854347229  fold:  5  kers:  32\n",
      "epoch:  4\n",
      "29673 464\n",
      "Loss:  0.12156030535697937\n",
      "Loss:  0.10725735127925873\n",
      "Loss:  0.08463292568922043\n",
      "4 **********\n",
      "Epoch:  252.63749814033508  fold:  5  kers:  32\n",
      "epoch:  5\n",
      "29673 464\n",
      "Loss:  0.08582107722759247\n",
      "Loss:  0.10234545171260834\n",
      "Loss:  0.07403453439474106\n",
      "5 **********\n",
      "Epoch:  293.1970500946045  fold:  5  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.1353563815355301\n",
      "Eval Loss:  0.3095819652080536\n",
      "Eval Loss:  0.21754750609397888\n",
      "[[2934  163]\n",
      " [  47   74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      3097\n",
      "           1       0.31      0.61      0.41       121\n",
      "\n",
      "    accuracy                           0.93      3218\n",
      "   macro avg       0.65      0.78      0.69      3218\n",
      "weighted avg       0.96      0.93      0.94      3218\n",
      "\n",
      "acc:  0.9347420758234929\n",
      "pre:  0.31223628691983124\n",
      "rec:  0.6115702479338843\n",
      "ma F1:  0.6894284910686219\n",
      "mi F1:  0.9347420758234929\n",
      "we F1:  0.9446918575827815\n",
      "update!  Acc:  0.9347420758234929\n",
      "Eval Loss:  0.5079776048660278\n",
      "Eval Loss:  0.32713252305984497\n",
      "Eval Loss:  0.4742071330547333\n",
      "Eval Loss:  0.4131059944629669\n",
      "Eval Loss:  0.4202801585197449\n",
      "Eval Loss:  0.35926729440689087\n",
      "Eval Loss:  0.42006731033325195\n",
      "Eval Loss:  0.31372129917144775\n",
      "Eval Loss:  0.4366035461425781\n",
      "Eval Loss:  0.44262194633483887\n",
      "Eval Loss:  0.3990827798843384\n",
      "Eval Loss:  0.36816149950027466\n",
      "Eval Loss:  0.32053133845329285\n",
      "Eval Loss:  0.43711042404174805\n",
      "Eval Loss:  0.4799308478832245\n",
      "Eval Loss:  0.456452876329422\n",
      "Eval Loss:  0.45076194405555725\n",
      "Eval Loss:  0.5594598650932312\n",
      "Eval Loss:  0.4639774262905121\n",
      "Eval Loss:  0.3910156488418579\n",
      "Eval Loss:  0.44546443223953247\n",
      "Eval Loss:  0.5467273592948914\n",
      "Eval Loss:  0.48089829087257385\n",
      "Eval Loss:  0.47743961215019226\n",
      "Eval Loss:  0.54140305519104\n",
      "Eval Loss:  0.38286152482032776\n",
      "Eval Loss:  0.4586145877838135\n",
      "Eval Loss:  0.4853174686431885\n",
      "Eval Loss:  0.33972615003585815\n",
      "[[15799  1268]\n",
      " [ 4047  8559]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86     17067\n",
      "           1       0.87      0.68      0.76     12606\n",
      "\n",
      "    accuracy                           0.82     29673\n",
      "   macro avg       0.83      0.80      0.81     29673\n",
      "weighted avg       0.83      0.82      0.82     29673\n",
      "\n",
      "acc:  0.820880935530617\n",
      "pre:  0.8709677419354839\n",
      "rec:  0.6789623988576868\n",
      "ma F1:  0.8095425232202991\n",
      "mi F1:  0.8208809355306171\n",
      "we F1:  0.8165288018551512\n",
      "29673 464\n",
      "Loss:  0.10415853559970856\n",
      "Loss:  0.12207341939210892\n",
      "Loss:  0.07795482873916626\n",
      "6 **********\n",
      "Epoch:  371.64828753471375  fold:  5  kers:  32\n",
      "epoch:  7\n",
      "29673 464\n",
      "Loss:  0.11718448996543884\n",
      "Loss:  0.08064258843660355\n",
      "Loss:  0.08207657188177109\n",
      "7 **********\n",
      "Epoch:  412.0343039035797  fold:  5  kers:  32\n",
      "epoch:  8\n",
      "29673 464\n",
      "Loss:  0.12022773176431656\n",
      "Loss:  0.08243553340435028\n",
      "Loss:  0.06896374374628067\n",
      "8 **********\n",
      "Epoch:  452.3764371871948  fold:  5  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.11776536703109741\n",
      "Eval Loss:  0.25286179780960083\n",
      "Eval Loss:  0.15289443731307983\n",
      "[[2974  123]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      3097\n",
      "           1       0.42      0.73      0.53       121\n",
      "\n",
      "    accuracy                           0.95      3218\n",
      "   macro avg       0.70      0.84      0.75      3218\n",
      "weighted avg       0.97      0.95      0.96      3218\n",
      "\n",
      "acc:  0.9515226848974518\n",
      "pre:  0.41706161137440756\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.7522817350660834\n",
      "mi F1:  0.9515226848974518\n",
      "we F1:  0.9577360201312782\n",
      "update!  Acc:  0.9515226848974518\n",
      "Eval Loss:  0.43342071771621704\n",
      "Eval Loss:  0.32837212085723877\n",
      "Eval Loss:  0.40235966444015503\n",
      "Eval Loss:  0.3858141005039215\n",
      "Eval Loss:  0.3890233337879181\n",
      "Eval Loss:  0.3124242126941681\n",
      "Eval Loss:  0.33578309416770935\n",
      "Eval Loss:  0.2756066620349884\n",
      "Eval Loss:  0.3441525399684906\n",
      "Eval Loss:  0.36894622445106506\n",
      "Eval Loss:  0.3407323658466339\n",
      "Eval Loss:  0.35082492232322693\n",
      "Eval Loss:  0.3019588589668274\n",
      "Eval Loss:  0.38660696148872375\n",
      "Eval Loss:  0.3865531086921692\n",
      "Eval Loss:  0.38223955035209656\n",
      "Eval Loss:  0.38669008016586304\n",
      "Eval Loss:  0.4902190864086151\n",
      "Eval Loss:  0.40243715047836304\n",
      "Eval Loss:  0.3322654366493225\n",
      "Eval Loss:  0.38624730706214905\n",
      "Eval Loss:  0.4935147762298584\n",
      "Eval Loss:  0.40319862961769104\n",
      "Eval Loss:  0.42020383477211\n",
      "Eval Loss:  0.45060816407203674\n",
      "Eval Loss:  0.3508760333061218\n",
      "Eval Loss:  0.3608425259590149\n",
      "Eval Loss:  0.4142686426639557\n",
      "Eval Loss:  0.2983247637748718\n",
      "[[15903  1164]\n",
      " [ 3520  9086]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87     17067\n",
      "           1       0.89      0.72      0.80     12606\n",
      "\n",
      "    accuracy                           0.84     29673\n",
      "   macro avg       0.85      0.83      0.83     29673\n",
      "weighted avg       0.85      0.84      0.84     29673\n",
      "\n",
      "acc:  0.8421460587065682\n",
      "pre:  0.8864390243902439\n",
      "rec:  0.7207678883071553\n",
      "ma F1:  0.8333504089564576\n",
      "mi F1:  0.8421460587065682\n",
      "we F1:  0.8391062243496282\n",
      "29673 464\n",
      "Loss:  0.09405694901943207\n",
      "Loss:  0.11733440309762955\n",
      "Loss:  0.10680080950260162\n",
      "9 **********\n",
      "Epoch:  530.8984849452972  fold:  5  kers:  32\n",
      "epoch:  10\n",
      "29673 464\n",
      "Loss:  0.08062972128391266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09249769151210785\n",
      "Loss:  0.06517758220434189\n",
      "10 **********\n",
      "Epoch:  571.4520530700684  fold:  5  kers:  32\n",
      "epoch:  11\n",
      "29673 464\n",
      "Loss:  0.1068514958024025\n",
      "Loss:  0.09129149466753006\n",
      "Loss:  0.08779053390026093\n",
      "11 **********\n",
      "Epoch:  611.7931895256042  fold:  5  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.09839770197868347\n",
      "Eval Loss:  0.19678306579589844\n",
      "Eval Loss:  0.12217523902654648\n",
      "[[3019   78]\n",
      " [  41   80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.51      0.66      0.57       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.75      0.82      0.78      3218\n",
      "weighted avg       0.97      0.96      0.97      3218\n",
      "\n",
      "acc:  0.9630205096333126\n",
      "pre:  0.5063291139240507\n",
      "rec:  0.6611570247933884\n",
      "ma F1:  0.7770745539505985\n",
      "mi F1:  0.9630205096333128\n",
      "we F1:  0.9653614420457864\n",
      "update!  Acc:  0.9630205096333126\n",
      "Eval Loss:  0.47680628299713135\n",
      "Eval Loss:  0.33476653695106506\n",
      "Eval Loss:  0.4250752031803131\n",
      "Eval Loss:  0.4118508994579315\n",
      "Eval Loss:  0.4467098116874695\n",
      "Eval Loss:  0.32940128445625305\n",
      "Eval Loss:  0.4212145507335663\n",
      "Eval Loss:  0.3068753480911255\n",
      "Eval Loss:  0.38459205627441406\n",
      "Eval Loss:  0.3961699604988098\n",
      "Eval Loss:  0.3590070605278015\n",
      "Eval Loss:  0.3667454123497009\n",
      "Eval Loss:  0.30120742321014404\n",
      "Eval Loss:  0.38916847109794617\n",
      "Eval Loss:  0.45091789960861206\n",
      "Eval Loss:  0.41713404655456543\n",
      "Eval Loss:  0.44977790117263794\n",
      "Eval Loss:  0.5727066397666931\n",
      "Eval Loss:  0.42791280150413513\n",
      "Eval Loss:  0.3685821294784546\n",
      "Eval Loss:  0.41030266880989075\n",
      "Eval Loss:  0.5521956086158752\n",
      "Eval Loss:  0.4684953987598419\n",
      "Eval Loss:  0.47260573506355286\n",
      "Eval Loss:  0.49594974517822266\n",
      "Eval Loss:  0.3587687313556671\n",
      "Eval Loss:  0.4352342188358307\n",
      "Eval Loss:  0.485623836517334\n",
      "Eval Loss:  0.31154781579971313\n",
      "[[16329   738]\n",
      " [ 4310  8296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87     17067\n",
      "           1       0.92      0.66      0.77     12606\n",
      "\n",
      "    accuracy                           0.83     29673\n",
      "   macro avg       0.85      0.81      0.82     29673\n",
      "weighted avg       0.85      0.83      0.82     29673\n",
      "\n",
      "acc:  0.8298790145923904\n",
      "pre:  0.9183086119105601\n",
      "rec:  0.6580993177851817\n",
      "ma F1:  0.8164251917721632\n",
      "mi F1:  0.8298790145923904\n",
      "we F1:  0.8238965603270038\n",
      "29673 464\n",
      "Loss:  0.07327495515346527\n",
      "Loss:  0.08903244882822037\n",
      "Loss:  0.06836463510990143\n",
      "12 **********\n",
      "Epoch:  690.0120477676392  fold:  5  kers:  32\n",
      "epoch:  13\n",
      "29673 464\n",
      "Loss:  0.08801824599504471\n",
      "Loss:  0.09825611859560013\n",
      "Loss:  0.0956469252705574\n",
      "13 **********\n",
      "Epoch:  730.301322221756  fold:  5  kers:  32\n",
      "epoch:  14\n",
      "29673 464\n",
      "Loss:  0.09983103722333908\n",
      "Loss:  0.08587570488452911\n",
      "Loss:  0.1083655059337616\n",
      "14 **********\n",
      "Epoch:  770.5048260688782  fold:  5  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.10130519419908524\n",
      "Eval Loss:  0.20718732476234436\n",
      "Eval Loss:  0.10415692627429962\n",
      "[[3022   75]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.54      0.74      0.62       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.86      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9667495338719702\n",
      "pre:  0.5426829268292683\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.803582929034503\n",
      "mi F1:  0.96674953387197\n",
      "we F1:  0.9691416798003748\n",
      "update!  Acc:  0.9667495338719702\n",
      "Eval Loss:  0.3725540041923523\n",
      "Eval Loss:  0.31081998348236084\n",
      "Eval Loss:  0.3570576608181\n",
      "Eval Loss:  0.3713792562484741\n",
      "Eval Loss:  0.3837295174598694\n",
      "Eval Loss:  0.27591487765312195\n",
      "Eval Loss:  0.2969444692134857\n",
      "Eval Loss:  0.26028403639793396\n",
      "Eval Loss:  0.28887850046157837\n",
      "Eval Loss:  0.3345794081687927\n",
      "Eval Loss:  0.3082610070705414\n",
      "Eval Loss:  0.3207641541957855\n",
      "Eval Loss:  0.28765103220939636\n",
      "Eval Loss:  0.31341642141342163\n",
      "Eval Loss:  0.32904213666915894\n",
      "Eval Loss:  0.3232868015766144\n",
      "Eval Loss:  0.36857694387435913\n",
      "Eval Loss:  0.459626168012619\n",
      "Eval Loss:  0.39017170667648315\n",
      "Eval Loss:  0.31509479880332947\n",
      "Eval Loss:  0.3448479473590851\n",
      "Eval Loss:  0.41820228099823\n",
      "Eval Loss:  0.3625878393650055\n",
      "Eval Loss:  0.37353429198265076\n",
      "Eval Loss:  0.4039820432662964\n",
      "Eval Loss:  0.320376992225647\n",
      "Eval Loss:  0.32137325406074524\n",
      "Eval Loss:  0.37770316004753113\n",
      "Eval Loss:  0.2844882905483246\n",
      "[[16022  1045]\n",
      " [ 3186  9420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88     17067\n",
      "           1       0.90      0.75      0.82     12606\n",
      "\n",
      "    accuracy                           0.86     29673\n",
      "   macro avg       0.87      0.84      0.85     29673\n",
      "weighted avg       0.86      0.86      0.86     29673\n",
      "\n",
      "acc:  0.857412462508004\n",
      "pre:  0.9001433349259437\n",
      "rec:  0.7472632079961923\n",
      "ma F1:  0.8499863971288584\n",
      "mi F1:  0.857412462508004\n",
      "we F1:  0.8550042216754152\n",
      "29673 464\n",
      "Loss:  0.09218745678663254\n",
      "Loss:  0.11222527176141739\n",
      "Loss:  0.09504826366901398\n",
      "15 **********\n",
      "Epoch:  848.5282077789307  fold:  5  kers:  32\n",
      "epoch:  16\n",
      "29673 464\n",
      "Loss:  0.07638613879680634\n",
      "Loss:  0.06857160478830338\n",
      "Loss:  0.09518157690763474\n",
      "16 **********\n",
      "Epoch:  888.647935628891  fold:  5  kers:  32\n",
      "epoch:  17\n",
      "29673 464\n",
      "Loss:  0.10365715622901917\n",
      "Loss:  0.08536307513713837\n",
      "Loss:  0.085385262966156\n",
      "17 **********\n",
      "Epoch:  928.7576904296875  fold:  5  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.08642550557851791\n",
      "Eval Loss:  0.15522272884845734\n",
      "Eval Loss:  0.09053897857666016\n",
      "[[3042   55]\n",
      " [  54   67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3097\n",
      "           1       0.55      0.55      0.55       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.77      0.77      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9661280298321939\n",
      "pre:  0.5491803278688525\n",
      "rec:  0.5537190082644629\n",
      "ma F1:  0.7669199062528449\n",
      "mi F1:  0.9661280298321939\n",
      "we F1:  0.9661949905460021\n",
      "Eval Loss:  0.4277547001838684\n",
      "Eval Loss:  0.33905038237571716\n",
      "Eval Loss:  0.42747342586517334\n",
      "Eval Loss:  0.42031756043434143\n",
      "Eval Loss:  0.45471352338790894\n",
      "Eval Loss:  0.33295494318008423\n",
      "Eval Loss:  0.42008331418037415\n",
      "Eval Loss:  0.3175763189792633\n",
      "Eval Loss:  0.3790000081062317\n",
      "Eval Loss:  0.43331199884414673\n",
      "Eval Loss:  0.33719828724861145\n",
      "Eval Loss:  0.35123032331466675\n",
      "Eval Loss:  0.30160680413246155\n",
      "Eval Loss:  0.385603129863739\n",
      "Eval Loss:  0.44166117906570435\n",
      "Eval Loss:  0.4073324203491211\n",
      "Eval Loss:  0.45918428897857666\n",
      "Eval Loss:  0.5769777894020081\n",
      "Eval Loss:  0.43812453746795654\n",
      "Eval Loss:  0.3698956370353699\n",
      "Eval Loss:  0.37066414952278137\n",
      "Eval Loss:  0.49914997816085815\n",
      "Eval Loss:  0.4674437940120697\n",
      "Eval Loss:  0.45933619141578674\n",
      "Eval Loss:  0.49142640829086304\n",
      "Eval Loss:  0.3596422076225281\n",
      "Eval Loss:  0.45078688859939575\n",
      "Eval Loss:  0.47751912474632263\n",
      "Eval Loss:  0.3183524012565613\n",
      "[[16545   522]\n",
      " [ 4476  8130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     17067\n",
      "           1       0.94      0.64      0.76     12606\n",
      "\n",
      "    accuracy                           0.83     29673\n",
      "   macro avg       0.86      0.81      0.82     29673\n",
      "weighted avg       0.85      0.83      0.82     29673\n",
      "\n",
      "acc:  0.8315640481245576\n",
      "pre:  0.9396671289875174\n",
      "rec:  0.6449309852451214\n",
      "ma F1:  0.8168330401489238\n",
      "mi F1:  0.8315640481245576\n",
      "we F1:  0.8246423124696965\n",
      "29673 464\n",
      "Loss:  0.11284290254116058\n",
      "Loss:  0.09820850193500519\n",
      "Loss:  0.07280901074409485\n",
      "18 **********\n",
      "Epoch:  1006.8169758319855  fold:  5  kers:  32\n",
      "epoch:  19\n",
      "29673 464\n",
      "Loss:  0.06367311626672745\n",
      "Loss:  0.08879198879003525\n",
      "Loss:  0.11049355566501617\n",
      "19 **********\n",
      "Epoch:  1046.9097754955292  fold:  5  kers:  32\n",
      "epoch:  20\n",
      "29673 464\n",
      "Loss:  0.09167495369911194\n",
      "Loss:  0.08661098778247833\n",
      "Loss:  0.06889782100915909\n",
      "20 **********\n",
      "Epoch:  1087.086351633072  fold:  5  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.08852963894605637\n",
      "Eval Loss:  0.17433129251003265\n",
      "Eval Loss:  0.08238890022039413\n",
      "[[3020   77]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.54      0.74      0.62       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.76      0.86      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc:  0.9661280298321939\n",
      "pre:  0.536144578313253\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.8012412998232623\n",
      "mi F1:  0.9661280298321939\n",
      "we F1:  0.9686595558814609\n",
      "Eval Loss:  0.3404600918292999\n",
      "Eval Loss:  0.2937578558921814\n",
      "Eval Loss:  0.3402555584907532\n",
      "Eval Loss:  0.35018742084503174\n",
      "Eval Loss:  0.3661177158355713\n",
      "Eval Loss:  0.27879950404167175\n",
      "Eval Loss:  0.29839181900024414\n",
      "Eval Loss:  0.23730474710464478\n",
      "Eval Loss:  0.26008695363998413\n",
      "Eval Loss:  0.33648744225502014\n",
      "Eval Loss:  0.2819790840148926\n",
      "Eval Loss:  0.2877807021141052\n",
      "Eval Loss:  0.2651645243167877\n",
      "Eval Loss:  0.2965349555015564\n",
      "Eval Loss:  0.29919564723968506\n",
      "Eval Loss:  0.3149354159832001\n",
      "Eval Loss:  0.3723647892475128\n",
      "Eval Loss:  0.44235360622406006\n",
      "Eval Loss:  0.392849862575531\n",
      "Eval Loss:  0.29737991094589233\n",
      "Eval Loss:  0.3061360716819763\n",
      "Eval Loss:  0.37208375334739685\n",
      "Eval Loss:  0.34572163224220276\n",
      "Eval Loss:  0.35220056772232056\n",
      "Eval Loss:  0.3984817862510681\n",
      "Eval Loss:  0.2986758053302765\n",
      "Eval Loss:  0.3192319869995117\n",
      "Eval Loss:  0.366963267326355\n",
      "Eval Loss:  0.28341835737228394\n",
      "[[16065  1002]\n",
      " [ 3007  9599]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     17067\n",
      "           1       0.91      0.76      0.83     12606\n",
      "\n",
      "    accuracy                           0.86     29673\n",
      "   macro avg       0.87      0.85      0.86     29673\n",
      "weighted avg       0.87      0.86      0.86     29673\n",
      "\n",
      "acc:  0.8648940113908267\n",
      "pre:  0.9054806150363174\n",
      "rec:  0.7614627954942091\n",
      "ma F1:  0.8581588056465639\n",
      "mi F1:  0.8648940113908267\n",
      "we F1:  0.8628055351277201\n",
      "29673 464\n",
      "Loss:  0.07671064138412476\n",
      "Loss:  0.05588889494538307\n",
      "Loss:  0.08226308226585388\n",
      "21 **********\n",
      "Epoch:  1165.2513542175293  fold:  5  kers:  32\n",
      "epoch:  22\n",
      "29673 464\n",
      "Loss:  0.0898204892873764\n",
      "Loss:  0.11455556750297546\n",
      "Loss:  0.08676032721996307\n",
      "22 **********\n",
      "Epoch:  1205.3750715255737  fold:  5  kers:  32\n",
      "epoch:  23\n",
      "29673 464\n",
      "Loss:  0.08145026862621307\n",
      "Loss:  0.047154054045677185\n",
      "Loss:  0.07340940088033676\n",
      "23 **********\n",
      "Epoch:  1245.532698392868  fold:  5  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.09134665131568909\n",
      "Eval Loss:  0.1900934875011444\n",
      "Eval Loss:  0.07190895825624466\n",
      "[[3016   81]\n",
      " [  36   85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.51      0.70      0.59       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.75      0.84      0.79      3218\n",
      "weighted avg       0.97      0.96      0.97      3218\n",
      "\n",
      "acc:  0.9636420136730889\n",
      "pre:  0.5120481927710844\n",
      "rec:  0.7024793388429752\n",
      "ma F1:  0.786653505314878\n",
      "mi F1:  0.9636420136730889\n",
      "we F1:  0.9663593397993664\n",
      "Eval Loss:  0.3207932114601135\n",
      "Eval Loss:  0.309579998254776\n",
      "Eval Loss:  0.3080851435661316\n",
      "Eval Loss:  0.35656505823135376\n",
      "Eval Loss:  0.3253530263900757\n",
      "Eval Loss:  0.26375457644462585\n",
      "Eval Loss:  0.27665847539901733\n",
      "Eval Loss:  0.2474769949913025\n",
      "Eval Loss:  0.2785475254058838\n",
      "Eval Loss:  0.31464460492134094\n",
      "Eval Loss:  0.25413161516189575\n",
      "Eval Loss:  0.27021610736846924\n",
      "Eval Loss:  0.2510446608066559\n",
      "Eval Loss:  0.2819046080112457\n",
      "Eval Loss:  0.28788742423057556\n",
      "Eval Loss:  0.29125529527664185\n",
      "Eval Loss:  0.3425404727458954\n",
      "Eval Loss:  0.41296324133872986\n",
      "Eval Loss:  0.36889806389808655\n",
      "Eval Loss:  0.273997962474823\n",
      "Eval Loss:  0.3013799488544464\n",
      "Eval Loss:  0.35978126525878906\n",
      "Eval Loss:  0.2976638078689575\n",
      "Eval Loss:  0.3144657015800476\n",
      "Eval Loss:  0.38861796259880066\n",
      "Eval Loss:  0.2824368178844452\n",
      "Eval Loss:  0.2843267321586609\n",
      "Eval Loss:  0.3518804609775543\n",
      "Eval Loss:  0.2578001022338867\n",
      "[[16060  1007]\n",
      " [ 2765  9841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     17067\n",
      "           1       0.91      0.78      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.86      0.87     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8728810703332996\n",
      "pre:  0.9071718289085545\n",
      "rec:  0.7806600031730921\n",
      "ma F1:  0.8670407487491896\n",
      "mi F1:  0.8728810703332996\n",
      "we F1:  0.871230115944352\n",
      "29673 464\n",
      "Loss:  0.08256252110004425\n",
      "Loss:  0.09061751514673233\n",
      "Loss:  0.1184140220284462\n",
      "24 **********\n",
      "Epoch:  1323.7695090770721  fold:  5  kers:  32\n",
      "epoch:  25\n",
      "29673 464\n",
      "Loss:  0.09326902031898499\n",
      "Loss:  0.0720829963684082\n",
      "Loss:  0.09601587057113647\n",
      "25 **********\n",
      "Epoch:  1364.0777332782745  fold:  5  kers:  32\n",
      "epoch:  26\n",
      "29673 464\n",
      "Loss:  0.10257770121097565\n",
      "Loss:  0.11953193694353104\n",
      "Loss:  0.0925261378288269\n",
      "26 **********\n",
      "Epoch:  1404.3789756298065  fold:  5  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.08129594475030899\n",
      "Eval Loss:  0.12769295275211334\n",
      "Eval Loss:  0.0599249042570591\n",
      "[[3038   59]\n",
      " [  42   79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.57      0.65      0.61       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.82      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.968614045991299\n",
      "pre:  0.572463768115942\n",
      "rec:  0.6528925619834711\n",
      "ma F1:  0.7968438152993762\n",
      "mi F1:  0.968614045991299\n",
      "we F1:  0.9696008976039258\n",
      "update!  Acc:  0.968614045991299\n",
      "Eval Loss:  0.3178263306617737\n",
      "Eval Loss:  0.28483709692955017\n",
      "Eval Loss:  0.3222326338291168\n",
      "Eval Loss:  0.3472491204738617\n",
      "Eval Loss:  0.3427032232284546\n",
      "Eval Loss:  0.28149715065956116\n",
      "Eval Loss:  0.2903439402580261\n",
      "Eval Loss:  0.2631506621837616\n",
      "Eval Loss:  0.265299528837204\n",
      "Eval Loss:  0.34174343943595886\n",
      "Eval Loss:  0.25368979573249817\n",
      "Eval Loss:  0.27455344796180725\n",
      "Eval Loss:  0.24465620517730713\n",
      "Eval Loss:  0.3004816174507141\n",
      "Eval Loss:  0.308430939912796\n",
      "Eval Loss:  0.3133850395679474\n",
      "Eval Loss:  0.34108054637908936\n",
      "Eval Loss:  0.41916540265083313\n",
      "Eval Loss:  0.3795360326766968\n",
      "Eval Loss:  0.2762680947780609\n",
      "Eval Loss:  0.28760018944740295\n",
      "Eval Loss:  0.35690054297447205\n",
      "Eval Loss:  0.3432413339614868\n",
      "Eval Loss:  0.2984859049320221\n",
      "Eval Loss:  0.3922545909881592\n",
      "Eval Loss:  0.29914894700050354\n",
      "Eval Loss:  0.31590497493743896\n",
      "Eval Loss:  0.3500536382198334\n",
      "Eval Loss:  0.26363635063171387\n",
      "[[16265   802]\n",
      " [ 3073  9533]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     17067\n",
      "           1       0.92      0.76      0.83     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.85      0.86     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.869409901257035\n",
      "pre:  0.9223996129656507\n",
      "rec:  0.7562271933999682\n",
      "ma F1:  0.8623235106943059\n",
      "mi F1:  0.869409901257035\n",
      "we F1:  0.8670193497169343\n",
      "29673 464\n",
      "Loss:  0.07530742883682251\n",
      "Loss:  0.09706409275531769\n",
      "Loss:  0.0688217431306839\n",
      "27 **********\n",
      "Epoch:  1482.6786184310913  fold:  5  kers:  32\n",
      "epoch:  28\n",
      "29673 464\n",
      "Loss:  0.08286746591329575\n",
      "Loss:  0.08670172840356827\n",
      "Loss:  0.06530538946390152\n",
      "28 **********\n",
      "Epoch:  1522.9260053634644  fold:  5  kers:  32\n",
      "epoch:  29\n",
      "29673 464\n",
      "Loss:  0.083272285759449\n",
      "Loss:  0.05289752408862114\n",
      "Loss:  0.04678330197930336\n",
      "29 **********\n",
      "Epoch:  1563.2152795791626  fold:  5  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.08109172433614731\n",
      "Eval Loss:  0.12569086253643036\n",
      "Eval Loss:  0.051302067935466766\n",
      "[[3038   59]\n",
      " [  34   87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.60      0.72      0.65       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.79      0.85      0.82      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.971100062150404\n",
      "pre:  0.5958904109589042\n",
      "rec:  0.71900826446281\n",
      "ma F1:  0.8183050081870025\n",
      "mi F1:  0.971100062150404\n",
      "we F1:  0.9723944966977048\n",
      "update!  Acc:  0.971100062150404\n",
      "Eval Loss:  0.2952565848827362\n",
      "Eval Loss:  0.2833114266395569\n",
      "Eval Loss:  0.3067006468772888\n",
      "Eval Loss:  0.3463003635406494\n",
      "Eval Loss:  0.3344341516494751\n",
      "Eval Loss:  0.28584834933280945\n",
      "Eval Loss:  0.26747146248817444\n",
      "Eval Loss:  0.2529473900794983\n",
      "Eval Loss:  0.2332576960325241\n",
      "Eval Loss:  0.33064383268356323\n",
      "Eval Loss:  0.24726763367652893\n",
      "Eval Loss:  0.2620500922203064\n",
      "Eval Loss:  0.2338763326406479\n",
      "Eval Loss:  0.2825920879840851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.27230405807495117\n",
      "Eval Loss:  0.31120339035987854\n",
      "Eval Loss:  0.32755687832832336\n",
      "Eval Loss:  0.3858562707901001\n",
      "Eval Loss:  0.36652645468711853\n",
      "Eval Loss:  0.25621944665908813\n",
      "Eval Loss:  0.27922213077545166\n",
      "Eval Loss:  0.339333713054657\n",
      "Eval Loss:  0.31234729290008545\n",
      "Eval Loss:  0.2892630994319916\n",
      "Eval Loss:  0.3834526240825653\n",
      "Eval Loss:  0.29149264097213745\n",
      "Eval Loss:  0.29450663924217224\n",
      "Eval Loss:  0.33815404772758484\n",
      "Eval Loss:  0.2554655373096466\n",
      "[[16132   935]\n",
      " [ 2747  9859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     17067\n",
      "           1       0.91      0.78      0.84     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.88      0.86      0.87     29673\n",
      "weighted avg       0.88      0.88      0.87     29673\n",
      "\n",
      "acc:  0.8759141306912007\n",
      "pre:  0.9133778024828608\n",
      "rec:  0.7820878946533397\n",
      "ma F1:  0.870109073867211\n",
      "mi F1:  0.8759141306912007\n",
      "we F1:  0.8742372993561028\n",
      "29673 464\n",
      "Loss:  0.06740283966064453\n",
      "Loss:  0.0744490921497345\n",
      "Loss:  0.08595199137926102\n",
      "30 **********\n",
      "Epoch:  1641.2117328643799  fold:  5  kers:  32\n",
      "epoch:  31\n",
      "29673 464\n",
      "Loss:  0.06852325052022934\n",
      "Loss:  0.09727469086647034\n",
      "Loss:  0.08589204400777817\n",
      "31 **********\n",
      "Epoch:  1681.3783354759216  fold:  5  kers:  32\n",
      "epoch:  32\n",
      "29673 464\n",
      "Loss:  0.07489980757236481\n",
      "Loss:  0.06958957016468048\n",
      "Loss:  0.09871892631053925\n",
      "32 **********\n",
      "Epoch:  1721.6735944747925  fold:  5  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.07786916196346283\n",
      "Eval Loss:  0.13728348910808563\n",
      "Eval Loss:  0.045693136751651764\n",
      "[[3037   60]\n",
      " [  38   83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.58      0.69      0.63       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.83      0.81      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9695463020509634\n",
      "pre:  0.5804195804195804\n",
      "rec:  0.6859504132231405\n",
      "ma F1:  0.8064548596790981\n",
      "mi F1:  0.9695463020509634\n",
      "we F1:  0.9707609302609095\n",
      "Eval Loss:  0.29619792103767395\n",
      "Eval Loss:  0.27334457635879517\n",
      "Eval Loss:  0.29430484771728516\n",
      "Eval Loss:  0.3423243463039398\n",
      "Eval Loss:  0.316283255815506\n",
      "Eval Loss:  0.28147077560424805\n",
      "Eval Loss:  0.25897473096847534\n",
      "Eval Loss:  0.2295636236667633\n",
      "Eval Loss:  0.23456136882305145\n",
      "Eval Loss:  0.3067414462566376\n",
      "Eval Loss:  0.2306889146566391\n",
      "Eval Loss:  0.24896220862865448\n",
      "Eval Loss:  0.2165961116552353\n",
      "Eval Loss:  0.27570903301239014\n",
      "Eval Loss:  0.25737759470939636\n",
      "Eval Loss:  0.3086238503456116\n",
      "Eval Loss:  0.3210603892803192\n",
      "Eval Loss:  0.3579855263233185\n",
      "Eval Loss:  0.37379297614097595\n",
      "Eval Loss:  0.25760817527770996\n",
      "Eval Loss:  0.2741456627845764\n",
      "Eval Loss:  0.3096717894077301\n",
      "Eval Loss:  0.2737492620944977\n",
      "Eval Loss:  0.2618056535720825\n",
      "Eval Loss:  0.374234139919281\n",
      "Eval Loss:  0.2838138937950134\n",
      "Eval Loss:  0.2587661147117615\n",
      "Eval Loss:  0.32115107774734497\n",
      "Eval Loss:  0.22175662219524384\n",
      "[[16094   973]\n",
      " [ 2517 10089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     17067\n",
      "           1       0.91      0.80      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.87      0.88     29673\n",
      "weighted avg       0.88      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8823846594547231\n",
      "pre:  0.9120412222021335\n",
      "rec:  0.8003331746787244\n",
      "ma F1:  0.8773620670901788\n",
      "mi F1:  0.8823846594547231\n",
      "we F1:  0.8810932551898012\n",
      "29673 464\n",
      "Loss:  0.06416632235050201\n",
      "Loss:  0.06092042475938797\n",
      "Loss:  0.0599806122481823\n",
      "33 **********\n",
      "Epoch:  1799.6630663871765  fold:  5  kers:  32\n",
      "epoch:  34\n",
      "29673 464\n",
      "Loss:  0.06892772018909454\n",
      "Loss:  0.10614258050918579\n",
      "Loss:  0.09957552701234818\n",
      "34 **********\n",
      "Epoch:  1839.794762134552  fold:  5  kers:  32\n",
      "epoch:  35\n",
      "29673 464\n",
      "Loss:  0.07120964676141739\n",
      "Loss:  0.053548894822597504\n",
      "Loss:  0.06717224419116974\n",
      "35 **********\n",
      "Epoch:  1879.9862985610962  fold:  5  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.07537351548671722\n",
      "Eval Loss:  0.14882850646972656\n",
      "Eval Loss:  0.04565995931625366\n",
      "[[3023   74]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.55      0.74      0.63       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.86      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9670602858918583\n",
      "pre:  0.5460122699386503\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.8047651971647832\n",
      "mi F1:  0.9670602858918583\n",
      "we F1:  0.9693835284707735\n",
      "Eval Loss:  0.28369030356407166\n",
      "Eval Loss:  0.28530794382095337\n",
      "Eval Loss:  0.2780940532684326\n",
      "Eval Loss:  0.3234293460845947\n",
      "Eval Loss:  0.2855110168457031\n",
      "Eval Loss:  0.2860488295555115\n",
      "Eval Loss:  0.22968527674674988\n",
      "Eval Loss:  0.2338775396347046\n",
      "Eval Loss:  0.20619958639144897\n",
      "Eval Loss:  0.3082500100135803\n",
      "Eval Loss:  0.23727700114250183\n",
      "Eval Loss:  0.25673702359199524\n",
      "Eval Loss:  0.21246543526649475\n",
      "Eval Loss:  0.2779979109764099\n",
      "Eval Loss:  0.23280632495880127\n",
      "Eval Loss:  0.27302512526512146\n",
      "Eval Loss:  0.3108334541320801\n",
      "Eval Loss:  0.3289889395236969\n",
      "Eval Loss:  0.36485573649406433\n",
      "Eval Loss:  0.23211032152175903\n",
      "Eval Loss:  0.26387089490890503\n",
      "Eval Loss:  0.30141395330429077\n",
      "Eval Loss:  0.2739994525909424\n",
      "Eval Loss:  0.25334346294403076\n",
      "Eval Loss:  0.34148967266082764\n",
      "Eval Loss:  0.2813996374607086\n",
      "Eval Loss:  0.24579478800296783\n",
      "Eval Loss:  0.326669305562973\n",
      "Eval Loss:  0.2243117392063141\n",
      "[[15921  1146]\n",
      " [ 2210 10396]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     17067\n",
      "           1       0.90      0.82      0.86     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.88      0.88     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8869005493209315\n",
      "pre:  0.9007104487957026\n",
      "rec:  0.8246866571473901\n",
      "ma F1:  0.8828386803830308\n",
      "mi F1:  0.8869005493209317\n",
      "we F1:  0.8861183179091802\n",
      "29673 464\n",
      "Loss:  0.07481960207223892\n",
      "Loss:  0.06255043298006058\n",
      "Loss:  0.06494522094726562\n",
      "36 **********\n",
      "Epoch:  1957.926901102066  fold:  5  kers:  32\n",
      "epoch:  37\n",
      "29673 464\n",
      "Loss:  0.056457024067640305\n",
      "Loss:  0.06475856900215149\n",
      "Loss:  0.054694194346666336\n",
      "37 **********\n",
      "Epoch:  1998.2770128250122  fold:  5  kers:  32\n",
      "epoch:  38\n",
      "29673 464\n",
      "Loss:  0.0740625336766243\n",
      "Loss:  0.06210141256451607\n",
      "Loss:  0.05623969808220863\n",
      "38 **********\n",
      "Epoch:  2038.38876247406  fold:  5  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.08133851736783981\n",
      "Eval Loss:  0.16043277084827423\n",
      "Eval Loss:  0.04978247731924057\n",
      "[[3012   85]\n",
      " [  24   97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.53      0.80      0.64       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.76      0.89      0.81      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9661280298321939\n",
      "pre:  0.532967032967033\n",
      "rec:  0.8016528925619835\n",
      "ma F1:  0.8112456606821615\n",
      "mi F1:  0.9661280298321939\n",
      "we F1:  0.9693691360133783\n",
      "Eval Loss:  0.2861800193786621\n",
      "Eval Loss:  0.299675315618515\n",
      "Eval Loss:  0.2568170726299286\n",
      "Eval Loss:  0.32292789220809937\n",
      "Eval Loss:  0.2514267563819885\n",
      "Eval Loss:  0.3040253221988678\n",
      "Eval Loss:  0.20075221359729767\n",
      "Eval Loss:  0.21256980299949646\n",
      "Eval Loss:  0.19071120023727417\n",
      "Eval Loss:  0.29176315665245056\n",
      "Eval Loss:  0.24442316591739655\n",
      "Eval Loss:  0.23744136095046997\n",
      "Eval Loss:  0.22036629915237427\n",
      "Eval Loss:  0.256464421749115\n",
      "Eval Loss:  0.20492160320281982\n",
      "Eval Loss:  0.2537505328655243\n",
      "Eval Loss:  0.2923789620399475\n",
      "Eval Loss:  0.29216066002845764\n",
      "Eval Loss:  0.35145100951194763\n",
      "Eval Loss:  0.22863386571407318\n",
      "Eval Loss:  0.2590293288230896\n",
      "Eval Loss:  0.2944219708442688\n",
      "Eval Loss:  0.26024219393730164\n",
      "Eval Loss:  0.237102672457695\n",
      "Eval Loss:  0.3262719213962555\n",
      "Eval Loss:  0.26803669333457947\n",
      "Eval Loss:  0.2127676010131836\n",
      "Eval Loss:  0.306477814912796\n",
      "Eval Loss:  0.21400266885757446\n",
      "[[15654  1413]\n",
      " [ 1814 10792]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17067\n",
      "           1       0.88      0.86      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8912479358339231\n",
      "pre:  0.8842277755018435\n",
      "rec:  0.8561002697128351\n",
      "ma F1:  0.888247642695646\n",
      "mi F1:  0.8912479358339231\n",
      "we F1:  0.8910004826154022\n",
      "29673 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06743041425943375\n",
      "Loss:  0.09933029860258102\n",
      "Loss:  0.04733743146061897\n",
      "39 **********\n",
      "Epoch:  2116.6534984111786  fold:  5  kers:  32\n",
      "epoch:  40\n",
      "29673 464\n",
      "Loss:  0.07694929838180542\n",
      "Loss:  0.08940388262271881\n",
      "Loss:  0.08736317604780197\n",
      "40 **********\n",
      "Epoch:  2156.9697012901306  fold:  5  kers:  32\n",
      "epoch:  41\n",
      "29673 464\n",
      "Loss:  0.056445807218551636\n",
      "Loss:  0.07661087810993195\n",
      "Loss:  0.06607086211442947\n",
      "41 **********\n",
      "Epoch:  2197.189162492752  fold:  5  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.07680355757474899\n",
      "Eval Loss:  0.1410830318927765\n",
      "Eval Loss:  0.03893539309501648\n",
      "[[3030   67]\n",
      " [  29   92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.58      0.76      0.66       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.87      0.82      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9701678060907396\n",
      "pre:  0.5786163522012578\n",
      "rec:  0.7603305785123967\n",
      "ma F1:  0.8207741576162629\n",
      "mi F1:  0.9701678060907396\n",
      "we F1:  0.9721000588620228\n",
      "Eval Loss:  0.2972632050514221\n",
      "Eval Loss:  0.2756024897098541\n",
      "Eval Loss:  0.2667261064052582\n",
      "Eval Loss:  0.3143094778060913\n",
      "Eval Loss:  0.26817595958709717\n",
      "Eval Loss:  0.2964756488800049\n",
      "Eval Loss:  0.21676111221313477\n",
      "Eval Loss:  0.22478307783603668\n",
      "Eval Loss:  0.19777286052703857\n",
      "Eval Loss:  0.29117029905319214\n",
      "Eval Loss:  0.2449333518743515\n",
      "Eval Loss:  0.2479192018508911\n",
      "Eval Loss:  0.20527389645576477\n",
      "Eval Loss:  0.26421472430229187\n",
      "Eval Loss:  0.21667194366455078\n",
      "Eval Loss:  0.2628997266292572\n",
      "Eval Loss:  0.2894766628742218\n",
      "Eval Loss:  0.30715078115463257\n",
      "Eval Loss:  0.37143346667289734\n",
      "Eval Loss:  0.24340708553791046\n",
      "Eval Loss:  0.26440703868865967\n",
      "Eval Loss:  0.28001007437705994\n",
      "Eval Loss:  0.25643450021743774\n",
      "Eval Loss:  0.2581271529197693\n",
      "Eval Loss:  0.3434460163116455\n",
      "Eval Loss:  0.2810960114002228\n",
      "Eval Loss:  0.21235084533691406\n",
      "Eval Loss:  0.3106813132762909\n",
      "Eval Loss:  0.1976100355386734\n",
      "[[15773  1294]\n",
      " [ 1939 10667]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91     17067\n",
      "           1       0.89      0.85      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.891045731810063\n",
      "pre:  0.891815065629964\n",
      "rec:  0.8461843566555608\n",
      "ma F1:  0.8877211528463815\n",
      "mi F1:  0.891045731810063\n",
      "we F1:  0.8906257644321596\n",
      "29673 464\n",
      "Loss:  0.07163058966398239\n",
      "Loss:  0.06394055485725403\n",
      "Loss:  0.048674967139959335\n",
      "42 **********\n",
      "Epoch:  2275.371119737625  fold:  5  kers:  32\n",
      "epoch:  43\n",
      "29673 464\n",
      "Loss:  0.06596201658248901\n",
      "Loss:  0.0804734081029892\n",
      "Loss:  0.09003200381994247\n",
      "43 **********\n",
      "Epoch:  2315.6823353767395  fold:  5  kers:  32\n",
      "epoch:  44\n",
      "29673 464\n",
      "Loss:  0.06526871025562286\n",
      "Loss:  0.07669781893491745\n",
      "Loss:  0.06494104862213135\n",
      "44 **********\n",
      "Epoch:  2355.8638982772827  fold:  5  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.08490020036697388\n",
      "Eval Loss:  0.136161670088768\n",
      "Eval Loss:  0.037852127104997635\n",
      "[[3022   75]\n",
      " [  18  103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.58      0.85      0.69       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.79      0.91      0.84      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n",
      "\n",
      "acc:  0.971100062150404\n",
      "pre:  0.5786516853932584\n",
      "rec:  0.8512396694214877\n",
      "ma F1:  0.8369046133355278\n",
      "mi F1:  0.971100062150404\n",
      "we F1:  0.9737205282629248\n",
      "Eval Loss:  0.28053537011146545\n",
      "Eval Loss:  0.29557812213897705\n",
      "Eval Loss:  0.2232317477464676\n",
      "Eval Loss:  0.28435707092285156\n",
      "Eval Loss:  0.2434215396642685\n",
      "Eval Loss:  0.2911888659000397\n",
      "Eval Loss:  0.18177692592144012\n",
      "Eval Loss:  0.23328004777431488\n",
      "Eval Loss:  0.19835248589515686\n",
      "Eval Loss:  0.2746804356575012\n",
      "Eval Loss:  0.24810662865638733\n",
      "Eval Loss:  0.25103676319122314\n",
      "Eval Loss:  0.2104603350162506\n",
      "Eval Loss:  0.2797221839427948\n",
      "Eval Loss:  0.19100482761859894\n",
      "Eval Loss:  0.22506959736347198\n",
      "Eval Loss:  0.2841114103794098\n",
      "Eval Loss:  0.30175867676734924\n",
      "Eval Loss:  0.36224451661109924\n",
      "Eval Loss:  0.24093890190124512\n",
      "Eval Loss:  0.2691985070705414\n",
      "Eval Loss:  0.2735235393047333\n",
      "Eval Loss:  0.24064594507217407\n",
      "Eval Loss:  0.24890419840812683\n",
      "Eval Loss:  0.3221970796585083\n",
      "Eval Loss:  0.2796594202518463\n",
      "Eval Loss:  0.20510344207286835\n",
      "Eval Loss:  0.30916720628738403\n",
      "Eval Loss:  0.19174176454544067\n",
      "[[15570  1497]\n",
      " [ 1652 10954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91     17067\n",
      "           1       0.88      0.87      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8938765881441041\n",
      "pre:  0.8797686932776484\n",
      "rec:  0.8689512930350627\n",
      "ma F1:  0.8912447516073281\n",
      "mi F1:  0.8938765881441041\n",
      "we F1:  0.8937882140836189\n",
      "29673 464\n",
      "Loss:  0.08333141356706619\n",
      "Loss:  0.08231460303068161\n",
      "Loss:  0.06030988693237305\n",
      "45 **********\n",
      "Epoch:  2434.244325399399  fold:  5  kers:  32\n",
      "epoch:  46\n",
      "29673 464\n",
      "Loss:  0.07122306525707245\n",
      "Loss:  0.10043726116418839\n",
      "Loss:  0.048722535371780396\n",
      "46 **********\n",
      "Epoch:  2474.408932685852  fold:  5  kers:  32\n",
      "epoch:  47\n",
      "29673 464\n",
      "Loss:  0.0789927989244461\n",
      "Loss:  0.089501291513443\n",
      "Loss:  0.05561838299036026\n",
      "47 **********\n",
      "Epoch:  2514.6283946037292  fold:  5  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.08043954521417618\n",
      "Eval Loss:  0.13497529923915863\n",
      "Eval Loss:  0.037406034767627716\n",
      "[[3028   69]\n",
      " [  28   93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.57      0.77      0.66       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.87      0.82      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9698570540708514\n",
      "pre:  0.5740740740740741\n",
      "rec:  0.768595041322314\n",
      "ma F1:  0.8207395743063082\n",
      "mi F1:  0.9698570540708514\n",
      "we F1:  0.97194012619022\n",
      "Eval Loss:  0.29767435789108276\n",
      "Eval Loss:  0.2746301293373108\n",
      "Eval Loss:  0.24650664627552032\n",
      "Eval Loss:  0.2841973602771759\n",
      "Eval Loss:  0.26156097650527954\n",
      "Eval Loss:  0.31119659543037415\n",
      "Eval Loss:  0.20625965297222137\n",
      "Eval Loss:  0.23287810385227203\n",
      "Eval Loss:  0.19494497776031494\n",
      "Eval Loss:  0.2737387418746948\n",
      "Eval Loss:  0.2488684058189392\n",
      "Eval Loss:  0.2425931841135025\n",
      "Eval Loss:  0.19720393419265747\n",
      "Eval Loss:  0.27013328671455383\n",
      "Eval Loss:  0.20269550383090973\n",
      "Eval Loss:  0.2380465567111969\n",
      "Eval Loss:  0.30006036162376404\n",
      "Eval Loss:  0.29564765095710754\n",
      "Eval Loss:  0.3820548355579376\n",
      "Eval Loss:  0.23121342062950134\n",
      "Eval Loss:  0.2557642161846161\n",
      "Eval Loss:  0.2771495580673218\n",
      "Eval Loss:  0.24992890655994415\n",
      "Eval Loss:  0.2643508017063141\n",
      "Eval Loss:  0.3239281475543976\n",
      "Eval Loss:  0.27861538529396057\n",
      "Eval Loss:  0.2115960419178009\n",
      "Eval Loss:  0.3110886216163635\n",
      "Eval Loss:  0.17453397810459137\n",
      "[[15728  1339]\n",
      " [ 1771 10835]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17067\n",
      "           1       0.89      0.86      0.87     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.89     29673\n",
      "\n",
      "acc:  0.8951909142991945\n",
      "pre:  0.8900114999178578\n",
      "rec:  0.8595113438045375\n",
      "ma F1:  0.8922613776445356\n",
      "mi F1:  0.8951909142991944\n",
      "we F1:  0.894932267286153\n",
      "29673 464\n",
      "Loss:  0.0740080326795578\n",
      "Loss:  0.05442936718463898\n",
      "Loss:  0.08067374676465988\n",
      "48 **********\n",
      "Epoch:  2596.2850608825684  fold:  5  kers:  32\n",
      "epoch:  49\n",
      "29673 464\n",
      "Loss:  0.07348384708166122\n",
      "Loss:  0.041498471051454544\n",
      "Loss:  0.08363721519708633\n",
      "49 **********\n",
      "Epoch:  2636.505519628525  fold:  5  kers:  32\n",
      "epoch:  50\n",
      "29673 464\n",
      "Loss:  0.0758698508143425\n",
      "Loss:  0.06305836886167526\n",
      "Loss:  0.07579744607210159\n",
      "50 **********\n",
      "Epoch:  2676.6990506649017  fold:  5  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.08529086410999298\n",
      "Eval Loss:  0.12505050003528595\n",
      "Eval Loss:  0.03205929696559906\n",
      "[[3018   79]\n",
      " [  19  102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.56      0.84      0.68       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.91      0.83      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc:  0.9695463020509634\n",
      "pre:  0.56353591160221\n",
      "rec:  0.8429752066115702\n",
      "ma F1:  0.829760082225442\n",
      "mi F1:  0.9695463020509634\n",
      "we F1:  0.9724225617181551\n",
      "Eval Loss:  0.2904810905456543\n",
      "Eval Loss:  0.30909645557403564\n",
      "Eval Loss:  0.23614172637462616\n",
      "Eval Loss:  0.29257509112358093\n",
      "Eval Loss:  0.2533953785896301\n",
      "Eval Loss:  0.3300614655017853\n",
      "Eval Loss:  0.19249001145362854\n",
      "Eval Loss:  0.2356046438217163\n",
      "Eval Loss:  0.1962268352508545\n",
      "Eval Loss:  0.28566622734069824\n",
      "Eval Loss:  0.29515793919563293\n",
      "Eval Loss:  0.2687050402164459\n",
      "Eval Loss:  0.2382906973361969\n",
      "Eval Loss:  0.27182188630104065\n",
      "Eval Loss:  0.17075009644031525\n",
      "Eval Loss:  0.24978747963905334\n",
      "Eval Loss:  0.2794484794139862\n",
      "Eval Loss:  0.2938348948955536\n",
      "Eval Loss:  0.366883784532547\n",
      "Eval Loss:  0.24590997397899628\n",
      "Eval Loss:  0.28582724928855896\n",
      "Eval Loss:  0.2884296476840973\n",
      "Eval Loss:  0.25225454568862915\n",
      "Eval Loss:  0.2757177948951721\n",
      "Eval Loss:  0.344723105430603\n",
      "Eval Loss:  0.30505135655403137\n",
      "Eval Loss:  0.20935757458209991\n",
      "Eval Loss:  0.3111378848552704\n",
      "Eval Loss:  0.18732717633247375\n",
      "[[15252  1815]\n",
      " [ 1408 11198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90     17067\n",
      "           1       0.86      0.89      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8913827385164965\n",
      "pre:  0.8605240912933221\n",
      "rec:  0.8883071553228621\n",
      "ma F1:  0.8893167569068554\n",
      "mi F1:  0.8913827385164965\n",
      "we F1:  0.8915901520624078\n",
      "29673 464\n",
      "Loss:  0.08828114718198776\n",
      "Loss:  0.049112457782030106\n",
      "Loss:  0.07314901798963547\n",
      "51 **********\n",
      "Epoch:  2754.824159860611  fold:  5  kers:  32\n",
      "epoch:  52\n",
      "29673 464\n",
      "Loss:  0.06258025765419006\n",
      "Loss:  0.05894428491592407\n",
      "Loss:  0.06446126103401184\n",
      "52 **********\n",
      "Epoch:  2794.881055831909  fold:  5  kers:  32\n",
      "epoch:  53\n",
      "29673 464\n",
      "Loss:  0.0561600923538208\n",
      "Loss:  0.08242124319076538\n",
      "Loss:  0.04467388615012169\n",
      "53 **********\n",
      "Epoch:  2835.0695996284485  fold:  5  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.08038321137428284\n",
      "Eval Loss:  0.11607164889574051\n",
      "Eval Loss:  0.03810127079486847\n",
      "[[3031   66]\n",
      " [  31   90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.58      0.74      0.65       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.86      0.82      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9698570540708514\n",
      "pre:  0.5769230769230769\n",
      "rec:  0.743801652892562\n",
      "ma F1:  0.8170350923159615\n",
      "mi F1:  0.9698570540708514\n",
      "we F1:  0.9716757445371627\n",
      "Eval Loss:  0.2870054841041565\n",
      "Eval Loss:  0.2784759998321533\n",
      "Eval Loss:  0.23918253183364868\n",
      "Eval Loss:  0.2897094190120697\n",
      "Eval Loss:  0.24055376648902893\n",
      "Eval Loss:  0.3121834397315979\n",
      "Eval Loss:  0.21455416083335876\n",
      "Eval Loss:  0.24857428669929504\n",
      "Eval Loss:  0.1911795735359192\n",
      "Eval Loss:  0.2704121470451355\n",
      "Eval Loss:  0.2260359227657318\n",
      "Eval Loss:  0.2520930767059326\n",
      "Eval Loss:  0.16583627462387085\n",
      "Eval Loss:  0.2282709926366806\n",
      "Eval Loss:  0.20492783188819885\n",
      "Eval Loss:  0.25546595454216003\n",
      "Eval Loss:  0.26557081937789917\n",
      "Eval Loss:  0.3169601857662201\n",
      "Eval Loss:  0.34698915481567383\n",
      "Eval Loss:  0.24194666743278503\n",
      "Eval Loss:  0.24885417520999908\n",
      "Eval Loss:  0.2858031094074249\n",
      "Eval Loss:  0.23509110510349274\n",
      "Eval Loss:  0.24675686657428741\n",
      "Eval Loss:  0.32438063621520996\n",
      "Eval Loss:  0.26002955436706543\n",
      "Eval Loss:  0.1990027129650116\n",
      "Eval Loss:  0.2729189395904541\n",
      "Eval Loss:  0.1769976168870926\n",
      "[[15772  1295]\n",
      " [ 1737 10869]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17067\n",
      "           1       0.89      0.86      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.8978195666093756\n",
      "pre:  0.8935383097665242\n",
      "rec:  0.8622084721561162\n",
      "ma F1:  0.8949514898472706\n",
      "mi F1:  0.8978195666093756\n",
      "we F1:  0.8975610126773237\n",
      "29673 464\n",
      "Loss:  0.05799140781164169\n",
      "Loss:  0.04269994795322418\n",
      "Loss:  0.051660340279340744\n",
      "54 **********\n",
      "Epoch:  2914.1641170978546  fold:  5  kers:  32\n",
      "epoch:  55\n",
      "29673 464\n",
      "Loss:  0.0741475522518158\n",
      "Loss:  0.07389327883720398\n",
      "Loss:  0.06709102541208267\n",
      "55 **********\n",
      "Epoch:  2954.3317172527313  fold:  5  kers:  32\n",
      "epoch:  56\n",
      "29673 464\n",
      "Loss:  0.030209727585315704\n",
      "Loss:  0.09311927855014801\n",
      "Loss:  0.06806491315364838\n",
      "56 **********\n",
      "Epoch:  2994.5900745391846  fold:  5  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.07548888027667999\n",
      "Eval Loss:  0.08091112226247787\n",
      "Eval Loss:  0.030256737023591995\n",
      "[[3049   48]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.65      0.73      0.68       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.82      0.86      0.84      3218\n",
      "weighted avg       0.98      0.97      0.98      3218\n",
      "\n",
      "acc:  0.9748290863890615\n",
      "pre:  0.6470588235294118\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.8358579927116008\n",
      "mi F1:  0.9748290863890615\n",
      "we F1:  0.9755330939558167\n",
      "update!  Acc:  0.9748290863890615\n",
      "Eval Loss:  0.27253252267837524\n",
      "Eval Loss:  0.2578357458114624\n",
      "Eval Loss:  0.2512659430503845\n",
      "Eval Loss:  0.2723597288131714\n",
      "Eval Loss:  0.2670064866542816\n",
      "Eval Loss:  0.29909324645996094\n",
      "Eval Loss:  0.22218331694602966\n",
      "Eval Loss:  0.23727306723594666\n",
      "Eval Loss:  0.20002400875091553\n",
      "Eval Loss:  0.27190741896629333\n",
      "Eval Loss:  0.22594645619392395\n",
      "Eval Loss:  0.24545368552207947\n",
      "Eval Loss:  0.16733784973621368\n",
      "Eval Loss:  0.24791285395622253\n",
      "Eval Loss:  0.19290965795516968\n",
      "Eval Loss:  0.22749827802181244\n",
      "Eval Loss:  0.27270376682281494\n",
      "Eval Loss:  0.3018394410610199\n",
      "Eval Loss:  0.3414006233215332\n",
      "Eval Loss:  0.21506482362747192\n",
      "Eval Loss:  0.2342929095029831\n",
      "Eval Loss:  0.26382261514663696\n",
      "Eval Loss:  0.2381400316953659\n",
      "Eval Loss:  0.23903559148311615\n",
      "Eval Loss:  0.32523849606513977\n",
      "Eval Loss:  0.28792431950569153\n",
      "Eval Loss:  0.20057356357574463\n",
      "Eval Loss:  0.2979176938533783\n",
      "Eval Loss:  0.18414540588855743\n",
      "[[15857  1210]\n",
      " [ 1809 10797]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     17067\n",
      "           1       0.90      0.86      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.898257675327739\n",
      "pre:  0.8992254518197718\n",
      "rec:  0.8564969062351261\n",
      "ma F1:  0.8952105112345687\n",
      "mi F1:  0.898257675327739\n",
      "we F1:  0.8978969537285674\n",
      "29673 464\n",
      "Loss:  0.06971247494220734\n",
      "Loss:  0.04941534250974655\n",
      "Loss:  0.04883509874343872\n",
      "57 **********\n",
      "Epoch:  3072.6852638721466  fold:  5  kers:  32\n",
      "epoch:  58\n",
      "29673 464\n",
      "Loss:  0.06470264494419098\n",
      "Loss:  0.09231603145599365\n",
      "Loss:  0.059507254511117935\n",
      "58 **********\n",
      "Epoch:  3112.8907623291016  fold:  5  kers:  32\n",
      "epoch:  59\n",
      "29673 464\n",
      "Loss:  0.0755872055888176\n",
      "Loss:  0.07233864814043045\n",
      "Loss:  0.07475186139345169\n",
      "59 **********\n",
      "Epoch:  3153.109225988388  fold:  5  kers:  32\n",
      "Eval Loss:  0.0777500718832016\n",
      "Eval Loss:  0.09441769868135452\n",
      "Eval Loss:  0.022807491943240166\n",
      "[[3055   42]\n",
      " [  19  102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.71      0.84      0.77       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.85      0.91      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9810441267868241\n",
      "pre:  0.7083333333333334\n",
      "rec:  0.8429752066115702\n",
      "ma F1:  0.8799631875204471\n",
      "mi F1:  0.981044126786824\n",
      "we F1:  0.9818314148339379\n",
      "update!  Acc:  0.9810441267868241\n",
      "Epoch:  3156.8203036785126  fold:  5  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29479 3412\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29479 461\n",
      "Loss:  0.1669381707906723\n",
      "Loss:  0.16035740077495575\n",
      "Loss:  0.15638500452041626\n",
      "0 **********\n",
      "Epoch:  52.472697496414185  fold:  6  kers:  32\n",
      "epoch:  1\n",
      "29479 461\n",
      "Loss:  0.16268840432167053\n",
      "Loss:  0.1470639407634735\n",
      "Loss:  0.14735561609268188\n",
      "1 **********\n",
      "Epoch:  92.67021799087524  fold:  6  kers:  32\n",
      "epoch:  2\n",
      "29479 461\n",
      "Loss:  0.12202213704586029\n",
      "Loss:  0.12789148092269897\n",
      "Loss:  0.12835170328617096\n",
      "2 **********\n",
      "Epoch:  132.77498531341553  fold:  6  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.1271962672472\n",
      "Eval Loss:  0.2539255619049072\n",
      "Eval Loss:  0.5477715730667114\n",
      "[[1732  500]\n",
      " [  86 1094]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.78      0.86      2232\n",
      "           1       0.69      0.93      0.79      1180\n",
      "\n",
      "    accuracy                           0.83      3412\n",
      "   macro avg       0.82      0.85      0.82      3412\n",
      "weighted avg       0.86      0.83      0.83      3412\n",
      "\n",
      "acc:  0.828253223915592\n",
      "pre:  0.6863237139272271\n",
      "rec:  0.9271186440677966\n",
      "ma F1:  0.8220306728261547\n",
      "mi F1:  0.828253223915592\n",
      "we F1:  0.8322910548733148\n",
      "update!  Acc:  0.828253223915592\n",
      "Eval Loss:  0.5419095754623413\n",
      "Eval Loss:  0.510671854019165\n",
      "Eval Loss:  0.5223429799079895\n",
      "Eval Loss:  0.4567170739173889\n",
      "Eval Loss:  0.47710734605789185\n",
      "Eval Loss:  0.470179945230484\n",
      "Eval Loss:  0.46727022528648376\n",
      "Eval Loss:  0.47856056690216064\n",
      "Eval Loss:  0.4358624219894409\n",
      "Eval Loss:  0.4273289442062378\n",
      "Eval Loss:  0.4103020131587982\n",
      "Eval Loss:  0.5231731534004211\n",
      "Eval Loss:  0.4471341371536255\n",
      "Eval Loss:  0.43548208475112915\n",
      "Eval Loss:  0.416110634803772\n",
      "Eval Loss:  0.3890897333621979\n",
      "Eval Loss:  0.4662192463874817\n",
      "Eval Loss:  0.48168280720710754\n",
      "Eval Loss:  0.49338191747665405\n",
      "Eval Loss:  0.5111720561981201\n",
      "Eval Loss:  0.38779959082603455\n",
      "Eval Loss:  0.3706527054309845\n",
      "Eval Loss:  0.46537554264068604\n",
      "Eval Loss:  0.5563291311264038\n",
      "Eval Loss:  0.48592257499694824\n",
      "Eval Loss:  0.45810797810554504\n",
      "Eval Loss:  0.38700708746910095\n",
      "Eval Loss:  0.3845973312854767\n",
      "[[14571  3361]\n",
      " [ 2689  8858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83     17932\n",
      "           1       0.72      0.77      0.75     11547\n",
      "\n",
      "    accuracy                           0.79     29479\n",
      "   macro avg       0.78      0.79      0.79     29479\n",
      "weighted avg       0.80      0.79      0.80     29479\n",
      "\n",
      "acc:  0.7947691577054853\n",
      "pre:  0.7249365741877404\n",
      "rec:  0.7671256603446782\n",
      "ma F1:  0.7867602915843277\n",
      "mi F1:  0.7947691577054853\n",
      "we F1:  0.7957112123236224\n",
      "29479 461\n",
      "Loss:  0.11110254377126694\n",
      "Loss:  0.1029074415564537\n",
      "Loss:  0.10141661018133163\n",
      "3 **********\n",
      "Epoch:  210.79836678504944  fold:  6  kers:  32\n",
      "epoch:  4\n",
      "29479 461\n",
      "Loss:  0.10985135287046432\n",
      "Loss:  0.13732405006885529\n",
      "Loss:  0.12655065953731537\n",
      "4 **********\n",
      "Epoch:  250.92607307434082  fold:  6  kers:  32\n",
      "epoch:  5\n",
      "29479 461\n",
      "Loss:  0.06677394360303879\n",
      "Loss:  0.07277638465166092\n",
      "Loss:  0.12038983404636383\n",
      "5 **********\n",
      "Epoch:  291.0318388938904  fold:  6  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.07032660394906998\n",
      "Eval Loss:  0.22014746069908142\n",
      "Eval Loss:  0.4919440448284149\n",
      "[[1961  271]\n",
      " [ 147 1033]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      2232\n",
      "           1       0.79      0.88      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.86      0.88      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8774912075029309\n",
      "pre:  0.7921779141104295\n",
      "rec:  0.8754237288135593\n",
      "ma F1:  0.8677048316599509\n",
      "mi F1:  0.8774912075029307\n",
      "we F1:  0.8787988697922946\n",
      "update!  Acc:  0.8774912075029309\n",
      "Eval Loss:  0.4530397653579712\n",
      "Eval Loss:  0.46930453181266785\n",
      "Eval Loss:  0.5071264505386353\n",
      "Eval Loss:  0.4029529094696045\n",
      "Eval Loss:  0.5364260673522949\n",
      "Eval Loss:  0.44866350293159485\n",
      "Eval Loss:  0.5029138922691345\n",
      "Eval Loss:  0.43143779039382935\n",
      "Eval Loss:  0.39390626549720764\n",
      "Eval Loss:  0.44729381799697876\n",
      "Eval Loss:  0.38698631525039673\n",
      "Eval Loss:  0.4545586109161377\n",
      "Eval Loss:  0.41588929295539856\n",
      "Eval Loss:  0.38016149401664734\n",
      "Eval Loss:  0.40910178422927856\n",
      "Eval Loss:  0.3871307373046875\n",
      "Eval Loss:  0.4443294107913971\n",
      "Eval Loss:  0.49623048305511475\n",
      "Eval Loss:  0.47556591033935547\n",
      "Eval Loss:  0.4829864799976349\n",
      "Eval Loss:  0.37023547291755676\n",
      "Eval Loss:  0.34862035512924194\n",
      "Eval Loss:  0.45252513885498047\n",
      "Eval Loss:  0.5198402404785156\n",
      "Eval Loss:  0.49303993582725525\n",
      "Eval Loss:  0.4197828769683838\n",
      "Eval Loss:  0.398475706577301\n",
      "Eval Loss:  0.326377809047699\n",
      "[[16471  1461]\n",
      " [ 3469  8078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87     17932\n",
      "           1       0.85      0.70      0.77     11547\n",
      "\n",
      "    accuracy                           0.83     29479\n",
      "   macro avg       0.84      0.81      0.82     29479\n",
      "weighted avg       0.83      0.83      0.83     29479\n",
      "\n",
      "acc:  0.8327623053699243\n",
      "pre:  0.8468392913303281\n",
      "rec:  0.6995756473542911\n",
      "ma F1:  0.8180101262935088\n",
      "mi F1:  0.8327623053699245\n",
      "we F1:  0.8292328909072241\n",
      "29479 461\n",
      "Loss:  0.12317685037851334\n",
      "Loss:  0.09406866878271103\n",
      "Loss:  0.10493816435337067\n",
      "6 **********\n",
      "Epoch:  369.10009956359863  fold:  6  kers:  32\n",
      "epoch:  7\n",
      "29479 461\n",
      "Loss:  0.08878893405199051\n",
      "Loss:  0.07694312930107117\n",
      "Loss:  0.10967223346233368\n",
      "7 **********\n",
      "Epoch:  409.30360412597656  fold:  6  kers:  32\n",
      "epoch:  8\n",
      "29479 461\n",
      "Loss:  0.12302744388580322\n",
      "Loss:  0.10403061658143997\n",
      "Loss:  0.0883936807513237\n",
      "8 **********\n",
      "Epoch:  449.36149740219116  fold:  6  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.047229163348674774\n",
      "Eval Loss:  0.2129494696855545\n",
      "Eval Loss:  0.4923921525478363\n",
      "[[2027  205]\n",
      " [ 174 1006]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      2232\n",
      "           1       0.83      0.85      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8889214536928488\n",
      "pre:  0.8307184145334434\n",
      "rec:  0.8525423728813559\n",
      "ma F1:  0.8779968833799732\n",
      "mi F1:  0.8889214536928488\n",
      "we F1:  0.8892531497552377\n",
      "update!  Acc:  0.8889214536928488\n",
      "Eval Loss:  0.45951277017593384\n",
      "Eval Loss:  0.4200378358364105\n",
      "Eval Loss:  0.4557400345802307\n",
      "Eval Loss:  0.38131818175315857\n",
      "Eval Loss:  0.5325085520744324\n",
      "Eval Loss:  0.3981861472129822\n",
      "Eval Loss:  0.4741765558719635\n",
      "Eval Loss:  0.41225361824035645\n",
      "Eval Loss:  0.36587125062942505\n",
      "Eval Loss:  0.40262195467948914\n",
      "Eval Loss:  0.36483585834503174\n",
      "Eval Loss:  0.44474148750305176\n",
      "Eval Loss:  0.4084140658378601\n",
      "Eval Loss:  0.3728612959384918\n",
      "Eval Loss:  0.36895522475242615\n",
      "Eval Loss:  0.368732750415802\n",
      "Eval Loss:  0.44476598501205444\n",
      "Eval Loss:  0.4523333013057709\n",
      "Eval Loss:  0.4680674076080322\n",
      "Eval Loss:  0.44625529646873474\n",
      "Eval Loss:  0.3515934646129608\n",
      "Eval Loss:  0.3268009424209595\n",
      "Eval Loss:  0.42726442217826843\n",
      "Eval Loss:  0.4752764403820038\n",
      "Eval Loss:  0.4843750298023224\n",
      "Eval Loss:  0.3984777331352234\n",
      "Eval Loss:  0.37029436230659485\n",
      "Eval Loss:  0.2935958206653595\n",
      "[[17000   932]\n",
      " [ 3641  7906]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88     17932\n",
      "           1       0.89      0.68      0.78     11547\n",
      "\n",
      "    accuracy                           0.84     29479\n",
      "   macro avg       0.86      0.82      0.83     29479\n",
      "weighted avg       0.85      0.84      0.84     29479\n",
      "\n",
      "acc:  0.8448726211879644\n",
      "pre:  0.8945462774383345\n",
      "rec:  0.6846800034641032\n",
      "ma F1:  0.8285569771757053\n",
      "mi F1:  0.8448726211879644\n",
      "we F1:  0.8400123749124849\n",
      "29479 461\n",
      "Loss:  0.07425470650196075\n",
      "Loss:  0.10229051113128662\n",
      "Loss:  0.10560790449380875\n",
      "9 **********\n",
      "Epoch:  527.4467134475708  fold:  6  kers:  32\n",
      "epoch:  10\n",
      "29479 461\n",
      "Loss:  0.08746609091758728\n",
      "Loss:  0.12352151423692703\n",
      "Loss:  0.08099822700023651\n",
      "10 **********\n",
      "Epoch:  567.4826657772064  fold:  6  kers:  32\n",
      "epoch:  11\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.12558789551258087\n",
      "Loss:  0.08355405181646347\n",
      "Loss:  0.13040047883987427\n",
      "11 **********\n",
      "Epoch:  607.5036571025848  fold:  6  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.04280088096857071\n",
      "Eval Loss:  0.19903819262981415\n",
      "Eval Loss:  0.47215691208839417\n",
      "[[2047  185]\n",
      " [ 186  994]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2232\n",
      "           1       0.84      0.84      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8912661195779601\n",
      "pre:  0.8430873621713316\n",
      "rec:  0.8423728813559322\n",
      "ma F1:  0.8798196324196438\n",
      "mi F1:  0.89126611957796\n",
      "we F1:  0.8912552492197852\n",
      "update!  Acc:  0.8912661195779601\n",
      "Eval Loss:  0.4468103349208832\n",
      "Eval Loss:  0.4114939868450165\n",
      "Eval Loss:  0.42603668570518494\n",
      "Eval Loss:  0.3666967451572418\n",
      "Eval Loss:  0.5131515860557556\n",
      "Eval Loss:  0.3609198331832886\n",
      "Eval Loss:  0.45702534914016724\n",
      "Eval Loss:  0.40311795473098755\n",
      "Eval Loss:  0.33292266726493835\n",
      "Eval Loss:  0.38836169242858887\n",
      "Eval Loss:  0.3504883050918579\n",
      "Eval Loss:  0.4364469051361084\n",
      "Eval Loss:  0.39178934693336487\n",
      "Eval Loss:  0.3586667478084564\n",
      "Eval Loss:  0.3549608290195465\n",
      "Eval Loss:  0.35584738850593567\n",
      "Eval Loss:  0.42162951827049255\n",
      "Eval Loss:  0.4365626573562622\n",
      "Eval Loss:  0.4597027599811554\n",
      "Eval Loss:  0.42129701375961304\n",
      "Eval Loss:  0.3309200406074524\n",
      "Eval Loss:  0.3133286237716675\n",
      "Eval Loss:  0.41295114159584045\n",
      "Eval Loss:  0.4398576319217682\n",
      "Eval Loss:  0.4689751863479614\n",
      "Eval Loss:  0.38102391362190247\n",
      "Eval Loss:  0.34963878989219666\n",
      "Eval Loss:  0.26868095993995667\n",
      "[[17154   778]\n",
      " [ 3643  7904]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89     17932\n",
      "           1       0.91      0.68      0.78     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.87      0.82      0.83     29479\n",
      "weighted avg       0.86      0.85      0.84     29479\n",
      "\n",
      "acc:  0.8500288340852811\n",
      "pre:  0.9103893112186132\n",
      "rec:  0.6845067983025894\n",
      "ma F1:  0.8336500923293737\n",
      "mi F1:  0.8500288340852811\n",
      "we F1:  0.8449558508279108\n",
      "29479 461\n",
      "Loss:  0.09133881330490112\n",
      "Loss:  0.12069617956876755\n",
      "Loss:  0.1007881760597229\n",
      "12 **********\n",
      "Epoch:  685.4193270206451  fold:  6  kers:  32\n",
      "epoch:  13\n",
      "29479 461\n",
      "Loss:  0.11675061285495758\n",
      "Loss:  0.1052984669804573\n",
      "Loss:  0.09953415393829346\n",
      "13 **********\n",
      "Epoch:  725.3385908603668  fold:  6  kers:  32\n",
      "epoch:  14\n",
      "29479 461\n",
      "Loss:  0.05973187834024429\n",
      "Loss:  0.050025343894958496\n",
      "Loss:  0.058061398565769196\n",
      "14 **********\n",
      "Epoch:  765.3206865787506  fold:  6  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.0415940135717392\n",
      "Eval Loss:  0.17263951897621155\n",
      "Eval Loss:  0.484117716550827\n",
      "[[2017  215]\n",
      " [ 158 1022]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92      2232\n",
      "           1       0.83      0.87      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8906799531066822\n",
      "pre:  0.826192400970089\n",
      "rec:  0.8661016949152542\n",
      "ma F1:  0.880519191315505\n",
      "mi F1:  0.8906799531066822\n",
      "we F1:  0.8912620268977347\n",
      "Eval Loss:  0.41810545325279236\n",
      "Eval Loss:  0.3934552073478699\n",
      "Eval Loss:  0.37791121006011963\n",
      "Eval Loss:  0.3438337445259094\n",
      "Eval Loss:  0.4921216666698456\n",
      "Eval Loss:  0.3233359754085541\n",
      "Eval Loss:  0.4241585433483124\n",
      "Eval Loss:  0.35973379015922546\n",
      "Eval Loss:  0.2956143319606781\n",
      "Eval Loss:  0.343225359916687\n",
      "Eval Loss:  0.3144064247608185\n",
      "Eval Loss:  0.4123176038265228\n",
      "Eval Loss:  0.373172789812088\n",
      "Eval Loss:  0.36066195368766785\n",
      "Eval Loss:  0.314860463142395\n",
      "Eval Loss:  0.3201218843460083\n",
      "Eval Loss:  0.3725433051586151\n",
      "Eval Loss:  0.40113595128059387\n",
      "Eval Loss:  0.4282776415348053\n",
      "Eval Loss:  0.35784998536109924\n",
      "Eval Loss:  0.2879285514354706\n",
      "Eval Loss:  0.28793612122535706\n",
      "Eval Loss:  0.38164764642715454\n",
      "Eval Loss:  0.3895830512046814\n",
      "Eval Loss:  0.4580662250518799\n",
      "Eval Loss:  0.3430132269859314\n",
      "Eval Loss:  0.2984136939048767\n",
      "Eval Loss:  0.21924114227294922\n",
      "[[16988   944]\n",
      " [ 3003  8544]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     17932\n",
      "           1       0.90      0.74      0.81     11547\n",
      "\n",
      "    accuracy                           0.87     29479\n",
      "   macro avg       0.88      0.84      0.85     29479\n",
      "weighted avg       0.87      0.87      0.86     29479\n",
      "\n",
      "acc:  0.866108076936124\n",
      "pre:  0.9005059021922428\n",
      "rec:  0.7399324499870096\n",
      "ma F1:  0.8541405165876601\n",
      "mi F1:  0.866108076936124\n",
      "we F1:  0.8631898857047777\n",
      "29479 461\n",
      "Loss:  0.07729769498109818\n",
      "Loss:  0.06479991972446442\n",
      "Loss:  0.09284429252147675\n",
      "15 **********\n",
      "Epoch:  843.1595613956451  fold:  6  kers:  32\n",
      "epoch:  16\n",
      "29479 461\n",
      "Loss:  0.08102601766586304\n",
      "Loss:  0.0678056925535202\n",
      "Loss:  0.06145642697811127\n",
      "16 **********\n",
      "Epoch:  883.1207132339478  fold:  6  kers:  32\n",
      "epoch:  17\n",
      "29479 461\n",
      "Loss:  0.0896976962685585\n",
      "Loss:  0.07330965995788574\n",
      "Loss:  0.10723860561847687\n",
      "17 **********\n",
      "Epoch:  923.0848569869995  fold:  6  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.035579852759838104\n",
      "Eval Loss:  0.17655284702777863\n",
      "Eval Loss:  0.49361148476600647\n",
      "[[2040  192]\n",
      " [ 179 1001]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      2232\n",
      "           1       0.84      0.85      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8912661195779601\n",
      "pre:  0.8390611902766136\n",
      "rec:  0.8483050847457627\n",
      "ma F1:  0.8801528806956642\n",
      "mi F1:  0.89126611957796\n",
      "we F1:  0.8914051687651303\n",
      "Eval Loss:  0.42401736974716187\n",
      "Eval Loss:  0.40204060077667236\n",
      "Eval Loss:  0.39149442315101624\n",
      "Eval Loss:  0.35744839906692505\n",
      "Eval Loss:  0.5051559805870056\n",
      "Eval Loss:  0.32514163851737976\n",
      "Eval Loss:  0.42416003346443176\n",
      "Eval Loss:  0.37485188245773315\n",
      "Eval Loss:  0.29674869775772095\n",
      "Eval Loss:  0.3358156681060791\n",
      "Eval Loss:  0.3306819796562195\n",
      "Eval Loss:  0.41628435254096985\n",
      "Eval Loss:  0.3823213577270508\n",
      "Eval Loss:  0.35722166299819946\n",
      "Eval Loss:  0.32130712270736694\n",
      "Eval Loss:  0.3173386752605438\n",
      "Eval Loss:  0.3673011362552643\n",
      "Eval Loss:  0.39209482073783875\n",
      "Eval Loss:  0.43957948684692383\n",
      "Eval Loss:  0.3833106756210327\n",
      "Eval Loss:  0.3086346983909607\n",
      "Eval Loss:  0.27399879693984985\n",
      "Eval Loss:  0.3814077079296112\n",
      "Eval Loss:  0.40927693247795105\n",
      "Eval Loss:  0.45220786333084106\n",
      "Eval Loss:  0.34651660919189453\n",
      "Eval Loss:  0.3027328848838806\n",
      "Eval Loss:  0.24487070739269257\n",
      "[[17153   779]\n",
      " [ 3231  8316]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     17932\n",
      "           1       0.91      0.72      0.81     11547\n",
      "\n",
      "    accuracy                           0.86     29479\n",
      "   macro avg       0.88      0.84      0.85     29479\n",
      "weighted avg       0.87      0.86      0.86     29479\n",
      "\n",
      "acc:  0.8639709623799994\n",
      "pre:  0.91434854315558\n",
      "rec:  0.7201870615744349\n",
      "ma F1:  0.85053992996642\n",
      "mi F1:  0.8639709623799994\n",
      "we F1:  0.8602442574486769\n",
      "29479 461\n",
      "Loss:  0.0681840181350708\n",
      "Loss:  0.07622754573822021\n",
      "Loss:  0.1057422012090683\n",
      "18 **********\n",
      "Epoch:  1001.0244626998901  fold:  6  kers:  32\n",
      "epoch:  19\n",
      "29479 461\n",
      "Loss:  0.1066136583685875\n",
      "Loss:  0.09749119728803635\n",
      "Loss:  0.052014198154211044\n",
      "19 **********\n",
      "Epoch:  1040.9497108459473  fold:  6  kers:  32\n",
      "epoch:  20\n",
      "29479 461\n",
      "Loss:  0.07349947094917297\n",
      "Loss:  0.10616350173950195\n",
      "Loss:  0.07358793914318085\n",
      "20 **********\n",
      "Epoch:  1080.8430445194244  fold:  6  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.03987659513950348\n",
      "Eval Loss:  0.15634486079216003\n",
      "Eval Loss:  0.48536208271980286\n",
      "[[2030  202]\n",
      " [ 168 1012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      2232\n",
      "           1       0.83      0.86      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.891559202813599\n",
      "pre:  0.8336079077429983\n",
      "rec:  0.8576271186440678\n",
      "ma F1:  0.8809627530074245\n",
      "mi F1:  0.891559202813599\n",
      "we F1:  0.8919131117462218\n",
      "update!  Acc:  0.891559202813599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.40064677596092224\n",
      "Eval Loss:  0.3865896761417389\n",
      "Eval Loss:  0.35647904872894287\n",
      "Eval Loss:  0.31873390078544617\n",
      "Eval Loss:  0.4632824659347534\n",
      "Eval Loss:  0.2892701327800751\n",
      "Eval Loss:  0.38811197876930237\n",
      "Eval Loss:  0.3225443661212921\n",
      "Eval Loss:  0.27290043234825134\n",
      "Eval Loss:  0.2990944981575012\n",
      "Eval Loss:  0.2698723077774048\n",
      "Eval Loss:  0.3960877060890198\n",
      "Eval Loss:  0.36293429136276245\n",
      "Eval Loss:  0.3385876417160034\n",
      "Eval Loss:  0.30137747526168823\n",
      "Eval Loss:  0.29092973470687866\n",
      "Eval Loss:  0.30896875262260437\n",
      "Eval Loss:  0.3612384498119354\n",
      "Eval Loss:  0.41222497820854187\n",
      "Eval Loss:  0.32672926783561707\n",
      "Eval Loss:  0.28722476959228516\n",
      "Eval Loss:  0.2589169144630432\n",
      "Eval Loss:  0.34910523891448975\n",
      "Eval Loss:  0.3397988975048065\n",
      "Eval Loss:  0.39910566806793213\n",
      "Eval Loss:  0.3202921152114868\n",
      "Eval Loss:  0.2733117341995239\n",
      "Eval Loss:  0.20276173949241638\n",
      "[[17028   904]\n",
      " [ 2763  8784]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     17932\n",
      "           1       0.91      0.76      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.88      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.87     29479\n",
      "\n",
      "acc:  0.8756063638522338\n",
      "pre:  0.9066886870355079\n",
      "rec:  0.7607170693686672\n",
      "ma F1:  0.8650523990821748\n",
      "mi F1:  0.8756063638522338\n",
      "we F1:  0.8732264729609747\n",
      "29479 461\n",
      "Loss:  0.10971324145793915\n",
      "Loss:  0.10111469775438309\n",
      "Loss:  0.07739542424678802\n",
      "21 **********\n",
      "Epoch:  1158.8504676818848  fold:  6  kers:  32\n",
      "epoch:  22\n",
      "29479 461\n",
      "Loss:  0.058154404163360596\n",
      "Loss:  0.09378357976675034\n",
      "Loss:  0.09855141490697861\n",
      "22 **********\n",
      "Epoch:  1198.8963930606842  fold:  6  kers:  32\n",
      "epoch:  23\n",
      "29479 461\n",
      "Loss:  0.06507818400859833\n",
      "Loss:  0.09927263855934143\n",
      "Loss:  0.09100449830293655\n",
      "23 **********\n",
      "Epoch:  1238.9413216114044  fold:  6  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.03419819474220276\n",
      "Eval Loss:  0.15338611602783203\n",
      "Eval Loss:  0.47207990288734436\n",
      "[[2046  186]\n",
      " [ 176 1004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2232\n",
      "           1       0.84      0.85      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8939038686987104\n",
      "pre:  0.8436974789915966\n",
      "rec:  0.8508474576271187\n",
      "ma F1:  0.8829910628856819\n",
      "mi F1:  0.8939038686987104\n",
      "we F1:  0.8940085981211002\n",
      "update!  Acc:  0.8939038686987104\n",
      "Eval Loss:  0.3911369740962982\n",
      "Eval Loss:  0.38342010974884033\n",
      "Eval Loss:  0.3528038263320923\n",
      "Eval Loss:  0.3107260465621948\n",
      "Eval Loss:  0.45496606826782227\n",
      "Eval Loss:  0.2690308094024658\n",
      "Eval Loss:  0.3765924870967865\n",
      "Eval Loss:  0.33199912309646606\n",
      "Eval Loss:  0.27682122588157654\n",
      "Eval Loss:  0.28906506299972534\n",
      "Eval Loss:  0.2603123188018799\n",
      "Eval Loss:  0.37909996509552\n",
      "Eval Loss:  0.3630656898021698\n",
      "Eval Loss:  0.34310394525527954\n",
      "Eval Loss:  0.2859327495098114\n",
      "Eval Loss:  0.28568971157073975\n",
      "Eval Loss:  0.2957506775856018\n",
      "Eval Loss:  0.36979252099990845\n",
      "Eval Loss:  0.419322669506073\n",
      "Eval Loss:  0.32447874546051025\n",
      "Eval Loss:  0.28279930353164673\n",
      "Eval Loss:  0.24650192260742188\n",
      "Eval Loss:  0.3309471905231476\n",
      "Eval Loss:  0.34820759296417236\n",
      "Eval Loss:  0.3899255692958832\n",
      "Eval Loss:  0.3195106089115143\n",
      "Eval Loss:  0.2685878872871399\n",
      "Eval Loss:  0.20268578827381134\n",
      "[[17108   824]\n",
      " [ 2747  8800]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91     17932\n",
      "           1       0.91      0.76      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.89      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8788629193663285\n",
      "pre:  0.914380714879468\n",
      "rec:  0.7621027106607777\n",
      "ma F1:  0.8684112348269193\n",
      "mi F1:  0.8788629193663285\n",
      "we F1:  0.876443734319472\n",
      "29479 461\n",
      "Loss:  0.07803858816623688\n",
      "Loss:  0.07310450077056885\n",
      "Loss:  0.05569499731063843\n",
      "24 **********\n",
      "Epoch:  1316.8061265945435  fold:  6  kers:  32\n",
      "epoch:  25\n",
      "29479 461\n",
      "Loss:  0.07291199266910553\n",
      "Loss:  0.05441230908036232\n",
      "Loss:  0.06585291028022766\n",
      "25 **********\n",
      "Epoch:  1356.7942068576813  fold:  6  kers:  32\n",
      "epoch:  26\n",
      "29479 461\n",
      "Loss:  0.0948329046368599\n",
      "Loss:  0.08741498738527298\n",
      "Loss:  0.09357926994562149\n",
      "26 **********\n",
      "Epoch:  1396.8670601844788  fold:  6  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.028855688869953156\n",
      "Eval Loss:  0.19408462941646576\n",
      "Eval Loss:  0.4818241000175476\n",
      "[[2118  114]\n",
      " [ 237  943]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      2232\n",
      "           1       0.89      0.80      0.84      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.90      0.87      0.88      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8971277842907386\n",
      "pre:  0.8921475875118259\n",
      "rec:  0.7991525423728814\n",
      "ma F1:  0.8832864134993463\n",
      "mi F1:  0.8971277842907386\n",
      "we F1:  0.8956788578164055\n",
      "update!  Acc:  0.8971277842907386\n",
      "Eval Loss:  0.3875634968280792\n",
      "Eval Loss:  0.3867584764957428\n",
      "Eval Loss:  0.370956689119339\n",
      "Eval Loss:  0.34307557344436646\n",
      "Eval Loss:  0.4629579484462738\n",
      "Eval Loss:  0.2709116041660309\n",
      "Eval Loss:  0.39253613352775574\n",
      "Eval Loss:  0.345096617937088\n",
      "Eval Loss:  0.27430444955825806\n",
      "Eval Loss:  0.28530097007751465\n",
      "Eval Loss:  0.2880692481994629\n",
      "Eval Loss:  0.41000863909721375\n",
      "Eval Loss:  0.37888219952583313\n",
      "Eval Loss:  0.35341760516166687\n",
      "Eval Loss:  0.3086879551410675\n",
      "Eval Loss:  0.3042937219142914\n",
      "Eval Loss:  0.314945250749588\n",
      "Eval Loss:  0.3631512522697449\n",
      "Eval Loss:  0.4593266546726227\n",
      "Eval Loss:  0.3566729426383972\n",
      "Eval Loss:  0.31152811646461487\n",
      "Eval Loss:  0.27182653546333313\n",
      "Eval Loss:  0.34476596117019653\n",
      "Eval Loss:  0.38091087341308594\n",
      "Eval Loss:  0.4102807641029358\n",
      "Eval Loss:  0.3240674138069153\n",
      "Eval Loss:  0.2844776213169098\n",
      "Eval Loss:  0.22394080460071564\n",
      "[[17266   666]\n",
      " [ 3129  8418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     17932\n",
      "           1       0.93      0.73      0.82     11547\n",
      "\n",
      "    accuracy                           0.87     29479\n",
      "   macro avg       0.89      0.85      0.86     29479\n",
      "weighted avg       0.88      0.87      0.87     29479\n",
      "\n",
      "acc:  0.8712642898334407\n",
      "pre:  0.9266842800528402\n",
      "rec:  0.7290205248116394\n",
      "ma F1:  0.8585185762405592\n",
      "mi F1:  0.8712642898334407\n",
      "we F1:  0.8677162911242108\n",
      "29479 461\n",
      "Loss:  0.0713387057185173\n",
      "Loss:  0.07559551298618317\n",
      "Loss:  0.07574496418237686\n",
      "27 **********\n",
      "Epoch:  1474.7697639465332  fold:  6  kers:  32\n",
      "epoch:  28\n",
      "29479 461\n",
      "Loss:  0.06616945564746857\n",
      "Loss:  0.07733919471502304\n",
      "Loss:  0.07890919595956802\n",
      "28 **********\n",
      "Epoch:  1514.7259294986725  fold:  6  kers:  32\n",
      "epoch:  29\n",
      "29479 461\n",
      "Loss:  0.06588514894247055\n",
      "Loss:  0.06462864577770233\n",
      "Loss:  0.11251383274793625\n",
      "29 **********\n",
      "Epoch:  1554.8127455711365  fold:  6  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.03071049228310585\n",
      "Eval Loss:  0.16336578130722046\n",
      "Eval Loss:  0.4594002664089203\n",
      "[[2063  169]\n",
      " [ 178 1002]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2232\n",
      "           1       0.86      0.85      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8983001172332943\n",
      "pre:  0.8556789069171649\n",
      "rec:  0.8491525423728814\n",
      "ma F1:  0.8874133310663167\n",
      "mi F1:  0.8983001172332943\n",
      "we F1:  0.898207769377024\n",
      "update!  Acc:  0.8983001172332943\n",
      "Eval Loss:  0.35875388979911804\n",
      "Eval Loss:  0.38030698895454407\n",
      "Eval Loss:  0.3123618960380554\n",
      "Eval Loss:  0.305574893951416\n",
      "Eval Loss:  0.42164933681488037\n",
      "Eval Loss:  0.258328914642334\n",
      "Eval Loss:  0.320272296667099\n",
      "Eval Loss:  0.27538299560546875\n",
      "Eval Loss:  0.2364881932735443\n",
      "Eval Loss:  0.24219776690006256\n",
      "Eval Loss:  0.24104081094264984\n",
      "Eval Loss:  0.34143874049186707\n",
      "Eval Loss:  0.3337317109107971\n",
      "Eval Loss:  0.31590622663497925\n",
      "Eval Loss:  0.27783483266830444\n",
      "Eval Loss:  0.25298872590065\n",
      "Eval Loss:  0.25355207920074463\n",
      "Eval Loss:  0.33143314719200134\n",
      "Eval Loss:  0.40341630578041077\n",
      "Eval Loss:  0.29288050532341003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.255946546792984\n",
      "Eval Loss:  0.24712912738323212\n",
      "Eval Loss:  0.2770286500453949\n",
      "Eval Loss:  0.3144119381904602\n",
      "Eval Loss:  0.34852027893066406\n",
      "Eval Loss:  0.2987152338027954\n",
      "Eval Loss:  0.23608741164207458\n",
      "Eval Loss:  0.17343659698963165\n",
      "[[16984   948]\n",
      " [ 2380  9167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     17932\n",
      "           1       0.91      0.79      0.85     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.89      0.87      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.887106075511381\n",
      "pre:  0.906277805239743\n",
      "rec:  0.7938858577985624\n",
      "ma F1:  0.8785674102819334\n",
      "mi F1:  0.887106075511381\n",
      "we F1:  0.8855418733099522\n",
      "29479 461\n",
      "Loss:  0.09146968275308609\n",
      "Loss:  0.10784769058227539\n",
      "Loss:  0.046613238751888275\n",
      "30 **********\n",
      "Epoch:  1632.5947721004486  fold:  6  kers:  32\n",
      "epoch:  31\n",
      "29479 461\n",
      "Loss:  0.06655286997556686\n",
      "Loss:  0.09289909154176712\n",
      "Loss:  0.07061640918254852\n",
      "31 **********\n",
      "Epoch:  1672.5429587364197  fold:  6  kers:  32\n",
      "epoch:  32\n",
      "29479 461\n",
      "Loss:  0.0753672868013382\n",
      "Loss:  0.05373101681470871\n",
      "Loss:  0.07816921919584274\n",
      "32 **********\n",
      "Epoch:  1712.5609588623047  fold:  6  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.0238603875041008\n",
      "Eval Loss:  0.19137266278266907\n",
      "Eval Loss:  0.45615464448928833\n",
      "[[2121  111]\n",
      " [ 238  942]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      2232\n",
      "           1       0.89      0.80      0.84      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.90      0.87      0.88      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8977139507620164\n",
      "pre:  0.8945868945868946\n",
      "rec:  0.7983050847457627\n",
      "ma F1:  0.8838448597272083\n",
      "mi F1:  0.8977139507620164\n",
      "we F1:  0.8962199943910065\n",
      "Eval Loss:  0.3520452380180359\n",
      "Eval Loss:  0.38791730999946594\n",
      "Eval Loss:  0.33841344714164734\n",
      "Eval Loss:  0.29419490694999695\n",
      "Eval Loss:  0.41430702805519104\n",
      "Eval Loss:  0.2519773244857788\n",
      "Eval Loss:  0.3330800235271454\n",
      "Eval Loss:  0.27933090925216675\n",
      "Eval Loss:  0.24513405561447144\n",
      "Eval Loss:  0.2404412180185318\n",
      "Eval Loss:  0.24883586168289185\n",
      "Eval Loss:  0.37723830342292786\n",
      "Eval Loss:  0.3416007459163666\n",
      "Eval Loss:  0.32043612003326416\n",
      "Eval Loss:  0.27185431122779846\n",
      "Eval Loss:  0.2775939702987671\n",
      "Eval Loss:  0.2899291515350342\n",
      "Eval Loss:  0.3436887264251709\n",
      "Eval Loss:  0.4299115538597107\n",
      "Eval Loss:  0.292479932308197\n",
      "Eval Loss:  0.27154430747032166\n",
      "Eval Loss:  0.2738695442676544\n",
      "Eval Loss:  0.30578306317329407\n",
      "Eval Loss:  0.3262263834476471\n",
      "Eval Loss:  0.3405284881591797\n",
      "Eval Loss:  0.3063031733036041\n",
      "Eval Loss:  0.23412922024726868\n",
      "Eval Loss:  0.18420279026031494\n",
      "[[17133   799]\n",
      " [ 2586  8961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17932\n",
      "           1       0.92      0.78      0.84     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.89      0.87      0.88     29479\n",
      "weighted avg       0.89      0.89      0.88     29479\n",
      "\n",
      "acc:  0.8851724956748872\n",
      "pre:  0.9181352459016393\n",
      "rec:  0.7760457261626397\n",
      "ma F1:  0.8756136858665932\n",
      "mi F1:  0.8851724956748872\n",
      "we F1:  0.8830822370934602\n",
      "29479 461\n",
      "Loss:  0.08119247108697891\n",
      "Loss:  0.0667952299118042\n",
      "Loss:  0.060982488095760345\n",
      "33 **********\n",
      "Epoch:  1790.0657269954681  fold:  6  kers:  32\n",
      "epoch:  34\n",
      "29479 461\n",
      "Loss:  0.060379233211278915\n",
      "Loss:  0.057141099125146866\n",
      "Loss:  0.09389758110046387\n",
      "34 **********\n",
      "Epoch:  1830.144564151764  fold:  6  kers:  32\n",
      "epoch:  35\n",
      "29479 461\n",
      "Loss:  0.08030609786510468\n",
      "Loss:  0.10436628758907318\n",
      "Loss:  0.06781016290187836\n",
      "35 **********\n",
      "Epoch:  1870.1336414813995  fold:  6  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.02893521636724472\n",
      "Eval Loss:  0.16820606589317322\n",
      "Eval Loss:  0.41245925426483154\n",
      "[[2054  178]\n",
      " [ 167 1013]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2232\n",
      "           1       0.85      0.86      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8988862837045721\n",
      "pre:  0.8505457598656591\n",
      "rec:  0.8584745762711864\n",
      "ma F1:  0.8885079583253102\n",
      "mi F1:  0.8988862837045721\n",
      "we F1:  0.8989959490063703\n",
      "update!  Acc:  0.8988862837045721\n",
      "Eval Loss:  0.3591425120830536\n",
      "Eval Loss:  0.36732813715934753\n",
      "Eval Loss:  0.28360515832901\n",
      "Eval Loss:  0.30361872911453247\n",
      "Eval Loss:  0.3992565870285034\n",
      "Eval Loss:  0.25851327180862427\n",
      "Eval Loss:  0.3256070017814636\n",
      "Eval Loss:  0.25345832109451294\n",
      "Eval Loss:  0.2423039674758911\n",
      "Eval Loss:  0.23307079076766968\n",
      "Eval Loss:  0.22188186645507812\n",
      "Eval Loss:  0.3117614984512329\n",
      "Eval Loss:  0.3177224099636078\n",
      "Eval Loss:  0.28904807567596436\n",
      "Eval Loss:  0.2614995539188385\n",
      "Eval Loss:  0.23060135543346405\n",
      "Eval Loss:  0.22253450751304626\n",
      "Eval Loss:  0.33325135707855225\n",
      "Eval Loss:  0.3919575810432434\n",
      "Eval Loss:  0.2570430636405945\n",
      "Eval Loss:  0.2551131248474121\n",
      "Eval Loss:  0.2350139319896698\n",
      "Eval Loss:  0.23676523566246033\n",
      "Eval Loss:  0.306428998708725\n",
      "Eval Loss:  0.33340027928352356\n",
      "Eval Loss:  0.28383076190948486\n",
      "Eval Loss:  0.23477382957935333\n",
      "Eval Loss:  0.16143645346164703\n",
      "[[16853  1079]\n",
      " [ 2105  9442]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     17932\n",
      "           1       0.90      0.82      0.86     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.89      0.88      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8919909087825232\n",
      "pre:  0.8974432088204544\n",
      "rec:  0.8177015675067117\n",
      "ma F1:  0.8847040171995055\n",
      "mi F1:  0.8919909087825232\n",
      "we F1:  0.8909820907061266\n",
      "29479 461\n",
      "Loss:  0.05397605895996094\n",
      "Loss:  0.07423608005046844\n",
      "Loss:  0.06757621467113495\n",
      "36 **********\n",
      "Epoch:  1948.2048950195312  fold:  6  kers:  32\n",
      "epoch:  37\n",
      "29479 461\n",
      "Loss:  0.08672969043254852\n",
      "Loss:  0.0676756203174591\n",
      "Loss:  0.06167113035917282\n",
      "37 **********\n",
      "Epoch:  1988.2478280067444  fold:  6  kers:  32\n",
      "epoch:  38\n",
      "29479 461\n",
      "Loss:  0.06413011252880096\n",
      "Loss:  0.051691070199012756\n",
      "Loss:  0.04334455728530884\n",
      "38 **********\n",
      "Epoch:  2028.2678225040436  fold:  6  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.03171245753765106\n",
      "Eval Loss:  0.1407276690006256\n",
      "Eval Loss:  0.41680407524108887\n",
      "[[2049  183]\n",
      " [ 145 1035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      2232\n",
      "           1       0.85      0.88      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.90      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.9038686987104337\n",
      "pre:  0.8497536945812808\n",
      "rec:  0.8771186440677966\n",
      "ma F1:  0.8945559015703326\n",
      "mi F1:  0.9038686987104337\n",
      "we F1:  0.9042176989977354\n",
      "update!  Acc:  0.9038686987104337\n",
      "Eval Loss:  0.34743839502334595\n",
      "Eval Loss:  0.36025071144104004\n",
      "Eval Loss:  0.27359718084335327\n",
      "Eval Loss:  0.2829713821411133\n",
      "Eval Loss:  0.3644992709159851\n",
      "Eval Loss:  0.26455825567245483\n",
      "Eval Loss:  0.28743448853492737\n",
      "Eval Loss:  0.22989514470100403\n",
      "Eval Loss:  0.22837625443935394\n",
      "Eval Loss:  0.21379409730434418\n",
      "Eval Loss:  0.2107056826353073\n",
      "Eval Loss:  0.32301056385040283\n",
      "Eval Loss:  0.2932380139827728\n",
      "Eval Loss:  0.2807815372943878\n",
      "Eval Loss:  0.24641819298267365\n",
      "Eval Loss:  0.221174955368042\n",
      "Eval Loss:  0.21510975062847137\n",
      "Eval Loss:  0.31510645151138306\n",
      "Eval Loss:  0.37511858344078064\n",
      "Eval Loss:  0.22650867700576782\n",
      "Eval Loss:  0.23948785662651062\n",
      "Eval Loss:  0.22447477281093597\n",
      "Eval Loss:  0.2384054809808731\n",
      "Eval Loss:  0.2742115557193756\n",
      "Eval Loss:  0.2970539927482605\n",
      "Eval Loss:  0.27377021312713623\n",
      "Eval Loss:  0.22067922353744507\n",
      "Eval Loss:  0.14812114834785461\n",
      "[[16749  1183]\n",
      " [ 1846  9701]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     17932\n",
      "           1       0.89      0.84      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.89      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8972488890396554\n",
      "pre:  0.8913083425211319\n",
      "rec:  0.8401316359227505\n",
      "ma F1:  0.8910193533678432\n",
      "mi F1:  0.8972488890396554\n",
      "we F1:  0.8966628813565664\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07743362337350845\n",
      "Loss:  0.07718627154827118\n",
      "Loss:  0.06395892053842545\n",
      "39 **********\n",
      "Epoch:  2106.2293696403503  fold:  6  kers:  32\n",
      "epoch:  40\n",
      "29479 461\n",
      "Loss:  0.05533541366457939\n",
      "Loss:  0.048227302730083466\n",
      "Loss:  0.05041952058672905\n",
      "40 **********\n",
      "Epoch:  2146.2164521217346  fold:  6  kers:  32\n",
      "epoch:  41\n",
      "29479 461\n",
      "Loss:  0.0855097696185112\n",
      "Loss:  0.055482834577560425\n",
      "Loss:  0.05528482422232628\n",
      "41 **********\n",
      "Epoch:  2186.1277375221252  fold:  6  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.019794713705778122\n",
      "Eval Loss:  0.2282472401857376\n",
      "Eval Loss:  0.5297963619232178\n",
      "[[2141   91]\n",
      " [ 275  905]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      2232\n",
      "           1       0.91      0.77      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.90      0.86      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8927315357561547\n",
      "pre:  0.9086345381526104\n",
      "rec:  0.7669491525423728\n",
      "ma F1:  0.8765289624886099\n",
      "mi F1:  0.8927315357561547\n",
      "we F1:  0.8903195021952904\n",
      "Eval Loss:  0.33448442816734314\n",
      "Eval Loss:  0.3651173412799835\n",
      "Eval Loss:  0.288677841424942\n",
      "Eval Loss:  0.33380910754203796\n",
      "Eval Loss:  0.3865373730659485\n",
      "Eval Loss:  0.2321634292602539\n",
      "Eval Loss:  0.3317505121231079\n",
      "Eval Loss:  0.2639550566673279\n",
      "Eval Loss:  0.24542686343193054\n",
      "Eval Loss:  0.22191639244556427\n",
      "Eval Loss:  0.23491151630878448\n",
      "Eval Loss:  0.3579062819480896\n",
      "Eval Loss:  0.33309024572372437\n",
      "Eval Loss:  0.29723408818244934\n",
      "Eval Loss:  0.26981866359710693\n",
      "Eval Loss:  0.264906108379364\n",
      "Eval Loss:  0.25101280212402344\n",
      "Eval Loss:  0.33842551708221436\n",
      "Eval Loss:  0.41752296686172485\n",
      "Eval Loss:  0.2653065621852875\n",
      "Eval Loss:  0.25701484084129333\n",
      "Eval Loss:  0.24118450284004211\n",
      "Eval Loss:  0.2626679539680481\n",
      "Eval Loss:  0.29320579767227173\n",
      "Eval Loss:  0.3383154571056366\n",
      "Eval Loss:  0.2809792459011078\n",
      "Eval Loss:  0.26017677783966064\n",
      "Eval Loss:  0.17551368474960327\n",
      "[[17215   717]\n",
      " [ 2572  8975]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17932\n",
      "           1       0.93      0.78      0.85     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.90      0.87      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.888429051188982\n",
      "pre:  0.9260214609987618\n",
      "rec:  0.7772581622932363\n",
      "ma F1:  0.8789729673388578\n",
      "mi F1:  0.888429051188982\n",
      "we F1:  0.8863002847397125\n",
      "29479 461\n",
      "Loss:  0.06350871920585632\n",
      "Loss:  0.07583868503570557\n",
      "Loss:  0.04559540003538132\n",
      "42 **********\n",
      "Epoch:  2263.967609643936  fold:  6  kers:  32\n",
      "epoch:  43\n",
      "29479 461\n",
      "Loss:  0.0563221238553524\n",
      "Loss:  0.06653740257024765\n",
      "Loss:  0.07307033985853195\n",
      "43 **********\n",
      "Epoch:  2303.861940383911  fold:  6  kers:  32\n",
      "epoch:  44\n",
      "29479 461\n",
      "Loss:  0.059488825500011444\n",
      "Loss:  0.06382912397384644\n",
      "Loss:  0.09198020398616791\n",
      "44 **********\n",
      "Epoch:  2343.7682387828827  fold:  6  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.02167956531047821\n",
      "Eval Loss:  0.16561856865882874\n",
      "Eval Loss:  0.40585222840309143\n",
      "[[2128  104]\n",
      " [ 226  954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93      2232\n",
      "           1       0.90      0.81      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.90      0.88      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.9032825322391559\n",
      "pre:  0.9017013232514177\n",
      "rec:  0.8084745762711865\n",
      "ma F1:  0.8902943917202255\n",
      "mi F1:  0.9032825322391559\n",
      "we F1:  0.9019328276877849\n",
      "Eval Loss:  0.33073264360427856\n",
      "Eval Loss:  0.36074480414390564\n",
      "Eval Loss:  0.30452990531921387\n",
      "Eval Loss:  0.2845478057861328\n",
      "Eval Loss:  0.3637096583843231\n",
      "Eval Loss:  0.23811592161655426\n",
      "Eval Loss:  0.3179855942726135\n",
      "Eval Loss:  0.23486486077308655\n",
      "Eval Loss:  0.23364658653736115\n",
      "Eval Loss:  0.21947988867759705\n",
      "Eval Loss:  0.23466229438781738\n",
      "Eval Loss:  0.34771883487701416\n",
      "Eval Loss:  0.3242560923099518\n",
      "Eval Loss:  0.2630544900894165\n",
      "Eval Loss:  0.22718816995620728\n",
      "Eval Loss:  0.24483878910541534\n",
      "Eval Loss:  0.22012224793434143\n",
      "Eval Loss:  0.3181911110877991\n",
      "Eval Loss:  0.4141380488872528\n",
      "Eval Loss:  0.2299627959728241\n",
      "Eval Loss:  0.25714755058288574\n",
      "Eval Loss:  0.23405233025550842\n",
      "Eval Loss:  0.25108128786087036\n",
      "Eval Loss:  0.3036368787288666\n",
      "Eval Loss:  0.30045509338378906\n",
      "Eval Loss:  0.2703981399536133\n",
      "Eval Loss:  0.24115332961082458\n",
      "Eval Loss:  0.16464391350746155\n",
      "[[17116   816]\n",
      " [ 2236  9311]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     17932\n",
      "           1       0.92      0.81      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.88      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8964686726144034\n",
      "pre:  0.9194233237878937\n",
      "rec:  0.8063566294275569\n",
      "ma F1:  0.8886639759480481\n",
      "mi F1:  0.8964686726144034\n",
      "we F1:  0.8950487278013063\n",
      "29479 461\n",
      "Loss:  0.06296853721141815\n",
      "Loss:  0.04568662866950035\n",
      "Loss:  0.03875598683953285\n",
      "45 **********\n",
      "Epoch:  2421.5751984119415  fold:  6  kers:  32\n",
      "epoch:  46\n",
      "29479 461\n",
      "Loss:  0.05539385601878166\n",
      "Loss:  0.056475088000297546\n",
      "Loss:  0.07100790739059448\n",
      "46 **********\n",
      "Epoch:  2461.586217403412  fold:  6  kers:  32\n",
      "epoch:  47\n",
      "29479 461\n",
      "Loss:  0.05688584968447685\n",
      "Loss:  0.08663931488990784\n",
      "Loss:  0.05610360577702522\n",
      "47 **********\n",
      "Epoch:  2501.5523562431335  fold:  6  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.018649544566869736\n",
      "Eval Loss:  0.1464138776063919\n",
      "Eval Loss:  0.4063912630081177\n",
      "[[2088  144]\n",
      " [ 182  998]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2232\n",
      "           1       0.87      0.85      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.90      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.9044548651817116\n",
      "pre:  0.8739054290718039\n",
      "rec:  0.8457627118644068\n",
      "ma F1:  0.8935957643095556\n",
      "mi F1:  0.9044548651817116\n",
      "we F1:  0.9040762910228657\n",
      "update!  Acc:  0.9044548651817116\n",
      "Eval Loss:  0.3428589701652527\n",
      "Eval Loss:  0.36221611499786377\n",
      "Eval Loss:  0.28617313504219055\n",
      "Eval Loss:  0.29766416549682617\n",
      "Eval Loss:  0.3759503960609436\n",
      "Eval Loss:  0.24575473368167877\n",
      "Eval Loss:  0.29181674122810364\n",
      "Eval Loss:  0.22311455011367798\n",
      "Eval Loss:  0.22600209712982178\n",
      "Eval Loss:  0.2136978954076767\n",
      "Eval Loss:  0.21842803061008453\n",
      "Eval Loss:  0.31914669275283813\n",
      "Eval Loss:  0.3104484975337982\n",
      "Eval Loss:  0.24688421189785004\n",
      "Eval Loss:  0.24462413787841797\n",
      "Eval Loss:  0.2252959907054901\n",
      "Eval Loss:  0.21531884372234344\n",
      "Eval Loss:  0.3117627203464508\n",
      "Eval Loss:  0.38452982902526855\n",
      "Eval Loss:  0.20743152499198914\n",
      "Eval Loss:  0.23412159085273743\n",
      "Eval Loss:  0.23601187765598297\n",
      "Eval Loss:  0.23003560304641724\n",
      "Eval Loss:  0.28819528222084045\n",
      "Eval Loss:  0.2964816689491272\n",
      "Eval Loss:  0.26193150877952576\n",
      "Eval Loss:  0.22385911643505096\n",
      "Eval Loss:  0.14787140488624573\n",
      "[[17027   905]\n",
      " [ 2032  9515]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17932\n",
      "           1       0.91      0.82      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.89      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9003697547406628\n",
      "pre:  0.913147792706334\n",
      "rec:  0.8240235559019659\n",
      "ma F1:  0.8934508789217186\n",
      "mi F1:  0.9003697547406628\n",
      "we F1:  0.8993317391592\n",
      "29479 461\n",
      "Loss:  0.07732131332159042\n",
      "Loss:  0.05925944820046425\n",
      "Loss:  0.06251117587089539\n",
      "48 **********\n",
      "Epoch:  2579.4670281410217  fold:  6  kers:  32\n",
      "epoch:  49\n",
      "29479 461\n",
      "Loss:  0.06649802625179291\n",
      "Loss:  0.06392798572778702\n",
      "Loss:  0.06089470908045769\n",
      "49 **********\n",
      "Epoch:  2619.268606901169  fold:  6  kers:  32\n",
      "epoch:  50\n",
      "29479 461\n",
      "Loss:  0.06222032010555267\n",
      "Loss:  0.06644707173109055\n",
      "Loss:  0.07370337843894958\n",
      "50 **********\n",
      "Epoch:  2659.271646976471  fold:  6  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.020582230761647224\n",
      "Eval Loss:  0.14417490363121033\n",
      "Eval Loss:  0.4041968882083893\n",
      "[[2102  130]\n",
      " [ 189  991]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2232\n",
      "           1       0.88      0.84      0.86      1180\n",
      "\n",
      "    accuracy                           0.91      3412\n",
      "   macro avg       0.90      0.89      0.90      3412\n",
      "weighted avg       0.91      0.91      0.91      3412\n",
      "\n",
      "acc:  0.9065064478311841\n",
      "pre:  0.8840321141837645\n",
      "rec:  0.8398305084745763\n",
      "ma F1:  0.8954181068646869\n",
      "mi F1:  0.9065064478311841\n",
      "we F1:  0.9059175980408841\n",
      "update!  Acc:  0.9065064478311841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3402172923088074\n",
      "Eval Loss:  0.35846441984176636\n",
      "Eval Loss:  0.27365466952323914\n",
      "Eval Loss:  0.2656676471233368\n",
      "Eval Loss:  0.33998653292655945\n",
      "Eval Loss:  0.23994655907154083\n",
      "Eval Loss:  0.2933628261089325\n",
      "Eval Loss:  0.2063935101032257\n",
      "Eval Loss:  0.23566250503063202\n",
      "Eval Loss:  0.20561844110488892\n",
      "Eval Loss:  0.21721181273460388\n",
      "Eval Loss:  0.3473125100135803\n",
      "Eval Loss:  0.29515978693962097\n",
      "Eval Loss:  0.24167564511299133\n",
      "Eval Loss:  0.219988152384758\n",
      "Eval Loss:  0.24074670672416687\n",
      "Eval Loss:  0.22936847805976868\n",
      "Eval Loss:  0.29447218775749207\n",
      "Eval Loss:  0.39172330498695374\n",
      "Eval Loss:  0.19931665062904358\n",
      "Eval Loss:  0.22789376974105835\n",
      "Eval Loss:  0.2422720044851303\n",
      "Eval Loss:  0.24519549310207367\n",
      "Eval Loss:  0.250497043132782\n",
      "Eval Loss:  0.2932853698730469\n",
      "Eval Loss:  0.24355995655059814\n",
      "Eval Loss:  0.2223125547170639\n",
      "Eval Loss:  0.1423850655555725\n",
      "[[16987   945]\n",
      " [ 1926  9621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17932\n",
      "           1       0.91      0.83      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.89      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.902608636656603\n",
      "pre:  0.9105621805792163\n",
      "rec:  0.8332034294621979\n",
      "ma F1:  0.8961229248378115\n",
      "mi F1:  0.902608636656603\n",
      "we F1:  0.9017448729728893\n",
      "29479 461\n",
      "Loss:  0.05017181858420372\n",
      "Loss:  0.06484397500753403\n",
      "Loss:  0.04834764078259468\n",
      "51 **********\n",
      "Epoch:  2739.0912251472473  fold:  6  kers:  32\n",
      "epoch:  52\n",
      "29479 461\n",
      "Loss:  0.0725223496556282\n",
      "Loss:  0.09424693882465363\n",
      "Loss:  0.07363659143447876\n",
      "52 **********\n",
      "Epoch:  2780.708948135376  fold:  6  kers:  32\n",
      "epoch:  53\n",
      "29479 461\n",
      "Loss:  0.06402810662984848\n",
      "Loss:  0.04073702171444893\n",
      "Loss:  0.05787300691008568\n",
      "53 **********\n",
      "Epoch:  2821.3054010868073  fold:  6  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.021152794361114502\n",
      "Eval Loss:  0.1305333822965622\n",
      "Eval Loss:  0.38100096583366394\n",
      "[[2084  148]\n",
      " [ 183  997]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      2232\n",
      "           1       0.87      0.84      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.90      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.902989449003517\n",
      "pre:  0.8707423580786027\n",
      "rec:  0.8449152542372881\n",
      "ma F1:  0.8920312518672011\n",
      "mi F1:  0.902989449003517\n",
      "we F1:  0.902636609169321\n",
      "Eval Loss:  0.3194272816181183\n",
      "Eval Loss:  0.3636486530303955\n",
      "Eval Loss:  0.2660730481147766\n",
      "Eval Loss:  0.2786986231803894\n",
      "Eval Loss:  0.32474446296691895\n",
      "Eval Loss:  0.221888929605484\n",
      "Eval Loss:  0.2817573845386505\n",
      "Eval Loss:  0.1891688108444214\n",
      "Eval Loss:  0.23408877849578857\n",
      "Eval Loss:  0.1899736374616623\n",
      "Eval Loss:  0.1976180374622345\n",
      "Eval Loss:  0.3516022264957428\n",
      "Eval Loss:  0.2922430634498596\n",
      "Eval Loss:  0.22877441346645355\n",
      "Eval Loss:  0.21897748112678528\n",
      "Eval Loss:  0.2191259115934372\n",
      "Eval Loss:  0.21142099797725677\n",
      "Eval Loss:  0.2836862802505493\n",
      "Eval Loss:  0.37570473551750183\n",
      "Eval Loss:  0.17655465006828308\n",
      "Eval Loss:  0.21817167103290558\n",
      "Eval Loss:  0.23009361326694489\n",
      "Eval Loss:  0.23417241871356964\n",
      "Eval Loss:  0.24167589843273163\n",
      "Eval Loss:  0.2708331346511841\n",
      "Eval Loss:  0.23135024309158325\n",
      "Eval Loss:  0.2058069109916687\n",
      "Eval Loss:  0.14915843307971954\n",
      "[[16783  1149]\n",
      " [ 1659  9888]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     17932\n",
      "           1       0.90      0.86      0.88     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9047457512127277\n",
      "pre:  0.8958956238108181\n",
      "rec:  0.856326318524292\n",
      "ma F1:  0.8992330942323309\n",
      "mi F1:  0.9047457512127278\n",
      "we F1:  0.9043379984846637\n",
      "29479 461\n",
      "Loss:  0.03029811568558216\n",
      "Loss:  0.06555238366127014\n",
      "Loss:  0.07574370503425598\n",
      "54 **********\n",
      "Epoch:  2904.8799402713776  fold:  6  kers:  32\n",
      "epoch:  55\n",
      "29479 461\n",
      "Loss:  0.07484947890043259\n",
      "Loss:  0.04858943074941635\n",
      "Loss:  0.07093939185142517\n",
      "55 **********\n",
      "Epoch:  2946.1466019153595  fold:  6  kers:  32\n",
      "epoch:  56\n",
      "29479 461\n",
      "Loss:  0.04135771840810776\n",
      "Loss:  0.07049958407878876\n",
      "Loss:  0.07861196994781494\n",
      "56 **********\n",
      "Epoch:  2987.4322123527527  fold:  6  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.012794259004294872\n",
      "Eval Loss:  0.17883241176605225\n",
      "Eval Loss:  0.39574891328811646\n",
      "[[2123  109]\n",
      " [ 255  925]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      2232\n",
      "           1       0.89      0.78      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.87      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8933177022274326\n",
      "pre:  0.8945841392649904\n",
      "rec:  0.7838983050847458\n",
      "ma F1:  0.8783164520003841\n",
      "mi F1:  0.8933177022274326\n",
      "we F1:  0.8914895031179592\n",
      "Eval Loss:  0.3069041967391968\n",
      "Eval Loss:  0.35161805152893066\n",
      "Eval Loss:  0.2607698142528534\n",
      "Eval Loss:  0.2937071919441223\n",
      "Eval Loss:  0.33377164602279663\n",
      "Eval Loss:  0.2053905427455902\n",
      "Eval Loss:  0.2946626842021942\n",
      "Eval Loss:  0.20280753076076508\n",
      "Eval Loss:  0.23245064914226532\n",
      "Eval Loss:  0.1998068243265152\n",
      "Eval Loss:  0.2128453552722931\n",
      "Eval Loss:  0.3373894691467285\n",
      "Eval Loss:  0.3014431297779083\n",
      "Eval Loss:  0.24026349186897278\n",
      "Eval Loss:  0.24156522750854492\n",
      "Eval Loss:  0.24842342734336853\n",
      "Eval Loss:  0.2305147349834442\n",
      "Eval Loss:  0.3056945502758026\n",
      "Eval Loss:  0.39588499069213867\n",
      "Eval Loss:  0.2111697494983673\n",
      "Eval Loss:  0.22511057555675507\n",
      "Eval Loss:  0.23281021416187286\n",
      "Eval Loss:  0.23057988286018372\n",
      "Eval Loss:  0.2554883062839508\n",
      "Eval Loss:  0.2925039231777191\n",
      "Eval Loss:  0.23703952133655548\n",
      "Eval Loss:  0.2210090458393097\n",
      "Eval Loss:  0.15399406850337982\n",
      "[[17104   828]\n",
      " [ 2108  9439]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17932\n",
      "           1       0.92      0.82      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.89      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9004036771939347\n",
      "pre:  0.9193532677510471\n",
      "rec:  0.817441759764441\n",
      "ma F1:  0.8931819073564231\n",
      "mi F1:  0.9004036771939347\n",
      "we F1:  0.8991976934506842\n",
      "29479 461\n",
      "Loss:  0.06652437150478363\n",
      "Loss:  0.031294237822294235\n",
      "Loss:  0.05750243738293648\n",
      "57 **********\n",
      "Epoch:  3067.1231348514557  fold:  6  kers:  32\n",
      "epoch:  58\n",
      "29479 461\n",
      "Loss:  0.05869391933083534\n",
      "Loss:  0.09449207037687302\n",
      "Loss:  0.09371735155582428\n",
      "58 **********\n",
      "Epoch:  3108.4097430706024  fold:  6  kers:  32\n",
      "epoch:  59\n",
      "29479 461\n",
      "Loss:  0.06840556114912033\n",
      "Loss:  0.08422787487506866\n",
      "Loss:  0.049098942428827286\n",
      "59 **********\n",
      "Epoch:  3148.6391780376434  fold:  6  kers:  32\n",
      "Eval Loss:  0.01641598716378212\n",
      "Eval Loss:  0.14832676947116852\n",
      "Eval Loss:  0.44755202531814575\n",
      "[[2115  117]\n",
      " [ 230  950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      2232\n",
      "           1       0.89      0.81      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.90      0.88      0.88      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8983001172332943\n",
      "pre:  0.8903467666354264\n",
      "rec:  0.8050847457627118\n",
      "ma F1:  0.8848790108706104\n",
      "mi F1:  0.8983001172332943\n",
      "we F1:  0.8969983275174288\n",
      "update!  Acc:  0.9065064478311841\n",
      "Epoch:  3152.5995881557465  fold:  6  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.1720663607120514\n",
      "Loss:  0.17102330923080444\n",
      "Loss:  0.1541113257408142\n",
      "0 **********\n",
      "Epoch:  52.7240264415741  fold:  7  kers:  32\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.14686165750026703\n",
      "Loss:  0.14242877066135406\n",
      "Loss:  0.1145084947347641\n",
      "1 **********\n",
      "Epoch:  93.60970664024353  fold:  7  kers:  32\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.11058245599269867\n",
      "Loss:  0.11829443275928497\n",
      "Loss:  0.10378380119800568\n",
      "2 **********\n",
      "Epoch:  133.5898072719574  fold:  7  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.8645037412643433\n",
      "Eval Loss:  0.15057526528835297\n",
      "Eval Loss:  1.9303512573242188\n",
      "[[1665  462]\n",
      " [ 702  602]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      2127\n",
      "           1       0.57      0.46      0.51      1304\n",
      "\n",
      "    accuracy                           0.66      3431\n",
      "   macro avg       0.63      0.62      0.62      3431\n",
      "weighted avg       0.65      0.66      0.65      3431\n",
      "\n",
      "acc:  0.6607403089478286\n",
      "pre:  0.5657894736842105\n",
      "rec:  0.4616564417177914\n",
      "ma F1:  0.6247169649622921\n",
      "mi F1:  0.6607403089478286\n",
      "we F1:  0.6526070986406519\n",
      "update!  Acc:  0.6607403089478286\n",
      "Eval Loss:  0.46362829208374023\n",
      "Eval Loss:  0.420199990272522\n",
      "Eval Loss:  0.43146663904190063\n",
      "Eval Loss:  0.49285751581192017\n",
      "Eval Loss:  0.4033133089542389\n",
      "Eval Loss:  0.4382231533527374\n",
      "Eval Loss:  0.39036381244659424\n",
      "Eval Loss:  0.41538575291633606\n",
      "Eval Loss:  0.4279092252254486\n",
      "Eval Loss:  0.5249389410018921\n",
      "Eval Loss:  0.46860983967781067\n",
      "Eval Loss:  0.4735221564769745\n",
      "Eval Loss:  0.4279206097126007\n",
      "Eval Loss:  0.40343254804611206\n",
      "Eval Loss:  0.4283551871776581\n",
      "Eval Loss:  0.4274260997772217\n",
      "Eval Loss:  0.4076637625694275\n",
      "Eval Loss:  0.5674573183059692\n",
      "Eval Loss:  0.3848472237586975\n",
      "Eval Loss:  0.560078501701355\n",
      "Eval Loss:  0.37310996651649475\n",
      "Eval Loss:  0.45366784930229187\n",
      "Eval Loss:  0.3904819190502167\n",
      "Eval Loss:  0.4333534240722656\n",
      "Eval Loss:  0.40414971113204956\n",
      "Eval Loss:  0.5135087370872498\n",
      "Eval Loss:  0.3420844078063965\n",
      "Eval Loss:  0.3998759984970093\n",
      "[[15379  2658]\n",
      " [ 3143  8280]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84     18037\n",
      "           1       0.76      0.72      0.74     11423\n",
      "\n",
      "    accuracy                           0.80     29460\n",
      "   macro avg       0.79      0.79      0.79     29460\n",
      "weighted avg       0.80      0.80      0.80     29460\n",
      "\n",
      "acc:  0.8030889341479973\n",
      "pre:  0.7569939659901261\n",
      "rec:  0.7248533660159328\n",
      "ma F1:  0.7909500449922191\n",
      "mi F1:  0.8030889341479973\n",
      "we F1:  0.8022596115334668\n",
      "29460 461\n",
      "Loss:  0.10193797200918198\n",
      "Loss:  0.0936257466673851\n",
      "Loss:  0.10390904545783997\n",
      "3 **********\n",
      "Epoch:  213.41237831115723  fold:  7  kers:  32\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.11020489037036896\n",
      "Loss:  0.11543640494346619\n",
      "Loss:  0.08644414693117142\n",
      "4 **********\n",
      "Epoch:  253.55404806137085  fold:  7  kers:  32\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.09710953384637833\n",
      "Loss:  0.09252343326807022\n",
      "Loss:  0.07430627197027206\n",
      "5 **********\n",
      "Epoch:  293.8572850227356  fold:  7  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.6127277612686157\n",
      "Eval Loss:  0.20664826035499573\n",
      "Eval Loss:  1.8930660486221313\n",
      "[[1673  454]\n",
      " [ 592  712]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      2127\n",
      "           1       0.61      0.55      0.58      1304\n",
      "\n",
      "    accuracy                           0.70      3431\n",
      "   macro avg       0.67      0.67      0.67      3431\n",
      "weighted avg       0.69      0.70      0.69      3431\n",
      "\n",
      "acc:  0.6951326143981347\n",
      "pre:  0.6106346483704974\n",
      "rec:  0.5460122699386503\n",
      "ma F1:  0.6691789635922509\n",
      "mi F1:  0.6951326143981347\n",
      "we F1:  0.6914056593396414\n",
      "update!  Acc:  0.6951326143981347\n",
      "Eval Loss:  0.389477401971817\n",
      "Eval Loss:  0.3466188609600067\n",
      "Eval Loss:  0.37778493762016296\n",
      "Eval Loss:  0.4483199715614319\n",
      "Eval Loss:  0.30740514397621155\n",
      "Eval Loss:  0.3472186028957367\n",
      "Eval Loss:  0.2668345868587494\n",
      "Eval Loss:  0.32123348116874695\n",
      "Eval Loss:  0.36376121640205383\n",
      "Eval Loss:  0.4179620146751404\n",
      "Eval Loss:  0.4045495390892029\n",
      "Eval Loss:  0.3327130973339081\n",
      "Eval Loss:  0.3412376046180725\n",
      "Eval Loss:  0.280325710773468\n",
      "Eval Loss:  0.326588898897171\n",
      "Eval Loss:  0.31709980964660645\n",
      "Eval Loss:  0.35842806100845337\n",
      "Eval Loss:  0.39052194356918335\n",
      "Eval Loss:  0.28055503964424133\n",
      "Eval Loss:  0.42041653394699097\n",
      "Eval Loss:  0.22457636892795563\n",
      "Eval Loss:  0.3817559480667114\n",
      "Eval Loss:  0.28220415115356445\n",
      "Eval Loss:  0.31722426414489746\n",
      "Eval Loss:  0.23282988369464874\n",
      "Eval Loss:  0.4147334098815918\n",
      "Eval Loss:  0.251312255859375\n",
      "Eval Loss:  0.3679819405078888\n",
      "[[15875  2162]\n",
      " [ 2252  9171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88     18037\n",
      "           1       0.81      0.80      0.81     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.84      0.84      0.84     29460\n",
      "weighted avg       0.85      0.85      0.85     29460\n",
      "\n",
      "acc:  0.8501697216564834\n",
      "pre:  0.8092296832259772\n",
      "rec:  0.8028538912719951\n",
      "ma F1:  0.8419870483576031\n",
      "mi F1:  0.8501697216564834\n",
      "we F1:  0.8500598707321249\n",
      "29460 461\n",
      "Loss:  0.11291320621967316\n",
      "Loss:  0.07151365280151367\n",
      "Loss:  0.09986826777458191\n",
      "6 **********\n",
      "Epoch:  373.6150290966034  fold:  7  kers:  32\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.08496958017349243\n",
      "Loss:  0.10153607279062271\n",
      "Loss:  0.06269419938325882\n",
      "7 **********\n",
      "Epoch:  414.0319619178772  fold:  7  kers:  32\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.09700602293014526\n",
      "Loss:  0.09875364601612091\n",
      "Loss:  0.05292773246765137\n",
      "8 **********\n",
      "Epoch:  454.22150349617004  fold:  7  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.7080997228622437\n",
      "Eval Loss:  0.1400720775127411\n",
      "Eval Loss:  2.7851433753967285\n",
      "[[1938  189]\n",
      " [ 803  501]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80      2127\n",
      "           1       0.73      0.38      0.50      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.72      0.65      0.65      3431\n",
      "weighted avg       0.71      0.71      0.68      3431\n",
      "\n",
      "acc:  0.7108714660448848\n",
      "pre:  0.7260869565217392\n",
      "rec:  0.38420245398773006\n",
      "ma F1:  0.6493638681039009\n",
      "mi F1:  0.7108714660448848\n",
      "we F1:  0.6845905578084449\n",
      "update!  Acc:  0.7108714660448848\n",
      "Eval Loss:  0.421106219291687\n",
      "Eval Loss:  0.35857856273651123\n",
      "Eval Loss:  0.36186355352401733\n",
      "Eval Loss:  0.4886399507522583\n",
      "Eval Loss:  0.3403187096118927\n",
      "Eval Loss:  0.32349857687950134\n",
      "Eval Loss:  0.2770753502845764\n",
      "Eval Loss:  0.29969072341918945\n",
      "Eval Loss:  0.36806368827819824\n",
      "Eval Loss:  0.4487413763999939\n",
      "Eval Loss:  0.46452099084854126\n",
      "Eval Loss:  0.37084510922431946\n",
      "Eval Loss:  0.3491899073123932\n",
      "Eval Loss:  0.279883474111557\n",
      "Eval Loss:  0.31817808747291565\n",
      "Eval Loss:  0.29893437027931213\n",
      "Eval Loss:  0.35454389452934265\n",
      "Eval Loss:  0.40552589297294617\n",
      "Eval Loss:  0.2519109845161438\n",
      "Eval Loss:  0.4467264413833618\n",
      "Eval Loss:  0.22566905617713928\n",
      "Eval Loss:  0.3810979723930359\n",
      "Eval Loss:  0.2953072488307953\n",
      "Eval Loss:  0.3370142877101898\n",
      "Eval Loss:  0.24443680047988892\n",
      "Eval Loss:  0.429232656955719\n",
      "Eval Loss:  0.24473029375076294\n",
      "Eval Loss:  0.4044254720211029\n",
      "[[16789  1248]\n",
      " [ 2958  8465]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     18037\n",
      "           1       0.87      0.74      0.80     11423\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.86      0.84      0.84     29460\n",
      "weighted avg       0.86      0.86      0.85     29460\n",
      "\n",
      "acc:  0.8572301425661915\n",
      "pre:  0.8715124060537424\n",
      "rec:  0.7410487612711196\n",
      "ma F1:  0.844843034224741\n",
      "mi F1:  0.8572301425661915\n",
      "we F1:  0.8546854578876859\n",
      "29460 461\n",
      "Loss:  0.0955415666103363\n",
      "Loss:  0.08603362739086151\n",
      "Loss:  0.09197521209716797\n",
      "9 **********\n",
      "Epoch:  533.382842540741  fold:  7  kers:  32\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.07518765330314636\n",
      "Loss:  0.09200695902109146\n",
      "Loss:  0.07492442429065704\n",
      "10 **********\n",
      "Epoch:  573.9802932739258  fold:  7  kers:  32\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08886727690696716\n",
      "Loss:  0.08813054114580154\n",
      "Loss:  0.08313383162021637\n",
      "11 **********\n",
      "Epoch:  614.7183680534363  fold:  7  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.6123225092887878\n",
      "Eval Loss:  0.13664844632148743\n",
      "Eval Loss:  2.8070995807647705\n",
      "[[2000  127]\n",
      " [ 819  485]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81      2127\n",
      "           1       0.79      0.37      0.51      1304\n",
      "\n",
      "    accuracy                           0.72      3431\n",
      "   macro avg       0.75      0.66      0.66      3431\n",
      "weighted avg       0.74      0.72      0.69      3431\n",
      "\n",
      "acc:  0.7242786359661906\n",
      "pre:  0.7924836601307189\n",
      "rec:  0.37193251533742333\n",
      "ma F1:  0.6574986893945214\n",
      "mi F1:  0.7242786359661906\n",
      "we F1:  0.6937758484892302\n",
      "update!  Acc:  0.7242786359661906\n",
      "Eval Loss:  0.4091890752315521\n",
      "Eval Loss:  0.3528442084789276\n",
      "Eval Loss:  0.3273828327655792\n",
      "Eval Loss:  0.5005643963813782\n",
      "Eval Loss:  0.32824867963790894\n",
      "Eval Loss:  0.28982865810394287\n",
      "Eval Loss:  0.26666751503944397\n",
      "Eval Loss:  0.2700953781604767\n",
      "Eval Loss:  0.35431331396102905\n",
      "Eval Loss:  0.45397207140922546\n",
      "Eval Loss:  0.47288215160369873\n",
      "Eval Loss:  0.3298746347427368\n",
      "Eval Loss:  0.33120256662368774\n",
      "Eval Loss:  0.26658251881599426\n",
      "Eval Loss:  0.29147201776504517\n",
      "Eval Loss:  0.2722412645816803\n",
      "Eval Loss:  0.32236379384994507\n",
      "Eval Loss:  0.36442506313323975\n",
      "Eval Loss:  0.2340676486492157\n",
      "Eval Loss:  0.41659867763519287\n",
      "Eval Loss:  0.22257111966609955\n",
      "Eval Loss:  0.3501482903957367\n",
      "Eval Loss:  0.26450178027153015\n",
      "Eval Loss:  0.3093191683292389\n",
      "Eval Loss:  0.22979827225208282\n",
      "Eval Loss:  0.3996763825416565\n",
      "Eval Loss:  0.2517850995063782\n",
      "Eval Loss:  0.37536105513572693\n",
      "[[17075   962]\n",
      " [ 2997  8426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     18037\n",
      "           1       0.90      0.74      0.81     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.87      0.84      0.85     29460\n",
      "weighted avg       0.87      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8656143923964698\n",
      "pre:  0.8975287601193013\n",
      "rec:  0.7376345968659722\n",
      "ma F1:  0.8529389229886415\n",
      "mi F1:  0.8656143923964698\n",
      "we F1:  0.8626320152147227\n",
      "29460 461\n",
      "Loss:  0.051760513335466385\n",
      "Loss:  0.09652264416217804\n",
      "Loss:  0.07306089997291565\n",
      "12 **********\n",
      "Epoch:  694.4741168022156  fold:  7  kers:  32\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.07846938073635101\n",
      "Loss:  0.05360804870724678\n",
      "Loss:  0.09094186127185822\n",
      "13 **********\n",
      "Epoch:  734.9050133228302  fold:  7  kers:  32\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.03888869285583496\n",
      "Loss:  0.08230270445346832\n",
      "Loss:  0.06494441628456116\n",
      "14 **********\n",
      "Epoch:  775.7408261299133  fold:  7  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.5460065603256226\n",
      "Eval Loss:  0.18429367244243622\n",
      "Eval Loss:  2.297893524169922\n",
      "[[1952  175]\n",
      " [ 719  585]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81      2127\n",
      "           1       0.77      0.45      0.57      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.68      0.69      3431\n",
      "weighted avg       0.75      0.74      0.72      3431\n",
      "\n",
      "acc:  0.7394345671815797\n",
      "pre:  0.7697368421052632\n",
      "rec:  0.4486196319018405\n",
      "ma F1:  0.6902664143005321\n",
      "mi F1:  0.7394345671815797\n",
      "we F1:  0.7198680162179443\n",
      "update!  Acc:  0.7394345671815797\n",
      "Eval Loss:  0.3539968430995941\n",
      "Eval Loss:  0.3196841776371002\n",
      "Eval Loss:  0.278209388256073\n",
      "Eval Loss:  0.483704537153244\n",
      "Eval Loss:  0.2846698462963104\n",
      "Eval Loss:  0.26087135076522827\n",
      "Eval Loss:  0.22719384729862213\n",
      "Eval Loss:  0.247500941157341\n",
      "Eval Loss:  0.329231858253479\n",
      "Eval Loss:  0.4134235084056854\n",
      "Eval Loss:  0.42419150471687317\n",
      "Eval Loss:  0.2828589379787445\n",
      "Eval Loss:  0.3030736744403839\n",
      "Eval Loss:  0.24774004518985748\n",
      "Eval Loss:  0.26355117559432983\n",
      "Eval Loss:  0.2566787600517273\n",
      "Eval Loss:  0.28139305114746094\n",
      "Eval Loss:  0.3428126573562622\n",
      "Eval Loss:  0.21672527492046356\n",
      "Eval Loss:  0.38096362352371216\n",
      "Eval Loss:  0.20271003246307373\n",
      "Eval Loss:  0.31927791237831116\n",
      "Eval Loss:  0.22280235588550568\n",
      "Eval Loss:  0.255717933177948\n",
      "Eval Loss:  0.18784014880657196\n",
      "Eval Loss:  0.3639640212059021\n",
      "Eval Loss:  0.2535284161567688\n",
      "Eval Loss:  0.34471338987350464\n",
      "[[17022  1015]\n",
      " [ 2682  8741]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     18037\n",
      "           1       0.90      0.77      0.83     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.85      0.86     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8745078071961983\n",
      "pre:  0.8959614596145962\n",
      "rec:  0.7652105401383175\n",
      "ma F1:  0.8637415828897814\n",
      "mi F1:  0.8745078071961984\n",
      "we F1:  0.8723405211294434\n",
      "29460 461\n",
      "Loss:  0.09338083863258362\n",
      "Loss:  0.09318209439516068\n",
      "Loss:  0.09380295127630234\n",
      "15 **********\n",
      "Epoch:  855.411801815033  fold:  7  kers:  32\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.057007476687431335\n",
      "Loss:  0.07857511937618256\n",
      "Loss:  0.05893078073859215\n",
      "16 **********\n",
      "Epoch:  896.2815256118774  fold:  7  kers:  32\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.040867194533348083\n",
      "Loss:  0.07494645565748215\n",
      "Loss:  0.06887936592102051\n",
      "17 **********\n",
      "Epoch:  937.1801702976227  fold:  7  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.5754263997077942\n",
      "Eval Loss:  0.16974744200706482\n",
      "Eval Loss:  2.2553884983062744\n",
      "[[1952  175]\n",
      " [ 694  610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82      2127\n",
      "           1       0.78      0.47      0.58      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.69      0.70      3431\n",
      "weighted avg       0.75      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7467210725735937\n",
      "pre:  0.7770700636942676\n",
      "rec:  0.4677914110429448\n",
      "ma F1:  0.7009728510168245\n",
      "mi F1:  0.7467210725735937\n",
      "we F1:  0.7290285785438148\n",
      "update!  Acc:  0.7467210725735937\n",
      "Eval Loss:  0.3157569468021393\n",
      "Eval Loss:  0.29346024990081787\n",
      "Eval Loss:  0.30007195472717285\n",
      "Eval Loss:  0.4491029381752014\n",
      "Eval Loss:  0.26663297414779663\n",
      "Eval Loss:  0.24709658324718475\n",
      "Eval Loss:  0.20950546860694885\n",
      "Eval Loss:  0.24906456470489502\n",
      "Eval Loss:  0.32392024993896484\n",
      "Eval Loss:  0.39214086532592773\n",
      "Eval Loss:  0.4069780707359314\n",
      "Eval Loss:  0.27289652824401855\n",
      "Eval Loss:  0.2581816017627716\n",
      "Eval Loss:  0.23280686140060425\n",
      "Eval Loss:  0.2503945827484131\n",
      "Eval Loss:  0.2559860348701477\n",
      "Eval Loss:  0.28680452704429626\n",
      "Eval Loss:  0.32184454798698425\n",
      "Eval Loss:  0.2141016125679016\n",
      "Eval Loss:  0.3548521399497986\n",
      "Eval Loss:  0.20185552537441254\n",
      "Eval Loss:  0.3194921016693115\n",
      "Eval Loss:  0.21479018032550812\n",
      "Eval Loss:  0.24723370373249054\n",
      "Eval Loss:  0.17097675800323486\n",
      "Eval Loss:  0.33882468938827515\n",
      "Eval Loss:  0.2064051330089569\n",
      "Eval Loss:  0.3412282168865204\n",
      "[[16825  1212]\n",
      " [ 2264  9159]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     18037\n",
      "           1       0.88      0.80      0.84     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.88      0.87      0.87     29460\n",
      "weighted avg       0.88      0.88      0.88     29460\n",
      "\n",
      "acc:  0.882009504412763\n",
      "pre:  0.8831356667630894\n",
      "rec:  0.8018033791473343\n",
      "ma F1:  0.8734397268757965\n",
      "mi F1:  0.882009504412763\n",
      "we F1:  0.8808334796320575\n",
      "29460 461\n",
      "Loss:  0.07850706577301025\n",
      "Loss:  0.07249048352241516\n",
      "Loss:  0.07661183178424835\n",
      "18 **********\n",
      "Epoch:  1017.3956904411316  fold:  7  kers:  32\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.06606978178024292\n",
      "Loss:  0.04842256009578705\n",
      "Loss:  0.06875825673341751\n",
      "19 **********\n",
      "Epoch:  1058.0410130023956  fold:  7  kers:  32\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.0796513557434082\n",
      "Loss:  0.08667992055416107\n",
      "Loss:  0.0740729570388794\n",
      "20 **********\n",
      "Epoch:  1099.1481008529663  fold:  7  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.6728109121322632\n",
      "Eval Loss:  0.15237444639205933\n",
      "Eval Loss:  2.426260232925415\n",
      "[[1993  134]\n",
      " [ 726  578]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.94      0.82      2127\n",
      "           1       0.81      0.44      0.57      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.69      0.70      3431\n",
      "weighted avg       0.76      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7493442145147188\n",
      "pre:  0.8117977528089888\n",
      "rec:  0.4432515337423313\n",
      "ma F1:  0.6979733735563285\n",
      "mi F1:  0.7493442145147187\n",
      "we F1:  0.727851961619053\n",
      "update!  Acc:  0.7493442145147188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3364470303058624\n",
      "Eval Loss:  0.31912335753440857\n",
      "Eval Loss:  0.3060362935066223\n",
      "Eval Loss:  0.4336065351963043\n",
      "Eval Loss:  0.27703410387039185\n",
      "Eval Loss:  0.24121014773845673\n",
      "Eval Loss:  0.22894063591957092\n",
      "Eval Loss:  0.26537609100341797\n",
      "Eval Loss:  0.34022897481918335\n",
      "Eval Loss:  0.4124031662940979\n",
      "Eval Loss:  0.4449591040611267\n",
      "Eval Loss:  0.28774985671043396\n",
      "Eval Loss:  0.26391032338142395\n",
      "Eval Loss:  0.24536877870559692\n",
      "Eval Loss:  0.23060698807239532\n",
      "Eval Loss:  0.2628479599952698\n",
      "Eval Loss:  0.318292498588562\n",
      "Eval Loss:  0.3174281418323517\n",
      "Eval Loss:  0.23141787946224213\n",
      "Eval Loss:  0.3612464964389801\n",
      "Eval Loss:  0.22570167481899261\n",
      "Eval Loss:  0.32233110070228577\n",
      "Eval Loss:  0.26089149713516235\n",
      "Eval Loss:  0.25660955905914307\n",
      "Eval Loss:  0.19513483345508575\n",
      "Eval Loss:  0.33832883834838867\n",
      "Eval Loss:  0.20378604531288147\n",
      "Eval Loss:  0.3387633264064789\n",
      "[[16956  1081]\n",
      " [ 2366  9057]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18037\n",
      "           1       0.89      0.79      0.84     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.87      0.87     29460\n",
      "weighted avg       0.88      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8829938900203665\n",
      "pre:  0.8933714736634445\n",
      "rec:  0.7928740260877177\n",
      "ma F1:  0.8739305426360539\n",
      "mi F1:  0.8829938900203665\n",
      "we F1:  0.8815194753616956\n",
      "29460 461\n",
      "Loss:  0.062394555658102036\n",
      "Loss:  0.09322988241910934\n",
      "Loss:  0.05774911120533943\n",
      "21 **********\n",
      "Epoch:  1179.108303785324  fold:  7  kers:  32\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.09128663688898087\n",
      "Loss:  0.06252317130565643\n",
      "Loss:  0.055703651160001755\n",
      "22 **********\n",
      "Epoch:  1219.4933223724365  fold:  7  kers:  32\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.08391272276639938\n",
      "Loss:  0.0534614734351635\n",
      "Loss:  0.07451527565717697\n",
      "23 **********\n",
      "Epoch:  1260.8666985034943  fold:  7  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.6106612682342529\n",
      "Eval Loss:  0.14306217432022095\n",
      "Eval Loss:  2.4239003658294678\n",
      "[[2021  106]\n",
      " [ 734  570]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.83      2127\n",
      "           1       0.84      0.44      0.58      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.79      0.69      0.70      3431\n",
      "weighted avg       0.78      0.76      0.73      3431\n",
      "\n",
      "acc:  0.7551734188283299\n",
      "pre:  0.8431952662721893\n",
      "rec:  0.4371165644171779\n",
      "ma F1:  0.7018484724342979\n",
      "mi F1:  0.7551734188283299\n",
      "we F1:  0.7320941174255373\n",
      "update!  Acc:  0.7551734188283299\n",
      "Eval Loss:  0.3125801682472229\n",
      "Eval Loss:  0.2945495545864105\n",
      "Eval Loss:  0.2887398600578308\n",
      "Eval Loss:  0.42204973101615906\n",
      "Eval Loss:  0.270006000995636\n",
      "Eval Loss:  0.23171423375606537\n",
      "Eval Loss:  0.2098015546798706\n",
      "Eval Loss:  0.2457813322544098\n",
      "Eval Loss:  0.31925907731056213\n",
      "Eval Loss:  0.41452065110206604\n",
      "Eval Loss:  0.4459683895111084\n",
      "Eval Loss:  0.2844987213611603\n",
      "Eval Loss:  0.25071069598197937\n",
      "Eval Loss:  0.2306319773197174\n",
      "Eval Loss:  0.2181931436061859\n",
      "Eval Loss:  0.2600400745868683\n",
      "Eval Loss:  0.33395129442214966\n",
      "Eval Loss:  0.3116248846054077\n",
      "Eval Loss:  0.2547515630722046\n",
      "Eval Loss:  0.34121400117874146\n",
      "Eval Loss:  0.2094482183456421\n",
      "Eval Loss:  0.27758070826530457\n",
      "Eval Loss:  0.2316926270723343\n",
      "Eval Loss:  0.23396609723567963\n",
      "Eval Loss:  0.19523988664150238\n",
      "Eval Loss:  0.34610438346862793\n",
      "Eval Loss:  0.20257724821567535\n",
      "Eval Loss:  0.3151648938655853\n",
      "[[17052   985]\n",
      " [ 2357  9066]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18037\n",
      "           1       0.90      0.79      0.84     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8865580448065173\n",
      "pre:  0.9019998010148244\n",
      "rec:  0.7936619101812133\n",
      "ma F1:  0.8775607089352563\n",
      "mi F1:  0.8865580448065173\n",
      "we F1:  0.8850122966453139\n",
      "29460 461\n",
      "Loss:  0.08018296957015991\n",
      "Loss:  0.10549982637166977\n",
      "Loss:  0.090672567486763\n",
      "24 **********\n",
      "Epoch:  1340.046986579895  fold:  7  kers:  32\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.055635400116443634\n",
      "Loss:  0.08398248255252838\n",
      "Loss:  0.08887476474046707\n",
      "25 **********\n",
      "Epoch:  1380.430010318756  fold:  7  kers:  32\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.06514745950698853\n",
      "Loss:  0.06988474726676941\n",
      "Loss:  0.07103781402111053\n",
      "26 **********\n",
      "Epoch:  1420.3951516151428  fold:  7  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.5436394810676575\n",
      "Eval Loss:  0.1966577172279358\n",
      "Eval Loss:  2.108684539794922\n",
      "[[2003  124]\n",
      " [ 671  633]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83      2127\n",
      "           1       0.84      0.49      0.61      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.71      0.72      3431\n",
      "weighted avg       0.78      0.77      0.75      3431\n",
      "\n",
      "acc:  0.7682891285339551\n",
      "pre:  0.8361955085865258\n",
      "rec:  0.4854294478527607\n",
      "ma F1:  0.7243372089815105\n",
      "mi F1:  0.7682891285339551\n",
      "we F1:  0.7507404424060813\n",
      "update!  Acc:  0.7682891285339551\n",
      "Eval Loss:  0.30720818042755127\n",
      "Eval Loss:  0.29080915451049805\n",
      "Eval Loss:  0.28911685943603516\n",
      "Eval Loss:  0.4149080216884613\n",
      "Eval Loss:  0.2658064365386963\n",
      "Eval Loss:  0.222867950797081\n",
      "Eval Loss:  0.19787275791168213\n",
      "Eval Loss:  0.23864151537418365\n",
      "Eval Loss:  0.3243047297000885\n",
      "Eval Loss:  0.40189114212989807\n",
      "Eval Loss:  0.444580614566803\n",
      "Eval Loss:  0.2782440781593323\n",
      "Eval Loss:  0.24000784754753113\n",
      "Eval Loss:  0.22845521569252014\n",
      "Eval Loss:  0.20525574684143066\n",
      "Eval Loss:  0.2516762614250183\n",
      "Eval Loss:  0.33122026920318604\n",
      "Eval Loss:  0.3125070035457611\n",
      "Eval Loss:  0.262309193611145\n",
      "Eval Loss:  0.33248370885849\n",
      "Eval Loss:  0.2044239491224289\n",
      "Eval Loss:  0.3020756244659424\n",
      "Eval Loss:  0.24277588725090027\n",
      "Eval Loss:  0.22723254561424255\n",
      "Eval Loss:  0.17479614913463593\n",
      "Eval Loss:  0.33358022570610046\n",
      "Eval Loss:  0.2054586559534073\n",
      "Eval Loss:  0.28480786085128784\n",
      "[[17043   994]\n",
      " [ 2249  9174]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18037\n",
      "           1       0.90      0.80      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8899185336048879\n",
      "pre:  0.9022423288749016\n",
      "rec:  0.8031165193031603\n",
      "ma F1:  0.881461185948037\n",
      "mi F1:  0.8899185336048879\n",
      "we F1:  0.8885697000416211\n",
      "29460 461\n",
      "Loss:  0.06842809915542603\n",
      "Loss:  0.044926900416612625\n",
      "Loss:  0.07695377618074417\n",
      "27 **********\n",
      "Epoch:  1498.1462607383728  fold:  7  kers:  32\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.10054336488246918\n",
      "Loss:  0.07076738774776459\n",
      "Loss:  0.09369418770074844\n",
      "28 **********\n",
      "Epoch:  1538.130351781845  fold:  7  kers:  32\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.0928041934967041\n",
      "Loss:  0.03546033799648285\n",
      "Loss:  0.07091280072927475\n",
      "29 **********\n",
      "Epoch:  1578.898345708847  fold:  7  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.5950254797935486\n",
      "Eval Loss:  0.13908199965953827\n",
      "Eval Loss:  2.272526502609253\n",
      "[[2036   91]\n",
      " [ 721  583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83      2127\n",
      "           1       0.86      0.45      0.59      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.80      0.70      0.71      3431\n",
      "weighted avg       0.79      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7633343048673856\n",
      "pre:  0.8649851632047477\n",
      "rec:  0.4470858895705521\n",
      "ma F1:  0.7116135806732369\n",
      "mi F1:  0.7633343048673855\n",
      "we F1:  0.7409089392498264\n",
      "Eval Loss:  0.33223965764045715\n",
      "Eval Loss:  0.2833407521247864\n",
      "Eval Loss:  0.28817135095596313\n",
      "Eval Loss:  0.39817607402801514\n",
      "Eval Loss:  0.267667293548584\n",
      "Eval Loss:  0.22300487756729126\n",
      "Eval Loss:  0.2043735235929489\n",
      "Eval Loss:  0.23628810048103333\n",
      "Eval Loss:  0.31263476610183716\n",
      "Eval Loss:  0.40435755252838135\n",
      "Eval Loss:  0.43922168016433716\n",
      "Eval Loss:  0.3103942275047302\n",
      "Eval Loss:  0.23950481414794922\n",
      "Eval Loss:  0.22107857465744019\n",
      "Eval Loss:  0.20919360220432281\n",
      "Eval Loss:  0.2536311447620392\n",
      "Eval Loss:  0.3496418297290802\n",
      "Eval Loss:  0.32672208547592163\n",
      "Eval Loss:  0.26222842931747437\n",
      "Eval Loss:  0.326204776763916\n",
      "Eval Loss:  0.21716398000717163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2866368591785431\n",
      "Eval Loss:  0.24318505823612213\n",
      "Eval Loss:  0.2298915982246399\n",
      "Eval Loss:  0.17645077407360077\n",
      "Eval Loss:  0.34142524003982544\n",
      "Eval Loss:  0.22523921728134155\n",
      "Eval Loss:  0.29044026136398315\n",
      "[[17155   882]\n",
      " [ 2404  9019]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18037\n",
      "           1       0.91      0.79      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.888458927359131\n",
      "pre:  0.910918089081911\n",
      "rec:  0.7895474043596253\n",
      "ma F1:  0.8792492083144658\n",
      "mi F1:  0.888458927359131\n",
      "we F1:  0.8867360669380419\n",
      "29460 461\n",
      "Loss:  0.07641526311635971\n",
      "Loss:  0.0567915216088295\n",
      "Loss:  0.0847930908203125\n",
      "30 **********\n",
      "Epoch:  1657.409423828125  fold:  7  kers:  32\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.04670790955424309\n",
      "Loss:  0.07037961483001709\n",
      "Loss:  0.0852571427822113\n",
      "31 **********\n",
      "Epoch:  1698.3988270759583  fold:  7  kers:  32\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.08461977541446686\n",
      "Loss:  0.049756795167922974\n",
      "Loss:  0.047901395708322525\n",
      "32 **********\n",
      "Epoch:  1739.2206771373749  fold:  7  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.5710316300392151\n",
      "Eval Loss:  0.1730719953775406\n",
      "Eval Loss:  2.003497362136841\n",
      "[[2003  124]\n",
      " [ 665  639]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.84      2127\n",
      "           1       0.84      0.49      0.62      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.72      0.73      3431\n",
      "weighted avg       0.78      0.77      0.75      3431\n",
      "\n",
      "acc:  0.7700378898280384\n",
      "pre:  0.8374836173001311\n",
      "rec:  0.49003067484662577\n",
      "ma F1:  0.7268704852508736\n",
      "mi F1:  0.7700378898280384\n",
      "we F1:  0.7529165072208198\n",
      "update!  Acc:  0.7700378898280384\n",
      "Eval Loss:  0.29082196950912476\n",
      "Eval Loss:  0.27421194314956665\n",
      "Eval Loss:  0.2820113003253937\n",
      "Eval Loss:  0.3940640091896057\n",
      "Eval Loss:  0.2509555518627167\n",
      "Eval Loss:  0.22305573523044586\n",
      "Eval Loss:  0.19185656309127808\n",
      "Eval Loss:  0.22709643840789795\n",
      "Eval Loss:  0.31925487518310547\n",
      "Eval Loss:  0.3908580541610718\n",
      "Eval Loss:  0.43818119168281555\n",
      "Eval Loss:  0.2887815535068512\n",
      "Eval Loss:  0.21034649014472961\n",
      "Eval Loss:  0.21733137965202332\n",
      "Eval Loss:  0.19053971767425537\n",
      "Eval Loss:  0.26356664299964905\n",
      "Eval Loss:  0.33906373381614685\n",
      "Eval Loss:  0.3096078336238861\n",
      "Eval Loss:  0.27433812618255615\n",
      "Eval Loss:  0.3197731375694275\n",
      "Eval Loss:  0.2091224193572998\n",
      "Eval Loss:  0.3034977614879608\n",
      "Eval Loss:  0.22897449135780334\n",
      "Eval Loss:  0.23360736668109894\n",
      "Eval Loss:  0.18202953040599823\n",
      "Eval Loss:  0.33878666162490845\n",
      "Eval Loss:  0.18107803165912628\n",
      "Eval Loss:  0.26772403717041016\n",
      "[[17136   901]\n",
      " [ 2214  9209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18037\n",
      "           1       0.91      0.81      0.86     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8942634080108622\n",
      "pre:  0.9108803165182987\n",
      "rec:  0.8061805130000875\n",
      "ma F1:  0.8860102935842943\n",
      "mi F1:  0.8942634080108622\n",
      "we F1:  0.8928963915806764\n",
      "29460 461\n",
      "Loss:  0.037776537239551544\n",
      "Loss:  0.06378930807113647\n",
      "Loss:  0.07457151263952255\n",
      "33 **********\n",
      "Epoch:  1819.4760909080505  fold:  7  kers:  32\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.05919582024216652\n",
      "Loss:  0.05494450405240059\n",
      "Loss:  0.08396546542644501\n",
      "34 **********\n",
      "Epoch:  1859.5020689964294  fold:  7  kers:  32\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.07151126116514206\n",
      "Loss:  0.05004322528839111\n",
      "Loss:  0.0780840665102005\n",
      "35 **********\n",
      "Epoch:  1899.4672102928162  fold:  7  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.5401545166969299\n",
      "Eval Loss:  0.12568899989128113\n",
      "Eval Loss:  2.813316822052002\n",
      "[[2035   92]\n",
      " [ 797  507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      2127\n",
      "           1       0.85      0.39      0.53      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.78      0.67      0.68      3431\n",
      "weighted avg       0.77      0.74      0.71      3431\n",
      "\n",
      "acc:  0.7408918682599825\n",
      "pre:  0.8464106844741235\n",
      "rec:  0.38880368098159507\n",
      "ma F1:  0.6767864327739699\n",
      "mi F1:  0.7408918682599825\n",
      "we F1:  0.7113144258400618\n",
      "Eval Loss:  0.36163195967674255\n",
      "Eval Loss:  0.28001970052719116\n",
      "Eval Loss:  0.34380778670310974\n",
      "Eval Loss:  0.41450443863868713\n",
      "Eval Loss:  0.29917213320732117\n",
      "Eval Loss:  0.22969956696033478\n",
      "Eval Loss:  0.2393592745065689\n",
      "Eval Loss:  0.2383381724357605\n",
      "Eval Loss:  0.31594231724739075\n",
      "Eval Loss:  0.43055206537246704\n",
      "Eval Loss:  0.457205593585968\n",
      "Eval Loss:  0.33723580837249756\n",
      "Eval Loss:  0.2674844563007355\n",
      "Eval Loss:  0.21847674250602722\n",
      "Eval Loss:  0.21309921145439148\n",
      "Eval Loss:  0.2753520905971527\n",
      "Eval Loss:  0.39087116718292236\n",
      "Eval Loss:  0.3496119976043701\n",
      "Eval Loss:  0.29127806425094604\n",
      "Eval Loss:  0.35263872146606445\n",
      "Eval Loss:  0.21973568201065063\n",
      "Eval Loss:  0.34246939420700073\n",
      "Eval Loss:  0.300962895154953\n",
      "Eval Loss:  0.24160446226596832\n",
      "Eval Loss:  0.23001299798488617\n",
      "Eval Loss:  0.3828493356704712\n",
      "Eval Loss:  0.20616687834262848\n",
      "Eval Loss:  0.27146345376968384\n",
      "[[17162   875]\n",
      " [ 2543  8880]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18037\n",
      "           1       0.91      0.78      0.84     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.86      0.87     29460\n",
      "weighted avg       0.89      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8839782756279702\n",
      "pre:  0.9103024090210149\n",
      "rec:  0.7773789722489713\n",
      "ma F1:  0.8740219311576796\n",
      "mi F1:  0.8839782756279702\n",
      "we F1:  0.8819730616003868\n",
      "29460 461\n",
      "Loss:  0.09889716655015945\n",
      "Loss:  0.09947055578231812\n",
      "Loss:  0.06513398885726929\n",
      "36 **********\n",
      "Epoch:  1978.1219036579132  fold:  7  kers:  32\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.07211577147245407\n",
      "Loss:  0.06946134567260742\n",
      "Loss:  0.059409406036138535\n",
      "37 **********\n",
      "Epoch:  2018.9846448898315  fold:  7  kers:  32\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.06266346573829651\n",
      "Loss:  0.03416138514876366\n",
      "Loss:  0.05035249516367912\n",
      "38 **********\n",
      "Epoch:  2059.4494507312775  fold:  7  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.5783230662345886\n",
      "Eval Loss:  0.14125871658325195\n",
      "Eval Loss:  2.543848991394043\n",
      "[[2020  107]\n",
      " [ 721  583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.95      0.83      2127\n",
      "           1       0.84      0.45      0.58      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.79      0.70      0.71      3431\n",
      "weighted avg       0.78      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7586709414164966\n",
      "pre:  0.8449275362318841\n",
      "rec:  0.4470858895705521\n",
      "ma F1:  0.7073319382964011\n",
      "mi F1:  0.7586709414164966\n",
      "we F1:  0.7367348607514037\n",
      "Eval Loss:  0.3145730793476105\n",
      "Eval Loss:  0.270817369222641\n",
      "Eval Loss:  0.3002902567386627\n",
      "Eval Loss:  0.40258318185806274\n",
      "Eval Loss:  0.25462859869003296\n",
      "Eval Loss:  0.22051793336868286\n",
      "Eval Loss:  0.2085607796907425\n",
      "Eval Loss:  0.21951381862163544\n",
      "Eval Loss:  0.33048102259635925\n",
      "Eval Loss:  0.4071909487247467\n",
      "Eval Loss:  0.44590672850608826\n",
      "Eval Loss:  0.30945703387260437\n",
      "Eval Loss:  0.2229650914669037\n",
      "Eval Loss:  0.2232830822467804\n",
      "Eval Loss:  0.2003657966852188\n",
      "Eval Loss:  0.2624400854110718\n",
      "Eval Loss:  0.3581327497959137\n",
      "Eval Loss:  0.3220651149749756\n",
      "Eval Loss:  0.2789393365383148\n",
      "Eval Loss:  0.3486798107624054\n",
      "Eval Loss:  0.19722725450992584\n",
      "Eval Loss:  0.3175960183143616\n",
      "Eval Loss:  0.2580873370170593\n",
      "Eval Loss:  0.22760728001594543\n",
      "Eval Loss:  0.2041306048631668\n",
      "Eval Loss:  0.34852707386016846\n",
      "Eval Loss:  0.1874113380908966\n",
      "Eval Loss:  0.2541474401950836\n",
      "[[17164   873]\n",
      " [ 2302  9121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     18037\n",
      "           1       0.91      0.80      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.88      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8922267481330618\n",
      "pre:  0.9126475885531319\n",
      "rec:  0.7984767574192418\n",
      "ma F1:  0.8835466931147166\n",
      "mi F1:  0.8922267481330619\n",
      "we F1:  0.8906845625529032\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07401853054761887\n",
      "Loss:  0.082636259496212\n",
      "Loss:  0.04331057891249657\n",
      "39 **********\n",
      "Epoch:  2137.495770215988  fold:  7  kers:  32\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.05305124819278717\n",
      "Loss:  0.07634451240301132\n",
      "Loss:  0.043196022510528564\n",
      "40 **********\n",
      "Epoch:  2177.7770664691925  fold:  7  kers:  32\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.06504262238740921\n",
      "Loss:  0.07074037194252014\n",
      "Loss:  0.07484444230794907\n",
      "41 **********\n",
      "Epoch:  2218.186021089554  fold:  7  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.5484554171562195\n",
      "Eval Loss:  0.21869656443595886\n",
      "Eval Loss:  2.126612901687622\n",
      "[[1983  144]\n",
      " [ 663  641]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      2127\n",
      "           1       0.82      0.49      0.61      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.71      0.72      3431\n",
      "weighted avg       0.77      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7647916059457884\n",
      "pre:  0.8165605095541402\n",
      "rec:  0.4915644171779141\n",
      "ma F1:  0.722307354166372\n",
      "mi F1:  0.7647916059457883\n",
      "we F1:  0.7483614072322884\n",
      "Eval Loss:  0.2893759310245514\n",
      "Eval Loss:  0.2553389370441437\n",
      "Eval Loss:  0.2886001169681549\n",
      "Eval Loss:  0.3810088038444519\n",
      "Eval Loss:  0.22136172652244568\n",
      "Eval Loss:  0.20576898753643036\n",
      "Eval Loss:  0.19884292781352997\n",
      "Eval Loss:  0.21612165868282318\n",
      "Eval Loss:  0.31417566537857056\n",
      "Eval Loss:  0.39723438024520874\n",
      "Eval Loss:  0.4186099171638489\n",
      "Eval Loss:  0.25986388325691223\n",
      "Eval Loss:  0.21784436702728271\n",
      "Eval Loss:  0.2060273140668869\n",
      "Eval Loss:  0.19609759747982025\n",
      "Eval Loss:  0.23532429337501526\n",
      "Eval Loss:  0.3101694583892822\n",
      "Eval Loss:  0.27000856399536133\n",
      "Eval Loss:  0.2416309118270874\n",
      "Eval Loss:  0.30744004249572754\n",
      "Eval Loss:  0.20124883949756622\n",
      "Eval Loss:  0.30388250946998596\n",
      "Eval Loss:  0.23773999512195587\n",
      "Eval Loss:  0.21932938694953918\n",
      "Eval Loss:  0.16720496118068695\n",
      "Eval Loss:  0.30283933877944946\n",
      "Eval Loss:  0.17944055795669556\n",
      "Eval Loss:  0.24979948997497559\n",
      "[[17032  1005]\n",
      " [ 1982  9441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18037\n",
      "           1       0.90      0.83      0.86     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.8986082824168364\n",
      "pre:  0.9037909247558874\n",
      "rec:  0.8264904140768625\n",
      "ma F1:  0.8913976790940039\n",
      "mi F1:  0.8986082824168364\n",
      "we F1:  0.8976802413884596\n",
      "29460 461\n",
      "Loss:  0.07754417508840561\n",
      "Loss:  0.07317964732646942\n",
      "Loss:  0.0538775734603405\n",
      "42 **********\n",
      "Epoch:  2295.906212568283  fold:  7  kers:  32\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.07799601554870605\n",
      "Loss:  0.094700388610363\n",
      "Loss:  0.07416606694459915\n",
      "43 **********\n",
      "Epoch:  2337.1100418567657  fold:  7  kers:  32\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.06044026091694832\n",
      "Loss:  0.06443193554878235\n",
      "Loss:  0.0631580725312233\n",
      "44 **********\n",
      "Epoch:  2378.12637257576  fold:  7  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.5362343192100525\n",
      "Eval Loss:  0.21731533110141754\n",
      "Eval Loss:  2.108513355255127\n",
      "[[1998  129]\n",
      " [ 670  634]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83      2127\n",
      "           1       0.83      0.49      0.61      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.71      0.72      3431\n",
      "weighted avg       0.78      0.77      0.75      3431\n",
      "\n",
      "acc:  0.7671232876712328\n",
      "pre:  0.8309305373525557\n",
      "rec:  0.48619631901840493\n",
      "ma F1:  0.7234087677001877\n",
      "mi F1:  0.7671232876712328\n",
      "we F1:  0.749784904017028\n",
      "Eval Loss:  0.24791929125785828\n",
      "Eval Loss:  0.2275049388408661\n",
      "Eval Loss:  0.2605483829975128\n",
      "Eval Loss:  0.366443932056427\n",
      "Eval Loss:  0.18883918225765228\n",
      "Eval Loss:  0.18190787732601166\n",
      "Eval Loss:  0.17909793555736542\n",
      "Eval Loss:  0.19840125739574432\n",
      "Eval Loss:  0.3080965578556061\n",
      "Eval Loss:  0.3710062801837921\n",
      "Eval Loss:  0.4020138680934906\n",
      "Eval Loss:  0.24872243404388428\n",
      "Eval Loss:  0.19197732210159302\n",
      "Eval Loss:  0.21058250963687897\n",
      "Eval Loss:  0.17786331474781036\n",
      "Eval Loss:  0.2307741343975067\n",
      "Eval Loss:  0.2947966754436493\n",
      "Eval Loss:  0.2757992148399353\n",
      "Eval Loss:  0.24164748191833496\n",
      "Eval Loss:  0.3126557767391205\n",
      "Eval Loss:  0.2004917562007904\n",
      "Eval Loss:  0.279458612203598\n",
      "Eval Loss:  0.21661117672920227\n",
      "Eval Loss:  0.20143425464630127\n",
      "Eval Loss:  0.16756227612495422\n",
      "Eval Loss:  0.2974937856197357\n",
      "Eval Loss:  0.16855457425117493\n",
      "Eval Loss:  0.2531389594078064\n",
      "[[17061   976]\n",
      " [ 1930  9493]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18037\n",
      "           1       0.91      0.83      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.901357773251867\n",
      "pre:  0.9067723755850606\n",
      "rec:  0.8310426332837259\n",
      "ma F1:  0.894388148120895\n",
      "mi F1:  0.901357773251867\n",
      "we F1:  0.9004792026420694\n",
      "29460 461\n",
      "Loss:  0.05207325145602226\n",
      "Loss:  0.06353113800287247\n",
      "Loss:  0.06133563071489334\n",
      "45 **********\n",
      "Epoch:  2457.4113812446594  fold:  7  kers:  32\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.05843085050582886\n",
      "Loss:  0.07216384261846542\n",
      "Loss:  0.058122847229242325\n",
      "46 **********\n",
      "Epoch:  2499.113877058029  fold:  7  kers:  32\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.07933973520994186\n",
      "Loss:  0.09118323773145676\n",
      "Loss:  0.06551794707775116\n",
      "47 **********\n",
      "Epoch:  2540.3675730228424  fold:  7  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.4737551808357239\n",
      "Eval Loss:  0.1768205314874649\n",
      "Eval Loss:  2.301982879638672\n",
      "[[2000  127]\n",
      " [ 704  600]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83      2127\n",
      "           1       0.83      0.46      0.59      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.70      0.71      3431\n",
      "weighted avg       0.77      0.76      0.74      3431\n",
      "\n",
      "acc:  0.757796560769455\n",
      "pre:  0.8253094910591472\n",
      "rec:  0.4601226993865031\n",
      "ma F1:  0.7094139370088611\n",
      "mi F1:  0.7577965607694549\n",
      "we F1:  0.7378560079766959\n",
      "Eval Loss:  0.24657323956489563\n",
      "Eval Loss:  0.2116958349943161\n",
      "Eval Loss:  0.2387648969888687\n",
      "Eval Loss:  0.37389257550239563\n",
      "Eval Loss:  0.18508978188037872\n",
      "Eval Loss:  0.17029552161693573\n",
      "Eval Loss:  0.16695813834667206\n",
      "Eval Loss:  0.18613027036190033\n",
      "Eval Loss:  0.30034390091896057\n",
      "Eval Loss:  0.3539752662181854\n",
      "Eval Loss:  0.37909096479415894\n",
      "Eval Loss:  0.264597624540329\n",
      "Eval Loss:  0.1856401562690735\n",
      "Eval Loss:  0.2082618772983551\n",
      "Eval Loss:  0.18563224375247955\n",
      "Eval Loss:  0.21792000532150269\n",
      "Eval Loss:  0.278264582157135\n",
      "Eval Loss:  0.2882923483848572\n",
      "Eval Loss:  0.23469319939613342\n",
      "Eval Loss:  0.2911750078201294\n",
      "Eval Loss:  0.1946801096200943\n",
      "Eval Loss:  0.26415330171585083\n",
      "Eval Loss:  0.1923021525144577\n",
      "Eval Loss:  0.19972142577171326\n",
      "Eval Loss:  0.15491633117198944\n",
      "Eval Loss:  0.29933926463127136\n",
      "Eval Loss:  0.16582979261875153\n",
      "Eval Loss:  0.23377284407615662\n",
      "[[17143   894]\n",
      " [ 1924  9499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18037\n",
      "           1       0.91      0.83      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9043448744059742\n",
      "pre:  0.9139805638410469\n",
      "rec:  0.8315678893460562\n",
      "ma F1:  0.8974400323818497\n",
      "mi F1:  0.9043448744059742\n",
      "we F1:  0.9034144731389873\n",
      "29460 461\n",
      "Loss:  0.06537710130214691\n",
      "Loss:  0.04717203974723816\n",
      "Loss:  0.04862430319190025\n",
      "48 **********\n",
      "Epoch:  2618.5774557590485  fold:  7  kers:  32\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.047324758023023605\n",
      "Loss:  0.0739310085773468\n",
      "Loss:  0.08496809005737305\n",
      "49 **********\n",
      "Epoch:  2658.4079570770264  fold:  7  kers:  32\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.050381164997816086\n",
      "Loss:  0.08051969856023788\n",
      "Loss:  0.06469955295324326\n",
      "50 **********\n",
      "Epoch:  2698.2663834095  fold:  7  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.4648604094982147\n",
      "Eval Loss:  0.32287514209747314\n",
      "Eval Loss:  1.4722986221313477\n",
      "[[1929  198]\n",
      " [ 504  800]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85      2127\n",
      "           1       0.80      0.61      0.70      1304\n",
      "\n",
      "    accuracy                           0.80      3431\n",
      "   macro avg       0.80      0.76      0.77      3431\n",
      "weighted avg       0.80      0.80      0.79      3431\n",
      "\n",
      "acc:  0.7953949285922471\n",
      "pre:  0.8016032064128257\n",
      "rec:  0.6134969325153374\n",
      "ma F1:  0.7705502080570671\n",
      "mi F1:  0.7953949285922471\n",
      "we F1:  0.788661107083155\n",
      "update!  Acc:  0.7953949285922471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20839864015579224\n",
      "Eval Loss:  0.21898579597473145\n",
      "Eval Loss:  0.24917641282081604\n",
      "Eval Loss:  0.3224797546863556\n",
      "Eval Loss:  0.1699645072221756\n",
      "Eval Loss:  0.16900788247585297\n",
      "Eval Loss:  0.14573019742965698\n",
      "Eval Loss:  0.2035195380449295\n",
      "Eval Loss:  0.31535977125167847\n",
      "Eval Loss:  0.3159222900867462\n",
      "Eval Loss:  0.3678947985172272\n",
      "Eval Loss:  0.22905674576759338\n",
      "Eval Loss:  0.1676640659570694\n",
      "Eval Loss:  0.20781169831752777\n",
      "Eval Loss:  0.1730290651321411\n",
      "Eval Loss:  0.2081317901611328\n",
      "Eval Loss:  0.2545231878757477\n",
      "Eval Loss:  0.2408493012189865\n",
      "Eval Loss:  0.22017574310302734\n",
      "Eval Loss:  0.28619393706321716\n",
      "Eval Loss:  0.1796129196882248\n",
      "Eval Loss:  0.25747573375701904\n",
      "Eval Loss:  0.17760206758975983\n",
      "Eval Loss:  0.19596710801124573\n",
      "Eval Loss:  0.13774530589580536\n",
      "Eval Loss:  0.26150795817375183\n",
      "Eval Loss:  0.1482369750738144\n",
      "Eval Loss:  0.25676092505455017\n",
      "[[16810  1227]\n",
      " [ 1390 10033]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18037\n",
      "           1       0.89      0.88      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9111676849966056\n",
      "pre:  0.8910301953818828\n",
      "rec:  0.8783156788934605\n",
      "ma F1:  0.9062041256068785\n",
      "mi F1:  0.9111676849966056\n",
      "we F1:  0.9110483017620586\n",
      "29460 461\n",
      "Loss:  0.043195560574531555\n",
      "Loss:  0.08393015712499619\n",
      "Loss:  0.08427710831165314\n",
      "51 **********\n",
      "Epoch:  2775.9018025398254  fold:  7  kers:  32\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.06285648792982101\n",
      "Loss:  0.04438211768865585\n",
      "Loss:  0.07577168941497803\n",
      "52 **********\n",
      "Epoch:  2815.7143511772156  fold:  7  kers:  32\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.06998385488986969\n",
      "Loss:  0.03797851502895355\n",
      "Loss:  0.03796740248799324\n",
      "53 **********\n",
      "Epoch:  2855.8011677265167  fold:  7  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.5670109987258911\n",
      "Eval Loss:  0.13097521662712097\n",
      "Eval Loss:  2.4373116493225098\n",
      "[[2019  108]\n",
      " [ 787  517]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82      2127\n",
      "           1       0.83      0.40      0.54      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.77      0.67      0.68      3431\n",
      "weighted avg       0.76      0.74      0.71      3431\n",
      "\n",
      "acc:  0.7391431069658991\n",
      "pre:  0.8272\n",
      "rec:  0.3964723926380368\n",
      "ma F1:  0.6772989264017566\n",
      "mi F1:  0.7391431069658991\n",
      "we F1:  0.7111855845936935\n",
      "Eval Loss:  0.28170984983444214\n",
      "Eval Loss:  0.21280787885189056\n",
      "Eval Loss:  0.2348855882883072\n",
      "Eval Loss:  0.3737245202064514\n",
      "Eval Loss:  0.19061310589313507\n",
      "Eval Loss:  0.17171522974967957\n",
      "Eval Loss:  0.18266595900058746\n",
      "Eval Loss:  0.1780395209789276\n",
      "Eval Loss:  0.29381322860717773\n",
      "Eval Loss:  0.3467452824115753\n",
      "Eval Loss:  0.38629254698753357\n",
      "Eval Loss:  0.28693777322769165\n",
      "Eval Loss:  0.20190021395683289\n",
      "Eval Loss:  0.21599379181861877\n",
      "Eval Loss:  0.19382691383361816\n",
      "Eval Loss:  0.21156185865402222\n",
      "Eval Loss:  0.2816062569618225\n",
      "Eval Loss:  0.3167741596698761\n",
      "Eval Loss:  0.23877251148223877\n",
      "Eval Loss:  0.2996526062488556\n",
      "Eval Loss:  0.19961349666118622\n",
      "Eval Loss:  0.2903106212615967\n",
      "Eval Loss:  0.23341254889965057\n",
      "Eval Loss:  0.2078530639410019\n",
      "Eval Loss:  0.17278531193733215\n",
      "Eval Loss:  0.32291844487190247\n",
      "Eval Loss:  0.18284541368484497\n",
      "Eval Loss:  0.23416267335414886\n",
      "[[17380   657]\n",
      " [ 2252  9171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18037\n",
      "           1       0.93      0.80      0.86     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.91      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.901255940257977\n",
      "pre:  0.9331501831501832\n",
      "rec:  0.8028538912719951\n",
      "ma F1:  0.8929435097493882\n",
      "mi F1:  0.901255940257977\n",
      "we F1:  0.8996408438197752\n",
      "29460 461\n",
      "Loss:  0.1037861630320549\n",
      "Loss:  0.05391876399517059\n",
      "Loss:  0.03683308884501457\n",
      "54 **********\n",
      "Epoch:  2937.605439901352  fold:  7  kers:  32\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.08862660825252533\n",
      "Loss:  0.07888331264257431\n",
      "Loss:  0.06725312769412994\n",
      "55 **********\n",
      "Epoch:  2978.3115997314453  fold:  7  kers:  32\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.06628399342298508\n",
      "Loss:  0.07572092860937119\n",
      "Loss:  0.057341884821653366\n",
      "56 **********\n",
      "Epoch:  3018.5430290699005  fold:  7  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.5269006490707397\n",
      "Eval Loss:  0.24550944566726685\n",
      "Eval Loss:  1.793057918548584\n",
      "[[1982  145]\n",
      " [ 601  703]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84      2127\n",
      "           1       0.83      0.54      0.65      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.80      0.74      0.75      3431\n",
      "weighted avg       0.79      0.78      0.77      3431\n",
      "\n",
      "acc:  0.7825706791023025\n",
      "pre:  0.8290094339622641\n",
      "rec:  0.5391104294478528\n",
      "ma F1:  0.7474796565087333\n",
      "mi F1:  0.7825706791023025\n",
      "we F1:  0.7700597281228908\n",
      "Eval Loss:  0.22933264076709747\n",
      "Eval Loss:  0.21555504202842712\n",
      "Eval Loss:  0.23310469090938568\n",
      "Eval Loss:  0.3552844822406769\n",
      "Eval Loss:  0.16352689266204834\n",
      "Eval Loss:  0.16420695185661316\n",
      "Eval Loss:  0.15298031270503998\n",
      "Eval Loss:  0.1689453423023224\n",
      "Eval Loss:  0.30280813574790955\n",
      "Eval Loss:  0.33459535241127014\n",
      "Eval Loss:  0.381405770778656\n",
      "Eval Loss:  0.2427128553390503\n",
      "Eval Loss:  0.1871953010559082\n",
      "Eval Loss:  0.20367208123207092\n",
      "Eval Loss:  0.16596214473247528\n",
      "Eval Loss:  0.2001456469297409\n",
      "Eval Loss:  0.2662455439567566\n",
      "Eval Loss:  0.2920709550380707\n",
      "Eval Loss:  0.22840306162834167\n",
      "Eval Loss:  0.27667737007141113\n",
      "Eval Loss:  0.19382105767726898\n",
      "Eval Loss:  0.2720830738544464\n",
      "Eval Loss:  0.219876229763031\n",
      "Eval Loss:  0.19603300094604492\n",
      "Eval Loss:  0.15048612654209137\n",
      "Eval Loss:  0.3002581000328064\n",
      "Eval Loss:  0.1559857577085495\n",
      "Eval Loss:  0.2504402995109558\n",
      "[[17226   811]\n",
      " [ 1855  9568]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18037\n",
      "           1       0.92      0.84      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9095044127630686\n",
      "pre:  0.9218614510068407\n",
      "rec:  0.8376083340628556\n",
      "ma F1:  0.90294632500641\n",
      "mi F1:  0.9095044127630686\n",
      "we F1:  0.9086103616246576\n",
      "29460 461\n",
      "Loss:  0.07104219496250153\n",
      "Loss:  0.08347170799970627\n",
      "Loss:  0.07264082133769989\n",
      "57 **********\n",
      "Epoch:  3097.771189212799  fold:  7  kers:  32\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.08189607411623001\n",
      "Loss:  0.0641382485628128\n",
      "Loss:  0.03739532455801964\n",
      "58 **********\n",
      "Epoch:  3143.18376493454  fold:  7  kers:  32\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.0954713225364685\n",
      "Loss:  0.06020721048116684\n",
      "Loss:  0.06853267550468445\n",
      "59 **********\n",
      "Epoch:  3183.8001651763916  fold:  7  kers:  32\n",
      "Eval Loss:  0.48246273398399353\n",
      "Eval Loss:  0.18609538674354553\n",
      "Eval Loss:  1.7421642541885376\n",
      "[[1975  152]\n",
      " [ 607  697]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84      2127\n",
      "           1       0.82      0.53      0.65      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.79      0.73      0.74      3431\n",
      "weighted avg       0.79      0.78      0.77      3431\n",
      "\n",
      "acc:  0.7787816962984553\n",
      "pre:  0.8209658421672555\n",
      "rec:  0.5345092024539877\n",
      "ma F1:  0.743143965311555\n",
      "mi F1:  0.7787816962984554\n",
      "we F1:  0.7660937717295667\n",
      "update!  Acc:  0.7953949285922471\n",
      "Epoch:  3187.842357158661  fold:  7  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29817 3074\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29817 466\n",
      "Loss:  0.17242908477783203\n",
      "Loss:  0.16599810123443604\n",
      "Loss:  0.15534013509750366\n",
      "0 **********\n",
      "Epoch:  53.72335433959961  fold:  8  kers:  32\n",
      "epoch:  1\n",
      "29817 466\n",
      "Loss:  0.13055068254470825\n",
      "Loss:  0.12701182067394257\n",
      "Loss:  0.11771104484796524\n",
      "1 **********\n",
      "Epoch:  94.92518925666809  fold:  8  kers:  32\n",
      "epoch:  2\n",
      "29817 466\n",
      "Loss:  0.11892218887805939\n",
      "Loss:  0.10801909863948822\n",
      "Loss:  0.10362665355205536\n",
      "2 **********\n",
      "Epoch:  140.6708745956421  fold:  8  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.27103912830352783\n",
      "Eval Loss:  1.3562124967575073\n",
      "Eval Loss:  0.1909499168395996\n",
      "[[1913  160]\n",
      " [ 534  467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85      2073\n",
      "           1       0.74      0.47      0.57      1001\n",
      "\n",
      "    accuracy                           0.77      3074\n",
      "   macro avg       0.76      0.69      0.71      3074\n",
      "weighted avg       0.77      0.77      0.76      3074\n",
      "\n",
      "acc:  0.7742355237475602\n",
      "pre:  0.74481658692185\n",
      "rec:  0.46653346653346656\n",
      "ma F1:  0.7100851253506122\n",
      "mi F1:  0.7742355237475602\n",
      "we F1:  0.7576433736780869\n",
      "update!  Acc:  0.7742355237475602\n",
      "Eval Loss:  0.5637365579605103\n",
      "Eval Loss:  0.49261340498924255\n",
      "Eval Loss:  0.48311230540275574\n",
      "Eval Loss:  0.4651170074939728\n",
      "Eval Loss:  0.4913778305053711\n",
      "Eval Loss:  0.5042333006858826\n",
      "Eval Loss:  0.4671376347541809\n",
      "Eval Loss:  0.5296134352684021\n",
      "Eval Loss:  0.5822333693504333\n",
      "Eval Loss:  0.4674835801124573\n",
      "Eval Loss:  0.5264452695846558\n",
      "Eval Loss:  0.6060621738433838\n",
      "Eval Loss:  0.5199335813522339\n",
      "Eval Loss:  0.4878511130809784\n",
      "Eval Loss:  0.553200900554657\n",
      "Eval Loss:  0.5957939624786377\n",
      "Eval Loss:  0.43226826190948486\n",
      "Eval Loss:  0.44584664702415466\n",
      "Eval Loss:  0.4117943346500397\n",
      "Eval Loss:  0.552516520023346\n",
      "Eval Loss:  0.49091148376464844\n",
      "Eval Loss:  0.5703405737876892\n",
      "Eval Loss:  0.5309686660766602\n",
      "Eval Loss:  0.42977669835090637\n",
      "Eval Loss:  0.5216179490089417\n",
      "Eval Loss:  0.40894296765327454\n",
      "Eval Loss:  0.511326014995575\n",
      "Eval Loss:  0.41018590331077576\n",
      "Eval Loss:  0.5369118452072144\n",
      "[[16144  1947]\n",
      " [ 4499  7227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83     18091\n",
      "           1       0.79      0.62      0.69     11726\n",
      "\n",
      "    accuracy                           0.78     29817\n",
      "   macro avg       0.78      0.75      0.76     29817\n",
      "weighted avg       0.78      0.78      0.78     29817\n",
      "\n",
      "acc:  0.7838146024080223\n",
      "pre:  0.7877697841726619\n",
      "rec:  0.6163227016885553\n",
      "ma F1:  0.7625809230568548\n",
      "mi F1:  0.7838146024080223\n",
      "we F1:  0.7777376314868403\n",
      "29817 466\n",
      "Loss:  0.1028536856174469\n",
      "Loss:  0.10325939208269119\n",
      "Loss:  0.08772330731153488\n",
      "3 **********\n",
      "Epoch:  220.30195784568787  fold:  8  kers:  32\n",
      "epoch:  4\n",
      "29817 466\n",
      "Loss:  0.07388781756162643\n",
      "Loss:  0.08638974279165268\n",
      "Loss:  0.10556868463754654\n",
      "4 **********\n",
      "Epoch:  261.0709488391876  fold:  8  kers:  32\n",
      "epoch:  5\n",
      "29817 466\n",
      "Loss:  0.09943586587905884\n",
      "Loss:  0.09051336348056793\n",
      "Loss:  0.0987410843372345\n",
      "5 **********\n",
      "Epoch:  301.7521755695343  fold:  8  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.34542417526245117\n",
      "Eval Loss:  1.5367355346679688\n",
      "Eval Loss:  0.24389079213142395\n",
      "[[1934  139]\n",
      " [ 398  603]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      2073\n",
      "           1       0.81      0.60      0.69      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.82      0.77      0.79      3074\n",
      "weighted avg       0.82      0.83      0.82      3074\n",
      "\n",
      "acc:  0.8253090435914119\n",
      "pre:  0.8126684636118598\n",
      "rec:  0.6023976023976024\n",
      "ma F1:  0.7850017875946791\n",
      "mi F1:  0.8253090435914119\n",
      "we F1:  0.8174656331457666\n",
      "update!  Acc:  0.8253090435914119\n",
      "Eval Loss:  0.4185943007469177\n",
      "Eval Loss:  0.35008668899536133\n",
      "Eval Loss:  0.3593290448188782\n",
      "Eval Loss:  0.32126718759536743\n",
      "Eval Loss:  0.37274566292762756\n",
      "Eval Loss:  0.35515183210372925\n",
      "Eval Loss:  0.35835811495780945\n",
      "Eval Loss:  0.3681824207305908\n",
      "Eval Loss:  0.3965480327606201\n",
      "Eval Loss:  0.28932589292526245\n",
      "Eval Loss:  0.33458322286605835\n",
      "Eval Loss:  0.4107596278190613\n",
      "Eval Loss:  0.3726342022418976\n",
      "Eval Loss:  0.3581370413303375\n",
      "Eval Loss:  0.3321446180343628\n",
      "Eval Loss:  0.3077104985713959\n",
      "Eval Loss:  0.33807939291000366\n",
      "Eval Loss:  0.40429678559303284\n",
      "Eval Loss:  0.3572225570678711\n",
      "Eval Loss:  0.40886181592941284\n",
      "Eval Loss:  0.3202190399169922\n",
      "Eval Loss:  0.4379914700984955\n",
      "Eval Loss:  0.4072768986225128\n",
      "Eval Loss:  0.2513938248157501\n",
      "Eval Loss:  0.3933343291282654\n",
      "Eval Loss:  0.3021039068698883\n",
      "Eval Loss:  0.3014700412750244\n",
      "Eval Loss:  0.3272247910499573\n",
      "Eval Loss:  0.35135799646377563\n",
      "[[16548  1543]\n",
      " [ 2854  8872]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     18091\n",
      "           1       0.85      0.76      0.80     11726\n",
      "\n",
      "    accuracy                           0.85     29817\n",
      "   macro avg       0.85      0.84      0.84     29817\n",
      "weighted avg       0.85      0.85      0.85     29817\n",
      "\n",
      "acc:  0.8525337894489721\n",
      "pre:  0.8518482957273164\n",
      "rec:  0.7566092444141225\n",
      "ma F1:  0.8420669628681319\n",
      "mi F1:  0.8525337894489721\n",
      "we F1:  0.8507461383745216\n",
      "29817 466\n",
      "Loss:  0.09572681784629822\n",
      "Loss:  0.10195285826921463\n",
      "Loss:  0.08172287046909332\n",
      "6 **********\n",
      "Epoch:  381.3962230682373  fold:  8  kers:  32\n",
      "epoch:  7\n",
      "29817 466\n",
      "Loss:  0.11090371757745743\n",
      "Loss:  0.0700891986489296\n",
      "Loss:  0.07805190235376358\n",
      "7 **********\n",
      "Epoch:  422.80749797821045  fold:  8  kers:  32\n",
      "epoch:  8\n",
      "29817 466\n",
      "Loss:  0.0934121236205101\n",
      "Loss:  0.10271590948104858\n",
      "Loss:  0.09178439527750015\n",
      "8 **********\n",
      "Epoch:  463.7879252433777  fold:  8  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.21525701880455017\n",
      "Eval Loss:  2.191066026687622\n",
      "Eval Loss:  0.104738749563694\n",
      "[[2028   45]\n",
      " [ 646  355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.85      2073\n",
      "           1       0.89      0.35      0.51      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.82      0.67      0.68      3074\n",
      "weighted avg       0.80      0.78      0.74      3074\n",
      "\n",
      "acc:  0.7752114508783344\n",
      "pre:  0.8875\n",
      "rec:  0.3546453546453546\n",
      "ma F1:  0.6806076252073701\n",
      "mi F1:  0.7752114508783344\n",
      "we F1:  0.7412264543282749\n",
      "Eval Loss:  0.5174517035484314\n",
      "Eval Loss:  0.4174922704696655\n",
      "Eval Loss:  0.45697757601737976\n",
      "Eval Loss:  0.42881321907043457\n",
      "Eval Loss:  0.38447338342666626\n",
      "Eval Loss:  0.4544408321380615\n",
      "Eval Loss:  0.4956602454185486\n",
      "Eval Loss:  0.47489437460899353\n",
      "Eval Loss:  0.5034342408180237\n",
      "Eval Loss:  0.4292396306991577\n",
      "Eval Loss:  0.5006179809570312\n",
      "Eval Loss:  0.49552008509635925\n",
      "Eval Loss:  0.5072294473648071\n",
      "Eval Loss:  0.45833972096443176\n",
      "Eval Loss:  0.4776463806629181\n",
      "Eval Loss:  0.44626763463020325\n",
      "Eval Loss:  0.4007602035999298\n",
      "Eval Loss:  0.4314480125904083\n",
      "Eval Loss:  0.4047272205352783\n",
      "Eval Loss:  0.5249152779579163\n",
      "Eval Loss:  0.3777541518211365\n",
      "Eval Loss:  0.5710515379905701\n",
      "Eval Loss:  0.5071995258331299\n",
      "Eval Loss:  0.3151454031467438\n",
      "Eval Loss:  0.5035450458526611\n",
      "Eval Loss:  0.44481128454208374\n",
      "Eval Loss:  0.3862563669681549\n",
      "Eval Loss:  0.40691691637039185\n",
      "Eval Loss:  0.4641147255897522\n",
      "[[17550   541]\n",
      " [ 4700  7026]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     18091\n",
      "           1       0.93      0.60      0.73     11726\n",
      "\n",
      "    accuracy                           0.82     29817\n",
      "   macro avg       0.86      0.78      0.80     29817\n",
      "weighted avg       0.84      0.82      0.81     29817\n",
      "\n",
      "acc:  0.8242277895160479\n",
      "pre:  0.9285053521871284\n",
      "rec:  0.5991813064983796\n",
      "ma F1:  0.7992148075889707\n",
      "mi F1:  0.8242277895160479\n",
      "we F1:  0.8143428606073901\n",
      "29817 466\n",
      "Loss:  0.07433212548494339\n",
      "Loss:  0.06784331053495407\n",
      "Loss:  0.08139186352491379\n",
      "9 **********\n",
      "Epoch:  542.9422824382782  fold:  8  kers:  32\n",
      "epoch:  10\n",
      "29817 466\n",
      "Loss:  0.07112973183393478\n",
      "Loss:  0.1252475380897522\n",
      "Loss:  0.07266105711460114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 **********\n",
      "Epoch:  583.9925224781036  fold:  8  kers:  32\n",
      "epoch:  11\n",
      "29817 466\n",
      "Loss:  0.08598127216100693\n",
      "Loss:  0.06887857615947723\n",
      "Loss:  0.06383305042982101\n",
      "11 **********\n",
      "Epoch:  624.444363117218  fold:  8  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.23302066326141357\n",
      "Eval Loss:  1.904443621635437\n",
      "Eval Loss:  0.10745403170585632\n",
      "[[1940  133]\n",
      " [ 510  491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      2073\n",
      "           1       0.79      0.49      0.60      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.79      0.71      0.73      3074\n",
      "weighted avg       0.79      0.79      0.78      3074\n",
      "\n",
      "acc:  0.7908262849707222\n",
      "pre:  0.7868589743589743\n",
      "rec:  0.4905094905094905\n",
      "ma F1:  0.7310727053181176\n",
      "mi F1:  0.7908262849707222\n",
      "we F1:  0.7752796324317078\n",
      "Eval Loss:  0.3983630836009979\n",
      "Eval Loss:  0.3148604929447174\n",
      "Eval Loss:  0.340827077627182\n",
      "Eval Loss:  0.3474346697330475\n",
      "Eval Loss:  0.3485349416732788\n",
      "Eval Loss:  0.3453015685081482\n",
      "Eval Loss:  0.3785263001918793\n",
      "Eval Loss:  0.37153154611587524\n",
      "Eval Loss:  0.37618622183799744\n",
      "Eval Loss:  0.2948184609413147\n",
      "Eval Loss:  0.34997230768203735\n",
      "Eval Loss:  0.3604351580142975\n",
      "Eval Loss:  0.3923012614250183\n",
      "Eval Loss:  0.35441750288009644\n",
      "Eval Loss:  0.34011000394821167\n",
      "Eval Loss:  0.29355186223983765\n",
      "Eval Loss:  0.33749836683273315\n",
      "Eval Loss:  0.37212812900543213\n",
      "Eval Loss:  0.3405986726284027\n",
      "Eval Loss:  0.4155828058719635\n",
      "Eval Loss:  0.2485431730747223\n",
      "Eval Loss:  0.434865266084671\n",
      "Eval Loss:  0.4014991819858551\n",
      "Eval Loss:  0.24371321499347687\n",
      "Eval Loss:  0.3959353268146515\n",
      "Eval Loss:  0.3521365523338318\n",
      "Eval Loss:  0.26531174778938293\n",
      "Eval Loss:  0.3567564785480499\n",
      "Eval Loss:  0.3237681984901428\n",
      "[[17205   886]\n",
      " [ 3319  8407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18091\n",
      "           1       0.90      0.72      0.80     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.87      0.83      0.85     29817\n",
      "weighted avg       0.86      0.86      0.86     29817\n",
      "\n",
      "acc:  0.8589730690545662\n",
      "pre:  0.9046594210696223\n",
      "rec:  0.7169537779293876\n",
      "ma F1:  0.8455237009347216\n",
      "mi F1:  0.8589730690545662\n",
      "we F1:  0.8552537791437249\n",
      "29817 466\n",
      "Loss:  0.09203698486089706\n",
      "Loss:  0.09839046001434326\n",
      "Loss:  0.07220635563135147\n",
      "12 **********\n",
      "Epoch:  702.8377540111542  fold:  8  kers:  32\n",
      "epoch:  13\n",
      "29817 466\n",
      "Loss:  0.08210643380880356\n",
      "Loss:  0.11460041999816895\n",
      "Loss:  0.11857396364212036\n",
      "13 **********\n",
      "Epoch:  743.4561488628387  fold:  8  kers:  32\n",
      "epoch:  14\n",
      "29817 466\n",
      "Loss:  0.0884753167629242\n",
      "Loss:  0.07649065554141998\n",
      "Loss:  0.08266272395849228\n",
      "14 **********\n",
      "Epoch:  784.0246770381927  fold:  8  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.23190222680568695\n",
      "Eval Loss:  2.023669719696045\n",
      "Eval Loss:  0.09328186511993408\n",
      "[[1872  201]\n",
      " [ 547  454]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83      2073\n",
      "           1       0.69      0.45      0.55      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.73      0.68      0.69      3074\n",
      "weighted avg       0.75      0.76      0.74      3074\n",
      "\n",
      "acc:  0.756668835393624\n",
      "pre:  0.6931297709923664\n",
      "rec:  0.45354645354645357\n",
      "ma F1:  0.6908954620344918\n",
      "mi F1:  0.756668835393624\n",
      "we F1:  0.7406197612171361\n",
      "Eval Loss:  0.39522090554237366\n",
      "Eval Loss:  0.3316485583782196\n",
      "Eval Loss:  0.3470879793167114\n",
      "Eval Loss:  0.36697492003440857\n",
      "Eval Loss:  0.32293739914894104\n",
      "Eval Loss:  0.3628900647163391\n",
      "Eval Loss:  0.3986573815345764\n",
      "Eval Loss:  0.39579933881759644\n",
      "Eval Loss:  0.38956910371780396\n",
      "Eval Loss:  0.31889891624450684\n",
      "Eval Loss:  0.3643333911895752\n",
      "Eval Loss:  0.3544107675552368\n",
      "Eval Loss:  0.37928152084350586\n",
      "Eval Loss:  0.40344157814979553\n",
      "Eval Loss:  0.3606052100658417\n",
      "Eval Loss:  0.3199968636035919\n",
      "Eval Loss:  0.34982752799987793\n",
      "Eval Loss:  0.35373276472091675\n",
      "Eval Loss:  0.3486521244049072\n",
      "Eval Loss:  0.4303341209888458\n",
      "Eval Loss:  0.23518630862236023\n",
      "Eval Loss:  0.4340955317020416\n",
      "Eval Loss:  0.4326643943786621\n",
      "Eval Loss:  0.23372933268547058\n",
      "Eval Loss:  0.40022364258766174\n",
      "Eval Loss:  0.38129985332489014\n",
      "Eval Loss:  0.26954326033592224\n",
      "Eval Loss:  0.3611674904823303\n",
      "Eval Loss:  0.33960065245628357\n",
      "[[17378   713]\n",
      " [ 3580  8146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18091\n",
      "           1       0.92      0.69      0.79     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.87      0.83      0.84     29817\n",
      "weighted avg       0.86      0.86      0.85     29817\n",
      "\n",
      "acc:  0.8560217325686689\n",
      "pre:  0.9195168754938481\n",
      "rec:  0.694695548354085\n",
      "ma F1:  0.84075564508293\n",
      "mi F1:  0.8560217325686689\n",
      "we F1:  0.8512808451313191\n",
      "29817 466\n",
      "Loss:  0.09068074822425842\n",
      "Loss:  0.09069628268480301\n",
      "Loss:  0.05986253172159195\n",
      "15 **********\n",
      "Epoch:  862.5876157283783  fold:  8  kers:  32\n",
      "epoch:  16\n",
      "29817 466\n",
      "Loss:  0.10512566566467285\n",
      "Loss:  0.09038981050252914\n",
      "Loss:  0.08370717614889145\n",
      "16 **********\n",
      "Epoch:  903.2139887809753  fold:  8  kers:  32\n",
      "epoch:  17\n",
      "29817 466\n",
      "Loss:  0.07259555906057358\n",
      "Loss:  0.06813182681798935\n",
      "Loss:  0.0764603391289711\n",
      "17 **********\n",
      "Epoch:  943.6269328594208  fold:  8  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.16600343585014343\n",
      "Eval Loss:  2.048290729522705\n",
      "Eval Loss:  0.07817953824996948\n",
      "[[1951  122]\n",
      " [ 635  366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.84      2073\n",
      "           1       0.75      0.37      0.49      1001\n",
      "\n",
      "    accuracy                           0.75      3074\n",
      "   macro avg       0.75      0.65      0.66      3074\n",
      "weighted avg       0.75      0.75      0.72      3074\n",
      "\n",
      "acc:  0.7537410540013012\n",
      "pre:  0.75\n",
      "rec:  0.36563436563436563\n",
      "ma F1:  0.6645619424754848\n",
      "mi F1:  0.7537410540013012\n",
      "we F1:  0.7248774046557216\n",
      "Eval Loss:  0.42875421047210693\n",
      "Eval Loss:  0.3407062292098999\n",
      "Eval Loss:  0.3858358561992645\n",
      "Eval Loss:  0.3917749226093292\n",
      "Eval Loss:  0.3599909842014313\n",
      "Eval Loss:  0.3776615858078003\n",
      "Eval Loss:  0.4494093954563141\n",
      "Eval Loss:  0.4191475808620453\n",
      "Eval Loss:  0.4288875460624695\n",
      "Eval Loss:  0.365215927362442\n",
      "Eval Loss:  0.4167996644973755\n",
      "Eval Loss:  0.3926782011985779\n",
      "Eval Loss:  0.4373778998851776\n",
      "Eval Loss:  0.418601930141449\n",
      "Eval Loss:  0.3974778950214386\n",
      "Eval Loss:  0.3538185954093933\n",
      "Eval Loss:  0.36234933137893677\n",
      "Eval Loss:  0.36401596665382385\n",
      "Eval Loss:  0.3769533336162567\n",
      "Eval Loss:  0.45897382497787476\n",
      "Eval Loss:  0.2684449553489685\n",
      "Eval Loss:  0.4701728820800781\n",
      "Eval Loss:  0.4377039968967438\n",
      "Eval Loss:  0.26986563205718994\n",
      "Eval Loss:  0.4241296648979187\n",
      "Eval Loss:  0.4072149097919464\n",
      "Eval Loss:  0.31658151745796204\n",
      "Eval Loss:  0.39811524748802185\n",
      "Eval Loss:  0.37891241908073425\n",
      "[[17615   476]\n",
      " [ 4114  7612]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88     18091\n",
      "           1       0.94      0.65      0.77     11726\n",
      "\n",
      "    accuracy                           0.85     29817\n",
      "   macro avg       0.88      0.81      0.83     29817\n",
      "weighted avg       0.86      0.85      0.84     29817\n",
      "\n",
      "acc:  0.8460609719287655\n",
      "pre:  0.9411473788328387\n",
      "rec:  0.649155722326454\n",
      "ma F1:  0.826538452510406\n",
      "mi F1:  0.8460609719287655\n",
      "we F1:  0.838960809413121\n",
      "29817 466\n",
      "Loss:  0.05806737020611763\n",
      "Loss:  0.07961464673280716\n",
      "Loss:  0.07994736731052399\n",
      "18 **********\n",
      "Epoch:  1022.0662019252777  fold:  8  kers:  32\n",
      "epoch:  19\n",
      "29817 466\n",
      "Loss:  0.07373002171516418\n",
      "Loss:  0.07880958169698715\n",
      "Loss:  0.07728904485702515\n",
      "19 **********\n",
      "Epoch:  1062.4980957508087  fold:  8  kers:  32\n",
      "epoch:  20\n",
      "29817 466\n",
      "Loss:  0.10944032669067383\n",
      "Loss:  0.08143715560436249\n",
      "Loss:  0.09289434552192688\n",
      "20 **********\n",
      "Epoch:  1102.8980739116669  fold:  8  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.27509304881095886\n",
      "Eval Loss:  1.8509328365325928\n",
      "Eval Loss:  0.0879257395863533\n",
      "[[1813  260]\n",
      " [ 511  490]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      2073\n",
      "           1       0.65      0.49      0.56      1001\n",
      "\n",
      "    accuracy                           0.75      3074\n",
      "   macro avg       0.72      0.68      0.69      3074\n",
      "weighted avg       0.74      0.75      0.74      3074\n",
      "\n",
      "acc:  0.7491867273910214\n",
      "pre:  0.6533333333333333\n",
      "rec:  0.48951048951048953\n",
      "ma F1:  0.6921666776852033\n",
      "mi F1:  0.7491867273910214\n",
      "we F1:  0.7383688645972495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.35082218050956726\n",
      "Eval Loss:  0.30944395065307617\n",
      "Eval Loss:  0.2944360375404358\n",
      "Eval Loss:  0.32869336009025574\n",
      "Eval Loss:  0.3224470615386963\n",
      "Eval Loss:  0.33072760701179504\n",
      "Eval Loss:  0.3776947259902954\n",
      "Eval Loss:  0.3528378903865814\n",
      "Eval Loss:  0.35981401801109314\n",
      "Eval Loss:  0.2750122547149658\n",
      "Eval Loss:  0.3187558352947235\n",
      "Eval Loss:  0.311739981174469\n",
      "Eval Loss:  0.33752450346946716\n",
      "Eval Loss:  0.3516201674938202\n",
      "Eval Loss:  0.32486435770988464\n",
      "Eval Loss:  0.2763805389404297\n",
      "Eval Loss:  0.3323095142841339\n",
      "Eval Loss:  0.3284587264060974\n",
      "Eval Loss:  0.33202388882637024\n",
      "Eval Loss:  0.3735581338405609\n",
      "Eval Loss:  0.19664312899112701\n",
      "Eval Loss:  0.3837279975414276\n",
      "Eval Loss:  0.380217045545578\n",
      "Eval Loss:  0.223441481590271\n",
      "Eval Loss:  0.3542422950267792\n",
      "Eval Loss:  0.3402615785598755\n",
      "Eval Loss:  0.22550156712532043\n",
      "Eval Loss:  0.35047677159309387\n",
      "Eval Loss:  0.3083023726940155\n",
      "[[17243   848]\n",
      " [ 3010  8716]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     18091\n",
      "           1       0.91      0.74      0.82     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.88      0.85      0.86     29817\n",
      "weighted avg       0.87      0.87      0.87     29817\n",
      "\n",
      "acc:  0.8706107254250931\n",
      "pre:  0.9113341698034295\n",
      "rec:  0.7433054750127921\n",
      "ma F1:  0.8590863412736811\n",
      "mi F1:  0.8706107254250931\n",
      "we F1:  0.8676887460026289\n",
      "29817 466\n",
      "Loss:  0.07725189626216888\n",
      "Loss:  0.08225838094949722\n",
      "Loss:  0.08736992627382278\n",
      "21 **********\n",
      "Epoch:  1181.4251096248627  fold:  8  kers:  32\n",
      "epoch:  22\n",
      "29817 466\n",
      "Loss:  0.0954432412981987\n",
      "Loss:  0.0892484113574028\n",
      "Loss:  0.09006521105766296\n",
      "22 **********\n",
      "Epoch:  1221.8420419692993  fold:  8  kers:  32\n",
      "epoch:  23\n",
      "29817 466\n",
      "Loss:  0.07857929170131683\n",
      "Loss:  0.07140060514211655\n",
      "Loss:  0.0874965637922287\n",
      "23 **********\n",
      "Epoch:  1262.2529923915863  fold:  8  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.3097679615020752\n",
      "Eval Loss:  1.6065130233764648\n",
      "Eval Loss:  0.08914411813020706\n",
      "[[1811  262]\n",
      " [ 466  535]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83      2073\n",
      "           1       0.67      0.53      0.60      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.73      0.70      0.71      3074\n",
      "weighted avg       0.75      0.76      0.76      3074\n",
      "\n",
      "acc:  0.7631750162654521\n",
      "pre:  0.671267252195734\n",
      "rec:  0.5344655344655345\n",
      "ma F1:  0.713874675565443\n",
      "mi F1:  0.7631750162654521\n",
      "we F1:  0.7552931436143536\n",
      "Eval Loss:  0.308917373418808\n",
      "Eval Loss:  0.28575754165649414\n",
      "Eval Loss:  0.2719615697860718\n",
      "Eval Loss:  0.312934547662735\n",
      "Eval Loss:  0.3071063160896301\n",
      "Eval Loss:  0.31279683113098145\n",
      "Eval Loss:  0.3331862986087799\n",
      "Eval Loss:  0.32236748933792114\n",
      "Eval Loss:  0.33813902735710144\n",
      "Eval Loss:  0.254280149936676\n",
      "Eval Loss:  0.3032422363758087\n",
      "Eval Loss:  0.29697078466415405\n",
      "Eval Loss:  0.32008442282676697\n",
      "Eval Loss:  0.33257293701171875\n",
      "Eval Loss:  0.285108357667923\n",
      "Eval Loss:  0.2382107377052307\n",
      "Eval Loss:  0.307049959897995\n",
      "Eval Loss:  0.3045920133590698\n",
      "Eval Loss:  0.3055580258369446\n",
      "Eval Loss:  0.35983267426490784\n",
      "Eval Loss:  0.19333763420581818\n",
      "Eval Loss:  0.34884458780288696\n",
      "Eval Loss:  0.368865430355072\n",
      "Eval Loss:  0.19937488436698914\n",
      "Eval Loss:  0.32397323846817017\n",
      "Eval Loss:  0.33211401104927063\n",
      "Eval Loss:  0.22311733663082123\n",
      "Eval Loss:  0.32257866859436035\n",
      "Eval Loss:  0.28650373220443726\n",
      "[[17148   943]\n",
      " [ 2680  9046]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18091\n",
      "           1       0.91      0.77      0.83     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.86      0.87     29817\n",
      "weighted avg       0.88      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8784921353590234\n",
      "pre:  0.9055961557713484\n",
      "rec:  0.771448064130991\n",
      "ma F1:  0.8688055177202285\n",
      "mi F1:  0.8784921353590234\n",
      "we F1:  0.8764154067934116\n",
      "29817 466\n",
      "Loss:  0.04607675224542618\n",
      "Loss:  0.08399780094623566\n",
      "Loss:  0.09179145842790604\n",
      "24 **********\n",
      "Epoch:  1340.7381381988525  fold:  8  kers:  32\n",
      "epoch:  25\n",
      "29817 466\n",
      "Loss:  0.06619927287101746\n",
      "Loss:  0.07416778057813644\n",
      "Loss:  0.06712273508310318\n",
      "25 **********\n",
      "Epoch:  1381.220895767212  fold:  8  kers:  32\n",
      "epoch:  26\n",
      "29817 466\n",
      "Loss:  0.08140696585178375\n",
      "Loss:  0.07973632216453552\n",
      "Loss:  0.08856573700904846\n",
      "26 **********\n",
      "Epoch:  1421.571007490158  fold:  8  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.31143254041671753\n",
      "Eval Loss:  1.4808125495910645\n",
      "Eval Loss:  0.08045798540115356\n",
      "[[1937  136]\n",
      " [ 485  516]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      2073\n",
      "           1       0.79      0.52      0.62      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.80      0.72      0.74      3074\n",
      "weighted avg       0.80      0.80      0.78      3074\n",
      "\n",
      "acc:  0.7979830839297333\n",
      "pre:  0.7914110429447853\n",
      "rec:  0.5154845154845155\n",
      "ma F1:  0.7430829576722674\n",
      "mi F1:  0.7979830839297333\n",
      "we F1:  0.7844995201972522\n",
      "Eval Loss:  0.32800278067588806\n",
      "Eval Loss:  0.27433040738105774\n",
      "Eval Loss:  0.2599358558654785\n",
      "Eval Loss:  0.30038657784461975\n",
      "Eval Loss:  0.34386470913887024\n",
      "Eval Loss:  0.2918706238269806\n",
      "Eval Loss:  0.3521384298801422\n",
      "Eval Loss:  0.31900763511657715\n",
      "Eval Loss:  0.330768346786499\n",
      "Eval Loss:  0.24642187356948853\n",
      "Eval Loss:  0.29726776480674744\n",
      "Eval Loss:  0.2963174879550934\n",
      "Eval Loss:  0.33523300290107727\n",
      "Eval Loss:  0.3146234452724457\n",
      "Eval Loss:  0.28899869322776794\n",
      "Eval Loss:  0.23852750658988953\n",
      "Eval Loss:  0.31796348094940186\n",
      "Eval Loss:  0.30230456590652466\n",
      "Eval Loss:  0.3233603537082672\n",
      "Eval Loss:  0.3367640972137451\n",
      "Eval Loss:  0.1902465522289276\n",
      "Eval Loss:  0.3542814552783966\n",
      "Eval Loss:  0.3437096178531647\n",
      "Eval Loss:  0.19920191168785095\n",
      "Eval Loss:  0.29425501823425293\n",
      "Eval Loss:  0.297904908657074\n",
      "Eval Loss:  0.21189871430397034\n",
      "Eval Loss:  0.3359345495700836\n",
      "Eval Loss:  0.2989039421081543\n",
      "[[17159   932]\n",
      " [ 2655  9071]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18091\n",
      "           1       0.91      0.77      0.83     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.86      0.87     29817\n",
      "weighted avg       0.88      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8796995002850723\n",
      "pre:  0.9068279516145157\n",
      "rec:  0.7735800784581273\n",
      "ma F1:  0.8701448790450953\n",
      "mi F1:  0.8796995002850723\n",
      "we F1:  0.8776640635397113\n",
      "29817 466\n",
      "Loss:  0.09506680816411972\n",
      "Loss:  0.08106344938278198\n",
      "Loss:  0.048232465982437134\n",
      "27 **********\n",
      "Epoch:  1500.1169917583466  fold:  8  kers:  32\n",
      "epoch:  28\n",
      "29817 466\n",
      "Loss:  0.07385370135307312\n",
      "Loss:  0.09013751149177551\n",
      "Loss:  0.099629707634449\n",
      "28 **********\n",
      "Epoch:  1540.5229544639587  fold:  8  kers:  32\n",
      "epoch:  29\n",
      "29817 466\n",
      "Loss:  0.05863834172487259\n",
      "Loss:  0.10061120986938477\n",
      "Loss:  0.051807258278131485\n",
      "29 **********\n",
      "Epoch:  1580.978783607483  fold:  8  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.33921560645103455\n",
      "Eval Loss:  1.5317351818084717\n",
      "Eval Loss:  0.08241850882768631\n",
      "[[1834  239]\n",
      " [ 479  522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.84      2073\n",
      "           1       0.69      0.52      0.59      1001\n",
      "\n",
      "    accuracy                           0.77      3074\n",
      "   macro avg       0.74      0.70      0.71      3074\n",
      "weighted avg       0.76      0.77      0.76      3074\n",
      "\n",
      "acc:  0.7664281067013663\n",
      "pre:  0.6859395532194481\n",
      "rec:  0.5214785214785215\n",
      "ma F1:  0.7144029113374357\n",
      "mi F1:  0.7664281067013663\n",
      "we F1:  0.7569113026713791\n",
      "Eval Loss:  0.29893144965171814\n",
      "Eval Loss:  0.2790772616863251\n",
      "Eval Loss:  0.28260287642478943\n",
      "Eval Loss:  0.3278467357158661\n",
      "Eval Loss:  0.30106300115585327\n",
      "Eval Loss:  0.3043133020401001\n",
      "Eval Loss:  0.34846949577331543\n",
      "Eval Loss:  0.3288089334964752\n",
      "Eval Loss:  0.32816261053085327\n",
      "Eval Loss:  0.2622007429599762\n",
      "Eval Loss:  0.31167492270469666\n",
      "Eval Loss:  0.28347262740135193\n",
      "Eval Loss:  0.319262832403183\n",
      "Eval Loss:  0.33234667778015137\n",
      "Eval Loss:  0.2949521243572235\n",
      "Eval Loss:  0.22526520490646362\n",
      "Eval Loss:  0.30151018500328064\n",
      "Eval Loss:  0.288777619600296\n",
      "Eval Loss:  0.30149513483047485\n",
      "Eval Loss:  0.3431850075721741\n",
      "Eval Loss:  0.19250492751598358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.33671835064888\n",
      "Eval Loss:  0.37365224957466125\n",
      "Eval Loss:  0.19073523581027985\n",
      "Eval Loss:  0.30160850286483765\n",
      "Eval Loss:  0.32343024015426636\n",
      "Eval Loss:  0.23171855509281158\n",
      "Eval Loss:  0.3260328769683838\n",
      "Eval Loss:  0.30497249960899353\n",
      "[[17273   818]\n",
      " [ 2710  9016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91     18091\n",
      "           1       0.92      0.77      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.86      0.87     29817\n",
      "weighted avg       0.89      0.88      0.88     29817\n",
      "\n",
      "acc:  0.881678237247208\n",
      "pre:  0.9168191986983933\n",
      "rec:  0.7688896469384274\n",
      "ma F1:  0.8718509887444068\n",
      "mi F1:  0.881678237247208\n",
      "we F1:  0.8794264322130189\n",
      "29817 466\n",
      "Loss:  0.07894454896450043\n",
      "Loss:  0.06479676067829132\n",
      "Loss:  0.10780957341194153\n",
      "30 **********\n",
      "Epoch:  1659.4778926372528  fold:  8  kers:  32\n",
      "epoch:  31\n",
      "29817 466\n",
      "Loss:  0.07148955762386322\n",
      "Loss:  0.07016361504793167\n",
      "Loss:  0.06575024873018265\n",
      "31 **********\n",
      "Epoch:  1699.9387090206146  fold:  8  kers:  32\n",
      "epoch:  32\n",
      "29817 466\n",
      "Loss:  0.05698566138744354\n",
      "Loss:  0.09144488722085953\n",
      "Loss:  0.08189569413661957\n",
      "32 **********\n",
      "Epoch:  1740.5830342769623  fold:  8  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.37642544507980347\n",
      "Eval Loss:  1.3003809452056885\n",
      "Eval Loss:  0.08386645466089249\n",
      "[[1881  192]\n",
      " [ 439  562]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86      2073\n",
      "           1       0.75      0.56      0.64      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.78      0.73      0.75      3074\n",
      "weighted avg       0.79      0.79      0.79      3074\n",
      "\n",
      "acc:  0.7947299934938191\n",
      "pre:  0.7453580901856764\n",
      "rec:  0.5614385614385614\n",
      "ma F1:  0.7484091175873557\n",
      "mi F1:  0.7947299934938191\n",
      "we F1:  0.7860558036917749\n",
      "Eval Loss:  0.2962763011455536\n",
      "Eval Loss:  0.2660878300666809\n",
      "Eval Loss:  0.23460382223129272\n",
      "Eval Loss:  0.28260454535484314\n",
      "Eval Loss:  0.29369863867759705\n",
      "Eval Loss:  0.2740018963813782\n",
      "Eval Loss:  0.32442188262939453\n",
      "Eval Loss:  0.2829623520374298\n",
      "Eval Loss:  0.3105899393558502\n",
      "Eval Loss:  0.22523905336856842\n",
      "Eval Loss:  0.2875572741031647\n",
      "Eval Loss:  0.2699112892150879\n",
      "Eval Loss:  0.3181764483451843\n",
      "Eval Loss:  0.2948446273803711\n",
      "Eval Loss:  0.278366357088089\n",
      "Eval Loss:  0.22028207778930664\n",
      "Eval Loss:  0.2888425886631012\n",
      "Eval Loss:  0.2849864959716797\n",
      "Eval Loss:  0.29930800199508667\n",
      "Eval Loss:  0.3116723299026489\n",
      "Eval Loss:  0.17625422775745392\n",
      "Eval Loss:  0.333543986082077\n",
      "Eval Loss:  0.32825323939323425\n",
      "Eval Loss:  0.17718908190727234\n",
      "Eval Loss:  0.2702488601207733\n",
      "Eval Loss:  0.27450111508369446\n",
      "Eval Loss:  0.21680046617984772\n",
      "Eval Loss:  0.3091805577278137\n",
      "Eval Loss:  0.28001824021339417\n",
      "[[17208   883]\n",
      " [ 2415  9311]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18091\n",
      "           1       0.91      0.79      0.85     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.87      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8893919576080759\n",
      "pre:  0.9133804198548165\n",
      "rec:  0.7940474159986355\n",
      "ma F1:  0.8810480817207031\n",
      "mi F1:  0.8893919576080759\n",
      "we F1:  0.8877732647045107\n",
      "29817 466\n",
      "Loss:  0.07478111982345581\n",
      "Loss:  0.03995637968182564\n",
      "Loss:  0.084058977663517\n",
      "33 **********\n",
      "Epoch:  1819.110069513321  fold:  8  kers:  32\n",
      "epoch:  34\n",
      "29817 466\n",
      "Loss:  0.0600510910153389\n",
      "Loss:  0.06844107061624527\n",
      "Loss:  0.06238524615764618\n",
      "34 **********\n",
      "Epoch:  1859.648677110672  fold:  8  kers:  32\n",
      "epoch:  35\n",
      "29817 466\n",
      "Loss:  0.05765027180314064\n",
      "Loss:  0.05859775096178055\n",
      "Loss:  0.0600915253162384\n",
      "35 **********\n",
      "Epoch:  1900.1673381328583  fold:  8  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.4051266610622406\n",
      "Eval Loss:  1.2239162921905518\n",
      "Eval Loss:  0.07924863696098328\n",
      "[[1835  238]\n",
      " [ 401  600]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      2073\n",
      "           1       0.72      0.60      0.65      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.77      0.74      0.75      3074\n",
      "weighted avg       0.79      0.79      0.79      3074\n",
      "\n",
      "acc:  0.7921275211450879\n",
      "pre:  0.7159904534606205\n",
      "rec:  0.5994005994005994\n",
      "ma F1:  0.7521171401562117\n",
      "mi F1:  0.7921275211450879\n",
      "we F1:  0.7868467987959487\n",
      "Eval Loss:  0.28642597794532776\n",
      "Eval Loss:  0.26583677530288696\n",
      "Eval Loss:  0.2195030301809311\n",
      "Eval Loss:  0.273386687040329\n",
      "Eval Loss:  0.30131426453590393\n",
      "Eval Loss:  0.26615333557128906\n",
      "Eval Loss:  0.2997850179672241\n",
      "Eval Loss:  0.2779499888420105\n",
      "Eval Loss:  0.3037664294242859\n",
      "Eval Loss:  0.1990458071231842\n",
      "Eval Loss:  0.2546469569206238\n",
      "Eval Loss:  0.260943204164505\n",
      "Eval Loss:  0.28750818967819214\n",
      "Eval Loss:  0.2834271490573883\n",
      "Eval Loss:  0.2596483826637268\n",
      "Eval Loss:  0.1748938262462616\n",
      "Eval Loss:  0.28697630763053894\n",
      "Eval Loss:  0.2939721345901489\n",
      "Eval Loss:  0.2985132336616516\n",
      "Eval Loss:  0.31235063076019287\n",
      "Eval Loss:  0.1685040146112442\n",
      "Eval Loss:  0.29501470923423767\n",
      "Eval Loss:  0.31644538044929504\n",
      "Eval Loss:  0.1662818044424057\n",
      "Eval Loss:  0.2402396947145462\n",
      "Eval Loss:  0.2598298192024231\n",
      "Eval Loss:  0.2005348801612854\n",
      "Eval Loss:  0.29704374074935913\n",
      "Eval Loss:  0.2642230689525604\n",
      "[[16922  1169]\n",
      " [ 1949  9777]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18091\n",
      "           1       0.89      0.83      0.86     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.89      0.88      0.89     29817\n",
      "weighted avg       0.90      0.90      0.89     29817\n",
      "\n",
      "acc:  0.8954287822383205\n",
      "pre:  0.8932029965284122\n",
      "rec:  0.8337881630564558\n",
      "ma F1:  0.8890583142724506\n",
      "mi F1:  0.8954287822383205\n",
      "we F1:  0.8947333357703878\n",
      "29817 466\n",
      "Loss:  0.047115594148635864\n",
      "Loss:  0.07116183638572693\n",
      "Loss:  0.06637518852949142\n",
      "36 **********\n",
      "Epoch:  1978.629546403885  fold:  8  kers:  32\n",
      "epoch:  37\n",
      "29817 466\n",
      "Loss:  0.06928052753210068\n",
      "Loss:  0.0674746036529541\n",
      "Loss:  0.05455650016665459\n",
      "37 **********\n",
      "Epoch:  2019.1581809520721  fold:  8  kers:  32\n",
      "epoch:  38\n",
      "29817 466\n",
      "Loss:  0.08152887225151062\n",
      "Loss:  0.056195806711912155\n",
      "Loss:  0.07429394870996475\n",
      "38 **********\n",
      "Epoch:  2061.0770983695984  fold:  8  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.3399607539176941\n",
      "Eval Loss:  1.4011032581329346\n",
      "Eval Loss:  0.07306597381830215\n",
      "[[2000   73]\n",
      " [ 504  497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87      2073\n",
      "           1       0.87      0.50      0.63      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.84      0.73      0.75      3074\n",
      "weighted avg       0.82      0.81      0.80      3074\n",
      "\n",
      "acc:  0.8122966818477554\n",
      "pre:  0.8719298245614036\n",
      "rec:  0.4965034965034965\n",
      "ma F1:  0.7533264529271881\n",
      "mi F1:  0.8122966818477554\n",
      "we F1:  0.795386389988298\n",
      "Eval Loss:  0.3261750638484955\n",
      "Eval Loss:  0.2615991532802582\n",
      "Eval Loss:  0.2660751938819885\n",
      "Eval Loss:  0.30342674255371094\n",
      "Eval Loss:  0.3226628005504608\n",
      "Eval Loss:  0.28785109519958496\n",
      "Eval Loss:  0.3594772219657898\n",
      "Eval Loss:  0.3050777018070221\n",
      "Eval Loss:  0.3207238018512726\n",
      "Eval Loss:  0.24716071784496307\n",
      "Eval Loss:  0.29676857590675354\n",
      "Eval Loss:  0.2696334421634674\n",
      "Eval Loss:  0.35816964507102966\n",
      "Eval Loss:  0.2942003607749939\n",
      "Eval Loss:  0.2817061245441437\n",
      "Eval Loss:  0.23876579105854034\n",
      "Eval Loss:  0.2948068380355835\n",
      "Eval Loss:  0.2934429943561554\n",
      "Eval Loss:  0.3065474331378937\n",
      "Eval Loss:  0.3456363081932068\n",
      "Eval Loss:  0.1945241093635559\n",
      "Eval Loss:  0.37444037199020386\n",
      "Eval Loss:  0.33087286353111267\n",
      "Eval Loss:  0.18798254430294037\n",
      "Eval Loss:  0.28981152176856995\n",
      "Eval Loss:  0.2809710204601288\n",
      "Eval Loss:  0.22776523232460022\n",
      "Eval Loss:  0.3233197331428528\n",
      "Eval Loss:  0.2823062241077423\n",
      "[[17393   698]\n",
      " [ 2744  8982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18091\n",
      "           1       0.93      0.77      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.90      0.86      0.87     29817\n",
      "weighted avg       0.89      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8845624979038803\n",
      "pre:  0.927892561983471\n",
      "rec:  0.7659901074535221\n",
      "ma F1:  0.8745826232140832\n",
      "mi F1:  0.8845624979038803\n",
      "we F1:  0.8821348646123188\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09000716358423233\n",
      "Loss:  0.08716876059770584\n",
      "Loss:  0.09042911231517792\n",
      "39 **********\n",
      "Epoch:  2142.1742606163025  fold:  8  kers:  32\n",
      "epoch:  40\n",
      "29817 466\n",
      "Loss:  0.08458680659532547\n",
      "Loss:  0.06174501031637192\n",
      "Loss:  0.06856139749288559\n",
      "40 **********\n",
      "Epoch:  2182.711871623993  fold:  8  kers:  32\n",
      "epoch:  41\n",
      "29817 466\n",
      "Loss:  0.056432388722896576\n",
      "Loss:  0.07995700091123581\n",
      "Loss:  0.07912859320640564\n",
      "41 **********\n",
      "Epoch:  2223.111849784851  fold:  8  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.4945870637893677\n",
      "Eval Loss:  1.147483468055725\n",
      "Eval Loss:  0.08401502668857574\n",
      "[[1779  294]\n",
      " [ 318  683]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      2073\n",
      "           1       0.70      0.68      0.69      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.77      0.77      0.77      3074\n",
      "weighted avg       0.80      0.80      0.80      3074\n",
      "\n",
      "acc:  0.8009108653220559\n",
      "pre:  0.6990788126919141\n",
      "rec:  0.6823176823176823\n",
      "ma F1:  0.7719169861279833\n",
      "mi F1:  0.8009108653220559\n",
      "we F1:  0.8002759628579521\n",
      "Eval Loss:  0.27971741557121277\n",
      "Eval Loss:  0.26169124245643616\n",
      "Eval Loss:  0.21587151288986206\n",
      "Eval Loss:  0.2660319209098816\n",
      "Eval Loss:  0.3159494400024414\n",
      "Eval Loss:  0.26056745648384094\n",
      "Eval Loss:  0.2784923315048218\n",
      "Eval Loss:  0.2538626194000244\n",
      "Eval Loss:  0.31065577268600464\n",
      "Eval Loss:  0.17477619647979736\n",
      "Eval Loss:  0.23525497317314148\n",
      "Eval Loss:  0.24715325236320496\n",
      "Eval Loss:  0.26179614663124084\n",
      "Eval Loss:  0.2515057921409607\n",
      "Eval Loss:  0.2605488896369934\n",
      "Eval Loss:  0.16440436244010925\n",
      "Eval Loss:  0.26613596081733704\n",
      "Eval Loss:  0.3034417927265167\n",
      "Eval Loss:  0.27502989768981934\n",
      "Eval Loss:  0.3072526156902313\n",
      "Eval Loss:  0.18152689933776855\n",
      "Eval Loss:  0.2772452235221863\n",
      "Eval Loss:  0.30705100297927856\n",
      "Eval Loss:  0.16325202584266663\n",
      "Eval Loss:  0.2461611032485962\n",
      "Eval Loss:  0.2544698119163513\n",
      "Eval Loss:  0.20527291297912598\n",
      "Eval Loss:  0.27697494626045227\n",
      "Eval Loss:  0.2550104856491089\n",
      "[[16674  1417]\n",
      " [ 1640 10086]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     18091\n",
      "           1       0.88      0.86      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.89      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8974745950296811\n",
      "pre:  0.8768147439798314\n",
      "rec:  0.8601398601398601\n",
      "ma F1:  0.8922126400862568\n",
      "mi F1:  0.8974745950296811\n",
      "we F1:  0.897296480889975\n",
      "29817 466\n",
      "Loss:  0.05591018125414848\n",
      "Loss:  0.04480552673339844\n",
      "Loss:  0.03840188682079315\n",
      "42 **********\n",
      "Epoch:  2301.472329854965  fold:  8  kers:  32\n",
      "epoch:  43\n",
      "29817 466\n",
      "Loss:  0.05549350380897522\n",
      "Loss:  0.07171542942523956\n",
      "Loss:  0.06862420588731766\n",
      "43 **********\n",
      "Epoch:  2341.8792901039124  fold:  8  kers:  32\n",
      "epoch:  44\n",
      "29817 466\n",
      "Loss:  0.04898879677057266\n",
      "Loss:  0.04917396232485771\n",
      "Loss:  0.06361864507198334\n",
      "44 **********\n",
      "Epoch:  2382.131663799286  fold:  8  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.3588283061981201\n",
      "Eval Loss:  1.0873051881790161\n",
      "Eval Loss:  0.07949153333902359\n",
      "[[1953  120]\n",
      " [ 373  628]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      2073\n",
      "           1       0.84      0.63      0.72      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.84      0.78      0.80      3074\n",
      "weighted avg       0.84      0.84      0.83      3074\n",
      "\n",
      "acc:  0.839622641509434\n",
      "pre:  0.839572192513369\n",
      "rec:  0.6273726273726273\n",
      "ma F1:  0.8030268587213347\n",
      "mi F1:  0.839622641509434\n",
      "we F1:  0.83263491845631\n",
      "update!  Acc:  0.839622641509434\n",
      "Eval Loss:  0.2993789315223694\n",
      "Eval Loss:  0.2391791194677353\n",
      "Eval Loss:  0.2095460146665573\n",
      "Eval Loss:  0.26689469814300537\n",
      "Eval Loss:  0.31932497024536133\n",
      "Eval Loss:  0.24244649708271027\n",
      "Eval Loss:  0.29955488443374634\n",
      "Eval Loss:  0.24749372899532318\n",
      "Eval Loss:  0.3064764440059662\n",
      "Eval Loss:  0.18442149460315704\n",
      "Eval Loss:  0.24270744621753693\n",
      "Eval Loss:  0.24038895964622498\n",
      "Eval Loss:  0.3122052252292633\n",
      "Eval Loss:  0.24537013471126556\n",
      "Eval Loss:  0.24537530541419983\n",
      "Eval Loss:  0.1794869303703308\n",
      "Eval Loss:  0.264785498380661\n",
      "Eval Loss:  0.30344632267951965\n",
      "Eval Loss:  0.2808711528778076\n",
      "Eval Loss:  0.29219433665275574\n",
      "Eval Loss:  0.17584139108657837\n",
      "Eval Loss:  0.3081512153148651\n",
      "Eval Loss:  0.3004359304904938\n",
      "Eval Loss:  0.15740039944648743\n",
      "Eval Loss:  0.2591196894645691\n",
      "Eval Loss:  0.2398570477962494\n",
      "Eval Loss:  0.21181218326091766\n",
      "Eval Loss:  0.28322163224220276\n",
      "Eval Loss:  0.2668832838535309\n",
      "[[16956  1135]\n",
      " [ 1909  9817]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18091\n",
      "           1       0.90      0.84      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8979105879196432\n",
      "pre:  0.8963659605551497\n",
      "rec:  0.8371993859798738\n",
      "ma F1:  0.891702387093001\n",
      "mi F1:  0.8979105879196432\n",
      "we F1:  0.8972375038126504\n",
      "29817 466\n",
      "Loss:  0.05547396466135979\n",
      "Loss:  0.06926121562719345\n",
      "Loss:  0.06413990259170532\n",
      "45 **********\n",
      "Epoch:  2460.977844953537  fold:  8  kers:  32\n",
      "epoch:  46\n",
      "29817 466\n",
      "Loss:  0.044641222804784775\n",
      "Loss:  0.04824965447187424\n",
      "Loss:  0.05966558679938316\n",
      "46 **********\n",
      "Epoch:  2501.4316794872284  fold:  8  kers:  32\n",
      "epoch:  47\n",
      "29817 466\n",
      "Loss:  0.08013539016246796\n",
      "Loss:  0.07677379995584488\n",
      "Loss:  0.07320277392864227\n",
      "47 **********\n",
      "Epoch:  2541.8785333633423  fold:  8  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.4446604549884796\n",
      "Eval Loss:  1.1919643878936768\n",
      "Eval Loss:  0.07445959001779556\n",
      "[[1920  153]\n",
      " [ 410  591]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      2073\n",
      "           1       0.79      0.59      0.68      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.81      0.76      0.77      3074\n",
      "weighted avg       0.81      0.82      0.81      3074\n",
      "\n",
      "acc:  0.8168510084580352\n",
      "pre:  0.7943548387096774\n",
      "rec:  0.5904095904095904\n",
      "ma F1:  0.7747482668433283\n",
      "mi F1:  0.8168510084580352\n",
      "we F1:  0.808709244278216\n",
      "Eval Loss:  0.28465691208839417\n",
      "Eval Loss:  0.23164765536785126\n",
      "Eval Loss:  0.2202722132205963\n",
      "Eval Loss:  0.26236653327941895\n",
      "Eval Loss:  0.28262844681739807\n",
      "Eval Loss:  0.25002288818359375\n",
      "Eval Loss:  0.3219667673110962\n",
      "Eval Loss:  0.2649814188480377\n",
      "Eval Loss:  0.2945220172405243\n",
      "Eval Loss:  0.17879055440425873\n",
      "Eval Loss:  0.22703580558300018\n",
      "Eval Loss:  0.24139444530010223\n",
      "Eval Loss:  0.3036760687828064\n",
      "Eval Loss:  0.23553845286369324\n",
      "Eval Loss:  0.24078521132469177\n",
      "Eval Loss:  0.18481023609638214\n",
      "Eval Loss:  0.25202515721321106\n",
      "Eval Loss:  0.2954941689968109\n",
      "Eval Loss:  0.2761932909488678\n",
      "Eval Loss:  0.30221039056777954\n",
      "Eval Loss:  0.1723637580871582\n",
      "Eval Loss:  0.315566748380661\n",
      "Eval Loss:  0.3068324029445648\n",
      "Eval Loss:  0.15164746344089508\n",
      "Eval Loss:  0.26094844937324524\n",
      "Eval Loss:  0.24335187673568726\n",
      "Eval Loss:  0.19792890548706055\n",
      "Eval Loss:  0.27002477645874023\n",
      "Eval Loss:  0.24937723577022552\n",
      "[[17087  1004]\n",
      " [ 1986  9740]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18091\n",
      "           1       0.91      0.83      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8997216353087165\n",
      "pre:  0.9065524944154877\n",
      "rec:  0.830632781852294\n",
      "ma F1:  0.8932397431857265\n",
      "mi F1:  0.8997216353087165\n",
      "we F1:  0.8988552656252027\n",
      "29817 466\n",
      "Loss:  0.06867942214012146\n",
      "Loss:  0.06918655335903168\n",
      "Loss:  0.05208104848861694\n",
      "48 **********\n",
      "Epoch:  2620.300847530365  fold:  8  kers:  32\n",
      "epoch:  49\n",
      "29817 466\n",
      "Loss:  0.05534205213189125\n",
      "Loss:  0.05261480063199997\n",
      "Loss:  0.04456281289458275\n",
      "49 **********\n",
      "Epoch:  2660.582143306732  fold:  8  kers:  32\n",
      "epoch:  50\n",
      "29817 466\n",
      "Loss:  0.09124188125133514\n",
      "Loss:  0.0648702085018158\n",
      "Loss:  0.0517011396586895\n",
      "50 **********\n",
      "Epoch:  2701.022015094757  fold:  8  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.5807161331176758\n",
      "Eval Loss:  0.9873945713043213\n",
      "Eval Loss:  0.0920896977186203\n",
      "[[1747  326]\n",
      " [ 267  734]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85      2073\n",
      "           1       0.69      0.73      0.71      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.78      0.79      0.78      3074\n",
      "weighted avg       0.81      0.81      0.81      3074\n",
      "\n",
      "acc:  0.8070917371502928\n",
      "pre:  0.6924528301886792\n",
      "rec:  0.7332667332667333\n",
      "ma F1:  0.7835906966230721\n",
      "mi F1:  0.8070917371502927\n",
      "we F1:  0.8084605045650075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2972568869590759\n",
      "Eval Loss:  0.2729044258594513\n",
      "Eval Loss:  0.20916804671287537\n",
      "Eval Loss:  0.25419414043426514\n",
      "Eval Loss:  0.32368624210357666\n",
      "Eval Loss:  0.2617414891719818\n",
      "Eval Loss:  0.2785322964191437\n",
      "Eval Loss:  0.24725988507270813\n",
      "Eval Loss:  0.29607638716697693\n",
      "Eval Loss:  0.16446241736412048\n",
      "Eval Loss:  0.22913867235183716\n",
      "Eval Loss:  0.23458562791347504\n",
      "Eval Loss:  0.2589762508869171\n",
      "Eval Loss:  0.2204880714416504\n",
      "Eval Loss:  0.26413995027542114\n",
      "Eval Loss:  0.15143772959709167\n",
      "Eval Loss:  0.2706441879272461\n",
      "Eval Loss:  0.32583823800086975\n",
      "Eval Loss:  0.27192422747612\n",
      "Eval Loss:  0.2816621661186218\n",
      "Eval Loss:  0.18492579460144043\n",
      "Eval Loss:  0.2659026086330414\n",
      "Eval Loss:  0.2955181896686554\n",
      "Eval Loss:  0.16981543600559235\n",
      "Eval Loss:  0.22444625198841095\n",
      "Eval Loss:  0.2650230824947357\n",
      "Eval Loss:  0.20123615860939026\n",
      "Eval Loss:  0.2776359021663666\n",
      "Eval Loss:  0.26501762866973877\n",
      "[[16312  1779]\n",
      " [ 1303 10423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91     18091\n",
      "           1       0.85      0.89      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.89      0.90      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8966361471643693\n",
      "pre:  0.8542042288149484\n",
      "rec:  0.8888794132696571\n",
      "ma F1:  0.8924404493938883\n",
      "mi F1:  0.8966361471643693\n",
      "we F1:  0.8969752798080693\n",
      "29817 466\n",
      "Loss:  0.04957427829504013\n",
      "Loss:  0.0731610506772995\n",
      "Loss:  0.06912167370319366\n",
      "51 **********\n",
      "Epoch:  2779.4463245868683  fold:  8  kers:  32\n",
      "epoch:  52\n",
      "29817 466\n",
      "Loss:  0.053868651390075684\n",
      "Loss:  0.0600302554666996\n",
      "Loss:  0.0991913378238678\n",
      "52 **********\n",
      "Epoch:  2819.8413166999817  fold:  8  kers:  32\n",
      "epoch:  53\n",
      "29817 466\n",
      "Loss:  0.06737861782312393\n",
      "Loss:  0.07098585367202759\n",
      "Loss:  0.07338780164718628\n",
      "53 **********\n",
      "Epoch:  2860.157520055771  fold:  8  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.32211944460868835\n",
      "Eval Loss:  1.1540977954864502\n",
      "Eval Loss:  0.07498139888048172\n",
      "[[1991   82]\n",
      " [ 415  586]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      2073\n",
      "           1       0.88      0.59      0.70      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.85      0.77      0.80      3074\n",
      "weighted avg       0.84      0.84      0.83      3074\n",
      "\n",
      "acc:  0.8383214053350683\n",
      "pre:  0.8772455089820359\n",
      "rec:  0.5854145854145855\n",
      "ma F1:  0.7956273139908214\n",
      "mi F1:  0.8383214053350683\n",
      "we F1:  0.8282024498776774\n",
      "Eval Loss:  0.29545971751213074\n",
      "Eval Loss:  0.240521639585495\n",
      "Eval Loss:  0.21716725826263428\n",
      "Eval Loss:  0.25594452023506165\n",
      "Eval Loss:  0.3193296492099762\n",
      "Eval Loss:  0.24118149280548096\n",
      "Eval Loss:  0.3291400074958801\n",
      "Eval Loss:  0.2514287531375885\n",
      "Eval Loss:  0.3057628273963928\n",
      "Eval Loss:  0.20664384961128235\n",
      "Eval Loss:  0.2646040916442871\n",
      "Eval Loss:  0.25545141100883484\n",
      "Eval Loss:  0.3519001007080078\n",
      "Eval Loss:  0.21880993247032166\n",
      "Eval Loss:  0.234612375497818\n",
      "Eval Loss:  0.2112175077199936\n",
      "Eval Loss:  0.27740511298179626\n",
      "Eval Loss:  0.3042828440666199\n",
      "Eval Loss:  0.28701117634773254\n",
      "Eval Loss:  0.28908851742744446\n",
      "Eval Loss:  0.1920998990535736\n",
      "Eval Loss:  0.3470441699028015\n",
      "Eval Loss:  0.2862807810306549\n",
      "Eval Loss:  0.16967110335826874\n",
      "Eval Loss:  0.25261425971984863\n",
      "Eval Loss:  0.2458648979663849\n",
      "Eval Loss:  0.22510483860969543\n",
      "Eval Loss:  0.30053532123565674\n",
      "Eval Loss:  0.2793881297111511\n",
      "[[17163   928]\n",
      " [ 2217  9509]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18091\n",
      "           1       0.91      0.81      0.86     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.88      0.89     29817\n",
      "weighted avg       0.90      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8945232585437838\n",
      "pre:  0.9110855609849574\n",
      "rec:  0.8109329694695548\n",
      "ma F1:  0.8870826271481889\n",
      "mi F1:  0.8945232585437838\n",
      "we F1:  0.8932701916677814\n",
      "29817 466\n",
      "Loss:  0.05047791078686714\n",
      "Loss:  0.0574381947517395\n",
      "Loss:  0.05746311694383621\n",
      "54 **********\n",
      "Epoch:  2938.6207246780396  fold:  8  kers:  32\n",
      "epoch:  55\n",
      "29817 466\n",
      "Loss:  0.0917975977063179\n",
      "Loss:  0.10912652313709259\n",
      "Loss:  0.044688839465379715\n",
      "55 **********\n",
      "Epoch:  2978.896036863327  fold:  8  kers:  32\n",
      "epoch:  56\n",
      "29817 466\n",
      "Loss:  0.050913821905851364\n",
      "Loss:  0.04373599588871002\n",
      "Loss:  0.04058535024523735\n",
      "56 **********\n",
      "Epoch:  3019.3718128204346  fold:  8  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.418211966753006\n",
      "Eval Loss:  1.0325621366500854\n",
      "Eval Loss:  0.07371164113283157\n",
      "[[1943  130]\n",
      " [ 341  660]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      2073\n",
      "           1       0.84      0.66      0.74      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.80      0.81      3074\n",
      "weighted avg       0.85      0.85      0.84      3074\n",
      "\n",
      "acc:  0.846779440468445\n",
      "pre:  0.8354430379746836\n",
      "rec:  0.6593406593406593\n",
      "ma F1:  0.8144582602400726\n",
      "mi F1:  0.846779440468445\n",
      "we F1:  0.8414639540863822\n",
      "update!  Acc:  0.846779440468445\n",
      "Eval Loss:  0.2857065200805664\n",
      "Eval Loss:  0.22837001085281372\n",
      "Eval Loss:  0.18730320036411285\n",
      "Eval Loss:  0.23237070441246033\n",
      "Eval Loss:  0.30755650997161865\n",
      "Eval Loss:  0.22973228991031647\n",
      "Eval Loss:  0.28883469104766846\n",
      "Eval Loss:  0.24253083765506744\n",
      "Eval Loss:  0.28441154956817627\n",
      "Eval Loss:  0.1769336760044098\n",
      "Eval Loss:  0.22914880514144897\n",
      "Eval Loss:  0.23558339476585388\n",
      "Eval Loss:  0.2819523811340332\n",
      "Eval Loss:  0.2072300910949707\n",
      "Eval Loss:  0.22674869000911713\n",
      "Eval Loss:  0.16480138897895813\n",
      "Eval Loss:  0.2561497092247009\n",
      "Eval Loss:  0.30227240920066833\n",
      "Eval Loss:  0.2478519082069397\n",
      "Eval Loss:  0.2573644816875458\n",
      "Eval Loss:  0.1737593412399292\n",
      "Eval Loss:  0.29270902276039124\n",
      "Eval Loss:  0.27727922797203064\n",
      "Eval Loss:  0.14789514243602753\n",
      "Eval Loss:  0.2362598180770874\n",
      "Eval Loss:  0.22862036526203156\n",
      "Eval Loss:  0.20042450726032257\n",
      "Eval Loss:  0.26790088415145874\n",
      "Eval Loss:  0.2719782590866089\n",
      "[[16850  1241]\n",
      " [ 1600 10126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18091\n",
      "           1       0.89      0.86      0.88     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.90      0.90     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.9047187845859744\n",
      "pre:  0.8908243160024633\n",
      "rec:  0.8635510830632782\n",
      "ma F1:  0.8996137120866468\n",
      "mi F1:  0.9047187845859744\n",
      "we F1:  0.9044462204831698\n",
      "29817 466\n",
      "Loss:  0.07462988793849945\n",
      "Loss:  0.10308375954627991\n",
      "Loss:  0.06976539641618729\n",
      "57 **********\n",
      "Epoch:  3099.9344050884247  fold:  8  kers:  32\n",
      "epoch:  58\n",
      "29817 466\n",
      "Loss:  0.04268784075975418\n",
      "Loss:  0.07892443984746933\n",
      "Loss:  0.050278373062610626\n",
      "58 **********\n",
      "Epoch:  3140.41117811203  fold:  8  kers:  32\n",
      "epoch:  59\n",
      "29817 466\n",
      "Loss:  0.061379048973321915\n",
      "Loss:  0.043898627161979675\n",
      "Loss:  0.07146772742271423\n",
      "59 **********\n",
      "Epoch:  3180.869999885559  fold:  8  kers:  32\n",
      "Eval Loss:  0.40473493933677673\n",
      "Eval Loss:  1.1608154773712158\n",
      "Eval Loss:  0.08261577785015106\n",
      "[[1978   95]\n",
      " [ 406  595]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      2073\n",
      "           1       0.86      0.59      0.70      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.85      0.77      0.80      3074\n",
      "weighted avg       0.84      0.84      0.83      3074\n",
      "\n",
      "acc:  0.8370201691607027\n",
      "pre:  0.8623188405797102\n",
      "rec:  0.5944055944055944\n",
      "ma F1:  0.7956590785967548\n",
      "mi F1:  0.8370201691607027\n",
      "we F1:  0.8277191574720636\n",
      "update!  Acc:  0.846779440468445\n",
      "Epoch:  3184.411529779434  fold:  8  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29483 3408\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29483 461\n",
      "Loss:  0.1714957058429718\n",
      "Loss:  0.1684591919183731\n",
      "Loss:  0.1543387919664383\n",
      "0 **********\n",
      "Epoch:  52.50561046600342  fold:  9  kers:  32\n",
      "epoch:  1\n",
      "29483 461\n",
      "Loss:  0.14072570204734802\n",
      "Loss:  0.14352916181087494\n",
      "Loss:  0.12248067557811737\n",
      "1 **********\n",
      "Epoch:  92.70811700820923  fold:  9  kers:  32\n",
      "epoch:  2\n",
      "29483 461\n",
      "Loss:  0.11106368154287338\n",
      "Loss:  0.1093422919511795\n",
      "Loss:  0.14534500241279602\n",
      "2 **********\n",
      "Epoch:  132.78595757484436  fold:  9  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.2732778489589691\n",
      "Eval Loss:  0.7347452044487\n",
      "Eval Loss:  0.33621373772621155\n",
      "[[1382  360]\n",
      " [ 289 1377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1742\n",
      "           1       0.79      0.83      0.81      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.81      0.81      0.81      3408\n",
      "weighted avg       0.81      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8095657276995305\n",
      "pre:  0.7927461139896373\n",
      "rec:  0.826530612244898\n",
      "ma F1:  0.8095653177910702\n",
      "mi F1:  0.8095657276995305\n",
      "we F1:  0.8095715483996664\n",
      "update!  Acc:  0.8095657276995305\n",
      "Eval Loss:  0.4535103440284729\n",
      "Eval Loss:  0.5061354637145996\n",
      "Eval Loss:  0.4953520596027374\n",
      "Eval Loss:  0.5249791145324707\n",
      "Eval Loss:  0.40636324882507324\n",
      "Eval Loss:  0.4964659810066223\n",
      "Eval Loss:  0.38993990421295166\n",
      "Eval Loss:  0.4510546922683716\n",
      "Eval Loss:  0.4309254586696625\n",
      "Eval Loss:  0.3304539918899536\n",
      "Eval Loss:  0.4215709865093231\n",
      "Eval Loss:  0.4285927414894104\n",
      "Eval Loss:  0.4771706759929657\n",
      "Eval Loss:  0.5001989006996155\n",
      "Eval Loss:  0.4129868447780609\n",
      "Eval Loss:  0.4733729660511017\n",
      "Eval Loss:  0.44962552189826965\n",
      "Eval Loss:  0.4242166578769684\n",
      "Eval Loss:  0.4076775312423706\n",
      "Eval Loss:  0.5034183263778687\n",
      "Eval Loss:  0.474439799785614\n",
      "Eval Loss:  0.4166865944862366\n",
      "Eval Loss:  0.48855483531951904\n",
      "Eval Loss:  0.4283427894115448\n",
      "Eval Loss:  0.3695981502532959\n",
      "Eval Loss:  0.49404552578926086\n",
      "Eval Loss:  0.45157405734062195\n",
      "Eval Loss:  0.4997938573360443\n",
      "[[14557  3865]\n",
      " [ 2352  8709]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82     18422\n",
      "           1       0.69      0.79      0.74     11061\n",
      "\n",
      "    accuracy                           0.79     29483\n",
      "   macro avg       0.78      0.79      0.78     29483\n",
      "weighted avg       0.80      0.79      0.79     29483\n",
      "\n",
      "acc:  0.789132720550826\n",
      "pre:  0.6926196914267536\n",
      "rec:  0.7873609981014374\n",
      "ma F1:  0.7804967254674053\n",
      "mi F1:  0.789132720550826\n",
      "we F1:  0.7913670332322924\n",
      "29483 461\n",
      "Loss:  0.12204565107822418\n",
      "Loss:  0.10870871692895889\n",
      "Loss:  0.10333289951086044\n",
      "3 **********\n",
      "Epoch:  210.89211750030518  fold:  9  kers:  32\n",
      "epoch:  4\n",
      "29483 461\n",
      "Loss:  0.10019761323928833\n",
      "Loss:  0.12797507643699646\n",
      "Loss:  0.13010962307453156\n",
      "4 **********\n",
      "Epoch:  250.9440267086029  fold:  9  kers:  32\n",
      "epoch:  5\n",
      "29483 461\n",
      "Loss:  0.11134349554777145\n",
      "Loss:  0.12432458251714706\n",
      "Loss:  0.08615144342184067\n",
      "5 **********\n",
      "Epoch:  291.08270382881165  fold:  9  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.14174342155456543\n",
      "Eval Loss:  1.46294367313385\n",
      "Eval Loss:  0.29555800557136536\n",
      "[[1626  116]\n",
      " [ 545 1121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      1742\n",
      "           1       0.91      0.67      0.77      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.83      0.80      0.80      3408\n",
      "weighted avg       0.83      0.81      0.80      3408\n",
      "\n",
      "acc:  0.8060446009389671\n",
      "pre:  0.9062247372675829\n",
      "rec:  0.6728691476590636\n",
      "ma F1:  0.8016902067082714\n",
      "mi F1:  0.8060446009389671\n",
      "we F1:  0.802345521483584\n",
      "Eval Loss:  0.3654547929763794\n",
      "Eval Loss:  0.43507176637649536\n",
      "Eval Loss:  0.4610164761543274\n",
      "Eval Loss:  0.5390876531600952\n",
      "Eval Loss:  0.3594082295894623\n",
      "Eval Loss:  0.47508755326271057\n",
      "Eval Loss:  0.3489498198032379\n",
      "Eval Loss:  0.46158382296562195\n",
      "Eval Loss:  0.3282281458377838\n",
      "Eval Loss:  0.25378596782684326\n",
      "Eval Loss:  0.3952833414077759\n",
      "Eval Loss:  0.3212760090827942\n",
      "Eval Loss:  0.4339049458503723\n",
      "Eval Loss:  0.47714513540267944\n",
      "Eval Loss:  0.37392523884773254\n",
      "Eval Loss:  0.4446907043457031\n",
      "Eval Loss:  0.3878605365753174\n",
      "Eval Loss:  0.3437599241733551\n",
      "Eval Loss:  0.3380431532859802\n",
      "Eval Loss:  0.4230819046497345\n",
      "Eval Loss:  0.44866931438446045\n",
      "Eval Loss:  0.4521489143371582\n",
      "Eval Loss:  0.4432562291622162\n",
      "Eval Loss:  0.32749709486961365\n",
      "Eval Loss:  0.3282737731933594\n",
      "Eval Loss:  0.4149262011051178\n",
      "Eval Loss:  0.37991902232170105\n",
      "Eval Loss:  0.48160320520401\n",
      "[[17048  1374]\n",
      " [ 3633  7428]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87     18422\n",
      "           1       0.84      0.67      0.75     11061\n",
      "\n",
      "    accuracy                           0.83     29483\n",
      "   macro avg       0.83      0.80      0.81     29483\n",
      "weighted avg       0.83      0.83      0.83     29483\n",
      "\n",
      "acc:  0.8301733202184309\n",
      "pre:  0.8438991138377642\n",
      "rec:  0.671548684567399\n",
      "ma F1:  0.8099384164901697\n",
      "mi F1:  0.830173320218431\n",
      "we F1:  0.8254216936568777\n",
      "29483 461\n",
      "Loss:  0.11156351119279861\n",
      "Loss:  0.1062392145395279\n",
      "Loss:  0.07568620890378952\n",
      "6 **********\n",
      "Epoch:  369.11705565452576  fold:  9  kers:  32\n",
      "epoch:  7\n",
      "29483 461\n",
      "Loss:  0.08780889213085175\n",
      "Loss:  0.12641486525535583\n",
      "Loss:  0.07991521060466766\n",
      "7 **********\n",
      "Epoch:  409.2966239452362  fold:  9  kers:  32\n",
      "epoch:  8\n",
      "29483 461\n",
      "Loss:  0.11916365474462509\n",
      "Loss:  0.055703919380903244\n",
      "Loss:  0.07159523665904999\n",
      "8 **********\n",
      "Epoch:  449.37147212028503  fold:  9  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.09177526831626892\n",
      "Eval Loss:  1.321021318435669\n",
      "Eval Loss:  0.1862114667892456\n",
      "[[1528  214]\n",
      " [ 402 1264]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83      1742\n",
      "           1       0.86      0.76      0.80      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.82      0.82      0.82      3408\n",
      "weighted avg       0.82      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8192488262910798\n",
      "pre:  0.8552097428958051\n",
      "rec:  0.758703481392557\n",
      "ma F1:  0.8181576277669677\n",
      "mi F1:  0.8192488262910798\n",
      "we F1:  0.8184717606754242\n",
      "update!  Acc:  0.8192488262910798\n",
      "Eval Loss:  0.39933544397354126\n",
      "Eval Loss:  0.3460855782032013\n",
      "Eval Loss:  0.3769533038139343\n",
      "Eval Loss:  0.4034106731414795\n",
      "Eval Loss:  0.3207661509513855\n",
      "Eval Loss:  0.44479355216026306\n",
      "Eval Loss:  0.29308241605758667\n",
      "Eval Loss:  0.3585599660873413\n",
      "Eval Loss:  0.3347097635269165\n",
      "Eval Loss:  0.2840617299079895\n",
      "Eval Loss:  0.3158123195171356\n",
      "Eval Loss:  0.3853837549686432\n",
      "Eval Loss:  0.33478209376335144\n",
      "Eval Loss:  0.35849007964134216\n",
      "Eval Loss:  0.31897300481796265\n",
      "Eval Loss:  0.3662474751472473\n",
      "Eval Loss:  0.2993910014629364\n",
      "Eval Loss:  0.3642478287220001\n",
      "Eval Loss:  0.3137049973011017\n",
      "Eval Loss:  0.33702337741851807\n",
      "Eval Loss:  0.34867313504219055\n",
      "Eval Loss:  0.35384947061538696\n",
      "Eval Loss:  0.3645092844963074\n",
      "Eval Loss:  0.28436774015426636\n",
      "Eval Loss:  0.28000742197036743\n",
      "Eval Loss:  0.3226543068885803\n",
      "Eval Loss:  0.26691150665283203\n",
      "Eval Loss:  0.30473312735557556\n",
      "[[16038  2384]\n",
      " [ 1915  9146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     18422\n",
      "           1       0.79      0.83      0.81     11061\n",
      "\n",
      "    accuracy                           0.85     29483\n",
      "   macro avg       0.84      0.85      0.85     29483\n",
      "weighted avg       0.86      0.85      0.85     29483\n",
      "\n",
      "acc:  0.8541871587016246\n",
      "pre:  0.793235039028621\n",
      "rec:  0.8268691800018082\n",
      "ma F1:  0.8457587060260747\n",
      "mi F1:  0.8541871587016246\n",
      "we F1:  0.8547607141724363\n",
      "29483 461\n",
      "Loss:  0.0822935625910759\n",
      "Loss:  0.10666956007480621\n",
      "Loss:  0.08809586614370346\n",
      "9 **********\n",
      "Epoch:  527.5484428405762  fold:  9  kers:  32\n",
      "epoch:  10\n",
      "29483 461\n",
      "Loss:  0.12578575313091278\n",
      "Loss:  0.08895283937454224\n",
      "Loss:  0.0747758224606514\n",
      "10 **********\n",
      "Epoch:  567.7090609073639  fold:  9  kers:  32\n",
      "epoch:  11\n",
      "29483 461\n",
      "Loss:  0.07371553778648376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07448618859052658\n",
      "Loss:  0.10143250226974487\n",
      "11 **********\n",
      "Epoch:  607.9564483165741  fold:  9  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.08024517446756363\n",
      "Eval Loss:  1.3441250324249268\n",
      "Eval Loss:  0.19272801280021667\n",
      "[[1567  175]\n",
      " [ 436 1230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84      1742\n",
      "           1       0.88      0.74      0.80      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.83      0.82      0.82      3408\n",
      "weighted avg       0.83      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8207159624413145\n",
      "pre:  0.8754448398576512\n",
      "rec:  0.7382953181272509\n",
      "ma F1:  0.818945569018759\n",
      "mi F1:  0.8207159624413144\n",
      "we F1:  0.8193448268825995\n",
      "update!  Acc:  0.8207159624413145\n",
      "Eval Loss:  0.33903270959854126\n",
      "Eval Loss:  0.3245067894458771\n",
      "Eval Loss:  0.3669547140598297\n",
      "Eval Loss:  0.3861923813819885\n",
      "Eval Loss:  0.3221483826637268\n",
      "Eval Loss:  0.4249260425567627\n",
      "Eval Loss:  0.2933453917503357\n",
      "Eval Loss:  0.34715238213539124\n",
      "Eval Loss:  0.31653648614883423\n",
      "Eval Loss:  0.24888204038143158\n",
      "Eval Loss:  0.2888038158416748\n",
      "Eval Loss:  0.31734761595726013\n",
      "Eval Loss:  0.3131939768791199\n",
      "Eval Loss:  0.3436158299446106\n",
      "Eval Loss:  0.2782818078994751\n",
      "Eval Loss:  0.35752129554748535\n",
      "Eval Loss:  0.2714320421218872\n",
      "Eval Loss:  0.3124854266643524\n",
      "Eval Loss:  0.28287479281425476\n",
      "Eval Loss:  0.3070099651813507\n",
      "Eval Loss:  0.32091444730758667\n",
      "Eval Loss:  0.37234893441200256\n",
      "Eval Loss:  0.34052085876464844\n",
      "Eval Loss:  0.24552606046199799\n",
      "Eval Loss:  0.27513402700424194\n",
      "Eval Loss:  0.2858608663082123\n",
      "Eval Loss:  0.24846205115318298\n",
      "Eval Loss:  0.30762872099876404\n",
      "[[16759  1663]\n",
      " [ 2264  8797]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90     18422\n",
      "           1       0.84      0.80      0.82     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.86      0.85      0.86     29483\n",
      "weighted avg       0.87      0.87      0.87     29483\n",
      "\n",
      "acc:  0.8668045992605908\n",
      "pre:  0.8410133843212237\n",
      "rec:  0.795316879124853\n",
      "ma F1:  0.8563266258287816\n",
      "mi F1:  0.8668045992605908\n",
      "we F1:  0.8660136846621838\n",
      "29483 461\n",
      "Loss:  0.09671653062105179\n",
      "Loss:  0.15462708473205566\n",
      "Loss:  0.09487604349851608\n",
      "12 **********\n",
      "Epoch:  686.3747730255127  fold:  9  kers:  32\n",
      "epoch:  13\n",
      "29483 461\n",
      "Loss:  0.0756593644618988\n",
      "Loss:  0.07961307466030121\n",
      "Loss:  0.0944082960486412\n",
      "13 **********\n",
      "Epoch:  726.4306716918945  fold:  9  kers:  32\n",
      "epoch:  14\n",
      "29483 461\n",
      "Loss:  0.06926847249269485\n",
      "Loss:  0.09319253265857697\n",
      "Loss:  0.0869026929140091\n",
      "14 **********\n",
      "Epoch:  766.3638987541199  fold:  9  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.06865018606185913\n",
      "Eval Loss:  1.4725677967071533\n",
      "Eval Loss:  0.19591571390628815\n",
      "[[1586  156]\n",
      " [ 464 1202]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.84      1742\n",
      "           1       0.89      0.72      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.83      0.82      0.82      3408\n",
      "weighted avg       0.83      0.82      0.82      3408\n",
      "\n",
      "acc:  0.818075117370892\n",
      "pre:  0.8851251840942562\n",
      "rec:  0.7214885954381752\n",
      "ma F1:  0.8157357176344519\n",
      "mi F1:  0.8180751173708921\n",
      "we F1:  0.816198723832289\n",
      "Eval Loss:  0.31570369005203247\n",
      "Eval Loss:  0.31819766759872437\n",
      "Eval Loss:  0.3659471869468689\n",
      "Eval Loss:  0.37253275513648987\n",
      "Eval Loss:  0.31771183013916016\n",
      "Eval Loss:  0.3959856331348419\n",
      "Eval Loss:  0.2995184659957886\n",
      "Eval Loss:  0.34143680334091187\n",
      "Eval Loss:  0.3071135878562927\n",
      "Eval Loss:  0.2448098361492157\n",
      "Eval Loss:  0.28334689140319824\n",
      "Eval Loss:  0.30416762828826904\n",
      "Eval Loss:  0.29563108086586\n",
      "Eval Loss:  0.32959580421447754\n",
      "Eval Loss:  0.2783174514770508\n",
      "Eval Loss:  0.35519281029701233\n",
      "Eval Loss:  0.26460331678390503\n",
      "Eval Loss:  0.3033347725868225\n",
      "Eval Loss:  0.2792827785015106\n",
      "Eval Loss:  0.29569563269615173\n",
      "Eval Loss:  0.2831144332885742\n",
      "Eval Loss:  0.3790738582611084\n",
      "Eval Loss:  0.3347851634025574\n",
      "Eval Loss:  0.24297702312469482\n",
      "Eval Loss:  0.2695297598838806\n",
      "Eval Loss:  0.27113035321235657\n",
      "Eval Loss:  0.24417151510715485\n",
      "Eval Loss:  0.3087674677371979\n",
      "[[16971  1451]\n",
      " [ 2326  8735]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     18422\n",
      "           1       0.86      0.79      0.82     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.87      0.86      0.86     29483\n",
      "weighted avg       0.87      0.87      0.87     29483\n",
      "\n",
      "acc:  0.8718922769053353\n",
      "pre:  0.8575495778519536\n",
      "rec:  0.7897115993129011\n",
      "ma F1:  0.8610492583714926\n",
      "mi F1:  0.8718922769053353\n",
      "we F1:  0.8707403049265698\n",
      "29483 461\n",
      "Loss:  0.09644150733947754\n",
      "Loss:  0.10011424124240875\n",
      "Loss:  0.065681092441082\n",
      "15 **********\n",
      "Epoch:  844.4880108833313  fold:  9  kers:  32\n",
      "epoch:  16\n",
      "29483 461\n",
      "Loss:  0.05383175238966942\n",
      "Loss:  0.07783792912960052\n",
      "Loss:  0.06915931403636932\n",
      "16 **********\n",
      "Epoch:  884.4202399253845  fold:  9  kers:  32\n",
      "epoch:  17\n",
      "29483 461\n",
      "Loss:  0.07120481133460999\n",
      "Loss:  0.0752459168434143\n",
      "Loss:  0.058050237596035004\n",
      "17 **********\n",
      "Epoch:  924.402336359024  fold:  9  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.09109023958444595\n",
      "Eval Loss:  1.1492433547973633\n",
      "Eval Loss:  0.1576143354177475\n",
      "[[1513  229]\n",
      " [ 379 1287]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83      1742\n",
      "           1       0.85      0.77      0.81      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.82      0.82      0.82      3408\n",
      "weighted avg       0.82      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8215962441314554\n",
      "pre:  0.8489445910290238\n",
      "rec:  0.7725090036014406\n",
      "ma F1:  0.8208082267930472\n",
      "mi F1:  0.8215962441314554\n",
      "we F1:  0.8210732237741047\n",
      "update!  Acc:  0.8215962441314554\n",
      "Eval Loss:  0.3658972382545471\n",
      "Eval Loss:  0.2938385605812073\n",
      "Eval Loss:  0.35816603899002075\n",
      "Eval Loss:  0.34487730264663696\n",
      "Eval Loss:  0.3157922625541687\n",
      "Eval Loss:  0.4054917097091675\n",
      "Eval Loss:  0.2909676432609558\n",
      "Eval Loss:  0.322327584028244\n",
      "Eval Loss:  0.30922067165374756\n",
      "Eval Loss:  0.26433229446411133\n",
      "Eval Loss:  0.2668922543525696\n",
      "Eval Loss:  0.3420781195163727\n",
      "Eval Loss:  0.2967852056026459\n",
      "Eval Loss:  0.32058411836624146\n",
      "Eval Loss:  0.2798423171043396\n",
      "Eval Loss:  0.3442367911338806\n",
      "Eval Loss:  0.2746807336807251\n",
      "Eval Loss:  0.34165164828300476\n",
      "Eval Loss:  0.31229260563850403\n",
      "Eval Loss:  0.2924678921699524\n",
      "Eval Loss:  0.2816812992095947\n",
      "Eval Loss:  0.3462250828742981\n",
      "Eval Loss:  0.34592729806900024\n",
      "Eval Loss:  0.2389545738697052\n",
      "Eval Loss:  0.265088826417923\n",
      "Eval Loss:  0.27106523513793945\n",
      "Eval Loss:  0.2543564736843109\n",
      "Eval Loss:  0.2730153501033783\n",
      "[[16145  2277]\n",
      " [ 1690  9371]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89     18422\n",
      "           1       0.80      0.85      0.83     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.85      0.86      0.86     29483\n",
      "weighted avg       0.87      0.87      0.87     29483\n",
      "\n",
      "acc:  0.8654478852219923\n",
      "pre:  0.8045157967032966\n",
      "rec:  0.8472109212548594\n",
      "ma F1:  0.8579490979120217\n",
      "mi F1:  0.8654478852219923\n",
      "we F1:  0.8660976915625523\n",
      "29483 461\n",
      "Loss:  0.08451317995786667\n",
      "Loss:  0.07653932273387909\n",
      "Loss:  0.07005220651626587\n",
      "18 **********\n",
      "Epoch:  1002.3658776283264  fold:  9  kers:  32\n",
      "epoch:  19\n",
      "29483 461\n",
      "Loss:  0.10401549190282822\n",
      "Loss:  0.08649317175149918\n",
      "Loss:  0.0739881619811058\n",
      "19 **********\n",
      "Epoch:  1042.3729066848755  fold:  9  kers:  32\n",
      "epoch:  20\n",
      "29483 461\n",
      "Loss:  0.07926199585199356\n",
      "Loss:  0.08813260495662689\n",
      "Loss:  0.09185005724430084\n",
      "20 **********\n",
      "Epoch:  1082.2782077789307  fold:  9  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.08053404837846756\n",
      "Eval Loss:  1.2000349760055542\n",
      "Eval Loss:  0.14964453876018524\n",
      "[[1532  210]\n",
      " [ 391 1275]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84      1742\n",
      "           1       0.86      0.77      0.81      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.83      0.82      0.82      3408\n",
      "weighted avg       0.83      0.82      0.82      3408\n",
      "\n",
      "acc:  0.823650234741784\n",
      "pre:  0.8585858585858586\n",
      "rec:  0.7653061224489796\n",
      "ma F1:  0.8226416352373896\n",
      "mi F1:  0.823650234741784\n",
      "we F1:  0.8229398981258488\n",
      "update!  Acc:  0.823650234741784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.35240331292152405\n",
      "Eval Loss:  0.28056448698043823\n",
      "Eval Loss:  0.34829455614089966\n",
      "Eval Loss:  0.34751978516578674\n",
      "Eval Loss:  0.2989048659801483\n",
      "Eval Loss:  0.3876599669456482\n",
      "Eval Loss:  0.2747504711151123\n",
      "Eval Loss:  0.3200196921825409\n",
      "Eval Loss:  0.2910088002681732\n",
      "Eval Loss:  0.24598997831344604\n",
      "Eval Loss:  0.26208654046058655\n",
      "Eval Loss:  0.32769325375556946\n",
      "Eval Loss:  0.2921935021877289\n",
      "Eval Loss:  0.3119409382343292\n",
      "Eval Loss:  0.2568410336971283\n",
      "Eval Loss:  0.3417680263519287\n",
      "Eval Loss:  0.25938335061073303\n",
      "Eval Loss:  0.3326084613800049\n",
      "Eval Loss:  0.29774466156959534\n",
      "Eval Loss:  0.279498428106308\n",
      "Eval Loss:  0.27621689438819885\n",
      "Eval Loss:  0.32754743099212646\n",
      "Eval Loss:  0.32946887612342834\n",
      "Eval Loss:  0.2277866154909134\n",
      "Eval Loss:  0.26406073570251465\n",
      "Eval Loss:  0.26863202452659607\n",
      "Eval Loss:  0.24988293647766113\n",
      "Eval Loss:  0.2639385461807251\n",
      "[[16398  2024]\n",
      " [ 1699  9362]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     18422\n",
      "           1       0.82      0.85      0.83     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.86      0.87      0.87     29483\n",
      "weighted avg       0.87      0.87      0.87     29483\n",
      "\n",
      "acc:  0.8737238408574433\n",
      "pre:  0.8222378359388723\n",
      "rec:  0.8463972516047373\n",
      "ma F1:  0.8660978576950857\n",
      "mi F1:  0.8737238408574433\n",
      "we F1:  0.8740760927800933\n",
      "29483 461\n",
      "Loss:  0.09212781488895416\n",
      "Loss:  0.10183325409889221\n",
      "Loss:  0.06290418654680252\n",
      "21 **********\n",
      "Epoch:  1160.2896213531494  fold:  9  kers:  32\n",
      "epoch:  22\n",
      "29483 461\n",
      "Loss:  0.079855777323246\n",
      "Loss:  0.08214535564184189\n",
      "Loss:  0.0713273286819458\n",
      "22 **********\n",
      "Epoch:  1200.1669969558716  fold:  9  kers:  32\n",
      "epoch:  23\n",
      "29483 461\n",
      "Loss:  0.05848053842782974\n",
      "Loss:  0.08060795813798904\n",
      "Loss:  0.058146487921476364\n",
      "23 **********\n",
      "Epoch:  1240.0782825946808  fold:  9  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.06748554855585098\n",
      "Eval Loss:  1.2567203044891357\n",
      "Eval Loss:  0.17447544634342194\n",
      "[[1548  194]\n",
      " [ 416 1250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84      1742\n",
      "           1       0.87      0.75      0.80      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.83      0.82      0.82      3408\n",
      "weighted avg       0.83      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8210093896713615\n",
      "pre:  0.8656509695290858\n",
      "rec:  0.7503001200480192\n",
      "ma F1:  0.8196302858144349\n",
      "mi F1:  0.8210093896713615\n",
      "we F1:  0.8199820035766041\n",
      "Eval Loss:  0.3472433090209961\n",
      "Eval Loss:  0.28046900033950806\n",
      "Eval Loss:  0.3323987126350403\n",
      "Eval Loss:  0.3412768840789795\n",
      "Eval Loss:  0.3077372908592224\n",
      "Eval Loss:  0.3822588324546814\n",
      "Eval Loss:  0.2750557065010071\n",
      "Eval Loss:  0.3239048421382904\n",
      "Eval Loss:  0.2899179458618164\n",
      "Eval Loss:  0.24217179417610168\n",
      "Eval Loss:  0.24914473295211792\n",
      "Eval Loss:  0.314041405916214\n",
      "Eval Loss:  0.2761012017726898\n",
      "Eval Loss:  0.3104313910007477\n",
      "Eval Loss:  0.2479841113090515\n",
      "Eval Loss:  0.33370062708854675\n",
      "Eval Loss:  0.24942341446876526\n",
      "Eval Loss:  0.315965861082077\n",
      "Eval Loss:  0.2911582887172699\n",
      "Eval Loss:  0.2593625783920288\n",
      "Eval Loss:  0.275763601064682\n",
      "Eval Loss:  0.3341023325920105\n",
      "Eval Loss:  0.31073808670043945\n",
      "Eval Loss:  0.2151879072189331\n",
      "Eval Loss:  0.25328707695007324\n",
      "Eval Loss:  0.2520575523376465\n",
      "Eval Loss:  0.2330251932144165\n",
      "Eval Loss:  0.2818845510482788\n",
      "[[16601  1821]\n",
      " [ 1838  9223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     18422\n",
      "           1       0.84      0.83      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.87      0.87      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8758945833192009\n",
      "pre:  0.8351140890981529\n",
      "rec:  0.8338305758972968\n",
      "ma F1:  0.8676035166646734\n",
      "mi F1:  0.8758945833192009\n",
      "we F1:  0.8758754794789831\n",
      "29483 461\n",
      "Loss:  0.046348556876182556\n",
      "Loss:  0.08613608032464981\n",
      "Loss:  0.054395709186792374\n",
      "24 **********\n",
      "Epoch:  1318.0129010677338  fold:  9  kers:  32\n",
      "epoch:  25\n",
      "29483 461\n",
      "Loss:  0.07031895220279694\n",
      "Loss:  0.07840480655431747\n",
      "Loss:  0.09005951881408691\n",
      "25 **********\n",
      "Epoch:  1357.9251837730408  fold:  9  kers:  32\n",
      "epoch:  26\n",
      "29483 461\n",
      "Loss:  0.06540143489837646\n",
      "Loss:  0.13414207100868225\n",
      "Loss:  0.08078557252883911\n",
      "26 **********\n",
      "Epoch:  1397.9641275405884  fold:  9  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.0627155750989914\n",
      "Eval Loss:  1.3503278493881226\n",
      "Eval Loss:  0.16355985403060913\n",
      "[[1545  197]\n",
      " [ 427 1239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      1742\n",
      "           1       0.86      0.74      0.80      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.82      0.82      0.82      3408\n",
      "weighted avg       0.82      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8169014084507042\n",
      "pre:  0.8628133704735376\n",
      "rec:  0.7436974789915967\n",
      "ma F1:  0.815413267171422\n",
      "mi F1:  0.8169014084507042\n",
      "we F1:  0.8157828708878451\n",
      "Eval Loss:  0.3271114230155945\n",
      "Eval Loss:  0.2713567912578583\n",
      "Eval Loss:  0.3212572932243347\n",
      "Eval Loss:  0.30757227540016174\n",
      "Eval Loss:  0.29012012481689453\n",
      "Eval Loss:  0.34542790055274963\n",
      "Eval Loss:  0.2582900822162628\n",
      "Eval Loss:  0.3151227533817291\n",
      "Eval Loss:  0.2800397574901581\n",
      "Eval Loss:  0.24614155292510986\n",
      "Eval Loss:  0.2435687631368637\n",
      "Eval Loss:  0.3286795914173126\n",
      "Eval Loss:  0.2647215723991394\n",
      "Eval Loss:  0.29673275351524353\n",
      "Eval Loss:  0.23575365543365479\n",
      "Eval Loss:  0.3173162639141083\n",
      "Eval Loss:  0.25351884961128235\n",
      "Eval Loss:  0.30548176169395447\n",
      "Eval Loss:  0.28503352403640747\n",
      "Eval Loss:  0.23908014595508575\n",
      "Eval Loss:  0.2556220591068268\n",
      "Eval Loss:  0.32707682251930237\n",
      "Eval Loss:  0.30019229650497437\n",
      "Eval Loss:  0.20757609605789185\n",
      "Eval Loss:  0.2498149424791336\n",
      "Eval Loss:  0.2535868287086487\n",
      "Eval Loss:  0.21213680505752563\n",
      "Eval Loss:  0.26012736558914185\n",
      "[[16625  1797]\n",
      " [ 1724  9337]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90     18422\n",
      "           1       0.84      0.84      0.84     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.87      0.87      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8805752467523658\n",
      "pre:  0.8386024788934794\n",
      "rec:  0.8441370581321761\n",
      "ma F1:  0.8728029300198854\n",
      "mi F1:  0.8805752467523658\n",
      "we F1:  0.8806530978941701\n",
      "29483 461\n",
      "Loss:  0.06961768865585327\n",
      "Loss:  0.060190945863723755\n",
      "Loss:  0.05694819614291191\n",
      "27 **********\n",
      "Epoch:  1475.7411682605743  fold:  9  kers:  32\n",
      "epoch:  28\n",
      "29483 461\n",
      "Loss:  0.07720623165369034\n",
      "Loss:  0.07162320613861084\n",
      "Loss:  0.08500517904758453\n",
      "28 **********\n",
      "Epoch:  1515.563690662384  fold:  9  kers:  32\n",
      "epoch:  29\n",
      "29483 461\n",
      "Loss:  0.09795138984918594\n",
      "Loss:  0.041986092925071716\n",
      "Loss:  0.05304751545190811\n",
      "29 **********\n",
      "Epoch:  1555.5647356510162  fold:  9  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.07776880264282227\n",
      "Eval Loss:  1.111974835395813\n",
      "Eval Loss:  0.13649195432662964\n",
      "[[1510  232]\n",
      " [ 374 1292]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83      1742\n",
      "           1       0.85      0.78      0.81      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.82      0.82      0.82      3408\n",
      "weighted avg       0.82      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8221830985915493\n",
      "pre:  0.847769028871391\n",
      "rec:  0.7755102040816326\n",
      "ma F1:  0.8214525189894648\n",
      "mi F1:  0.8221830985915493\n",
      "we F1:  0.8217072164654209\n",
      "Eval Loss:  0.39893537759780884\n",
      "Eval Loss:  0.25466567277908325\n",
      "Eval Loss:  0.33809807896614075\n",
      "Eval Loss:  0.3068509101867676\n",
      "Eval Loss:  0.2958274483680725\n",
      "Eval Loss:  0.3796267807483673\n",
      "Eval Loss:  0.2630467712879181\n",
      "Eval Loss:  0.32264524698257446\n",
      "Eval Loss:  0.2978552281856537\n",
      "Eval Loss:  0.25388526916503906\n",
      "Eval Loss:  0.24313929677009583\n",
      "Eval Loss:  0.3515734076499939\n",
      "Eval Loss:  0.2844027578830719\n",
      "Eval Loss:  0.2883591055870056\n",
      "Eval Loss:  0.23510296642780304\n",
      "Eval Loss:  0.3518369197845459\n",
      "Eval Loss:  0.26067081093788147\n",
      "Eval Loss:  0.34020859003067017\n",
      "Eval Loss:  0.2971634566783905\n",
      "Eval Loss:  0.23817075788974762\n",
      "Eval Loss:  0.2716485261917114\n",
      "Eval Loss:  0.32381999492645264\n",
      "Eval Loss:  0.31348446011543274\n",
      "Eval Loss:  0.2187773734331131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.26904627680778503\n",
      "Eval Loss:  0.2715262174606323\n",
      "Eval Loss:  0.2346225529909134\n",
      "Eval Loss:  0.24716824293136597\n",
      "[[16074  2348]\n",
      " [ 1369  9692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90     18422\n",
      "           1       0.80      0.88      0.84     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.86      0.87      0.87     29483\n",
      "weighted avg       0.88      0.87      0.87     29483\n",
      "\n",
      "acc:  0.873927347963233\n",
      "pre:  0.804983388704319\n",
      "rec:  0.8762318054425459\n",
      "ma F1:  0.8677296148162206\n",
      "mi F1:  0.873927347963233\n",
      "we F1:  0.8748780813933372\n",
      "29483 461\n",
      "Loss:  0.09814250469207764\n",
      "Loss:  0.07245664298534393\n",
      "Loss:  0.04657784476876259\n",
      "30 **********\n",
      "Epoch:  1633.2440371513367  fold:  9  kers:  32\n",
      "epoch:  31\n",
      "29483 461\n",
      "Loss:  0.05117911100387573\n",
      "Loss:  0.0757884606719017\n",
      "Loss:  0.06255996227264404\n",
      "31 **********\n",
      "Epoch:  1673.356784582138  fold:  9  kers:  32\n",
      "epoch:  32\n",
      "29483 461\n",
      "Loss:  0.09006113559007645\n",
      "Loss:  0.060918718576431274\n",
      "Loss:  0.1039753258228302\n",
      "32 **********\n",
      "Epoch:  1713.4625492095947  fold:  9  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.07510244846343994\n",
      "Eval Loss:  1.1421235799789429\n",
      "Eval Loss:  0.1422949582338333\n",
      "[[1560  182]\n",
      " [ 385 1281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1742\n",
      "           1       0.88      0.77      0.82      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.84      0.83      0.83      3408\n",
      "weighted avg       0.84      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8336267605633803\n",
      "pre:  0.8755980861244019\n",
      "rec:  0.7689075630252101\n",
      "ma F1:  0.8325041912178288\n",
      "mi F1:  0.8336267605633803\n",
      "we F1:  0.8328099807169755\n",
      "update!  Acc:  0.8336267605633803\n",
      "Eval Loss:  0.3482222855091095\n",
      "Eval Loss:  0.24306242167949677\n",
      "Eval Loss:  0.3330691158771515\n",
      "Eval Loss:  0.27741795778274536\n",
      "Eval Loss:  0.29114338755607605\n",
      "Eval Loss:  0.33884528279304504\n",
      "Eval Loss:  0.2500714063644409\n",
      "Eval Loss:  0.31268948316574097\n",
      "Eval Loss:  0.29456770420074463\n",
      "Eval Loss:  0.24495044350624084\n",
      "Eval Loss:  0.2438563108444214\n",
      "Eval Loss:  0.31702762842178345\n",
      "Eval Loss:  0.2695188522338867\n",
      "Eval Loss:  0.281892329454422\n",
      "Eval Loss:  0.20931720733642578\n",
      "Eval Loss:  0.3248923122882843\n",
      "Eval Loss:  0.24972358345985413\n",
      "Eval Loss:  0.31581106781959534\n",
      "Eval Loss:  0.2589128017425537\n",
      "Eval Loss:  0.23093658685684204\n",
      "Eval Loss:  0.27508610486984253\n",
      "Eval Loss:  0.3165832757949829\n",
      "Eval Loss:  0.2927822768688202\n",
      "Eval Loss:  0.20101085305213928\n",
      "Eval Loss:  0.25757670402526855\n",
      "Eval Loss:  0.2508058249950409\n",
      "Eval Loss:  0.22702163457870483\n",
      "Eval Loss:  0.2424570620059967\n",
      "[[16381  2041]\n",
      " [ 1412  9649]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90     18422\n",
      "           1       0.83      0.87      0.85     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.87      0.88      0.88     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8828816606179832\n",
      "pre:  0.8254063301967494\n",
      "rec:  0.8723442726697406\n",
      "ma F1:  0.8764396098872611\n",
      "mi F1:  0.8828816606179832\n",
      "we F1:  0.883483569398379\n",
      "29483 461\n",
      "Loss:  0.07206102460622787\n",
      "Loss:  0.05590871348977089\n",
      "Loss:  0.07843538373708725\n",
      "33 **********\n",
      "Epoch:  1791.7043466567993  fold:  9  kers:  32\n",
      "epoch:  34\n",
      "29483 461\n",
      "Loss:  0.06654922664165497\n",
      "Loss:  0.05822919309139252\n",
      "Loss:  0.05970638617873192\n",
      "34 **********\n",
      "Epoch:  1831.8180906772614  fold:  9  kers:  32\n",
      "epoch:  35\n",
      "29483 461\n",
      "Loss:  0.05894339457154274\n",
      "Loss:  0.06750935316085815\n",
      "Loss:  0.05227387696504593\n",
      "35 **********\n",
      "Epoch:  1871.8450665473938  fold:  9  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.0629093125462532\n",
      "Eval Loss:  1.162894606590271\n",
      "Eval Loss:  0.14918242394924164\n",
      "[[1563  179]\n",
      " [ 381 1285]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1742\n",
      "           1       0.88      0.77      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.84      0.83      0.83      3408\n",
      "weighted avg       0.84      0.84      0.83      3408\n",
      "\n",
      "acc:  0.8356807511737089\n",
      "pre:  0.8777322404371585\n",
      "rec:  0.7713085234093637\n",
      "ma F1:  0.8345800273550383\n",
      "mi F1:  0.8356807511737089\n",
      "we F1:  0.8348809446579842\n",
      "update!  Acc:  0.8356807511737089\n",
      "Eval Loss:  0.34726935625076294\n",
      "Eval Loss:  0.23276512324810028\n",
      "Eval Loss:  0.30821213126182556\n",
      "Eval Loss:  0.26275622844696045\n",
      "Eval Loss:  0.2860879898071289\n",
      "Eval Loss:  0.33489495515823364\n",
      "Eval Loss:  0.247995987534523\n",
      "Eval Loss:  0.31351345777511597\n",
      "Eval Loss:  0.29010945558547974\n",
      "Eval Loss:  0.2394481748342514\n",
      "Eval Loss:  0.2305140197277069\n",
      "Eval Loss:  0.3223591148853302\n",
      "Eval Loss:  0.2708856165409088\n",
      "Eval Loss:  0.2677758038043976\n",
      "Eval Loss:  0.20393013954162598\n",
      "Eval Loss:  0.322629451751709\n",
      "Eval Loss:  0.2551375925540924\n",
      "Eval Loss:  0.3074246644973755\n",
      "Eval Loss:  0.2510172724723816\n",
      "Eval Loss:  0.2231748253107071\n",
      "Eval Loss:  0.26608553528785706\n",
      "Eval Loss:  0.3063628375530243\n",
      "Eval Loss:  0.28522390127182007\n",
      "Eval Loss:  0.2013656049966812\n",
      "Eval Loss:  0.25597691535949707\n",
      "Eval Loss:  0.24845997989177704\n",
      "Eval Loss:  0.21781989932060242\n",
      "Eval Loss:  0.2376096248626709\n",
      "[[16359  2063]\n",
      " [ 1332  9729]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91     18422\n",
      "           1       0.83      0.88      0.85     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.87      0.88      0.88     29483\n",
      "weighted avg       0.89      0.88      0.89     29483\n",
      "\n",
      "acc:  0.8848488959739511\n",
      "pre:  0.825050881953867\n",
      "rec:  0.8795768917819365\n",
      "ma F1:  0.8787156783428869\n",
      "mi F1:  0.8848488959739511\n",
      "we F1:  0.8855251225332736\n",
      "29483 461\n",
      "Loss:  0.10164348036050797\n",
      "Loss:  0.09014007449150085\n",
      "Loss:  0.048878394067287445\n",
      "36 **********\n",
      "Epoch:  1949.9153225421906  fold:  9  kers:  32\n",
      "epoch:  37\n",
      "29483 461\n",
      "Loss:  0.07025200128555298\n",
      "Loss:  0.0673140287399292\n",
      "Loss:  0.06325733661651611\n",
      "37 **********\n",
      "Epoch:  1989.9811944961548  fold:  9  kers:  32\n",
      "epoch:  38\n",
      "29483 461\n",
      "Loss:  0.08093446493148804\n",
      "Loss:  0.06636421382427216\n",
      "Loss:  0.06571636348962784\n",
      "38 **********\n",
      "Epoch:  2030.0370931625366  fold:  9  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.05256369337439537\n",
      "Eval Loss:  1.3850305080413818\n",
      "Eval Loss:  0.1702057421207428\n",
      "[[1595  147]\n",
      " [ 431 1235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85      1742\n",
      "           1       0.89      0.74      0.81      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.84      0.83      0.83      3408\n",
      "weighted avg       0.84      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8303990610328639\n",
      "pre:  0.8936324167872648\n",
      "rec:  0.741296518607443\n",
      "ma F1:  0.8284852132336961\n",
      "mi F1:  0.8303990610328639\n",
      "we F1:  0.828889247769076\n",
      "Eval Loss:  0.2980223298072815\n",
      "Eval Loss:  0.23871712386608124\n",
      "Eval Loss:  0.29129090905189514\n",
      "Eval Loss:  0.26184791326522827\n",
      "Eval Loss:  0.27384570240974426\n",
      "Eval Loss:  0.3127571940422058\n",
      "Eval Loss:  0.24142178893089294\n",
      "Eval Loss:  0.3066386878490448\n",
      "Eval Loss:  0.2525559365749359\n",
      "Eval Loss:  0.20816200971603394\n",
      "Eval Loss:  0.2148146629333496\n",
      "Eval Loss:  0.28604960441589355\n",
      "Eval Loss:  0.23458515107631683\n",
      "Eval Loss:  0.2635655701160431\n",
      "Eval Loss:  0.1830606311559677\n",
      "Eval Loss:  0.30851009488105774\n",
      "Eval Loss:  0.2221309393644333\n",
      "Eval Loss:  0.2575377821922302\n",
      "Eval Loss:  0.22866548597812653\n",
      "Eval Loss:  0.20390276610851288\n",
      "Eval Loss:  0.2564855217933655\n",
      "Eval Loss:  0.295265257358551\n",
      "Eval Loss:  0.27055054903030396\n",
      "Eval Loss:  0.18257427215576172\n",
      "Eval Loss:  0.2313545197248459\n",
      "Eval Loss:  0.2283635437488556\n",
      "Eval Loss:  0.1951076239347458\n",
      "Eval Loss:  0.24235941469669342\n",
      "[[16948  1474]\n",
      " [ 1616  9445]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     18422\n",
      "           1       0.87      0.85      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.89      0.89      0.89     29483\n",
      "weighted avg       0.89      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8951938405182648\n",
      "pre:  0.8650059529260922\n",
      "rec:  0.8539010939336407\n",
      "ma F1:  0.8879362636143908\n",
      "mi F1:  0.8951938405182648\n",
      "we F1:  0.8950564853376238\n",
      "29483 461\n",
      "Loss:  0.053395360708236694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07571956515312195\n",
      "Loss:  0.05652020499110222\n",
      "39 **********\n",
      "Epoch:  2107.863003015518  fold:  9  kers:  32\n",
      "epoch:  40\n",
      "29483 461\n",
      "Loss:  0.08025147765874863\n",
      "Loss:  0.08409100770950317\n",
      "Loss:  0.08282167464494705\n",
      "40 **********\n",
      "Epoch:  2147.9069335460663  fold:  9  kers:  32\n",
      "epoch:  41\n",
      "29483 461\n",
      "Loss:  0.06255243718624115\n",
      "Loss:  0.07397117465734482\n",
      "Loss:  0.06042403727769852\n",
      "41 **********\n",
      "Epoch:  2187.912964820862  fold:  9  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.044081125408411026\n",
      "Eval Loss:  1.274647831916809\n",
      "Eval Loss:  0.15506847202777863\n",
      "[[1606  136]\n",
      " [ 392 1274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86      1742\n",
      "           1       0.90      0.76      0.83      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.85      0.84      3408\n",
      "\n",
      "acc:  0.8450704225352113\n",
      "pre:  0.9035460992907801\n",
      "rec:  0.7647058823529411\n",
      "ma F1:  0.843586016981565\n",
      "mi F1:  0.8450704225352113\n",
      "we F1:  0.8439258206625202\n",
      "update!  Acc:  0.8450704225352113\n",
      "Eval Loss:  0.3127577304840088\n",
      "Eval Loss:  0.23009531199932098\n",
      "Eval Loss:  0.2929221987724304\n",
      "Eval Loss:  0.26371344923973083\n",
      "Eval Loss:  0.26345497369766235\n",
      "Eval Loss:  0.30191847681999207\n",
      "Eval Loss:  0.2384660243988037\n",
      "Eval Loss:  0.3053061366081238\n",
      "Eval Loss:  0.26269716024398804\n",
      "Eval Loss:  0.21980787813663483\n",
      "Eval Loss:  0.21834631264209747\n",
      "Eval Loss:  0.295214980840683\n",
      "Eval Loss:  0.25004011392593384\n",
      "Eval Loss:  0.26390746235847473\n",
      "Eval Loss:  0.18136563897132874\n",
      "Eval Loss:  0.3107835352420807\n",
      "Eval Loss:  0.2239130437374115\n",
      "Eval Loss:  0.2694997489452362\n",
      "Eval Loss:  0.22459907829761505\n",
      "Eval Loss:  0.2087143212556839\n",
      "Eval Loss:  0.26451170444488525\n",
      "Eval Loss:  0.2949722707271576\n",
      "Eval Loss:  0.26600658893585205\n",
      "Eval Loss:  0.1894562840461731\n",
      "Eval Loss:  0.23729144036769867\n",
      "Eval Loss:  0.23653244972229004\n",
      "Eval Loss:  0.20261292159557343\n",
      "Eval Loss:  0.23613369464874268\n",
      "[[16740  1682]\n",
      " [ 1435  9626]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91     18422\n",
      "           1       0.85      0.87      0.86     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.89      0.89     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8942780585422108\n",
      "pre:  0.8512557481429077\n",
      "rec:  0.8702648946749841\n",
      "ma F1:  0.88774222781196\n",
      "mi F1:  0.8942780585422108\n",
      "we F1:  0.8945049843491228\n",
      "29483 461\n",
      "Loss:  0.054642193019390106\n",
      "Loss:  0.06704699248075485\n",
      "Loss:  0.06686200201511383\n",
      "42 **********\n",
      "Epoch:  2266.171717405319  fold:  9  kers:  32\n",
      "epoch:  43\n",
      "29483 461\n",
      "Loss:  0.062086813151836395\n",
      "Loss:  0.07919494062662125\n",
      "Loss:  0.042515888810157776\n",
      "43 **********\n",
      "Epoch:  2306.0610613822937  fold:  9  kers:  32\n",
      "epoch:  44\n",
      "29483 461\n",
      "Loss:  0.07909663021564484\n",
      "Loss:  0.07409636676311493\n",
      "Loss:  0.10287590324878693\n",
      "44 **********\n",
      "Epoch:  2345.9663622379303  fold:  9  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.033316779881715775\n",
      "Eval Loss:  1.4020966291427612\n",
      "Eval Loss:  0.19472071528434753\n",
      "[[1645   97]\n",
      " [ 458 1208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.86      1742\n",
      "           1       0.93      0.73      0.81      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.84      0.83      3408\n",
      "\n",
      "acc:  0.8371478873239436\n",
      "pre:  0.9256704980842911\n",
      "rec:  0.7250900360144058\n",
      "ma F1:  0.8344254538562847\n",
      "mi F1:  0.8371478873239436\n",
      "we F1:  0.8348989205463125\n",
      "Eval Loss:  0.26912885904312134\n",
      "Eval Loss:  0.22944799065589905\n",
      "Eval Loss:  0.27656468749046326\n",
      "Eval Loss:  0.2654443383216858\n",
      "Eval Loss:  0.2717629373073578\n",
      "Eval Loss:  0.2678840160369873\n",
      "Eval Loss:  0.23237209022045135\n",
      "Eval Loss:  0.301104336977005\n",
      "Eval Loss:  0.24007761478424072\n",
      "Eval Loss:  0.20632769167423248\n",
      "Eval Loss:  0.21016660332679749\n",
      "Eval Loss:  0.2737824022769928\n",
      "Eval Loss:  0.22672998905181885\n",
      "Eval Loss:  0.24649697542190552\n",
      "Eval Loss:  0.17055493593215942\n",
      "Eval Loss:  0.3020542860031128\n",
      "Eval Loss:  0.22115378081798553\n",
      "Eval Loss:  0.24237218499183655\n",
      "Eval Loss:  0.21330121159553528\n",
      "Eval Loss:  0.21261048316955566\n",
      "Eval Loss:  0.25922393798828125\n",
      "Eval Loss:  0.3063572645187378\n",
      "Eval Loss:  0.2566041946411133\n",
      "Eval Loss:  0.17327255010604858\n",
      "Eval Loss:  0.23254339396953583\n",
      "Eval Loss:  0.21124307811260223\n",
      "Eval Loss:  0.18401949107646942\n",
      "Eval Loss:  0.2377871572971344\n",
      "[[17204  1218]\n",
      " [ 1754  9307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18422\n",
      "           1       0.88      0.84      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.89      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8991961469321303\n",
      "pre:  0.8842755344418052\n",
      "rec:  0.8414248259651026\n",
      "ma F1:  0.8914052055121433\n",
      "mi F1:  0.8991961469321302\n",
      "we F1:  0.8986673455390555\n",
      "29483 461\n",
      "Loss:  0.10718458890914917\n",
      "Loss:  0.045404840260744095\n",
      "Loss:  0.04778645932674408\n",
      "45 **********\n",
      "Epoch:  2423.9279091358185  fold:  9  kers:  32\n",
      "epoch:  46\n",
      "29483 461\n",
      "Loss:  0.08037023991346359\n",
      "Loss:  0.0646008849143982\n",
      "Loss:  0.059643346816301346\n",
      "46 **********\n",
      "Epoch:  2463.8611359596252  fold:  9  kers:  32\n",
      "epoch:  47\n",
      "29483 461\n",
      "Loss:  0.07604851573705673\n",
      "Loss:  0.07006432861089706\n",
      "Loss:  0.070201575756073\n",
      "47 **********\n",
      "Epoch:  2503.8093230724335  fold:  9  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.04218339920043945\n",
      "Eval Loss:  1.1619876623153687\n",
      "Eval Loss:  0.1470833420753479\n",
      "[[1608  134]\n",
      " [ 372 1294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86      1742\n",
      "           1       0.91      0.78      0.84      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.86      0.85      0.85      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8515258215962441\n",
      "pre:  0.9061624649859944\n",
      "rec:  0.7767106842737095\n",
      "ma F1:  0.8502546225781678\n",
      "mi F1:  0.8515258215962441\n",
      "we F1:  0.8505623013213964\n",
      "update!  Acc:  0.8515258215962441\n",
      "Eval Loss:  0.33769118785858154\n",
      "Eval Loss:  0.2205212563276291\n",
      "Eval Loss:  0.279543936252594\n",
      "Eval Loss:  0.26118606328964233\n",
      "Eval Loss:  0.26081448793411255\n",
      "Eval Loss:  0.2917157709598541\n",
      "Eval Loss:  0.2280043214559555\n",
      "Eval Loss:  0.3030112385749817\n",
      "Eval Loss:  0.2597452998161316\n",
      "Eval Loss:  0.23095504939556122\n",
      "Eval Loss:  0.22208496928215027\n",
      "Eval Loss:  0.3024078905582428\n",
      "Eval Loss:  0.25242605805397034\n",
      "Eval Loss:  0.2526872754096985\n",
      "Eval Loss:  0.18676334619522095\n",
      "Eval Loss:  0.2964971661567688\n",
      "Eval Loss:  0.23552368581295013\n",
      "Eval Loss:  0.2657538056373596\n",
      "Eval Loss:  0.2083931863307953\n",
      "Eval Loss:  0.23148874938488007\n",
      "Eval Loss:  0.27362602949142456\n",
      "Eval Loss:  0.28787723183631897\n",
      "Eval Loss:  0.2690047323703766\n",
      "Eval Loss:  0.17387743294239044\n",
      "Eval Loss:  0.24767744541168213\n",
      "Eval Loss:  0.24366407096385956\n",
      "Eval Loss:  0.22318673133850098\n",
      "Eval Loss:  0.24283254146575928\n",
      "[[16583  1839]\n",
      " [ 1304  9757]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91     18422\n",
      "           1       0.84      0.88      0.86     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.88      0.89      0.89     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8933961944171217\n",
      "pre:  0.8414108313211452\n",
      "rec:  0.8821083084712051\n",
      "ma F1:  0.8873582573264094\n",
      "mi F1:  0.8933961944171217\n",
      "we F1:  0.8938694285723416\n",
      "29483 461\n",
      "Loss:  0.06074484437704086\n",
      "Loss:  0.11624475568532944\n",
      "Loss:  0.06213030219078064\n",
      "48 **********\n",
      "Epoch:  2581.793808221817  fold:  9  kers:  32\n",
      "epoch:  49\n",
      "29483 461\n",
      "Loss:  0.05836232006549835\n",
      "Loss:  0.08617840707302094\n",
      "Loss:  0.07144980132579803\n",
      "49 **********\n",
      "Epoch:  2621.816794157028  fold:  9  kers:  32\n",
      "epoch:  50\n",
      "29483 461\n",
      "Loss:  0.05398978292942047\n",
      "Loss:  0.08849716186523438\n",
      "Loss:  0.10393092036247253\n",
      "50 **********\n",
      "Epoch:  2661.716112136841  fold:  9  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.049138158559799194\n",
      "Eval Loss:  0.9393008351325989\n",
      "Eval Loss:  0.1677141785621643\n",
      "[[1602  140]\n",
      " [ 347 1319]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87      1742\n",
      "           1       0.90      0.79      0.84      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.86      0.86      0.86      3408\n",
      "weighted avg       0.86      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8571009389671361\n",
      "pre:  0.9040438656614119\n",
      "rec:  0.7917166866746699\n",
      "ma F1:  0.8561087185044703\n",
      "mi F1:  0.8571009389671361\n",
      "we F1:  0.8563751805368471\n",
      "update!  Acc:  0.8571009389671361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.29639193415641785\n",
      "Eval Loss:  0.1935940682888031\n",
      "Eval Loss:  0.2761254608631134\n",
      "Eval Loss:  0.22816671431064606\n",
      "Eval Loss:  0.2622029781341553\n",
      "Eval Loss:  0.29022252559661865\n",
      "Eval Loss:  0.2274128496646881\n",
      "Eval Loss:  0.3120228946208954\n",
      "Eval Loss:  0.2526225745677948\n",
      "Eval Loss:  0.22640694677829742\n",
      "Eval Loss:  0.20060794055461884\n",
      "Eval Loss:  0.2726430594921112\n",
      "Eval Loss:  0.22778576612472534\n",
      "Eval Loss:  0.23591721057891846\n",
      "Eval Loss:  0.17445459961891174\n",
      "Eval Loss:  0.3065841794013977\n",
      "Eval Loss:  0.22678282856941223\n",
      "Eval Loss:  0.24348406493663788\n",
      "Eval Loss:  0.22419428825378418\n",
      "Eval Loss:  0.2139347642660141\n",
      "Eval Loss:  0.24962632358074188\n",
      "Eval Loss:  0.2708234488964081\n",
      "Eval Loss:  0.2762671411037445\n",
      "Eval Loss:  0.16913709044456482\n",
      "Eval Loss:  0.24240882694721222\n",
      "Eval Loss:  0.21326974034309387\n",
      "Eval Loss:  0.19931448996067047\n",
      "Eval Loss:  0.23158888518810272\n",
      "[[16688  1734]\n",
      " [ 1273  9788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     18422\n",
      "           1       0.85      0.88      0.87     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.89      0.90      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8980090221483567\n",
      "pre:  0.8495052942197535\n",
      "rec:  0.8849109483771811\n",
      "ma F1:  0.8920991267230569\n",
      "mi F1:  0.8980090221483567\n",
      "we F1:  0.8984038716832933\n",
      "29483 461\n",
      "Loss:  0.052597422152757645\n",
      "Loss:  0.04210229963064194\n",
      "Loss:  0.0728142261505127\n",
      "51 **********\n",
      "Epoch:  2739.618816137314  fold:  9  kers:  32\n",
      "epoch:  52\n",
      "29483 461\n",
      "Loss:  0.06656261533498764\n",
      "Loss:  0.04567688703536987\n",
      "Loss:  0.031258128583431244\n",
      "52 **********\n",
      "Epoch:  2779.5041704177856  fold:  9  kers:  32\n",
      "epoch:  53\n",
      "29483 461\n",
      "Loss:  0.07185050845146179\n",
      "Loss:  0.07433778792619705\n",
      "Loss:  0.06799822300672531\n",
      "53 **********\n",
      "Epoch:  2819.5072104930878  fold:  9  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.038016483187675476\n",
      "Eval Loss:  1.0227093696594238\n",
      "Eval Loss:  0.13483260571956635\n",
      "[[1591  151]\n",
      " [ 345 1321]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.87      1742\n",
      "           1       0.90      0.79      0.84      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.86      0.85      0.85      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8544600938967136\n",
      "pre:  0.8974184782608695\n",
      "rec:  0.7929171668667467\n",
      "ma F1:  0.8535408199443334\n",
      "mi F1:  0.8544600938967136\n",
      "we F1:  0.8537995785383368\n",
      "Eval Loss:  0.35806363821029663\n",
      "Eval Loss:  0.2105431854724884\n",
      "Eval Loss:  0.29598239064216614\n",
      "Eval Loss:  0.2568928599357605\n",
      "Eval Loss:  0.25731855630874634\n",
      "Eval Loss:  0.30498838424682617\n",
      "Eval Loss:  0.2194003313779831\n",
      "Eval Loss:  0.3024330139160156\n",
      "Eval Loss:  0.2660227417945862\n",
      "Eval Loss:  0.23559342324733734\n",
      "Eval Loss:  0.2025356888771057\n",
      "Eval Loss:  0.30769819021224976\n",
      "Eval Loss:  0.25060153007507324\n",
      "Eval Loss:  0.243591770529747\n",
      "Eval Loss:  0.17732933163642883\n",
      "Eval Loss:  0.30808281898498535\n",
      "Eval Loss:  0.23186570405960083\n",
      "Eval Loss:  0.2728370428085327\n",
      "Eval Loss:  0.21428968012332916\n",
      "Eval Loss:  0.2265823781490326\n",
      "Eval Loss:  0.2707616686820984\n",
      "Eval Loss:  0.2783694565296173\n",
      "Eval Loss:  0.2776334881782532\n",
      "Eval Loss:  0.1768818199634552\n",
      "Eval Loss:  0.26551353931427\n",
      "Eval Loss:  0.24092504382133484\n",
      "Eval Loss:  0.2062811553478241\n",
      "Eval Loss:  0.22214655578136444\n",
      "[[16393  2029]\n",
      " [ 1133  9928]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91     18422\n",
      "           1       0.83      0.90      0.86     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.88      0.89      0.89     29483\n",
      "weighted avg       0.90      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8927517552487875\n",
      "pre:  0.8303086058375847\n",
      "rec:  0.8975680318235241\n",
      "ma F1:  0.8873344297252606\n",
      "mi F1:  0.8927517552487875\n",
      "we F1:  0.8935025555069591\n",
      "29483 461\n",
      "Loss:  0.06956452131271362\n",
      "Loss:  0.049578793346881866\n",
      "Loss:  0.05276653915643692\n",
      "54 **********\n",
      "Epoch:  2897.3201541900635  fold:  9  kers:  32\n",
      "epoch:  55\n",
      "29483 461\n",
      "Loss:  0.06611981242895126\n",
      "Loss:  0.045632876455783844\n",
      "Loss:  0.05340054631233215\n",
      "55 **********\n",
      "Epoch:  2937.310229063034  fold:  9  kers:  32\n",
      "epoch:  56\n",
      "29483 461\n",
      "Loss:  0.06140214577317238\n",
      "Loss:  0.05443759262561798\n",
      "Loss:  0.05263374000787735\n",
      "56 **********\n",
      "Epoch:  2977.377098798752  fold:  9  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.049348168075084686\n",
      "Eval Loss:  0.8844468593597412\n",
      "Eval Loss:  0.14399565756320953\n",
      "[[1537  205]\n",
      " [ 308 1358]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86      1742\n",
      "           1       0.87      0.82      0.84      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.85      0.85      0.85      3408\n",
      "weighted avg       0.85      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8494718309859155\n",
      "pre:  0.8688419705694178\n",
      "rec:  0.8151260504201681\n",
      "ma F1:  0.8490554178516879\n",
      "mi F1:  0.8494718309859155\n",
      "we F1:  0.8492322189589578\n",
      "Eval Loss:  0.3706555962562561\n",
      "Eval Loss:  0.20919059216976166\n",
      "Eval Loss:  0.3112981617450714\n",
      "Eval Loss:  0.27364861965179443\n",
      "Eval Loss:  0.2573869526386261\n",
      "Eval Loss:  0.29482415318489075\n",
      "Eval Loss:  0.22439749538898468\n",
      "Eval Loss:  0.3137800395488739\n",
      "Eval Loss:  0.2730664908885956\n",
      "Eval Loss:  0.2603773772716522\n",
      "Eval Loss:  0.22916260361671448\n",
      "Eval Loss:  0.33239805698394775\n",
      "Eval Loss:  0.26541581749916077\n",
      "Eval Loss:  0.2581607699394226\n",
      "Eval Loss:  0.20155048370361328\n",
      "Eval Loss:  0.3143851161003113\n",
      "Eval Loss:  0.2366042137145996\n",
      "Eval Loss:  0.2933870255947113\n",
      "Eval Loss:  0.22805120050907135\n",
      "Eval Loss:  0.22652265429496765\n",
      "Eval Loss:  0.28851118683815\n",
      "Eval Loss:  0.3008555769920349\n",
      "Eval Loss:  0.29225796461105347\n",
      "Eval Loss:  0.18637819588184357\n",
      "Eval Loss:  0.2954319715499878\n",
      "Eval Loss:  0.2543089985847473\n",
      "Eval Loss:  0.21280568838119507\n",
      "Eval Loss:  0.23555059731006622\n",
      "[[16104  2318]\n",
      " [  969 10092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91     18422\n",
      "           1       0.81      0.91      0.86     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.88      0.89      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8885120238781671\n",
      "pre:  0.8132151490733279\n",
      "rec:  0.9123949010035259\n",
      "ma F1:  0.8836751228444829\n",
      "mi F1:  0.8885120238781672\n",
      "we F1:  0.8895973498087127\n",
      "29483 461\n",
      "Loss:  0.06497364491224289\n",
      "Loss:  0.0527016706764698\n",
      "Loss:  0.050760332494974136\n",
      "57 **********\n",
      "Epoch:  3055.1132481098175  fold:  9  kers:  32\n",
      "epoch:  58\n",
      "29483 461\n",
      "Loss:  0.0829780101776123\n",
      "Loss:  0.08456224203109741\n",
      "Loss:  0.0797070562839508\n",
      "58 **********\n",
      "Epoch:  3095.0913541316986  fold:  9  kers:  32\n",
      "epoch:  59\n",
      "29483 461\n",
      "Loss:  0.07264561206102371\n",
      "Loss:  0.11117132008075714\n",
      "Loss:  0.0521811842918396\n",
      "59 **********\n",
      "Epoch:  3135.01261305809  fold:  9  kers:  32\n",
      "Eval Loss:  0.025976460427045822\n",
      "Eval Loss:  1.1397221088409424\n",
      "Eval Loss:  0.18552300333976746\n",
      "[[1616  126]\n",
      " [ 405 1261]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      1742\n",
      "           1       0.91      0.76      0.83      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8441901408450704\n",
      "pre:  0.9091564527757751\n",
      "rec:  0.7569027611044418\n",
      "ma F1:  0.8424809497617561\n",
      "mi F1:  0.8441901408450704\n",
      "we F1:  0.8428468610922684\n",
      "update!  Acc:  0.8571009389671361\n",
      "Epoch:  3138.928143978119  fold:  9  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29871 3020\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29871 467\n",
      "Loss:  0.169640451669693\n",
      "Loss:  0.16656850278377533\n",
      "Loss:  0.1731136292219162\n",
      "0 **********\n",
      "Epoch:  52.99031376838684  fold:  10  kers:  32\n",
      "epoch:  1\n",
      "29871 467\n",
      "Loss:  0.1441696733236313\n",
      "Loss:  0.13974489271640778\n",
      "Loss:  0.1330365687608719\n",
      "1 **********\n",
      "Epoch:  93.84208393096924  fold:  10  kers:  32\n",
      "epoch:  2\n",
      "29871 467\n",
      "Loss:  0.12416573613882065\n",
      "Loss:  0.10628906637430191\n",
      "Loss:  0.10009294748306274\n",
      "2 **********\n",
      "Epoch:  134.54026579856873  fold:  10  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.395693838596344\n",
      "Eval Loss:  0.38932114839553833\n",
      "Eval Loss:  0.2462034672498703\n",
      "[[1465  286]\n",
      " [ 139 1130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87      1751\n",
      "           1       0.80      0.89      0.84      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.86      0.86      0.86      3020\n",
      "weighted avg       0.86      0.86      0.86      3020\n",
      "\n",
      "acc:  0.859271523178808\n",
      "pre:  0.7980225988700564\n",
      "rec:  0.8904649330181245\n",
      "ma F1:  0.8575183097575259\n",
      "mi F1:  0.8592715231788081\n",
      "we F1:  0.8600408436950123\n",
      "update!  Acc:  0.859271523178808\n",
      "Eval Loss:  0.41558837890625\n",
      "Eval Loss:  0.45326676964759827\n",
      "Eval Loss:  0.41301804780960083\n",
      "Eval Loss:  0.45213010907173157\n",
      "Eval Loss:  0.3429035246372223\n",
      "Eval Loss:  0.3796566426753998\n",
      "Eval Loss:  0.45660215616226196\n",
      "Eval Loss:  0.4597609043121338\n",
      "Eval Loss:  0.48073360323905945\n",
      "Eval Loss:  0.4365854561328888\n",
      "Eval Loss:  0.44608408212661743\n",
      "Eval Loss:  0.4506462514400482\n",
      "Eval Loss:  0.3513769507408142\n",
      "Eval Loss:  0.4340974986553192\n",
      "Eval Loss:  0.333607017993927\n",
      "Eval Loss:  0.41877812147140503\n",
      "Eval Loss:  0.45416438579559326\n",
      "Eval Loss:  0.3597584664821625\n",
      "Eval Loss:  0.42818987369537354\n",
      "Eval Loss:  0.46206754446029663\n",
      "Eval Loss:  0.43468624353408813\n",
      "Eval Loss:  0.48658499121665955\n",
      "Eval Loss:  0.44631239771842957\n",
      "Eval Loss:  0.4087805449962616\n",
      "Eval Loss:  0.4404197931289673\n",
      "Eval Loss:  0.36089375615119934\n",
      "Eval Loss:  0.46899712085723877\n",
      "Eval Loss:  0.46991366147994995\n",
      "Eval Loss:  0.43617090582847595\n",
      "[[14895  3518]\n",
      " [ 2366  9092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.84     18413\n",
      "           1       0.72      0.79      0.76     11458\n",
      "\n",
      "    accuracy                           0.80     29871\n",
      "   macro avg       0.79      0.80      0.80     29871\n",
      "weighted avg       0.81      0.80      0.80     29871\n",
      "\n",
      "acc:  0.8030196511666834\n",
      "pre:  0.72101506740682\n",
      "rec:  0.7935067201954966\n",
      "ma F1:  0.7952939797594095\n",
      "mi F1:  0.8030196511666834\n",
      "we F1:  0.8045533360643535\n",
      "29871 467\n",
      "Loss:  0.11261975020170212\n",
      "Loss:  0.10125721246004105\n",
      "Loss:  0.09899276494979858\n",
      "3 **********\n",
      "Epoch:  213.37148690223694  fold:  10  kers:  32\n",
      "epoch:  4\n",
      "29871 467\n",
      "Loss:  0.09426049888134003\n",
      "Loss:  0.105913445353508\n",
      "Loss:  0.10570071637630463\n",
      "4 **********\n",
      "Epoch:  253.99087834358215  fold:  10  kers:  32\n",
      "epoch:  5\n",
      "29871 467\n",
      "Loss:  0.09332257509231567\n",
      "Loss:  0.10888252407312393\n",
      "Loss:  0.11500093340873718\n",
      "5 **********\n",
      "Epoch:  294.6092734336853  fold:  10  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.547939658164978\n",
      "Eval Loss:  0.18588168919086456\n",
      "Eval Loss:  0.16269034147262573\n",
      "[[1629  122]\n",
      " [ 213 1056]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      1751\n",
      "           1       0.90      0.83      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.88      0.88      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8890728476821192\n",
      "pre:  0.8964346349745331\n",
      "rec:  0.8321513002364066\n",
      "ma F1:  0.884930410593818\n",
      "mi F1:  0.8890728476821192\n",
      "we F1:  0.888414973729178\n",
      "update!  Acc:  0.8890728476821192\n",
      "Eval Loss:  0.4161239564418793\n",
      "Eval Loss:  0.37524348497390747\n",
      "Eval Loss:  0.3750337064266205\n",
      "Eval Loss:  0.3909536302089691\n",
      "Eval Loss:  0.31746575236320496\n",
      "Eval Loss:  0.3225606083869934\n",
      "Eval Loss:  0.3952263593673706\n",
      "Eval Loss:  0.4446379542350769\n",
      "Eval Loss:  0.47271719574928284\n",
      "Eval Loss:  0.336270272731781\n",
      "Eval Loss:  0.3983099162578583\n",
      "Eval Loss:  0.3519214391708374\n",
      "Eval Loss:  0.3028101325035095\n",
      "Eval Loss:  0.4202226996421814\n",
      "Eval Loss:  0.2878681719303131\n",
      "Eval Loss:  0.372613787651062\n",
      "Eval Loss:  0.4098702073097229\n",
      "Eval Loss:  0.3162894546985626\n",
      "Eval Loss:  0.318798303604126\n",
      "Eval Loss:  0.49077385663986206\n",
      "Eval Loss:  0.40202999114990234\n",
      "Eval Loss:  0.4972818195819855\n",
      "Eval Loss:  0.3795947730541229\n",
      "Eval Loss:  0.3285040259361267\n",
      "Eval Loss:  0.45015862584114075\n",
      "Eval Loss:  0.25030744075775146\n",
      "Eval Loss:  0.4490887522697449\n",
      "Eval Loss:  0.46334412693977356\n",
      "Eval Loss:  0.4059153199195862\n",
      "[[17001  1412]\n",
      " [ 3451  8007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87     18413\n",
      "           1       0.85      0.70      0.77     11458\n",
      "\n",
      "    accuracy                           0.84     29871\n",
      "   macro avg       0.84      0.81      0.82     29871\n",
      "weighted avg       0.84      0.84      0.83     29871\n",
      "\n",
      "acc:  0.8371999598272573\n",
      "pre:  0.8500902431255972\n",
      "rec:  0.6988130563798219\n",
      "ma F1:  0.8209693995857859\n",
      "mi F1:  0.8371999598272573\n",
      "we F1:  0.833520383183677\n",
      "29871 467\n",
      "Loss:  0.10659719258546829\n",
      "Loss:  0.09882689267396927\n",
      "Loss:  0.10477141290903091\n",
      "6 **********\n",
      "Epoch:  373.52526807785034  fold:  10  kers:  32\n",
      "epoch:  7\n",
      "29871 467\n",
      "Loss:  0.0858161672949791\n",
      "Loss:  0.1208844780921936\n",
      "Loss:  0.0773935616016388\n",
      "7 **********\n",
      "Epoch:  414.2025055885315  fold:  10  kers:  32\n",
      "epoch:  8\n",
      "29871 467\n",
      "Loss:  0.07922249287366867\n",
      "Loss:  0.09650412201881409\n",
      "Loss:  0.11252729594707489\n",
      "8 **********\n",
      "Epoch:  454.6952362060547  fold:  10  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.5344744920730591\n",
      "Eval Loss:  0.1399768888950348\n",
      "Eval Loss:  0.14027468860149384\n",
      "[[1644  107]\n",
      " [ 217 1052]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1751\n",
      "           1       0.91      0.83      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.88      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8927152317880794\n",
      "pre:  0.907679033649698\n",
      "rec:  0.8289992119779354\n",
      "ma F1:  0.88842792011253\n",
      "mi F1:  0.8927152317880794\n",
      "we F1:  0.891918602929447\n",
      "update!  Acc:  0.8927152317880794\n",
      "Eval Loss:  0.37620532512664795\n",
      "Eval Loss:  0.3415917754173279\n",
      "Eval Loss:  0.3425859808921814\n",
      "Eval Loss:  0.3423183262348175\n",
      "Eval Loss:  0.31478387117385864\n",
      "Eval Loss:  0.27395153045654297\n",
      "Eval Loss:  0.38331207633018494\n",
      "Eval Loss:  0.4192447066307068\n",
      "Eval Loss:  0.46598494052886963\n",
      "Eval Loss:  0.286998450756073\n",
      "Eval Loss:  0.3693217635154724\n",
      "Eval Loss:  0.3051905632019043\n",
      "Eval Loss:  0.2958889603614807\n",
      "Eval Loss:  0.34295910596847534\n",
      "Eval Loss:  0.2704898715019226\n",
      "Eval Loss:  0.34432557225227356\n",
      "Eval Loss:  0.37124544382095337\n",
      "Eval Loss:  0.28165268898010254\n",
      "Eval Loss:  0.2813369333744049\n",
      "Eval Loss:  0.46136555075645447\n",
      "Eval Loss:  0.3527469336986542\n",
      "Eval Loss:  0.5060168504714966\n",
      "Eval Loss:  0.35984110832214355\n",
      "Eval Loss:  0.3169265389442444\n",
      "Eval Loss:  0.4265817701816559\n",
      "Eval Loss:  0.2598293125629425\n",
      "Eval Loss:  0.4151502847671509\n",
      "Eval Loss:  0.40566399693489075\n",
      "Eval Loss:  0.3646470308303833\n",
      "[[17131  1282]\n",
      " [ 3228  8230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88     18413\n",
      "           1       0.87      0.72      0.78     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.85      0.82      0.83     29871\n",
      "weighted avg       0.85      0.85      0.85     29871\n",
      "\n",
      "acc:  0.8490174416658297\n",
      "pre:  0.8652228763666947\n",
      "rec:  0.7182754407400943\n",
      "ma F1:  0.8343048985839523\n",
      "mi F1:  0.8490174416658297\n",
      "we F1:  0.8458008807358967\n",
      "29871 467\n",
      "Loss:  0.11131174862384796\n",
      "Loss:  0.09490262717008591\n",
      "Loss:  0.07397416234016418\n",
      "9 **********\n",
      "Epoch:  533.0716736316681  fold:  10  kers:  32\n",
      "epoch:  10\n",
      "29871 467\n",
      "Loss:  0.08390665799379349\n",
      "Loss:  0.08274388313293457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08429219573736191\n",
      "10 **********\n",
      "Epoch:  573.5743775367737  fold:  10  kers:  32\n",
      "epoch:  11\n",
      "29871 467\n",
      "Loss:  0.08872663974761963\n",
      "Loss:  0.09791704267263412\n",
      "Loss:  0.1052226573228836\n",
      "11 **********\n",
      "Epoch:  613.9544098377228  fold:  10  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.5289256572723389\n",
      "Eval Loss:  0.12434698641300201\n",
      "Eval Loss:  0.1512708216905594\n",
      "[[1633  118]\n",
      " [ 206 1063]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1751\n",
      "           1       0.90      0.84      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.89      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8927152317880794\n",
      "pre:  0.9000846740050804\n",
      "rec:  0.8376674546887313\n",
      "ma F1:  0.8887522028309931\n",
      "mi F1:  0.8927152317880794\n",
      "we F1:  0.8921033957385643\n",
      "Eval Loss:  0.34752362966537476\n",
      "Eval Loss:  0.3224186897277832\n",
      "Eval Loss:  0.3285823166370392\n",
      "Eval Loss:  0.31869006156921387\n",
      "Eval Loss:  0.28826266527175903\n",
      "Eval Loss:  0.27850785851478577\n",
      "Eval Loss:  0.350748747587204\n",
      "Eval Loss:  0.36117440462112427\n",
      "Eval Loss:  0.4155319631099701\n",
      "Eval Loss:  0.2616645395755768\n",
      "Eval Loss:  0.31238245964050293\n",
      "Eval Loss:  0.2855920195579529\n",
      "Eval Loss:  0.28619852662086487\n",
      "Eval Loss:  0.3391370475292206\n",
      "Eval Loss:  0.23479239642620087\n",
      "Eval Loss:  0.32783645391464233\n",
      "Eval Loss:  0.34914252161979675\n",
      "Eval Loss:  0.24746760725975037\n",
      "Eval Loss:  0.267925888299942\n",
      "Eval Loss:  0.4428950548171997\n",
      "Eval Loss:  0.3213219940662384\n",
      "Eval Loss:  0.4654507637023926\n",
      "Eval Loss:  0.3570519983768463\n",
      "Eval Loss:  0.3175291419029236\n",
      "Eval Loss:  0.41841182112693787\n",
      "Eval Loss:  0.24553798139095306\n",
      "Eval Loss:  0.39671778678894043\n",
      "Eval Loss:  0.3789792060852051\n",
      "Eval Loss:  0.34259122610092163\n",
      "[[16991  1422]\n",
      " [ 2683  8775]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     18413\n",
      "           1       0.86      0.77      0.81     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.86      0.84      0.85     29871\n",
      "weighted avg       0.86      0.86      0.86     29871\n",
      "\n",
      "acc:  0.8625757423588095\n",
      "pre:  0.8605472197705207\n",
      "rec:  0.7658404608134055\n",
      "ma F1:  0.8513284157477397\n",
      "mi F1:  0.8625757423588095\n",
      "we F1:  0.8608494912808445\n",
      "29871 467\n",
      "Loss:  0.07052692770957947\n",
      "Loss:  0.0787123590707779\n",
      "Loss:  0.07745487242937088\n",
      "12 **********\n",
      "Epoch:  692.5193424224854  fold:  10  kers:  32\n",
      "epoch:  13\n",
      "29871 467\n",
      "Loss:  0.0699767991900444\n",
      "Loss:  0.11304742097854614\n",
      "Loss:  0.06987407803535461\n",
      "13 **********\n",
      "Epoch:  732.9053590297699  fold:  10  kers:  32\n",
      "epoch:  14\n",
      "29871 467\n",
      "Loss:  0.10002205520868301\n",
      "Loss:  0.09666533768177032\n",
      "Loss:  0.061054959893226624\n",
      "14 **********\n",
      "Epoch:  773.3950974941254  fold:  10  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.5810760855674744\n",
      "Eval Loss:  0.1118951290845871\n",
      "Eval Loss:  0.11324689537286758\n",
      "[[1658   93]\n",
      " [ 252 1017]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1751\n",
      "           1       0.92      0.80      0.85      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.87      0.88      3020\n",
      "weighted avg       0.89      0.89      0.88      3020\n",
      "\n",
      "acc:  0.8857615894039735\n",
      "pre:  0.9162162162162162\n",
      "rec:  0.8014184397163121\n",
      "ma F1:  0.8803722685489291\n",
      "mi F1:  0.8857615894039735\n",
      "we F1:  0.8844247687862636\n",
      "Eval Loss:  0.34354913234710693\n",
      "Eval Loss:  0.3175126612186432\n",
      "Eval Loss:  0.3522123396396637\n",
      "Eval Loss:  0.3162427544593811\n",
      "Eval Loss:  0.31130579113960266\n",
      "Eval Loss:  0.27515292167663574\n",
      "Eval Loss:  0.35164788365364075\n",
      "Eval Loss:  0.37883350253105164\n",
      "Eval Loss:  0.44422057271003723\n",
      "Eval Loss:  0.2720622718334198\n",
      "Eval Loss:  0.3237186074256897\n",
      "Eval Loss:  0.2886601686477661\n",
      "Eval Loss:  0.27612629532814026\n",
      "Eval Loss:  0.3142719566822052\n",
      "Eval Loss:  0.2612278461456299\n",
      "Eval Loss:  0.3199407458305359\n",
      "Eval Loss:  0.3683215379714966\n",
      "Eval Loss:  0.25505879521369934\n",
      "Eval Loss:  0.2535322606563568\n",
      "Eval Loss:  0.4311322867870331\n",
      "Eval Loss:  0.33474305272102356\n",
      "Eval Loss:  0.4625250995159149\n",
      "Eval Loss:  0.3434506058692932\n",
      "Eval Loss:  0.31259816884994507\n",
      "Eval Loss:  0.406935453414917\n",
      "Eval Loss:  0.25256654620170593\n",
      "Eval Loss:  0.37603455781936646\n",
      "Eval Loss:  0.3668840229511261\n",
      "Eval Loss:  0.34400102496147156\n",
      "[[17401  1012]\n",
      " [ 3167  8291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.89     18413\n",
      "           1       0.89      0.72      0.80     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.87      0.83      0.85     29871\n",
      "weighted avg       0.86      0.86      0.86     29871\n",
      "\n",
      "acc:  0.8600984232198453\n",
      "pre:  0.891217886703214\n",
      "rec:  0.7235992319776575\n",
      "ma F1:  0.8457515216517647\n",
      "mi F1:  0.8600984232198453\n",
      "we F1:  0.8567046171957823\n",
      "29871 467\n",
      "Loss:  0.10530620813369751\n",
      "Loss:  0.115378737449646\n",
      "Loss:  0.07081151753664017\n",
      "15 **********\n",
      "Epoch:  852.0787136554718  fold:  10  kers:  32\n",
      "epoch:  16\n",
      "29871 467\n",
      "Loss:  0.06177196651697159\n",
      "Loss:  0.10690967738628387\n",
      "Loss:  0.08912323415279388\n",
      "16 **********\n",
      "Epoch:  892.5784256458282  fold:  10  kers:  32\n",
      "epoch:  17\n",
      "29871 467\n",
      "Loss:  0.033949416130781174\n",
      "Loss:  0.07536882162094116\n",
      "Loss:  0.07044646888971329\n",
      "17 **********\n",
      "Epoch:  933.1010761260986  fold:  10  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.4397229850292206\n",
      "Eval Loss:  0.13293451070785522\n",
      "Eval Loss:  0.1310170739889145\n",
      "[[1609  142]\n",
      " [ 180 1089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1751\n",
      "           1       0.88      0.86      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.89      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8933774834437086\n",
      "pre:  0.8846466287571081\n",
      "rec:  0.8581560283687943\n",
      "ma F1:  0.8901197740112995\n",
      "mi F1:  0.8933774834437086\n",
      "we F1:  0.8931394200621096\n",
      "update!  Acc:  0.8933774834437086\n",
      "Eval Loss:  0.3017314374446869\n",
      "Eval Loss:  0.33382153511047363\n",
      "Eval Loss:  0.3267432451248169\n",
      "Eval Loss:  0.3077467381954193\n",
      "Eval Loss:  0.255217045545578\n",
      "Eval Loss:  0.25913316011428833\n",
      "Eval Loss:  0.3388320207595825\n",
      "Eval Loss:  0.3276989459991455\n",
      "Eval Loss:  0.4067928194999695\n",
      "Eval Loss:  0.26038315892219543\n",
      "Eval Loss:  0.25842124223709106\n",
      "Eval Loss:  0.24660450220108032\n",
      "Eval Loss:  0.3117050528526306\n",
      "Eval Loss:  0.2689814567565918\n",
      "Eval Loss:  0.2322658747434616\n",
      "Eval Loss:  0.30828267335891724\n",
      "Eval Loss:  0.3328203856945038\n",
      "Eval Loss:  0.20830222964286804\n",
      "Eval Loss:  0.22572851181030273\n",
      "Eval Loss:  0.4092298746109009\n",
      "Eval Loss:  0.2985769510269165\n",
      "Eval Loss:  0.43370646238327026\n",
      "Eval Loss:  0.3368314802646637\n",
      "Eval Loss:  0.30644890666007996\n",
      "Eval Loss:  0.37723276019096375\n",
      "Eval Loss:  0.2473832666873932\n",
      "Eval Loss:  0.3542376160621643\n",
      "Eval Loss:  0.3341405987739563\n",
      "Eval Loss:  0.3123458921909332\n",
      "[[16658  1755]\n",
      " [ 2146  9312]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90     18413\n",
      "           1       0.84      0.81      0.83     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.86      0.86      0.86     29871\n",
      "weighted avg       0.87      0.87      0.87     29871\n",
      "\n",
      "acc:  0.869405108633792\n",
      "pre:  0.8414204391433993\n",
      "rec:  0.8127072787572002\n",
      "ma F1:  0.8609984797741249\n",
      "mi F1:  0.8694051086337921\n",
      "we F1:  0.8689576553416425\n",
      "29871 467\n",
      "Loss:  0.10091200470924377\n",
      "Loss:  0.09202049672603607\n",
      "Loss:  0.06077564135193825\n",
      "18 **********\n",
      "Epoch:  1014.3398599624634  fold:  10  kers:  32\n",
      "epoch:  19\n",
      "29871 467\n",
      "Loss:  0.09635142236948013\n",
      "Loss:  0.05909254401922226\n",
      "Loss:  0.07209999859333038\n",
      "19 **********\n",
      "Epoch:  1055.0101161003113  fold:  10  kers:  32\n",
      "epoch:  20\n",
      "29871 467\n",
      "Loss:  0.08578888326883316\n",
      "Loss:  0.0722108706831932\n",
      "Loss:  0.07530315965414047\n",
      "20 **********\n",
      "Epoch:  1095.5946011543274  fold:  10  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.7835671901702881\n",
      "Eval Loss:  0.08809696137905121\n",
      "Eval Loss:  0.08758027851581573\n",
      "[[1681   70]\n",
      " [ 335  934]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1751\n",
      "           1       0.93      0.74      0.82      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.88      0.85      0.86      3020\n",
      "weighted avg       0.87      0.87      0.86      3020\n",
      "\n",
      "acc:  0.8658940397350994\n",
      "pre:  0.9302788844621513\n",
      "rec:  0.7360126083530338\n",
      "ma F1:  0.8571543859653221\n",
      "mi F1:  0.8658940397350994\n",
      "we F1:  0.8627936270858477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.33556607365608215\n",
      "Eval Loss:  0.32298028469085693\n",
      "Eval Loss:  0.4044862687587738\n",
      "Eval Loss:  0.2916210889816284\n",
      "Eval Loss:  0.2909543216228485\n",
      "Eval Loss:  0.29655006527900696\n",
      "Eval Loss:  0.3474404513835907\n",
      "Eval Loss:  0.3794025778770447\n",
      "Eval Loss:  0.42402830719947815\n",
      "Eval Loss:  0.2736643850803375\n",
      "Eval Loss:  0.3081335425376892\n",
      "Eval Loss:  0.31237998604774475\n",
      "Eval Loss:  0.2704283893108368\n",
      "Eval Loss:  0.3208325505256653\n",
      "Eval Loss:  0.28115367889404297\n",
      "Eval Loss:  0.31485623121261597\n",
      "Eval Loss:  0.3831259310245514\n",
      "Eval Loss:  0.24390938878059387\n",
      "Eval Loss:  0.25800853967666626\n",
      "Eval Loss:  0.4161835014820099\n",
      "Eval Loss:  0.337375283241272\n",
      "Eval Loss:  0.4474901258945465\n",
      "Eval Loss:  0.3391026258468628\n",
      "Eval Loss:  0.3069297969341278\n",
      "Eval Loss:  0.4176749289035797\n",
      "Eval Loss:  0.2539714574813843\n",
      "Eval Loss:  0.3818112909793854\n",
      "Eval Loss:  0.3757590055465698\n",
      "Eval Loss:  0.32811999320983887\n",
      "[[17657   756]\n",
      " [ 3375  8083]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     18413\n",
      "           1       0.91      0.71      0.80     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.88      0.83      0.85     29871\n",
      "weighted avg       0.87      0.86      0.86     29871\n",
      "\n",
      "acc:  0.8617053329316059\n",
      "pre:  0.9144699626654599\n",
      "rec:  0.7054459766102287\n",
      "ma F1:  0.8458721413302233\n",
      "mi F1:  0.8617053329316059\n",
      "we F1:  0.8573741099522847\n",
      "29871 467\n",
      "Loss:  0.0604705736041069\n",
      "Loss:  0.06636443734169006\n",
      "Loss:  0.07968262583017349\n",
      "21 **********\n",
      "Epoch:  1180.7967882156372  fold:  10  kers:  32\n",
      "epoch:  22\n",
      "29871 467\n",
      "Loss:  0.07864002883434296\n",
      "Loss:  0.05674436315894127\n",
      "Loss:  0.06085050851106644\n",
      "22 **********\n",
      "Epoch:  1221.2955026626587  fold:  10  kers:  32\n",
      "epoch:  23\n",
      "29871 467\n",
      "Loss:  0.08620497584342957\n",
      "Loss:  0.06870169192552567\n",
      "Loss:  0.09023836255073547\n",
      "23 **********\n",
      "Epoch:  1261.8231399059296  fold:  10  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.5536437034606934\n",
      "Eval Loss:  0.10287699848413467\n",
      "Eval Loss:  0.09363412857055664\n",
      "[[1665   86]\n",
      " [ 238 1031]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1751\n",
      "           1       0.92      0.81      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.88      0.89      3020\n",
      "weighted avg       0.90      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8927152317880794\n",
      "pre:  0.9230080572963295\n",
      "rec:  0.8124507486209613\n",
      "ma F1:  0.8877689642784883\n",
      "mi F1:  0.8927152317880794\n",
      "we F1:  0.8915293758551807\n",
      "Eval Loss:  0.2636038661003113\n",
      "Eval Loss:  0.3177441656589508\n",
      "Eval Loss:  0.3457243740558624\n",
      "Eval Loss:  0.2839110791683197\n",
      "Eval Loss:  0.25332891941070557\n",
      "Eval Loss:  0.26025205850601196\n",
      "Eval Loss:  0.3051167130470276\n",
      "Eval Loss:  0.33781617879867554\n",
      "Eval Loss:  0.37647944688796997\n",
      "Eval Loss:  0.2463352382183075\n",
      "Eval Loss:  0.2605043649673462\n",
      "Eval Loss:  0.26700955629348755\n",
      "Eval Loss:  0.25578537583351135\n",
      "Eval Loss:  0.28536689281463623\n",
      "Eval Loss:  0.2428124099969864\n",
      "Eval Loss:  0.29469621181488037\n",
      "Eval Loss:  0.3349069058895111\n",
      "Eval Loss:  0.21913127601146698\n",
      "Eval Loss:  0.22398145496845245\n",
      "Eval Loss:  0.3686932921409607\n",
      "Eval Loss:  0.29382944107055664\n",
      "Eval Loss:  0.4011183977127075\n",
      "Eval Loss:  0.31123799085617065\n",
      "Eval Loss:  0.27159595489501953\n",
      "Eval Loss:  0.3710364103317261\n",
      "Eval Loss:  0.2257230281829834\n",
      "Eval Loss:  0.34365764260292053\n",
      "Eval Loss:  0.3443838357925415\n",
      "Eval Loss:  0.27887919545173645\n",
      "[[17395  1018]\n",
      " [ 2656  8802]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     18413\n",
      "           1       0.90      0.77      0.83     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.88      0.86      0.87     29871\n",
      "weighted avg       0.88      0.88      0.87     29871\n",
      "\n",
      "acc:  0.8770044524789931\n",
      "pre:  0.8963340122199592\n",
      "rec:  0.7681968930005236\n",
      "ma F1:  0.8659077545703115\n",
      "mi F1:  0.8770044524789931\n",
      "we F1:  0.8748891969018463\n",
      "29871 467\n",
      "Loss:  0.06587399542331696\n",
      "Loss:  0.0832507461309433\n",
      "Loss:  0.08044148236513138\n",
      "24 **********\n",
      "Epoch:  1340.1796305179596  fold:  10  kers:  32\n",
      "epoch:  25\n",
      "29871 467\n",
      "Loss:  0.11310918629169464\n",
      "Loss:  0.06034678593277931\n",
      "Loss:  0.0626503974199295\n",
      "25 **********\n",
      "Epoch:  1380.6025483608246  fold:  10  kers:  32\n",
      "epoch:  26\n",
      "29871 467\n",
      "Loss:  0.06485792249441147\n",
      "Loss:  0.057699233293533325\n",
      "Loss:  0.09434185922145844\n",
      "26 **********\n",
      "Epoch:  1421.0952789783478  fold:  10  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.6526660919189453\n",
      "Eval Loss:  0.09839107096195221\n",
      "Eval Loss:  0.08409903943538666\n",
      "[[1666   85]\n",
      " [ 299  970]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      1751\n",
      "           1       0.92      0.76      0.83      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.88      0.86      0.87      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8728476821192053\n",
      "pre:  0.919431279620853\n",
      "rec:  0.764381402679275\n",
      "ma F1:  0.8657153602878376\n",
      "mi F1:  0.8728476821192053\n",
      "we F1:  0.8706546981078366\n",
      "Eval Loss:  0.2720579206943512\n",
      "Eval Loss:  0.305547297000885\n",
      "Eval Loss:  0.35036349296569824\n",
      "Eval Loss:  0.27802979946136475\n",
      "Eval Loss:  0.27028289437294006\n",
      "Eval Loss:  0.25665947794914246\n",
      "Eval Loss:  0.3053385019302368\n",
      "Eval Loss:  0.32302895188331604\n",
      "Eval Loss:  0.37352198362350464\n",
      "Eval Loss:  0.24653874337673187\n",
      "Eval Loss:  0.2668711245059967\n",
      "Eval Loss:  0.2847447991371155\n",
      "Eval Loss:  0.25250837206840515\n",
      "Eval Loss:  0.27686116099357605\n",
      "Eval Loss:  0.27223387360572815\n",
      "Eval Loss:  0.30383121967315674\n",
      "Eval Loss:  0.341866135597229\n",
      "Eval Loss:  0.21865876019001007\n",
      "Eval Loss:  0.23567618429660797\n",
      "Eval Loss:  0.36535337567329407\n",
      "Eval Loss:  0.2868635654449463\n",
      "Eval Loss:  0.3891444802284241\n",
      "Eval Loss:  0.31042543053627014\n",
      "Eval Loss:  0.2737717032432556\n",
      "Eval Loss:  0.35603657364845276\n",
      "Eval Loss:  0.23652420938014984\n",
      "Eval Loss:  0.3346596658229828\n",
      "Eval Loss:  0.33963921666145325\n",
      "Eval Loss:  0.2618546485900879\n",
      "[[17607   806]\n",
      " [ 2959  8499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.90     18413\n",
      "           1       0.91      0.74      0.82     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.88      0.85      0.86     29871\n",
      "weighted avg       0.88      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8739580194837803\n",
      "pre:  0.9133799032778076\n",
      "rec:  0.7417524873450864\n",
      "ma F1:  0.8610386753882446\n",
      "mi F1:  0.8739580194837803\n",
      "we F1:  0.8709040726416977\n",
      "29871 467\n",
      "Loss:  0.0723702684044838\n",
      "Loss:  0.08957803249359131\n",
      "Loss:  0.03938121348619461\n",
      "27 **********\n",
      "Epoch:  1499.4846813678741  fold:  10  kers:  32\n",
      "epoch:  28\n",
      "29871 467\n",
      "Loss:  0.096856489777565\n",
      "Loss:  0.09819633513689041\n",
      "Loss:  0.08919991552829742\n",
      "28 **********\n",
      "Epoch:  1540.0023458003998  fold:  10  kers:  32\n",
      "epoch:  29\n",
      "29871 467\n",
      "Loss:  0.04809870943427086\n",
      "Loss:  0.053494811058044434\n",
      "Loss:  0.07159799337387085\n",
      "29 **********\n",
      "Epoch:  1580.4511940479279  fold:  10  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.731753945350647\n",
      "Eval Loss:  0.09174132347106934\n",
      "Eval Loss:  0.06550364196300507\n",
      "[[1675   76]\n",
      " [ 332  937]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1751\n",
      "           1       0.92      0.74      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.88      0.85      0.86      3020\n",
      "weighted avg       0.87      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8649006622516556\n",
      "pre:  0.9249753208292202\n",
      "rec:  0.7383766745468873\n",
      "ma F1:  0.8563205389705584\n",
      "mi F1:  0.8649006622516556\n",
      "we F1:  0.8619243593248794\n",
      "Eval Loss:  0.28436943888664246\n",
      "Eval Loss:  0.29234883189201355\n",
      "Eval Loss:  0.36881333589553833\n",
      "Eval Loss:  0.2887733578681946\n",
      "Eval Loss:  0.27858495712280273\n",
      "Eval Loss:  0.2544325888156891\n",
      "Eval Loss:  0.31458207964897156\n",
      "Eval Loss:  0.34133175015449524\n",
      "Eval Loss:  0.3715208172798157\n",
      "Eval Loss:  0.258334755897522\n",
      "Eval Loss:  0.28213587403297424\n",
      "Eval Loss:  0.28450796008110046\n",
      "Eval Loss:  0.2639785408973694\n",
      "Eval Loss:  0.30548250675201416\n",
      "Eval Loss:  0.2781628668308258\n",
      "Eval Loss:  0.31015658378601074\n",
      "Eval Loss:  0.3376380503177643\n",
      "Eval Loss:  0.23522476851940155\n",
      "Eval Loss:  0.25042736530303955\n",
      "Eval Loss:  0.38298463821411133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.28975963592529297\n",
      "Eval Loss:  0.40582406520843506\n",
      "Eval Loss:  0.32254883646965027\n",
      "Eval Loss:  0.25761404633522034\n",
      "Eval Loss:  0.3416938781738281\n",
      "Eval Loss:  0.23656535148620605\n",
      "Eval Loss:  0.34883713722229004\n",
      "Eval Loss:  0.3579941391944885\n",
      "Eval Loss:  0.28738704323768616\n",
      "[[17711   702]\n",
      " [ 3122  8336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     18413\n",
      "           1       0.92      0.73      0.81     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.89      0.84      0.86     29871\n",
      "weighted avg       0.88      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8719828596297412\n",
      "pre:  0.9223279486612083\n",
      "rec:  0.7275266189561879\n",
      "ma F1:  0.8579951643515393\n",
      "mi F1:  0.8719828596297412\n",
      "we F1:  0.8683721692219281\n",
      "29871 467\n",
      "Loss:  0.07826873660087585\n",
      "Loss:  0.05219455435872078\n",
      "Loss:  0.09428860247135162\n",
      "30 **********\n",
      "Epoch:  1659.2066175937653  fold:  10  kers:  32\n",
      "epoch:  31\n",
      "29871 467\n",
      "Loss:  0.06854447722434998\n",
      "Loss:  0.07430791109800339\n",
      "Loss:  0.09264954179525375\n",
      "31 **********\n",
      "Epoch:  1699.8180303573608  fold:  10  kers:  32\n",
      "epoch:  32\n",
      "29871 467\n",
      "Loss:  0.07754316926002502\n",
      "Loss:  0.08952596038579941\n",
      "Loss:  0.0934266448020935\n",
      "32 **********\n",
      "Epoch:  1740.3157482147217  fold:  10  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.7232252955436707\n",
      "Eval Loss:  0.08795743435621262\n",
      "Eval Loss:  0.07274699211120605\n",
      "[[1661   90]\n",
      " [ 301  968]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.89      1751\n",
      "           1       0.91      0.76      0.83      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.88      0.86      0.86      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8705298013245033\n",
      "pre:  0.9149338374291115\n",
      "rec:  0.7628053585500394\n",
      "ma F1:  0.8633334070203171\n",
      "mi F1:  0.8705298013245033\n",
      "we F1:  0.8683386913704149\n",
      "Eval Loss:  0.244117870926857\n",
      "Eval Loss:  0.2836690843105316\n",
      "Eval Loss:  0.3346318006515503\n",
      "Eval Loss:  0.25773659348487854\n",
      "Eval Loss:  0.24647270143032074\n",
      "Eval Loss:  0.26645493507385254\n",
      "Eval Loss:  0.29296839237213135\n",
      "Eval Loss:  0.293637216091156\n",
      "Eval Loss:  0.33426380157470703\n",
      "Eval Loss:  0.23405176401138306\n",
      "Eval Loss:  0.24245457351207733\n",
      "Eval Loss:  0.2613716423511505\n",
      "Eval Loss:  0.25539326667785645\n",
      "Eval Loss:  0.2648079991340637\n",
      "Eval Loss:  0.2650352120399475\n",
      "Eval Loss:  0.2761072814464569\n",
      "Eval Loss:  0.2950167655944824\n",
      "Eval Loss:  0.19133520126342773\n",
      "Eval Loss:  0.25072452425956726\n",
      "Eval Loss:  0.3482508361339569\n",
      "Eval Loss:  0.25622791051864624\n",
      "Eval Loss:  0.36350366473197937\n",
      "Eval Loss:  0.3160746395587921\n",
      "Eval Loss:  0.2578316926956177\n",
      "Eval Loss:  0.3347618579864502\n",
      "Eval Loss:  0.22461988031864166\n",
      "Eval Loss:  0.3315495550632477\n",
      "Eval Loss:  0.3102629482746124\n",
      "Eval Loss:  0.24262695014476776\n",
      "[[17477   936]\n",
      " [ 2602  8856]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18413\n",
      "           1       0.90      0.77      0.83     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.89      0.86      0.87     29871\n",
      "weighted avg       0.88      0.88      0.88     29871\n",
      "\n",
      "acc:  0.8815573633289813\n",
      "pre:  0.9044117647058824\n",
      "rec:  0.77290975737476\n",
      "ma F1:  0.8707953395969217\n",
      "mi F1:  0.8815573633289813\n",
      "we F1:  0.8794776125416468\n",
      "29871 467\n",
      "Loss:  0.08547289669513702\n",
      "Loss:  0.08036527782678604\n",
      "Loss:  0.06126612797379494\n",
      "33 **********\n",
      "Epoch:  1818.8128628730774  fold:  10  kers:  32\n",
      "epoch:  34\n",
      "29871 467\n",
      "Loss:  0.05896507948637009\n",
      "Loss:  0.08356556296348572\n",
      "Loss:  0.10438723862171173\n",
      "34 **********\n",
      "Epoch:  1859.2377746105194  fold:  10  kers:  32\n",
      "epoch:  35\n",
      "29871 467\n",
      "Loss:  0.08023391664028168\n",
      "Loss:  0.06432738900184631\n",
      "Loss:  0.07610657066106796\n",
      "35 **********\n",
      "Epoch:  1899.7055718898773  fold:  10  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.65049809217453\n",
      "Eval Loss:  0.08549773693084717\n",
      "Eval Loss:  0.06677919626235962\n",
      "[[1662   89]\n",
      " [ 294  975]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      1751\n",
      "           1       0.92      0.77      0.84      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.88      0.86      0.87      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8731788079470199\n",
      "pre:  0.9163533834586466\n",
      "rec:  0.7683215130023641\n",
      "ma F1:  0.8662578217944966\n",
      "mi F1:  0.8731788079470199\n",
      "we F1:  0.8711135937384794\n",
      "Eval Loss:  0.2238701581954956\n",
      "Eval Loss:  0.2803817093372345\n",
      "Eval Loss:  0.32127687335014343\n",
      "Eval Loss:  0.26367151737213135\n",
      "Eval Loss:  0.23978681862354279\n",
      "Eval Loss:  0.2643586993217468\n",
      "Eval Loss:  0.2776404619216919\n",
      "Eval Loss:  0.2647332549095154\n",
      "Eval Loss:  0.31382888555526733\n",
      "Eval Loss:  0.233604297041893\n",
      "Eval Loss:  0.21937839686870575\n",
      "Eval Loss:  0.24051029980182648\n",
      "Eval Loss:  0.23687505722045898\n",
      "Eval Loss:  0.2665829062461853\n",
      "Eval Loss:  0.2399149388074875\n",
      "Eval Loss:  0.26928889751434326\n",
      "Eval Loss:  0.2711511254310608\n",
      "Eval Loss:  0.19039204716682434\n",
      "Eval Loss:  0.22839388251304626\n",
      "Eval Loss:  0.33009856939315796\n",
      "Eval Loss:  0.23940087854862213\n",
      "Eval Loss:  0.34515121579170227\n",
      "Eval Loss:  0.29891860485076904\n",
      "Eval Loss:  0.25581130385398865\n",
      "Eval Loss:  0.32732704281806946\n",
      "Eval Loss:  0.2045428305864334\n",
      "Eval Loss:  0.3219011425971985\n",
      "Eval Loss:  0.29876238107681274\n",
      "Eval Loss:  0.23011773824691772\n",
      "[[17364  1049]\n",
      " [ 2272  9186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18413\n",
      "           1       0.90      0.80      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8888219343175655\n",
      "pre:  0.8975085490962385\n",
      "rec:  0.8017105952173154\n",
      "ma F1:  0.879813476220509\n",
      "mi F1:  0.8888219343175655\n",
      "we F1:  0.8874747413299525\n",
      "29871 467\n",
      "Loss:  0.058380477130413055\n",
      "Loss:  0.057844698429107666\n",
      "Loss:  0.06918255984783173\n",
      "36 **********\n",
      "Epoch:  1978.1498284339905  fold:  10  kers:  32\n",
      "epoch:  37\n",
      "29871 467\n",
      "Loss:  0.06770312041044235\n",
      "Loss:  0.05883864685893059\n",
      "Loss:  0.0743141770362854\n",
      "37 **********\n",
      "Epoch:  2018.6136364936829  fold:  10  kers:  32\n",
      "epoch:  38\n",
      "29871 467\n",
      "Loss:  0.0744151622056961\n",
      "Loss:  0.07974964380264282\n",
      "Loss:  0.033247459679841995\n",
      "38 **********\n",
      "Epoch:  2058.9418070316315  fold:  10  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.6537963151931763\n",
      "Eval Loss:  0.08687739074230194\n",
      "Eval Loss:  0.07550198584794998\n",
      "[[1648  103]\n",
      " [ 308  961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      1751\n",
      "           1       0.90      0.76      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.87      0.85      0.86      3020\n",
      "weighted avg       0.87      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8639072847682119\n",
      "pre:  0.9031954887218046\n",
      "rec:  0.7572892040977147\n",
      "ma F1:  0.8564803257376973\n",
      "mi F1:  0.8639072847682119\n",
      "we F1:  0.8616910888420757\n",
      "Eval Loss:  0.21743276715278625\n",
      "Eval Loss:  0.2764182686805725\n",
      "Eval Loss:  0.29666510224342346\n",
      "Eval Loss:  0.2646786868572235\n",
      "Eval Loss:  0.2399190068244934\n",
      "Eval Loss:  0.27194732427597046\n",
      "Eval Loss:  0.272079199552536\n",
      "Eval Loss:  0.2794145345687866\n",
      "Eval Loss:  0.328396737575531\n",
      "Eval Loss:  0.22794795036315918\n",
      "Eval Loss:  0.2221679389476776\n",
      "Eval Loss:  0.22691895067691803\n",
      "Eval Loss:  0.25626376271247864\n",
      "Eval Loss:  0.237612783908844\n",
      "Eval Loss:  0.24595557153224945\n",
      "Eval Loss:  0.2775556147098541\n",
      "Eval Loss:  0.2616950571537018\n",
      "Eval Loss:  0.18322989344596863\n",
      "Eval Loss:  0.23715783655643463\n",
      "Eval Loss:  0.3416217565536499\n",
      "Eval Loss:  0.2490702122449875\n",
      "Eval Loss:  0.3399205207824707\n",
      "Eval Loss:  0.29128867387771606\n",
      "Eval Loss:  0.2407831847667694\n",
      "Eval Loss:  0.30558428168296814\n",
      "Eval Loss:  0.2252044677734375\n",
      "Eval Loss:  0.32607707381248474\n",
      "Eval Loss:  0.27696818113327026\n",
      "Eval Loss:  0.2411426454782486\n",
      "[[17183  1230]\n",
      " [ 2085  9373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18413\n",
      "           1       0.88      0.82      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8890227980315356\n",
      "pre:  0.8839950957276242\n",
      "rec:  0.8180310699947635\n",
      "ma F1:  0.8808797269801603\n",
      "mi F1:  0.8890227980315356\n",
      "we F1:  0.8881313350675246\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06320483982563019\n",
      "Loss:  0.05918306112289429\n",
      "Loss:  0.07400435209274292\n",
      "39 **********\n",
      "Epoch:  2137.39603638649  fold:  10  kers:  32\n",
      "epoch:  40\n",
      "29871 467\n",
      "Loss:  0.06274692714214325\n",
      "Loss:  0.0686936005949974\n",
      "Loss:  0.05842124670743942\n",
      "40 **********\n",
      "Epoch:  2177.825934648514  fold:  10  kers:  32\n",
      "epoch:  41\n",
      "29871 467\n",
      "Loss:  0.07914551347494125\n",
      "Loss:  0.081273652613163\n",
      "Loss:  0.05207449942827225\n",
      "41 **********\n",
      "Epoch:  2218.1820306777954  fold:  10  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.8249512314796448\n",
      "Eval Loss:  0.0743083655834198\n",
      "Eval Loss:  0.05782780051231384\n",
      "[[1668   83]\n",
      " [ 414  855]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87      1751\n",
      "           1       0.91      0.67      0.77      1269\n",
      "\n",
      "    accuracy                           0.84      3020\n",
      "   macro avg       0.86      0.81      0.82      3020\n",
      "weighted avg       0.85      0.84      0.83      3020\n",
      "\n",
      "acc:  0.8354304635761589\n",
      "pre:  0.9115138592750534\n",
      "rec:  0.6737588652482269\n",
      "ma F1:  0.8225719909530558\n",
      "mi F1:  0.8354304635761589\n",
      "we F1:  0.8301953412658919\n",
      "Eval Loss:  0.23948076367378235\n",
      "Eval Loss:  0.29945895075798035\n",
      "Eval Loss:  0.3403530418872833\n",
      "Eval Loss:  0.26677218079566956\n",
      "Eval Loss:  0.24528861045837402\n",
      "Eval Loss:  0.2735890746116638\n",
      "Eval Loss:  0.28974223136901855\n",
      "Eval Loss:  0.2828504145145416\n",
      "Eval Loss:  0.33310258388519287\n",
      "Eval Loss:  0.24373438954353333\n",
      "Eval Loss:  0.23089717328548431\n",
      "Eval Loss:  0.2620072066783905\n",
      "Eval Loss:  0.2561900019645691\n",
      "Eval Loss:  0.2678804397583008\n",
      "Eval Loss:  0.26702043414115906\n",
      "Eval Loss:  0.2770706117153168\n",
      "Eval Loss:  0.2907792925834656\n",
      "Eval Loss:  0.2093033343553543\n",
      "Eval Loss:  0.2555025517940521\n",
      "Eval Loss:  0.36296865344047546\n",
      "Eval Loss:  0.2622480094432831\n",
      "Eval Loss:  0.3238707184791565\n",
      "Eval Loss:  0.2962171733379364\n",
      "Eval Loss:  0.2576963007450104\n",
      "Eval Loss:  0.3502022922039032\n",
      "Eval Loss:  0.22878053784370422\n",
      "Eval Loss:  0.3316876292228699\n",
      "Eval Loss:  0.2928084135055542\n",
      "Eval Loss:  0.2306319624185562\n",
      "[[17517   896]\n",
      " [ 2578  8880]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18413\n",
      "           1       0.91      0.78      0.84     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.89      0.86      0.87     29871\n",
      "weighted avg       0.89      0.88      0.88     29871\n",
      "\n",
      "acc:  0.8836999096113287\n",
      "pre:  0.9083469721767594\n",
      "rec:  0.7750043637633095\n",
      "ma F1:  0.8730897207284084\n",
      "mi F1:  0.8836999096113287\n",
      "we F1:  0.8816336438128951\n",
      "29871 467\n",
      "Loss:  0.05545159429311752\n",
      "Loss:  0.09775831550359726\n",
      "Loss:  0.05613177642226219\n",
      "42 **********\n",
      "Epoch:  2296.4776842594147  fold:  10  kers:  32\n",
      "epoch:  43\n",
      "29871 467\n",
      "Loss:  0.05838853865861893\n",
      "Loss:  0.07456168532371521\n",
      "Loss:  0.054746877402067184\n",
      "43 **********\n",
      "Epoch:  2336.7659616470337  fold:  10  kers:  32\n",
      "epoch:  44\n",
      "29871 467\n",
      "Loss:  0.046925101429224014\n",
      "Loss:  0.0846053957939148\n",
      "Loss:  0.07382303476333618\n",
      "44 **********\n",
      "Epoch:  2377.2187983989716  fold:  10  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.7375608086585999\n",
      "Eval Loss:  0.0860448107123375\n",
      "Eval Loss:  0.05835075303912163\n",
      "[[1642  109]\n",
      " [ 345  924]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      1751\n",
      "           1       0.89      0.73      0.80      1269\n",
      "\n",
      "    accuracy                           0.85      3020\n",
      "   macro avg       0.86      0.83      0.84      3020\n",
      "weighted avg       0.85      0.85      0.85      3020\n",
      "\n",
      "acc:  0.8496688741721854\n",
      "pre:  0.8944820909970959\n",
      "rec:  0.7281323877068558\n",
      "ma F1:  0.840662433717813\n",
      "mi F1:  0.8496688741721853\n",
      "we F1:  0.8467085399838402\n",
      "Eval Loss:  0.23419566452503204\n",
      "Eval Loss:  0.2848178744316101\n",
      "Eval Loss:  0.29205214977264404\n",
      "Eval Loss:  0.24016167223453522\n",
      "Eval Loss:  0.21266452968120575\n",
      "Eval Loss:  0.26310309767723083\n",
      "Eval Loss:  0.265383243560791\n",
      "Eval Loss:  0.2764374613761902\n",
      "Eval Loss:  0.30443036556243896\n",
      "Eval Loss:  0.23897098004817963\n",
      "Eval Loss:  0.21560007333755493\n",
      "Eval Loss:  0.22571367025375366\n",
      "Eval Loss:  0.26490166783332825\n",
      "Eval Loss:  0.25115588307380676\n",
      "Eval Loss:  0.23385578393936157\n",
      "Eval Loss:  0.25796064734458923\n",
      "Eval Loss:  0.26588350534439087\n",
      "Eval Loss:  0.1936107575893402\n",
      "Eval Loss:  0.2371198832988739\n",
      "Eval Loss:  0.3647412657737732\n",
      "Eval Loss:  0.24116551876068115\n",
      "Eval Loss:  0.32664868235588074\n",
      "Eval Loss:  0.284685879945755\n",
      "Eval Loss:  0.24791578948497772\n",
      "Eval Loss:  0.30010539293289185\n",
      "Eval Loss:  0.23378553986549377\n",
      "Eval Loss:  0.31057149171829224\n",
      "Eval Loss:  0.2747757136821747\n",
      "Eval Loss:  0.24581801891326904\n",
      "[[17215  1198]\n",
      " [ 2044  9414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     18413\n",
      "           1       0.89      0.82      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8914666398848381\n",
      "pre:  0.8871089332830757\n",
      "rec:  0.8216093559085356\n",
      "ma F1:  0.8835225747955573\n",
      "mi F1:  0.8914666398848381\n",
      "we F1:  0.8906051248142662\n",
      "29871 467\n",
      "Loss:  0.08031515032052994\n",
      "Loss:  0.0940055251121521\n",
      "Loss:  0.08159221708774567\n",
      "45 **********\n",
      "Epoch:  2455.4256892204285  fold:  10  kers:  32\n",
      "epoch:  46\n",
      "29871 467\n",
      "Loss:  0.06423985213041306\n",
      "Loss:  0.06708918511867523\n",
      "Loss:  0.09341660887002945\n",
      "46 **********\n",
      "Epoch:  2495.8436200618744  fold:  10  kers:  32\n",
      "epoch:  47\n",
      "29871 467\n",
      "Loss:  0.07771497219800949\n",
      "Loss:  0.07875187695026398\n",
      "Loss:  0.059519212692976\n",
      "47 **********\n",
      "Epoch:  2536.259556055069  fold:  10  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.7904148101806641\n",
      "Eval Loss:  0.06911811232566833\n",
      "Eval Loss:  0.03685271367430687\n",
      "[[1669   82]\n",
      " [ 385  884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88      1751\n",
      "           1       0.92      0.70      0.79      1269\n",
      "\n",
      "    accuracy                           0.85      3020\n",
      "   macro avg       0.86      0.82      0.83      3020\n",
      "weighted avg       0.86      0.85      0.84      3020\n",
      "\n",
      "acc:  0.845364238410596\n",
      "pre:  0.9151138716356108\n",
      "rec:  0.6966115051221434\n",
      "ma F1:  0.8341591042046994\n",
      "mi F1:  0.845364238410596\n",
      "we F1:  0.841039199347683\n",
      "Eval Loss:  0.22363543510437012\n",
      "Eval Loss:  0.2652266323566437\n",
      "Eval Loss:  0.30352067947387695\n",
      "Eval Loss:  0.2528824806213379\n",
      "Eval Loss:  0.21614503860473633\n",
      "Eval Loss:  0.26236945390701294\n",
      "Eval Loss:  0.2643883526325226\n",
      "Eval Loss:  0.30010831356048584\n",
      "Eval Loss:  0.33207741379737854\n",
      "Eval Loss:  0.23810097575187683\n",
      "Eval Loss:  0.22961603105068207\n",
      "Eval Loss:  0.244775652885437\n",
      "Eval Loss:  0.25179323554039\n",
      "Eval Loss:  0.24277514219284058\n",
      "Eval Loss:  0.24427951872348785\n",
      "Eval Loss:  0.25861984491348267\n",
      "Eval Loss:  0.27420851588249207\n",
      "Eval Loss:  0.2034243792295456\n",
      "Eval Loss:  0.24276790022850037\n",
      "Eval Loss:  0.34899425506591797\n",
      "Eval Loss:  0.24337364733219147\n",
      "Eval Loss:  0.30688387155532837\n",
      "Eval Loss:  0.29049286246299744\n",
      "Eval Loss:  0.23235920071601868\n",
      "Eval Loss:  0.27911293506622314\n",
      "Eval Loss:  0.25093239545822144\n",
      "Eval Loss:  0.3023895025253296\n",
      "Eval Loss:  0.28526702523231506\n",
      "Eval Loss:  0.2356705218553543\n",
      "[[17540   873]\n",
      " [ 2441  9017]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18413\n",
      "           1       0.91      0.79      0.84     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8890562753171973\n",
      "pre:  0.9117290192113245\n",
      "rec:  0.7869610752312794\n",
      "ma F1:  0.8792237026566037\n",
      "mi F1:  0.8890562753171973\n",
      "we F1:  0.8872473495948214\n",
      "29871 467\n",
      "Loss:  0.053775493055582047\n",
      "Loss:  0.07354854047298431\n",
      "Loss:  0.08662435412406921\n",
      "48 **********\n",
      "Epoch:  2614.383668422699  fold:  10  kers:  32\n",
      "epoch:  49\n",
      "29871 467\n",
      "Loss:  0.05595915764570236\n",
      "Loss:  0.07359931617975235\n",
      "Loss:  0.04810941219329834\n",
      "49 **********\n",
      "Epoch:  2654.7946174144745  fold:  10  kers:  32\n",
      "epoch:  50\n",
      "29871 467\n",
      "Loss:  0.06985440105199814\n",
      "Loss:  0.05942877382040024\n",
      "Loss:  0.06887773424386978\n",
      "50 **********\n",
      "Epoch:  2695.1626818180084  fold:  10  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.6891399621963501\n",
      "Eval Loss:  0.07289466261863708\n",
      "Eval Loss:  0.03487494960427284\n",
      "[[1670   81]\n",
      " [ 341  928]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      1751\n",
      "           1       0.92      0.73      0.81      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.88      0.84      0.85      3020\n",
      "weighted avg       0.87      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8602649006622517\n",
      "pre:  0.9197224975222993\n",
      "rec:  0.731284475965327\n",
      "ma F1:  0.8512877025884742\n",
      "mi F1:  0.8602649006622517\n",
      "we F1:  0.857119251741521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22004541754722595\n",
      "Eval Loss:  0.27915140986442566\n",
      "Eval Loss:  0.3325948417186737\n",
      "Eval Loss:  0.2564420700073242\n",
      "Eval Loss:  0.22958482801914215\n",
      "Eval Loss:  0.2732837200164795\n",
      "Eval Loss:  0.27617815136909485\n",
      "Eval Loss:  0.24148385226726532\n",
      "Eval Loss:  0.3221961259841919\n",
      "Eval Loss:  0.2517525553703308\n",
      "Eval Loss:  0.20692095160484314\n",
      "Eval Loss:  0.22507202625274658\n",
      "Eval Loss:  0.237519770860672\n",
      "Eval Loss:  0.24431225657463074\n",
      "Eval Loss:  0.2382250428199768\n",
      "Eval Loss:  0.25603237748146057\n",
      "Eval Loss:  0.2913862466812134\n",
      "Eval Loss:  0.18279671669006348\n",
      "Eval Loss:  0.228830024600029\n",
      "Eval Loss:  0.3431412875652313\n",
      "Eval Loss:  0.2340104579925537\n",
      "Eval Loss:  0.3040025234222412\n",
      "Eval Loss:  0.2837056815624237\n",
      "Eval Loss:  0.23930302262306213\n",
      "Eval Loss:  0.308231920003891\n",
      "Eval Loss:  0.2203110158443451\n",
      "Eval Loss:  0.3078835904598236\n",
      "Eval Loss:  0.27858713269233704\n",
      "Eval Loss:  0.2293744683265686\n",
      "[[17580   833]\n",
      " [ 2445  9013]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18413\n",
      "           1       0.92      0.79      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.90      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8902614576010177\n",
      "pre:  0.915397115579931\n",
      "rec:  0.7866119741665212\n",
      "ma F1:  0.8804259951363611\n",
      "mi F1:  0.8902614576010176\n",
      "we F1:  0.8884107787761052\n",
      "29871 467\n",
      "Loss:  0.07164466381072998\n",
      "Loss:  0.08327770233154297\n",
      "Loss:  0.05734642967581749\n",
      "51 **********\n",
      "Epoch:  2773.3217000961304  fold:  10  kers:  32\n",
      "epoch:  52\n",
      "29871 467\n",
      "Loss:  0.060907334089279175\n",
      "Loss:  0.08400757610797882\n",
      "Loss:  0.0421278178691864\n",
      "52 **********\n",
      "Epoch:  2813.7545907497406  fold:  10  kers:  32\n",
      "epoch:  53\n",
      "29871 467\n",
      "Loss:  0.0424368754029274\n",
      "Loss:  0.0754803866147995\n",
      "Loss:  0.07257366180419922\n",
      "53 **********\n",
      "Epoch:  2854.1156735420227  fold:  10  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.5140573382377625\n",
      "Eval Loss:  0.08563985675573349\n",
      "Eval Loss:  0.043500881642103195\n",
      "[[1651  100]\n",
      " [ 250 1019]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1751\n",
      "           1       0.91      0.80      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.89      0.87      0.88      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8841059602649006\n",
      "pre:  0.9106344950848972\n",
      "rec:  0.8029944838455477\n",
      "ma F1:  0.8787979694015899\n",
      "mi F1:  0.8841059602649006\n",
      "we F1:  0.8828461523068365\n",
      "Eval Loss:  0.2068932056427002\n",
      "Eval Loss:  0.2763527035713196\n",
      "Eval Loss:  0.30768251419067383\n",
      "Eval Loss:  0.24722588062286377\n",
      "Eval Loss:  0.2077031284570694\n",
      "Eval Loss:  0.28462013602256775\n",
      "Eval Loss:  0.27250099182128906\n",
      "Eval Loss:  0.24167609214782715\n",
      "Eval Loss:  0.30777183175086975\n",
      "Eval Loss:  0.24552220106124878\n",
      "Eval Loss:  0.19375315308570862\n",
      "Eval Loss:  0.21060147881507874\n",
      "Eval Loss:  0.25672727823257446\n",
      "Eval Loss:  0.21309708058834076\n",
      "Eval Loss:  0.2321821004152298\n",
      "Eval Loss:  0.2377903312444687\n",
      "Eval Loss:  0.24594901502132416\n",
      "Eval Loss:  0.1592775583267212\n",
      "Eval Loss:  0.23841862380504608\n",
      "Eval Loss:  0.31854677200317383\n",
      "Eval Loss:  0.23163528740406036\n",
      "Eval Loss:  0.3023284077644348\n",
      "Eval Loss:  0.302280992269516\n",
      "Eval Loss:  0.2541109323501587\n",
      "Eval Loss:  0.3025314211845398\n",
      "Eval Loss:  0.24592649936676025\n",
      "Eval Loss:  0.3090205192565918\n",
      "Eval Loss:  0.24341116845607758\n",
      "Eval Loss:  0.23488591611385345\n",
      "[[17065  1348]\n",
      " [ 1750  9708]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18413\n",
      "           1       0.88      0.85      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.89      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.8962873690201199\n",
      "pre:  0.8780752532561505\n",
      "rec:  0.8472682841682667\n",
      "ma F1:  0.8895898987160302\n",
      "mi F1:  0.8962873690201199\n",
      "we F1:  0.8959214069347258\n",
      "29871 467\n",
      "Loss:  0.05894901230931282\n",
      "Loss:  0.06288200616836548\n",
      "Loss:  0.07841857522726059\n",
      "54 **********\n",
      "Epoch:  2932.392377614975  fold:  10  kers:  32\n",
      "epoch:  55\n",
      "29871 467\n",
      "Loss:  0.04585355147719383\n",
      "Loss:  0.06688802689313889\n",
      "Loss:  0.08577031642198563\n",
      "55 **********\n",
      "Epoch:  2972.844217777252  fold:  10  kers:  32\n",
      "epoch:  56\n",
      "29871 467\n",
      "Loss:  0.045840419828891754\n",
      "Loss:  0.06492695957422256\n",
      "Loss:  0.07866404950618744\n",
      "56 **********\n",
      "Epoch:  3013.1225214004517  fold:  10  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.6050460934638977\n",
      "Eval Loss:  0.08431372046470642\n",
      "Eval Loss:  0.0355595164000988\n",
      "[[1661   90]\n",
      " [ 288  981]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      1751\n",
      "           1       0.92      0.77      0.84      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.88      0.86      0.87      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8748344370860928\n",
      "pre:  0.9159663865546218\n",
      "rec:  0.7730496453900709\n",
      "ma F1:  0.8681496881496882\n",
      "mi F1:  0.8748344370860928\n",
      "we F1:  0.8728879954840221\n",
      "Eval Loss:  0.21326333284378052\n",
      "Eval Loss:  0.25447404384613037\n",
      "Eval Loss:  0.3016345202922821\n",
      "Eval Loss:  0.2578281760215759\n",
      "Eval Loss:  0.214670792222023\n",
      "Eval Loss:  0.255046010017395\n",
      "Eval Loss:  0.25562047958374023\n",
      "Eval Loss:  0.23922298848628998\n",
      "Eval Loss:  0.31441476941108704\n",
      "Eval Loss:  0.24308614432811737\n",
      "Eval Loss:  0.21131771802902222\n",
      "Eval Loss:  0.2132302224636078\n",
      "Eval Loss:  0.26038771867752075\n",
      "Eval Loss:  0.2227790355682373\n",
      "Eval Loss:  0.23871083557605743\n",
      "Eval Loss:  0.23194141685962677\n",
      "Eval Loss:  0.26708829402923584\n",
      "Eval Loss:  0.17456082999706268\n",
      "Eval Loss:  0.2306472808122635\n",
      "Eval Loss:  0.3283039927482605\n",
      "Eval Loss:  0.22364407777786255\n",
      "Eval Loss:  0.28646722435951233\n",
      "Eval Loss:  0.2891398072242737\n",
      "Eval Loss:  0.24101093411445618\n",
      "Eval Loss:  0.2812741696834564\n",
      "Eval Loss:  0.2441743016242981\n",
      "Eval Loss:  0.3086663782596588\n",
      "Eval Loss:  0.2547147274017334\n",
      "Eval Loss:  0.22841207683086395\n",
      "[[17388  1025]\n",
      " [ 2070  9388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     18413\n",
      "           1       0.90      0.82      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.88      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.8963878008771049\n",
      "pre:  0.9015653510035533\n",
      "rec:  0.8193401989876069\n",
      "ma F1:  0.8883818033448561\n",
      "mi F1:  0.8963878008771049\n",
      "we F1:  0.8953420174494546\n",
      "29871 467\n",
      "Loss:  0.05141465365886688\n",
      "Loss:  0.0717192068696022\n",
      "Loss:  0.06020694971084595\n",
      "57 **********\n",
      "Epoch:  3091.471033334732  fold:  10  kers:  32\n",
      "epoch:  58\n",
      "29871 467\n",
      "Loss:  0.07186944037675858\n",
      "Loss:  0.05715890973806381\n",
      "Loss:  0.06490763276815414\n",
      "58 **********\n",
      "Epoch:  3131.913897752762  fold:  10  kers:  32\n",
      "epoch:  59\n",
      "29871 467\n",
      "Loss:  0.11424078047275543\n",
      "Loss:  0.08762247115373611\n",
      "Loss:  0.08521440625190735\n",
      "59 **********\n",
      "Epoch:  3172.3258440494537  fold:  10  kers:  32\n",
      "Eval Loss:  0.505184531211853\n",
      "Eval Loss:  0.10069384425878525\n",
      "Eval Loss:  0.04540613666176796\n",
      "[[1635  116]\n",
      " [ 228 1041]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      1751\n",
      "           1       0.90      0.82      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.88      0.88      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8860927152317881\n",
      "pre:  0.8997407087294728\n",
      "rec:  0.8203309692671394\n",
      "ma F1:  0.8815087064092146\n",
      "mi F1:  0.8860927152317881\n",
      "we F1:  0.8852283903359494\n",
      "update!  Acc:  0.8933774834437086\n",
      "Epoch:  3175.8025481700897  fold:  10  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from time import time\n",
    "for kers in [128,64,32]:\n",
    "    print(\"  \")\n",
    "    print(\"kernel:\",kers)\n",
    "    print(\"  \")\n",
    "    for fold in range(1,11):\n",
    "        begin=time()\n",
    "        #train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "        train_dtlist,test_dtlist=getTrainTestList(reclist,opt='kfold',fold = fold)#fold 1-10   \n",
    "        print('*********')\n",
    "\n",
    "        train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "        np.random.shuffle(train_dtlist)\n",
    "        test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "        print(len(train_dtlist),len(test_dtlist))\n",
    "        model = MyLSTM(2,kers).to(device)\n",
    "\n",
    "        #model.features[0]=nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if(m.in_channels!=m.out_channels or m.out_channels!=m.groups or m.bias is not None):\n",
    "                    # don't want to reinitialize downsample layers, code assuming normal conv layers will not have these characteristics\n",
    "                    #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                    print(m,'init')\n",
    "                else:\n",
    "                    print('Not initializing')\n",
    "        criterion=nn.CrossEntropyLoss().to(device)#weight=torch.FloatTensor([1,1.5])\n",
    "        #criterion = CircleLoss(m=0.25, gamma=256)\n",
    "        opt=torch.optim.Adam(model.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001)\n",
    "        loss_list=[]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        epoch_flag=0\n",
    "        best_acc=0\n",
    "        for epoch in range(60):\n",
    "            print('epoch: ', epoch)\n",
    "            if epoch_flag%3==0 and epoch_flag!=0:\n",
    "                model.eval()\n",
    "                prob_file,lab_file,tmp_acc,seg_file=eval(model,test_dtlist,criterion,device)\n",
    "                if tmp_acc>best_acc:\n",
    "                    best_acc=tmp_acc                   \n",
    "                    res_file_name=\"./weights/fold_%.0f_w_%.0f_fs_%.0f.csv\"%(fold,kers,38)\n",
    "                    res_file=pd.DataFrame({\"prob\":prob_file,'label':lab_file,'seg':seg_file})\n",
    "                    res_file.to_csv(res_file_name,index=False)\n",
    "                    torch.save(model.state_dict(), \"./weights/fold_%.0f_w_%.0f_fs_%.0f.pkl\"%(fold,kers,38))\n",
    "                    print(\"update! \",'Acc: ',best_acc)\n",
    "                #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "                _,_,_,_=eval(model,train_dtlist,criterion,device)\n",
    "                model.train()\n",
    "            train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "            #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "            train_loader=DataLoader(train_dataset, batch_size=64, shuffle=True, sampler=None, num_workers=0)\n",
    "\n",
    "            #test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "            print(len(train_dataset),len(train_loader)) #,len(test_dataset)\n",
    "            flag=0\n",
    "            accum_flag=0\n",
    "            for fe, label,seg_id in train_loader:\n",
    "                del seg_id\n",
    "                fe=fe.float().to(device)\n",
    "                #fe=(fe-fe_mean)/fe_std\n",
    "                #fe=torch.stft(fe,100,hop_length=50,onesided=True)\n",
    "\n",
    "                label=label.long().to(device)\n",
    "                pred_prob_no_softmax=model(fe)\n",
    "                loss=criterion(pred_prob_no_softmax,label)/4#/256\n",
    "                del label\n",
    "                del fe\n",
    "                #inp_sp, inp_sn = convert_label_to_similarity(pred_prob_no_softmax,label)\n",
    "                #loss = criterion(inp_sp, inp_sn)/256\n",
    "                \n",
    "                loss_list.append(loss.item())\n",
    "                loss.backward()\n",
    "                accum_flag+=1\n",
    "                if accum_flag%4==0:\n",
    "                    opt.step()\n",
    "                    accum_flag=0\n",
    "                    opt.zero_grad()\n",
    "                flag+=1\n",
    "                if flag%128==0:\n",
    "                    print(\"Loss: \", loss.item())\n",
    "                #print('step')\n",
    "            print(epoch_flag,'*'*10)\n",
    "            epoch_flag+=1\n",
    "            #scheduler.step()\n",
    "            print('Epoch: ', time()-begin,' fold: ',fold,' kers: ',kers)\n",
    "            \n",
    "        model.eval()\n",
    "\n",
    "        prob_file,lab_file,tmp_acc,seg_file=eval(model,test_dtlist,criterion,device)\n",
    "        if tmp_acc>best_acc:\n",
    "            best_acc=tmp_acc                   \n",
    "            res_file_name=\"./weights/fold_%.0f_w_%.0f_fs_%.0f.csv\"%(fold,kers,38)\n",
    "            res_file=pd.DataFrame({\"prob\":prob_file,'label':lab_file,'seg':seg_file})\n",
    "            res_file.to_csv(res_file_name,index=False)\n",
    "            torch.save(model.state_dict(), \"./weights/fold_%.0f_w_%.0f_fs_%.0f.pkl\"%(fold,kers,38))\n",
    "        print(\"update! \",'Acc: ',best_acc)\n",
    "        #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "\n",
    "        print('Epoch: ', time()-begin,' fold: ',fold,' kers: ',kers)\n",
    "        plt.plot(loss_list)\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "        print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blind val ^^^^^^^^^^^^^^^^^^^^\n",
      "  \n",
      "kernel: 128\n",
      "  \n",
      "70 0 []\n",
      "*********\n",
      "32891 0\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "32891 129\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0c76cec02dde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#,len(test_dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mflag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m                 \u001b[0mfe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;31m#fe=(fe-fe_mean)/fe_std\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "print('blind val','^^^^^^^^^^^^^^^^^^^^')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from time import time\n",
    "for kers in [128,64,32]:\n",
    "    print(\"  \")\n",
    "    print(\"kernel:\",kers)\n",
    "    print(\"  \")\n",
    "    for fold in range(1,11):\n",
    "        begin=time()\n",
    "        #train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "        train_dtlist,test_dtlist=getTrainTestList(reclist,opt='blind',fold = fold)#fold 1-10   \n",
    "        print('*********')\n",
    "\n",
    "        train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "        np.random.shuffle(train_dtlist)\n",
    "        test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "        print(len(train_dtlist),len(test_dtlist))\n",
    "        model = MyLSTM(2,kers).to(device)\n",
    "\n",
    "        #model.features[0]=nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if(m.in_channels!=m.out_channels or m.out_channels!=m.groups or m.bias is not None):\n",
    "                    # don't want to reinitialize downsample layers, code assuming normal conv layers will not have these characteristics\n",
    "                    #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                    print(m,'init')\n",
    "                else:\n",
    "                    print('Not initializing')\n",
    "        criterion=nn.CrossEntropyLoss().to(device)#weight=torch.FloatTensor([1,1.5])\n",
    "        #criterion = CircleLoss(m=0.25, gamma=256)\n",
    "        opt=torch.optim.Adam(model.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001)\n",
    "        loss_list=[]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        epoch_flag=0\n",
    "        for epoch in range(60):\n",
    "            print('epoch: ', epoch)\n",
    "            if epoch_flag%3==0 and epoch_flag!=0:\n",
    "                model.eval()\n",
    "                eval(model,test_dtlist,criterion,device)\n",
    "                #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "                eval(model,train_dtlist,criterion,device)\n",
    "                model.train()\n",
    "            train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "            #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "            train_loader=DataLoader(train_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "\n",
    "            #test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "            print(len(train_dataset),len(train_loader)) #,len(test_dataset)\n",
    "            flag=0\n",
    "            for fe, label in train_loader:\n",
    "                fe=fe.float().to(device)\n",
    "                #fe=(fe-fe_mean)/fe_std\n",
    "                #fe=torch.stft(fe,100,hop_length=50,onesided=True)\n",
    "\n",
    "                label=label.long().to(device)\n",
    "                pred_prob_no_softmax=model(fe)\n",
    "                loss=criterion(pred_prob_no_softmax,label)#/256\n",
    "\n",
    "                #inp_sp, inp_sn = convert_label_to_similarity(pred_prob_no_softmax,label)\n",
    "                #loss = criterion(inp_sp, inp_sn)/256\n",
    "\n",
    "                loss_list.append(loss.item())\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "                flag+=1\n",
    "                if flag%4==0:\n",
    "                    print(\"Loss: \", loss.item())\n",
    "\n",
    "                #print('step')\n",
    "            print(epoch_flag,'*'*10)\n",
    "            epoch_flag+=1\n",
    "            #scheduler.step()\n",
    "            \n",
    "        model.eval()\n",
    "        eval(model,test_dtlist,criterion,device)\n",
    "        print('Epoch: ', time()-begin,' fold: ',fold,' kers: ',kers)\n",
    "        plt.plot(loss_list)\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "        print('------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
