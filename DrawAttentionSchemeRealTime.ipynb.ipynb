{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import wfdb\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, lfilter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.alexnet import alexnet\n",
    "seed=2020\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reclist=glob(\"../apnea/seg/*\")\n",
    "dtlist=glob(\"../apnea/seg/*/*.npy*\")\n",
    "reclist.sort()\n",
    "dtlist.sort()\n",
    "lab_list=[seg.split('_')[0][-1] for seg in dtlist]#shuffle by idx\n",
    "print(lab_list.count('A')/len(lab_list),lab_list.count('N')/len(lab_list))\n",
    "\n",
    "reclist[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cheb_bandpass_filter(data, lowcut, highcut, signal_freq, filter_order):\n",
    "        \"\"\"\n",
    "        Method responsible for creating and applying Butterworth filter.\n",
    "        :param deque data: raw data\n",
    "        :param float lowcut: filter lowcut frequency value\n",
    "        :param float highcut: filter highcut frequency value\n",
    "        :param int signal_freq: signal frequency in samples per second (Hz)\n",
    "        :param int filter_order: filter order\n",
    "        :return array: filtered data\n",
    "        \"\"\"\n",
    "        nyquist_freq = 0.5 * signal_freq\n",
    "        low = lowcut / nyquist_freq\n",
    "        high = highcut / nyquist_freq\n",
    "        #b, a = butter(filter_order, [low, high], btype=\"band\")\n",
    "        b, a = signal.cheby2(filter_order, 40, [low, high], 'band', analog=False)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import numpy as np\n",
    "bw2=3\n",
    "filetmp=dtlist[1925]#5\n",
    "dt=np.load(filetmp)\n",
    "f=plt.figure(dpi=512)\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "ax=plt.subplot(3,2,1)\n",
    "plt.plot(dt)\n",
    "#plt.xlim(0,6000)\n",
    "plt.ylim(-1,4)\n",
    "plt.xticks([])\n",
    "ax=plt.gca()\n",
    "ax.yaxis.set_ticks_position('right')\n",
    "plt.xlabel('0-60 seconds',rotation=0,ha='center',va='top',font='Times New Roman')\n",
    "\n",
    "ax=plt.subplot(3,3,3)\n",
    "plt.ylim(-1,4)\n",
    "plt.plot(dt[0:500])\n",
    "plt.xticks([])\n",
    "plt.ylabel('Voltage ($mv$)',rotation=0,ha='right',va='top',font='Times New Roman')\n",
    "plt.xlabel('0-5 seconds',rotation=0,ha='center',va='top',font='Times New Roman')\n",
    "\n",
    "#plt.show()\n",
    "#plt.close(\"all\")\n",
    "\n",
    "dt=cheb_bandpass_filter(dt, 0.01, 38, 100, 4)\n",
    "ax=plt.subplot(3,2,3)\n",
    "plt.plot(dt)\n",
    "#plt.xlim(0,6000)\n",
    "plt.ylim(-1,4)\n",
    "plt.xticks([])\n",
    "ax=plt.gca()\n",
    "ax.yaxis.set_ticks_position('right')\n",
    "plt.xlabel('0-60 seconds',rotation=0,ha='center',va='top',font='Times New Roman')\n",
    "\n",
    "ax=plt.subplot(3,3,6)\n",
    "plt.ylim(-1,4)\n",
    "plt.plot(dt[0:500])\n",
    "plt.xticks([])\n",
    "plt.ylabel('Voltage ($mv$)',rotation=0,ha='right',va='top',font='Times New Roman')\n",
    "plt.xlabel('0-5 seconds',rotation=0,ha='center',va='top',font='Times New Roman')\n",
    "\n",
    "\n",
    "f, t, Sxx=signal.spectrogram(dt, fs=100.0, window=('hamming'), nperseg=128, noverlap=64, nfft=128, detrend='constant',\n",
    "return_onesided=True, scaling='density', axis=-1, mode='psd')\n",
    "input=torch.FloatTensor(Sxx[0:26]).unsqueeze(dim=0)\n",
    "# with torch.no_grad():\n",
    "#     pred_prob_no_softmax,_=model(torch.FloatTensor(input))\n",
    "\n",
    "\n",
    "ax=plt.subplot(3,1,3)\n",
    "plt.imshow(Sxx,aspect='auto',interpolation='nearest')\n",
    "plt.plot([26]*92,'r--',linewidth=3)\n",
    "ax=plt.gca()\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "plt.xlim(0,91)\n",
    "plt.ylim(0,50)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('0-60 seconds',rotation=0,ha='center',va='top',font='Times New Roman')\n",
    "#plt.ylabel('Frequency ($Hz$)',rotation=0,ha='right')\n",
    "cb=plt.colorbar(orientation='vertical',fraction=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('RawApneaScheme.pdf',dpi=512)\n",
    "plt.show()\n",
    "plt.close(\"all\")\n",
    "print(filetmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects=[['a11'],['a15'],['a17'],['b01'],['c07'],\n",
    "          ['a11','a15','a17','b01','c07'],\n",
    "          ['a14','a19','b05','c01','c07'],\n",
    "          ['a04','a19','b05','c01','c09'],['b02','b03'],['x16','x21']]\n",
    "len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def getTrainTestList(reclist,opt='rec_cv',fold=1):\n",
    "    train_dtlist=[]\n",
    "    test_dtlist=[]\n",
    "    if opt=='rec_cv':#reclist is rec list\n",
    "        kf = KFold(n_splits=10)\n",
    "        kf_idx=kf.split(reclist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_rec,test_rec=list(np.array(reclist)[train_idx]),list(np.array(reclist)[test_idx])\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "    elif opt=='physionet':\n",
    "        train_rec=[rec for rec in reclist if rec[-3]!='x']\n",
    "        test_rec=[rec for rec in reclist if rec[-3]=='x']\n",
    "        print(len(train_rec),len(test_rec))\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "    elif opt=='physionet_train':\n",
    "        train_rec=[rec for rec in reclist if rec[-3]!='x']\n",
    "        #print(len(train_rec),len(test_rec))\n",
    "        kf_idx=kf.split(dtlist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_dtlist,test_dtlist=list(np.array(dtlist)[train_idx]),list(np.array(dtlist)[test_idx])\n",
    "    elif opt=='blind':\n",
    "        subjects=[['a11'],\n",
    "                  ['a15','x27','x28'],\n",
    "                  ['a17','x12'],\n",
    "                  ['b01','x03'],\n",
    "                  ['c07','x34'],\n",
    "                  ['a11','a15','x27','x28','a17','x12','b01','x03','c07','x34'],\n",
    "                  ['a14','a19','x05','x08','x25','b05','x11','c01','x35','c07','x34'],\n",
    "                  ['a04','a19','x05','x08','x25','b05','x11','c01','x35','c09'],\n",
    "                  ['b02','b03','x16','x21']]\n",
    "        train_rec=[rec for rec in reclist if rec.split('/')[-1] not in subjects[fold-1]]\n",
    "        test_rec=[rec for rec in reclist if rec.split('/')[-1] in subjects[fold-1]]\n",
    "        print(len(train_rec),len(test_rec),test_rec)\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "\n",
    "    else:#reclist is npy data list\n",
    "        kf = KFold(n_splits=10)\n",
    "        kf_idx=kf.split(dtlist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_dtlist,test_dtlist=list(np.array(dtlist)[train_idx]),list(np.array(dtlist)[test_idx])\n",
    "         \n",
    "    return train_dtlist,test_dtlist\n",
    "\n",
    "def dtclean(dt_path):\n",
    "    dt=np.load(dt_path)\n",
    "    if dt.std()<0.1:\n",
    "        print(dt_path)\n",
    "        return 1      \n",
    "    else:\n",
    "        return 0\n",
    "#train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "train_dtlist,test_dtlist=getTrainTestList(reclist,opt='kfold',fold=6)#fold 1-10\n",
    "print('*********')\n",
    "print(len(train_dtlist),len(test_dtlist))\n",
    "train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "np.random.shuffle(train_dtlist)\n",
    "test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "print(len(train_dtlist),len(test_dtlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "ApneaECGDict={'N':0,\n",
    "              'A':1}\n",
    "class ApneaECGDataset(Dataset):\n",
    "    def __init__(self, filelist, istrain=False):\n",
    "        # Get the filelist and img data\n",
    "        self.filelist = filelist\n",
    "        self.istrain = istrain\n",
    "        \n",
    "    def getFeature(self, dt):\n",
    "\n",
    "        dt=cheb_bandpass_filter(dt, 0.01, 38, 100, 4)\n",
    "        f, t, Sxx=signal.spectrogram(dt, fs=100.0, window=('hamming'), nperseg=128, noverlap=64, nfft=128, detrend='constant',\n",
    "        return_onesided=True, scaling='density', axis=-1, mode='psd')\n",
    "        return Sxx[0:26]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # return to the data of a Picture\n",
    "        dt_path = self.filelist[index]\n",
    "        label = ApneaECGDict.__getitem__(dt_path.split('_')[0][-1])\n",
    "        data = np.load(dt_path)\n",
    "\n",
    "        if self.istrain:\n",
    "            noise = np.random.normal(0, 0.1, data.shape[0])\n",
    "            data = noise+data\n",
    "        data=self.getFeature(data)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    \n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, class_num,fs):\n",
    "        super(MyLSTM, self).__init__()\n",
    "#25 * 65\n",
    "#12* 32\n",
    "#b*64*6*16\n",
    "#b*6*64*16\n",
    "        self.branch1=nn.Sequential(nn.Conv2d(1,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),                             \n",
    "                                nn.LayerNorm([64,26,92],elementwise_affine=False),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Dropout(p=0.25),\n",
    "                                nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "\n",
    "                                nn.LayerNorm([64,13,46],elementwise_affine=False),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Dropout(p=0.5),\n",
    "                                nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                                          \n",
    "                                nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                nn.LayerNorm([64,6,23],elementwise_affine=False),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.5),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(1,3),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False))\n",
    "        \n",
    "        \n",
    "        self.avg = nn.Sequential(nn.AdaptiveMaxPool2d((8,8)),nn.LayerNorm([6,8,8],elementwise_affine=False))\n",
    "    \n",
    "        self.lstm = nn.LSTM(64, 8, 2,\n",
    "                            bias=False,\n",
    "                            batch_first=True,\n",
    "                            dropout=0.5,\n",
    "                            bidirectional=True)\n",
    "        #self.conv2=nn.Sequential(nn.Conv1d(64,64,kernel_size=1,stride=1,padding=0, bias=False))\n",
    "        \n",
    "        self.fc=nn.Sequential(nn.Linear(16*2,class_num))\n",
    "    def attention_net(self,lstm_output, final_state):\n",
    "        hidden = final_state.view(-1, 16, 2)   # hidden : [batch_size, n_hidden * num_directions(=2), 1(=n_layer)]\n",
    "        #print('hi',hidden.shape)\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2) # attn_weights : [batch_size, n_step]\n",
    "        #print('att',attn_weights.shape)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "\n",
    "        # [batch_size, n_hidden * num_directions(=2), n_step] * [batch_size, n_step, 1] = [batch_size, n_hidden * num_directions(=2), 1]\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights)\n",
    "        return context, soft_attn_weights.data.numpy() # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "    def forward(self, x):\n",
    "        x=x.unsqueeze(dim=1)#x.reshape(x.shape[0],1,-1)\n",
    "        out=self.branch1(x)\n",
    "        out=out.permute(0,2,1,3)\n",
    "        out=self.avg(out)\n",
    "        out=out.view(out.shape[0],out.shape[1],-1)\n",
    "        out,(h,c) = self.lstm(out)\n",
    "        out,attn=self.attention_net(out, h)\n",
    "\n",
    "        out = self.fc(out.reshape(out.shape[0],-1))\n",
    "        return out,attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MyLSTM(2,100)\n",
    "#model=alexnet(num_classes=2)\n",
    "#model.features[0]=nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        if(m.in_channels!=m.out_channels or m.out_channels!=m.groups or m.bias is not None):\n",
    "            # don't want to reinitialize downsample layers, code assuming normal conv layers will not have these characteristics\n",
    "            #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "            print(m,'init')\n",
    "        else:\n",
    "            print('Not initializing')\n",
    "criterion=nn.CrossEntropyLoss()#weight=torch.FloatTensor([1,1.5])\n",
    "#criterion = CircleLoss(m=0.25, gamma=256)\n",
    "opt=torch.optim.Adam(model.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt,T_max=20,eta_min=0.000005)\n",
    "loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(model,test_dtlist,criterion):\n",
    "    test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "    test_loader=DataLoader(test_dataset, batch_size=256, shuffle=False, sampler=None, num_workers=0)\n",
    "    #train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "        #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "    #train_loader=DataLoader(train_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "    sft=nn.Softmax()\n",
    "    all_pred_prob=torch.Tensor([])\n",
    "    all_label=torch.Tensor([]).long()\n",
    "    flag=0\n",
    "    with torch.no_grad():\n",
    "        for fe, label in test_loader:\n",
    "            fe=fe.float()\n",
    "            #fe=(fe-fe_mean)/fe_std\n",
    "            label=label.long()\n",
    "            pred_prob_no_softmax,_=model(fe)\n",
    "            all_pred_prob=torch.cat((all_pred_prob,pred_prob_no_softmax),0)\n",
    "            all_label=torch.cat((all_label,label),0)\n",
    "            \n",
    "            loss=criterion(pred_prob_no_softmax,label)\n",
    "            flag+=1\n",
    "            if flag%8==0:\n",
    "                print('Eval Loss: ',loss.item())\n",
    "            #pos=(sft(pred_prob_no_softmax)[:,1]>0.5)\n",
    "            #print(\"Acc: \", sum(label==pos).detach().numpy()/len(label))\n",
    "    all_pred=sft(all_pred_prob)[:,1].detach().numpy()\n",
    "    all_pred[all_pred>0.5]=1\n",
    "    all_pred[all_pred<=0.5]=0\n",
    "    all_label=all_label.detach().numpy()\n",
    "\n",
    "    print(confusion_matrix(all_label,all_pred))\n",
    "    print(classification_report(all_label,all_pred))\n",
    "    print(\"acc: \",accuracy_score(all_label,all_pred))\n",
    "    print(\"pre: \",precision_score(all_label,all_pred))\n",
    "    print(\"rec: \",recall_score(all_label,all_pred))\n",
    "    print(\"ma F1: \",f1_score(all_label,all_pred, average='macro'))\n",
    "    print(\"mi F1: \",f1_score(all_label,all_pred, average='micro'))\n",
    "    print(\"we F1: \",f1_score(all_label,all_pred, average='weighted'))\n",
    "    return accuracy_score(all_label,all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use a good model for data visualization\n",
    "ma=0.8\n",
    "opt.zero_grad()\n",
    "epoch_flag=0\n",
    "for epoch in range(26):\n",
    "    print('epoch: ', epoch)\n",
    "    if epoch_flag%3==0:# and epoch_flag!=0:\n",
    "        model.eval()\n",
    "        atmp=eval(model,test_dtlist,criterion)\n",
    "        #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "        tmp=eval(model,train_dtlist,criterion)\n",
    "        \n",
    "        if atmp >ma:\n",
    "            ma=atmp.copy()\n",
    "            torch.save(model.state_dict(),'param.pkl')\n",
    "            print(atmp,ma)\n",
    "        model.train()\n",
    "    train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "    #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "    train_loader=DataLoader(train_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "    #test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "    len(train_dataset),len(train_loader)#,len(test_dataset)\n",
    "    flag=0\n",
    "    for fe, label in train_loader:\n",
    "        fe=fe.float()\n",
    "        #fe=(fe-fe_mean)/fe_std\n",
    "        #fe=torch.stft(fe,100,hop_length=50,onesided=True)\n",
    "        \n",
    "        label=label.long()\n",
    "        pred_prob_no_softmax,_=model(fe)\n",
    "        loss=criterion(pred_prob_no_softmax,label)#/256\n",
    "        \n",
    "        #inp_sp, inp_sn = convert_label_to_similarity(pred_prob_no_softmax,label)\n",
    "        #loss = criterion(inp_sp, inp_sn)/256\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        flag+=1\n",
    "        if flag%4==0:\n",
    "            print(\"Loss: \", loss.item())\n",
    "        \n",
    "        #print('step')\n",
    "    print(epoch_flag,'*'*10)\n",
    "    epoch_flag+=1\n",
    "    #scheduler.step()\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('param.pkl'))\n",
    "train_dtlist=[file for file in dtlist if (dtclean(file)==0) and file.split('/')[-1][0]=='A']\n",
    "train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "#test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "train_loader=DataLoader(train_dataset, batch_size=256, shuffle=False, sampler=None, num_workers=0)\n",
    "#test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "len(train_dataset),len(train_loader)#,len(test_dataset)\n",
    "flag=0\n",
    "model.eval()\n",
    "ftmp_=[]\n",
    "btmp_=[]\n",
    "with torch.no_grad():\n",
    "    for fe, label in train_loader:\n",
    "        fe=fe.float()\n",
    "        pred_prob_no_softmax,_=model(fe)\n",
    "        ftmp_.append(_[:,:,0])\n",
    "        btmp_.append(_[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of attention weights \n",
    "model.load_state_dict(torch.load('param.pkl'))\n",
    "train_dtlist=[file for file in dtlist if (dtclean(file)==0) and file.split('/')[-1][0]=='N']\n",
    "train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "#test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "train_loader=DataLoader(train_dataset, batch_size=256, shuffle=False, sampler=None, num_workers=0)\n",
    "#test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "len(train_dataset),len(train_loader)#,len(test_dataset)\n",
    "flag=0\n",
    "model.eval()\n",
    "fntmp_=[]\n",
    "bntmp_=[]\n",
    "with torch.no_grad():\n",
    "    for fe, label in train_loader:\n",
    "        fe=fe.float()\n",
    "        pred_prob_no_softmax,_=model(fe)\n",
    "        fntmp_.append(_[:,:,0])\n",
    "        bntmp_.append(_[:,:,1])\n",
    "an=fntmp_[0]\n",
    "for tmppp in fntmp_[1::]:\n",
    "    an=np.vstack((an,tmppp))\n",
    "bn=bntmp_[0]\n",
    "for tmppp in bntmp_[1::]:\n",
    "    bn=np.vstack((bn,tmppp))\n",
    "an.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=np.array(_[:,:,0].shape)\n",
    "a=ftmp_[0]\n",
    "for tmppp in ftmp_[1::]:\n",
    "    a=np.vstack((a,tmppp))\n",
    "b=btmp_[0]\n",
    "for tmppp in btmp_[1::]:\n",
    "    b=np.vstack((b,tmppp))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apnea->all\n",
    "#Figure 4\n",
    "sns.set(style='darkgrid',font='Times New Roman')\n",
    "cmap_=['Greens','hot','spring','summer','autumn','winter','ocean']\n",
    "f=plt.figure(dpi=256)\n",
    "f.subplots_adjust(hspace=0.09,wspace=0.05)\n",
    "for i in range(6):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    sns.kdeplot(a[:,i],b[:,i],shade=True,cmap='Greens',shade_lowest=False)\n",
    "    plt.xlim(0.1,0.25)\n",
    "    plt.ylim(0.1,0.25)\n",
    "    plt.legend([i])\n",
    "    if i in [0,1,2,3,4,5]:\n",
    "        plt.xticks([])\n",
    "    if i in [1,5,2,3,0,4]:\n",
    "        plt.yticks([])\n",
    "    if i==4:\n",
    "        plt.ylabel('Backward weights')\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(3,4,i+1+6)\n",
    "    sns.kdeplot(an[:,i],bn[:,i],shade=True,cmap='Blues',shade_lowest=False)\n",
    "    plt.xlim(0.1,0.25)\n",
    "    plt.ylim(0.1,0.25)\n",
    "    plt.legend([i])\n",
    "    if i in [0,1,3,2,4,5]:\n",
    "        plt.xticks([])\n",
    "    if i in [1,3,0,2,4,5]:\n",
    "        plt.yticks([])\n",
    "\n",
    "plt.savefig('Atten.pdf',dpi=256)\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAC/value of model parameters\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ResBlock1(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(ResBlock1, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, out_planes, kernel_size=3, stride=1,padding=0)\n",
    "        self.bn = nn.BatchNorm1d(out_planes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(out_planes, out_planes, kernel_size=3, stride=1,padding=1)\n",
    "\n",
    "        self.downsample = nn.Sequential(nn.AvgPool1d(kernel_size =2, stride = 1,padding=0),\n",
    "                                        nn.Conv1d(in_planes, out_planes, kernel_size=1, stride=1,padding=0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out=torch.nn.functional.pad(out,(0,1))\n",
    "        shortcut = self.downsample(x)\n",
    "\n",
    "        return out + shortcut\n",
    "\n",
    "class ResBlock2(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(in_planes)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout()\n",
    "        self.conv1 = nn.Conv1d(in_planes, out_planes, kernel_size=3, stride= 1, padding=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm1d(out_planes)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout()\n",
    "        self.conv2 = nn.Conv1d(out_planes, out_planes, kernel_size=3, stride=1, padding=1)\n",
    "        self.downsample = nn.Conv1d(in_planes, out_planes, kernel_size=1, stride=1,padding=0)      \n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu1(out)\n",
    "        #out = self.dropout1(out)\n",
    "        out = self.conv1(out)\n",
    "        \n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        #out = self.dropout2(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "\n",
    "        shortcut = self.downsample(x)\n",
    "        #print(shortcut.shape)\n",
    "        return out + shortcut\n",
    "\n",
    "\n",
    "class RRNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(RRNet, self).__init__()\n",
    "        self.Begin = [nn.Conv1d(1, 128, kernel_size=20, stride= 5, padding=0),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),nn.AvgPool1d(kernel_size = 2, stride = 1)] \n",
    "        \n",
    "        self.Res1 = [ResBlock1(128,64)]\n",
    "        self.Res64 = [ResBlock2(64,64),ResBlock2(64,64)]\n",
    "        self.Res128 = [ResBlock2(64,128),ResBlock2(128,128),ResBlock2(128,128),\n",
    "                       ResBlock2(128,128)]\n",
    "        self.Res256 = [ResBlock2(128,256),ResBlock2(256,256),ResBlock2(256,256),\n",
    "                       ResBlock2(256,256),ResBlock2(256,256),ResBlock2(256,256)]\n",
    "        self.Res512 = [ResBlock2(256,512),ResBlock2(512,512),ResBlock2(512,512)]\n",
    "        #self.conv512 = nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        self.End = [nn.AvgPool1d(kernel_size=67,stride=1,padding=0)]\n",
    "        self.Features = nn.Sequential(*self.Begin,*self.Res1,\n",
    "                                      *self.Res64,*self.Res128,\n",
    "                                      *self.Res256,*self.Res512,*self.End)\n",
    "        self.Out = nn.Sequential(nn.Linear(512, num_classes))\n",
    "\n",
    "    def forward(self, x):       \n",
    "        Features = self.Features(x)\n",
    "        out = self.Out(Features.view(Features.size(0),1,-1))\n",
    "        out = out.view(out.size(0),-1)\n",
    "        return out\n",
    "# model=MyLSTM(2,100)\n",
    "# inp=torch.FloatTensor(1,26,92)\n",
    "model=RRNet(2)\n",
    "inp=torch.FloatTensor(1,1,360)\n",
    "from thop import profile\n",
    "from thop import clever_format\n",
    "with torch.no_grad():\n",
    "    macs, params = profile(model, inputs=(inp, ))\n",
    "print(macs, params)\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "print(macs, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
