{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import wfdb\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, lfilter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchvision.models.alexnet import alexnet\n",
    "\n",
    "\n",
    "seed=2020\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a01_100'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reclist=glob(\"./seg/*\")\n",
    "dtlist=glob(\"./seg/*/*.npy*\")\n",
    "reclist.sort()\n",
    "dtlist.sort()\n",
    "lab_list=[seg.split('_')[0][-1] for seg in dtlist]#shuffle by idx\n",
    "(dtlist[0].split('_')[1]+'_'+dtlist[0].split('_')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cheb_bandpass_filter(data, lowcut, highcut, signal_freq, filter_order):    # \n",
    "        \"\"\"\n",
    "        Method responsible for creating and applying Butterworth filter.\n",
    "        :param deque data: raw data\n",
    "        :param float lowcut: filter lowcut frequency value\n",
    "        :param float highcut: filter highcut frequency value\n",
    "        :param int signal_freq: signal frequency in samples per second (Hz)\n",
    "        :param int filter_order: filter order\n",
    "        :return array: filtered data\n",
    "        \"\"\"\n",
    "        nyquist_freq = 0.5 * signal_freq\n",
    "        low = lowcut / nyquist_freq\n",
    "        high = highcut / nyquist_freq\n",
    "        #b, a = butter(filter_order, [low, high], btype=\"band\")\n",
    "        b, a = signal.cheby2(filter_order, 40, [low, high], 'band', analog=False)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects=[['a11'],['a15'],['a17'],['b01'],['c07'],\n",
    "          ['a11','a15','a17','b01','c07'],\n",
    "          ['a14','a19','b05','c01','c07'],\n",
    "          ['a04','a19','b05','c01','c09'],['b02','b03'],['x16','x21']]\n",
    "len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def getTrainTestList(reclist,opt='rec_cv',fold=1):\n",
    "    train_dtlist=[]\n",
    "    test_dtlist=[]\n",
    "    if opt=='rec_cv':#reclist is rec list\n",
    "        kf = KFold(n_splits=10)\n",
    "        kf_idx=kf.split(reclist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_rec,test_rec=list(np.array(reclist)[train_idx]),list(np.array(reclist)[test_idx])\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "    elif opt=='physionet':\n",
    "        train_rec=[rec for rec in reclist if rec[-3]!='x']\n",
    "        test_rec=[rec for rec in reclist if rec[-3]=='x']\n",
    "        print(len(train_rec),len(test_rec))\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "    elif opt=='physionet_train':\n",
    "        train_rec=[rec for rec in reclist if rec[-3]!='x']\n",
    "        #print(len(train_rec),len(test_rec))\n",
    "        kf_idx=kf.split(dtlist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_dtlist,test_dtlist=list(np.array(dtlist)[train_idx]),list(np.array(dtlist)[test_idx])\n",
    "    elif opt=='blind':\n",
    "        subjects=[['a11'],\n",
    "                  ['a15','x27','x28'],\n",
    "                  ['a17','x12'],\n",
    "                  ['b01','x03'],\n",
    "                  ['c07','x34'],\n",
    "                  ['a11','a15','x27','x28','a17','x12','b01','x03','c07','x34'],\n",
    "                  ['a14','a19','x05','x08','x25','b05','x11','c01','x35','c07','x34'],\n",
    "                  ['a04','a19','x05','x08','x25','b05','x11','c01','x35','c09'],\n",
    "                  ['b02','b03','x16','x21']]\n",
    "        train_rec=[rec for rec in reclist if rec.split('/')[-1] not in subjects[fold-1]]\n",
    "        test_rec=[rec for rec in reclist if rec.split('/')[-1] in subjects[fold-1]]\n",
    "        print(len(train_rec),len(test_rec),test_rec)\n",
    "        for rec in train_rec:\n",
    "            train_dtlist+=glob(rec+'/*.npy*')\n",
    "        for rec in test_rec:\n",
    "            test_dtlist+=glob(rec+'/*.npy*')\n",
    "\n",
    "    else:#reclist is npy data list\n",
    "        kf = KFold(n_splits=10)\n",
    "        kf_idx=kf.split(dtlist)\n",
    "        for fold_idx in range(fold):#1,2,3,4,5\n",
    "            train_idx,test_idx=kf_idx.__next__()\n",
    "        train_dtlist,test_dtlist=list(np.array(dtlist)[train_idx]),list(np.array(dtlist)[test_idx])\n",
    "         \n",
    "    return train_dtlist,test_dtlist\n",
    "\n",
    "def dtclean(dt_path):\n",
    "    dt=np.load(dt_path)\n",
    "    if dt.std()<0.1:\n",
    "#        print(dt_path)\n",
    "        return 1      \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "#train_dtlist,test_dtlist=getTrainTestList(reclist,opt='kfold',fold=1)#fold 1-10\n",
    "#print('*********')\n",
    "#print(len(train_dtlist),len(test_dtlist))\n",
    "#train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "#np.random.shuffle(train_dtlist)\n",
    "#test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "\n",
    "#print(len(train_dtlist),len(test_dtlist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "ApneaECGDict={'N':0,\n",
    "              'A':1}\n",
    "class ApneaECGDataset(Dataset):\n",
    "    def __init__(self, filelist, istrain=False):\n",
    "        # Get the filelist and img data\n",
    "        self.filelist = filelist\n",
    "        self.istrain = istrain\n",
    "        \n",
    "    def getFeature(self, dt):\n",
    "#         dt=dt.reshape(-1,100)\n",
    "#         if self.istrain:\n",
    "#             shift=np.random.randint(0,5)\n",
    "#             shift=0\n",
    "#         else:\n",
    "#             shift=0\n",
    "#         dt=dt[:,shift::]\n",
    "#         dt_flag=dt[:,20::]*dt[:,0:-20]\n",
    "#         pd_dt=pd.DataFrame(dt)\n",
    "#         pd_dt_flag=pd.DataFrame(dt_flag)\n",
    "#scipy.signal.stft(x,fs=1.0,window='hann',nperseg=256,noverlap=None,nfft=None,detrend=False,return_onesided=True,boundary='zeros',padded=True,axis=-1)\n",
    "        dt=cheb_bandpass_filter(dt, 0.01, 28, 100, 4)\n",
    "    \n",
    "    \n",
    "        f, t, Sxx=signal.spectrogram(dt, fs=100.0, window=('hamming'), nperseg=128, noverlap=64, nfft=128, detrend='constant',\n",
    "        return_onesided=True, scaling='density', axis=-1, mode='psd')\n",
    "        return Sxx[0:20]\n",
    "        \n",
    "#         return np.concatenate((dt_flag.max(axis=1,keepdims=True),\n",
    "#                                dt_flag.min(axis=1,keepdims=True),\n",
    "#                                dt_flag.std(axis=1,keepdims=True),\n",
    "#                                dt.std(axis=1,keepdims=True),\n",
    "#             abs(dt).sum(axis=1,keepdims=True)/100,\n",
    "#             abs(dt_flag).sum(axis=1,keepdims=True)/100,\n",
    "#             (dt.argmax(axis=1)-dt.argmax(axis=1)[0])[:,np.newaxis]/100,\n",
    "#             (dt.argmin(axis=1)-dt.argmin(axis=1)[0])[:,np.newaxis]/100,\n",
    "#             (dt_flag.argmin(axis=1)-dt_flag.argmin(axis=1)[0])[:,np.newaxis]/100,\n",
    "#             (dt_flag.argmax(axis=1)-dt_flag.argmax(axis=1)[0])[:,np.newaxis]/100,\n",
    "#                                dt.mean(axis=1,keepdims=True),#\n",
    "#                                dt.min(axis=1,keepdims=True),\n",
    "#                                dt.max(axis=1,keepdims=True),\n",
    "#                                #pd_dt.skew(axis=1).values[:,np.newaxis],\n",
    "#                                #pd_dt.kurt(axis=1).values[:,np.newaxis],\n",
    "#                                #pd_dt_flag.skew(axis=1).values[:,np.newaxis],\n",
    "#                                #pd_dt_flag.kurt(axis=1).values[:,np.newaxis]\n",
    "#                                ),axis=1)\n",
    "    def __getitem__(self, index):\n",
    "        # return to the data of a Picture\n",
    "        dt_path = self.filelist[index]\n",
    "        label = ApneaECGDict.__getitem__(dt_path.split('_')[0][-1])\n",
    "        data = np.load(dt_path)\n",
    "        seg_id= dt_path.split('_')[1]+'_'+ dt_path.split('_')[-1].split('.')[0]\n",
    "\n",
    "        if self.istrain:\n",
    "            noise = np.random.normal(0, 0.1, data.shape[0])\n",
    "            data = noise+data\n",
    "        data=self.getFeature(data)\n",
    "        return data, label,seg_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "class conv3x3(nn.Module):#ACNet\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, \n",
    "                 padding=1, dilation=1, groups=1, padding_mode='zeros', bias=False, deploy=False):\n",
    "        super(conv3x3, self).__init__()\n",
    "        self.deploy=deploy\n",
    "        if self.deploy:\n",
    "            self.fused_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(kernel_size,kernel_size), stride=stride,\n",
    "                                      padding=padding, dilation=dilation, groups=groups, bias=False, padding_mode=padding_mode)\n",
    "# c=a.square_conv.weight.data.numpy().copy()\n",
    "# c[:,:,1:2,:]=a.square_conv.weight.data[:,:,1:2,:,].numpy().copy()+a.hor_conv.weight.data[:,:,0:1,:,].numpy().copy()\n",
    "# c[:,:,:,1:2]+=a.ver_conv.weight.data[:,:,:,0:1].numpy().copy()\n",
    "# c-a.square_conv.weight.data.numpy()\n",
    "# b.fused_conv.weight.data=torch.FloatTensor(c)    \n",
    "        else:\n",
    "            self.square_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=(kernel_size, kernel_size), stride=stride,\n",
    "                                         padding=padding, dilation=dilation, groups=groups, bias=False,\n",
    "                                         padding_mode=padding_mode)\n",
    "\n",
    "            center_offset_from_origin_border = padding - kernel_size // 2 #1-3//2=0\n",
    "            ver_pad_or_crop = (center_offset_from_origin_border + 1, center_offset_from_origin_border)\n",
    "            hor_pad_or_crop = (center_offset_from_origin_border, center_offset_from_origin_border + 1)\n",
    "            if center_offset_from_origin_border >= 0:\n",
    "                self.ver_conv_crop_layer = nn.Identity()\n",
    "                ver_conv_padding = ver_pad_or_crop\n",
    "                self.hor_conv_crop_layer = nn.Identity()\n",
    "                hor_conv_padding = hor_pad_or_crop\n",
    "\n",
    "            self.ver_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 1),\n",
    "                                      stride=stride,\n",
    "                                      padding=ver_conv_padding, dilation=dilation, groups=groups, bias=False,\n",
    "                                      padding_mode=padding_mode)\n",
    "\n",
    "            self.hor_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1, 3),\n",
    "                                      stride=stride,\n",
    "                                      padding=hor_conv_padding, dilation=dilation, groups=groups, bias=False,\n",
    "                                      padding_mode=padding_mode)\n",
    "\n",
    "    # forward函数\n",
    "    def forward(self, input):\n",
    "        if self.deploy:\n",
    "            #assert self.square_conv\n",
    "            print(\"True\")\n",
    "            return self.fused_conv(input)\n",
    "        square_outputs = self.square_conv(input)\n",
    "        # print(square_outputs.size())\n",
    "        # return square_outputs\n",
    "        vertical_outputs = self.ver_conv(input)\n",
    "        # print(vertical_outputs.size())\n",
    "        #horizontal_outputs = self.hor_conv_crop_layer(input)\n",
    "        horizontal_outputs = self.hor_conv(input)\n",
    "        # print(horizontal_outputs.size())\n",
    "        return square_outputs + vertical_outputs + horizontal_outputs\n",
    "    \n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, class_num,fs):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        #self.bn=nn.BatchNorm1d(60)\n",
    "#         self.conv10=nn.Sequential(nn.Conv1d(1,64,kernel_size=10,stride=10,padding=0, bias=False),\n",
    "#                   nn.Conv1d(64,32,kernel_size=3,stride=2,padding=0, bias=False),\n",
    "#                   nn.MaxPool1d(kernel_size=3,stride=2),\n",
    "#                   nn.Conv1d(32,32,kernel_size=3,stride=2,padding=0, bias=False),\n",
    "#                   nn.MaxPool1d(kernel_size=3,stride=2),\n",
    "#                                nn.ReLU())1200\n",
    "#25 * 65\n",
    "#12* 32\n",
    "#b*64*6*16\n",
    "#b*6*64*16\n",
    "        self.branch1=nn.Sequential(nn.Conv2d(1,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                nn.Conv2d(fs,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                #nn.Conv2d(32,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(3,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                #nn.ReLU(),                               \n",
    "                                nn.LayerNorm([fs,20,92],elementwise_affine=False),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Dropout(p=0.25),\n",
    "                                #nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                #nn.Dropout(p=0.25),\n",
    "                                \n",
    "#                                 nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Dropout(p=0.25),\n",
    "                                nn.LayerNorm([fs,10,46],elementwise_affine=False),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Dropout(p=0.5),\n",
    "                                nn.Conv2d(fs,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(5,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                                          \n",
    "                                nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                #nn.Dropout(p=0.5),\n",
    "                                nn.LayerNorm([fs,5,23],elementwise_affine=False),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.5),\n",
    "                                #nn.Conv2d(64,64,kernel_size=(1,3),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                nn.Conv2d(fs,fs,kernel_size=3,dilation=1,stride=1,padding=1, bias=False))\n",
    "        \n",
    "#         self.branch2=nn.Sequential(nn.Conv2d(1,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False),\n",
    "#                                 nn.Conv2d(32,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False),\n",
    "#                                 #nn.Conv2d(32,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=(3,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "#                                 #nn.ReLU(),                               \n",
    "#                                 nn.LayerNorm([32,25,92]),\n",
    "#                                 nn.ReLU(), \n",
    "#                                 nn.Dropout(p=0.25),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "#                                 nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#                                 #nn.Dropout(p=0.25),\n",
    "                                \n",
    "# #                                 nn.Conv2d(64,64,kernel_size=3,dilation=1,stride=1,padding=1, bias=False),\n",
    "# #                                 nn.ReLU(),\n",
    "# #                                 nn.Dropout(p=0.25),\n",
    "#                                 nn.LayerNorm([32,12,46]),\n",
    "#                                 nn.ReLU(), \n",
    "#                                 nn.Dropout(p=0.25),\n",
    "#                                 nn.Conv2d(32,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=(5,1),dilation=1,stride=1,padding=0, bias=False),\n",
    "                                                          \n",
    "#                                 nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#                                 #nn.Dropout(p=0.5),\n",
    "#                                 nn.LayerNorm([32,6,23]),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Dropout(p=0.5),\n",
    "#                                 #nn.Conv2d(64,64,kernel_size=(1,3),dilation=1,stride=1,padding=0, bias=False),\n",
    "#                                 nn.Conv2d(32,32,kernel_size=5,dilation=1,stride=1,padding=2, bias=False))\n",
    "        \n",
    "        self.avg = nn.Sequential(nn.AdaptiveMaxPool2d((8,8)),nn.LayerNorm([5,8,8],elementwise_affine=False))\n",
    "    \n",
    "        self.lstm = nn.LSTM(64, 8, 2,\n",
    "                            bias=False,\n",
    "                            batch_first=True,\n",
    "                            dropout=0.5,\n",
    "                            bidirectional=True)\n",
    "        #self.conv2=nn.Sequential(nn.Conv1d(64,64,kernel_size=1,stride=1,padding=0, bias=False))\n",
    "        \n",
    "        self.fc=nn.Sequential(nn.Linear(16*2,class_num))\n",
    "    def attention_net(self,lstm_output, final_state):\n",
    "        hidden = final_state.view(-1, 16, 2)   # hidden : [batch_size, n_hidden * num_directions(=2), 1(=n_layer)]\n",
    "        #print('hi',hidden.shape)\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2) # attn_weights : [batch_size, n_step]\n",
    "        #print('att',attn_weights.shape)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        #print('sft',soft_attn_weights.shape)\n",
    "        #print('yimr',torch.bmm(lstm_output.transpose(1, 2),soft_attn_weights).shape)\n",
    "        # [batch_size, n_hidden * num_directions(=2), n_step] * [batch_size, n_step, 1] = [batch_size, n_hidden * num_directions(=2), 1]\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights)\n",
    "        return context#, soft_attn_weights.data.numpy() # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "    def forward(self, x):\n",
    "        x=x.unsqueeze(dim=1)#x.reshape(x.shape[0],1,-1)\n",
    "        #x1=self.conv10(x)\n",
    "        out=self.branch1(x)\n",
    "        #out_1=self.branch1(x)\n",
    "        #out_2=self.branch2(x)\n",
    "        #out=torch.cat((out_1,out_2),1)\n",
    "        #print(out.shape)\n",
    "        out=out.permute(0,2,1,3)\n",
    "        out=self.avg(out)\n",
    "        #print(out.shape)\n",
    "        out=out.view(out.shape[0],out.shape[1],-1)\n",
    "        #print(x2.shape)\n",
    "        #print(x1.shape,x2.shape)\n",
    "        #x=torch.cat((x1,x2),dim=1)\n",
    "        #print(x.shape)\n",
    "        out,(h,c) = self.lstm(out)\n",
    "        out=self.attention_net(out, h)\n",
    "        \n",
    "        #out = self.conv2(out)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out.reshape(out.shape[0],-1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,test_dtlist,criterion,my_device):\n",
    "    test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "    test_loader=DataLoader(test_dataset, batch_size=128, shuffle=False, sampler=None, num_workers=0)\n",
    "    #train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "        #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "    #train_loader=DataLoader(train_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "    sft=nn.Softmax().to(my_device)\n",
    "    all_pred_prob=torch.Tensor([]).to(my_device)\n",
    "    all_label=torch.Tensor([]).long().to(my_device)\n",
    "    all_seg=[]#torch.Tensor([]).to(my_device)\n",
    "    flag=0\n",
    "    with torch.no_grad():\n",
    "        for fe, label,seg_id in test_loader:\n",
    "            fe=fe.float().to(my_device)\n",
    "            #fe=(fe-fe_mean)/fe_std\n",
    "            label=label.long().to(my_device)\n",
    "            pred_prob_no_softmax=model(fe)\n",
    "            all_pred_prob=torch.cat((all_pred_prob,pred_prob_no_softmax),0)\n",
    "            all_label=torch.cat((all_label,label),0)\n",
    "            all_seg+=list(seg_id)\n",
    "            loss=criterion(pred_prob_no_softmax,label)\n",
    "            flag+=1\n",
    "            if flag%8==0:\n",
    "                print('Eval Loss: ',loss.item())\n",
    "            #pos=(sft(pred_prob_no_softmax)[:,1]>0.5)\n",
    "            #print(\"Acc: \", sum(label==pos).detach().numpy()/len(label))\n",
    "    all_pred=sft(all_pred_prob)[:,1].detach().cpu().numpy()\n",
    "    all_pred[all_pred>0.5]=1\n",
    "    all_pred[all_pred<=0.5]=0\n",
    "    all_label=all_label.detach().cpu().numpy()\n",
    "    #all_seg=all_seg.detach().cpu().numpy()\n",
    "    print(confusion_matrix(all_label,all_pred))\n",
    "    print(classification_report(all_label,all_pred))\n",
    "    print(\"acc: \",accuracy_score(all_label,all_pred))\n",
    "    print(\"pre: \",precision_score(all_label,all_pred))\n",
    "    print(\"rec: \",recall_score(all_label,all_pred))\n",
    "    print(\"ma F1: \",f1_score(all_label,all_pred, average='macro'))\n",
    "    print(\"mi F1: \",f1_score(all_label,all_pred, average='micro'))\n",
    "    print(\"we F1: \",f1_score(all_label,all_pred, average='weighted'))\n",
    "    return sft(all_pred_prob)[:,1].detach().cpu().numpy(),all_label, accuracy_score(all_label,all_pred),all_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "kernel: 128\n",
      "  \n",
      "*********\n",
      "29459 3432\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29459 461\n",
      "Loss:  0.16827286779880524\n",
      "Loss:  0.15400761365890503\n",
      "Loss:  0.1668827384710312\n",
      "0 **********\n",
      "Epoch:  69.85222911834717  fold:  1  kers:  128\n",
      "epoch:  1\n",
      "29459 461\n",
      "Loss:  0.1361810863018036\n",
      "Loss:  0.13710737228393555\n",
      "Loss:  0.12114819884300232\n",
      "1 **********\n",
      "Epoch:  123.0380208492279  fold:  1  kers:  128\n",
      "epoch:  2\n",
      "29459 461\n",
      "Loss:  0.10052928328514099\n",
      "Loss:  0.11523830890655518\n",
      "Loss:  0.09965768456459045\n",
      "2 **********\n",
      "Epoch:  177.66994619369507  fold:  1  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.4002053439617157\n",
      "Eval Loss:  0.6910831928253174\n",
      "Eval Loss:  0.26847705245018005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\install\\envs\\pytorch-gpu\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\anaconda\\install\\envs\\pytorch-gpu\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 880  159]\n",
      " [ 898 1495]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.85      0.62      1039\n",
      "           1       0.90      0.62      0.74      2393\n",
      "\n",
      "    accuracy                           0.69      3432\n",
      "   macro avg       0.70      0.74      0.68      3432\n",
      "weighted avg       0.78      0.69      0.70      3432\n",
      "\n",
      "acc:  0.692016317016317\n",
      "pre:  0.903869407496977\n",
      "rec:  0.6247388215628917\n",
      "ma F1:  0.6817985054733611\n",
      "mi F1:  0.692016317016317\n",
      "we F1:  0.7042943051955763\n",
      "update!  Acc:  0.692016317016317\n",
      "Eval Loss:  0.4328390955924988\n",
      "Eval Loss:  0.4830372929573059\n",
      "Eval Loss:  0.4970913529396057\n",
      "Eval Loss:  0.5380541086196899\n",
      "Eval Loss:  0.44366008043289185\n",
      "Eval Loss:  0.4926806688308716\n",
      "Eval Loss:  0.4254724085330963\n",
      "Eval Loss:  0.415473610162735\n",
      "Eval Loss:  0.43978872895240784\n",
      "Eval Loss:  0.40788447856903076\n",
      "Eval Loss:  0.37723684310913086\n",
      "Eval Loss:  0.4905098080635071\n",
      "Eval Loss:  0.42432069778442383\n",
      "Eval Loss:  0.45054659247398376\n",
      "Eval Loss:  0.4201377034187317\n",
      "Eval Loss:  0.5925275683403015\n",
      "Eval Loss:  0.44336146116256714\n",
      "Eval Loss:  0.49799028038978577\n",
      "Eval Loss:  0.4634425640106201\n",
      "Eval Loss:  0.4926191568374634\n",
      "Eval Loss:  0.3902195394039154\n",
      "Eval Loss:  0.45371389389038086\n",
      "Eval Loss:  0.40568268299102783\n",
      "Eval Loss:  0.4987071752548218\n",
      "Eval Loss:  0.3892669975757599\n",
      "Eval Loss:  0.4037679135799408\n",
      "Eval Loss:  0.39442020654678345\n",
      "Eval Loss:  0.5193037390708923\n",
      "[[16881  2244]\n",
      " [ 3571  6763]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85     19125\n",
      "           1       0.75      0.65      0.70     10334\n",
      "\n",
      "    accuracy                           0.80     29459\n",
      "   macro avg       0.79      0.77      0.78     29459\n",
      "weighted avg       0.80      0.80      0.80     29459\n",
      "\n",
      "acc:  0.8026070131369021\n",
      "pre:  0.750860441878539\n",
      "rec:  0.6544416489258758\n",
      "ma F1:  0.7762072960385507\n",
      "mi F1:  0.8026070131369022\n",
      "we F1:  0.799144626836298\n",
      "29459 461\n",
      "Loss:  0.09334136545658112\n",
      "Loss:  0.09873814880847931\n",
      "Loss:  0.09596985578536987\n",
      "3 **********\n",
      "Epoch:  272.8783779144287  fold:  1  kers:  128\n",
      "epoch:  4\n",
      "29459 461\n",
      "Loss:  0.08439697325229645\n",
      "Loss:  0.07377714663743973\n",
      "Loss:  0.0932428166270256\n",
      "4 **********\n",
      "Epoch:  326.5209484100342  fold:  1  kers:  128\n",
      "epoch:  5\n",
      "29459 461\n",
      "Loss:  0.0843467116355896\n",
      "Loss:  0.0954301580786705\n",
      "Loss:  0.08211152255535126\n",
      "5 **********\n",
      "Epoch:  379.14623975753784  fold:  1  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.5264791250228882\n",
      "Eval Loss:  0.443759560585022\n",
      "Eval Loss:  0.14140716195106506\n",
      "[[ 857  182]\n",
      " [ 478 1915]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.82      0.72      1039\n",
      "           1       0.91      0.80      0.85      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.81      0.79      3432\n",
      "weighted avg       0.83      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8076923076923077\n",
      "pre:  0.9132093466857415\n",
      "rec:  0.8002507312996239\n",
      "ma F1:  0.7874974435373563\n",
      "mi F1:  0.8076923076923077\n",
      "we F1:  0.8133422885901014\n",
      "update!  Acc:  0.8076923076923077\n",
      "Eval Loss:  0.33930355310440063\n",
      "Eval Loss:  0.4077623188495636\n",
      "Eval Loss:  0.5206723809242249\n",
      "Eval Loss:  0.48188233375549316\n",
      "Eval Loss:  0.33975955843925476\n",
      "Eval Loss:  0.3812626302242279\n",
      "Eval Loss:  0.3800947666168213\n",
      "Eval Loss:  0.2967051565647125\n",
      "Eval Loss:  0.32812416553497314\n",
      "Eval Loss:  0.32516488432884216\n",
      "Eval Loss:  0.23969390988349915\n",
      "Eval Loss:  0.43684664368629456\n",
      "Eval Loss:  0.3368454873561859\n",
      "Eval Loss:  0.3357941210269928\n",
      "Eval Loss:  0.29183462262153625\n",
      "Eval Loss:  0.5048144459724426\n",
      "Eval Loss:  0.42472395300865173\n",
      "Eval Loss:  0.46226415038108826\n",
      "Eval Loss:  0.4118598699569702\n",
      "Eval Loss:  0.390847384929657\n",
      "Eval Loss:  0.3136524558067322\n",
      "Eval Loss:  0.3603762984275818\n",
      "Eval Loss:  0.3280006945133209\n",
      "Eval Loss:  0.4047900140285492\n",
      "Eval Loss:  0.33507952094078064\n",
      "Eval Loss:  0.41127389669418335\n",
      "Eval Loss:  0.3303093910217285\n",
      "Eval Loss:  0.4133235216140747\n",
      "[[17854  1271]\n",
      " [ 3056  7278]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     19125\n",
      "           1       0.85      0.70      0.77     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.85      0.82      0.83     29459\n",
      "weighted avg       0.85      0.85      0.85     29459\n",
      "\n",
      "acc:  0.853117892664381\n",
      "pre:  0.8513276406597263\n",
      "rec:  0.7042771434101026\n",
      "ma F1:  0.8313858297783329\n",
      "mi F1:  0.853117892664381\n",
      "we F1:  0.8494499905982317\n",
      "29459 461\n",
      "Loss:  0.07466769963502884\n",
      "Loss:  0.09857621788978577\n",
      "Loss:  0.10126348584890366\n",
      "6 **********\n",
      "Epoch:  471.96805238723755  fold:  1  kers:  128\n",
      "epoch:  7\n",
      "29459 461\n",
      "Loss:  0.07094452530145645\n",
      "Loss:  0.059850990772247314\n",
      "Loss:  0.08211611956357956\n",
      "7 **********\n",
      "Epoch:  524.6631569862366  fold:  1  kers:  128\n",
      "epoch:  8\n",
      "29459 461\n",
      "Loss:  0.07961637526750565\n",
      "Loss:  0.09643038362264633\n",
      "Loss:  0.10837353765964508\n",
      "8 **********\n",
      "Epoch:  577.3403112888336  fold:  1  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.5505149364471436\n",
      "Eval Loss:  0.444254606962204\n",
      "Eval Loss:  0.1371837705373764\n",
      "[[ 918  121]\n",
      " [ 572 1821]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.73      1039\n",
      "           1       0.94      0.76      0.84      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.78      0.82      0.78      3432\n",
      "weighted avg       0.84      0.80      0.81      3432\n",
      "\n",
      "acc:  0.7980769230769231\n",
      "pre:  0.9376930998970134\n",
      "rec:  0.7609694943585458\n",
      "ma F1:  0.7830585279956657\n",
      "mi F1:  0.7980769230769231\n",
      "we F1:  0.8055778047841737\n",
      "Eval Loss:  0.2832300662994385\n",
      "Eval Loss:  0.3741898834705353\n",
      "Eval Loss:  0.5350358486175537\n",
      "Eval Loss:  0.4739552140235901\n",
      "Eval Loss:  0.344539076089859\n",
      "Eval Loss:  0.3642767369747162\n",
      "Eval Loss:  0.400855153799057\n",
      "Eval Loss:  0.27763840556144714\n",
      "Eval Loss:  0.33481329679489136\n",
      "Eval Loss:  0.29456856846809387\n",
      "Eval Loss:  0.2415798455476761\n",
      "Eval Loss:  0.40327566862106323\n",
      "Eval Loss:  0.35563310980796814\n",
      "Eval Loss:  0.34464606642723083\n",
      "Eval Loss:  0.2967768609523773\n",
      "Eval Loss:  0.4906168580055237\n",
      "Eval Loss:  0.41508203744888306\n",
      "Eval Loss:  0.42411211133003235\n",
      "Eval Loss:  0.40474098920822144\n",
      "Eval Loss:  0.3655967712402344\n",
      "Eval Loss:  0.2982168197631836\n",
      "Eval Loss:  0.2962976098060608\n",
      "Eval Loss:  0.30269405245780945\n",
      "Eval Loss:  0.416548490524292\n",
      "Eval Loss:  0.33093076944351196\n",
      "Eval Loss:  0.38994666934013367\n",
      "Eval Loss:  0.33153629302978516\n",
      "Eval Loss:  0.37757694721221924\n",
      "[[18464   661]\n",
      " [ 3300  7034]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90     19125\n",
      "           1       0.91      0.68      0.78     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.88      0.82      0.84     29459\n",
      "weighted avg       0.87      0.87      0.86     29459\n",
      "\n",
      "acc:  0.8655419396449302\n",
      "pre:  0.9141000649772579\n",
      "rec:  0.6806657634991291\n",
      "ma F1:  0.8417131943753691\n",
      "mi F1:  0.8655419396449302\n",
      "we F1:  0.8600402722113019\n",
      "29459 461\n",
      "Loss:  0.08290398865938187\n",
      "Loss:  0.05843818187713623\n",
      "Loss:  0.09967975318431854\n",
      "9 **********\n",
      "Epoch:  669.5657169818878  fold:  1  kers:  128\n",
      "epoch:  10\n",
      "29459 461\n",
      "Loss:  0.09330742061138153\n",
      "Loss:  0.048667483031749725\n",
      "Loss:  0.11006972193717957\n",
      "10 **********\n",
      "Epoch:  723.4496417045593  fold:  1  kers:  128\n",
      "epoch:  11\n",
      "29459 461\n",
      "Loss:  0.0599273256957531\n",
      "Loss:  0.07451439648866653\n",
      "Loss:  0.08146917819976807\n",
      "11 **********\n",
      "Epoch:  776.5895571708679  fold:  1  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.43877100944519043\n",
      "Eval Loss:  0.38311514258384705\n",
      "Eval Loss:  0.10671323537826538\n",
      "[[ 908  131]\n",
      " [ 483 1910]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.75      1039\n",
      "           1       0.94      0.80      0.86      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.84      0.80      3432\n",
      "weighted avg       0.85      0.82      0.83      3432\n",
      "\n",
      "acc:  0.8210955710955711\n",
      "pre:  0.9358157765801078\n",
      "rec:  0.7981613038027581\n",
      "ma F1:  0.8044248428250834\n",
      "mi F1:  0.8210955710955711\n",
      "we F1:  0.8269519546796147\n",
      "update!  Acc:  0.8210955710955711\n",
      "Eval Loss:  0.24370363354682922\n",
      "Eval Loss:  0.3231244683265686\n",
      "Eval Loss:  0.4834282100200653\n",
      "Eval Loss:  0.43318286538124084\n",
      "Eval Loss:  0.3023703992366791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.29561102390289307\n",
      "Eval Loss:  0.359205961227417\n",
      "Eval Loss:  0.2196313738822937\n",
      "Eval Loss:  0.31920647621154785\n",
      "Eval Loss:  0.24949035048484802\n",
      "Eval Loss:  0.21522913873195648\n",
      "Eval Loss:  0.324390709400177\n",
      "Eval Loss:  0.31833216547966003\n",
      "Eval Loss:  0.3225296437740326\n",
      "Eval Loss:  0.2873270511627197\n",
      "Eval Loss:  0.4280637800693512\n",
      "Eval Loss:  0.3757375478744507\n",
      "Eval Loss:  0.3711549937725067\n",
      "Eval Loss:  0.3781222999095917\n",
      "Eval Loss:  0.3183671534061432\n",
      "Eval Loss:  0.25919780135154724\n",
      "Eval Loss:  0.2515551745891571\n",
      "Eval Loss:  0.23727035522460938\n",
      "Eval Loss:  0.382465124130249\n",
      "Eval Loss:  0.2849618196487427\n",
      "Eval Loss:  0.40087181329727173\n",
      "Eval Loss:  0.2959759533405304\n",
      "Eval Loss:  0.3249933421611786\n",
      "[[18448   677]\n",
      " [ 2836  7498]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     19125\n",
      "           1       0.92      0.73      0.81     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.89      0.85      0.86     29459\n",
      "weighted avg       0.88      0.88      0.88     29459\n",
      "\n",
      "acc:  0.8807495162768594\n",
      "pre:  0.9171865443425077\n",
      "rec:  0.7255660925101607\n",
      "ma F1:  0.8616321822156819\n",
      "mi F1:  0.8807495162768594\n",
      "we F1:  0.8769801715975823\n",
      "29459 461\n",
      "Loss:  0.07292801886796951\n",
      "Loss:  0.10493914037942886\n",
      "Loss:  0.08330390602350235\n",
      "12 **********\n",
      "Epoch:  869.286703824997  fold:  1  kers:  128\n",
      "epoch:  13\n",
      "29459 461\n",
      "Loss:  0.06933389604091644\n",
      "Loss:  0.09790828078985214\n",
      "Loss:  0.13608767092227936\n",
      "13 **********\n",
      "Epoch:  923.7480847835541  fold:  1  kers:  128\n",
      "epoch:  14\n",
      "29459 461\n",
      "Loss:  0.07678984105587006\n",
      "Loss:  0.0769108310341835\n",
      "Loss:  0.08066289871931076\n",
      "14 **********\n",
      "Epoch:  976.7962443828583  fold:  1  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.7468278408050537\n",
      "Eval Loss:  0.3415600061416626\n",
      "Eval Loss:  0.08704626560211182\n",
      "[[ 884  155]\n",
      " [ 443 1950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.85      0.75      1039\n",
      "           1       0.93      0.81      0.87      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.83      0.81      3432\n",
      "weighted avg       0.85      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8257575757575758\n",
      "pre:  0.9263657957244655\n",
      "rec:  0.8148767237776849\n",
      "ma F1:  0.8071523851870672\n",
      "mi F1:  0.8257575757575757\n",
      "we F1:  0.8307841188010152\n",
      "update!  Acc:  0.8257575757575758\n",
      "Eval Loss:  0.2128010243177414\n",
      "Eval Loss:  0.30702340602874756\n",
      "Eval Loss:  0.4413987994194031\n",
      "Eval Loss:  0.42014017701148987\n",
      "Eval Loss:  0.2777954339981079\n",
      "Eval Loss:  0.2688573896884918\n",
      "Eval Loss:  0.33334454894065857\n",
      "Eval Loss:  0.2019609957933426\n",
      "Eval Loss:  0.2705622911453247\n",
      "Eval Loss:  0.21006478369235992\n",
      "Eval Loss:  0.17299774289131165\n",
      "Eval Loss:  0.30286726355552673\n",
      "Eval Loss:  0.287644624710083\n",
      "Eval Loss:  0.2836841940879822\n",
      "Eval Loss:  0.275422602891922\n",
      "Eval Loss:  0.41128337383270264\n",
      "Eval Loss:  0.35916250944137573\n",
      "Eval Loss:  0.32024502754211426\n",
      "Eval Loss:  0.33363059163093567\n",
      "Eval Loss:  0.27449342608451843\n",
      "Eval Loss:  0.23242242634296417\n",
      "Eval Loss:  0.21342779695987701\n",
      "Eval Loss:  0.22102317214012146\n",
      "Eval Loss:  0.34703928232192993\n",
      "Eval Loss:  0.25757673382759094\n",
      "Eval Loss:  0.36413419246673584\n",
      "Eval Loss:  0.2759016156196594\n",
      "Eval Loss:  0.3287319540977478\n",
      "[[18467   658]\n",
      " [ 2561  7773]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     19125\n",
      "           1       0.92      0.75      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.90      0.86      0.87     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8907294884415629\n",
      "pre:  0.9219546910212312\n",
      "rec:  0.7521772788852332\n",
      "ma F1:  0.8741444390872379\n",
      "mi F1:  0.8907294884415629\n",
      "we F1:  0.8877781747216001\n",
      "29459 461\n",
      "Loss:  0.050742778927087784\n",
      "Loss:  0.060420941561460495\n",
      "Loss:  0.06594077497720718\n",
      "15 **********\n",
      "Epoch:  1070.0947842597961  fold:  1  kers:  128\n",
      "epoch:  16\n",
      "29459 461\n",
      "Loss:  0.0642634928226471\n",
      "Loss:  0.07542172819375992\n",
      "Loss:  0.054846812039613724\n",
      "16 **********\n",
      "Epoch:  1124.0146124362946  fold:  1  kers:  128\n",
      "epoch:  17\n",
      "29459 461\n",
      "Loss:  0.04059790447354317\n",
      "Loss:  0.06835304200649261\n",
      "Loss:  0.052370160818099976\n",
      "17 **********\n",
      "Epoch:  1177.5863726139069  fold:  1  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.9230474233627319\n",
      "Eval Loss:  0.2540794312953949\n",
      "Eval Loss:  0.08248964697122574\n",
      "[[ 825  214]\n",
      " [ 292 2101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77      1039\n",
      "           1       0.91      0.88      0.89      2393\n",
      "\n",
      "    accuracy                           0.85      3432\n",
      "   macro avg       0.82      0.84      0.83      3432\n",
      "weighted avg       0.86      0.85      0.85      3432\n",
      "\n",
      "acc:  0.8525641025641025\n",
      "pre:  0.9075593952483801\n",
      "rec:  0.8779774341830339\n",
      "ma F1:  0.8289147434674804\n",
      "mi F1:  0.8525641025641025\n",
      "we F1:  0.8540097530417958\n",
      "update!  Acc:  0.8525641025641025\n",
      "Eval Loss:  0.17282231152057648\n",
      "Eval Loss:  0.24746765196323395\n",
      "Eval Loss:  0.4025336503982544\n",
      "Eval Loss:  0.34326285123825073\n",
      "Eval Loss:  0.222601518034935\n",
      "Eval Loss:  0.2394152730703354\n",
      "Eval Loss:  0.31287887692451477\n",
      "Eval Loss:  0.1663484424352646\n",
      "Eval Loss:  0.23964440822601318\n",
      "Eval Loss:  0.19529414176940918\n",
      "Eval Loss:  0.1515684276819229\n",
      "Eval Loss:  0.22199930250644684\n",
      "Eval Loss:  0.22482514381408691\n",
      "Eval Loss:  0.28342682123184204\n",
      "Eval Loss:  0.24447347223758698\n",
      "Eval Loss:  0.3380609154701233\n",
      "Eval Loss:  0.27506792545318604\n",
      "Eval Loss:  0.2965794801712036\n",
      "Eval Loss:  0.3375616669654846\n",
      "Eval Loss:  0.25767746567726135\n",
      "Eval Loss:  0.20183677971363068\n",
      "Eval Loss:  0.18054017424583435\n",
      "Eval Loss:  0.17061814665794373\n",
      "Eval Loss:  0.29676753282546997\n",
      "Eval Loss:  0.2108280211687088\n",
      "Eval Loss:  0.34871557354927063\n",
      "Eval Loss:  0.23122942447662354\n",
      "Eval Loss:  0.26659172773361206\n",
      "[[18193   932]\n",
      " [ 1781  8553]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     19125\n",
      "           1       0.90      0.83      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.89      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.90790590311959\n",
      "pre:  0.9017395888244597\n",
      "rec:  0.8276562802399845\n",
      "ma F1:  0.8968615960374533\n",
      "mi F1:  0.90790590311959\n",
      "we F1:  0.9069332250373561\n",
      "29459 461\n",
      "Loss:  0.05058746412396431\n",
      "Loss:  0.044382158666849136\n",
      "Loss:  0.03301564231514931\n",
      "18 **********\n",
      "Epoch:  1270.6295940876007  fold:  1  kers:  128\n",
      "epoch:  19\n",
      "29459 461\n",
      "Loss:  0.0630868598818779\n",
      "Loss:  0.04367499798536301\n",
      "Loss:  0.06496889889240265\n",
      "19 **********\n",
      "Epoch:  1324.5574023723602  fold:  1  kers:  128\n",
      "epoch:  20\n",
      "29459 461\n",
      "Loss:  0.05475831404328346\n",
      "Loss:  0.08580062538385391\n",
      "Loss:  0.0559212900698185\n",
      "20 **********\n",
      "Epoch:  1378.5729758739471  fold:  1  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  1.5655720233917236\n",
      "Eval Loss:  0.2423419952392578\n",
      "Eval Loss:  0.07400833070278168\n",
      "[[ 778  261]\n",
      " [ 346 2047]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72      1039\n",
      "           1       0.89      0.86      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.80      0.80      3432\n",
      "weighted avg       0.83      0.82      0.83      3432\n",
      "\n",
      "acc:  0.8231351981351981\n",
      "pre:  0.8869150779896013\n",
      "rec:  0.8554116172168825\n",
      "ma F1:  0.795124890062344\n",
      "mi F1:  0.8231351981351981\n",
      "we F1:  0.8250113811030411\n",
      "Eval Loss:  0.1759181171655655\n",
      "Eval Loss:  0.2590664327144623\n",
      "Eval Loss:  0.3800153136253357\n",
      "Eval Loss:  0.31655585765838623\n",
      "Eval Loss:  0.23040422797203064\n",
      "Eval Loss:  0.2569233477115631\n",
      "Eval Loss:  0.3201453685760498\n",
      "Eval Loss:  0.1777307391166687\n",
      "Eval Loss:  0.25253164768218994\n",
      "Eval Loss:  0.2290903478860855\n",
      "Eval Loss:  0.13386857509613037\n",
      "Eval Loss:  0.19062833487987518\n",
      "Eval Loss:  0.2585955858230591\n",
      "Eval Loss:  0.25400784611701965\n",
      "Eval Loss:  0.23401501774787903\n",
      "Eval Loss:  0.33203554153442383\n",
      "Eval Loss:  0.25086015462875366\n",
      "Eval Loss:  0.272889643907547\n",
      "Eval Loss:  0.3150791525840759\n",
      "Eval Loss:  0.2660164535045624\n",
      "Eval Loss:  0.16034428775310516\n",
      "Eval Loss:  0.1804661899805069\n",
      "Eval Loss:  0.16945070028305054\n",
      "Eval Loss:  0.28631266951560974\n",
      "Eval Loss:  0.21966210007667542\n",
      "Eval Loss:  0.32770493626594543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24130070209503174\n",
      "Eval Loss:  0.2521783411502838\n",
      "[[18007  1118]\n",
      " [ 1691  8643]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     19125\n",
      "           1       0.89      0.84      0.86     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.89      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.9046471366984623\n",
      "pre:  0.8854625550660793\n",
      "rec:  0.8363653957809174\n",
      "ma F1:  0.8939299833146442\n",
      "mi F1:  0.9046471366984623\n",
      "we F1:  0.9039913348094268\n",
      "29459 461\n",
      "Loss:  0.06695583462715149\n",
      "Loss:  0.08594270050525665\n",
      "Loss:  0.04526104778051376\n",
      "21 **********\n",
      "Epoch:  1474.114516735077  fold:  1  kers:  128\n",
      "epoch:  22\n",
      "29459 461\n",
      "Loss:  0.06750817596912384\n",
      "Loss:  0.07363305240869522\n",
      "Loss:  0.07412374019622803\n",
      "22 **********\n",
      "Epoch:  1527.5955193042755  fold:  1  kers:  128\n",
      "epoch:  23\n",
      "29459 461\n",
      "Loss:  0.07364506274461746\n",
      "Loss:  0.08371371775865555\n",
      "Loss:  0.057724494487047195\n",
      "23 **********\n",
      "Epoch:  1580.648666381836  fold:  1  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  1.2632527351379395\n",
      "Eval Loss:  0.23944145441055298\n",
      "Eval Loss:  0.07049260288476944\n",
      "[[ 777  262]\n",
      " [ 384 2009]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71      1039\n",
      "           1       0.88      0.84      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.79      0.78      3432\n",
      "weighted avg       0.82      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8117715617715617\n",
      "pre:  0.8846323205636284\n",
      "rec:  0.8395319682407021\n",
      "ma F1:  0.7839279588336192\n",
      "mi F1:  0.8117715617715617\n",
      "we F1:  0.814528801672884\n",
      "Eval Loss:  0.13733471930027008\n",
      "Eval Loss:  0.2135915756225586\n",
      "Eval Loss:  0.33336853981018066\n",
      "Eval Loss:  0.2893292307853699\n",
      "Eval Loss:  0.21333974599838257\n",
      "Eval Loss:  0.23713669180870056\n",
      "Eval Loss:  0.2887517511844635\n",
      "Eval Loss:  0.15624643862247467\n",
      "Eval Loss:  0.24698489904403687\n",
      "Eval Loss:  0.1739274561405182\n",
      "Eval Loss:  0.1372707486152649\n",
      "Eval Loss:  0.1818830966949463\n",
      "Eval Loss:  0.24960799515247345\n",
      "Eval Loss:  0.27746838331222534\n",
      "Eval Loss:  0.21754509210586548\n",
      "Eval Loss:  0.30062565207481384\n",
      "Eval Loss:  0.23964254558086395\n",
      "Eval Loss:  0.2643638849258423\n",
      "Eval Loss:  0.281677782535553\n",
      "Eval Loss:  0.23226924240589142\n",
      "Eval Loss:  0.1505662202835083\n",
      "Eval Loss:  0.14681635797023773\n",
      "Eval Loss:  0.16163620352745056\n",
      "Eval Loss:  0.26012739539146423\n",
      "Eval Loss:  0.19482460618019104\n",
      "Eval Loss:  0.3130764365196228\n",
      "Eval Loss:  0.23127873241901398\n",
      "Eval Loss:  0.2560260593891144\n",
      "[[18225   900]\n",
      " [ 1652  8682]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     19125\n",
      "           1       0.91      0.84      0.87     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.90      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9133711259716895\n",
      "pre:  0.9060738885410144\n",
      "rec:  0.8401393458486549\n",
      "ma F1:  0.9032146388607857\n",
      "mi F1:  0.9133711259716895\n",
      "we F1:  0.9125707824416256\n",
      "29459 461\n",
      "Loss:  0.05110243335366249\n",
      "Loss:  0.058355119079351425\n",
      "Loss:  0.03189120814204216\n",
      "24 **********\n",
      "Epoch:  1673.0685541629791  fold:  1  kers:  128\n",
      "epoch:  25\n",
      "29459 461\n",
      "Loss:  0.09549383819103241\n",
      "Loss:  0.07084571570158005\n",
      "Loss:  0.03708408772945404\n",
      "25 **********\n",
      "Epoch:  1725.9371938705444  fold:  1  kers:  128\n",
      "epoch:  26\n",
      "29459 461\n",
      "Loss:  0.08115126192569733\n",
      "Loss:  0.06144369766116142\n",
      "Loss:  0.036978840827941895\n",
      "26 **********\n",
      "Epoch:  1778.7699301242828  fold:  1  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  1.3797054290771484\n",
      "Eval Loss:  0.23239880800247192\n",
      "Eval Loss:  0.08536531031131744\n",
      "[[ 731  308]\n",
      " [ 331 2062]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70      1039\n",
      "           1       0.87      0.86      0.87      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.78      0.78      3432\n",
      "weighted avg       0.82      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8138111888111889\n",
      "pre:  0.870042194092827\n",
      "rec:  0.8616798997074802\n",
      "ma F1:  0.7808499856551319\n",
      "mi F1:  0.8138111888111889\n",
      "we F1:  0.8143807663262823\n",
      "Eval Loss:  0.1289845108985901\n",
      "Eval Loss:  0.22726942598819733\n",
      "Eval Loss:  0.3303011953830719\n",
      "Eval Loss:  0.2477257251739502\n",
      "Eval Loss:  0.1882278025150299\n",
      "Eval Loss:  0.22714680433273315\n",
      "Eval Loss:  0.28608426451683044\n",
      "Eval Loss:  0.14614979922771454\n",
      "Eval Loss:  0.24364496767520905\n",
      "Eval Loss:  0.1934024840593338\n",
      "Eval Loss:  0.12637454271316528\n",
      "Eval Loss:  0.18636491894721985\n",
      "Eval Loss:  0.22857347130775452\n",
      "Eval Loss:  0.25728705525398254\n",
      "Eval Loss:  0.22873184084892273\n",
      "Eval Loss:  0.2816098928451538\n",
      "Eval Loss:  0.22019898891448975\n",
      "Eval Loss:  0.25059521198272705\n",
      "Eval Loss:  0.2934289872646332\n",
      "Eval Loss:  0.22528190910816193\n",
      "Eval Loss:  0.1737046092748642\n",
      "Eval Loss:  0.13707080483436584\n",
      "Eval Loss:  0.15056642889976501\n",
      "Eval Loss:  0.25435832142829895\n",
      "Eval Loss:  0.20056329667568207\n",
      "Eval Loss:  0.2845165729522705\n",
      "Eval Loss:  0.2070709466934204\n",
      "Eval Loss:  0.24651853740215302\n",
      "[[18069  1056]\n",
      " [ 1414  8920]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     19125\n",
      "           1       0.89      0.86      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.91      0.90      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9161546556230693\n",
      "pre:  0.8941459502806736\n",
      "rec:  0.8631701180568996\n",
      "ma F1:  0.9072043270255915\n",
      "mi F1:  0.9161546556230694\n",
      "we F1:  0.9158044296270156\n",
      "29459 461\n",
      "Loss:  0.058181844651699066\n",
      "Loss:  0.08582572638988495\n",
      "Loss:  0.05521054565906525\n",
      "27 **********\n",
      "Epoch:  1871.3733274936676  fold:  1  kers:  128\n",
      "epoch:  28\n",
      "29459 461\n",
      "Loss:  0.06275239586830139\n",
      "Loss:  0.05991413816809654\n",
      "Loss:  0.08576121181249619\n",
      "28 **********\n",
      "Epoch:  1924.2349858283997  fold:  1  kers:  128\n",
      "epoch:  29\n",
      "29459 461\n",
      "Loss:  0.07545112818479538\n",
      "Loss:  0.06197550147771835\n",
      "Loss:  0.05652938038110733\n",
      "29 **********\n",
      "Epoch:  1977.1854074001312  fold:  1  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  1.5713210105895996\n",
      "Eval Loss:  0.261270135641098\n",
      "Eval Loss:  0.20165912806987762\n",
      "[[ 720  319]\n",
      " [ 301 2092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70      1039\n",
      "           1       0.87      0.87      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.78      0.78      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8193473193473193\n",
      "pre:  0.8676897552882621\n",
      "rec:  0.8742164646886753\n",
      "ma F1:  0.7849850044057137\n",
      "mi F1:  0.8193473193473193\n",
      "we F1:  0.8188965018043538\n",
      "Eval Loss:  0.12757675349712372\n",
      "Eval Loss:  0.20606403052806854\n",
      "Eval Loss:  0.3414396047592163\n",
      "Eval Loss:  0.25980982184410095\n",
      "Eval Loss:  0.16521231830120087\n",
      "Eval Loss:  0.2201545536518097\n",
      "Eval Loss:  0.29464954137802124\n",
      "Eval Loss:  0.13999170064926147\n",
      "Eval Loss:  0.20181620121002197\n",
      "Eval Loss:  0.2085724174976349\n",
      "Eval Loss:  0.12187846004962921\n",
      "Eval Loss:  0.19587627053260803\n",
      "Eval Loss:  0.2040572315454483\n",
      "Eval Loss:  0.2422041893005371\n",
      "Eval Loss:  0.2087240070104599\n",
      "Eval Loss:  0.253543496131897\n",
      "Eval Loss:  0.22837123274803162\n",
      "Eval Loss:  0.24992147088050842\n",
      "Eval Loss:  0.26889312267303467\n",
      "Eval Loss:  0.2337796986103058\n",
      "Eval Loss:  0.1525108367204666\n",
      "Eval Loss:  0.14301951229572296\n",
      "Eval Loss:  0.15103782713413239\n",
      "Eval Loss:  0.21705247461795807\n",
      "Eval Loss:  0.18540272116661072\n",
      "Eval Loss:  0.25950539112091064\n",
      "Eval Loss:  0.1880219280719757\n",
      "Eval Loss:  0.21351252496242523\n",
      "[[18112  1013]\n",
      " [ 1286  9048]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.90      0.88      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.921959333310703\n",
      "pre:  0.8993141834807673\n",
      "rec:  0.8755564157151151\n",
      "ma F1:  0.9137988298327613\n",
      "mi F1:  0.921959333310703\n",
      "we F1:  0.9217135458604077\n",
      "29459 461\n",
      "Loss:  0.0429166704416275\n",
      "Loss:  0.03956390172243118\n",
      "Loss:  0.0434282049536705\n",
      "30 **********\n",
      "Epoch:  2069.661145925522  fold:  1  kers:  128\n",
      "epoch:  31\n",
      "29459 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07529456168413162\n",
      "Loss:  0.033212557435035706\n",
      "Loss:  0.06411895155906677\n",
      "31 **********\n",
      "Epoch:  2122.490890979767  fold:  1  kers:  128\n",
      "epoch:  32\n",
      "29459 461\n",
      "Loss:  0.04850369691848755\n",
      "Loss:  0.05767451599240303\n",
      "Loss:  0.0458349771797657\n",
      "32 **********\n",
      "Epoch:  2175.3276154994965  fold:  1  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  1.2987034320831299\n",
      "Eval Loss:  0.2483641356229782\n",
      "Eval Loss:  0.1753360629081726\n",
      "[[ 732  307]\n",
      " [ 291 2102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71      1039\n",
      "           1       0.87      0.88      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.79      0.79      0.79      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8257575757575758\n",
      "pre:  0.8725612287256123\n",
      "rec:  0.878395319682407\n",
      "ma F1:  0.7927294277238994\n",
      "mi F1:  0.8257575757575757\n",
      "we F1:  0.825371845561562\n",
      "Eval Loss:  0.12688949704170227\n",
      "Eval Loss:  0.19698403775691986\n",
      "Eval Loss:  0.3628405034542084\n",
      "Eval Loss:  0.27230513095855713\n",
      "Eval Loss:  0.1522139608860016\n",
      "Eval Loss:  0.2273823320865631\n",
      "Eval Loss:  0.2841949462890625\n",
      "Eval Loss:  0.14285199344158173\n",
      "Eval Loss:  0.19087737798690796\n",
      "Eval Loss:  0.17356126010417938\n",
      "Eval Loss:  0.12893423438072205\n",
      "Eval Loss:  0.1917305737733841\n",
      "Eval Loss:  0.20160852372646332\n",
      "Eval Loss:  0.2545888423919678\n",
      "Eval Loss:  0.19329139590263367\n",
      "Eval Loss:  0.25673577189445496\n",
      "Eval Loss:  0.21804411709308624\n",
      "Eval Loss:  0.23947808146476746\n",
      "Eval Loss:  0.27021369338035583\n",
      "Eval Loss:  0.24016696214675903\n",
      "Eval Loss:  0.13525725901126862\n",
      "Eval Loss:  0.11057368665933609\n",
      "Eval Loss:  0.14984656870365143\n",
      "Eval Loss:  0.22790312767028809\n",
      "Eval Loss:  0.17566072940826416\n",
      "Eval Loss:  0.29109853506088257\n",
      "Eval Loss:  0.21822792291641235\n",
      "Eval Loss:  0.2084668129682541\n",
      "[[18231   894]\n",
      " [ 1403  8931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.91      0.86      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9220272242778098\n",
      "pre:  0.9090076335877862\n",
      "rec:  0.8642345655119025\n",
      "ma F1:  0.9133961005260891\n",
      "mi F1:  0.9220272242778098\n",
      "we F1:  0.9215548326660222\n",
      "29459 461\n",
      "Loss:  0.06772150099277496\n",
      "Loss:  0.06135014072060585\n",
      "Loss:  0.09059681743383408\n",
      "33 **********\n",
      "Epoch:  2267.786399126053  fold:  1  kers:  128\n",
      "epoch:  34\n",
      "29459 461\n",
      "Loss:  0.06054988130927086\n",
      "Loss:  0.019430160522460938\n",
      "Loss:  0.05358835309743881\n",
      "34 **********\n",
      "Epoch:  2320.6610231399536  fold:  1  kers:  128\n",
      "epoch:  35\n",
      "29459 461\n",
      "Loss:  0.07135802507400513\n",
      "Loss:  0.04713849723339081\n",
      "Loss:  0.05830284208059311\n",
      "35 **********\n",
      "Epoch:  2373.515700817108  fold:  1  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  1.3431670665740967\n",
      "Eval Loss:  0.25984811782836914\n",
      "Eval Loss:  0.07138299196958542\n",
      "[[ 783  256]\n",
      " [ 404 1989]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70      1039\n",
      "           1       0.89      0.83      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.79      0.78      3432\n",
      "weighted avg       0.82      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8076923076923077\n",
      "pre:  0.8859688195991091\n",
      "rec:  0.8311742582532387\n",
      "ma F1:  0.7806006632192285\n",
      "mi F1:  0.8076923076923077\n",
      "we F1:  0.811016987113548\n",
      "Eval Loss:  0.12783612310886383\n",
      "Eval Loss:  0.18798592686653137\n",
      "Eval Loss:  0.32188668847084045\n",
      "Eval Loss:  0.24377931654453278\n",
      "Eval Loss:  0.17668373882770538\n",
      "Eval Loss:  0.22721216082572937\n",
      "Eval Loss:  0.26982545852661133\n",
      "Eval Loss:  0.12378428876399994\n",
      "Eval Loss:  0.2375478297472\n",
      "Eval Loss:  0.156472310423851\n",
      "Eval Loss:  0.1125183030962944\n",
      "Eval Loss:  0.16738775372505188\n",
      "Eval Loss:  0.23240987956523895\n",
      "Eval Loss:  0.24417221546173096\n",
      "Eval Loss:  0.20832623541355133\n",
      "Eval Loss:  0.282279908657074\n",
      "Eval Loss:  0.21442334353923798\n",
      "Eval Loss:  0.235304594039917\n",
      "Eval Loss:  0.2421148121356964\n",
      "Eval Loss:  0.23788157105445862\n",
      "Eval Loss:  0.13880734145641327\n",
      "Eval Loss:  0.10623449832201004\n",
      "Eval Loss:  0.14487406611442566\n",
      "Eval Loss:  0.22148872911930084\n",
      "Eval Loss:  0.17920219898223877\n",
      "Eval Loss:  0.25693997740745544\n",
      "Eval Loss:  0.20814576745033264\n",
      "Eval Loss:  0.21397936344146729\n",
      "[[18253   872]\n",
      " [ 1387  8947]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.91      0.87      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9233171526528395\n",
      "pre:  0.911192585803035\n",
      "rec:  0.8657828527191794\n",
      "ma F1:  0.9148166455673814\n",
      "mi F1:  0.9233171526528396\n",
      "we F1:  0.9228467291466059\n",
      "29459 461\n",
      "Loss:  0.06399287283420563\n",
      "Loss:  0.05693681538105011\n",
      "Loss:  0.06851990520954132\n",
      "36 **********\n",
      "Epoch:  2465.983460664749  fold:  1  kers:  128\n",
      "epoch:  37\n",
      "29459 461\n",
      "Loss:  0.04022884741425514\n",
      "Loss:  0.047517165541648865\n",
      "Loss:  0.06904890388250351\n",
      "37 **********\n",
      "Epoch:  2518.8770337104797  fold:  1  kers:  128\n",
      "epoch:  38\n",
      "29459 461\n",
      "Loss:  0.04420194774866104\n",
      "Loss:  0.05418690666556358\n",
      "Loss:  0.05356858670711517\n",
      "38 **********\n",
      "Epoch:  2571.72772192955  fold:  1  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  1.3502404689788818\n",
      "Eval Loss:  0.2407020479440689\n",
      "Eval Loss:  0.10696833580732346\n",
      "[[ 715  324]\n",
      " [ 268 2125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71      1039\n",
      "           1       0.87      0.89      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.79      0.79      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8275058275058275\n",
      "pre:  0.8677011024908126\n",
      "rec:  0.88800668616799\n",
      "ma F1:  0.7924785231107141\n",
      "mi F1:  0.8275058275058275\n",
      "we F1:  0.8261146721539648\n",
      "Eval Loss:  0.126261904835701\n",
      "Eval Loss:  0.1584388166666031\n",
      "Eval Loss:  0.3238593637943268\n",
      "Eval Loss:  0.24296340346336365\n",
      "Eval Loss:  0.13295206427574158\n",
      "Eval Loss:  0.22983227670192719\n",
      "Eval Loss:  0.262404203414917\n",
      "Eval Loss:  0.1262994110584259\n",
      "Eval Loss:  0.2058134526014328\n",
      "Eval Loss:  0.1723092645406723\n",
      "Eval Loss:  0.1306876540184021\n",
      "Eval Loss:  0.16252577304840088\n",
      "Eval Loss:  0.2539049983024597\n",
      "Eval Loss:  0.23174987733364105\n",
      "Eval Loss:  0.19356122612953186\n",
      "Eval Loss:  0.21222765743732452\n",
      "Eval Loss:  0.17352643609046936\n",
      "Eval Loss:  0.2200639396905899\n",
      "Eval Loss:  0.27356216311454773\n",
      "Eval Loss:  0.2443460375070572\n",
      "Eval Loss:  0.14186809957027435\n",
      "Eval Loss:  0.10639675706624985\n",
      "Eval Loss:  0.14563506841659546\n",
      "Eval Loss:  0.20410950481891632\n",
      "Eval Loss:  0.1431771069765091\n",
      "Eval Loss:  0.23856708407402039\n",
      "Eval Loss:  0.19577601552009583\n",
      "Eval Loss:  0.17079056799411774\n",
      "[[17915  1210]\n",
      " [ 1017  9317]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     19125\n",
      "           1       0.89      0.90      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.92      0.92     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9244034081265488\n",
      "pre:  0.8850574712643678\n",
      "rec:  0.9015869943874589\n",
      "ma F1:  0.9173641413452219\n",
      "mi F1:  0.9244034081265488\n",
      "we F1:  0.9245614191161738\n",
      "29459 461\n",
      "Loss:  0.0538422092795372\n",
      "Loss:  0.07730935513973236\n",
      "Loss:  0.05125010386109352\n",
      "39 **********\n",
      "Epoch:  2663.9541273117065  fold:  1  kers:  128\n",
      "epoch:  40\n",
      "29459 461\n",
      "Loss:  0.09263210743665695\n",
      "Loss:  0.04440032318234444\n",
      "Loss:  0.053637463599443436\n",
      "40 **********\n",
      "Epoch:  2716.7090725898743  fold:  1  kers:  128\n",
      "epoch:  41\n",
      "29459 461\n",
      "Loss:  0.03960029408335686\n",
      "Loss:  0.06353628635406494\n",
      "Loss:  0.02981783263385296\n",
      "41 **********\n",
      "Epoch:  2769.596660375595  fold:  1  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  1.5888381004333496\n",
      "Eval Loss:  0.21104170382022858\n",
      "Eval Loss:  0.26155248284339905\n",
      "[[ 688  351]\n",
      " [ 213 2180]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.66      0.71      1039\n",
      "           1       0.86      0.91      0.89      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.81      0.79      0.80      3432\n",
      "weighted avg       0.83      0.84      0.83      3432\n",
      "\n",
      "acc:  0.8356643356643356\n",
      "pre:  0.8613196365073094\n",
      "rec:  0.9109903886335144\n",
      "ma F1:  0.7973686634786905\n",
      "mi F1:  0.8356643356643356\n",
      "we F1:  0.8321222426605697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1184656098484993\n",
      "Eval Loss:  0.1787809431552887\n",
      "Eval Loss:  0.32668861746788025\n",
      "Eval Loss:  0.2573794722557068\n",
      "Eval Loss:  0.1556028425693512\n",
      "Eval Loss:  0.20505386590957642\n",
      "Eval Loss:  0.26408782601356506\n",
      "Eval Loss:  0.13626906275749207\n",
      "Eval Loss:  0.1832864135503769\n",
      "Eval Loss:  0.18328770995140076\n",
      "Eval Loss:  0.11774086207151413\n",
      "Eval Loss:  0.17866459488868713\n",
      "Eval Loss:  0.23623058199882507\n",
      "Eval Loss:  0.25204190611839294\n",
      "Eval Loss:  0.19675129652023315\n",
      "Eval Loss:  0.22611241042613983\n",
      "Eval Loss:  0.20479734241962433\n",
      "Eval Loss:  0.22259381413459778\n",
      "Eval Loss:  0.24910564720630646\n",
      "Eval Loss:  0.25630420446395874\n",
      "Eval Loss:  0.14620360732078552\n",
      "Eval Loss:  0.11307740211486816\n",
      "Eval Loss:  0.16245999932289124\n",
      "Eval Loss:  0.20031684637069702\n",
      "Eval Loss:  0.17029361426830292\n",
      "Eval Loss:  0.24803036451339722\n",
      "Eval Loss:  0.19708241522312164\n",
      "Eval Loss:  0.18800044059753418\n",
      "[[18057  1068]\n",
      " [ 1141  9193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     19125\n",
      "           1       0.90      0.89      0.89     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.92      0.92      0.92     29459\n",
      "weighted avg       0.92      0.93      0.92     29459\n",
      "\n",
      "acc:  0.9250144268305102\n",
      "pre:  0.8959165773316441\n",
      "rec:  0.8895877685310625\n",
      "ma F1:  0.9175496657045593\n",
      "mi F1:  0.9250144268305103\n",
      "we F1:  0.9249529503456055\n",
      "29459 461\n",
      "Loss:  0.04904969409108162\n",
      "Loss:  0.046617187559604645\n",
      "Loss:  0.03383360058069229\n",
      "42 **********\n",
      "Epoch:  2861.857973098755  fold:  1  kers:  128\n",
      "epoch:  43\n",
      "29459 461\n",
      "Loss:  0.046844758093357086\n",
      "Loss:  0.06319823116064072\n",
      "Loss:  0.06454671919345856\n",
      "43 **********\n",
      "Epoch:  2914.764511346817  fold:  1  kers:  128\n",
      "epoch:  44\n",
      "29459 461\n",
      "Loss:  0.062287941575050354\n",
      "Loss:  0.0423102043569088\n",
      "Loss:  0.05921081453561783\n",
      "44 **********\n",
      "Epoch:  2967.535412311554  fold:  1  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  1.4857361316680908\n",
      "Eval Loss:  0.20059239864349365\n",
      "Eval Loss:  0.266755074262619\n",
      "[[ 715  324]\n",
      " [ 199 2194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73      1039\n",
      "           1       0.87      0.92      0.89      2393\n",
      "\n",
      "    accuracy                           0.85      3432\n",
      "   macro avg       0.83      0.80      0.81      3432\n",
      "weighted avg       0.84      0.85      0.84      3432\n",
      "\n",
      "acc:  0.8476107226107226\n",
      "pre:  0.8713264495631453\n",
      "rec:  0.9168407856247388\n",
      "ma F1:  0.8128556195831109\n",
      "mi F1:  0.8476107226107226\n",
      "we F1:  0.8446733406780307\n",
      "Eval Loss:  0.14460916817188263\n",
      "Eval Loss:  0.17578034102916718\n",
      "Eval Loss:  0.32945516705513\n",
      "Eval Loss:  0.2568936347961426\n",
      "Eval Loss:  0.1432753950357437\n",
      "Eval Loss:  0.18072181940078735\n",
      "Eval Loss:  0.27264609932899475\n",
      "Eval Loss:  0.1265476495027542\n",
      "Eval Loss:  0.20740161836147308\n",
      "Eval Loss:  0.2245776206254959\n",
      "Eval Loss:  0.09706137329339981\n",
      "Eval Loss:  0.17590348422527313\n",
      "Eval Loss:  0.20485864579677582\n",
      "Eval Loss:  0.26900747418403625\n",
      "Eval Loss:  0.2038709670305252\n",
      "Eval Loss:  0.22556853294372559\n",
      "Eval Loss:  0.24305962026119232\n",
      "Eval Loss:  0.22907140851020813\n",
      "Eval Loss:  0.24848602712154388\n",
      "Eval Loss:  0.23638521134853363\n",
      "Eval Loss:  0.12967970967292786\n",
      "Eval Loss:  0.1377599686384201\n",
      "Eval Loss:  0.13255634903907776\n",
      "Eval Loss:  0.22356946766376495\n",
      "Eval Loss:  0.15864157676696777\n",
      "Eval Loss:  0.22369173169136047\n",
      "Eval Loss:  0.18758361041545868\n",
      "Eval Loss:  0.1752396821975708\n",
      "[[18187   938]\n",
      " [ 1230  9104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     19125\n",
      "           1       0.91      0.88      0.89     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.92      0.92      0.92     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9264061916562002\n",
      "pre:  0.9065923122883888\n",
      "rec:  0.8809754209405845\n",
      "ma F1:  0.9186749948867472\n",
      "mi F1:  0.9264061916562003\n",
      "we F1:  0.9261576493841888\n",
      "29459 461\n",
      "Loss:  0.0488632395863533\n",
      "Loss:  0.03403692692518234\n",
      "Loss:  0.023391621187329292\n",
      "45 **********\n",
      "Epoch:  3059.7568311691284  fold:  1  kers:  128\n",
      "epoch:  46\n",
      "29459 461\n",
      "Loss:  0.049859944730997086\n",
      "Loss:  0.029060587286949158\n",
      "Loss:  0.06370632350444794\n",
      "46 **********\n",
      "Epoch:  3112.424010038376  fold:  1  kers:  128\n",
      "epoch:  47\n",
      "29459 461\n",
      "Loss:  0.07335120439529419\n",
      "Loss:  0.03735574334859848\n",
      "Loss:  0.031075574457645416\n",
      "47 **********\n",
      "Epoch:  3165.1350708007812  fold:  1  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  1.9024995565414429\n",
      "Eval Loss:  0.249452143907547\n",
      "Eval Loss:  0.14406253397464752\n",
      "[[ 677  362]\n",
      " [ 249 2144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69      1039\n",
      "           1       0.86      0.90      0.88      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.77      0.78      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.821969696969697\n",
      "pre:  0.8555466879489226\n",
      "rec:  0.8959465106560802\n",
      "ma F1:  0.7821695968487103\n",
      "mi F1:  0.8219696969696971\n",
      "we F1:  0.8189039769194779\n",
      "Eval Loss:  0.11496687680482864\n",
      "Eval Loss:  0.15924957394599915\n",
      "Eval Loss:  0.3032870888710022\n",
      "Eval Loss:  0.23119913041591644\n",
      "Eval Loss:  0.12782998383045197\n",
      "Eval Loss:  0.20449478924274445\n",
      "Eval Loss:  0.24200530350208282\n",
      "Eval Loss:  0.12897266447544098\n",
      "Eval Loss:  0.1970880627632141\n",
      "Eval Loss:  0.1860426664352417\n",
      "Eval Loss:  0.11152423173189163\n",
      "Eval Loss:  0.14135664701461792\n",
      "Eval Loss:  0.22696629166603088\n",
      "Eval Loss:  0.2179904580116272\n",
      "Eval Loss:  0.18968932330608368\n",
      "Eval Loss:  0.19164885580539703\n",
      "Eval Loss:  0.17442765831947327\n",
      "Eval Loss:  0.20388516783714294\n",
      "Eval Loss:  0.23037175834178925\n",
      "Eval Loss:  0.24087689816951752\n",
      "Eval Loss:  0.13449953496456146\n",
      "Eval Loss:  0.1220293939113617\n",
      "Eval Loss:  0.11279883235692978\n",
      "Eval Loss:  0.195261150598526\n",
      "Eval Loss:  0.1357388198375702\n",
      "Eval Loss:  0.21305452287197113\n",
      "Eval Loss:  0.19277073442935944\n",
      "Eval Loss:  0.15722650289535522\n",
      "[[17861  1264]\n",
      " [  828  9506]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94     19125\n",
      "           1       0.88      0.92      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.92      0.93      0.92     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9289860484062595\n",
      "pre:  0.8826369545032497\n",
      "rec:  0.9198761370234179\n",
      "ma F1:  0.922774223722171\n",
      "mi F1:  0.9289860484062595\n",
      "we F1:  0.9293102082581164\n",
      "29459 461\n",
      "Loss:  0.04550683870911598\n",
      "Loss:  0.06351571530103683\n",
      "Loss:  0.035496585071086884\n",
      "48 **********\n",
      "Epoch:  3257.422313928604  fold:  1  kers:  128\n",
      "epoch:  49\n",
      "29459 461\n",
      "Loss:  0.062329210340976715\n",
      "Loss:  0.04880296438932419\n",
      "Loss:  0.06134326756000519\n",
      "49 **********\n",
      "Epoch:  3310.105450153351  fold:  1  kers:  128\n",
      "epoch:  50\n",
      "29459 461\n",
      "Loss:  0.060816891491413116\n",
      "Loss:  0.05571724474430084\n",
      "Loss:  0.03417973220348358\n",
      "50 **********\n",
      "Epoch:  3362.9272150993347  fold:  1  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  1.5412272214889526\n",
      "Eval Loss:  0.2507952153682709\n",
      "Eval Loss:  0.07765144854784012\n",
      "[[ 736  303]\n",
      " [ 306 2087]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      1039\n",
      "           1       0.87      0.87      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.79      0.79      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8225524475524476\n",
      "pre:  0.8732217573221758\n",
      "rec:  0.8721270371918094\n",
      "ma F1:  0.7900131442218421\n",
      "mi F1:  0.8225524475524476\n",
      "we F1:  0.8226247035924119\n",
      "Eval Loss:  0.10522517561912537\n",
      "Eval Loss:  0.13171164691448212\n",
      "Eval Loss:  0.3182843029499054\n",
      "Eval Loss:  0.2233451008796692\n",
      "Eval Loss:  0.12972420454025269\n",
      "Eval Loss:  0.19362829625606537\n",
      "Eval Loss:  0.23707139492034912\n",
      "Eval Loss:  0.11605251580476761\n",
      "Eval Loss:  0.20074696838855743\n",
      "Eval Loss:  0.1579608917236328\n",
      "Eval Loss:  0.0979963019490242\n",
      "Eval Loss:  0.14870713651180267\n",
      "Eval Loss:  0.21674376726150513\n",
      "Eval Loss:  0.23029343783855438\n",
      "Eval Loss:  0.18585561215877533\n",
      "Eval Loss:  0.2036077082157135\n",
      "Eval Loss:  0.18060417473316193\n",
      "Eval Loss:  0.19012151658535004\n",
      "Eval Loss:  0.22559073567390442\n",
      "Eval Loss:  0.23535771667957306\n",
      "Eval Loss:  0.13493964076042175\n",
      "Eval Loss:  0.10054521262645721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.12378954887390137\n",
      "Eval Loss:  0.22881127893924713\n",
      "Eval Loss:  0.15774793922901154\n",
      "Eval Loss:  0.21662192046642303\n",
      "Eval Loss:  0.15859480202198029\n",
      "Eval Loss:  0.1942986696958542\n",
      "[[18258   867]\n",
      " [ 1109  9225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     19125\n",
      "           1       0.91      0.89      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.93      0.92      0.93     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9329237244984555\n",
      "pre:  0.914090368608799\n",
      "rec:  0.8926843429456164\n",
      "ma F1:  0.925962603935122\n",
      "mi F1:  0.9329237244984555\n",
      "we F1:  0.9327372315087149\n",
      "29459 461\n",
      "Loss:  0.060034457594156265\n",
      "Loss:  0.03967553749680519\n",
      "Loss:  0.05932500958442688\n",
      "51 **********\n",
      "Epoch:  3455.2344048023224  fold:  1  kers:  128\n",
      "epoch:  52\n",
      "29459 461\n",
      "Loss:  0.04861249774694443\n",
      "Loss:  0.07280371338129044\n",
      "Loss:  0.05963095277547836\n",
      "52 **********\n",
      "Epoch:  3507.9434716701508  fold:  1  kers:  128\n",
      "epoch:  53\n",
      "29459 461\n",
      "Loss:  0.043671730905771255\n",
      "Loss:  0.04761273413896561\n",
      "Loss:  0.0351792648434639\n",
      "53 **********\n",
      "Epoch:  3560.6066608428955  fold:  1  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  1.2426626682281494\n",
      "Eval Loss:  0.2782835066318512\n",
      "Eval Loss:  0.09300898015499115\n",
      "[[ 729  310]\n",
      " [ 293 2100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      1039\n",
      "           1       0.87      0.88      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.79      0.79      3432\n",
      "weighted avg       0.82      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8243006993006993\n",
      "pre:  0.8713692946058091\n",
      "rec:  0.8775595486836607\n",
      "ma F1:  0.7909385236847057\n",
      "mi F1:  0.8243006993006993\n",
      "we F1:  0.8238870180567374\n",
      "Eval Loss:  0.10137668251991272\n",
      "Eval Loss:  0.1555563360452652\n",
      "Eval Loss:  0.3281409442424774\n",
      "Eval Loss:  0.23245736956596375\n",
      "Eval Loss:  0.13105015456676483\n",
      "Eval Loss:  0.2134442925453186\n",
      "Eval Loss:  0.23364561796188354\n",
      "Eval Loss:  0.10242951661348343\n",
      "Eval Loss:  0.17636021971702576\n",
      "Eval Loss:  0.1645338088274002\n",
      "Eval Loss:  0.10446786135435104\n",
      "Eval Loss:  0.146128848195076\n",
      "Eval Loss:  0.2740181088447571\n",
      "Eval Loss:  0.24701304733753204\n",
      "Eval Loss:  0.18878987431526184\n",
      "Eval Loss:  0.19143590331077576\n",
      "Eval Loss:  0.1964873969554901\n",
      "Eval Loss:  0.1806095689535141\n",
      "Eval Loss:  0.20582352578639984\n",
      "Eval Loss:  0.2626858055591583\n",
      "Eval Loss:  0.13554756343364716\n",
      "Eval Loss:  0.10078750550746918\n",
      "Eval Loss:  0.11650046706199646\n",
      "Eval Loss:  0.20426645874977112\n",
      "Eval Loss:  0.14986439049243927\n",
      "Eval Loss:  0.23705396056175232\n",
      "Eval Loss:  0.15338467061519623\n",
      "Eval Loss:  0.16224095225334167\n",
      "[[18133   992]\n",
      " [ 1037  9297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     19125\n",
      "           1       0.90      0.90      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.92      0.92      0.92     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9311246138701246\n",
      "pre:  0.9035863543590242\n",
      "rec:  0.8996516353783627\n",
      "ma F1:  0.9243156419154513\n",
      "mi F1:  0.9311246138701246\n",
      "we F1:  0.9310899371229584\n",
      "29459 461\n",
      "Loss:  0.05295791104435921\n",
      "Loss:  0.04691718518733978\n",
      "Loss:  0.04835601896047592\n",
      "54 **********\n",
      "Epoch:  3660.674101114273  fold:  1  kers:  128\n",
      "epoch:  55\n",
      "29459 461\n",
      "Loss:  0.05119922757148743\n",
      "Loss:  0.03129888325929642\n",
      "Loss:  0.04190313071012497\n",
      "55 **********\n",
      "Epoch:  3713.51082611084  fold:  1  kers:  128\n",
      "epoch:  56\n",
      "29459 461\n",
      "Loss:  0.026990219950675964\n",
      "Loss:  0.04829134792089462\n",
      "Loss:  0.047196365892887115\n",
      "56 **********\n",
      "Epoch:  3766.4642391204834  fold:  1  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  1.726637840270996\n",
      "Eval Loss:  0.21930602192878723\n",
      "Eval Loss:  0.16007454693317413\n",
      "[[ 711  328]\n",
      " [ 262 2131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.71      1039\n",
      "           1       0.87      0.89      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.79      0.79      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.828088578088578\n",
      "pre:  0.8666124440829606\n",
      "rec:  0.890513999164229\n",
      "ma F1:  0.7925800514309036\n",
      "mi F1:  0.828088578088578\n",
      "we F1:  0.826438181779137\n",
      "Eval Loss:  0.11589929461479187\n",
      "Eval Loss:  0.17697232961654663\n",
      "Eval Loss:  0.3499656617641449\n",
      "Eval Loss:  0.20572879910469055\n",
      "Eval Loss:  0.12245745956897736\n",
      "Eval Loss:  0.18621806800365448\n",
      "Eval Loss:  0.21591781079769135\n",
      "Eval Loss:  0.09769295901060104\n",
      "Eval Loss:  0.1786765456199646\n",
      "Eval Loss:  0.20714171230793\n",
      "Eval Loss:  0.09485548734664917\n",
      "Eval Loss:  0.1718844771385193\n",
      "Eval Loss:  0.20564398169517517\n",
      "Eval Loss:  0.23846884071826935\n",
      "Eval Loss:  0.1810181587934494\n",
      "Eval Loss:  0.196524977684021\n",
      "Eval Loss:  0.21462489664554596\n",
      "Eval Loss:  0.18958976864814758\n",
      "Eval Loss:  0.21241477131843567\n",
      "Eval Loss:  0.22930137813091278\n",
      "Eval Loss:  0.12073816359043121\n",
      "Eval Loss:  0.1066051498055458\n",
      "Eval Loss:  0.11901375651359558\n",
      "Eval Loss:  0.19924168288707733\n",
      "Eval Loss:  0.150509312748909\n",
      "Eval Loss:  0.2024354487657547\n",
      "Eval Loss:  0.17451441287994385\n",
      "Eval Loss:  0.14252664148807526\n",
      "[[18196   929]\n",
      " [ 1031  9303]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     19125\n",
      "           1       0.91      0.90      0.90     10334\n",
      "\n",
      "    accuracy                           0.93     29459\n",
      "   macro avg       0.93      0.93      0.93     29459\n",
      "weighted avg       0.93      0.93      0.93     29459\n",
      "\n",
      "acc:  0.9334668522353101\n",
      "pre:  0.909206411258796\n",
      "rec:  0.9002322430810915\n",
      "ma F1:  0.926795762118123\n",
      "mi F1:  0.9334668522353101\n",
      "we F1:  0.9333903368645742\n",
      "29459 461\n",
      "Loss:  0.050223927944898605\n",
      "Loss:  0.061685312539339066\n",
      "Loss:  0.03754081577062607\n",
      "57 **********\n",
      "Epoch:  3859.294031381607  fold:  1  kers:  128\n",
      "epoch:  58\n",
      "29459 461\n",
      "Loss:  0.03968073055148125\n",
      "Loss:  0.042411092668771744\n",
      "Loss:  0.06943406164646149\n",
      "58 **********\n",
      "Epoch:  3912.1586821079254  fold:  1  kers:  128\n",
      "epoch:  59\n",
      "29459 461\n",
      "Loss:  0.08240292966365814\n",
      "Loss:  0.05558188259601593\n",
      "Loss:  0.03009280189871788\n",
      "59 **********\n",
      "Epoch:  3965.0911514759064  fold:  1  kers:  128\n",
      "Eval Loss:  1.504815936088562\n",
      "Eval Loss:  0.1934228092432022\n",
      "Eval Loss:  0.15157999098300934\n",
      "[[ 736  303]\n",
      " [ 363 2030]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      1039\n",
      "           1       0.87      0.85      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.77      0.78      0.77      3432\n",
      "weighted avg       0.81      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8059440559440559\n",
      "pre:  0.8701243034719246\n",
      "rec:  0.8483075637275387\n",
      "ma F1:  0.7737856817390967\n",
      "mi F1:  0.8059440559440559\n",
      "we F1:  0.8074351706676243\n",
      "update!  Acc:  0.8525641025641025\n",
      "Epoch:  3969.2889275550842  fold:  1  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29797 3094\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29797 466\n",
      "Loss:  0.16766300797462463\n",
      "Loss:  0.1634133756160736\n",
      "Loss:  0.1605810821056366\n",
      "0 **********\n",
      "Epoch:  65.9237322807312  fold:  2  kers:  128\n",
      "epoch:  1\n",
      "29797 466\n",
      "Loss:  0.16199582815170288\n",
      "Loss:  0.11213541775941849\n",
      "Loss:  0.1067516878247261\n",
      "1 **********\n",
      "Epoch:  119.68299150466919  fold:  2  kers:  128\n",
      "epoch:  2\n",
      "29797 466\n",
      "Loss:  0.10587312281131744\n",
      "Loss:  0.09906651824712753\n",
      "Loss:  0.10002750158309937\n",
      "2 **********\n",
      "Epoch:  173.3385272026062  fold:  2  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  1.0346250534057617\n",
      "Eval Loss:  0.10620489716529846\n",
      "Eval Loss:  0.9071074724197388\n",
      "[[1283  147]\n",
      " [ 851  813]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72      1430\n",
      "           1       0.85      0.49      0.62      1664\n",
      "\n",
      "    accuracy                           0.68      3094\n",
      "   macro avg       0.72      0.69      0.67      3094\n",
      "weighted avg       0.73      0.68      0.67      3094\n",
      "\n",
      "acc:  0.6774402068519716\n",
      "pre:  0.846875\n",
      "rec:  0.4885817307692308\n",
      "ma F1:  0.669821093728614\n",
      "mi F1:  0.6774402068519716\n",
      "we F1:  0.6660277480459212\n",
      "update!  Acc:  0.6774402068519716\n",
      "Eval Loss:  0.3869931101799011\n",
      "Eval Loss:  0.4252561628818512\n",
      "Eval Loss:  0.40331199765205383\n",
      "Eval Loss:  0.4063665270805359\n",
      "Eval Loss:  0.3384529650211334\n",
      "Eval Loss:  0.5239200592041016\n",
      "Eval Loss:  0.4413178563117981\n",
      "Eval Loss:  0.3719782531261444\n",
      "Eval Loss:  0.3142184615135193\n",
      "Eval Loss:  0.513107419013977\n",
      "Eval Loss:  0.3792498707771301\n",
      "Eval Loss:  0.38366949558258057\n",
      "Eval Loss:  0.42709094285964966\n",
      "Eval Loss:  0.37454310059547424\n",
      "Eval Loss:  0.3076653778553009\n",
      "Eval Loss:  0.3689678907394409\n",
      "Eval Loss:  0.3817477226257324\n",
      "Eval Loss:  0.36741408705711365\n",
      "Eval Loss:  0.3974319398403168\n",
      "Eval Loss:  0.37031131982803345\n",
      "Eval Loss:  0.3772684335708618\n",
      "Eval Loss:  0.3828003704547882\n",
      "Eval Loss:  0.38686439394950867\n",
      "Eval Loss:  0.6254674792289734\n",
      "Eval Loss:  0.37042665481567383\n",
      "Eval Loss:  0.29384645819664\n",
      "Eval Loss:  0.32837411761283875\n",
      "Eval Loss:  0.3572062849998474\n",
      "Eval Loss:  0.2810423970222473\n",
      "[[16936  1798]\n",
      " [ 3095  7968]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87     18734\n",
      "           1       0.82      0.72      0.77     11063\n",
      "\n",
      "    accuracy                           0.84     29797\n",
      "   macro avg       0.83      0.81      0.82     29797\n",
      "weighted avg       0.83      0.84      0.83     29797\n",
      "\n",
      "acc:  0.8357888378024634\n",
      "pre:  0.8158918697522015\n",
      "rec:  0.7202386332821116\n",
      "ma F1:  0.8194325152767337\n",
      "mi F1:  0.8357888378024634\n",
      "we F1:  0.8334232991856179\n",
      "29797 466\n",
      "Loss:  0.08273762464523315\n",
      "Loss:  0.09699621051549911\n",
      "Loss:  0.09281841665506363\n",
      "3 **********\n",
      "Epoch:  267.37609004974365  fold:  2  kers:  128\n",
      "epoch:  4\n",
      "29797 466\n",
      "Loss:  0.0636574923992157\n",
      "Loss:  0.10846754908561707\n",
      "Loss:  0.06710939109325409\n",
      "4 **********\n",
      "Epoch:  320.8929967880249  fold:  2  kers:  128\n",
      "epoch:  5\n",
      "29797 466\n",
      "Loss:  0.0870695486664772\n",
      "Loss:  0.0870506763458252\n",
      "Loss:  0.07921764254570007\n",
      "5 **********\n",
      "Epoch:  374.2722713947296  fold:  2  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  1.133272647857666\n",
      "Eval Loss:  0.07704893499612808\n",
      "Eval Loss:  1.1377133131027222\n",
      "[[1366   64]\n",
      " [1009  655]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.96      0.72      1430\n",
      "           1       0.91      0.39      0.55      1664\n",
      "\n",
      "    accuracy                           0.65      3094\n",
      "   macro avg       0.74      0.67      0.63      3094\n",
      "weighted avg       0.76      0.65      0.63      3094\n",
      "\n",
      "acc:  0.6531997414350356\n",
      "pre:  0.9109874826147427\n",
      "rec:  0.3936298076923077\n",
      "ma F1:  0.6338649313495781\n",
      "mi F1:  0.6531997414350356\n",
      "we F1:  0.6275015761315795\n",
      "Eval Loss:  0.37070950865745544\n",
      "Eval Loss:  0.38244110345840454\n",
      "Eval Loss:  0.44790971279144287\n",
      "Eval Loss:  0.39408907294273376\n",
      "Eval Loss:  0.3109041452407837\n",
      "Eval Loss:  0.5393415689468384\n",
      "Eval Loss:  0.4226866662502289\n",
      "Eval Loss:  0.31713154911994934\n",
      "Eval Loss:  0.3223101496696472\n",
      "Eval Loss:  0.5933211445808411\n",
      "Eval Loss:  0.3972165286540985\n",
      "Eval Loss:  0.32588255405426025\n",
      "Eval Loss:  0.42717263102531433\n",
      "Eval Loss:  0.4116976261138916\n",
      "Eval Loss:  0.2920883893966675\n",
      "Eval Loss:  0.41077324748039246\n",
      "Eval Loss:  0.4563606083393097\n",
      "Eval Loss:  0.3568134307861328\n",
      "Eval Loss:  0.42242011427879333\n",
      "Eval Loss:  0.24402928352355957\n",
      "Eval Loss:  0.36257466673851013\n",
      "Eval Loss:  0.32083848118782043\n",
      "Eval Loss:  0.3773760497570038\n",
      "Eval Loss:  0.65472012758255\n",
      "Eval Loss:  0.4157990515232086\n",
      "Eval Loss:  0.29773038625717163\n",
      "Eval Loss:  0.33705228567123413\n",
      "Eval Loss:  0.3737223744392395\n",
      "Eval Loss:  0.2870868146419525\n",
      "[[18243   491]\n",
      " [ 4041  7022]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     18734\n",
      "           1       0.93      0.63      0.76     11063\n",
      "\n",
      "    accuracy                           0.85     29797\n",
      "   macro avg       0.88      0.80      0.82     29797\n",
      "weighted avg       0.86      0.85      0.84     29797\n",
      "\n",
      "acc:  0.84790415142464\n",
      "pre:  0.934646612538267\n",
      "rec:  0.6347283738588086\n",
      "ma F1:  0.8227706033472248\n",
      "mi F1:  0.84790415142464\n",
      "we F1:  0.8399526234258143\n",
      "29797 466\n",
      "Loss:  0.07857587933540344\n",
      "Loss:  0.04789400100708008\n",
      "Loss:  0.07890653610229492\n",
      "6 **********\n",
      "Epoch:  468.0255937576294  fold:  2  kers:  128\n",
      "epoch:  7\n",
      "29797 466\n",
      "Loss:  0.08016638457775116\n",
      "Loss:  0.03447964787483215\n",
      "Loss:  0.060050249099731445\n",
      "7 **********\n",
      "Epoch:  521.4686977863312  fold:  2  kers:  128\n",
      "epoch:  8\n",
      "29797 466\n",
      "Loss:  0.07965026050806046\n",
      "Loss:  0.09502175450325012\n",
      "Loss:  0.04999871179461479\n",
      "8 **********\n",
      "Epoch:  574.8579456806183  fold:  2  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.9884912967681885\n",
      "Eval Loss:  0.09105680882930756\n",
      "Eval Loss:  0.5380275249481201\n",
      "[[1360   70]\n",
      " [ 896  768]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.95      0.74      1430\n",
      "           1       0.92      0.46      0.61      1664\n",
      "\n",
      "    accuracy                           0.69      3094\n",
      "   macro avg       0.76      0.71      0.68      3094\n",
      "weighted avg       0.77      0.69      0.67      3094\n",
      "\n",
      "acc:  0.6877828054298643\n",
      "pre:  0.9164677804295943\n",
      "rec:  0.46153846153846156\n",
      "ma F1:  0.6759180826798138\n",
      "mi F1:  0.6877828054298643\n",
      "we F1:  0.6712283105117196\n",
      "update!  Acc:  0.6877828054298643\n",
      "Eval Loss:  0.33185040950775146\n",
      "Eval Loss:  0.31609442830085754\n",
      "Eval Loss:  0.40078872442245483\n",
      "Eval Loss:  0.31476491689682007\n",
      "Eval Loss:  0.2723645567893982\n",
      "Eval Loss:  0.4360857307910919\n",
      "Eval Loss:  0.3524157702922821\n",
      "Eval Loss:  0.3000909090042114\n",
      "Eval Loss:  0.28407445549964905\n",
      "Eval Loss:  0.4971521198749542\n",
      "Eval Loss:  0.34698188304901123\n",
      "Eval Loss:  0.2824368178844452\n",
      "Eval Loss:  0.381158709526062\n",
      "Eval Loss:  0.3523596227169037\n",
      "Eval Loss:  0.2699931263923645\n",
      "Eval Loss:  0.363625705242157\n",
      "Eval Loss:  0.3836595416069031\n",
      "Eval Loss:  0.32020851969718933\n",
      "Eval Loss:  0.3916601240634918\n",
      "Eval Loss:  0.20088663697242737\n",
      "Eval Loss:  0.30901044607162476\n",
      "Eval Loss:  0.2591626048088074\n",
      "Eval Loss:  0.3327472507953644\n",
      "Eval Loss:  0.5773035883903503\n",
      "Eval Loss:  0.36443158984184265\n",
      "Eval Loss:  0.2614246606826782\n",
      "Eval Loss:  0.31936579942703247\n",
      "Eval Loss:  0.32508206367492676\n",
      "Eval Loss:  0.24178163707256317\n",
      "[[18146   588]\n",
      " [ 3339  7724]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     18734\n",
      "           1       0.93      0.70      0.80     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.89      0.83      0.85     29797\n",
      "weighted avg       0.88      0.87      0.86     29797\n",
      "\n",
      "acc:  0.8682082088800886\n",
      "pre:  0.9292589027911453\n",
      "rec:  0.6981831329657416\n",
      "ma F1:  0.849837855162341\n",
      "mi F1:  0.8682082088800886\n",
      "we F1:  0.8633591546604069\n",
      "29797 466\n",
      "Loss:  0.06281436234712601\n",
      "Loss:  0.08691993355751038\n",
      "Loss:  0.06424679607152939\n",
      "9 **********\n",
      "Epoch:  668.834671497345  fold:  2  kers:  128\n",
      "epoch:  10\n",
      "29797 466\n",
      "Loss:  0.09833817183971405\n",
      "Loss:  0.08394529670476913\n",
      "Loss:  0.08903190493583679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 **********\n",
      "Epoch:  722.2309000492096  fold:  2  kers:  128\n",
      "epoch:  11\n",
      "29797 466\n",
      "Loss:  0.060611043125391006\n",
      "Loss:  0.046098824590444565\n",
      "Loss:  0.07185445725917816\n",
      "11 **********\n",
      "Epoch:  775.6470761299133  fold:  2  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.4894852042198181\n",
      "Eval Loss:  0.3353460729122162\n",
      "Eval Loss:  0.3426971435546875\n",
      "[[1207  223]\n",
      " [ 522 1142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1430\n",
      "           1       0.84      0.69      0.75      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.77      0.76      3094\n",
      "weighted avg       0.77      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7592113768584356\n",
      "pre:  0.8366300366300367\n",
      "rec:  0.6862980769230769\n",
      "ma F1:  0.7591050571498832\n",
      "mi F1:  0.7592113768584355\n",
      "we F1:  0.7587223061990938\n",
      "update!  Acc:  0.7592113768584356\n",
      "Eval Loss:  0.2633025646209717\n",
      "Eval Loss:  0.23789586126804352\n",
      "Eval Loss:  0.2676266133785248\n",
      "Eval Loss:  0.23500490188598633\n",
      "Eval Loss:  0.20884351432323456\n",
      "Eval Loss:  0.29982447624206543\n",
      "Eval Loss:  0.26316335797309875\n",
      "Eval Loss:  0.2790110409259796\n",
      "Eval Loss:  0.2263774275779724\n",
      "Eval Loss:  0.30599114298820496\n",
      "Eval Loss:  0.24570152163505554\n",
      "Eval Loss:  0.19806040823459625\n",
      "Eval Loss:  0.2572181224822998\n",
      "Eval Loss:  0.255179226398468\n",
      "Eval Loss:  0.2515576481819153\n",
      "Eval Loss:  0.2116115242242813\n",
      "Eval Loss:  0.21124736964702606\n",
      "Eval Loss:  0.1990460753440857\n",
      "Eval Loss:  0.27575111389160156\n",
      "Eval Loss:  0.20134283602237701\n",
      "Eval Loss:  0.2145344763994217\n",
      "Eval Loss:  0.18233339488506317\n",
      "Eval Loss:  0.2629731297492981\n",
      "Eval Loss:  0.41542428731918335\n",
      "Eval Loss:  0.2559727728366852\n",
      "Eval Loss:  0.23672997951507568\n",
      "Eval Loss:  0.2969500720500946\n",
      "Eval Loss:  0.2064237892627716\n",
      "Eval Loss:  0.18635228276252747\n",
      "[[17500  1234]\n",
      " [ 1682  9381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18734\n",
      "           1       0.88      0.85      0.87     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.89      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9021377991072926\n",
      "pre:  0.8837494112105511\n",
      "rec:  0.8479616740486305\n",
      "ma F1:  0.8942894496018658\n",
      "mi F1:  0.9021377991072926\n",
      "we F1:  0.9017047333875696\n",
      "29797 466\n",
      "Loss:  0.04986579343676567\n",
      "Loss:  0.07319577038288116\n",
      "Loss:  0.0933406874537468\n",
      "12 **********\n",
      "Epoch:  869.5170867443085  fold:  2  kers:  128\n",
      "epoch:  13\n",
      "29797 466\n",
      "Loss:  0.040553100407123566\n",
      "Loss:  0.08195794373750687\n",
      "Loss:  0.0582338385283947\n",
      "13 **********\n",
      "Epoch:  922.9083302021027  fold:  2  kers:  128\n",
      "epoch:  14\n",
      "29797 466\n",
      "Loss:  0.06655272096395493\n",
      "Loss:  0.04348643496632576\n",
      "Loss:  0.05092279985547066\n",
      "14 **********\n",
      "Epoch:  976.3723781108856  fold:  2  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.648792564868927\n",
      "Eval Loss:  0.08999147266149521\n",
      "Eval Loss:  0.6215109825134277\n",
      "[[1361   69]\n",
      " [ 853  811]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.95      0.75      1430\n",
      "           1       0.92      0.49      0.64      1664\n",
      "\n",
      "    accuracy                           0.70      3094\n",
      "   macro avg       0.77      0.72      0.69      3094\n",
      "weighted avg       0.78      0.70      0.69      3094\n",
      "\n",
      "acc:  0.7020038784744667\n",
      "pre:  0.9215909090909091\n",
      "rec:  0.4873798076923077\n",
      "ma F1:  0.6922799777699535\n",
      "mi F1:  0.7020038784744667\n",
      "we F1:  0.6881429000156697\n",
      "Eval Loss:  0.3258987367153168\n",
      "Eval Loss:  0.2666545808315277\n",
      "Eval Loss:  0.360154390335083\n",
      "Eval Loss:  0.27671483159065247\n",
      "Eval Loss:  0.24804265797138214\n",
      "Eval Loss:  0.3277319371700287\n",
      "Eval Loss:  0.2970505952835083\n",
      "Eval Loss:  0.26546284556388855\n",
      "Eval Loss:  0.2576737403869629\n",
      "Eval Loss:  0.4374684691429138\n",
      "Eval Loss:  0.3246007263660431\n",
      "Eval Loss:  0.21721115708351135\n",
      "Eval Loss:  0.3473604917526245\n",
      "Eval Loss:  0.30174344778060913\n",
      "Eval Loss:  0.21028007566928864\n",
      "Eval Loss:  0.34879475831985474\n",
      "Eval Loss:  0.29465654492378235\n",
      "Eval Loss:  0.270766943693161\n",
      "Eval Loss:  0.33392831683158875\n",
      "Eval Loss:  0.1453123688697815\n",
      "Eval Loss:  0.27696868777275085\n",
      "Eval Loss:  0.18829011917114258\n",
      "Eval Loss:  0.3118453919887543\n",
      "Eval Loss:  0.5415958166122437\n",
      "Eval Loss:  0.3152466416358948\n",
      "Eval Loss:  0.2207465022802353\n",
      "Eval Loss:  0.26928025484085083\n",
      "Eval Loss:  0.24899205565452576\n",
      "Eval Loss:  0.20640504360198975\n",
      "[[18239   495]\n",
      " [ 2966  8097]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     18734\n",
      "           1       0.94      0.73      0.82     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.90      0.85      0.87     29797\n",
      "weighted avg       0.89      0.88      0.88     29797\n",
      "\n",
      "acc:  0.8838473671846159\n",
      "pre:  0.9423882681564246\n",
      "rec:  0.7318991232034711\n",
      "ma F1:  0.8686276691517016\n",
      "mi F1:  0.8838473671846159\n",
      "we F1:  0.8801392352738162\n",
      "29797 466\n",
      "Loss:  0.07026718556880951\n",
      "Loss:  0.04447159916162491\n",
      "Loss:  0.06896089762449265\n",
      "15 **********\n",
      "Epoch:  1070.1207139492035  fold:  2  kers:  128\n",
      "epoch:  16\n",
      "29797 466\n",
      "Loss:  0.0456397719681263\n",
      "Loss:  0.038416117429733276\n",
      "Loss:  0.08278647065162659\n",
      "16 **********\n",
      "Epoch:  1123.515946149826  fold:  2  kers:  128\n",
      "epoch:  17\n",
      "29797 466\n",
      "Loss:  0.06981080025434494\n",
      "Loss:  0.047561708837747574\n",
      "Loss:  0.06346869468688965\n",
      "17 **********\n",
      "Epoch:  1177.015897989273  fold:  2  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.7627841234207153\n",
      "Eval Loss:  0.06932936608791351\n",
      "Eval Loss:  0.9454429745674133\n",
      "[[1357   73]\n",
      " [ 900  764]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.95      0.74      1430\n",
      "           1       0.91      0.46      0.61      1664\n",
      "\n",
      "    accuracy                           0.69      3094\n",
      "   macro avg       0.76      0.70      0.67      3094\n",
      "weighted avg       0.77      0.69      0.67      3094\n",
      "\n",
      "acc:  0.6855203619909502\n",
      "pre:  0.9127837514934289\n",
      "rec:  0.45913461538461536\n",
      "ma F1:  0.6735277139483237\n",
      "mi F1:  0.6855203619909502\n",
      "we F1:  0.6687953705385857\n",
      "Eval Loss:  0.3374365270137787\n",
      "Eval Loss:  0.26149818301200867\n",
      "Eval Loss:  0.36691558361053467\n",
      "Eval Loss:  0.2885260581970215\n",
      "Eval Loss:  0.2670527398586273\n",
      "Eval Loss:  0.3389526307582855\n",
      "Eval Loss:  0.32971516251564026\n",
      "Eval Loss:  0.25845399498939514\n",
      "Eval Loss:  0.26472803950309753\n",
      "Eval Loss:  0.45057040452957153\n",
      "Eval Loss:  0.33287298679351807\n",
      "Eval Loss:  0.2150864154100418\n",
      "Eval Loss:  0.34994935989379883\n",
      "Eval Loss:  0.31741568446159363\n",
      "Eval Loss:  0.21167446672916412\n",
      "Eval Loss:  0.3586046099662781\n",
      "Eval Loss:  0.30545395612716675\n",
      "Eval Loss:  0.2663048803806305\n",
      "Eval Loss:  0.32428327202796936\n",
      "Eval Loss:  0.16130666434764862\n",
      "Eval Loss:  0.273530513048172\n",
      "Eval Loss:  0.19476735591888428\n",
      "Eval Loss:  0.33786940574645996\n",
      "Eval Loss:  0.5503088235855103\n",
      "Eval Loss:  0.3163334131240845\n",
      "Eval Loss:  0.22168254852294922\n",
      "Eval Loss:  0.2504129409790039\n",
      "Eval Loss:  0.2510511875152588\n",
      "Eval Loss:  0.19779688119888306\n",
      "[[18341   393]\n",
      " [ 3196  7867]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91     18734\n",
      "           1       0.95      0.71      0.81     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.90      0.85      0.86     29797\n",
      "weighted avg       0.89      0.88      0.88     29797\n",
      "\n",
      "acc:  0.8795516327147028\n",
      "pre:  0.9524213075060532\n",
      "rec:  0.7111091024134503\n",
      "ma F1:  0.8625707958940956\n",
      "mi F1:  0.8795516327147028\n",
      "we F1:  0.8750073052745498\n",
      "29797 466\n",
      "Loss:  0.05155584216117859\n",
      "Loss:  0.07662828266620636\n",
      "Loss:  0.08029024302959442\n",
      "18 **********\n",
      "Epoch:  1272.105647802353  fold:  2  kers:  128\n",
      "epoch:  19\n",
      "29797 466\n",
      "Loss:  0.044088102877140045\n",
      "Loss:  0.054826367646455765\n",
      "Loss:  0.06813528388738632\n",
      "19 **********\n",
      "Epoch:  1325.7611830234528  fold:  2  kers:  128\n",
      "epoch:  20\n",
      "29797 466\n",
      "Loss:  0.057391196489334106\n",
      "Loss:  0.06942939758300781\n",
      "Loss:  0.04621925204992294\n",
      "20 **********\n",
      "Epoch:  1379.2362022399902  fold:  2  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.48920097947120667\n",
      "Eval Loss:  0.18893305957317352\n",
      "Eval Loss:  0.5091958045959473\n",
      "[[1281  149]\n",
      " [ 618 1046]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      1430\n",
      "           1       0.88      0.63      0.73      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.77      0.76      0.75      3094\n",
      "weighted avg       0.78      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7521008403361344\n",
      "pre:  0.8753138075313808\n",
      "rec:  0.6286057692307693\n",
      "ma F1:  0.7506624298891813\n",
      "mi F1:  0.7521008403361344\n",
      "we F1:  0.749230140337747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.25060856342315674\n",
      "Eval Loss:  0.2016974538564682\n",
      "Eval Loss:  0.22967927157878876\n",
      "Eval Loss:  0.19271236658096313\n",
      "Eval Loss:  0.19843879342079163\n",
      "Eval Loss:  0.23942255973815918\n",
      "Eval Loss:  0.2466888129711151\n",
      "Eval Loss:  0.2147296518087387\n",
      "Eval Loss:  0.1907063126564026\n",
      "Eval Loss:  0.25244051218032837\n",
      "Eval Loss:  0.21055516600608826\n",
      "Eval Loss:  0.15550753474235535\n",
      "Eval Loss:  0.24885748326778412\n",
      "Eval Loss:  0.225590780377388\n",
      "Eval Loss:  0.17205306887626648\n",
      "Eval Loss:  0.2389092594385147\n",
      "Eval Loss:  0.17187367379665375\n",
      "Eval Loss:  0.1852681040763855\n",
      "Eval Loss:  0.2420567274093628\n",
      "Eval Loss:  0.14186640083789825\n",
      "Eval Loss:  0.20030924677848816\n",
      "Eval Loss:  0.15748851001262665\n",
      "Eval Loss:  0.254974365234375\n",
      "Eval Loss:  0.4332365393638611\n",
      "Eval Loss:  0.237501859664917\n",
      "Eval Loss:  0.20794661343097687\n",
      "Eval Loss:  0.22330082952976227\n",
      "Eval Loss:  0.17971886694431305\n",
      "Eval Loss:  0.15254926681518555\n",
      "[[17839   895]\n",
      " [ 1687  9376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18734\n",
      "           1       0.91      0.85      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9133469812397221\n",
      "pre:  0.9128614545808588\n",
      "rec:  0.8475097170749345\n",
      "ma F1:  0.9057434537175417\n",
      "mi F1:  0.9133469812397221\n",
      "we F1:  0.9126354139707198\n",
      "29797 466\n",
      "Loss:  0.0521073043346405\n",
      "Loss:  0.062016718089580536\n",
      "Loss:  0.06311514228582382\n",
      "21 **********\n",
      "Epoch:  1473.0553481578827  fold:  2  kers:  128\n",
      "epoch:  22\n",
      "29797 466\n",
      "Loss:  0.05834745243191719\n",
      "Loss:  0.0732450783252716\n",
      "Loss:  0.07302486151456833\n",
      "22 **********\n",
      "Epoch:  1526.51740193367  fold:  2  kers:  128\n",
      "epoch:  23\n",
      "29797 466\n",
      "Loss:  0.05344069004058838\n",
      "Loss:  0.04496079683303833\n",
      "Loss:  0.046108826994895935\n",
      "23 **********\n",
      "Epoch:  1579.9375672340393  fold:  2  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.508354902267456\n",
      "Eval Loss:  0.36938726902008057\n",
      "Eval Loss:  0.45370912551879883\n",
      "[[1205  225]\n",
      " [ 501 1163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      1430\n",
      "           1       0.84      0.70      0.76      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.77      0.77      0.77      3094\n",
      "weighted avg       0.78      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7653522947640594\n",
      "pre:  0.8378962536023055\n",
      "rec:  0.6989182692307693\n",
      "ma F1:  0.7653090479310991\n",
      "mi F1:  0.7653522947640594\n",
      "we F1:  0.7650681012903197\n",
      "update!  Acc:  0.7653522947640594\n",
      "Eval Loss:  0.22788721323013306\n",
      "Eval Loss:  0.1719895899295807\n",
      "Eval Loss:  0.20177575945854187\n",
      "Eval Loss:  0.19487999379634857\n",
      "Eval Loss:  0.19812820851802826\n",
      "Eval Loss:  0.21230243146419525\n",
      "Eval Loss:  0.19913709163665771\n",
      "Eval Loss:  0.23179827630519867\n",
      "Eval Loss:  0.1582222729921341\n",
      "Eval Loss:  0.21390414237976074\n",
      "Eval Loss:  0.19451355934143066\n",
      "Eval Loss:  0.13046959042549133\n",
      "Eval Loss:  0.22519280016422272\n",
      "Eval Loss:  0.23018860816955566\n",
      "Eval Loss:  0.19114068150520325\n",
      "Eval Loss:  0.1869184970855713\n",
      "Eval Loss:  0.14327660202980042\n",
      "Eval Loss:  0.14104889333248138\n",
      "Eval Loss:  0.20999278128147125\n",
      "Eval Loss:  0.17454388737678528\n",
      "Eval Loss:  0.1923617720603943\n",
      "Eval Loss:  0.1670704334974289\n",
      "Eval Loss:  0.23160873353481293\n",
      "Eval Loss:  0.3667154312133789\n",
      "Eval Loss:  0.21274785697460175\n",
      "Eval Loss:  0.1754172444343567\n",
      "Eval Loss:  0.24356329441070557\n",
      "Eval Loss:  0.15757359564304352\n",
      "Eval Loss:  0.158186674118042\n",
      "[[17571  1163]\n",
      " [ 1209  9854]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18734\n",
      "           1       0.89      0.89      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.91      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9203946706044233\n",
      "pre:  0.8944358718344377\n",
      "rec:  0.8907168037602821\n",
      "ma F1:  0.9146713680998708\n",
      "mi F1:  0.9203946706044233\n",
      "we F1:  0.9203605547672833\n",
      "29797 466\n",
      "Loss:  0.051270563155412674\n",
      "Loss:  0.04135388508439064\n",
      "Loss:  0.060344576835632324\n",
      "24 **********\n",
      "Epoch:  1673.8275244235992  fold:  2  kers:  128\n",
      "epoch:  25\n",
      "29797 466\n",
      "Loss:  0.058861300349235535\n",
      "Loss:  0.062286872416734695\n",
      "Loss:  0.0595850795507431\n",
      "25 **********\n",
      "Epoch:  1727.368367433548  fold:  2  kers:  128\n",
      "epoch:  26\n",
      "29797 466\n",
      "Loss:  0.05617757514119148\n",
      "Loss:  0.06459824740886688\n",
      "Loss:  0.060454998165369034\n",
      "26 **********\n",
      "Epoch:  1780.7995030879974  fold:  2  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.532518744468689\n",
      "Eval Loss:  0.4680461287498474\n",
      "Eval Loss:  0.7540360689163208\n",
      "[[1167  263]\n",
      " [ 508 1156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75      1430\n",
      "           1       0.81      0.69      0.75      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.76      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7508080155138979\n",
      "pre:  0.8146582100070472\n",
      "rec:  0.6947115384615384\n",
      "ma F1:  0.7508048657042438\n",
      "mi F1:  0.7508080155138979\n",
      "we F1:  0.7507378606625115\n",
      "Eval Loss:  0.2305028885602951\n",
      "Eval Loss:  0.164024218916893\n",
      "Eval Loss:  0.1873287409543991\n",
      "Eval Loss:  0.18483106791973114\n",
      "Eval Loss:  0.1822028011083603\n",
      "Eval Loss:  0.20510445535182953\n",
      "Eval Loss:  0.2029094249010086\n",
      "Eval Loss:  0.2661001980304718\n",
      "Eval Loss:  0.1807861030101776\n",
      "Eval Loss:  0.21238839626312256\n",
      "Eval Loss:  0.20704111456871033\n",
      "Eval Loss:  0.11599033325910568\n",
      "Eval Loss:  0.23901404440402985\n",
      "Eval Loss:  0.23921744525432587\n",
      "Eval Loss:  0.19986915588378906\n",
      "Eval Loss:  0.1875954121351242\n",
      "Eval Loss:  0.1328362226486206\n",
      "Eval Loss:  0.14517192542552948\n",
      "Eval Loss:  0.20719359815120697\n",
      "Eval Loss:  0.17597436904907227\n",
      "Eval Loss:  0.1838321089744568\n",
      "Eval Loss:  0.17451921105384827\n",
      "Eval Loss:  0.23739059269428253\n",
      "Eval Loss:  0.34013521671295166\n",
      "Eval Loss:  0.21757158637046814\n",
      "Eval Loss:  0.1372217983007431\n",
      "Eval Loss:  0.24647031724452972\n",
      "Eval Loss:  0.16213129460811615\n",
      "Eval Loss:  0.1655052900314331\n",
      "[[17522  1212]\n",
      " [ 1192  9871]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18734\n",
      "           1       0.89      0.89      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.91      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9193207369869449\n",
      "pre:  0.8906433276188758\n",
      "rec:  0.8922534574708487\n",
      "ma F1:  0.9136259904049399\n",
      "mi F1:  0.9193207369869449\n",
      "we F1:  0.9193356232673842\n",
      "29797 466\n",
      "Loss:  0.07187207043170929\n",
      "Loss:  0.08038130402565002\n",
      "Loss:  0.0577738955616951\n",
      "27 **********\n",
      "Epoch:  1874.6974391937256  fold:  2  kers:  128\n",
      "epoch:  28\n",
      "29797 466\n",
      "Loss:  0.054665423929691315\n",
      "Loss:  0.03252694010734558\n",
      "Loss:  0.04906601086258888\n",
      "28 **********\n",
      "Epoch:  1928.071727514267  fold:  2  kers:  128\n",
      "epoch:  29\n",
      "29797 466\n",
      "Loss:  0.04004690423607826\n",
      "Loss:  0.07999495416879654\n",
      "Loss:  0.05065245181322098\n",
      "29 **********\n",
      "Epoch:  1981.4190874099731  fold:  2  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.5686053037643433\n",
      "Eval Loss:  0.32912445068359375\n",
      "Eval Loss:  0.2915003001689911\n",
      "[[1184  246]\n",
      " [ 427 1237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78      1430\n",
      "           1       0.83      0.74      0.79      1664\n",
      "\n",
      "    accuracy                           0.78      3094\n",
      "   macro avg       0.78      0.79      0.78      3094\n",
      "weighted avg       0.79      0.78      0.78      3094\n",
      "\n",
      "acc:  0.7824822236586942\n",
      "pre:  0.8341200269723533\n",
      "rec:  0.7433894230769231\n",
      "ma F1:  0.7824183777119961\n",
      "mi F1:  0.7824822236586942\n",
      "we F1:  0.7827002635898713\n",
      "update!  Acc:  0.7824822236586942\n",
      "Eval Loss:  0.22354260087013245\n",
      "Eval Loss:  0.15495681762695312\n",
      "Eval Loss:  0.16855663061141968\n",
      "Eval Loss:  0.1640220731496811\n",
      "Eval Loss:  0.18133001029491425\n",
      "Eval Loss:  0.1802026480436325\n",
      "Eval Loss:  0.18339930474758148\n",
      "Eval Loss:  0.1966305524110794\n",
      "Eval Loss:  0.14175722002983093\n",
      "Eval Loss:  0.18379555642604828\n",
      "Eval Loss:  0.18764571845531464\n",
      "Eval Loss:  0.11858886480331421\n",
      "Eval Loss:  0.2066795378923416\n",
      "Eval Loss:  0.1940821260213852\n",
      "Eval Loss:  0.1765982210636139\n",
      "Eval Loss:  0.17296987771987915\n",
      "Eval Loss:  0.09921734780073166\n",
      "Eval Loss:  0.15081071853637695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20274825394153595\n",
      "Eval Loss:  0.1876317858695984\n",
      "Eval Loss:  0.1975715458393097\n",
      "Eval Loss:  0.15987563133239746\n",
      "Eval Loss:  0.24509495496749878\n",
      "Eval Loss:  0.3253837823867798\n",
      "Eval Loss:  0.186287522315979\n",
      "Eval Loss:  0.18124116957187653\n",
      "Eval Loss:  0.24499143660068512\n",
      "Eval Loss:  0.15648910403251648\n",
      "Eval Loss:  0.16340696811676025\n",
      "[[17497  1237]\n",
      " [  981 10082]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18734\n",
      "           1       0.89      0.91      0.90     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.92      0.92      0.92     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9255629761385374\n",
      "pre:  0.8907147274494214\n",
      "rec:  0.9113260417608243\n",
      "ma F1:  0.9206490411336876\n",
      "mi F1:  0.9255629761385374\n",
      "we F1:  0.9257326278393119\n",
      "29797 466\n",
      "Loss:  0.059593312442302704\n",
      "Loss:  0.044047463685274124\n",
      "Loss:  0.05152008682489395\n",
      "30 **********\n",
      "Epoch:  2075.4337112903595  fold:  2  kers:  128\n",
      "epoch:  31\n",
      "29797 466\n",
      "Loss:  0.0653129369020462\n",
      "Loss:  0.09161091595888138\n",
      "Loss:  0.06254752725362778\n",
      "31 **********\n",
      "Epoch:  2128.9276793003082  fold:  2  kers:  128\n",
      "epoch:  32\n",
      "29797 466\n",
      "Loss:  0.027239210903644562\n",
      "Loss:  0.07327763736248016\n",
      "Loss:  0.05504101514816284\n",
      "32 **********\n",
      "Epoch:  2182.4705169200897  fold:  2  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.5838486552238464\n",
      "Eval Loss:  0.1561899483203888\n",
      "Eval Loss:  0.6965614557266235\n",
      "[[1276  154]\n",
      " [ 625 1039]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.77      1430\n",
      "           1       0.87      0.62      0.73      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.77      0.76      0.75      3094\n",
      "weighted avg       0.78      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7482223658694247\n",
      "pre:  0.8709136630343671\n",
      "rec:  0.6243990384615384\n",
      "ma F1:  0.7467363311125628\n",
      "mi F1:  0.7482223658694247\n",
      "we F1:  0.7452691069222435\n",
      "Eval Loss:  0.21363522112369537\n",
      "Eval Loss:  0.17912383377552032\n",
      "Eval Loss:  0.20216681063175201\n",
      "Eval Loss:  0.18084770441055298\n",
      "Eval Loss:  0.1503290832042694\n",
      "Eval Loss:  0.19081993401050568\n",
      "Eval Loss:  0.20332428812980652\n",
      "Eval Loss:  0.17859382927417755\n",
      "Eval Loss:  0.1254820078611374\n",
      "Eval Loss:  0.21856102347373962\n",
      "Eval Loss:  0.18271149694919586\n",
      "Eval Loss:  0.13822254538536072\n",
      "Eval Loss:  0.24027565121650696\n",
      "Eval Loss:  0.2242276966571808\n",
      "Eval Loss:  0.1550930142402649\n",
      "Eval Loss:  0.16899436712265015\n",
      "Eval Loss:  0.130879744887352\n",
      "Eval Loss:  0.13586948812007904\n",
      "Eval Loss:  0.19505949318408966\n",
      "Eval Loss:  0.11174214631319046\n",
      "Eval Loss:  0.20453794300556183\n",
      "Eval Loss:  0.1442689746618271\n",
      "Eval Loss:  0.2361132800579071\n",
      "Eval Loss:  0.3242371082305908\n",
      "Eval Loss:  0.18310853838920593\n",
      "Eval Loss:  0.12955321371555328\n",
      "Eval Loss:  0.25782909989356995\n",
      "Eval Loss:  0.1489640176296234\n",
      "Eval Loss:  0.15145350992679596\n",
      "[[18034   700]\n",
      " [ 1539  9524]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18734\n",
      "           1       0.93      0.86      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.93      0.91      0.92     29797\n",
      "weighted avg       0.93      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9248582072020674\n",
      "pre:  0.9315336463223787\n",
      "rec:  0.8608876434963392\n",
      "ma F1:  0.9181847931583739\n",
      "mi F1:  0.9248582072020674\n",
      "we F1:  0.924200276017266\n",
      "29797 466\n",
      "Loss:  0.04199152812361717\n",
      "Loss:  0.06618298590183258\n",
      "Loss:  0.084275022149086\n",
      "33 **********\n",
      "Epoch:  2276.2946503162384  fold:  2  kers:  128\n",
      "epoch:  34\n",
      "29797 466\n",
      "Loss:  0.07741789519786835\n",
      "Loss:  0.042480167001485825\n",
      "Loss:  0.023701399564743042\n",
      "34 **********\n",
      "Epoch:  2329.7846286296844  fold:  2  kers:  128\n",
      "epoch:  35\n",
      "29797 466\n",
      "Loss:  0.05491168051958084\n",
      "Loss:  0.0441025048494339\n",
      "Loss:  0.043604373931884766\n",
      "35 **********\n",
      "Epoch:  2383.1898336410522  fold:  2  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.5944761037826538\n",
      "Eval Loss:  0.38062208890914917\n",
      "Eval Loss:  0.5619882345199585\n",
      "[[1200  230]\n",
      " [ 533 1131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1430\n",
      "           1       0.83      0.68      0.75      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.77      0.75      0.75      3094\n",
      "\n",
      "acc:  0.753393665158371\n",
      "pre:  0.8310066127847171\n",
      "rec:  0.6796875\n",
      "ma F1:  0.7532709557565131\n",
      "mi F1:  0.753393665158371\n",
      "we F1:  0.7528548108284735\n",
      "Eval Loss:  0.18479199707508087\n",
      "Eval Loss:  0.1650153249502182\n",
      "Eval Loss:  0.1858968585729599\n",
      "Eval Loss:  0.17676600813865662\n",
      "Eval Loss:  0.17949795722961426\n",
      "Eval Loss:  0.20388402044773102\n",
      "Eval Loss:  0.1805090308189392\n",
      "Eval Loss:  0.22870327532291412\n",
      "Eval Loss:  0.1546017825603485\n",
      "Eval Loss:  0.20994481444358826\n",
      "Eval Loss:  0.199446439743042\n",
      "Eval Loss:  0.09832949936389923\n",
      "Eval Loss:  0.20833958685398102\n",
      "Eval Loss:  0.23026320338249207\n",
      "Eval Loss:  0.16026240587234497\n",
      "Eval Loss:  0.15540814399719238\n",
      "Eval Loss:  0.11575989425182343\n",
      "Eval Loss:  0.14150309562683105\n",
      "Eval Loss:  0.1831253170967102\n",
      "Eval Loss:  0.1510278433561325\n",
      "Eval Loss:  0.17300549149513245\n",
      "Eval Loss:  0.15051893889904022\n",
      "Eval Loss:  0.22473041713237762\n",
      "Eval Loss:  0.3019770681858063\n",
      "Eval Loss:  0.17883029580116272\n",
      "Eval Loss:  0.12798716127872467\n",
      "Eval Loss:  0.2566819190979004\n",
      "Eval Loss:  0.132376030087471\n",
      "Eval Loss:  0.14924147725105286\n",
      "[[17766   968]\n",
      " [ 1272  9791]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18734\n",
      "           1       0.91      0.89      0.90     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.92      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9248246467765211\n",
      "pre:  0.9100288130867181\n",
      "rec:  0.8850221458917111\n",
      "ma F1:  0.9190240546550265\n",
      "mi F1:  0.9248246467765211\n",
      "we F1:  0.9246035332962785\n",
      "29797 466\n",
      "Loss:  0.07244525849819183\n",
      "Loss:  0.03264697268605232\n",
      "Loss:  0.05635793134570122\n",
      "36 **********\n",
      "Epoch:  2477.1037266254425  fold:  2  kers:  128\n",
      "epoch:  37\n",
      "29797 466\n",
      "Loss:  0.09534306079149246\n",
      "Loss:  0.0492589995265007\n",
      "Loss:  0.037827443331480026\n",
      "37 **********\n",
      "Epoch:  2530.601684331894  fold:  2  kers:  128\n",
      "epoch:  38\n",
      "29797 466\n",
      "Loss:  0.07649704068899155\n",
      "Loss:  0.052867550402879715\n",
      "Loss:  0.03748801350593567\n",
      "38 **********\n",
      "Epoch:  2584.117593765259  fold:  2  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.5291159152984619\n",
      "Eval Loss:  0.25146469473838806\n",
      "Eval Loss:  0.48207637667655945\n",
      "[[1227  203]\n",
      " [ 538 1126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77      1430\n",
      "           1       0.85      0.68      0.75      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.77      0.76      3094\n",
      "weighted avg       0.78      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7605042016806722\n",
      "pre:  0.8472535741158767\n",
      "rec:  0.6766826923076923\n",
      "ma F1:  0.7602487180573136\n",
      "mi F1:  0.7605042016806722\n",
      "we F1:  0.7596568055041858\n",
      "Eval Loss:  0.18509268760681152\n",
      "Eval Loss:  0.16337554156780243\n",
      "Eval Loss:  0.1707185059785843\n",
      "Eval Loss:  0.15565724670886993\n",
      "Eval Loss:  0.17313124239444733\n",
      "Eval Loss:  0.18300902843475342\n",
      "Eval Loss:  0.16712258756160736\n",
      "Eval Loss:  0.18501920998096466\n",
      "Eval Loss:  0.13301967084407806\n",
      "Eval Loss:  0.18850257992744446\n",
      "Eval Loss:  0.18604715168476105\n",
      "Eval Loss:  0.10096506029367447\n",
      "Eval Loss:  0.2033606469631195\n",
      "Eval Loss:  0.19989827275276184\n",
      "Eval Loss:  0.13367459177970886\n",
      "Eval Loss:  0.1356014460325241\n",
      "Eval Loss:  0.09457012265920639\n",
      "Eval Loss:  0.1396067589521408\n",
      "Eval Loss:  0.17147573828697205\n",
      "Eval Loss:  0.14443089067935944\n",
      "Eval Loss:  0.17517921328544617\n",
      "Eval Loss:  0.12200605869293213\n",
      "Eval Loss:  0.21193204820156097\n",
      "Eval Loss:  0.3133874237537384\n",
      "Eval Loss:  0.16926901042461395\n",
      "Eval Loss:  0.13083940744400024\n",
      "Eval Loss:  0.21615757048130035\n",
      "Eval Loss:  0.13219840824604034\n",
      "Eval Loss:  0.1458664983510971\n",
      "[[17827   907]\n",
      " [ 1158  9905]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18734\n",
      "           1       0.92      0.90      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.92      0.93     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9306977212471054\n",
      "pre:  0.9161117277099519\n",
      "rec:  0.8953267648919823\n",
      "ma F1:  0.925426527744638\n",
      "mi F1:  0.9306977212471054\n",
      "we F1:  0.9305307091833438\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.03670603781938553\n",
      "Loss:  0.0472576767206192\n",
      "Loss:  0.02544613927602768\n",
      "39 **********\n",
      "Epoch:  2678.137204647064  fold:  2  kers:  128\n",
      "epoch:  40\n",
      "29797 466\n",
      "Loss:  0.05139566957950592\n",
      "Loss:  0.046836890280246735\n",
      "Loss:  0.0689789354801178\n",
      "40 **********\n",
      "Epoch:  2731.61621260643  fold:  2  kers:  128\n",
      "epoch:  41\n",
      "29797 466\n",
      "Loss:  0.06945061683654785\n",
      "Loss:  0.05804010480642319\n",
      "Loss:  0.03951002657413483\n",
      "41 **********\n",
      "Epoch:  2785.2129056453705  fold:  2  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.7849262356758118\n",
      "Eval Loss:  0.12733913958072662\n",
      "Eval Loss:  0.9274497032165527\n",
      "[[1264  166]\n",
      " [ 700  964]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74      1430\n",
      "           1       0.85      0.58      0.69      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.75      0.73      0.72      3094\n",
      "weighted avg       0.76      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7201034259857789\n",
      "pre:  0.8530973451327434\n",
      "rec:  0.5793269230769231\n",
      "ma F1:  0.7174469747235954\n",
      "mi F1:  0.7201034259857788\n",
      "we F1:  0.7153749427390922\n",
      "Eval Loss:  0.19837738573551178\n",
      "Eval Loss:  0.1863732784986496\n",
      "Eval Loss:  0.17971009016036987\n",
      "Eval Loss:  0.15634587407112122\n",
      "Eval Loss:  0.1459474414587021\n",
      "Eval Loss:  0.18004751205444336\n",
      "Eval Loss:  0.20101520419120789\n",
      "Eval Loss:  0.14763088524341583\n",
      "Eval Loss:  0.12810584902763367\n",
      "Eval Loss:  0.20199401676654816\n",
      "Eval Loss:  0.19524835050106049\n",
      "Eval Loss:  0.13830339908599854\n",
      "Eval Loss:  0.24437664449214935\n",
      "Eval Loss:  0.2392563670873642\n",
      "Eval Loss:  0.15198683738708496\n",
      "Eval Loss:  0.13157500326633453\n",
      "Eval Loss:  0.10644792020320892\n",
      "Eval Loss:  0.16220687329769135\n",
      "Eval Loss:  0.16522300243377686\n",
      "Eval Loss:  0.10260811448097229\n",
      "Eval Loss:  0.17605677247047424\n",
      "Eval Loss:  0.12969781458377838\n",
      "Eval Loss:  0.22270040214061737\n",
      "Eval Loss:  0.3386074900627136\n",
      "Eval Loss:  0.1630454957485199\n",
      "Eval Loss:  0.11489952355623245\n",
      "Eval Loss:  0.24458327889442444\n",
      "Eval Loss:  0.13590405881404877\n",
      "Eval Loss:  0.15004873275756836\n",
      "[[18022   712]\n",
      " [ 1409  9654]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     18734\n",
      "           1       0.93      0.87      0.90     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.92      0.92     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9288183374165184\n",
      "pre:  0.9313139108624349\n",
      "rec:  0.8726385248124379\n",
      "ma F1:  0.9227237501627538\n",
      "mi F1:  0.9288183374165184\n",
      "we F1:  0.9283106979189235\n",
      "29797 466\n",
      "Loss:  0.06422339379787445\n",
      "Loss:  0.0381896011531353\n",
      "Loss:  0.04354047030210495\n",
      "42 **********\n",
      "Epoch:  2879.1766657829285  fold:  2  kers:  128\n",
      "epoch:  43\n",
      "29797 466\n",
      "Loss:  0.04289337992668152\n",
      "Loss:  0.033719517290592194\n",
      "Loss:  0.06022385135293007\n",
      "43 **********\n",
      "Epoch:  2932.5938391685486  fold:  2  kers:  128\n",
      "epoch:  44\n",
      "29797 466\n",
      "Loss:  0.04624716192483902\n",
      "Loss:  0.0337381511926651\n",
      "Loss:  0.036465201526880264\n",
      "44 **********\n",
      "Epoch:  2986.278297662735  fold:  2  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.47686031460762024\n",
      "Eval Loss:  0.3894121050834656\n",
      "Eval Loss:  0.3446613848209381\n",
      "[[1082  348]\n",
      " [ 414 1250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      1430\n",
      "           1       0.78      0.75      0.77      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.75      0.75      0.75      3094\n",
      "weighted avg       0.75      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7537168713639302\n",
      "pre:  0.7822277847309136\n",
      "rec:  0.7512019230769231\n",
      "ma F1:  0.7529885971268397\n",
      "mi F1:  0.7537168713639302\n",
      "we F1:  0.7540029790999301\n",
      "Eval Loss:  0.1897365152835846\n",
      "Eval Loss:  0.13909931480884552\n",
      "Eval Loss:  0.16123747825622559\n",
      "Eval Loss:  0.160652756690979\n",
      "Eval Loss:  0.14595873653888702\n",
      "Eval Loss:  0.16772320866584778\n",
      "Eval Loss:  0.16624858975410461\n",
      "Eval Loss:  0.20815011858940125\n",
      "Eval Loss:  0.14510899782180786\n",
      "Eval Loss:  0.16696323454380035\n",
      "Eval Loss:  0.17769867181777954\n",
      "Eval Loss:  0.09019280225038528\n",
      "Eval Loss:  0.1768544465303421\n",
      "Eval Loss:  0.23208217322826385\n",
      "Eval Loss:  0.15199212729930878\n",
      "Eval Loss:  0.1442517638206482\n",
      "Eval Loss:  0.10422409325838089\n",
      "Eval Loss:  0.13590805232524872\n",
      "Eval Loss:  0.16797780990600586\n",
      "Eval Loss:  0.1439388543367386\n",
      "Eval Loss:  0.19190038740634918\n",
      "Eval Loss:  0.15981441736221313\n",
      "Eval Loss:  0.20273102819919586\n",
      "Eval Loss:  0.30052924156188965\n",
      "Eval Loss:  0.17151154577732086\n",
      "Eval Loss:  0.14848817884922028\n",
      "Eval Loss:  0.2154880315065384\n",
      "Eval Loss:  0.14295560121536255\n",
      "Eval Loss:  0.15520378947257996\n",
      "[[17617  1117]\n",
      " [  914 10149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     18734\n",
      "           1       0.90      0.92      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.93      0.93     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9318387757156761\n",
      "pre:  0.9008521214273034\n",
      "rec:  0.9173822652083522\n",
      "ma F1:  0.9272702549664132\n",
      "mi F1:  0.9318387757156761\n",
      "we F1:  0.9319629601977463\n",
      "29797 466\n",
      "Loss:  0.06530238687992096\n",
      "Loss:  0.06407228112220764\n",
      "Loss:  0.07927936315536499\n",
      "45 **********\n",
      "Epoch:  3080.4066178798676  fold:  2  kers:  128\n",
      "epoch:  46\n",
      "29797 466\n",
      "Loss:  0.032944537699222565\n",
      "Loss:  0.04062081500887871\n",
      "Loss:  0.049879223108291626\n",
      "46 **********\n",
      "Epoch:  3133.9065701961517  fold:  2  kers:  128\n",
      "epoch:  47\n",
      "29797 466\n",
      "Loss:  0.06725846230983734\n",
      "Loss:  0.035882480442523956\n",
      "Loss:  0.07635196298360825\n",
      "47 **********\n",
      "Epoch:  3187.464367866516  fold:  2  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.5773257613182068\n",
      "Eval Loss:  0.17619237303733826\n",
      "Eval Loss:  1.0180909633636475\n",
      "[[1260  170]\n",
      " [ 617 1047]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76      1430\n",
      "           1       0.86      0.63      0.73      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.77      0.76      0.74      3094\n",
      "weighted avg       0.77      0.75      0.74      3094\n",
      "\n",
      "acc:  0.7456367162249515\n",
      "pre:  0.8603122432210353\n",
      "rec:  0.6292067307692307\n",
      "ma F1:  0.7444254595686346\n",
      "mi F1:  0.7456367162249515\n",
      "we F1:  0.7430947832419765\n",
      "Eval Loss:  0.187992662191391\n",
      "Eval Loss:  0.1632869988679886\n",
      "Eval Loss:  0.16211161017417908\n",
      "Eval Loss:  0.1335737109184265\n",
      "Eval Loss:  0.12439263612031937\n",
      "Eval Loss:  0.16243623197078705\n",
      "Eval Loss:  0.18301767110824585\n",
      "Eval Loss:  0.16113683581352234\n",
      "Eval Loss:  0.10666512697935104\n",
      "Eval Loss:  0.1626160442829132\n",
      "Eval Loss:  0.18141412734985352\n",
      "Eval Loss:  0.105540432035923\n",
      "Eval Loss:  0.2063142955303192\n",
      "Eval Loss:  0.22897537052631378\n",
      "Eval Loss:  0.13237208127975464\n",
      "Eval Loss:  0.1569845974445343\n",
      "Eval Loss:  0.09297440201044083\n",
      "Eval Loss:  0.14771175384521484\n",
      "Eval Loss:  0.15221571922302246\n",
      "Eval Loss:  0.11528328061103821\n",
      "Eval Loss:  0.16412952542304993\n",
      "Eval Loss:  0.11487723886966705\n",
      "Eval Loss:  0.20441089570522308\n",
      "Eval Loss:  0.27380087971687317\n",
      "Eval Loss:  0.15667562186717987\n",
      "Eval Loss:  0.11266237497329712\n",
      "Eval Loss:  0.1965438276529312\n",
      "Eval Loss:  0.13296206295490265\n",
      "Eval Loss:  0.1351335048675537\n",
      "[[17936   798]\n",
      " [ 1151  9912]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     18734\n",
      "           1       0.93      0.90      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.93      0.93     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9345907306104642\n",
      "pre:  0.9254901960784314\n",
      "rec:  0.8959595046551568\n",
      "ma F1:  0.9294766230482705\n",
      "mi F1:  0.9345907306104642\n",
      "we F1:  0.9343657455694054\n",
      "29797 466\n",
      "Loss:  0.04609311372041702\n",
      "Loss:  0.05307098105549812\n",
      "Loss:  0.049176931381225586\n",
      "48 **********\n",
      "Epoch:  3287.312394142151  fold:  2  kers:  128\n",
      "epoch:  49\n",
      "29797 466\n",
      "Loss:  0.09871015697717667\n",
      "Loss:  0.040450725704431534\n",
      "Loss:  0.06383799761533737\n",
      "49 **********\n",
      "Epoch:  3341.0197916030884  fold:  2  kers:  128\n",
      "epoch:  50\n",
      "29797 466\n",
      "Loss:  0.05275615304708481\n",
      "Loss:  0.06423294544219971\n",
      "Loss:  0.02147545851767063\n",
      "50 **********\n",
      "Epoch:  3394.518745660782  fold:  2  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.5290790796279907\n",
      "Eval Loss:  0.4117680788040161\n",
      "Eval Loss:  0.7742919325828552\n",
      "[[1129  301]\n",
      " [ 541 1123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73      1430\n",
      "           1       0.79      0.67      0.73      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.73      0.73      0.73      3094\n",
      "weighted avg       0.74      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7278603749191984\n",
      "pre:  0.788623595505618\n",
      "rec:  0.6748798076923077\n",
      "ma F1:  0.7278593514959051\n",
      "mi F1:  0.7278603749191984\n",
      "we F1:  0.727819437987463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17230401933193207\n",
      "Eval Loss:  0.14507557451725006\n",
      "Eval Loss:  0.1552383303642273\n",
      "Eval Loss:  0.15543590486049652\n",
      "Eval Loss:  0.14155875146389008\n",
      "Eval Loss:  0.17472349107265472\n",
      "Eval Loss:  0.1621190905570984\n",
      "Eval Loss:  0.19019748270511627\n",
      "Eval Loss:  0.12890376150608063\n",
      "Eval Loss:  0.1665622591972351\n",
      "Eval Loss:  0.1762482225894928\n",
      "Eval Loss:  0.08476921170949936\n",
      "Eval Loss:  0.18397590517997742\n",
      "Eval Loss:  0.23148709535598755\n",
      "Eval Loss:  0.13212443888187408\n",
      "Eval Loss:  0.15150411427021027\n",
      "Eval Loss:  0.08053964376449585\n",
      "Eval Loss:  0.129822239279747\n",
      "Eval Loss:  0.1641382873058319\n",
      "Eval Loss:  0.13347123563289642\n",
      "Eval Loss:  0.171014666557312\n",
      "Eval Loss:  0.11259748041629791\n",
      "Eval Loss:  0.20733985304832458\n",
      "Eval Loss:  0.2753883898258209\n",
      "Eval Loss:  0.15705180168151855\n",
      "Eval Loss:  0.11648215353488922\n",
      "Eval Loss:  0.21739962697029114\n",
      "Eval Loss:  0.13563323020935059\n",
      "Eval Loss:  0.12478692084550858\n",
      "[[17878   856]\n",
      " [ 1065  9998]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18734\n",
      "           1       0.92      0.90      0.91     11063\n",
      "\n",
      "    accuracy                           0.94     29797\n",
      "   macro avg       0.93      0.93      0.93     29797\n",
      "weighted avg       0.94      0.94      0.94     29797\n",
      "\n",
      "acc:  0.9355304225257576\n",
      "pre:  0.9211350654136724\n",
      "rec:  0.9037331646027298\n",
      "ma F1:  0.9306825651308055\n",
      "mi F1:  0.9355304225257576\n",
      "we F1:  0.935401843566932\n",
      "29797 466\n",
      "Loss:  0.07099562883377075\n",
      "Loss:  0.05079622566699982\n",
      "Loss:  0.05358046293258667\n",
      "51 **********\n",
      "Epoch:  3492.6433801651  fold:  2  kers:  128\n",
      "epoch:  52\n",
      "29797 466\n",
      "Loss:  0.04845600575208664\n",
      "Loss:  0.0368882492184639\n",
      "Loss:  0.0705278143286705\n",
      "52 **********\n",
      "Epoch:  3546.1084263324738  fold:  2  kers:  128\n",
      "epoch:  53\n",
      "29797 466\n",
      "Loss:  0.0495181567966938\n",
      "Loss:  0.017396122217178345\n",
      "Loss:  0.027068035677075386\n",
      "53 **********\n",
      "Epoch:  3599.749999523163  fold:  2  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.5431663990020752\n",
      "Eval Loss:  0.22434675693511963\n",
      "Eval Loss:  1.00723135471344\n",
      "[[1238  192]\n",
      " [ 606 1058]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76      1430\n",
      "           1       0.85      0.64      0.73      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.76      0.75      0.74      3094\n",
      "weighted avg       0.77      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7420814479638009\n",
      "pre:  0.8464\n",
      "rec:  0.6358173076923077\n",
      "ma F1:  0.741205538195529\n",
      "mi F1:  0.7420814479638009\n",
      "we F1:  0.7400668554967755\n",
      "Eval Loss:  0.17468790709972382\n",
      "Eval Loss:  0.1534750908613205\n",
      "Eval Loss:  0.14125971496105194\n",
      "Eval Loss:  0.13737013936042786\n",
      "Eval Loss:  0.12995965778827667\n",
      "Eval Loss:  0.15080541372299194\n",
      "Eval Loss:  0.16449584066867828\n",
      "Eval Loss:  0.14057517051696777\n",
      "Eval Loss:  0.104963019490242\n",
      "Eval Loss:  0.18622705340385437\n",
      "Eval Loss:  0.1848151683807373\n",
      "Eval Loss:  0.10700882226228714\n",
      "Eval Loss:  0.1833147257566452\n",
      "Eval Loss:  0.21942780911922455\n",
      "Eval Loss:  0.13673703372478485\n",
      "Eval Loss:  0.13940897583961487\n",
      "Eval Loss:  0.08725104480981827\n",
      "Eval Loss:  0.15443682670593262\n",
      "Eval Loss:  0.14998425543308258\n",
      "Eval Loss:  0.11891569942235947\n",
      "Eval Loss:  0.15844617784023285\n",
      "Eval Loss:  0.1189645528793335\n",
      "Eval Loss:  0.20833705365657806\n",
      "Eval Loss:  0.25362730026245117\n",
      "Eval Loss:  0.1622258871793747\n",
      "Eval Loss:  0.11602523177862167\n",
      "Eval Loss:  0.19540059566497803\n",
      "Eval Loss:  0.12517620623111725\n",
      "Eval Loss:  0.13937346637248993\n",
      "[[18006   728]\n",
      " [ 1185  9878]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     18734\n",
      "           1       0.93      0.89      0.91     11063\n",
      "\n",
      "    accuracy                           0.94     29797\n",
      "   macro avg       0.93      0.93      0.93     29797\n",
      "weighted avg       0.94      0.94      0.94     29797\n",
      "\n",
      "acc:  0.9357989059301272\n",
      "pre:  0.9313596077691872\n",
      "rec:  0.8928861972340233\n",
      "ma F1:  0.9306377692564096\n",
      "mi F1:  0.9357989059301272\n",
      "we F1:  0.9355087189887039\n",
      "29797 466\n",
      "Loss:  0.038676828145980835\n",
      "Loss:  0.02697983756661415\n",
      "Loss:  0.059027884155511856\n",
      "54 **********\n",
      "Epoch:  3693.599066257477  fold:  2  kers:  128\n",
      "epoch:  55\n",
      "29797 466\n",
      "Loss:  0.041694920510053635\n",
      "Loss:  0.05700402706861496\n",
      "Loss:  0.04069705307483673\n",
      "55 **********\n",
      "Epoch:  3747.0371832847595  fold:  2  kers:  128\n",
      "epoch:  56\n",
      "29797 466\n",
      "Loss:  0.03567831590771675\n",
      "Loss:  0.05906578153371811\n",
      "Loss:  0.023785803467035294\n",
      "56 **********\n",
      "Epoch:  3800.4723086357117  fold:  2  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.4538097083568573\n",
      "Eval Loss:  0.3256630003452301\n",
      "Eval Loss:  0.5113410353660583\n",
      "[[1054  376]\n",
      " [ 448 1216]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      1430\n",
      "           1       0.76      0.73      0.75      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.73      0.73      0.73      3094\n",
      "weighted avg       0.74      0.73      0.73      3094\n",
      "\n",
      "acc:  0.733678086619263\n",
      "pre:  0.7638190954773869\n",
      "rec:  0.7307692307692307\n",
      "ma F1:  0.7329459560018905\n",
      "mi F1:  0.7336780866192631\n",
      "we F1:  0.7340034780047618\n",
      "Eval Loss:  0.1924080103635788\n",
      "Eval Loss:  0.14719124138355255\n",
      "Eval Loss:  0.14689207077026367\n",
      "Eval Loss:  0.12279915064573288\n",
      "Eval Loss:  0.18017736077308655\n",
      "Eval Loss:  0.18117262423038483\n",
      "Eval Loss:  0.1621989756822586\n",
      "Eval Loss:  0.21878619492053986\n",
      "Eval Loss:  0.12388550490140915\n",
      "Eval Loss:  0.17051488161087036\n",
      "Eval Loss:  0.19173800945281982\n",
      "Eval Loss:  0.08501491695642471\n",
      "Eval Loss:  0.17093627154827118\n",
      "Eval Loss:  0.181941956281662\n",
      "Eval Loss:  0.1418469250202179\n",
      "Eval Loss:  0.12609723210334778\n",
      "Eval Loss:  0.08008679002523422\n",
      "Eval Loss:  0.1428743600845337\n",
      "Eval Loss:  0.18655042350292206\n",
      "Eval Loss:  0.15636198222637177\n",
      "Eval Loss:  0.14172330498695374\n",
      "Eval Loss:  0.12803569436073303\n",
      "Eval Loss:  0.17982850968837738\n",
      "Eval Loss:  0.23038633167743683\n",
      "Eval Loss:  0.15261362493038177\n",
      "Eval Loss:  0.11760323494672775\n",
      "Eval Loss:  0.1959855556488037\n",
      "Eval Loss:  0.12660501897335052\n",
      "Eval Loss:  0.14819830656051636\n",
      "[[17637  1097]\n",
      " [  873 10190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     18734\n",
      "           1       0.90      0.92      0.91     11063\n",
      "\n",
      "    accuracy                           0.93     29797\n",
      "   macro avg       0.93      0.93      0.93     29797\n",
      "weighted avg       0.93      0.93      0.93     29797\n",
      "\n",
      "acc:  0.9338859616739941\n",
      "pre:  0.9028085407991495\n",
      "rec:  0.9210883123926602\n",
      "ma F1:  0.9294811986592078\n",
      "mi F1:  0.9338859616739941\n",
      "we F1:  0.9340184535385452\n",
      "29797 466\n",
      "Loss:  0.029529590159654617\n",
      "Loss:  0.03366030007600784\n",
      "Loss:  0.026787884533405304\n",
      "57 **********\n",
      "Epoch:  3894.5427832603455  fold:  2  kers:  128\n",
      "epoch:  58\n",
      "29797 466\n",
      "Loss:  0.04261752963066101\n",
      "Loss:  0.047396283596754074\n",
      "Loss:  0.03972512483596802\n",
      "58 **********\n",
      "Epoch:  3948.1115510463715  fold:  2  kers:  128\n",
      "epoch:  59\n",
      "29797 466\n",
      "Loss:  0.04215015470981598\n",
      "Loss:  0.02939610555768013\n",
      "Loss:  0.05766348913311958\n",
      "59 **********\n",
      "Epoch:  4001.61349773407  fold:  2  kers:  128\n",
      "Eval Loss:  0.5239021182060242\n",
      "Eval Loss:  0.48170793056488037\n",
      "Eval Loss:  0.8037987947463989\n",
      "[[1038  392]\n",
      " [ 463 1201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      1430\n",
      "           1       0.75      0.72      0.74      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.72      0.72      0.72      3094\n",
      "weighted avg       0.73      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7236586942469295\n",
      "pre:  0.7539234149403641\n",
      "rec:  0.7217548076923077\n",
      "ma F1:  0.7228895860549469\n",
      "mi F1:  0.7236586942469295\n",
      "we F1:  0.7239937045636827\n",
      "update!  Acc:  0.7824822236586942\n",
      "Epoch:  4005.4402661323547  fold:  2  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.16601401567459106\n",
      "Loss:  0.16001424193382263\n",
      "Loss:  0.1590544879436493\n",
      "0 **********\n",
      "Epoch:  65.25452327728271  fold:  3  kers:  128\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.1514359414577484\n",
      "Loss:  0.1318374127149582\n",
      "Loss:  0.12387124449014664\n",
      "1 **********\n",
      "Epoch:  118.32262992858887  fold:  3  kers:  128\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.12379796802997589\n",
      "Loss:  0.10251650214195251\n",
      "Loss:  0.08616722375154495\n",
      "2 **********\n",
      "Epoch:  171.32391500473022  fold:  3  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  1.1286873817443848\n",
      "Eval Loss:  1.0486525297164917\n",
      "Eval Loss:  0.4210711419582367\n",
      "[[1427  109]\n",
      " [ 819 1076]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.75      1536\n",
      "           1       0.91      0.57      0.70      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.77      0.75      0.73      3431\n",
      "weighted avg       0.79      0.73      0.72      3431\n",
      "\n",
      "acc:  0.7295249198484407\n",
      "pre:  0.9080168776371308\n",
      "rec:  0.5678100263852243\n",
      "ma F1:  0.7266642400434045\n",
      "mi F1:  0.7295249198484407\n",
      "we F1:  0.7237383595590513\n",
      "update!  Acc:  0.7295249198484407\n",
      "Eval Loss:  0.42347434163093567\n",
      "Eval Loss:  0.6991659998893738\n",
      "Eval Loss:  0.2952994406223297\n",
      "Eval Loss:  0.37974292039871216\n",
      "Eval Loss:  0.44931578636169434\n",
      "Eval Loss:  0.3930121064186096\n",
      "Eval Loss:  0.5644305944442749\n",
      "Eval Loss:  0.46421554684638977\n",
      "Eval Loss:  0.41222578287124634\n",
      "Eval Loss:  0.4695541560649872\n",
      "Eval Loss:  0.42691823840141296\n",
      "Eval Loss:  0.4911169707775116\n",
      "Eval Loss:  0.4998933672904968\n",
      "Eval Loss:  0.3338196575641632\n",
      "Eval Loss:  0.39450207352638245\n",
      "Eval Loss:  0.3876815736293793\n",
      "Eval Loss:  0.38435444235801697\n",
      "Eval Loss:  0.4362010061740875\n",
      "Eval Loss:  0.43339014053344727\n",
      "Eval Loss:  0.4607981741428375\n",
      "Eval Loss:  0.397169291973114\n",
      "Eval Loss:  0.4587791860103607\n",
      "Eval Loss:  0.5026915073394775\n",
      "Eval Loss:  0.3249782621860504\n",
      "Eval Loss:  0.40566742420196533\n",
      "Eval Loss:  0.4232947528362274\n",
      "Eval Loss:  0.4921899735927582\n",
      "Eval Loss:  0.48267000913619995\n",
      "[[17416  1212]\n",
      " [ 4041  6791]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87     18628\n",
      "           1       0.85      0.63      0.72     10832\n",
      "\n",
      "    accuracy                           0.82     29460\n",
      "   macro avg       0.83      0.78      0.80     29460\n",
      "weighted avg       0.83      0.82      0.81     29460\n",
      "\n",
      "acc:  0.8216904276985744\n",
      "pre:  0.8485567912032987\n",
      "rec:  0.6269387001477105\n",
      "ma F1:  0.7950289004593669\n",
      "mi F1:  0.8216904276985744\n",
      "we F1:  0.8145915608223656\n",
      "29460 461\n",
      "Loss:  0.096920445561409\n",
      "Loss:  0.09093102812767029\n",
      "Loss:  0.13477729260921478\n",
      "3 **********\n",
      "Epoch:  264.95356845855713  fold:  3  kers:  128\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.09903555363416672\n",
      "Loss:  0.08293519914150238\n",
      "Loss:  0.08433213829994202\n",
      "4 **********\n",
      "Epoch:  317.93291211128235  fold:  3  kers:  128\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.07452695816755295\n",
      "Loss:  0.0909731462597847\n",
      "Loss:  0.10319171100854874\n",
      "5 **********\n",
      "Epoch:  370.9082667827606  fold:  3  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  1.1276100873947144\n",
      "Eval Loss:  0.6798478364944458\n",
      "Eval Loss:  0.6524536609649658\n",
      "[[1438   98]\n",
      " [ 775 1120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.94      0.77      1536\n",
      "           1       0.92      0.59      0.72      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.76      0.74      3431\n",
      "weighted avg       0.80      0.75      0.74      3431\n",
      "\n",
      "acc:  0.7455552317108715\n",
      "pre:  0.9195402298850575\n",
      "rec:  0.5910290237467019\n",
      "ma F1:  0.7433505129154476\n",
      "mi F1:  0.7455552317108716\n",
      "we F1:  0.7408615379231295\n",
      "update!  Acc:  0.7455552317108715\n",
      "Eval Loss:  0.44914478063583374\n",
      "Eval Loss:  0.7046627402305603\n",
      "Eval Loss:  0.23767909407615662\n",
      "Eval Loss:  0.3518425226211548\n",
      "Eval Loss:  0.3939908742904663\n",
      "Eval Loss:  0.36690375208854675\n",
      "Eval Loss:  0.580488920211792\n",
      "Eval Loss:  0.43557074666023254\n",
      "Eval Loss:  0.38493314385414124\n",
      "Eval Loss:  0.4305066168308258\n",
      "Eval Loss:  0.3745799958705902\n",
      "Eval Loss:  0.456495463848114\n",
      "Eval Loss:  0.5133094787597656\n",
      "Eval Loss:  0.31787028908729553\n",
      "Eval Loss:  0.3916565179824829\n",
      "Eval Loss:  0.3621786832809448\n",
      "Eval Loss:  0.3543378412723541\n",
      "Eval Loss:  0.37842175364494324\n",
      "Eval Loss:  0.44343358278274536\n",
      "Eval Loss:  0.4676828980445862\n",
      "Eval Loss:  0.36706826090812683\n",
      "Eval Loss:  0.45298677682876587\n",
      "Eval Loss:  0.5282188057899475\n",
      "Eval Loss:  0.2751650810241699\n",
      "Eval Loss:  0.38556039333343506\n",
      "Eval Loss:  0.43115606904029846\n",
      "Eval Loss:  0.5116912722587585\n",
      "Eval Loss:  0.4839564561843872\n",
      "[[18078   550]\n",
      " [ 4147  6685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89     18628\n",
      "           1       0.92      0.62      0.74     10832\n",
      "\n",
      "    accuracy                           0.84     29460\n",
      "   macro avg       0.87      0.79      0.81     29460\n",
      "weighted avg       0.85      0.84      0.83     29460\n",
      "\n",
      "acc:  0.8405634758995247\n",
      "pre:  0.9239806496199032\n",
      "rec:  0.6171528803545052\n",
      "ma F1:  0.8125250251103471\n",
      "mi F1:  0.8405634758995247\n",
      "we F1:  0.8317111711958759\n",
      "29460 461\n",
      "Loss:  0.09024704247713089\n",
      "Loss:  0.08276142179965973\n",
      "Loss:  0.08145227283239365\n",
      "6 **********\n",
      "Epoch:  464.5139846801758  fold:  3  kers:  128\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.07493632286787033\n",
      "Loss:  0.07202272862195969\n",
      "Loss:  0.08326467871665955\n",
      "7 **********\n",
      "Epoch:  517.4993124008179  fold:  3  kers:  128\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.06242397800087929\n",
      "Loss:  0.07120806723833084\n",
      "Loss:  0.09979274123907089\n",
      "8 **********\n",
      "Epoch:  570.4996027946472  fold:  3  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.9474730491638184\n",
      "Eval Loss:  0.3211767375469208\n",
      "Eval Loss:  0.7495182156562805\n",
      "[[1381  155]\n",
      " [ 703 1192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      1536\n",
      "           1       0.88      0.63      0.74      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.76      0.75      3431\n",
      "weighted avg       0.79      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7499271349460799\n",
      "pre:  0.8849294729027468\n",
      "rec:  0.629023746701847\n",
      "ma F1:  0.7491659878459855\n",
      "mi F1:  0.7499271349460799\n",
      "we F1:  0.7477202110791397\n",
      "update!  Acc:  0.7499271349460799\n",
      "Eval Loss:  0.41397449374198914\n",
      "Eval Loss:  0.5646806955337524\n",
      "Eval Loss:  0.20175334811210632\n",
      "Eval Loss:  0.3222961723804474\n",
      "Eval Loss:  0.2945070266723633\n",
      "Eval Loss:  0.33096906542778015\n",
      "Eval Loss:  0.5280726552009583\n",
      "Eval Loss:  0.40321776270866394\n",
      "Eval Loss:  0.32270920276641846\n",
      "Eval Loss:  0.40858614444732666\n",
      "Eval Loss:  0.36481374502182007\n",
      "Eval Loss:  0.4265487492084503\n",
      "Eval Loss:  0.5022179484367371\n",
      "Eval Loss:  0.29232698678970337\n",
      "Eval Loss:  0.3490608334541321\n",
      "Eval Loss:  0.3148285746574402\n",
      "Eval Loss:  0.3290119171142578\n",
      "Eval Loss:  0.28985804319381714\n",
      "Eval Loss:  0.39543822407722473\n",
      "Eval Loss:  0.4060021936893463\n",
      "Eval Loss:  0.2993800938129425\n",
      "Eval Loss:  0.4071090817451477\n",
      "Eval Loss:  0.4664175808429718\n",
      "Eval Loss:  0.26143014430999756\n",
      "Eval Loss:  0.3362938463687897\n",
      "Eval Loss:  0.38606029748916626\n",
      "Eval Loss:  0.458615779876709\n",
      "Eval Loss:  0.3990193009376526\n",
      "[[18145   483]\n",
      " [ 3755  7077]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     18628\n",
      "           1       0.94      0.65      0.77     10832\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.88      0.81      0.83     29460\n",
      "weighted avg       0.87      0.86      0.85     29460\n",
      "\n",
      "acc:  0.8561439239646979\n",
      "pre:  0.9361111111111111\n",
      "rec:  0.6533419497784343\n",
      "ma F1:  0.8325020237433086\n",
      "mi F1:  0.8561439239646979\n",
      "we F1:  0.8491547391504237\n",
      "29460 461\n",
      "Loss:  0.07570590823888779\n",
      "Loss:  0.07726733386516571\n",
      "Loss:  0.060113757848739624\n",
      "9 **********\n",
      "Epoch:  664.2000646591187  fold:  3  kers:  128\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.06409505009651184\n",
      "Loss:  0.06598677486181259\n",
      "Loss:  0.09444626420736313\n",
      "10 **********\n",
      "Epoch:  717.297093629837  fold:  3  kers:  128\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06357401609420776\n",
      "Loss:  0.08626914769411087\n",
      "Loss:  0.07891053706407547\n",
      "11 **********\n",
      "Epoch:  770.4390029907227  fold:  3  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.9779435396194458\n",
      "Eval Loss:  0.2308444082736969\n",
      "Eval Loss:  0.7136959433555603\n",
      "[[1341  195]\n",
      " [ 681 1214]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.75      1536\n",
      "           1       0.86      0.64      0.73      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.76      0.76      0.74      3431\n",
      "weighted avg       0.77      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7446808510638298\n",
      "pre:  0.8616039744499645\n",
      "rec:  0.6406332453825857\n",
      "ma F1:  0.7443305472644941\n",
      "mi F1:  0.7446808510638298\n",
      "we F1:  0.7433403184144037\n",
      "Eval Loss:  0.40816113352775574\n",
      "Eval Loss:  0.5023683309555054\n",
      "Eval Loss:  0.19881227612495422\n",
      "Eval Loss:  0.2814231812953949\n",
      "Eval Loss:  0.2552594542503357\n",
      "Eval Loss:  0.31406694650650024\n",
      "Eval Loss:  0.4124833345413208\n",
      "Eval Loss:  0.3550564646720886\n",
      "Eval Loss:  0.2715689539909363\n",
      "Eval Loss:  0.39051878452301025\n",
      "Eval Loss:  0.32391852140426636\n",
      "Eval Loss:  0.3719908893108368\n",
      "Eval Loss:  0.4480936527252197\n",
      "Eval Loss:  0.259237676858902\n",
      "Eval Loss:  0.3044309914112091\n",
      "Eval Loss:  0.3013620972633362\n",
      "Eval Loss:  0.27316030859947205\n",
      "Eval Loss:  0.2505500018596649\n",
      "Eval Loss:  0.3399522304534912\n",
      "Eval Loss:  0.3628217577934265\n",
      "Eval Loss:  0.2734924852848053\n",
      "Eval Loss:  0.3770061433315277\n",
      "Eval Loss:  0.4167223572731018\n",
      "Eval Loss:  0.2156980037689209\n",
      "Eval Loss:  0.2883640229701996\n",
      "Eval Loss:  0.2840104103088379\n",
      "Eval Loss:  0.40819287300109863\n",
      "Eval Loss:  0.3648015558719635\n",
      "[[18095   533]\n",
      " [ 3254  7578]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91     18628\n",
      "           1       0.93      0.70      0.80     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.89      0.84      0.85     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8714528173794976\n",
      "pre:  0.9342867710516582\n",
      "rec:  0.6995937961595273\n",
      "ma F1:  0.8526774972365696\n",
      "mi F1:  0.8714528173794976\n",
      "we F1:  0.8665951920006911\n",
      "29460 461\n",
      "Loss:  0.08243169635534286\n",
      "Loss:  0.08404611796140671\n",
      "Loss:  0.06035346910357475\n",
      "12 **********\n",
      "Epoch:  864.1594135761261  fold:  3  kers:  128\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.05855664610862732\n",
      "Loss:  0.05788392201066017\n",
      "Loss:  0.09357642382383347\n",
      "13 **********\n",
      "Epoch:  917.2225337028503  fold:  3  kers:  128\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.08452682197093964\n",
      "Loss:  0.08807157725095749\n",
      "Loss:  0.07524917274713516\n",
      "14 **********\n",
      "Epoch:  970.2846574783325  fold:  3  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.8037238121032715\n",
      "Eval Loss:  0.24947303533554077\n",
      "Eval Loss:  0.8798454999923706\n",
      "[[1345  191]\n",
      " [ 673 1222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76      1536\n",
      "           1       0.86      0.64      0.74      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.76      0.75      3431\n",
      "weighted avg       0.78      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7481783736519965\n",
      "pre:  0.86482661004954\n",
      "rec:  0.6448548812664908\n",
      "ma F1:  0.7478543174609872\n",
      "mi F1:  0.7481783736519965\n",
      "we F1:  0.7469084949197484\n",
      "Eval Loss:  0.39602839946746826\n",
      "Eval Loss:  0.4728512763977051\n",
      "Eval Loss:  0.1701117753982544\n",
      "Eval Loss:  0.2600199580192566\n",
      "Eval Loss:  0.2430257350206375\n",
      "Eval Loss:  0.2765747606754303\n",
      "Eval Loss:  0.3666500449180603\n",
      "Eval Loss:  0.34805828332901\n",
      "Eval Loss:  0.22912265360355377\n",
      "Eval Loss:  0.38746970891952515\n",
      "Eval Loss:  0.3052942752838135\n",
      "Eval Loss:  0.36977583169937134\n",
      "Eval Loss:  0.42032748460769653\n",
      "Eval Loss:  0.23260284960269928\n",
      "Eval Loss:  0.28643399477005005\n",
      "Eval Loss:  0.2669106721878052\n",
      "Eval Loss:  0.28315046429634094\n",
      "Eval Loss:  0.25318941473960876\n",
      "Eval Loss:  0.32917970418930054\n",
      "Eval Loss:  0.3760383427143097\n",
      "Eval Loss:  0.2484661489725113\n",
      "Eval Loss:  0.3649672269821167\n",
      "Eval Loss:  0.41474801301956177\n",
      "Eval Loss:  0.2271658182144165\n",
      "Eval Loss:  0.2654082477092743\n",
      "Eval Loss:  0.2641739249229431\n",
      "Eval Loss:  0.38630130887031555\n",
      "Eval Loss:  0.3577004075050354\n",
      "[[18154   474]\n",
      " [ 3075  7757]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     18628\n",
      "           1       0.94      0.72      0.81     10832\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.90      0.85      0.86     29460\n",
      "weighted avg       0.89      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8795315682281059\n",
      "pre:  0.9424128295468351\n",
      "rec:  0.7161189069423929\n",
      "ma F1:  0.8623922520598086\n",
      "mi F1:  0.8795315682281057\n",
      "we F1:  0.8752438543343153\n",
      "29460 461\n",
      "Loss:  0.08331859111785889\n",
      "Loss:  0.04072580859065056\n",
      "Loss:  0.08820941299200058\n",
      "15 **********\n",
      "Epoch:  1063.7567312717438  fold:  3  kers:  128\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.0827881470322609\n",
      "Loss:  0.08781737834215164\n",
      "Loss:  0.05969758331775665\n",
      "16 **********\n",
      "Epoch:  1116.6552906036377  fold:  3  kers:  128\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.05279219523072243\n",
      "Loss:  0.04734935611486435\n",
      "Loss:  0.05254928767681122\n",
      "17 **********\n",
      "Epoch:  1169.5378937721252  fold:  3  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.49083659052848816\n",
      "Eval Loss:  0.11756669729948044\n",
      "Eval Loss:  0.822083592414856\n",
      "[[1233  303]\n",
      " [ 570 1325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74      1536\n",
      "           1       0.81      0.70      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7455552317108715\n",
      "pre:  0.8138820638820639\n",
      "rec:  0.6992084432717678\n",
      "ma F1:  0.7453721520420677\n",
      "mi F1:  0.7455552317108716\n",
      "we F1:  0.7460865607496822\n",
      "Eval Loss:  0.2691054344177246\n",
      "Eval Loss:  0.29399389028549194\n",
      "Eval Loss:  0.1695229858160019\n",
      "Eval Loss:  0.17583811283111572\n",
      "Eval Loss:  0.19470947980880737\n",
      "Eval Loss:  0.20254775881767273\n",
      "Eval Loss:  0.23488152027130127\n",
      "Eval Loss:  0.28001201152801514\n",
      "Eval Loss:  0.2148561030626297\n",
      "Eval Loss:  0.22558344900608063\n",
      "Eval Loss:  0.285655677318573\n",
      "Eval Loss:  0.2466927170753479\n",
      "Eval Loss:  0.3421544134616852\n",
      "Eval Loss:  0.1670416295528412\n",
      "Eval Loss:  0.20950275659561157\n",
      "Eval Loss:  0.2054615318775177\n",
      "Eval Loss:  0.1937076598405838\n",
      "Eval Loss:  0.1974673569202423\n",
      "Eval Loss:  0.20162498950958252\n",
      "Eval Loss:  0.2555670440196991\n",
      "Eval Loss:  0.17243140935897827\n",
      "Eval Loss:  0.2708549499511719\n",
      "Eval Loss:  0.3177679777145386\n",
      "Eval Loss:  0.15505890548229218\n",
      "Eval Loss:  0.24266624450683594\n",
      "Eval Loss:  0.23129670321941376\n",
      "Eval Loss:  0.2804928719997406\n",
      "Eval Loss:  0.25463762879371643\n",
      "[[17498  1130]\n",
      " [ 1510  9322]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18628\n",
      "           1       0.89      0.86      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9103869653767821\n",
      "pre:  0.8918867202449292\n",
      "rec:  0.8605982274741507\n",
      "ma F1:  0.9029087797735472\n",
      "mi F1:  0.9103869653767822\n",
      "we F1:  0.9100393980419936\n",
      "29460 461\n",
      "Loss:  0.06982722878456116\n",
      "Loss:  0.05500303953886032\n",
      "Loss:  0.06130213290452957\n",
      "18 **********\n",
      "Epoch:  1262.9351680278778  fold:  3  kers:  128\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.04711037501692772\n",
      "Loss:  0.07466985285282135\n",
      "Loss:  0.05889035016298294\n",
      "19 **********\n",
      "Epoch:  1315.860656261444  fold:  3  kers:  128\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.06457389891147614\n",
      "Loss:  0.06436879187822342\n",
      "Loss:  0.05673670023679733\n",
      "20 **********\n",
      "Epoch:  1368.7582185268402  fold:  3  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.6162922978401184\n",
      "Eval Loss:  0.12531384825706482\n",
      "Eval Loss:  0.7933151125907898\n",
      "[[1264  272]\n",
      " [ 647 1248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.82      0.73      1536\n",
      "           1       0.82      0.66      0.73      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.74      0.74      0.73      3431\n",
      "weighted avg       0.75      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7321480617895657\n",
      "pre:  0.8210526315789474\n",
      "rec:  0.6585751978891821\n",
      "ma F1:  0.7321422366978563\n",
      "mi F1:  0.7321480617895657\n",
      "we F1:  0.732011536202628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2804911136627197\n",
      "Eval Loss:  0.2966570258140564\n",
      "Eval Loss:  0.17565970122814178\n",
      "Eval Loss:  0.18756279349327087\n",
      "Eval Loss:  0.20250387489795685\n",
      "Eval Loss:  0.19323280453681946\n",
      "Eval Loss:  0.24328644573688507\n",
      "Eval Loss:  0.2631164789199829\n",
      "Eval Loss:  0.21100157499313354\n",
      "Eval Loss:  0.23083782196044922\n",
      "Eval Loss:  0.2858407199382782\n",
      "Eval Loss:  0.25196439027786255\n",
      "Eval Loss:  0.3412070870399475\n",
      "Eval Loss:  0.16287876665592194\n",
      "Eval Loss:  0.2040044665336609\n",
      "Eval Loss:  0.19678761065006256\n",
      "Eval Loss:  0.1904139369726181\n",
      "Eval Loss:  0.18747906386852264\n",
      "Eval Loss:  0.2207174003124237\n",
      "Eval Loss:  0.26129236817359924\n",
      "Eval Loss:  0.1708858162164688\n",
      "Eval Loss:  0.2976900637149811\n",
      "Eval Loss:  0.30521610379219055\n",
      "Eval Loss:  0.14171361923217773\n",
      "Eval Loss:  0.24892088770866394\n",
      "Eval Loss:  0.22435565292835236\n",
      "Eval Loss:  0.2869516611099243\n",
      "Eval Loss:  0.23263880610466003\n",
      "[[17698   930]\n",
      " [ 1666  9166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.91      0.85      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9118805159538357\n",
      "pre:  0.9078843106180665\n",
      "rec:  0.8461964549483013\n",
      "ma F1:  0.9038127413593592\n",
      "mi F1:  0.9118805159538357\n",
      "we F1:  0.9111845616522026\n",
      "29460 461\n",
      "Loss:  0.0683431327342987\n",
      "Loss:  0.07266675680875778\n",
      "Loss:  0.0930953323841095\n",
      "21 **********\n",
      "Epoch:  1462.2083523273468  fold:  3  kers:  128\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.06801382452249527\n",
      "Loss:  0.03756247088313103\n",
      "Loss:  0.07919670641422272\n",
      "22 **********\n",
      "Epoch:  1515.1188805103302  fold:  3  kers:  128\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.044971905648708344\n",
      "Loss:  0.07942565530538559\n",
      "Loss:  0.053821876645088196\n",
      "23 **********\n",
      "Epoch:  1568.0234246253967  fold:  3  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.5363564491271973\n",
      "Eval Loss:  0.10025817900896072\n",
      "Eval Loss:  0.7251042723655701\n",
      "[[1257  279]\n",
      " [ 594 1301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74      1536\n",
      "           1       0.82      0.69      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7455552317108715\n",
      "pre:  0.8234177215189873\n",
      "rec:  0.6865435356200528\n",
      "ma F1:  0.745513378491184\n",
      "mi F1:  0.7455552317108716\n",
      "we F1:  0.7458548627154521\n",
      "Eval Loss:  0.25507616996765137\n",
      "Eval Loss:  0.274971604347229\n",
      "Eval Loss:  0.1712656021118164\n",
      "Eval Loss:  0.1658250093460083\n",
      "Eval Loss:  0.193832665681839\n",
      "Eval Loss:  0.1754366010427475\n",
      "Eval Loss:  0.22688888013362885\n",
      "Eval Loss:  0.27136293053627014\n",
      "Eval Loss:  0.20252925157546997\n",
      "Eval Loss:  0.19483698904514313\n",
      "Eval Loss:  0.2610015571117401\n",
      "Eval Loss:  0.22336627542972565\n",
      "Eval Loss:  0.31763896346092224\n",
      "Eval Loss:  0.13587522506713867\n",
      "Eval Loss:  0.2106696516275406\n",
      "Eval Loss:  0.20212361216545105\n",
      "Eval Loss:  0.17945431172847748\n",
      "Eval Loss:  0.17805247008800507\n",
      "Eval Loss:  0.19612695276737213\n",
      "Eval Loss:  0.2426072061061859\n",
      "Eval Loss:  0.15526871383190155\n",
      "Eval Loss:  0.2817842364311218\n",
      "Eval Loss:  0.2763288617134094\n",
      "Eval Loss:  0.13587041199207306\n",
      "Eval Loss:  0.21835219860076904\n",
      "Eval Loss:  0.23530782759189606\n",
      "Eval Loss:  0.25372904539108276\n",
      "Eval Loss:  0.2354510873556137\n",
      "[[17639   989]\n",
      " [ 1426  9406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.90      0.87      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9180244399185336\n",
      "pre:  0.9048581048581048\n",
      "rec:  0.8683530280649926\n",
      "ma F1:  0.9110797749484008\n",
      "mi F1:  0.9180244399185336\n",
      "we F1:  0.9176558235463791\n",
      "29460 461\n",
      "Loss:  0.0478973463177681\n",
      "Loss:  0.05950590968132019\n",
      "Loss:  0.045583873987197876\n",
      "24 **********\n",
      "Epoch:  1661.5792751312256  fold:  3  kers:  128\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.08092819154262543\n",
      "Loss:  0.06207377836108208\n",
      "Loss:  0.05833807587623596\n",
      "25 **********\n",
      "Epoch:  1714.5835518836975  fold:  3  kers:  128\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.05756738409399986\n",
      "Loss:  0.03972049802541733\n",
      "Loss:  0.04578106105327606\n",
      "26 **********\n",
      "Epoch:  1767.6037864685059  fold:  3  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.6741024255752563\n",
      "Eval Loss:  0.17422477900981903\n",
      "Eval Loss:  0.7965126633644104\n",
      "[[1297  239]\n",
      " [ 633 1262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.75      1536\n",
      "           1       0.84      0.67      0.74      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.77      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7458466919265521\n",
      "pre:  0.8407728181212525\n",
      "rec:  0.6659630606860159\n",
      "ma F1:  0.7458202413212109\n",
      "mi F1:  0.7458466919265521\n",
      "we F1:  0.7455489336835687\n",
      "Eval Loss:  0.27582868933677673\n",
      "Eval Loss:  0.2900589406490326\n",
      "Eval Loss:  0.17639341950416565\n",
      "Eval Loss:  0.16157308220863342\n",
      "Eval Loss:  0.17974285781383514\n",
      "Eval Loss:  0.18943442404270172\n",
      "Eval Loss:  0.25181376934051514\n",
      "Eval Loss:  0.23115459084510803\n",
      "Eval Loss:  0.18601572513580322\n",
      "Eval Loss:  0.23450887203216553\n",
      "Eval Loss:  0.2610040307044983\n",
      "Eval Loss:  0.26080378890037537\n",
      "Eval Loss:  0.3153580129146576\n",
      "Eval Loss:  0.15032029151916504\n",
      "Eval Loss:  0.19792920351028442\n",
      "Eval Loss:  0.193696528673172\n",
      "Eval Loss:  0.18350714445114136\n",
      "Eval Loss:  0.19818922877311707\n",
      "Eval Loss:  0.2065562903881073\n",
      "Eval Loss:  0.24249312281608582\n",
      "Eval Loss:  0.16595008969306946\n",
      "Eval Loss:  0.28596094250679016\n",
      "Eval Loss:  0.2846532166004181\n",
      "Eval Loss:  0.14220231771469116\n",
      "Eval Loss:  0.2027221918106079\n",
      "Eval Loss:  0.20821654796600342\n",
      "Eval Loss:  0.27003493905067444\n",
      "Eval Loss:  0.24522654712200165\n",
      "[[17845   783]\n",
      " [ 1668  9164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     18628\n",
      "           1       0.92      0.85      0.88     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.90      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9168024439918534\n",
      "pre:  0.9212827988338192\n",
      "rec:  0.8460118168389956\n",
      "ma F1:  0.9088914079576808\n",
      "mi F1:  0.9168024439918534\n",
      "we F1:  0.9159959393391355\n",
      "29460 461\n",
      "Loss:  0.02343830280005932\n",
      "Loss:  0.06699731200933456\n",
      "Loss:  0.059139102697372437\n",
      "27 **********\n",
      "Epoch:  1860.9940803050995  fold:  3  kers:  128\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.07179827988147736\n",
      "Loss:  0.04055946692824364\n",
      "Loss:  0.06886821985244751\n",
      "28 **********\n",
      "Epoch:  1913.9704329967499  fold:  3  kers:  128\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.03672512620687485\n",
      "Loss:  0.02916065976023674\n",
      "Loss:  0.03710591793060303\n",
      "29 **********\n",
      "Epoch:  1966.9757070541382  fold:  3  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.5245674252510071\n",
      "Eval Loss:  0.14602218568325043\n",
      "Eval Loss:  0.6950539350509644\n",
      "[[1248  288]\n",
      " [ 559 1336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75      1536\n",
      "           1       0.82      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.753133197318566\n",
      "pre:  0.8226600985221675\n",
      "rec:  0.7050131926121372\n",
      "ma F1:  0.7529706901987646\n",
      "mi F1:  0.7531331973185661\n",
      "we F1:  0.7536336453806819\n",
      "update!  Acc:  0.753133197318566\n",
      "Eval Loss:  0.2582691013813019\n",
      "Eval Loss:  0.2514253258705139\n",
      "Eval Loss:  0.18170388042926788\n",
      "Eval Loss:  0.14625373482704163\n",
      "Eval Loss:  0.18367141485214233\n",
      "Eval Loss:  0.16626690328121185\n",
      "Eval Loss:  0.228309765458107\n",
      "Eval Loss:  0.23553505539894104\n",
      "Eval Loss:  0.2061443030834198\n",
      "Eval Loss:  0.19666878879070282\n",
      "Eval Loss:  0.261152058839798\n",
      "Eval Loss:  0.24238505959510803\n",
      "Eval Loss:  0.26825690269470215\n",
      "Eval Loss:  0.1394553780555725\n",
      "Eval Loss:  0.19934771955013275\n",
      "Eval Loss:  0.17582392692565918\n",
      "Eval Loss:  0.16272374987602234\n",
      "Eval Loss:  0.1785372495651245\n",
      "Eval Loss:  0.17346692085266113\n",
      "Eval Loss:  0.22794988751411438\n",
      "Eval Loss:  0.16303108632564545\n",
      "Eval Loss:  0.2930649518966675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.289910227060318\n",
      "Eval Loss:  0.1371787041425705\n",
      "Eval Loss:  0.22295573353767395\n",
      "Eval Loss:  0.2027951031923294\n",
      "Eval Loss:  0.25270092487335205\n",
      "Eval Loss:  0.21305979788303375\n",
      "[[17687   941]\n",
      " [ 1378  9454]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.91      0.87      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9212830957230143\n",
      "pre:  0.9094757094757094\n",
      "rec:  0.8727843426883308\n",
      "ma F1:  0.9146144919690855\n",
      "mi F1:  0.9212830957230143\n",
      "we F1:  0.9209291324240385\n",
      "29460 461\n",
      "Loss:  0.06726610660552979\n",
      "Loss:  0.07374277710914612\n",
      "Loss:  0.037634678184986115\n",
      "30 **********\n",
      "Epoch:  2060.4816908836365  fold:  3  kers:  128\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.050806041806936264\n",
      "Loss:  0.04873849079012871\n",
      "Loss:  0.06264350563287735\n",
      "31 **********\n",
      "Epoch:  2113.4500644207  fold:  3  kers:  128\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.038811299949884415\n",
      "Loss:  0.04625973850488663\n",
      "Loss:  0.029490388929843903\n",
      "32 **********\n",
      "Epoch:  2166.366576194763  fold:  3  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.4614402949810028\n",
      "Eval Loss:  0.09470326453447342\n",
      "Eval Loss:  0.9692739844322205\n",
      "[[1232  304]\n",
      " [ 615 1280]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73      1536\n",
      "           1       0.81      0.68      0.74      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.74      0.74      0.73      3431\n",
      "weighted avg       0.74      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7321480617895657\n",
      "pre:  0.8080808080808081\n",
      "rec:  0.6754617414248021\n",
      "ma F1:  0.7320956268415781\n",
      "mi F1:  0.7321480617895657\n",
      "we F1:  0.7324877965567351\n",
      "Eval Loss:  0.2644294798374176\n",
      "Eval Loss:  0.24314868450164795\n",
      "Eval Loss:  0.16405807435512543\n",
      "Eval Loss:  0.15852555632591248\n",
      "Eval Loss:  0.18437251448631287\n",
      "Eval Loss:  0.15778714418411255\n",
      "Eval Loss:  0.2332184612751007\n",
      "Eval Loss:  0.2230360060930252\n",
      "Eval Loss:  0.2006453573703766\n",
      "Eval Loss:  0.18663141131401062\n",
      "Eval Loss:  0.2542154788970947\n",
      "Eval Loss:  0.22494229674339294\n",
      "Eval Loss:  0.27571848034858704\n",
      "Eval Loss:  0.13576091825962067\n",
      "Eval Loss:  0.20027799904346466\n",
      "Eval Loss:  0.1687709391117096\n",
      "Eval Loss:  0.17026884853839874\n",
      "Eval Loss:  0.18258899450302124\n",
      "Eval Loss:  0.164687842130661\n",
      "Eval Loss:  0.22296826541423798\n",
      "Eval Loss:  0.1589912623167038\n",
      "Eval Loss:  0.26029860973358154\n",
      "Eval Loss:  0.2778868079185486\n",
      "Eval Loss:  0.11641350388526917\n",
      "Eval Loss:  0.23105064034461975\n",
      "Eval Loss:  0.19795942306518555\n",
      "Eval Loss:  0.2520001232624054\n",
      "Eval Loss:  0.18397016823291779\n",
      "[[17675   953]\n",
      " [ 1293  9539]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.91      0.88      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9237610319076714\n",
      "pre:  0.9091688905833015\n",
      "rec:  0.8806314623338257\n",
      "ma F1:  0.9174661356890719\n",
      "mi F1:  0.9237610319076714\n",
      "we F1:  0.9234979708562551\n",
      "29460 461\n",
      "Loss:  0.046651121228933334\n",
      "Loss:  0.06134920194745064\n",
      "Loss:  0.04787697643041611\n",
      "33 **********\n",
      "Epoch:  2259.6581337451935  fold:  3  kers:  128\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.035254642367362976\n",
      "Loss:  0.058879077434539795\n",
      "Loss:  0.03739720582962036\n",
      "34 **********\n",
      "Epoch:  2312.531760454178  fold:  3  kers:  128\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.05655783414840698\n",
      "Loss:  0.05045192688703537\n",
      "Loss:  0.041460055857896805\n",
      "35 **********\n",
      "Epoch:  2365.4572484493256  fold:  3  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.4816451966762543\n",
      "Eval Loss:  0.08639019727706909\n",
      "Eval Loss:  0.9840072393417358\n",
      "[[1242  294]\n",
      " [ 589 1306]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74      1536\n",
      "           1       0.82      0.69      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7426406295540658\n",
      "pre:  0.81625\n",
      "rec:  0.6891820580474934\n",
      "ma F1:  0.7425510498471872\n",
      "mi F1:  0.742640629554066\n",
      "we F1:  0.7430535360154598\n",
      "Eval Loss:  0.24538621306419373\n",
      "Eval Loss:  0.2384156584739685\n",
      "Eval Loss:  0.16342759132385254\n",
      "Eval Loss:  0.14858420193195343\n",
      "Eval Loss:  0.18709008395671844\n",
      "Eval Loss:  0.13969579339027405\n",
      "Eval Loss:  0.23625776171684265\n",
      "Eval Loss:  0.24173326790332794\n",
      "Eval Loss:  0.19229765236377716\n",
      "Eval Loss:  0.17476271092891693\n",
      "Eval Loss:  0.26298344135284424\n",
      "Eval Loss:  0.2284831702709198\n",
      "Eval Loss:  0.27781814336776733\n",
      "Eval Loss:  0.14202676713466644\n",
      "Eval Loss:  0.17687860131263733\n",
      "Eval Loss:  0.1688341498374939\n",
      "Eval Loss:  0.16220086812973022\n",
      "Eval Loss:  0.15929196774959564\n",
      "Eval Loss:  0.16189511120319366\n",
      "Eval Loss:  0.23364412784576416\n",
      "Eval Loss:  0.16162720322608948\n",
      "Eval Loss:  0.25172749161720276\n",
      "Eval Loss:  0.26549994945526123\n",
      "Eval Loss:  0.11476501822471619\n",
      "Eval Loss:  0.21411724388599396\n",
      "Eval Loss:  0.18630751967430115\n",
      "Eval Loss:  0.2449003905057907\n",
      "Eval Loss:  0.1941913366317749\n",
      "[[17664   964]\n",
      " [ 1247  9585]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18628\n",
      "           1       0.91      0.88      0.90     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9249490835030549\n",
      "pre:  0.9086169305147407\n",
      "rec:  0.8848781388478582\n",
      "ma F1:  0.918845842725698\n",
      "mi F1:  0.9249490835030549\n",
      "we F1:  0.9247352925462544\n",
      "29460 461\n",
      "Loss:  0.07590656727552414\n",
      "Loss:  0.05853559076786041\n",
      "Loss:  0.10329028964042664\n",
      "36 **********\n",
      "Epoch:  2458.6730082035065  fold:  3  kers:  128\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.057008400559425354\n",
      "Loss:  0.07911670207977295\n",
      "Loss:  0.044879328459501266\n",
      "37 **********\n",
      "Epoch:  2511.4608640670776  fold:  3  kers:  128\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.038306016474962234\n",
      "Loss:  0.03869723528623581\n",
      "Loss:  0.048808857798576355\n",
      "38 **********\n",
      "Epoch:  2564.3843574523926  fold:  3  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.41425052285194397\n",
      "Eval Loss:  0.08148309588432312\n",
      "Eval Loss:  0.8518909811973572\n",
      "[[1257  279]\n",
      " [ 551 1344]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75      1536\n",
      "           1       0.83      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7580880209851355\n",
      "pre:  0.8280961182994455\n",
      "rec:  0.7092348284960422\n",
      "ma F1:  0.7579323764862049\n",
      "mi F1:  0.7580880209851355\n",
      "we F1:  0.7585746336714473\n",
      "update!  Acc:  0.7580880209851355\n",
      "Eval Loss:  0.24709896743297577\n",
      "Eval Loss:  0.21221880614757538\n",
      "Eval Loss:  0.17885994911193848\n",
      "Eval Loss:  0.1517888456583023\n",
      "Eval Loss:  0.1741856038570404\n",
      "Eval Loss:  0.14036591351032257\n",
      "Eval Loss:  0.23735959827899933\n",
      "Eval Loss:  0.21802885830402374\n",
      "Eval Loss:  0.19118574261665344\n",
      "Eval Loss:  0.18435612320899963\n",
      "Eval Loss:  0.24779725074768066\n",
      "Eval Loss:  0.21774902939796448\n",
      "Eval Loss:  0.2431727647781372\n",
      "Eval Loss:  0.1427682787179947\n",
      "Eval Loss:  0.1767253875732422\n",
      "Eval Loss:  0.1671850085258484\n",
      "Eval Loss:  0.15932048857212067\n",
      "Eval Loss:  0.16009120643138885\n",
      "Eval Loss:  0.18023565411567688\n",
      "Eval Loss:  0.20556874573230743\n",
      "Eval Loss:  0.15109938383102417\n",
      "Eval Loss:  0.24908004701137543\n",
      "Eval Loss:  0.2445104718208313\n",
      "Eval Loss:  0.12693598866462708\n",
      "Eval Loss:  0.19999463856220245\n",
      "Eval Loss:  0.19003024697303772\n",
      "Eval Loss:  0.22143307328224182\n",
      "Eval Loss:  0.18201975524425507\n",
      "[[17643   985]\n",
      " [ 1174  9658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18628\n",
      "           1       0.91      0.89      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9267141887304821\n",
      "pre:  0.9074509066992389\n",
      "rec:  0.8916174298375185\n",
      "ma F1:  0.9209032976732192\n",
      "mi F1:  0.9267141887304821\n",
      "we F1:  0.9265766485413997\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04561590030789375\n",
      "Loss:  0.06902298331260681\n",
      "Loss:  0.040047623217105865\n",
      "39 **********\n",
      "Epoch:  2657.708827018738  fold:  3  kers:  128\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.07212211936712265\n",
      "Loss:  0.06094101443886757\n",
      "Loss:  0.05845861881971359\n",
      "40 **********\n",
      "Epoch:  2710.5106451511383  fold:  3  kers:  128\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.025120703503489494\n",
      "Loss:  0.04309934005141258\n",
      "Loss:  0.09288595616817474\n",
      "41 **********\n",
      "Epoch:  2763.3164536952972  fold:  3  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.374208003282547\n",
      "Eval Loss:  0.05793905258178711\n",
      "Eval Loss:  0.9575427174568176\n",
      "[[1206  330]\n",
      " [ 551 1344]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.73      1536\n",
      "           1       0.80      0.71      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.74      0.75      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.743223549985427\n",
      "pre:  0.8028673835125448\n",
      "rec:  0.7092348284960422\n",
      "ma F1:  0.7428074716680406\n",
      "mi F1:  0.743223549985427\n",
      "we F1:  0.7438898783052993\n",
      "Eval Loss:  0.24638137221336365\n",
      "Eval Loss:  0.19897057116031647\n",
      "Eval Loss:  0.17031385004520416\n",
      "Eval Loss:  0.1612808108329773\n",
      "Eval Loss:  0.18470978736877441\n",
      "Eval Loss:  0.14198701083660126\n",
      "Eval Loss:  0.20391003787517548\n",
      "Eval Loss:  0.20711804926395416\n",
      "Eval Loss:  0.1875489354133606\n",
      "Eval Loss:  0.16943033039569855\n",
      "Eval Loss:  0.24562926590442657\n",
      "Eval Loss:  0.22050073742866516\n",
      "Eval Loss:  0.2425719052553177\n",
      "Eval Loss:  0.12629812955856323\n",
      "Eval Loss:  0.16922475397586823\n",
      "Eval Loss:  0.15112805366516113\n",
      "Eval Loss:  0.16624149680137634\n",
      "Eval Loss:  0.17510223388671875\n",
      "Eval Loss:  0.1540737748146057\n",
      "Eval Loss:  0.1898546814918518\n",
      "Eval Loss:  0.15361258387565613\n",
      "Eval Loss:  0.23864394426345825\n",
      "Eval Loss:  0.26029571890830994\n",
      "Eval Loss:  0.12298566848039627\n",
      "Eval Loss:  0.19323180615901947\n",
      "Eval Loss:  0.1956794410943985\n",
      "Eval Loss:  0.22980335354804993\n",
      "Eval Loss:  0.17103148996829987\n",
      "[[17584  1044]\n",
      " [  991  9841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     18628\n",
      "           1       0.90      0.91      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9309232858112695\n",
      "pre:  0.9040881947634359\n",
      "rec:  0.9085118168389956\n",
      "ma F1:  0.9257973590585097\n",
      "mi F1:  0.9309232858112695\n",
      "we F1:  0.9309583722271154\n",
      "29460 461\n",
      "Loss:  0.03310669958591461\n",
      "Loss:  0.05307024344801903\n",
      "Loss:  0.05263224616646767\n",
      "42 **********\n",
      "Epoch:  2856.424501657486  fold:  3  kers:  128\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.0417867936193943\n",
      "Loss:  0.04336659610271454\n",
      "Loss:  0.08044213801622391\n",
      "43 **********\n",
      "Epoch:  2910.976639986038  fold:  3  kers:  128\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.06883300840854645\n",
      "Loss:  0.051512666046619415\n",
      "Loss:  0.07690887153148651\n",
      "44 **********\n",
      "Epoch:  2964.09760594368  fold:  3  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.3612278401851654\n",
      "Eval Loss:  0.12439733743667603\n",
      "Eval Loss:  1.0123229026794434\n",
      "[[1218  318]\n",
      " [ 546 1349]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74      1536\n",
      "           1       0.81      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7481783736519965\n",
      "pre:  0.8092381523695261\n",
      "rec:  0.7118733509234828\n",
      "ma F1:  0.7478107294165688\n",
      "mi F1:  0.7481783736519965\n",
      "we F1:  0.7488182430083132\n",
      "Eval Loss:  0.23284313082695007\n",
      "Eval Loss:  0.20378947257995605\n",
      "Eval Loss:  0.17502236366271973\n",
      "Eval Loss:  0.16664369404315948\n",
      "Eval Loss:  0.19702039659023285\n",
      "Eval Loss:  0.12255734205245972\n",
      "Eval Loss:  0.20372867584228516\n",
      "Eval Loss:  0.2401255965232849\n",
      "Eval Loss:  0.19036300480365753\n",
      "Eval Loss:  0.17289792001247406\n",
      "Eval Loss:  0.2518730163574219\n",
      "Eval Loss:  0.20560690760612488\n",
      "Eval Loss:  0.25025102496147156\n",
      "Eval Loss:  0.12263950705528259\n",
      "Eval Loss:  0.19003087282180786\n",
      "Eval Loss:  0.16264407336711884\n",
      "Eval Loss:  0.16749513149261475\n",
      "Eval Loss:  0.17248329520225525\n",
      "Eval Loss:  0.16050775349140167\n",
      "Eval Loss:  0.20147369801998138\n",
      "Eval Loss:  0.16645479202270508\n",
      "Eval Loss:  0.24326728284358978\n",
      "Eval Loss:  0.25289100408554077\n",
      "Eval Loss:  0.1408858746290207\n",
      "Eval Loss:  0.20517750084400177\n",
      "Eval Loss:  0.183290034532547\n",
      "Eval Loss:  0.25845885276794434\n",
      "Eval Loss:  0.17022928595542908\n",
      "[[17598  1030]\n",
      " [ 1078  9754]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18628\n",
      "           1       0.90      0.90      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9284453496266124\n",
      "pre:  0.9044881305637982\n",
      "rec:  0.9004800590841949\n",
      "ma F1:  0.922985479655978\n",
      "mi F1:  0.9284453496266124\n",
      "we F1:  0.9284119388975722\n",
      "29460 461\n",
      "Loss:  0.0784798115491867\n",
      "Loss:  0.03400832414627075\n",
      "Loss:  0.04197989031672478\n",
      "45 **********\n",
      "Epoch:  3056.90545630455  fold:  3  kers:  128\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.04297839105129242\n",
      "Loss:  0.036132439970970154\n",
      "Loss:  0.08404548466205597\n",
      "46 **********\n",
      "Epoch:  3109.7342031002045  fold:  3  kers:  128\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.05114416778087616\n",
      "Loss:  0.06221111863851547\n",
      "Loss:  0.062463242560625076\n",
      "47 **********\n",
      "Epoch:  3162.564944267273  fold:  3  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.4530411958694458\n",
      "Eval Loss:  0.09684891253709793\n",
      "Eval Loss:  0.8600579500198364\n",
      "[[1227  309]\n",
      " [ 568 1327]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74      1536\n",
      "           1       0.81      0.70      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7443893908481493\n",
      "pre:  0.8111246943765281\n",
      "rec:  0.700263852242744\n",
      "ma F1:  0.744172067431059\n",
      "mi F1:  0.7443893908481491\n",
      "we F1:  0.7449522584984128\n",
      "Eval Loss:  0.21303123235702515\n",
      "Eval Loss:  0.21444278955459595\n",
      "Eval Loss:  0.16422314941883087\n",
      "Eval Loss:  0.160873681306839\n",
      "Eval Loss:  0.19478033483028412\n",
      "Eval Loss:  0.1449178010225296\n",
      "Eval Loss:  0.19960591197013855\n",
      "Eval Loss:  0.21549390256404877\n",
      "Eval Loss:  0.15697766840457916\n",
      "Eval Loss:  0.15263818204402924\n",
      "Eval Loss:  0.24068817496299744\n",
      "Eval Loss:  0.2059060037136078\n",
      "Eval Loss:  0.22699394822120667\n",
      "Eval Loss:  0.12245035171508789\n",
      "Eval Loss:  0.16252389550209045\n",
      "Eval Loss:  0.1637597233057022\n",
      "Eval Loss:  0.16152280569076538\n",
      "Eval Loss:  0.15995679795742035\n",
      "Eval Loss:  0.14236290752887726\n",
      "Eval Loss:  0.19564102590084076\n",
      "Eval Loss:  0.1672469675540924\n",
      "Eval Loss:  0.22513213753700256\n",
      "Eval Loss:  0.2248239815235138\n",
      "Eval Loss:  0.12529508769512177\n",
      "Eval Loss:  0.19448299705982208\n",
      "Eval Loss:  0.18375496566295624\n",
      "Eval Loss:  0.23044681549072266\n",
      "Eval Loss:  0.1880093663930893\n",
      "[[17768   860]\n",
      " [ 1165  9667]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     18628\n",
      "           1       0.92      0.89      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9312627291242362\n",
      "pre:  0.91830531015484\n",
      "rec:  0.8924483013293943\n",
      "ma F1:  0.9256399439956402\n",
      "mi F1:  0.9312627291242362\n",
      "we F1:  0.9310510331034707\n",
      "29460 461\n",
      "Loss:  0.0673552006483078\n",
      "Loss:  0.03183560445904732\n",
      "Loss:  0.041642554104328156\n",
      "48 **********\n",
      "Epoch:  3255.8046402931213  fold:  3  kers:  128\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.0626322403550148\n",
      "Loss:  0.055187907069921494\n",
      "Loss:  0.0557372160255909\n",
      "49 **********\n",
      "Epoch:  3308.5865120887756  fold:  3  kers:  128\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.061703842133283615\n",
      "Loss:  0.04943622648715973\n",
      "Loss:  0.041294362396001816\n",
      "50 **********\n",
      "Epoch:  3361.376362800598  fold:  3  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.4210372567176819\n",
      "Eval Loss:  0.11328926682472229\n",
      "Eval Loss:  0.9496462941169739\n",
      "[[1214  322]\n",
      " [ 542 1353]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74      1536\n",
      "           1       0.81      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7481783736519965\n",
      "pre:  0.8077611940298507\n",
      "rec:  0.7139841688654354\n",
      "ma F1:  0.7477643791416932\n",
      "mi F1:  0.7481783736519965\n",
      "we F1:  0.7488336167618292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22368884086608887\n",
      "Eval Loss:  0.18650662899017334\n",
      "Eval Loss:  0.16030217707157135\n",
      "Eval Loss:  0.15599706768989563\n",
      "Eval Loss:  0.17299142479896545\n",
      "Eval Loss:  0.1448906660079956\n",
      "Eval Loss:  0.1854291558265686\n",
      "Eval Loss:  0.1922634243965149\n",
      "Eval Loss:  0.18308402597904205\n",
      "Eval Loss:  0.17911797761917114\n",
      "Eval Loss:  0.2668110132217407\n",
      "Eval Loss:  0.19874286651611328\n",
      "Eval Loss:  0.2411646544933319\n",
      "Eval Loss:  0.11402663588523865\n",
      "Eval Loss:  0.17447307705879211\n",
      "Eval Loss:  0.15080472826957703\n",
      "Eval Loss:  0.16904336214065552\n",
      "Eval Loss:  0.1757926642894745\n",
      "Eval Loss:  0.15721522271633148\n",
      "Eval Loss:  0.19311220943927765\n",
      "Eval Loss:  0.16639919579029083\n",
      "Eval Loss:  0.22889888286590576\n",
      "Eval Loss:  0.25681525468826294\n",
      "Eval Loss:  0.1298586130142212\n",
      "Eval Loss:  0.2051354944705963\n",
      "Eval Loss:  0.20141874253749847\n",
      "Eval Loss:  0.26531434059143066\n",
      "Eval Loss:  0.15394634008407593\n",
      "[[17642   986]\n",
      " [ 1085  9747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18628\n",
      "           1       0.91      0.90      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9297012898845892\n",
      "pre:  0.9081337929749371\n",
      "rec:  0.8998338257016248\n",
      "ma F1:  0.924261859513172\n",
      "mi F1:  0.9297012898845892\n",
      "we F1:  0.9296330817013378\n",
      "29460 461\n",
      "Loss:  0.04643206670880318\n",
      "Loss:  0.0708375796675682\n",
      "Loss:  0.058720074594020844\n",
      "51 **********\n",
      "Epoch:  3454.6220428943634  fold:  3  kers:  128\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.0355663001537323\n",
      "Loss:  0.043096743524074554\n",
      "Loss:  0.05831107497215271\n",
      "52 **********\n",
      "Epoch:  3507.4497923851013  fold:  3  kers:  128\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.02362242341041565\n",
      "Loss:  0.046084925532341\n",
      "Loss:  0.04736366122961044\n",
      "53 **********\n",
      "Epoch:  3560.343365907669  fold:  3  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.574165940284729\n",
      "Eval Loss:  0.10667108744382858\n",
      "Eval Loss:  1.1310440301895142\n",
      "[[1271  265]\n",
      " [ 693 1202]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.83      0.73      1536\n",
      "           1       0.82      0.63      0.72      1895\n",
      "\n",
      "    accuracy                           0.72      3431\n",
      "   macro avg       0.73      0.73      0.72      3431\n",
      "weighted avg       0.74      0.72      0.72      3431\n",
      "\n",
      "acc:  0.7207811133780239\n",
      "pre:  0.8193592365371506\n",
      "rec:  0.6343007915567282\n",
      "ma F1:  0.7206681397127559\n",
      "mi F1:  0.7207811133780239\n",
      "we F1:  0.7200803491934636\n",
      "Eval Loss:  0.21169891953468323\n",
      "Eval Loss:  0.22177527844905853\n",
      "Eval Loss:  0.16290853917598724\n",
      "Eval Loss:  0.1600058376789093\n",
      "Eval Loss:  0.17095845937728882\n",
      "Eval Loss:  0.14696066081523895\n",
      "Eval Loss:  0.19770313799381256\n",
      "Eval Loss:  0.2100869119167328\n",
      "Eval Loss:  0.174291729927063\n",
      "Eval Loss:  0.16807696223258972\n",
      "Eval Loss:  0.23555722832679749\n",
      "Eval Loss:  0.2128874808549881\n",
      "Eval Loss:  0.2279253751039505\n",
      "Eval Loss:  0.14186684787273407\n",
      "Eval Loss:  0.1759481132030487\n",
      "Eval Loss:  0.16787730157375336\n",
      "Eval Loss:  0.1534048318862915\n",
      "Eval Loss:  0.16684044897556305\n",
      "Eval Loss:  0.18416090309619904\n",
      "Eval Loss:  0.2236385941505432\n",
      "Eval Loss:  0.15369097888469696\n",
      "Eval Loss:  0.2829965054988861\n",
      "Eval Loss:  0.26730236411094666\n",
      "Eval Loss:  0.13108794391155243\n",
      "Eval Loss:  0.20339421927928925\n",
      "Eval Loss:  0.19822202622890472\n",
      "Eval Loss:  0.2251783013343811\n",
      "Eval Loss:  0.18255078792572021\n",
      "[[18057   571]\n",
      " [ 1518  9314]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     18628\n",
      "           1       0.94      0.86      0.90     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.91      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9290902919212491\n",
      "pre:  0.9422357106727365\n",
      "rec:  0.8598596750369276\n",
      "ma F1:  0.9222416837490031\n",
      "mi F1:  0.9290902919212491\n",
      "we F1:  0.9283484833956724\n",
      "29460 461\n",
      "Loss:  0.039785388857126236\n",
      "Loss:  0.06064767763018608\n",
      "Loss:  0.05517187342047691\n",
      "54 **********\n",
      "Epoch:  3653.567104578018  fold:  3  kers:  128\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.054834816604852676\n",
      "Loss:  0.03367318958044052\n",
      "Loss:  0.03146074339747429\n",
      "55 **********\n",
      "Epoch:  3706.3818879127502  fold:  3  kers:  128\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.047858551144599915\n",
      "Loss:  0.06893256306648254\n",
      "Loss:  0.03780829906463623\n",
      "56 **********\n",
      "Epoch:  3759.2096376419067  fold:  3  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.41528210043907166\n",
      "Eval Loss:  0.06570218503475189\n",
      "Eval Loss:  0.7834373712539673\n",
      "[[1195  341]\n",
      " [ 518 1377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      1536\n",
      "           1       0.80      0.73      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.75      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7496356747303993\n",
      "pre:  0.8015133876600699\n",
      "rec:  0.7266490765171504\n",
      "ma F1:  0.7489291985091625\n",
      "mi F1:  0.7496356747303993\n",
      "we F1:  0.7503227422642395\n",
      "Eval Loss:  0.1870243102312088\n",
      "Eval Loss:  0.2030935436487198\n",
      "Eval Loss:  0.16998879611492157\n",
      "Eval Loss:  0.16554713249206543\n",
      "Eval Loss:  0.19626474380493164\n",
      "Eval Loss:  0.1534656137228012\n",
      "Eval Loss:  0.1749112904071808\n",
      "Eval Loss:  0.19699618220329285\n",
      "Eval Loss:  0.1772935837507248\n",
      "Eval Loss:  0.1529063880443573\n",
      "Eval Loss:  0.24617859721183777\n",
      "Eval Loss:  0.19404199719429016\n",
      "Eval Loss:  0.23418332636356354\n",
      "Eval Loss:  0.10922707617282867\n",
      "Eval Loss:  0.13086339831352234\n",
      "Eval Loss:  0.144419863820076\n",
      "Eval Loss:  0.13783331215381622\n",
      "Eval Loss:  0.17066098749637604\n",
      "Eval Loss:  0.15020807087421417\n",
      "Eval Loss:  0.20447683334350586\n",
      "Eval Loss:  0.17407411336898804\n",
      "Eval Loss:  0.24827808141708374\n",
      "Eval Loss:  0.23926246166229248\n",
      "Eval Loss:  0.13581234216690063\n",
      "Eval Loss:  0.1853276640176773\n",
      "Eval Loss:  0.1870458871126175\n",
      "Eval Loss:  0.2266720086336136\n",
      "Eval Loss:  0.16642609238624573\n",
      "[[17475  1153]\n",
      " [  852  9980]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     18628\n",
      "           1       0.90      0.92      0.91     10832\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.93      0.93     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9319416157501698\n",
      "pre:  0.8964340249708075\n",
      "rec:  0.9213441654357459\n",
      "ma F1:  0.9272316202240911\n",
      "mi F1:  0.9319416157501698\n",
      "we F1:  0.9321307696732316\n",
      "29460 461\n",
      "Loss:  0.03033294342458248\n",
      "Loss:  0.07395122945308685\n",
      "Loss:  0.03399723768234253\n",
      "57 **********\n",
      "Epoch:  3852.490224123001  fold:  3  kers:  128\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.0476958304643631\n",
      "Loss:  0.05978632718324661\n",
      "Loss:  0.022729437798261642\n",
      "58 **********\n",
      "Epoch:  3905.297029733658  fold:  3  kers:  128\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.02364143170416355\n",
      "Loss:  0.029765883460640907\n",
      "Loss:  0.030882660299539566\n",
      "59 **********\n",
      "Epoch:  3958.1696593761444  fold:  3  kers:  128\n",
      "Eval Loss:  0.432163268327713\n",
      "Eval Loss:  0.0618542842566967\n",
      "Eval Loss:  1.0487076044082642\n",
      "[[1219  317]\n",
      " [ 570 1325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73      1536\n",
      "           1       0.81      0.70      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.74      0.75      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7414747886913436\n",
      "pre:  0.8069427527405603\n",
      "rec:  0.6992084432717678\n",
      "ma F1:  0.7412277938272314\n",
      "mi F1:  0.7414747886913435\n",
      "we F1:  0.7420643141688946\n",
      "update!  Acc:  0.7580880209851355\n",
      "Epoch:  3962.4063305854797  fold:  3  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29520 3371\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29520 462\n",
      "Loss:  0.18200930953025818\n",
      "Loss:  0.16054746508598328\n",
      "Loss:  0.15680460631847382\n",
      "0 **********\n",
      "Epoch:  65.47692775726318  fold:  4  kers:  128\n",
      "epoch:  1\n",
      "29520 462\n",
      "Loss:  0.14740204811096191\n",
      "Loss:  0.13014499843120575\n",
      "Loss:  0.11538656800985336\n",
      "1 **********\n",
      "Epoch:  118.75746583938599  fold:  4  kers:  128\n",
      "epoch:  2\n",
      "29520 462\n",
      "Loss:  0.14247992634773254\n",
      "Loss:  0.09408252686262131\n",
      "Loss:  0.10448414087295532\n",
      "2 **********\n",
      "Epoch:  171.89039993286133  fold:  4  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.15642504394054413\n",
      "Eval Loss:  0.1720067709684372\n",
      "Eval Loss:  0.07944568991661072\n",
      "[[3035  102]\n",
      " [ 219   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3137\n",
      "           1       0.13      0.06      0.09       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.53      0.52      0.52      3371\n",
      "weighted avg       0.88      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9047760308513794\n",
      "pre:  0.1282051282051282\n",
      "rec:  0.0641025641025641\n",
      "ma F1:  0.5176216019589513\n",
      "mi F1:  0.9047760308513794\n",
      "we F1:  0.8897770016525669\n",
      "update!  Acc:  0.9047760308513794\n",
      "Eval Loss:  0.4904959499835968\n",
      "Eval Loss:  0.4903435707092285\n",
      "Eval Loss:  0.34116223454475403\n",
      "Eval Loss:  0.45096340775489807\n",
      "Eval Loss:  0.41643962264060974\n",
      "Eval Loss:  0.4059217572212219\n",
      "Eval Loss:  0.48770180344581604\n",
      "Eval Loss:  0.3915666341781616\n",
      "Eval Loss:  0.5044541954994202\n",
      "Eval Loss:  0.46785768866539\n",
      "Eval Loss:  0.4887227416038513\n",
      "Eval Loss:  0.4006294012069702\n",
      "Eval Loss:  0.5519197583198547\n",
      "Eval Loss:  0.4174368977546692\n",
      "Eval Loss:  0.4396907091140747\n",
      "Eval Loss:  0.41015681624412537\n",
      "Eval Loss:  0.4099111557006836\n",
      "Eval Loss:  0.5044549703598022\n",
      "Eval Loss:  0.5440514087677002\n",
      "Eval Loss:  0.5248708128929138\n",
      "Eval Loss:  0.3767777383327484\n",
      "Eval Loss:  0.48066702485084534\n",
      "Eval Loss:  0.5508724451065063\n",
      "Eval Loss:  0.5536728501319885\n",
      "Eval Loss:  0.39738374948501587\n",
      "Eval Loss:  0.34897902607917786\n",
      "Eval Loss:  0.48231270909309387\n",
      "Eval Loss:  0.3861308693885803\n",
      "[[16021  1006]\n",
      " [ 4834  7659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85     17027\n",
      "           1       0.88      0.61      0.72     12493\n",
      "\n",
      "    accuracy                           0.80     29520\n",
      "   macro avg       0.83      0.78      0.78     29520\n",
      "weighted avg       0.82      0.80      0.79     29520\n",
      "\n",
      "acc:  0.8021680216802168\n",
      "pre:  0.8839007501442585\n",
      "rec:  0.6130633154566557\n",
      "ma F1:  0.7849092728725998\n",
      "mi F1:  0.8021680216802168\n",
      "we F1:  0.7942672215802935\n",
      "29520 462\n",
      "Loss:  0.08797208964824677\n",
      "Loss:  0.08964028209447861\n",
      "Loss:  0.10083845257759094\n",
      "3 **********\n",
      "Epoch:  266.08454489707947  fold:  4  kers:  128\n",
      "epoch:  4\n",
      "29520 462\n",
      "Loss:  0.10453693568706512\n",
      "Loss:  0.08140146732330322\n",
      "Loss:  0.06914093345403671\n",
      "4 **********\n",
      "Epoch:  319.37605333328247  fold:  4  kers:  128\n",
      "epoch:  5\n",
      "29520 462\n",
      "Loss:  0.10548257827758789\n",
      "Loss:  0.07700977474451065\n",
      "Loss:  0.13046208024024963\n",
      "5 **********\n",
      "Epoch:  372.4421651363373  fold:  4  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.11215416342020035\n",
      "Eval Loss:  0.12378004193305969\n",
      "Eval Loss:  0.04683854803442955\n",
      "[[3081   56]\n",
      " [ 222   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.18      0.05      0.08       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.55      0.52      0.52      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9175318896469891\n",
      "pre:  0.17647058823529413\n",
      "rec:  0.05128205128205128\n",
      "ma F1:  0.5181512484060714\n",
      "mi F1:  0.9175318896469891\n",
      "we F1:  0.8959296783579723\n",
      "update!  Acc:  0.9175318896469891\n",
      "Eval Loss:  0.4028500020503998\n",
      "Eval Loss:  0.41656962037086487\n",
      "Eval Loss:  0.291254460811615\n",
      "Eval Loss:  0.4347487688064575\n",
      "Eval Loss:  0.35644230246543884\n",
      "Eval Loss:  0.34734752774238586\n",
      "Eval Loss:  0.4351789951324463\n",
      "Eval Loss:  0.31267881393432617\n",
      "Eval Loss:  0.439544677734375\n",
      "Eval Loss:  0.39117392897605896\n",
      "Eval Loss:  0.4638826251029968\n",
      "Eval Loss:  0.3422228693962097\n",
      "Eval Loss:  0.4524382948875427\n",
      "Eval Loss:  0.34832775592803955\n",
      "Eval Loss:  0.41346412897109985\n",
      "Eval Loss:  0.37944531440734863\n",
      "Eval Loss:  0.33535873889923096\n",
      "Eval Loss:  0.391448050737381\n",
      "Eval Loss:  0.5144655704498291\n",
      "Eval Loss:  0.49357426166534424\n",
      "Eval Loss:  0.32190877199172974\n",
      "Eval Loss:  0.40966010093688965\n",
      "Eval Loss:  0.4725775122642517\n",
      "Eval Loss:  0.4374484121799469\n",
      "Eval Loss:  0.3507011830806732\n",
      "Eval Loss:  0.30681291222572327\n",
      "Eval Loss:  0.41998252272605896\n",
      "Eval Loss:  0.3027588129043579\n",
      "[[16358   669]\n",
      " [ 4199  8294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87     17027\n",
      "           1       0.93      0.66      0.77     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.86      0.81      0.82     29520\n",
      "weighted avg       0.85      0.84      0.83     29520\n",
      "\n",
      "acc:  0.8350948509485094\n",
      "pre:  0.925359812562758\n",
      "rec:  0.663891779396462\n",
      "ma F1:  0.8217969377230352\n",
      "mi F1:  0.8350948509485093\n",
      "we F1:  0.8292737158188066\n",
      "29520 462\n",
      "Loss:  0.03848706930875778\n",
      "Loss:  0.0649881586432457\n",
      "Loss:  0.08555355668067932\n",
      "6 **********\n",
      "Epoch:  465.8593862056732  fold:  4  kers:  128\n",
      "epoch:  7\n",
      "29520 462\n",
      "Loss:  0.07889220118522644\n",
      "Loss:  0.06640646606683731\n",
      "Loss:  0.07547776401042938\n",
      "7 **********\n",
      "Epoch:  518.6821494102478  fold:  4  kers:  128\n",
      "epoch:  8\n",
      "29520 462\n",
      "Loss:  0.06097482144832611\n",
      "Loss:  0.06021536886692047\n",
      "Loss:  0.08626130223274231\n",
      "8 **********\n",
      "Epoch:  571.5787138938904  fold:  4  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.10076919943094254\n",
      "Eval Loss:  0.1136125922203064\n",
      "Eval Loss:  0.03092876449227333\n",
      "[[3104   33]\n",
      " [ 225    9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.21      0.04      0.07       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.57      0.51      0.51      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9234648472263424\n",
      "pre:  0.21428571428571427\n",
      "rec:  0.038461538461538464\n",
      "ma F1:  0.512658185290281\n",
      "mi F1:  0.9234648472263424\n",
      "we F1:  0.8979802336264315\n",
      "update!  Acc:  0.9234648472263424\n",
      "Eval Loss:  0.39019525051116943\n",
      "Eval Loss:  0.41631224751472473\n",
      "Eval Loss:  0.2989460825920105\n",
      "Eval Loss:  0.4683361053466797\n",
      "Eval Loss:  0.37043967843055725\n",
      "Eval Loss:  0.36989179253578186\n",
      "Eval Loss:  0.46024268865585327\n",
      "Eval Loss:  0.3198026418685913\n",
      "Eval Loss:  0.4654022455215454\n",
      "Eval Loss:  0.3826169967651367\n",
      "Eval Loss:  0.45765259861946106\n",
      "Eval Loss:  0.3689730167388916\n",
      "Eval Loss:  0.47034692764282227\n",
      "Eval Loss:  0.3546319603919983\n",
      "Eval Loss:  0.4313068389892578\n",
      "Eval Loss:  0.41437938809394836\n",
      "Eval Loss:  0.3378628194332123\n",
      "Eval Loss:  0.42726001143455505\n",
      "Eval Loss:  0.5236035585403442\n",
      "Eval Loss:  0.49130934476852417\n",
      "Eval Loss:  0.2982580363750458\n",
      "Eval Loss:  0.42488744854927063\n",
      "Eval Loss:  0.45515504479408264\n",
      "Eval Loss:  0.44135791063308716\n",
      "Eval Loss:  0.3350735902786255\n",
      "Eval Loss:  0.3161863386631012\n",
      "Eval Loss:  0.4221160113811493\n",
      "Eval Loss:  0.3038144111633301\n",
      "[[16556   471]\n",
      " [ 4552  7941]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.87     17027\n",
      "           1       0.94      0.64      0.76     12493\n",
      "\n",
      "    accuracy                           0.83     29520\n",
      "   macro avg       0.86      0.80      0.81     29520\n",
      "weighted avg       0.85      0.83      0.82     29520\n",
      "\n",
      "acc:  0.8298441734417344\n",
      "pre:  0.9440085592011412\n",
      "rec:  0.6356359561354359\n",
      "ma F1:  0.8140031416354122\n",
      "mi F1:  0.8298441734417344\n",
      "we F1:  0.8223401396864702\n",
      "29520 462\n",
      "Loss:  0.1127002164721489\n",
      "Loss:  0.06256774067878723\n",
      "Loss:  0.08023475855588913\n",
      "9 **********\n",
      "Epoch:  664.8094339370728  fold:  4  kers:  128\n",
      "epoch:  10\n",
      "29520 462\n",
      "Loss:  0.08939437568187714\n",
      "Loss:  0.11148514598608017\n",
      "Loss:  0.052269142121076584\n",
      "10 **********\n",
      "Epoch:  717.7199618816376  fold:  4  kers:  128\n",
      "epoch:  11\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.10938998311758041\n",
      "Loss:  0.0747605562210083\n",
      "Loss:  0.07121029496192932\n",
      "11 **********\n",
      "Epoch:  770.5636689662933  fold:  4  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.0984237864613533\n",
      "Eval Loss:  0.10981782525777817\n",
      "Eval Loss:  0.024335458874702454\n",
      "[[3087   50]\n",
      " [ 214   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.29      0.09      0.13       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.61      0.53      0.55      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9216849599525363\n",
      "pre:  0.2857142857142857\n",
      "rec:  0.08547008547008547\n",
      "ma F1:  0.5452862118016384\n",
      "mi F1:  0.9216849599525363\n",
      "we F1:  0.9015579972212852\n",
      "Eval Loss:  0.2799142897129059\n",
      "Eval Loss:  0.3468072712421417\n",
      "Eval Loss:  0.23743991553783417\n",
      "Eval Loss:  0.3443920314311981\n",
      "Eval Loss:  0.283614844083786\n",
      "Eval Loss:  0.2919338345527649\n",
      "Eval Loss:  0.37102267146110535\n",
      "Eval Loss:  0.25887641310691833\n",
      "Eval Loss:  0.372285395860672\n",
      "Eval Loss:  0.3067816197872162\n",
      "Eval Loss:  0.38945022225379944\n",
      "Eval Loss:  0.28170254826545715\n",
      "Eval Loss:  0.37515631318092346\n",
      "Eval Loss:  0.28822630643844604\n",
      "Eval Loss:  0.3384186923503876\n",
      "Eval Loss:  0.2861432135105133\n",
      "Eval Loss:  0.26799896359443665\n",
      "Eval Loss:  0.3117324113845825\n",
      "Eval Loss:  0.4119555950164795\n",
      "Eval Loss:  0.39422985911369324\n",
      "Eval Loss:  0.24435506761074066\n",
      "Eval Loss:  0.37894269824028015\n",
      "Eval Loss:  0.35554781556129456\n",
      "Eval Loss:  0.3445171117782593\n",
      "Eval Loss:  0.2793092727661133\n",
      "Eval Loss:  0.24611423909664154\n",
      "Eval Loss:  0.2733997702598572\n",
      "Eval Loss:  0.21262314915657043\n",
      "[[16387   640]\n",
      " [ 3333  9160]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     17027\n",
      "           1       0.93      0.73      0.82     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.88      0.85      0.86     29520\n",
      "weighted avg       0.87      0.87      0.86     29520\n",
      "\n",
      "acc:  0.8654132791327913\n",
      "pre:  0.9346938775510204\n",
      "rec:  0.7332105979348436\n",
      "ma F1:  0.8568324764391029\n",
      "mi F1:  0.8654132791327913\n",
      "we F1:  0.8622158110749384\n",
      "29520 462\n",
      "Loss:  0.06455677002668381\n",
      "Loss:  0.07938563823699951\n",
      "Loss:  0.05735305696725845\n",
      "12 **********\n",
      "Epoch:  863.7245755195618  fold:  4  kers:  128\n",
      "epoch:  13\n",
      "29520 462\n",
      "Loss:  0.08403506129980087\n",
      "Loss:  0.10507026314735413\n",
      "Loss:  0.059753358364105225\n",
      "13 **********\n",
      "Epoch:  916.6390931606293  fold:  4  kers:  128\n",
      "epoch:  14\n",
      "29520 462\n",
      "Loss:  0.053797412663698196\n",
      "Loss:  0.04481426626443863\n",
      "Loss:  0.07984911650419235\n",
      "14 **********\n",
      "Epoch:  969.5017492771149  fold:  4  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.09282844513654709\n",
      "Eval Loss:  0.16064739227294922\n",
      "Eval Loss:  0.02402469702064991\n",
      "[[3054   83]\n",
      " [ 218   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3137\n",
      "           1       0.16      0.07      0.10       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.55      0.52      0.52      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9107089884307327\n",
      "pre:  0.16161616161616163\n",
      "rec:  0.06837606837606838\n",
      "ma F1:  0.5245654454579404\n",
      "mi F1:  0.9107089884307327\n",
      "we F1:  0.8935498777324685\n",
      "Eval Loss:  0.3263549506664276\n",
      "Eval Loss:  0.3328050971031189\n",
      "Eval Loss:  0.24473220109939575\n",
      "Eval Loss:  0.39140018820762634\n",
      "Eval Loss:  0.311535507440567\n",
      "Eval Loss:  0.3135231137275696\n",
      "Eval Loss:  0.3855591118335724\n",
      "Eval Loss:  0.2812328636646271\n",
      "Eval Loss:  0.37570369243621826\n",
      "Eval Loss:  0.31916067004203796\n",
      "Eval Loss:  0.3832540512084961\n",
      "Eval Loss:  0.2800556719303131\n",
      "Eval Loss:  0.4304424226284027\n",
      "Eval Loss:  0.2580803334712982\n",
      "Eval Loss:  0.34809762239456177\n",
      "Eval Loss:  0.33779242634773254\n",
      "Eval Loss:  0.27406811714172363\n",
      "Eval Loss:  0.31397947669029236\n",
      "Eval Loss:  0.4234718978404999\n",
      "Eval Loss:  0.3963795006275177\n",
      "Eval Loss:  0.231906920671463\n",
      "Eval Loss:  0.37848979234695435\n",
      "Eval Loss:  0.3236362338066101\n",
      "Eval Loss:  0.3105848431587219\n",
      "Eval Loss:  0.27212291955947876\n",
      "Eval Loss:  0.24860090017318726\n",
      "Eval Loss:  0.28375962376594543\n",
      "Eval Loss:  0.23018257319927216\n",
      "[[16466   561]\n",
      " [ 3537  8956]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     17027\n",
      "           1       0.94      0.72      0.81     12493\n",
      "\n",
      "    accuracy                           0.86     29520\n",
      "   macro avg       0.88      0.84      0.85     29520\n",
      "weighted avg       0.87      0.86      0.86     29520\n",
      "\n",
      "acc:  0.8611788617886179\n",
      "pre:  0.9410528527897447\n",
      "rec:  0.7168814536140239\n",
      "ma F1:  0.8515724384725329\n",
      "mi F1:  0.8611788617886179\n",
      "we F1:  0.8573721086875967\n",
      "29520 462\n",
      "Loss:  0.09797636419534683\n",
      "Loss:  0.06940576434135437\n",
      "Loss:  0.056593701243400574\n",
      "15 **********\n",
      "Epoch:  1062.761391878128  fold:  4  kers:  128\n",
      "epoch:  16\n",
      "29520 462\n",
      "Loss:  0.08525583148002625\n",
      "Loss:  0.11096181720495224\n",
      "Loss:  0.056687869131565094\n",
      "16 **********\n",
      "Epoch:  1115.5911355018616  fold:  4  kers:  128\n",
      "epoch:  17\n",
      "29520 462\n",
      "Loss:  0.06110211834311485\n",
      "Loss:  0.09937664866447449\n",
      "Loss:  0.05083587393164635\n",
      "17 **********\n",
      "Epoch:  1168.486703634262  fold:  4  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.10449304431676865\n",
      "Eval Loss:  0.1262229084968567\n",
      "Eval Loss:  0.019300401210784912\n",
      "[[3071   66]\n",
      " [ 214   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.23      0.09      0.12       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.58      0.53      0.54      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9169385938890537\n",
      "pre:  0.23255813953488372\n",
      "rec:  0.08547008547008547\n",
      "ma F1:  0.5406999377141077\n",
      "mi F1:  0.9169385938890537\n",
      "we F1:  0.8986877511771912\n",
      "Eval Loss:  0.2896791994571686\n",
      "Eval Loss:  0.2871708869934082\n",
      "Eval Loss:  0.21720565855503082\n",
      "Eval Loss:  0.327176570892334\n",
      "Eval Loss:  0.2607460618019104\n",
      "Eval Loss:  0.2991350293159485\n",
      "Eval Loss:  0.3137745261192322\n",
      "Eval Loss:  0.24155175685882568\n",
      "Eval Loss:  0.3397027850151062\n",
      "Eval Loss:  0.31132498383522034\n",
      "Eval Loss:  0.4029632806777954\n",
      "Eval Loss:  0.28288453817367554\n",
      "Eval Loss:  0.38537049293518066\n",
      "Eval Loss:  0.24739134311676025\n",
      "Eval Loss:  0.25862917304039\n",
      "Eval Loss:  0.28424325585365295\n",
      "Eval Loss:  0.2754775583744049\n",
      "Eval Loss:  0.2787545323371887\n",
      "Eval Loss:  0.38861405849456787\n",
      "Eval Loss:  0.34908628463745117\n",
      "Eval Loss:  0.1985882818698883\n",
      "Eval Loss:  0.36083197593688965\n",
      "Eval Loss:  0.27835699915885925\n",
      "Eval Loss:  0.29477930068969727\n",
      "Eval Loss:  0.26489582657814026\n",
      "Eval Loss:  0.22669290006160736\n",
      "Eval Loss:  0.24903100728988647\n",
      "Eval Loss:  0.19159892201423645\n",
      "[[16460   567]\n",
      " [ 3105  9388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     17027\n",
      "           1       0.94      0.75      0.84     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.89      0.86      0.87     29520\n",
      "weighted avg       0.88      0.88      0.87     29520\n",
      "\n",
      "acc:  0.875609756097561\n",
      "pre:  0.9430436966348569\n",
      "rec:  0.7514608180581125\n",
      "ma F1:  0.8680360748611338\n",
      "mi F1:  0.875609756097561\n",
      "we F1:  0.872891712690031\n",
      "29520 462\n",
      "Loss:  0.07838521897792816\n",
      "Loss:  0.06142329052090645\n",
      "Loss:  0.06237006187438965\n",
      "18 **********\n",
      "Epoch:  1261.72340798378  fold:  4  kers:  128\n",
      "epoch:  19\n",
      "29520 462\n",
      "Loss:  0.034636665135622025\n",
      "Loss:  0.0657358318567276\n",
      "Loss:  0.06903573125600815\n",
      "19 **********\n",
      "Epoch:  1314.6788160800934  fold:  4  kers:  128\n",
      "epoch:  20\n",
      "29520 462\n",
      "Loss:  0.04096423462033272\n",
      "Loss:  0.0546531081199646\n",
      "Loss:  0.06683354824781418\n",
      "20 **********\n",
      "Epoch:  1367.663146018982  fold:  4  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.10536717623472214\n",
      "Eval Loss:  0.21629023551940918\n",
      "Eval Loss:  0.022580716758966446\n",
      "[[3018  119]\n",
      " [ 203   31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.21      0.13      0.16       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.57      0.55      0.56      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9044793829724117\n",
      "pre:  0.20666666666666667\n",
      "rec:  0.13247863247863248\n",
      "ma F1:  0.5554067382300514\n",
      "mi F1:  0.9044793829724117\n",
      "we F1:  0.8946628104386461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23024341464042664\n",
      "Eval Loss:  0.2329375445842743\n",
      "Eval Loss:  0.18679696321487427\n",
      "Eval Loss:  0.258331835269928\n",
      "Eval Loss:  0.21099618077278137\n",
      "Eval Loss:  0.25554779171943665\n",
      "Eval Loss:  0.21795159578323364\n",
      "Eval Loss:  0.23554253578186035\n",
      "Eval Loss:  0.2615520656108856\n",
      "Eval Loss:  0.31516799330711365\n",
      "Eval Loss:  0.34858784079551697\n",
      "Eval Loss:  0.2323429137468338\n",
      "Eval Loss:  0.3158555328845978\n",
      "Eval Loss:  0.23695753514766693\n",
      "Eval Loss:  0.20046980679035187\n",
      "Eval Loss:  0.22250418365001678\n",
      "Eval Loss:  0.23445773124694824\n",
      "Eval Loss:  0.19806094467639923\n",
      "Eval Loss:  0.30259501934051514\n",
      "Eval Loss:  0.2951332628726959\n",
      "Eval Loss:  0.16372643411159515\n",
      "Eval Loss:  0.32014966011047363\n",
      "Eval Loss:  0.24953843653202057\n",
      "Eval Loss:  0.26814988255500793\n",
      "Eval Loss:  0.2577248513698578\n",
      "Eval Loss:  0.2131415456533432\n",
      "Eval Loss:  0.2002960741519928\n",
      "Eval Loss:  0.15750610828399658\n",
      "[[16084   943]\n",
      " [ 2020 10473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     17027\n",
      "           1       0.92      0.84      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.89      0.90     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.8996273712737127\n",
      "pre:  0.91739663629993\n",
      "rec:  0.8383094532938445\n",
      "ma F1:  0.8958651536664252\n",
      "mi F1:  0.8996273712737127\n",
      "we F1:  0.8989052346914549\n",
      "29520 462\n",
      "Loss:  0.053019873797893524\n",
      "Loss:  0.04338281229138374\n",
      "Loss:  0.07222980260848999\n",
      "21 **********\n",
      "Epoch:  1460.9098238945007  fold:  4  kers:  128\n",
      "epoch:  22\n",
      "29520 462\n",
      "Loss:  0.08307135850191116\n",
      "Loss:  0.09083688259124756\n",
      "Loss:  0.09957997500896454\n",
      "22 **********\n",
      "Epoch:  1513.8303248882294  fold:  4  kers:  128\n",
      "epoch:  23\n",
      "29520 462\n",
      "Loss:  0.05739310756325722\n",
      "Loss:  0.07862747460603714\n",
      "Loss:  0.04523065686225891\n",
      "23 **********\n",
      "Epoch:  1566.7308797836304  fold:  4  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.09529508650302887\n",
      "Eval Loss:  0.14510324597358704\n",
      "Eval Loss:  0.011281239800155163\n",
      "[[3068   69]\n",
      " [ 219   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.18      0.06      0.09       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.56      0.52      0.52      3371\n",
      "weighted avg       0.88      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9145654108573124\n",
      "pre:  0.17857142857142858\n",
      "rec:  0.0641025641025641\n",
      "ma F1:  0.5247538710965953\n",
      "mi F1:  0.9145654108573124\n",
      "we F1:  0.895413189775063\n",
      "Eval Loss:  0.3099105656147003\n",
      "Eval Loss:  0.31828272342681885\n",
      "Eval Loss:  0.23672974109649658\n",
      "Eval Loss:  0.34205159544944763\n",
      "Eval Loss:  0.2649405896663666\n",
      "Eval Loss:  0.3178529441356659\n",
      "Eval Loss:  0.3344930410385132\n",
      "Eval Loss:  0.25953152775764465\n",
      "Eval Loss:  0.3530934751033783\n",
      "Eval Loss:  0.3070409297943115\n",
      "Eval Loss:  0.4027162194252014\n",
      "Eval Loss:  0.26544493436813354\n",
      "Eval Loss:  0.38567519187927246\n",
      "Eval Loss:  0.2590464651584625\n",
      "Eval Loss:  0.27418190240859985\n",
      "Eval Loss:  0.32544049620628357\n",
      "Eval Loss:  0.2785913944244385\n",
      "Eval Loss:  0.2944982945919037\n",
      "Eval Loss:  0.3812730312347412\n",
      "Eval Loss:  0.3417859971523285\n",
      "Eval Loss:  0.202159583568573\n",
      "Eval Loss:  0.3589394986629486\n",
      "Eval Loss:  0.2892475128173828\n",
      "Eval Loss:  0.3002336025238037\n",
      "Eval Loss:  0.2757728099822998\n",
      "Eval Loss:  0.22392182052135468\n",
      "Eval Loss:  0.24649931490421295\n",
      "Eval Loss:  0.21501298248767853\n",
      "[[16580   447]\n",
      " [ 3309  9184]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     17027\n",
      "           1       0.95      0.74      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.89      0.85      0.86     29520\n",
      "weighted avg       0.88      0.87      0.87     29520\n",
      "\n",
      "acc:  0.8727642276422765\n",
      "pre:  0.9535873741044544\n",
      "rec:  0.7351316737372929\n",
      "ma F1:  0.8642425569342422\n",
      "mi F1:  0.8727642276422765\n",
      "we F1:  0.8694666314326505\n",
      "29520 462\n",
      "Loss:  0.0659678727388382\n",
      "Loss:  0.06288135796785355\n",
      "Loss:  0.07084069401025772\n",
      "24 **********\n",
      "Epoch:  1660.0473709106445  fold:  4  kers:  128\n",
      "epoch:  25\n",
      "29520 462\n",
      "Loss:  0.06381528079509735\n",
      "Loss:  0.0695953294634819\n",
      "Loss:  0.058555155992507935\n",
      "25 **********\n",
      "Epoch:  1712.9628853797913  fold:  4  kers:  128\n",
      "epoch:  26\n",
      "29520 462\n",
      "Loss:  0.05753812566399574\n",
      "Loss:  0.06681228429079056\n",
      "Loss:  0.05317773297429085\n",
      "26 **********\n",
      "Epoch:  1765.8953545093536  fold:  4  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.08233343064785004\n",
      "Eval Loss:  0.35318219661712646\n",
      "Eval Loss:  0.01841462031006813\n",
      "[[2954  183]\n",
      " [ 197   37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.17      0.16      0.16       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.55      0.55      0.55      3371\n",
      "weighted avg       0.88      0.89      0.89      3371\n",
      "\n",
      "acc:  0.8872738059922871\n",
      "pre:  0.16818181818181818\n",
      "rec:  0.1581196581196581\n",
      "ma F1:  0.5512815123695508\n",
      "mi F1:  0.8872738059922871\n",
      "we F1:  0.8856612272776082\n",
      "Eval Loss:  0.21782541275024414\n",
      "Eval Loss:  0.22460226714611053\n",
      "Eval Loss:  0.18345777690410614\n",
      "Eval Loss:  0.26627838611602783\n",
      "Eval Loss:  0.2271789163351059\n",
      "Eval Loss:  0.27088701725006104\n",
      "Eval Loss:  0.21950207650661469\n",
      "Eval Loss:  0.222866490483284\n",
      "Eval Loss:  0.22882889211177826\n",
      "Eval Loss:  0.25325536727905273\n",
      "Eval Loss:  0.32187551259994507\n",
      "Eval Loss:  0.20216959714889526\n",
      "Eval Loss:  0.314231812953949\n",
      "Eval Loss:  0.2271752953529358\n",
      "Eval Loss:  0.19439616799354553\n",
      "Eval Loss:  0.1947726607322693\n",
      "Eval Loss:  0.19267737865447998\n",
      "Eval Loss:  0.2113519310951233\n",
      "Eval Loss:  0.2851105034351349\n",
      "Eval Loss:  0.28269049525260925\n",
      "Eval Loss:  0.16463445127010345\n",
      "Eval Loss:  0.3159830570220947\n",
      "Eval Loss:  0.2057911902666092\n",
      "Eval Loss:  0.24643740057945251\n",
      "Eval Loss:  0.24411262571811676\n",
      "Eval Loss:  0.17792104184627533\n",
      "Eval Loss:  0.2061433643102646\n",
      "Eval Loss:  0.15375398099422455\n",
      "[[16156   871]\n",
      " [ 1933 10560]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17027\n",
      "           1       0.92      0.85      0.88     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.91      0.90     29520\n",
      "\n",
      "acc:  0.9050135501355013\n",
      "pre:  0.9238036917155105\n",
      "rec:  0.8452733530777236\n",
      "ma F1:  0.9014729389773772\n",
      "mi F1:  0.9050135501355013\n",
      "we F1:  0.9043416185683235\n",
      "29520 462\n",
      "Loss:  0.06078963726758957\n",
      "Loss:  0.05204666033387184\n",
      "Loss:  0.0477774403989315\n",
      "27 **********\n",
      "Epoch:  1859.2018718719482  fold:  4  kers:  128\n",
      "epoch:  28\n",
      "29520 462\n",
      "Loss:  0.06236625835299492\n",
      "Loss:  0.06086452305316925\n",
      "Loss:  0.049729179590940475\n",
      "28 **********\n",
      "Epoch:  1919.966331243515  fold:  4  kers:  128\n",
      "epoch:  29\n",
      "29520 462\n",
      "Loss:  0.056552108377218246\n",
      "Loss:  0.06620560586452484\n",
      "Loss:  0.0687161237001419\n",
      "29 **********\n",
      "Epoch:  1972.9167520999908  fold:  4  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.07092887908220291\n",
      "Eval Loss:  0.21485182642936707\n",
      "Eval Loss:  0.018521055579185486\n",
      "[[3015  122]\n",
      " [ 197   37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.23      0.16      0.19       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.59      0.56      0.57      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9053693266093148\n",
      "pre:  0.23270440251572327\n",
      "rec:  0.1581196581196581\n",
      "ma F1:  0.5690255162300407\n",
      "mi F1:  0.9053693266093148\n",
      "we F1:  0.8968986127817641\n",
      "Eval Loss:  0.18941731750965118\n",
      "Eval Loss:  0.20654743909835815\n",
      "Eval Loss:  0.18745870888233185\n",
      "Eval Loss:  0.25036948919296265\n",
      "Eval Loss:  0.2019965648651123\n",
      "Eval Loss:  0.2638589143753052\n",
      "Eval Loss:  0.20574374496936798\n",
      "Eval Loss:  0.21319425106048584\n",
      "Eval Loss:  0.24432028830051422\n",
      "Eval Loss:  0.24758505821228027\n",
      "Eval Loss:  0.3588484227657318\n",
      "Eval Loss:  0.2017875611782074\n",
      "Eval Loss:  0.30386611819267273\n",
      "Eval Loss:  0.24917666614055634\n",
      "Eval Loss:  0.15076039731502533\n",
      "Eval Loss:  0.21146635711193085\n",
      "Eval Loss:  0.214742049574852\n",
      "Eval Loss:  0.2122989445924759\n",
      "Eval Loss:  0.2927708029747009\n",
      "Eval Loss:  0.2922326922416687\n",
      "Eval Loss:  0.14105279743671417\n",
      "Eval Loss:  0.31698504090309143\n",
      "Eval Loss:  0.21189486980438232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.262890100479126\n",
      "Eval Loss:  0.2605149745941162\n",
      "Eval Loss:  0.1860279142856598\n",
      "Eval Loss:  0.19995710253715515\n",
      "Eval Loss:  0.16152828931808472\n",
      "[[16173   854]\n",
      " [ 1923 10570]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17027\n",
      "           1       0.93      0.85      0.88     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9059281842818429\n",
      "pre:  0.9252450980392157\n",
      "rec:  0.8460738013287441\n",
      "ma F1:  0.9024125599279854\n",
      "mi F1:  0.9059281842818429\n",
      "we F1:  0.9052574360337127\n",
      "29520 462\n",
      "Loss:  0.05134831741452217\n",
      "Loss:  0.05869108438491821\n",
      "Loss:  0.0744553804397583\n",
      "30 **********\n",
      "Epoch:  2066.3259947299957  fold:  4  kers:  128\n",
      "epoch:  31\n",
      "29520 462\n",
      "Loss:  0.052244704216718674\n",
      "Loss:  0.045569922775030136\n",
      "Loss:  0.05947897583246231\n",
      "31 **********\n",
      "Epoch:  2119.2694351673126  fold:  4  kers:  128\n",
      "epoch:  32\n",
      "29520 462\n",
      "Loss:  0.06957864761352539\n",
      "Loss:  0.05890161544084549\n",
      "Loss:  0.08231461048126221\n",
      "32 **********\n",
      "Epoch:  2172.1580214500427  fold:  4  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.09441273659467697\n",
      "Eval Loss:  0.2232334017753601\n",
      "Eval Loss:  0.013876033946871758\n",
      "[[3011  126]\n",
      " [ 201   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.21      0.14      0.17       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.57      0.55      0.56      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9029961435775734\n",
      "pre:  0.20754716981132076\n",
      "rec:  0.14102564102564102\n",
      "ma F1:  0.5582173787060293\n",
      "mi F1:  0.9029961435775734\n",
      "we F1:  0.894312998055288\n",
      "Eval Loss:  0.2308330088853836\n",
      "Eval Loss:  0.24027396738529205\n",
      "Eval Loss:  0.1886633187532425\n",
      "Eval Loss:  0.25706711411476135\n",
      "Eval Loss:  0.19978073239326477\n",
      "Eval Loss:  0.2620461583137512\n",
      "Eval Loss:  0.21197910606861115\n",
      "Eval Loss:  0.19003024697303772\n",
      "Eval Loss:  0.24770130217075348\n",
      "Eval Loss:  0.2173386663198471\n",
      "Eval Loss:  0.3520257771015167\n",
      "Eval Loss:  0.21105016767978668\n",
      "Eval Loss:  0.3097301423549652\n",
      "Eval Loss:  0.2395433932542801\n",
      "Eval Loss:  0.200132817029953\n",
      "Eval Loss:  0.23196624219417572\n",
      "Eval Loss:  0.21042300760746002\n",
      "Eval Loss:  0.231868177652359\n",
      "Eval Loss:  0.311329185962677\n",
      "Eval Loss:  0.2797594666481018\n",
      "Eval Loss:  0.1470808982849121\n",
      "Eval Loss:  0.3319302201271057\n",
      "Eval Loss:  0.19722966849803925\n",
      "Eval Loss:  0.25601476430892944\n",
      "Eval Loss:  0.21982555091381073\n",
      "Eval Loss:  0.15707047283649445\n",
      "Eval Loss:  0.19543886184692383\n",
      "Eval Loss:  0.1491672694683075\n",
      "[[16410   617]\n",
      " [ 2224 10269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17027\n",
      "           1       0.94      0.82      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.91      0.89      0.90     29520\n",
      "weighted avg       0.91      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9037601626016261\n",
      "pre:  0.943321697593239\n",
      "rec:  0.8219803089730249\n",
      "ma F1:  0.8994069124186024\n",
      "mi F1:  0.9037601626016261\n",
      "we F1:  0.9026209877043585\n",
      "29520 462\n",
      "Loss:  0.07168860733509064\n",
      "Loss:  0.05273452773690224\n",
      "Loss:  0.06506598740816116\n",
      "33 **********\n",
      "Epoch:  2265.730827331543  fold:  4  kers:  128\n",
      "epoch:  34\n",
      "29520 462\n",
      "Loss:  0.09680229425430298\n",
      "Loss:  0.056970153003931046\n",
      "Loss:  0.04583878070116043\n",
      "34 **********\n",
      "Epoch:  2318.785968542099  fold:  4  kers:  128\n",
      "epoch:  35\n",
      "29520 462\n",
      "Loss:  0.06526556611061096\n",
      "Loss:  0.106438547372818\n",
      "Loss:  0.06433580070734024\n",
      "35 **********\n",
      "Epoch:  2371.8012161254883  fold:  4  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.07965993136167526\n",
      "Eval Loss:  0.3294130861759186\n",
      "Eval Loss:  0.014233877882361412\n",
      "[[2949  188]\n",
      " [ 185   49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.21      0.21      0.21       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.57      0.57      0.57      3371\n",
      "weighted avg       0.89      0.89      0.89      3371\n",
      "\n",
      "acc:  0.8893503411450608\n",
      "pre:  0.20675105485232068\n",
      "rec:  0.2094017094017094\n",
      "ma F1:  0.5742938969224765\n",
      "mi F1:  0.8893503411450608\n",
      "we F1:  0.8896762616046016\n",
      "Eval Loss:  0.1925227791070938\n",
      "Eval Loss:  0.20624884963035583\n",
      "Eval Loss:  0.15651139616966248\n",
      "Eval Loss:  0.21298618614673615\n",
      "Eval Loss:  0.19475401937961578\n",
      "Eval Loss:  0.2141500860452652\n",
      "Eval Loss:  0.1731930524110794\n",
      "Eval Loss:  0.16778798401355743\n",
      "Eval Loss:  0.18663901090621948\n",
      "Eval Loss:  0.20960257947444916\n",
      "Eval Loss:  0.3585938811302185\n",
      "Eval Loss:  0.20598186552524567\n",
      "Eval Loss:  0.26890677213668823\n",
      "Eval Loss:  0.23263543844223022\n",
      "Eval Loss:  0.1536204218864441\n",
      "Eval Loss:  0.18389715254306793\n",
      "Eval Loss:  0.18514388799667358\n",
      "Eval Loss:  0.16611021757125854\n",
      "Eval Loss:  0.2488686442375183\n",
      "Eval Loss:  0.26318812370300293\n",
      "Eval Loss:  0.16695095598697662\n",
      "Eval Loss:  0.27724674344062805\n",
      "Eval Loss:  0.1726521998643875\n",
      "Eval Loss:  0.24097907543182373\n",
      "Eval Loss:  0.24505463242530823\n",
      "Eval Loss:  0.1879483461380005\n",
      "Eval Loss:  0.18851131200790405\n",
      "Eval Loss:  0.16225087642669678\n",
      "[[15847  1180]\n",
      " [ 1314 11179]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     17027\n",
      "           1       0.90      0.89      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.91      0.91      0.91     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9155149051490515\n",
      "pre:  0.9045230196617849\n",
      "rec:  0.8948210998158969\n",
      "ma F1:  0.9133481654003142\n",
      "mi F1:  0.9155149051490516\n",
      "we F1:  0.9154527065358701\n",
      "29520 462\n",
      "Loss:  0.0582554005086422\n",
      "Loss:  0.040681444108486176\n",
      "Loss:  0.0724620595574379\n",
      "36 **********\n",
      "Epoch:  2465.0758187770844  fold:  4  kers:  128\n",
      "epoch:  37\n",
      "29520 462\n",
      "Loss:  0.05518535152077675\n",
      "Loss:  0.07568339258432388\n",
      "Loss:  0.10490014404058456\n",
      "37 **********\n",
      "Epoch:  2518.09405875206  fold:  4  kers:  128\n",
      "epoch:  38\n",
      "29520 462\n",
      "Loss:  0.05380867049098015\n",
      "Loss:  0.04086516425013542\n",
      "Loss:  0.08143621683120728\n",
      "38 **********\n",
      "Epoch:  2571.025531053543  fold:  4  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.5567597150802612\n",
      "Eval Loss:  0.1422460973262787\n",
      "Eval Loss:  0.011331652291119099\n",
      "[[2860  277]\n",
      " [ 195   39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92      3137\n",
      "           1       0.12      0.17      0.14       234\n",
      "\n",
      "    accuracy                           0.86      3371\n",
      "   macro avg       0.53      0.54      0.53      3371\n",
      "weighted avg       0.88      0.86      0.87      3371\n",
      "\n",
      "acc:  0.859982201127262\n",
      "pre:  0.12341772151898735\n",
      "rec:  0.16666666666666666\n",
      "ma F1:  0.5327953958186517\n",
      "mi F1:  0.859982201127262\n",
      "we F1:  0.8694927711504119\n",
      "Eval Loss:  0.2154691368341446\n",
      "Eval Loss:  0.23453855514526367\n",
      "Eval Loss:  0.18707869946956635\n",
      "Eval Loss:  0.26886987686157227\n",
      "Eval Loss:  0.1838488131761551\n",
      "Eval Loss:  0.2274939864873886\n",
      "Eval Loss:  0.23460683226585388\n",
      "Eval Loss:  0.1711447685956955\n",
      "Eval Loss:  0.21554318070411682\n",
      "Eval Loss:  0.17113091051578522\n",
      "Eval Loss:  0.3704850375652313\n",
      "Eval Loss:  0.21271324157714844\n",
      "Eval Loss:  0.2861577868461609\n",
      "Eval Loss:  0.22794176638126373\n",
      "Eval Loss:  0.15652231872081757\n",
      "Eval Loss:  0.20622079074382782\n",
      "Eval Loss:  0.20745433866977692\n",
      "Eval Loss:  0.20463432371616364\n",
      "Eval Loss:  0.28735053539276123\n",
      "Eval Loss:  0.26935669779777527\n",
      "Eval Loss:  0.16428759694099426\n",
      "Eval Loss:  0.3532814383506775\n",
      "Eval Loss:  0.18282827734947205\n",
      "Eval Loss:  0.23100870847702026\n",
      "Eval Loss:  0.20048658549785614\n",
      "Eval Loss:  0.1752169281244278\n",
      "Eval Loss:  0.17652511596679688\n",
      "Eval Loss:  0.1610618382692337\n",
      "[[16308   719]\n",
      " [ 1975 10518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     17027\n",
      "           1       0.94      0.84      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9087398373983739\n",
      "pre:  0.9360149506095933\n",
      "rec:  0.8419114704234372\n",
      "ma F1:  0.9050885761331547\n",
      "mi F1:  0.9087398373983739\n",
      "we F1:  0.9079477848683022\n",
      "29520 462\n",
      "Loss:  0.052127595990896225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.054417312145233154\n",
      "Loss:  0.026442190632224083\n",
      "39 **********\n",
      "Epoch:  2664.942416191101  fold:  4  kers:  128\n",
      "epoch:  40\n",
      "29520 462\n",
      "Loss:  0.050890762358903885\n",
      "Loss:  0.060442931950092316\n",
      "Loss:  0.09162731468677521\n",
      "40 **********\n",
      "Epoch:  2717.892838001251  fold:  4  kers:  128\n",
      "epoch:  41\n",
      "29520 462\n",
      "Loss:  0.04528442770242691\n",
      "Loss:  0.07124115526676178\n",
      "Loss:  0.05713323503732681\n",
      "41 **********\n",
      "Epoch:  2770.8372750282288  fold:  4  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.11398101598024368\n",
      "Eval Loss:  0.17622560262680054\n",
      "Eval Loss:  0.015697594732046127\n",
      "[[3021  116]\n",
      " [ 191   43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.27      0.18      0.22       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.61      0.57      0.59      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9089291011569267\n",
      "pre:  0.27044025157232704\n",
      "rec:  0.18376068376068377\n",
      "ma F1:  0.5852377225160581\n",
      "mi F1:  0.9089291011569267\n",
      "we F1:  0.9007770348714784\n",
      "Eval Loss:  0.18767890334129333\n",
      "Eval Loss:  0.212600976228714\n",
      "Eval Loss:  0.16473500430583954\n",
      "Eval Loss:  0.25449052453041077\n",
      "Eval Loss:  0.15539394319057465\n",
      "Eval Loss:  0.218262180685997\n",
      "Eval Loss:  0.1777888834476471\n",
      "Eval Loss:  0.19933177530765533\n",
      "Eval Loss:  0.1835293471813202\n",
      "Eval Loss:  0.19193404912948608\n",
      "Eval Loss:  0.33048903942108154\n",
      "Eval Loss:  0.1559872329235077\n",
      "Eval Loss:  0.2868972420692444\n",
      "Eval Loss:  0.21679653227329254\n",
      "Eval Loss:  0.14403100311756134\n",
      "Eval Loss:  0.16749240458011627\n",
      "Eval Loss:  0.16725249588489532\n",
      "Eval Loss:  0.15398485958576202\n",
      "Eval Loss:  0.2398790717124939\n",
      "Eval Loss:  0.3005136549472809\n",
      "Eval Loss:  0.13874082267284393\n",
      "Eval Loss:  0.3070250153541565\n",
      "Eval Loss:  0.15021741390228271\n",
      "Eval Loss:  0.20343944430351257\n",
      "Eval Loss:  0.18611547350883484\n",
      "Eval Loss:  0.15484879910945892\n",
      "Eval Loss:  0.17752237617969513\n",
      "Eval Loss:  0.14763472974300385\n",
      "[[16153   874]\n",
      " [ 1574 10919]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     17027\n",
      "           1       0.93      0.87      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9170731707317074\n",
      "pre:  0.9258882387857204\n",
      "rec:  0.8740094452893621\n",
      "ma F1:  0.9143816253333491\n",
      "mi F1:  0.9170731707317074\n",
      "we F1:  0.9167132009611971\n",
      "29520 462\n",
      "Loss:  0.03794780746102333\n",
      "Loss:  0.07561861723661423\n",
      "Loss:  0.05254857987165451\n",
      "42 **********\n",
      "Epoch:  2864.297381401062  fold:  4  kers:  128\n",
      "epoch:  43\n",
      "29520 462\n",
      "Loss:  0.0439121276140213\n",
      "Loss:  0.0631544291973114\n",
      "Loss:  0.028872519731521606\n",
      "43 **********\n",
      "Epoch:  2917.237829685211  fold:  4  kers:  128\n",
      "epoch:  44\n",
      "29520 462\n",
      "Loss:  0.05666758865118027\n",
      "Loss:  0.03937535732984543\n",
      "Loss:  0.04414521902799606\n",
      "44 **********\n",
      "Epoch:  2970.211189508438  fold:  4  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.09640635550022125\n",
      "Eval Loss:  0.1422896534204483\n",
      "Eval Loss:  0.009895147755742073\n",
      "[[3045   92]\n",
      " [ 185   49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      3137\n",
      "           1       0.35      0.21      0.26       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.65      0.59      0.61      3371\n",
      "weighted avg       0.90      0.92      0.91      3371\n",
      "\n",
      "acc:  0.9178285375259567\n",
      "pre:  0.3475177304964539\n",
      "rec:  0.2094017094017094\n",
      "ma F1:  0.6089138788545102\n",
      "mi F1:  0.9178285375259567\n",
      "we F1:  0.9082393975872236\n",
      "Eval Loss:  0.2274855077266693\n",
      "Eval Loss:  0.2168574333190918\n",
      "Eval Loss:  0.19705310463905334\n",
      "Eval Loss:  0.22811204195022583\n",
      "Eval Loss:  0.17753423750400543\n",
      "Eval Loss:  0.25049614906311035\n",
      "Eval Loss:  0.19951693713665009\n",
      "Eval Loss:  0.2029079794883728\n",
      "Eval Loss:  0.18981781601905823\n",
      "Eval Loss:  0.20627360045909882\n",
      "Eval Loss:  0.368998259305954\n",
      "Eval Loss:  0.17634542286396027\n",
      "Eval Loss:  0.30535537004470825\n",
      "Eval Loss:  0.25525981187820435\n",
      "Eval Loss:  0.1599106639623642\n",
      "Eval Loss:  0.18711525201797485\n",
      "Eval Loss:  0.2170025110244751\n",
      "Eval Loss:  0.17601585388183594\n",
      "Eval Loss:  0.23005835711956024\n",
      "Eval Loss:  0.25314411520957947\n",
      "Eval Loss:  0.13318659365177155\n",
      "Eval Loss:  0.31840646266937256\n",
      "Eval Loss:  0.1394921839237213\n",
      "Eval Loss:  0.2295636534690857\n",
      "Eval Loss:  0.16918468475341797\n",
      "Eval Loss:  0.13922210037708282\n",
      "Eval Loss:  0.1958618015050888\n",
      "Eval Loss:  0.13640934228897095\n",
      "[[16204   823]\n",
      " [ 1641 10852]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     17027\n",
      "           1       0.93      0.87      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9165311653116531\n",
      "pre:  0.9295074946466809\n",
      "rec:  0.8686464420075242\n",
      "ma F1:  0.9136942982057463\n",
      "mi F1:  0.9165311653116531\n",
      "we F1:  0.9160975783735681\n",
      "29520 462\n",
      "Loss:  0.053878411650657654\n",
      "Loss:  0.06291919201612473\n",
      "Loss:  0.0889768898487091\n",
      "45 **********\n",
      "Epoch:  3063.5506188869476  fold:  4  kers:  128\n",
      "epoch:  46\n",
      "29520 462\n",
      "Loss:  0.05913960561156273\n",
      "Loss:  0.035100359469652176\n",
      "Loss:  0.041008446365594864\n",
      "46 **********\n",
      "Epoch:  3116.5459203720093  fold:  4  kers:  128\n",
      "epoch:  47\n",
      "29520 462\n",
      "Loss:  0.04257604479789734\n",
      "Loss:  0.10643470287322998\n",
      "Loss:  0.0478401780128479\n",
      "47 **********\n",
      "Epoch:  3169.5691471099854  fold:  4  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.0619172677397728\n",
      "Eval Loss:  0.3430687189102173\n",
      "Eval Loss:  0.018282921984791756\n",
      "[[2938  199]\n",
      " [ 197   37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.16      0.16      0.16       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.55      0.55      0.55      3371\n",
      "weighted avg       0.88      0.88      0.88      3371\n",
      "\n",
      "acc:  0.8825274399288046\n",
      "pre:  0.15677966101694915\n",
      "rec:  0.1581196581196581\n",
      "ma F1:  0.5471545267042988\n",
      "mi F1:  0.8825274399288046\n",
      "we F1:  0.8827586518648435\n",
      "Eval Loss:  0.2245783507823944\n",
      "Eval Loss:  0.22456759214401245\n",
      "Eval Loss:  0.16161581873893738\n",
      "Eval Loss:  0.24079547822475433\n",
      "Eval Loss:  0.16132105886936188\n",
      "Eval Loss:  0.22186130285263062\n",
      "Eval Loss:  0.19062113761901855\n",
      "Eval Loss:  0.16130433976650238\n",
      "Eval Loss:  0.19957812130451202\n",
      "Eval Loss:  0.19405007362365723\n",
      "Eval Loss:  0.3252263069152832\n",
      "Eval Loss:  0.18233126401901245\n",
      "Eval Loss:  0.285830557346344\n",
      "Eval Loss:  0.23357829451560974\n",
      "Eval Loss:  0.1458788365125656\n",
      "Eval Loss:  0.19369468092918396\n",
      "Eval Loss:  0.1938028633594513\n",
      "Eval Loss:  0.18875455856323242\n",
      "Eval Loss:  0.26284557580947876\n",
      "Eval Loss:  0.23678246140480042\n",
      "Eval Loss:  0.13536548614501953\n",
      "Eval Loss:  0.28839361667633057\n",
      "Eval Loss:  0.16462068259716034\n",
      "Eval Loss:  0.2359001487493515\n",
      "Eval Loss:  0.18324925005435944\n",
      "Eval Loss:  0.1472267061471939\n",
      "Eval Loss:  0.19270206987857819\n",
      "Eval Loss:  0.15449902415275574\n",
      "[[16393   634]\n",
      " [ 1884 10609]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     17027\n",
      "           1       0.94      0.85      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.92      0.91      0.91     29520\n",
      "weighted avg       0.92      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9147018970189702\n",
      "pre:  0.9436093569332029\n",
      "rec:  0.8491955495077244\n",
      "ma F1:  0.9112965255471643\n",
      "mi F1:  0.9147018970189702\n",
      "we F1:  0.9139659505563565\n",
      "29520 462\n",
      "Loss:  0.046017441898584366\n",
      "Loss:  0.03831051290035248\n",
      "Loss:  0.07109588384628296\n",
      "48 **********\n",
      "Epoch:  3263.059173345566  fold:  4  kers:  128\n",
      "epoch:  49\n",
      "29520 462\n",
      "Loss:  0.04904215782880783\n",
      "Loss:  0.05214580148458481\n",
      "Loss:  0.04843165725469589\n",
      "49 **********\n",
      "Epoch:  3316.050485610962  fold:  4  kers:  128\n",
      "epoch:  50\n",
      "29520 462\n",
      "Loss:  0.10351134836673737\n",
      "Loss:  0.06359497457742691\n",
      "Loss:  0.058081965893507004\n",
      "50 **********\n",
      "Epoch:  3369.0288321971893  fold:  4  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.13056230545043945\n",
      "Eval Loss:  0.20753616094589233\n",
      "Eval Loss:  0.012380107305943966\n",
      "[[2989  148]\n",
      " [ 184   50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      3137\n",
      "           1       0.25      0.21      0.23       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.60      0.58      0.59      3371\n",
      "weighted avg       0.89      0.90      0.90      3371\n",
      "\n",
      "acc:  0.9015129041827351\n",
      "pre:  0.25252525252525254\n",
      "rec:  0.21367521367521367\n",
      "ma F1:  0.5894332922462875\n",
      "mi F1:  0.9015129041827351\n",
      "we F1:  0.8976902209470384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18251349031925201\n",
      "Eval Loss:  0.18614661693572998\n",
      "Eval Loss:  0.1345382183790207\n",
      "Eval Loss:  0.22144098579883575\n",
      "Eval Loss:  0.14876234531402588\n",
      "Eval Loss:  0.18710343539714813\n",
      "Eval Loss:  0.17203551530838013\n",
      "Eval Loss:  0.15036410093307495\n",
      "Eval Loss:  0.15930117666721344\n",
      "Eval Loss:  0.16143004596233368\n",
      "Eval Loss:  0.29760104417800903\n",
      "Eval Loss:  0.1385653167963028\n",
      "Eval Loss:  0.23919880390167236\n",
      "Eval Loss:  0.20211374759674072\n",
      "Eval Loss:  0.1210625171661377\n",
      "Eval Loss:  0.1598137468099594\n",
      "Eval Loss:  0.16542911529541016\n",
      "Eval Loss:  0.1564197689294815\n",
      "Eval Loss:  0.19092369079589844\n",
      "Eval Loss:  0.2756776809692383\n",
      "Eval Loss:  0.1347101777791977\n",
      "Eval Loss:  0.26448050141334534\n",
      "Eval Loss:  0.11351770162582397\n",
      "Eval Loss:  0.19081395864486694\n",
      "Eval Loss:  0.16812963783740997\n",
      "Eval Loss:  0.1517844796180725\n",
      "Eval Loss:  0.15941065549850464\n",
      "Eval Loss:  0.14099588990211487\n",
      "[[16126   901]\n",
      " [ 1295 11198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     17027\n",
      "           1       0.93      0.90      0.91     12493\n",
      "\n",
      "    accuracy                           0.93     29520\n",
      "   macro avg       0.93      0.92      0.92     29520\n",
      "weighted avg       0.93      0.93      0.93     29520\n",
      "\n",
      "acc:  0.925609756097561\n",
      "pre:  0.9255310356227787\n",
      "rec:  0.896341951492836\n",
      "ma F1:  0.9234772046449236\n",
      "mi F1:  0.925609756097561\n",
      "we F1:  0.9254392558393753\n",
      "29520 462\n",
      "Loss:  0.05198242515325546\n",
      "Loss:  0.038632750511169434\n",
      "Loss:  0.03181608393788338\n",
      "51 **********\n",
      "Epoch:  3462.7003734111786  fold:  4  kers:  128\n",
      "epoch:  52\n",
      "29520 462\n",
      "Loss:  0.053435515612363815\n",
      "Loss:  0.04397593066096306\n",
      "Loss:  0.04953421279788017\n",
      "52 **********\n",
      "Epoch:  3515.830314874649  fold:  4  kers:  128\n",
      "epoch:  53\n",
      "29520 462\n",
      "Loss:  0.05296168848872185\n",
      "Loss:  0.0450323224067688\n",
      "Loss:  0.03894839808344841\n",
      "53 **********\n",
      "Epoch:  3568.8864538669586  fold:  4  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.07552783936262131\n",
      "Eval Loss:  0.23050732910633087\n",
      "Eval Loss:  0.012730206362903118\n",
      "[[2970  167]\n",
      " [ 182   52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      3137\n",
      "           1       0.24      0.22      0.23       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.59      0.58      0.59      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.8964698902402848\n",
      "pre:  0.2374429223744292\n",
      "rec:  0.2222222222222222\n",
      "ma F1:  0.5870434273795972\n",
      "mi F1:  0.8964698902402848\n",
      "we F1:  0.8948792812810968\n",
      "Eval Loss:  0.1722264587879181\n",
      "Eval Loss:  0.1670737862586975\n",
      "Eval Loss:  0.15423515439033508\n",
      "Eval Loss:  0.23285838961601257\n",
      "Eval Loss:  0.14166758954524994\n",
      "Eval Loss:  0.18093839287757874\n",
      "Eval Loss:  0.1568204015493393\n",
      "Eval Loss:  0.17081962525844574\n",
      "Eval Loss:  0.15391221642494202\n",
      "Eval Loss:  0.2053404003381729\n",
      "Eval Loss:  0.30706483125686646\n",
      "Eval Loss:  0.1404396891593933\n",
      "Eval Loss:  0.20476073026657104\n",
      "Eval Loss:  0.2153249830007553\n",
      "Eval Loss:  0.10681973397731781\n",
      "Eval Loss:  0.16085708141326904\n",
      "Eval Loss:  0.15161240100860596\n",
      "Eval Loss:  0.13294285535812378\n",
      "Eval Loss:  0.17780137062072754\n",
      "Eval Loss:  0.27326053380966187\n",
      "Eval Loss:  0.1208396926522255\n",
      "Eval Loss:  0.26194819808006287\n",
      "Eval Loss:  0.1128809005022049\n",
      "Eval Loss:  0.17969121038913727\n",
      "Eval Loss:  0.20711801946163177\n",
      "Eval Loss:  0.1566498577594757\n",
      "Eval Loss:  0.1522832065820694\n",
      "Eval Loss:  0.1526966094970703\n",
      "[[15913  1114]\n",
      " [ 1053 11440]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     17027\n",
      "           1       0.91      0.92      0.91     12493\n",
      "\n",
      "    accuracy                           0.93     29520\n",
      "   macro avg       0.92      0.93      0.92     29520\n",
      "weighted avg       0.93      0.93      0.93     29520\n",
      "\n",
      "acc:  0.9265921409214092\n",
      "pre:  0.9112633423610005\n",
      "rec:  0.9157127991675338\n",
      "ma F1:  0.9248671169104916\n",
      "mi F1:  0.9265921409214092\n",
      "we F1:  0.9266156657290698\n",
      "29520 462\n",
      "Loss:  0.05129879713058472\n",
      "Loss:  0.06151770427823067\n",
      "Loss:  0.04507465288043022\n",
      "54 **********\n",
      "Epoch:  3662.3495519161224  fold:  4  kers:  128\n",
      "epoch:  55\n",
      "29520 462\n",
      "Loss:  0.03728308156132698\n",
      "Loss:  0.04678378999233246\n",
      "Loss:  0.0971585139632225\n",
      "55 **********\n",
      "Epoch:  3715.343856573105  fold:  4  kers:  128\n",
      "epoch:  56\n",
      "29520 462\n",
      "Loss:  0.038749806582927704\n",
      "Loss:  0.04415183141827583\n",
      "Loss:  0.039730221033096313\n",
      "56 **********\n",
      "Epoch:  3768.2962729930878  fold:  4  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.06507713347673416\n",
      "Eval Loss:  0.21111899614334106\n",
      "Eval Loss:  0.011797774583101273\n",
      "[[2996  141]\n",
      " [ 187   47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.25      0.20      0.22       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.60      0.58      0.59      3371\n",
      "weighted avg       0.89      0.90      0.90      3371\n",
      "\n",
      "acc:  0.9026994956986057\n",
      "pre:  0.25\n",
      "rec:  0.20085470085470086\n",
      "ma F1:  0.5854250404943309\n",
      "mi F1:  0.9026994956986057\n",
      "we F1:  0.8977504875808043\n",
      "Eval Loss:  0.19420187175273895\n",
      "Eval Loss:  0.18691515922546387\n",
      "Eval Loss:  0.16042622923851013\n",
      "Eval Loss:  0.2234242856502533\n",
      "Eval Loss:  0.15718790888786316\n",
      "Eval Loss:  0.18612037599086761\n",
      "Eval Loss:  0.17278814315795898\n",
      "Eval Loss:  0.15448547899723053\n",
      "Eval Loss:  0.19192782044410706\n",
      "Eval Loss:  0.17202840745449066\n",
      "Eval Loss:  0.3181949257850647\n",
      "Eval Loss:  0.15197250247001648\n",
      "Eval Loss:  0.23151801526546478\n",
      "Eval Loss:  0.21789981424808502\n",
      "Eval Loss:  0.12596188485622406\n",
      "Eval Loss:  0.16162845492362976\n",
      "Eval Loss:  0.18056461215019226\n",
      "Eval Loss:  0.1534862369298935\n",
      "Eval Loss:  0.21738921105861664\n",
      "Eval Loss:  0.2262953519821167\n",
      "Eval Loss:  0.12014583498239517\n",
      "Eval Loss:  0.26237377524375916\n",
      "Eval Loss:  0.1409914195537567\n",
      "Eval Loss:  0.179502472281456\n",
      "Eval Loss:  0.17123495042324066\n",
      "Eval Loss:  0.13088665902614594\n",
      "Eval Loss:  0.160246342420578\n",
      "Eval Loss:  0.12677061557769775\n",
      "[[16350   677]\n",
      " [ 1533 10960]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     17027\n",
      "           1       0.94      0.88      0.91     12493\n",
      "\n",
      "    accuracy                           0.93     29520\n",
      "   macro avg       0.93      0.92      0.92     29520\n",
      "weighted avg       0.93      0.93      0.92     29520\n",
      "\n",
      "acc:  0.9251355013550135\n",
      "pre:  0.9418234940276704\n",
      "rec:  0.8772912831185464\n",
      "ma F1:  0.922553560555869\n",
      "mi F1:  0.9251355013550135\n",
      "we F1:  0.9247254565824592\n",
      "29520 462\n",
      "Loss:  0.0743275061249733\n",
      "Loss:  0.05828922614455223\n",
      "Loss:  0.038229092955589294\n",
      "57 **********\n",
      "Epoch:  3861.9428803920746  fold:  4  kers:  128\n",
      "epoch:  58\n",
      "29520 462\n",
      "Loss:  0.027029726654291153\n",
      "Loss:  0.07660233229398727\n",
      "Loss:  0.05390551686286926\n",
      "58 **********\n",
      "Epoch:  3914.988048315048  fold:  4  kers:  128\n",
      "epoch:  59\n",
      "29520 462\n",
      "Loss:  0.03278501331806183\n",
      "Loss:  0.07018200308084488\n",
      "Loss:  0.057819921523332596\n",
      "59 **********\n",
      "Epoch:  3967.977365732193  fold:  4  kers:  128\n",
      "Eval Loss:  0.050294164568185806\n",
      "Eval Loss:  0.21646642684936523\n",
      "Eval Loss:  0.010329467244446278\n",
      "[[2976  161]\n",
      " [ 178   56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      3137\n",
      "           1       0.26      0.24      0.25       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.60      0.59      0.60      3371\n",
      "weighted avg       0.90      0.90      0.90      3371\n",
      "\n",
      "acc:  0.8994363690299615\n",
      "pre:  0.25806451612903225\n",
      "rec:  0.23931623931623933\n",
      "ma F1:  0.5972252621472762\n",
      "mi F1:  0.8994363690299615\n",
      "we F1:  0.8976769208049594\n",
      "update!  Acc:  0.9234648472263424\n",
      "Epoch:  3972.130262851715  fold:  4  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29673 3218\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29673 464\n",
      "Loss:  0.1729276031255722\n",
      "Loss:  0.17096871137619019\n",
      "Loss:  0.16169506311416626\n",
      "0 **********\n",
      "Epoch:  65.91176462173462  fold:  5  kers:  128\n",
      "epoch:  1\n",
      "29673 464\n",
      "Loss:  0.15075142681598663\n",
      "Loss:  0.13901111483573914\n",
      "Loss:  0.1300032138824463\n",
      "1 **********\n",
      "Epoch:  119.40872430801392  fold:  5  kers:  128\n",
      "epoch:  2\n",
      "29673 464\n",
      "Loss:  0.11672918498516083\n",
      "Loss:  0.12700015306472778\n",
      "Loss:  0.10974466055631638\n",
      "2 **********\n",
      "Epoch:  172.7540898323059  fold:  5  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.15718796849250793\n",
      "Eval Loss:  0.30836349725723267\n",
      "Eval Loss:  0.23542244732379913\n",
      "[[2832  265]\n",
      " [  50   71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95      3097\n",
      "           1       0.21      0.59      0.31       121\n",
      "\n",
      "    accuracy                           0.90      3218\n",
      "   macro avg       0.60      0.75      0.63      3218\n",
      "weighted avg       0.95      0.90      0.92      3218\n",
      "\n",
      "acc:  0.9021131137352393\n",
      "pre:  0.2113095238095238\n",
      "rec:  0.5867768595041323\n",
      "ma F1:  0.6290188526363059\n",
      "mi F1:  0.9021131137352393\n",
      "we F1:  0.9233790558345767\n",
      "update!  Acc:  0.9021131137352393\n",
      "Eval Loss:  0.474994421005249\n",
      "Eval Loss:  0.40165096521377563\n",
      "Eval Loss:  0.4573204517364502\n",
      "Eval Loss:  0.35736674070358276\n",
      "Eval Loss:  0.39449694752693176\n",
      "Eval Loss:  0.45409074425697327\n",
      "Eval Loss:  0.4268816113471985\n",
      "Eval Loss:  0.4735478460788727\n",
      "Eval Loss:  0.47149786353111267\n",
      "Eval Loss:  0.47419315576553345\n",
      "Eval Loss:  0.4076194763183594\n",
      "Eval Loss:  0.5991477370262146\n",
      "Eval Loss:  0.42436426877975464\n",
      "Eval Loss:  0.5204366445541382\n",
      "Eval Loss:  0.35810431838035583\n",
      "Eval Loss:  0.4828305244445801\n",
      "Eval Loss:  0.44542279839515686\n",
      "Eval Loss:  0.5136788487434387\n",
      "Eval Loss:  0.5333443880081177\n",
      "Eval Loss:  0.468549907207489\n",
      "Eval Loss:  0.42422133684158325\n",
      "Eval Loss:  0.4821579158306122\n",
      "Eval Loss:  0.4884006679058075\n",
      "Eval Loss:  0.37052038311958313\n",
      "Eval Loss:  0.44955670833587646\n",
      "Eval Loss:  0.4426865875720978\n",
      "Eval Loss:  0.517601490020752\n",
      "Eval Loss:  0.4638999104499817\n",
      "Eval Loss:  0.37101393938064575\n",
      "[[14729  2338]\n",
      " [ 3456  9150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84     17067\n",
      "           1       0.80      0.73      0.76     12606\n",
      "\n",
      "    accuracy                           0.80     29673\n",
      "   macro avg       0.80      0.79      0.80     29673\n",
      "weighted avg       0.80      0.80      0.80     29673\n",
      "\n",
      "acc:  0.8047383142924545\n",
      "pre:  0.796483286908078\n",
      "rec:  0.7258448357924798\n",
      "ma F1:  0.7975828620139034\n",
      "mi F1:  0.8047383142924545\n",
      "we F1:  0.8033044021850122\n",
      "29673 464\n",
      "Loss:  0.11744978278875351\n",
      "Loss:  0.07400575280189514\n",
      "Loss:  0.10280443727970123\n",
      "3 **********\n",
      "Epoch:  267.2973003387451  fold:  5  kers:  128\n",
      "epoch:  4\n",
      "29673 464\n",
      "Loss:  0.09383223205804825\n",
      "Loss:  0.1163160428404808\n",
      "Loss:  0.09988351166248322\n",
      "4 **********\n",
      "Epoch:  320.8471190929413  fold:  5  kers:  128\n",
      "epoch:  5\n",
      "29673 464\n",
      "Loss:  0.0873572900891304\n",
      "Loss:  0.08979005366563797\n",
      "Loss:  0.09644533693790436\n",
      "5 **********\n",
      "Epoch:  374.39294838905334  fold:  5  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.0976126492023468\n",
      "Eval Loss:  0.14625100791454315\n",
      "Eval Loss:  0.08633353561162949\n",
      "[[3040   57]\n",
      " [  62   59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3097\n",
      "           1       0.51      0.49      0.50       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.74      0.73      0.74      3218\n",
      "weighted avg       0.96      0.96      0.96      3218\n",
      "\n",
      "acc:  0.9630205096333126\n",
      "pre:  0.5086206896551724\n",
      "rec:  0.48760330578512395\n",
      "ma F1:  0.7393468253692748\n",
      "mi F1:  0.9630205096333128\n",
      "we F1:  0.9626453441112325\n",
      "update!  Acc:  0.9630205096333126\n",
      "Eval Loss:  0.5237792134284973\n",
      "Eval Loss:  0.43632134795188904\n",
      "Eval Loss:  0.4813118875026703\n",
      "Eval Loss:  0.3455701172351837\n",
      "Eval Loss:  0.44420936703681946\n",
      "Eval Loss:  0.4111165404319763\n",
      "Eval Loss:  0.4536627531051636\n",
      "Eval Loss:  0.41890662908554077\n",
      "Eval Loss:  0.47017568349838257\n",
      "Eval Loss:  0.44800207018852234\n",
      "Eval Loss:  0.455868124961853\n",
      "Eval Loss:  0.6721190214157104\n",
      "Eval Loss:  0.4507478177547455\n",
      "Eval Loss:  0.5070363283157349\n",
      "Eval Loss:  0.36615079641342163\n",
      "Eval Loss:  0.48770415782928467\n",
      "Eval Loss:  0.4581480920314789\n",
      "Eval Loss:  0.4327286183834076\n",
      "Eval Loss:  0.5816181898117065\n",
      "Eval Loss:  0.49825870990753174\n",
      "Eval Loss:  0.38670432567596436\n",
      "Eval Loss:  0.5589052438735962\n",
      "Eval Loss:  0.5138363838195801\n",
      "Eval Loss:  0.36035507917404175\n",
      "Eval Loss:  0.4461117088794708\n",
      "Eval Loss:  0.4781323969364166\n",
      "Eval Loss:  0.5792174339294434\n",
      "Eval Loss:  0.6345366835594177\n",
      "Eval Loss:  0.41699308156967163\n",
      "[[16440   627]\n",
      " [ 4953  7653]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85     17067\n",
      "           1       0.92      0.61      0.73     12606\n",
      "\n",
      "    accuracy                           0.81     29673\n",
      "   macro avg       0.85      0.79      0.79     29673\n",
      "weighted avg       0.83      0.81      0.80     29673\n",
      "\n",
      "acc:  0.8119502578101304\n",
      "pre:  0.9242753623188406\n",
      "rec:  0.6070918610185626\n",
      "ma F1:  0.7938747943482807\n",
      "mi F1:  0.8119502578101304\n",
      "we F1:  0.8030513782225622\n",
      "29673 464\n",
      "Loss:  0.09696749597787857\n",
      "Loss:  0.07607347518205643\n",
      "Loss:  0.10260774940252304\n",
      "6 **********\n",
      "Epoch:  468.79453802108765  fold:  5  kers:  128\n",
      "epoch:  7\n",
      "29673 464\n",
      "Loss:  0.12311410158872604\n",
      "Loss:  0.11230995506048203\n",
      "Loss:  0.07850290089845657\n",
      "7 **********\n",
      "Epoch:  522.3343834877014  fold:  5  kers:  128\n",
      "epoch:  8\n",
      "29673 464\n",
      "Loss:  0.10268016904592514\n",
      "Loss:  0.09641347825527191\n",
      "Loss:  0.0764331966638565\n",
      "8 **********\n",
      "Epoch:  575.9360632896423  fold:  5  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.08557195961475372\n",
      "Eval Loss:  0.12485664337873459\n",
      "Eval Loss:  0.0723147913813591\n",
      "[[3049   48]\n",
      " [  69   52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3097\n",
      "           1       0.52      0.43      0.47       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.75      0.71      0.73      3218\n",
      "weighted avg       0.96      0.96      0.96      3218\n",
      "\n",
      "acc:  0.9636420136730889\n",
      "pre:  0.52\n",
      "rec:  0.4297520661157025\n",
      "ma F1:  0.7258814064644362\n",
      "mi F1:  0.9636420136730889\n",
      "we F1:  0.9619760234323876\n",
      "update!  Acc:  0.9636420136730889\n",
      "Eval Loss:  0.49770331382751465\n",
      "Eval Loss:  0.38835135102272034\n",
      "Eval Loss:  0.44875895977020264\n",
      "Eval Loss:  0.2898794114589691\n",
      "Eval Loss:  0.45219725370407104\n",
      "Eval Loss:  0.35669952630996704\n",
      "Eval Loss:  0.386739581823349\n",
      "Eval Loss:  0.36881929636001587\n",
      "Eval Loss:  0.44019535183906555\n",
      "Eval Loss:  0.4050757586956024\n",
      "Eval Loss:  0.4227942228317261\n",
      "Eval Loss:  0.5506982207298279\n",
      "Eval Loss:  0.39655065536499023\n",
      "Eval Loss:  0.4183292090892792\n",
      "Eval Loss:  0.2930392622947693\n",
      "Eval Loss:  0.42870935797691345\n",
      "Eval Loss:  0.4107947051525116\n",
      "Eval Loss:  0.37168559432029724\n",
      "Eval Loss:  0.5098803639411926\n",
      "Eval Loss:  0.4483841359615326\n",
      "Eval Loss:  0.3441362679004669\n",
      "Eval Loss:  0.5141301155090332\n",
      "Eval Loss:  0.4660201072692871\n",
      "Eval Loss:  0.3109292685985565\n",
      "Eval Loss:  0.3465231657028198\n",
      "Eval Loss:  0.4050981402397156\n",
      "Eval Loss:  0.5335171818733215\n",
      "Eval Loss:  0.5657773017883301\n",
      "Eval Loss:  0.3599938154220581\n",
      "[[16525   542]\n",
      " [ 4585  8021]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.87     17067\n",
      "           1       0.94      0.64      0.76     12606\n",
      "\n",
      "    accuracy                           0.83     29673\n",
      "   macro avg       0.86      0.80      0.81     29673\n",
      "weighted avg       0.85      0.83      0.82     29673\n",
      "\n",
      "acc:  0.827216661611566\n",
      "pre:  0.9367044260189186\n",
      "rec:  0.6362843090591782\n",
      "ma F1:  0.8117553539206723\n",
      "mi F1:  0.827216661611566\n",
      "we F1:  0.8198659952199524\n",
      "29673 464\n",
      "Loss:  0.10270027816295624\n",
      "Loss:  0.07324343174695969\n",
      "Loss:  0.0801074355840683\n",
      "9 **********\n",
      "Epoch:  670.0454339981079  fold:  5  kers:  128\n",
      "epoch:  10\n",
      "29673 464\n",
      "Loss:  0.07744845002889633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08938643336296082\n",
      "Loss:  0.07742989808320999\n",
      "10 **********\n",
      "Epoch:  723.1753752231598  fold:  5  kers:  128\n",
      "epoch:  11\n",
      "29673 464\n",
      "Loss:  0.0574246346950531\n",
      "Loss:  0.10011559724807739\n",
      "Loss:  0.11341537535190582\n",
      "11 **********\n",
      "Epoch:  776.2803831100464  fold:  5  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.07744960486888885\n",
      "Eval Loss:  0.1281317174434662\n",
      "Eval Loss:  0.06625586003065109\n",
      "[[3052   45]\n",
      " [  66   55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3097\n",
      "           1       0.55      0.45      0.50       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.76      0.72      0.74      3218\n",
      "weighted avg       0.96      0.97      0.96      3218\n",
      "\n",
      "acc:  0.9655065257924177\n",
      "pre:  0.55\n",
      "rec:  0.45454545454545453\n",
      "ma F1:  0.7399387702354907\n",
      "mi F1:  0.9655065257924177\n",
      "we F1:  0.9639259709486754\n",
      "update!  Acc:  0.9655065257924177\n",
      "Eval Loss:  0.42298424243927\n",
      "Eval Loss:  0.3327619135379791\n",
      "Eval Loss:  0.4010472595691681\n",
      "Eval Loss:  0.24435697495937347\n",
      "Eval Loss:  0.4394637942314148\n",
      "Eval Loss:  0.30363523960113525\n",
      "Eval Loss:  0.33108025789260864\n",
      "Eval Loss:  0.3011515438556671\n",
      "Eval Loss:  0.3737550377845764\n",
      "Eval Loss:  0.3946115970611572\n",
      "Eval Loss:  0.3698538839817047\n",
      "Eval Loss:  0.448470801115036\n",
      "Eval Loss:  0.3118405342102051\n",
      "Eval Loss:  0.37164679169654846\n",
      "Eval Loss:  0.24008560180664062\n",
      "Eval Loss:  0.37258777022361755\n",
      "Eval Loss:  0.36556729674339294\n",
      "Eval Loss:  0.31871065497398376\n",
      "Eval Loss:  0.4306814670562744\n",
      "Eval Loss:  0.386967271566391\n",
      "Eval Loss:  0.2680291533470154\n",
      "Eval Loss:  0.4502256512641907\n",
      "Eval Loss:  0.3860919773578644\n",
      "Eval Loss:  0.26993805170059204\n",
      "Eval Loss:  0.30848973989486694\n",
      "Eval Loss:  0.3368569016456604\n",
      "Eval Loss:  0.45695289969444275\n",
      "Eval Loss:  0.4878746271133423\n",
      "Eval Loss:  0.33020567893981934\n",
      "[[16429   638]\n",
      " [ 3771  8835]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88     17067\n",
      "           1       0.93      0.70      0.80     12606\n",
      "\n",
      "    accuracy                           0.85     29673\n",
      "   macro avg       0.87      0.83      0.84     29673\n",
      "weighted avg       0.86      0.85      0.85     29673\n",
      "\n",
      "acc:  0.8514137431334884\n",
      "pre:  0.9326506914388262\n",
      "rec:  0.7008567348881485\n",
      "ma F1:  0.8409997809807519\n",
      "mi F1:  0.8514137431334884\n",
      "we F1:  0.8471173323585972\n",
      "29673 464\n",
      "Loss:  0.08443155884742737\n",
      "Loss:  0.09164410829544067\n",
      "Loss:  0.08866484463214874\n",
      "12 **********\n",
      "Epoch:  870.2022557258606  fold:  5  kers:  128\n",
      "epoch:  13\n",
      "29673 464\n",
      "Loss:  0.09383263438940048\n",
      "Loss:  0.06178439408540726\n",
      "Loss:  0.08180999010801315\n",
      "13 **********\n",
      "Epoch:  923.5865168571472  fold:  5  kers:  128\n",
      "epoch:  14\n",
      "29673 464\n",
      "Loss:  0.10120312124490738\n",
      "Loss:  0.09850786626338959\n",
      "Loss:  0.07076726853847504\n",
      "14 **********\n",
      "Epoch:  976.9518284797668  fold:  5  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.07290896773338318\n",
      "Eval Loss:  0.09091085940599442\n",
      "Eval Loss:  0.05406057462096214\n",
      "[[3053   44]\n",
      " [  56   65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3097\n",
      "           1       0.60      0.54      0.57       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.79      0.76      0.77      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.968924798011187\n",
      "pre:  0.5963302752293578\n",
      "rec:  0.5371900826446281\n",
      "ma F1:  0.7745519763482744\n",
      "mi F1:  0.968924798011187\n",
      "we F1:  0.968144184269569\n",
      "update!  Acc:  0.968924798011187\n",
      "Eval Loss:  0.3606265187263489\n",
      "Eval Loss:  0.26040005683898926\n",
      "Eval Loss:  0.3334861993789673\n",
      "Eval Loss:  0.21280831098556519\n",
      "Eval Loss:  0.3851598799228668\n",
      "Eval Loss:  0.25664713978767395\n",
      "Eval Loss:  0.28729668259620667\n",
      "Eval Loss:  0.23670640587806702\n",
      "Eval Loss:  0.34496009349823\n",
      "Eval Loss:  0.35336729884147644\n",
      "Eval Loss:  0.3304363787174225\n",
      "Eval Loss:  0.3702048361301422\n",
      "Eval Loss:  0.28217315673828125\n",
      "Eval Loss:  0.32271790504455566\n",
      "Eval Loss:  0.18872636556625366\n",
      "Eval Loss:  0.34287229180336\n",
      "Eval Loss:  0.29873204231262207\n",
      "Eval Loss:  0.28757452964782715\n",
      "Eval Loss:  0.3583039343357086\n",
      "Eval Loss:  0.31537842750549316\n",
      "Eval Loss:  0.26213786005973816\n",
      "Eval Loss:  0.366800457239151\n",
      "Eval Loss:  0.2945646047592163\n",
      "Eval Loss:  0.23564042150974274\n",
      "Eval Loss:  0.28130218386650085\n",
      "Eval Loss:  0.27056294679641724\n",
      "Eval Loss:  0.3945131301879883\n",
      "Eval Loss:  0.43232905864715576\n",
      "Eval Loss:  0.30115923285484314\n",
      "[[16288   779]\n",
      " [ 2982  9624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     17067\n",
      "           1       0.93      0.76      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.89      0.86      0.87     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8732517777103764\n",
      "pre:  0.925117754493896\n",
      "rec:  0.763445978105664\n",
      "ma F1:  0.8665194532147216\n",
      "mi F1:  0.8732517777103764\n",
      "we F1:  0.8710261908460415\n",
      "29673 464\n",
      "Loss:  0.09548372775316238\n",
      "Loss:  0.11816111952066422\n",
      "Loss:  0.06661361455917358\n",
      "15 **********\n",
      "Epoch:  1070.6064155101776  fold:  5  kers:  128\n",
      "epoch:  16\n",
      "29673 464\n",
      "Loss:  0.09082819521427155\n",
      "Loss:  0.08412738889455795\n",
      "Loss:  0.08730074763298035\n",
      "16 **********\n",
      "Epoch:  1123.7722606658936  fold:  5  kers:  128\n",
      "epoch:  17\n",
      "29673 464\n",
      "Loss:  0.09538634866476059\n",
      "Loss:  0.04722154513001442\n",
      "Loss:  0.05988031625747681\n",
      "17 **********\n",
      "Epoch:  1177.039834022522  fold:  5  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.07891053706407547\n",
      "Eval Loss:  0.14591746032238007\n",
      "Eval Loss:  0.06089121848344803\n",
      "[[3029   68]\n",
      " [  32   89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.57      0.74      0.64       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.86      0.81      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.968924798011187\n",
      "pre:  0.5668789808917197\n",
      "rec:  0.7355371900826446\n",
      "ma F1:  0.8120243655676302\n",
      "mi F1:  0.968924798011187\n",
      "we F1:  0.9708460277962101\n",
      "Eval Loss:  0.2740689516067505\n",
      "Eval Loss:  0.2433420568704605\n",
      "Eval Loss:  0.25381705164909363\n",
      "Eval Loss:  0.20856492221355438\n",
      "Eval Loss:  0.3234499394893646\n",
      "Eval Loss:  0.2292163372039795\n",
      "Eval Loss:  0.27669212222099304\n",
      "Eval Loss:  0.18798299133777618\n",
      "Eval Loss:  0.30857864022254944\n",
      "Eval Loss:  0.3258811831474304\n",
      "Eval Loss:  0.3205595910549164\n",
      "Eval Loss:  0.3049570620059967\n",
      "Eval Loss:  0.2678474187850952\n",
      "Eval Loss:  0.2925587594509125\n",
      "Eval Loss:  0.16959446668624878\n",
      "Eval Loss:  0.30309954285621643\n",
      "Eval Loss:  0.25015220046043396\n",
      "Eval Loss:  0.3466566503047943\n",
      "Eval Loss:  0.2704738676548004\n",
      "Eval Loss:  0.2817403972148895\n",
      "Eval Loss:  0.25460678339004517\n",
      "Eval Loss:  0.2911245822906494\n",
      "Eval Loss:  0.2678283452987671\n",
      "Eval Loss:  0.20540112257003784\n",
      "Eval Loss:  0.30381327867507935\n",
      "Eval Loss:  0.21975873410701752\n",
      "Eval Loss:  0.35302913188934326\n",
      "Eval Loss:  0.3900427222251892\n",
      "Eval Loss:  0.3170335292816162\n",
      "[[15585  1482]\n",
      " [ 1781 10825]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91     17067\n",
      "           1       0.88      0.86      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8900347116907626\n",
      "pre:  0.8795807264158609\n",
      "rec:  0.8587180707599555\n",
      "ma F1:  0.8871302300740058\n",
      "mi F1:  0.8900347116907626\n",
      "we F1:  0.889852266311895\n",
      "29673 464\n",
      "Loss:  0.05476272851228714\n",
      "Loss:  0.07828684896230698\n",
      "Loss:  0.07386868447065353\n",
      "18 **********\n",
      "Epoch:  1270.8290605545044  fold:  5  kers:  128\n",
      "epoch:  19\n",
      "29673 464\n",
      "Loss:  0.06482977420091629\n",
      "Loss:  0.0640479102730751\n",
      "Loss:  0.05072266608476639\n",
      "19 **********\n",
      "Epoch:  1324.131540775299  fold:  5  kers:  128\n",
      "epoch:  20\n",
      "29673 464\n",
      "Loss:  0.09551427513360977\n",
      "Loss:  0.0678957849740982\n",
      "Loss:  0.08717615157365799\n",
      "20 **********\n",
      "Epoch:  1377.3921325206757  fold:  5  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.06473808735609055\n",
      "Eval Loss:  0.06493881344795227\n",
      "Eval Loss:  0.03927187994122505\n",
      "[[3070   27]\n",
      " [  35   86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.76      0.71      0.74       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.85      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.980733374766936\n",
      "pre:  0.7610619469026548\n",
      "rec:  0.7107438016528925\n",
      "ma F1:  0.8625229799044697\n",
      "mi F1:  0.980733374766936\n",
      "we F1:  0.9804164568182429\n",
      "update!  Acc:  0.980733374766936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3083556592464447\n",
      "Eval Loss:  0.22530575096607208\n",
      "Eval Loss:  0.2954109311103821\n",
      "Eval Loss:  0.17668062448501587\n",
      "Eval Loss:  0.35399383306503296\n",
      "Eval Loss:  0.2277771532535553\n",
      "Eval Loss:  0.2677192687988281\n",
      "Eval Loss:  0.18693944811820984\n",
      "Eval Loss:  0.30969956517219543\n",
      "Eval Loss:  0.30261608958244324\n",
      "Eval Loss:  0.3016059398651123\n",
      "Eval Loss:  0.3115694522857666\n",
      "Eval Loss:  0.22282513976097107\n",
      "Eval Loss:  0.33389225602149963\n",
      "Eval Loss:  0.16699817776679993\n",
      "Eval Loss:  0.2930324971675873\n",
      "Eval Loss:  0.27455973625183105\n",
      "Eval Loss:  0.25253984332084656\n",
      "Eval Loss:  0.279541015625\n",
      "Eval Loss:  0.27032583951950073\n",
      "Eval Loss:  0.22469186782836914\n",
      "Eval Loss:  0.2929055094718933\n",
      "Eval Loss:  0.22155717015266418\n",
      "Eval Loss:  0.21399244666099548\n",
      "Eval Loss:  0.2846214771270752\n",
      "Eval Loss:  0.2285495549440384\n",
      "Eval Loss:  0.33228349685668945\n",
      "Eval Loss:  0.4081234335899353\n",
      "Eval Loss:  0.28609323501586914\n",
      "[[16134   933]\n",
      " [ 2269 10337]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     17067\n",
      "           1       0.92      0.82      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.88      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8920904526000067\n",
      "pre:  0.9172138420585626\n",
      "rec:  0.8200063461843566\n",
      "ma F1:  0.887808481685022\n",
      "mi F1:  0.8920904526000067\n",
      "we F1:  0.8911036123132343\n",
      "29673 464\n",
      "Loss:  0.06342532485723495\n",
      "Loss:  0.07484348118305206\n",
      "Loss:  0.0733090192079544\n",
      "21 **********\n",
      "Epoch:  1471.1314923763275  fold:  5  kers:  128\n",
      "epoch:  22\n",
      "29673 464\n",
      "Loss:  0.08179029077291489\n",
      "Loss:  0.07406467944383621\n",
      "Loss:  0.09699415415525436\n",
      "22 **********\n",
      "Epoch:  1524.3631618022919  fold:  5  kers:  128\n",
      "epoch:  23\n",
      "29673 464\n",
      "Loss:  0.07166048884391785\n",
      "Loss:  0.04083743691444397\n",
      "Loss:  0.05837852135300636\n",
      "23 **********\n",
      "Epoch:  1577.614777803421  fold:  5  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.060466013848781586\n",
      "Eval Loss:  0.05351851135492325\n",
      "Eval Loss:  0.027791935950517654\n",
      "[[3086   11]\n",
      " [  65   56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3097\n",
      "           1       0.84      0.46      0.60       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.91      0.73      0.79      3218\n",
      "weighted avg       0.97      0.98      0.97      3218\n",
      "\n",
      "acc:  0.9763828464885022\n",
      "pre:  0.835820895522388\n",
      "rec:  0.4628099173553719\n",
      "ma F1:  0.7917903942027407\n",
      "mi F1:  0.9763828464885022\n",
      "we F1:  0.9730930800121224\n",
      "Eval Loss:  0.3546017110347748\n",
      "Eval Loss:  0.25324535369873047\n",
      "Eval Loss:  0.3401683568954468\n",
      "Eval Loss:  0.19207632541656494\n",
      "Eval Loss:  0.3636080026626587\n",
      "Eval Loss:  0.24018771946430206\n",
      "Eval Loss:  0.2892157733440399\n",
      "Eval Loss:  0.18590177595615387\n",
      "Eval Loss:  0.32875683903694153\n",
      "Eval Loss:  0.2992994487285614\n",
      "Eval Loss:  0.2936039865016937\n",
      "Eval Loss:  0.32022935152053833\n",
      "Eval Loss:  0.24645300209522247\n",
      "Eval Loss:  0.3485870659351349\n",
      "Eval Loss:  0.19720475375652313\n",
      "Eval Loss:  0.3193134367465973\n",
      "Eval Loss:  0.29924240708351135\n",
      "Eval Loss:  0.23934192955493927\n",
      "Eval Loss:  0.30778011679649353\n",
      "Eval Loss:  0.29093432426452637\n",
      "Eval Loss:  0.22117933630943298\n",
      "Eval Loss:  0.31727805733680725\n",
      "Eval Loss:  0.24589195847511292\n",
      "Eval Loss:  0.2162306159734726\n",
      "Eval Loss:  0.264504611492157\n",
      "Eval Loss:  0.2616499364376068\n",
      "Eval Loss:  0.3480713963508606\n",
      "Eval Loss:  0.43527621030807495\n",
      "Eval Loss:  0.2959587872028351\n",
      "[[16532   535]\n",
      " [ 2993  9613]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90     17067\n",
      "           1       0.95      0.76      0.84     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.90      0.87      0.87     29673\n",
      "weighted avg       0.89      0.88      0.88     29673\n",
      "\n",
      "acc:  0.881104033970276\n",
      "pre:  0.9472802522664564\n",
      "rec:  0.7625733777566238\n",
      "ma F1:  0.8742679107838792\n",
      "mi F1:  0.881104033970276\n",
      "we F1:  0.8786754762607569\n",
      "29673 464\n",
      "Loss:  0.07782147079706192\n",
      "Loss:  0.09214846789836884\n",
      "Loss:  0.04942312464118004\n",
      "24 **********\n",
      "Epoch:  1671.2653756141663  fold:  5  kers:  128\n",
      "epoch:  25\n",
      "29673 464\n",
      "Loss:  0.08821182698011398\n",
      "Loss:  0.04612166807055473\n",
      "Loss:  0.10095912218093872\n",
      "25 **********\n",
      "Epoch:  1724.43221783638  fold:  5  kers:  128\n",
      "epoch:  26\n",
      "29673 464\n",
      "Loss:  0.04719187691807747\n",
      "Loss:  0.05611830949783325\n",
      "Loss:  0.10327794402837753\n",
      "26 **********\n",
      "Epoch:  1777.6828367710114  fold:  5  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.05795770138502121\n",
      "Eval Loss:  0.07420004159212112\n",
      "Eval Loss:  0.038274407386779785\n",
      "[[3072   25]\n",
      " [  53   68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.73      0.56      0.64       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.78      0.81      3218\n",
      "weighted avg       0.97      0.98      0.97      3218\n",
      "\n",
      "acc:  0.9757613424487259\n",
      "pre:  0.7311827956989247\n",
      "rec:  0.5619834710743802\n",
      "ma F1:  0.8114889283429014\n",
      "mi F1:  0.9757613424487259\n",
      "we F1:  0.9742301748072602\n",
      "Eval Loss:  0.2802485525608063\n",
      "Eval Loss:  0.2206350862979889\n",
      "Eval Loss:  0.29426854848861694\n",
      "Eval Loss:  0.18127140402793884\n",
      "Eval Loss:  0.29099130630493164\n",
      "Eval Loss:  0.20790106058120728\n",
      "Eval Loss:  0.2572556138038635\n",
      "Eval Loss:  0.13318978250026703\n",
      "Eval Loss:  0.307275652885437\n",
      "Eval Loss:  0.251930296421051\n",
      "Eval Loss:  0.2773175537586212\n",
      "Eval Loss:  0.2877766788005829\n",
      "Eval Loss:  0.2050023227930069\n",
      "Eval Loss:  0.2931016981601715\n",
      "Eval Loss:  0.1465548872947693\n",
      "Eval Loss:  0.2662205994129181\n",
      "Eval Loss:  0.23827654123306274\n",
      "Eval Loss:  0.23245765268802643\n",
      "Eval Loss:  0.25582361221313477\n",
      "Eval Loss:  0.2230544537305832\n",
      "Eval Loss:  0.20847724378108978\n",
      "Eval Loss:  0.27323248982429504\n",
      "Eval Loss:  0.2287711650133133\n",
      "Eval Loss:  0.1789754182100296\n",
      "Eval Loss:  0.2571968138217926\n",
      "Eval Loss:  0.21412140130996704\n",
      "Eval Loss:  0.3080329895019531\n",
      "Eval Loss:  0.39119356870651245\n",
      "Eval Loss:  0.26379701495170593\n",
      "[[16194   873]\n",
      " [ 2076 10530]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17067\n",
      "           1       0.92      0.84      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9006167222727732\n",
      "pre:  0.9234411996842936\n",
      "rec:  0.8353165159447882\n",
      "ma F1:  0.8968587284904421\n",
      "mi F1:  0.9006167222727732\n",
      "we F1:  0.8998185466865896\n",
      "29673 464\n",
      "Loss:  0.05593444034457207\n",
      "Loss:  0.095664381980896\n",
      "Loss:  0.044631410390138626\n",
      "27 **********\n",
      "Epoch:  1871.618671655655  fold:  5  kers:  128\n",
      "epoch:  28\n",
      "29673 464\n",
      "Loss:  0.050413403660058975\n",
      "Loss:  0.06580580770969391\n",
      "Loss:  0.06307028979063034\n",
      "28 **********\n",
      "Epoch:  1924.822415113449  fold:  5  kers:  128\n",
      "epoch:  29\n",
      "29673 464\n",
      "Loss:  0.04858808219432831\n",
      "Loss:  0.05937641113996506\n",
      "Loss:  0.06337115913629532\n",
      "29 **********\n",
      "Epoch:  1978.08101272583  fold:  5  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.06021083891391754\n",
      "Eval Loss:  0.0941767618060112\n",
      "Eval Loss:  0.041049204766750336\n",
      "[[3065   32]\n",
      " [  47   74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.70      0.61      0.65       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.84      0.80      0.82      3218\n",
      "weighted avg       0.97      0.98      0.97      3218\n",
      "\n",
      "acc:  0.9754505904288377\n",
      "pre:  0.6981132075471698\n",
      "rec:  0.6115702479338843\n",
      "ma F1:  0.819629456459041\n",
      "mi F1:  0.9754505904288377\n",
      "we F1:  0.9746691404089292\n",
      "Eval Loss:  0.2694211006164551\n",
      "Eval Loss:  0.2088092416524887\n",
      "Eval Loss:  0.2775074243545532\n",
      "Eval Loss:  0.17901656031608582\n",
      "Eval Loss:  0.29909753799438477\n",
      "Eval Loss:  0.21790573000907898\n",
      "Eval Loss:  0.2512848377227783\n",
      "Eval Loss:  0.1727747917175293\n",
      "Eval Loss:  0.3052331209182739\n",
      "Eval Loss:  0.27364596724510193\n",
      "Eval Loss:  0.2645784318447113\n",
      "Eval Loss:  0.29730522632598877\n",
      "Eval Loss:  0.22128313779830933\n",
      "Eval Loss:  0.2941697835922241\n",
      "Eval Loss:  0.17240020632743835\n",
      "Eval Loss:  0.2924785017967224\n",
      "Eval Loss:  0.23045563697814941\n",
      "Eval Loss:  0.20969711244106293\n",
      "Eval Loss:  0.2551119327545166\n",
      "Eval Loss:  0.24891629815101624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2145242691040039\n",
      "Eval Loss:  0.2733518183231354\n",
      "Eval Loss:  0.23376117646694183\n",
      "Eval Loss:  0.17348875105381012\n",
      "Eval Loss:  0.26235824823379517\n",
      "Eval Loss:  0.20286814868450165\n",
      "Eval Loss:  0.3039033114910126\n",
      "Eval Loss:  0.3412725031375885\n",
      "Eval Loss:  0.28506019711494446\n",
      "[[16281   786]\n",
      " [ 2130 10476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     17067\n",
      "           1       0.93      0.83      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.91      0.89      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9017288444040037\n",
      "pre:  0.9302077783697389\n",
      "rec:  0.8310328415040457\n",
      "ma F1:  0.8978181367383622\n",
      "mi F1:  0.9017288444040037\n",
      "we F1:  0.9008234195801238\n",
      "29673 464\n",
      "Loss:  0.0793122798204422\n",
      "Loss:  0.05662180110812187\n",
      "Loss:  0.05490223318338394\n",
      "30 **********\n",
      "Epoch:  2071.614921569824  fold:  5  kers:  128\n",
      "epoch:  31\n",
      "29673 464\n",
      "Loss:  0.0848703533411026\n",
      "Loss:  0.07028613984584808\n",
      "Loss:  0.04383111372590065\n",
      "31 **********\n",
      "Epoch:  2124.757828235626  fold:  5  kers:  128\n",
      "epoch:  32\n",
      "29673 464\n",
      "Loss:  0.04669278487563133\n",
      "Loss:  0.06071874871850014\n",
      "Loss:  0.06254643201828003\n",
      "32 **********\n",
      "Epoch:  2177.870815515518  fold:  5  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.05798080936074257\n",
      "Eval Loss:  0.04518967866897583\n",
      "Eval Loss:  0.01937257871031761\n",
      "[[3085   12]\n",
      " [  48   73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3097\n",
      "           1       0.86      0.60      0.71       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.92      0.80      0.85      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9813548788067122\n",
      "pre:  0.8588235294117647\n",
      "rec:  0.6033057851239669\n",
      "ma F1:  0.8495535227290436\n",
      "mi F1:  0.9813548788067122\n",
      "we F1:  0.9797795637938318\n",
      "update!  Acc:  0.9813548788067122\n",
      "Eval Loss:  0.37397876381874084\n",
      "Eval Loss:  0.27886754274368286\n",
      "Eval Loss:  0.33123892545700073\n",
      "Eval Loss:  0.1934116631746292\n",
      "Eval Loss:  0.37871506810188293\n",
      "Eval Loss:  0.2213200479745865\n",
      "Eval Loss:  0.2924248278141022\n",
      "Eval Loss:  0.2094806432723999\n",
      "Eval Loss:  0.36473244428634644\n",
      "Eval Loss:  0.2756807208061218\n",
      "Eval Loss:  0.27556419372558594\n",
      "Eval Loss:  0.3083370327949524\n",
      "Eval Loss:  0.24406728148460388\n",
      "Eval Loss:  0.3171156346797943\n",
      "Eval Loss:  0.19205789268016815\n",
      "Eval Loss:  0.31328630447387695\n",
      "Eval Loss:  0.2985714077949524\n",
      "Eval Loss:  0.21115007996559143\n",
      "Eval Loss:  0.32346516847610474\n",
      "Eval Loss:  0.2825295031070709\n",
      "Eval Loss:  0.2312232404947281\n",
      "Eval Loss:  0.3064468801021576\n",
      "Eval Loss:  0.24585109949111938\n",
      "Eval Loss:  0.2398490309715271\n",
      "Eval Loss:  0.26080644130706787\n",
      "Eval Loss:  0.24124525487422943\n",
      "Eval Loss:  0.35767048597335815\n",
      "Eval Loss:  0.44034162163734436\n",
      "Eval Loss:  0.32299816608428955\n",
      "[[16483   584]\n",
      " [ 2932  9674]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90     17067\n",
      "           1       0.94      0.77      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.90      0.87      0.87     29673\n",
      "weighted avg       0.89      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8815084420179962\n",
      "pre:  0.9430688243322285\n",
      "rec:  0.7674123433285737\n",
      "ma F1:  0.8749224192503227\n",
      "mi F1:  0.8815084420179963\n",
      "we F1:  0.8792373329772417\n",
      "29673 464\n",
      "Loss:  0.0576179139316082\n",
      "Loss:  0.061574678868055344\n",
      "Loss:  0.06579150259494781\n",
      "33 **********\n",
      "Epoch:  2276.5419886112213  fold:  5  kers:  128\n",
      "epoch:  34\n",
      "29673 464\n",
      "Loss:  0.07685334980487823\n",
      "Loss:  0.086283378303051\n",
      "Loss:  0.07989997416734695\n",
      "34 **********\n",
      "Epoch:  2329.8255190849304  fold:  5  kers:  128\n",
      "epoch:  35\n",
      "29673 464\n",
      "Loss:  0.0815587043762207\n",
      "Loss:  0.06091911345720291\n",
      "Loss:  0.038988348096609116\n",
      "35 **********\n",
      "Epoch:  2383.0332527160645  fold:  5  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.06514501571655273\n",
      "Eval Loss:  0.1364031583070755\n",
      "Eval Loss:  0.03923577070236206\n",
      "[[3055   42]\n",
      " [  22   99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.70      0.82      0.76       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.85      0.90      0.87      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9801118707271598\n",
      "pre:  0.7021276595744681\n",
      "rec:  0.8181818181818182\n",
      "ma F1:  0.8726795698286585\n",
      "mi F1:  0.9801118707271598\n",
      "we F1:  0.9808387469172714\n",
      "Eval Loss:  0.2380751371383667\n",
      "Eval Loss:  0.20455409586429596\n",
      "Eval Loss:  0.2370818704366684\n",
      "Eval Loss:  0.17183499038219452\n",
      "Eval Loss:  0.28763648867607117\n",
      "Eval Loss:  0.20541176199913025\n",
      "Eval Loss:  0.26269960403442383\n",
      "Eval Loss:  0.17600831389427185\n",
      "Eval Loss:  0.2719613015651703\n",
      "Eval Loss:  0.22751595079898834\n",
      "Eval Loss:  0.25279855728149414\n",
      "Eval Loss:  0.28449034690856934\n",
      "Eval Loss:  0.1772833913564682\n",
      "Eval Loss:  0.2519617974758148\n",
      "Eval Loss:  0.15021032094955444\n",
      "Eval Loss:  0.26871156692504883\n",
      "Eval Loss:  0.1975024938583374\n",
      "Eval Loss:  0.23430821299552917\n",
      "Eval Loss:  0.22810408473014832\n",
      "Eval Loss:  0.1991139054298401\n",
      "Eval Loss:  0.21542811393737793\n",
      "Eval Loss:  0.21737906336784363\n",
      "Eval Loss:  0.19861222803592682\n",
      "Eval Loss:  0.17288124561309814\n",
      "Eval Loss:  0.2861552834510803\n",
      "Eval Loss:  0.17297260463237762\n",
      "Eval Loss:  0.26085925102233887\n",
      "Eval Loss:  0.3161153495311737\n",
      "Eval Loss:  0.26662683486938477\n",
      "[[15780  1287]\n",
      " [ 1404 11202]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     17067\n",
      "           1       0.90      0.89      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.91      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9093114952987564\n",
      "pre:  0.8969493153975499\n",
      "rec:  0.8886244645406949\n",
      "ma F1:  0.9071002172126057\n",
      "mi F1:  0.9093114952987564\n",
      "we F1:  0.9092549816386256\n",
      "29673 464\n",
      "Loss:  0.08530817180871964\n",
      "Loss:  0.07138308137655258\n",
      "Loss:  0.04324053227901459\n",
      "36 **********\n",
      "Epoch:  2476.9102444648743  fold:  5  kers:  128\n",
      "epoch:  37\n",
      "29673 464\n",
      "Loss:  0.04895086586475372\n",
      "Loss:  0.08816950768232346\n",
      "Loss:  0.07122012972831726\n",
      "37 **********\n",
      "Epoch:  2530.1129910945892  fold:  5  kers:  128\n",
      "epoch:  38\n",
      "29673 464\n",
      "Loss:  0.04769577831029892\n",
      "Loss:  0.058525823056697845\n",
      "Loss:  0.06625707447528839\n",
      "38 **********\n",
      "Epoch:  2583.3476524353027  fold:  5  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.06300384551286697\n",
      "Eval Loss:  0.09252718091011047\n",
      "Eval Loss:  0.029283925890922546\n",
      "[[3072   25]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.78      0.73      0.75       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.88      0.86      0.87      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9819763828464885\n",
      "pre:  0.7787610619469026\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.8713924650719233\n",
      "mi F1:  0.9819763828464885\n",
      "we F1:  0.9816799112170661\n",
      "update!  Acc:  0.9819763828464885\n",
      "Eval Loss:  0.23131349682807922\n",
      "Eval Loss:  0.20989945530891418\n",
      "Eval Loss:  0.2425881177186966\n",
      "Eval Loss:  0.18808159232139587\n",
      "Eval Loss:  0.28970223665237427\n",
      "Eval Loss:  0.21375538408756256\n",
      "Eval Loss:  0.24961590766906738\n",
      "Eval Loss:  0.16003115475177765\n",
      "Eval Loss:  0.2759368121623993\n",
      "Eval Loss:  0.22009645402431488\n",
      "Eval Loss:  0.2850479781627655\n",
      "Eval Loss:  0.26776790618896484\n",
      "Eval Loss:  0.16080039739608765\n",
      "Eval Loss:  0.2838437855243683\n",
      "Eval Loss:  0.13885943591594696\n",
      "Eval Loss:  0.27523937821388245\n",
      "Eval Loss:  0.17935191094875336\n",
      "Eval Loss:  0.21424256265163422\n",
      "Eval Loss:  0.2430989146232605\n",
      "Eval Loss:  0.17775367200374603\n",
      "Eval Loss:  0.22345171868801117\n",
      "Eval Loss:  0.23218123614788055\n",
      "Eval Loss:  0.20380422472953796\n",
      "Eval Loss:  0.17173230648040771\n",
      "Eval Loss:  0.29486122727394104\n",
      "Eval Loss:  0.15436159074306488\n",
      "Eval Loss:  0.2622472643852234\n",
      "Eval Loss:  0.3187958300113678\n",
      "Eval Loss:  0.2651737332344055\n",
      "[[15783  1284]\n",
      " [ 1375 11231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     17067\n",
      "           1       0.90      0.89      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.91      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9103899167593436\n",
      "pre:  0.8974031162604874\n",
      "rec:  0.8909249563699826\n",
      "ma F1:  0.9082302785271659\n",
      "mi F1:  0.9103899167593436\n",
      "we F1:  0.9103467429721889\n",
      "29673 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.051436897367239\n",
      "Loss:  0.04716268926858902\n",
      "Loss:  0.059977203607559204\n",
      "39 **********\n",
      "Epoch:  2677.066068649292  fold:  5  kers:  128\n",
      "epoch:  40\n",
      "29673 464\n",
      "Loss:  0.03724776953458786\n",
      "Loss:  0.08030720055103302\n",
      "Loss:  0.027096733450889587\n",
      "40 **********\n",
      "Epoch:  2730.294746160507  fold:  5  kers:  128\n",
      "epoch:  41\n",
      "29673 464\n",
      "Loss:  0.074002206325531\n",
      "Loss:  0.07341831177473068\n",
      "Loss:  0.0959847941994667\n",
      "41 **********\n",
      "Epoch:  2783.550351381302  fold:  5  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.06062053143978119\n",
      "Eval Loss:  0.0630926564335823\n",
      "Eval Loss:  0.03269030153751373\n",
      "[[3077   20]\n",
      " [  27   94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.82      0.78      0.80       121\n",
      "\n",
      "    accuracy                           0.99      3218\n",
      "   macro avg       0.91      0.89      0.90      3218\n",
      "weighted avg       0.99      0.99      0.99      3218\n",
      "\n",
      "acc:  0.9853946550652579\n",
      "pre:  0.8245614035087719\n",
      "rec:  0.7768595041322314\n",
      "ma F1:  0.8962102886631189\n",
      "mi F1:  0.9853946550652579\n",
      "we F1:  0.9851853722745054\n",
      "update!  Acc:  0.9853946550652579\n",
      "Eval Loss:  0.2442602962255478\n",
      "Eval Loss:  0.1736339032649994\n",
      "Eval Loss:  0.2305370271205902\n",
      "Eval Loss:  0.14500777423381805\n",
      "Eval Loss:  0.2824972867965698\n",
      "Eval Loss:  0.18198104202747345\n",
      "Eval Loss:  0.2481841892004013\n",
      "Eval Loss:  0.13684186339378357\n",
      "Eval Loss:  0.2607876658439636\n",
      "Eval Loss:  0.22365975379943848\n",
      "Eval Loss:  0.2621501386165619\n",
      "Eval Loss:  0.258617103099823\n",
      "Eval Loss:  0.18225887417793274\n",
      "Eval Loss:  0.25874486565589905\n",
      "Eval Loss:  0.13288244605064392\n",
      "Eval Loss:  0.24294039607048035\n",
      "Eval Loss:  0.19151407480239868\n",
      "Eval Loss:  0.18829087913036346\n",
      "Eval Loss:  0.22956596314907074\n",
      "Eval Loss:  0.18743593990802765\n",
      "Eval Loss:  0.18736664950847626\n",
      "Eval Loss:  0.18166100978851318\n",
      "Eval Loss:  0.17736920714378357\n",
      "Eval Loss:  0.16930152475833893\n",
      "Eval Loss:  0.25939318537712097\n",
      "Eval Loss:  0.15099798142910004\n",
      "Eval Loss:  0.22594736516475677\n",
      "Eval Loss:  0.3158620297908783\n",
      "Eval Loss:  0.2618213891983032\n",
      "[[16070   997]\n",
      " [ 1558 11048]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     17067\n",
      "           1       0.92      0.88      0.90     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.91      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9138947865062514\n",
      "pre:  0.9172270651722707\n",
      "rec:  0.8764080596541329\n",
      "ma F1:  0.9113556770019196\n",
      "mi F1:  0.9138947865062514\n",
      "we F1:  0.9136111464361738\n",
      "29673 464\n",
      "Loss:  0.08029015362262726\n",
      "Loss:  0.04687640070915222\n",
      "Loss:  0.07367690652608871\n",
      "42 **********\n",
      "Epoch:  2877.334591150284  fold:  5  kers:  128\n",
      "epoch:  43\n",
      "29673 464\n",
      "Loss:  0.06769785284996033\n",
      "Loss:  0.054813459515571594\n",
      "Loss:  0.05261925980448723\n",
      "43 **********\n",
      "Epoch:  2930.4834818840027  fold:  5  kers:  128\n",
      "epoch:  44\n",
      "29673 464\n",
      "Loss:  0.057640936225652695\n",
      "Loss:  0.061160486191511154\n",
      "Loss:  0.08780912309885025\n",
      "44 **********\n",
      "Epoch:  2983.7171461582184  fold:  5  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.06447497010231018\n",
      "Eval Loss:  0.07066623121500015\n",
      "Eval Loss:  0.03575529530644417\n",
      "[[3065   32]\n",
      " [  41   80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.71      0.66      0.69       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.85      0.83      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9773151025481666\n",
      "pre:  0.7142857142857143\n",
      "rec:  0.6611570247933884\n",
      "ma F1:  0.8374633899283124\n",
      "mi F1:  0.9773151025481666\n",
      "we F1:  0.9768934390930313\n",
      "Eval Loss:  0.24154217541217804\n",
      "Eval Loss:  0.18826289474964142\n",
      "Eval Loss:  0.24456292390823364\n",
      "Eval Loss:  0.143568217754364\n",
      "Eval Loss:  0.2575600743293762\n",
      "Eval Loss:  0.2125621885061264\n",
      "Eval Loss:  0.26025933027267456\n",
      "Eval Loss:  0.15219955146312714\n",
      "Eval Loss:  0.25425124168395996\n",
      "Eval Loss:  0.20979103446006775\n",
      "Eval Loss:  0.24809224903583527\n",
      "Eval Loss:  0.2514706254005432\n",
      "Eval Loss:  0.1310531497001648\n",
      "Eval Loss:  0.2578597068786621\n",
      "Eval Loss:  0.13360440731048584\n",
      "Eval Loss:  0.24975036084651947\n",
      "Eval Loss:  0.18845784664154053\n",
      "Eval Loss:  0.18920810520648956\n",
      "Eval Loss:  0.23885579407215118\n",
      "Eval Loss:  0.15949282050132751\n",
      "Eval Loss:  0.19118502736091614\n",
      "Eval Loss:  0.1847391426563263\n",
      "Eval Loss:  0.1705547571182251\n",
      "Eval Loss:  0.18005268275737762\n",
      "Eval Loss:  0.24992163479328156\n",
      "Eval Loss:  0.15755590796470642\n",
      "Eval Loss:  0.21835152804851532\n",
      "Eval Loss:  0.29486382007598877\n",
      "Eval Loss:  0.23558887839317322\n",
      "[[15994  1073]\n",
      " [ 1428 11178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17067\n",
      "           1       0.91      0.89      0.90     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.91      0.91     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9157146227209921\n",
      "pre:  0.9124153130356706\n",
      "rec:  0.8867206092336982\n",
      "ma F1:  0.9134343022972262\n",
      "mi F1:  0.9157146227209921\n",
      "we F1:  0.9155465343176622\n",
      "29673 464\n",
      "Loss:  0.04049370065331459\n",
      "Loss:  0.05470375344157219\n",
      "Loss:  0.04832276701927185\n",
      "45 **********\n",
      "Epoch:  3077.4355618953705  fold:  5  kers:  128\n",
      "epoch:  46\n",
      "29673 464\n",
      "Loss:  0.06655856221914291\n",
      "Loss:  0.05253544822335243\n",
      "Loss:  0.03813778981566429\n",
      "46 **********\n",
      "Epoch:  3130.604399204254  fold:  5  kers:  128\n",
      "epoch:  47\n",
      "29673 464\n",
      "Loss:  0.06333521008491516\n",
      "Loss:  0.0424901619553566\n",
      "Loss:  0.0659852921962738\n",
      "47 **********\n",
      "Epoch:  3183.7971720695496  fold:  5  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.052116602659225464\n",
      "Eval Loss:  0.04358112812042236\n",
      "Eval Loss:  0.02512555569410324\n",
      "[[3083   14]\n",
      " [  48   73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3097\n",
      "           1       0.84      0.60      0.70       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.91      0.80      0.85      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.980733374766936\n",
      "pre:  0.8390804597701149\n",
      "rec:  0.6033057851239669\n",
      "ma F1:  0.8459840175880637\n",
      "mi F1:  0.980733374766936\n",
      "we F1:  0.9792112890047826\n",
      "Eval Loss:  0.2542826235294342\n",
      "Eval Loss:  0.18250302970409393\n",
      "Eval Loss:  0.28275442123413086\n",
      "Eval Loss:  0.1435757726430893\n",
      "Eval Loss:  0.28142789006233215\n",
      "Eval Loss:  0.1917489469051361\n",
      "Eval Loss:  0.24439319968223572\n",
      "Eval Loss:  0.14623373746871948\n",
      "Eval Loss:  0.2743999660015106\n",
      "Eval Loss:  0.21972253918647766\n",
      "Eval Loss:  0.24648958444595337\n",
      "Eval Loss:  0.2619614601135254\n",
      "Eval Loss:  0.15691377222537994\n",
      "Eval Loss:  0.2710448205471039\n",
      "Eval Loss:  0.16924342513084412\n",
      "Eval Loss:  0.25637686252593994\n",
      "Eval Loss:  0.19606921076774597\n",
      "Eval Loss:  0.16531246900558472\n",
      "Eval Loss:  0.259026437997818\n",
      "Eval Loss:  0.18958598375320435\n",
      "Eval Loss:  0.18203382194042206\n",
      "Eval Loss:  0.20774415135383606\n",
      "Eval Loss:  0.18119387328624725\n",
      "Eval Loss:  0.1992819607257843\n",
      "Eval Loss:  0.23085880279541016\n",
      "Eval Loss:  0.1601748764514923\n",
      "Eval Loss:  0.2485179901123047\n",
      "Eval Loss:  0.31034746766090393\n",
      "Eval Loss:  0.2724910080432892\n",
      "[[16390   677]\n",
      " [ 1905 10701]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     17067\n",
      "           1       0.94      0.85      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.92      0.90      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9129848683988812\n",
      "pre:  0.9404992089998242\n",
      "rec:  0.8488814850071394\n",
      "ma F1:  0.9096643322420819\n",
      "mi F1:  0.9129848683988812\n",
      "we F1:  0.912268113538528\n",
      "29673 464\n",
      "Loss:  0.0639868974685669\n",
      "Loss:  0.09400254487991333\n",
      "Loss:  0.04766474664211273\n",
      "48 **********\n",
      "Epoch:  3277.5644578933716  fold:  5  kers:  128\n",
      "epoch:  49\n",
      "29673 464\n",
      "Loss:  0.06627874076366425\n",
      "Loss:  0.07105722278356552\n",
      "Loss:  0.03321859613060951\n",
      "49 **********\n",
      "Epoch:  3330.83203125  fold:  5  kers:  128\n",
      "epoch:  50\n",
      "29673 464\n",
      "Loss:  0.05202605202794075\n",
      "Loss:  0.08542224764823914\n",
      "Loss:  0.10031874477863312\n",
      "50 **********\n",
      "Epoch:  3384.0966126918793  fold:  5  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.0631268322467804\n",
      "Eval Loss:  0.06099758297204971\n",
      "Eval Loss:  0.029417701065540314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3072   25]\n",
      " [  22   99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.80      0.82      0.81       121\n",
      "\n",
      "    accuracy                           0.99      3218\n",
      "   macro avg       0.90      0.91      0.90      3218\n",
      "weighted avg       0.99      0.99      0.99      3218\n",
      "\n",
      "acc:  0.9853946550652579\n",
      "pre:  0.7983870967741935\n",
      "rec:  0.8181818181818182\n",
      "ma F1:  0.9002857999927478\n",
      "mi F1:  0.9853946550652579\n",
      "we F1:  0.9854805368564511\n",
      "Eval Loss:  0.22048218548297882\n",
      "Eval Loss:  0.1847531795501709\n",
      "Eval Loss:  0.21582739055156708\n",
      "Eval Loss:  0.14704114198684692\n",
      "Eval Loss:  0.2732875943183899\n",
      "Eval Loss:  0.20900952816009521\n",
      "Eval Loss:  0.2275606393814087\n",
      "Eval Loss:  0.1304437816143036\n",
      "Eval Loss:  0.29579630494117737\n",
      "Eval Loss:  0.19434477388858795\n",
      "Eval Loss:  0.2499706745147705\n",
      "Eval Loss:  0.2430025190114975\n",
      "Eval Loss:  0.12583859264850616\n",
      "Eval Loss:  0.30261680483818054\n",
      "Eval Loss:  0.14052587747573853\n",
      "Eval Loss:  0.2566075623035431\n",
      "Eval Loss:  0.1679379940032959\n",
      "Eval Loss:  0.17983506619930267\n",
      "Eval Loss:  0.23821955919265747\n",
      "Eval Loss:  0.17924487590789795\n",
      "Eval Loss:  0.19557727873325348\n",
      "Eval Loss:  0.16469460725784302\n",
      "Eval Loss:  0.1500425487756729\n",
      "Eval Loss:  0.18093252182006836\n",
      "Eval Loss:  0.2625805139541626\n",
      "Eval Loss:  0.1481582522392273\n",
      "Eval Loss:  0.2131255716085434\n",
      "Eval Loss:  0.2573961317539215\n",
      "Eval Loss:  0.24202105402946472\n",
      "[[15816  1251]\n",
      " [ 1183 11423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17067\n",
      "           1       0.90      0.91      0.90     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.92      0.92     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9179725676540963\n",
      "pre:  0.9012939876913366\n",
      "rec:  0.9061557988259559\n",
      "ma F1:  0.9161344076502277\n",
      "mi F1:  0.9179725676540963\n",
      "we F1:  0.9180010208478733\n",
      "29673 464\n",
      "Loss:  0.05296061187982559\n",
      "Loss:  0.08641371130943298\n",
      "Loss:  0.05310378968715668\n",
      "51 **********\n",
      "Epoch:  3477.7861058712006  fold:  5  kers:  128\n",
      "epoch:  52\n",
      "29673 464\n",
      "Loss:  0.05834530293941498\n",
      "Loss:  0.07018467783927917\n",
      "Loss:  0.062066663056612015\n",
      "52 **********\n",
      "Epoch:  3531.012788772583  fold:  5  kers:  128\n",
      "epoch:  53\n",
      "29673 464\n",
      "Loss:  0.06277105957269669\n",
      "Loss:  0.08493756502866745\n",
      "Loss:  0.040814973413944244\n",
      "53 **********\n",
      "Epoch:  3584.277369737625  fold:  5  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.058005817234516144\n",
      "Eval Loss:  0.060086145997047424\n",
      "Eval Loss:  0.030791085213422775\n",
      "[[3076   21]\n",
      " [  53   68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.76      0.56      0.65       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.78      0.82      3218\n",
      "weighted avg       0.97      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9770043505282784\n",
      "pre:  0.7640449438202247\n",
      "rec:  0.5619834710743802\n",
      "ma F1:  0.817866703379071\n",
      "mi F1:  0.9770043505282784\n",
      "we F1:  0.975311396835202\n",
      "Eval Loss:  0.24207249283790588\n",
      "Eval Loss:  0.1622363030910492\n",
      "Eval Loss:  0.2512061297893524\n",
      "Eval Loss:  0.14198245108127594\n",
      "Eval Loss:  0.2461055964231491\n",
      "Eval Loss:  0.21272937953472137\n",
      "Eval Loss:  0.21879757940769196\n",
      "Eval Loss:  0.13234779238700867\n",
      "Eval Loss:  0.24030986428260803\n",
      "Eval Loss:  0.24003149569034576\n",
      "Eval Loss:  0.22675539553165436\n",
      "Eval Loss:  0.24287591874599457\n",
      "Eval Loss:  0.15811388194561005\n",
      "Eval Loss:  0.2658342719078064\n",
      "Eval Loss:  0.15706469118595123\n",
      "Eval Loss:  0.23549479246139526\n",
      "Eval Loss:  0.17222748696804047\n",
      "Eval Loss:  0.15764985978603363\n",
      "Eval Loss:  0.21215346455574036\n",
      "Eval Loss:  0.19179202616214752\n",
      "Eval Loss:  0.1723715215921402\n",
      "Eval Loss:  0.20960281789302826\n",
      "Eval Loss:  0.17214350402355194\n",
      "Eval Loss:  0.17948859930038452\n",
      "Eval Loss:  0.2137834131717682\n",
      "Eval Loss:  0.13287678360939026\n",
      "Eval Loss:  0.2345191091299057\n",
      "Eval Loss:  0.2601216733455658\n",
      "Eval Loss:  0.2391500622034073\n",
      "[[16409   658]\n",
      " [ 1821 10785]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     17067\n",
      "           1       0.94      0.86      0.90     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.91      0.91     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9164560374751457\n",
      "pre:  0.9424975967840601\n",
      "rec:  0.8555449785816278\n",
      "ma F1:  0.9133430965654611\n",
      "mi F1:  0.9164560374751457\n",
      "we F1:  0.9158123052066601\n",
      "29673 464\n",
      "Loss:  0.015450727194547653\n",
      "Loss:  0.05389173701405525\n",
      "Loss:  0.06789261102676392\n",
      "54 **********\n",
      "Epoch:  3678.051636695862  fold:  5  kers:  128\n",
      "epoch:  55\n",
      "29673 464\n",
      "Loss:  0.048914920538663864\n",
      "Loss:  0.033009711652994156\n",
      "Loss:  0.07318593561649323\n",
      "55 **********\n",
      "Epoch:  3731.215487241745  fold:  5  kers:  128\n",
      "epoch:  56\n",
      "29673 464\n",
      "Loss:  0.06239747628569603\n",
      "Loss:  0.04835634306073189\n",
      "Loss:  0.12070565670728683\n",
      "56 **********\n",
      "Epoch:  3785.0854506492615  fold:  5  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.06046503037214279\n",
      "Eval Loss:  0.05322502180933952\n",
      "Eval Loss:  0.023595288395881653\n",
      "[[3072   25]\n",
      " [  29   92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.79      0.76      0.77       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.89      0.88      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.983219390926041\n",
      "pre:  0.7863247863247863\n",
      "rec:  0.7603305785123967\n",
      "ma F1:  0.8821983778990783\n",
      "mi F1:  0.983219390926041\n",
      "we F1:  0.983083792250837\n",
      "Eval Loss:  0.2219296395778656\n",
      "Eval Loss:  0.14661194384098053\n",
      "Eval Loss:  0.20613867044448853\n",
      "Eval Loss:  0.13991159200668335\n",
      "Eval Loss:  0.26284530758857727\n",
      "Eval Loss:  0.18782518804073334\n",
      "Eval Loss:  0.20322786271572113\n",
      "Eval Loss:  0.14356710016727448\n",
      "Eval Loss:  0.2463943362236023\n",
      "Eval Loss:  0.22022375464439392\n",
      "Eval Loss:  0.20167306065559387\n",
      "Eval Loss:  0.2318168580532074\n",
      "Eval Loss:  0.14001081883907318\n",
      "Eval Loss:  0.24464742839336395\n",
      "Eval Loss:  0.11880114674568176\n",
      "Eval Loss:  0.22812578082084656\n",
      "Eval Loss:  0.15150456130504608\n",
      "Eval Loss:  0.15614597499370575\n",
      "Eval Loss:  0.1923731416463852\n",
      "Eval Loss:  0.1791568249464035\n",
      "Eval Loss:  0.19819001853466034\n",
      "Eval Loss:  0.1874667853116989\n",
      "Eval Loss:  0.1276896446943283\n",
      "Eval Loss:  0.17266066372394562\n",
      "Eval Loss:  0.22717568278312683\n",
      "Eval Loss:  0.12085550278425217\n",
      "Eval Loss:  0.20985953509807587\n",
      "Eval Loss:  0.23291198909282684\n",
      "Eval Loss:  0.2308826595544815\n",
      "[[16069   998]\n",
      " [ 1240 11366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     17067\n",
      "           1       0.92      0.90      0.91     12606\n",
      "\n",
      "    accuracy                           0.92     29673\n",
      "   macro avg       0.92      0.92      0.92     29673\n",
      "weighted avg       0.92      0.92      0.92     29673\n",
      "\n",
      "acc:  0.9245778991001921\n",
      "pre:  0.9192817858298286\n",
      "rec:  0.9016341424718388\n",
      "ma F1:  0.9226344431563163\n",
      "mi F1:  0.9245778991001921\n",
      "we F1:  0.9244778956261503\n",
      "29673 464\n",
      "Loss:  0.06155989319086075\n",
      "Loss:  0.04441189765930176\n",
      "Loss:  0.037023331969976425\n",
      "57 **********\n",
      "Epoch:  3879.9278604984283  fold:  5  kers:  128\n",
      "epoch:  58\n",
      "29673 464\n",
      "Loss:  0.038207508623600006\n",
      "Loss:  0.05993029847741127\n",
      "Loss:  0.044529274106025696\n",
      "58 **********\n",
      "Epoch:  3933.152548789978  fold:  5  kers:  128\n",
      "epoch:  59\n",
      "29673 464\n",
      "Loss:  0.0438191220164299\n",
      "Loss:  0.11705158650875092\n",
      "Loss:  0.07459389418363571\n",
      "59 **********\n",
      "Epoch:  3986.4430606365204  fold:  5  kers:  128\n",
      "Eval Loss:  0.0615692213177681\n",
      "Eval Loss:  0.0768669843673706\n",
      "Eval Loss:  0.05123911798000336\n",
      "[[3060   37]\n",
      " [  24   97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.72      0.80      0.76       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.89      0.88      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9810441267868241\n",
      "pre:  0.7238805970149254\n",
      "rec:  0.8016528925619835\n",
      "ma F1:  0.8754576802408393\n",
      "mi F1:  0.981044126786824\n",
      "we F1:  0.9815073815303603\n",
      "update!  Acc:  0.9853946550652579\n",
      "Epoch:  3990.4553327560425  fold:  5  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29479 3412\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29479 461\n",
      "Loss:  0.17684751749038696\n",
      "Loss:  0.17259196937084198\n",
      "Loss:  0.1701730638742447\n",
      "0 **********\n",
      "Epoch:  65.41309833526611  fold:  6  kers:  128\n",
      "epoch:  1\n",
      "29479 461\n",
      "Loss:  0.14792686700820923\n",
      "Loss:  0.13327907025814056\n",
      "Loss:  0.12616947293281555\n",
      "1 **********\n",
      "Epoch:  118.60786581039429  fold:  6  kers:  128\n",
      "epoch:  2\n",
      "29479 461\n",
      "Loss:  0.12156448513269424\n",
      "Loss:  0.0856056958436966\n",
      "Loss:  0.11672988533973694\n",
      "2 **********\n",
      "Epoch:  171.76573300361633  fold:  6  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.06631883233785629\n",
      "Eval Loss:  0.32469624280929565\n",
      "Eval Loss:  0.5449470281600952\n",
      "[[2007  225]\n",
      " [ 176 1004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      2232\n",
      "           1       0.82      0.85      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.88      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8824736225087925\n",
      "pre:  0.8169243287225386\n",
      "rec:  0.8508474576271187\n",
      "ma F1:  0.8713570806342956\n",
      "mi F1:  0.8824736225087925\n",
      "we F1:  0.883016703816719\n",
      "update!  Acc:  0.8824736225087925\n",
      "Eval Loss:  0.42569491267204285\n",
      "Eval Loss:  0.49205654859542847\n",
      "Eval Loss:  0.45253071188926697\n",
      "Eval Loss:  0.3700147569179535\n",
      "Eval Loss:  0.40285560488700867\n",
      "Eval Loss:  0.4857620298862457\n",
      "Eval Loss:  0.49975132942199707\n",
      "Eval Loss:  0.434202641248703\n",
      "Eval Loss:  0.4457906186580658\n",
      "Eval Loss:  0.48981547355651855\n",
      "Eval Loss:  0.5540637373924255\n",
      "Eval Loss:  0.4396703839302063\n",
      "Eval Loss:  0.501356303691864\n",
      "Eval Loss:  0.4417896568775177\n",
      "Eval Loss:  0.5177492499351501\n",
      "Eval Loss:  0.38745567202568054\n",
      "Eval Loss:  0.5266481041908264\n",
      "Eval Loss:  0.5316153168678284\n",
      "Eval Loss:  0.3673647344112396\n",
      "Eval Loss:  0.63775235414505\n",
      "Eval Loss:  0.49351754784584045\n",
      "Eval Loss:  0.44439786672592163\n",
      "Eval Loss:  0.44862794876098633\n",
      "Eval Loss:  0.4215865433216095\n",
      "Eval Loss:  0.4565027058124542\n",
      "Eval Loss:  0.5523978471755981\n",
      "Eval Loss:  0.3857940435409546\n",
      "Eval Loss:  0.5135330557823181\n",
      "[[16607  1325]\n",
      " [ 4534  7013]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85     17932\n",
      "           1       0.84      0.61      0.71     11547\n",
      "\n",
      "    accuracy                           0.80     29479\n",
      "   macro avg       0.81      0.77      0.78     29479\n",
      "weighted avg       0.81      0.80      0.79     29479\n",
      "\n",
      "acc:  0.801248346280403\n",
      "pre:  0.8410889901655073\n",
      "rec:  0.6073438988481856\n",
      "ma F1:  0.7777028512055547\n",
      "mi F1:  0.8012483462804029\n",
      "we F1:  0.7933728518364601\n",
      "29479 461\n",
      "Loss:  0.09658478945493698\n",
      "Loss:  0.06279827654361725\n",
      "Loss:  0.10003744065761566\n",
      "3 **********\n",
      "Epoch:  265.8621382713318  fold:  6  kers:  128\n",
      "epoch:  4\n",
      "29479 461\n",
      "Loss:  0.11684072017669678\n",
      "Loss:  0.07841107249259949\n",
      "Loss:  0.08420519530773163\n",
      "4 **********\n",
      "Epoch:  319.13968443870544  fold:  6  kers:  128\n",
      "epoch:  5\n",
      "29479 461\n",
      "Loss:  0.09176767617464066\n",
      "Loss:  0.11750787496566772\n",
      "Loss:  0.0801636278629303\n",
      "5 **********\n",
      "Epoch:  372.35938596725464  fold:  6  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.023801080882549286\n",
      "Eval Loss:  0.31043148040771484\n",
      "Eval Loss:  0.4961598813533783\n",
      "[[2145   87]\n",
      " [ 321  859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      2232\n",
      "           1       0.91      0.73      0.81      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.89      0.84      0.86      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.88042203985932\n",
      "pre:  0.9080338266384778\n",
      "rec:  0.7279661016949153\n",
      "ma F1:  0.860622422143167\n",
      "mi F1:  0.88042203985932\n",
      "we F1:  0.8768193100416063\n",
      "Eval Loss:  0.35404089093208313\n",
      "Eval Loss:  0.433097779750824\n",
      "Eval Loss:  0.42805564403533936\n",
      "Eval Loss:  0.35124844312667847\n",
      "Eval Loss:  0.35810351371765137\n",
      "Eval Loss:  0.4022919833660126\n",
      "Eval Loss:  0.4736366868019104\n",
      "Eval Loss:  0.42355939745903015\n",
      "Eval Loss:  0.4660228192806244\n",
      "Eval Loss:  0.49660444259643555\n",
      "Eval Loss:  0.49985188245773315\n",
      "Eval Loss:  0.4319247007369995\n",
      "Eval Loss:  0.5003730058670044\n",
      "Eval Loss:  0.4556525945663452\n",
      "Eval Loss:  0.5152605772018433\n",
      "Eval Loss:  0.37983155250549316\n",
      "Eval Loss:  0.5542298555374146\n",
      "Eval Loss:  0.47395429015159607\n",
      "Eval Loss:  0.36758771538734436\n",
      "Eval Loss:  0.6756832599639893\n",
      "Eval Loss:  0.468811571598053\n",
      "Eval Loss:  0.4210311472415924\n",
      "Eval Loss:  0.4505687654018402\n",
      "Eval Loss:  0.4146448075771332\n",
      "Eval Loss:  0.4208877980709076\n",
      "Eval Loss:  0.5557309985160828\n",
      "Eval Loss:  0.398548424243927\n",
      "Eval Loss:  0.49395832419395447\n",
      "[[17440   492]\n",
      " [ 4737  6810]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     17932\n",
      "           1       0.93      0.59      0.72     11547\n",
      "\n",
      "    accuracy                           0.82     29479\n",
      "   macro avg       0.86      0.78      0.80     29479\n",
      "weighted avg       0.84      0.82      0.81     29479\n",
      "\n",
      "acc:  0.82261949184165\n",
      "pre:  0.932621199671323\n",
      "rec:  0.5897635749545337\n",
      "ma F1:  0.7961075050274729\n",
      "mi F1:  0.82261949184165\n",
      "we F1:  0.8120321556209368\n",
      "29479 461\n",
      "Loss:  0.09720581769943237\n",
      "Loss:  0.08626756072044373\n",
      "Loss:  0.10508501529693604\n",
      "6 **********\n",
      "Epoch:  466.3361110687256  fold:  6  kers:  128\n",
      "epoch:  7\n",
      "29479 461\n",
      "Loss:  0.0937587171792984\n",
      "Loss:  0.10740270465612411\n",
      "Loss:  0.06604914367198944\n",
      "7 **********\n",
      "Epoch:  519.5837380886078  fold:  6  kers:  128\n",
      "epoch:  8\n",
      "29479 461\n",
      "Loss:  0.08216381072998047\n",
      "Loss:  0.11731123179197311\n",
      "Loss:  0.10744424909353256\n",
      "8 **********\n",
      "Epoch:  572.7535727024078  fold:  6  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.017724351957440376\n",
      "Eval Loss:  0.31077972054481506\n",
      "Eval Loss:  0.4304790496826172\n",
      "[[2149   83]\n",
      " [ 343  837]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      2232\n",
      "           1       0.91      0.71      0.80      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.89      0.84      0.85      3412\n",
      "weighted avg       0.88      0.88      0.87      3412\n",
      "\n",
      "acc:  0.8751465416178195\n",
      "pre:  0.9097826086956522\n",
      "rec:  0.7093220338983051\n",
      "ma F1:  0.8534825208660941\n",
      "mi F1:  0.8751465416178195\n",
      "we F1:  0.8708533667737276\n",
      "Eval Loss:  0.39231550693511963\n",
      "Eval Loss:  0.42911654710769653\n",
      "Eval Loss:  0.40181758999824524\n",
      "Eval Loss:  0.3779986500740051\n",
      "Eval Loss:  0.3543589413166046\n",
      "Eval Loss:  0.38199490308761597\n",
      "Eval Loss:  0.4677095115184784\n",
      "Eval Loss:  0.4435971677303314\n",
      "Eval Loss:  0.4421321451663971\n",
      "Eval Loss:  0.4756619334220886\n",
      "Eval Loss:  0.542945146560669\n",
      "Eval Loss:  0.4103602170944214\n",
      "Eval Loss:  0.5199851989746094\n",
      "Eval Loss:  0.4256846010684967\n",
      "Eval Loss:  0.4956470727920532\n",
      "Eval Loss:  0.36176353693008423\n",
      "Eval Loss:  0.5497584939002991\n",
      "Eval Loss:  0.4931114912033081\n",
      "Eval Loss:  0.38992834091186523\n",
      "Eval Loss:  0.6687330007553101\n",
      "Eval Loss:  0.4449211657047272\n",
      "Eval Loss:  0.4277380108833313\n",
      "Eval Loss:  0.3989737629890442\n",
      "Eval Loss:  0.415084570646286\n",
      "Eval Loss:  0.4316173195838928\n",
      "Eval Loss:  0.5545264482498169\n",
      "Eval Loss:  0.4167385995388031\n",
      "Eval Loss:  0.4796673357486725\n",
      "[[17566   366]\n",
      " [ 4940  6607]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87     17932\n",
      "           1       0.95      0.57      0.71     11547\n",
      "\n",
      "    accuracy                           0.82     29479\n",
      "   macro avg       0.86      0.78      0.79     29479\n",
      "weighted avg       0.85      0.82      0.81     29479\n",
      "\n",
      "acc:  0.8200074629397198\n",
      "pre:  0.9475118313494909\n",
      "rec:  0.5721832510608816\n",
      "ma F1:  0.7911428523969233\n",
      "mi F1:  0.8200074629397198\n",
      "we F1:  0.8079601293670624\n",
      "29479 461\n",
      "Loss:  0.08305096626281738\n",
      "Loss:  0.05478881299495697\n",
      "Loss:  0.061828866600990295\n",
      "9 **********\n",
      "Epoch:  666.3154072761536  fold:  6  kers:  128\n",
      "epoch:  10\n",
      "29479 461\n",
      "Loss:  0.09335087984800339\n",
      "Loss:  0.08158020675182343\n",
      "Loss:  0.07019897550344467\n",
      "10 **********\n",
      "Epoch:  719.3196847438812  fold:  6  kers:  128\n",
      "epoch:  11\n",
      "29479 461\n",
      "Loss:  0.09020049124956131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08658813685178757\n",
      "Loss:  0.09828490763902664\n",
      "11 **********\n",
      "Epoch:  772.3568737506866  fold:  6  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.0187936220318079\n",
      "Eval Loss:  0.35321542620658875\n",
      "Eval Loss:  0.5220750570297241\n",
      "[[2174   58]\n",
      " [ 437  743]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90      2232\n",
      "           1       0.93      0.63      0.75      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.88      0.80      0.82      3412\n",
      "weighted avg       0.87      0.85      0.85      3412\n",
      "\n",
      "acc:  0.8549237983587339\n",
      "pre:  0.9275905118601748\n",
      "rec:  0.6296610169491526\n",
      "ma F1:  0.8239584122673556\n",
      "mi F1:  0.8549237983587339\n",
      "we F1:  0.8467226234260767\n",
      "Eval Loss:  0.3306324779987335\n",
      "Eval Loss:  0.36836084723472595\n",
      "Eval Loss:  0.34601178765296936\n",
      "Eval Loss:  0.337266743183136\n",
      "Eval Loss:  0.31885409355163574\n",
      "Eval Loss:  0.31358858942985535\n",
      "Eval Loss:  0.4705897867679596\n",
      "Eval Loss:  0.4032137095928192\n",
      "Eval Loss:  0.3677481710910797\n",
      "Eval Loss:  0.39442598819732666\n",
      "Eval Loss:  0.41207897663116455\n",
      "Eval Loss:  0.33539262413978577\n",
      "Eval Loss:  0.42906469106674194\n",
      "Eval Loss:  0.38778430223464966\n",
      "Eval Loss:  0.4348793029785156\n",
      "Eval Loss:  0.2795161008834839\n",
      "Eval Loss:  0.4613923132419586\n",
      "Eval Loss:  0.3882112503051758\n",
      "Eval Loss:  0.3110979199409485\n",
      "Eval Loss:  0.6061698198318481\n",
      "Eval Loss:  0.3868594169616699\n",
      "Eval Loss:  0.38719332218170166\n",
      "Eval Loss:  0.40452951192855835\n",
      "Eval Loss:  0.33157801628112793\n",
      "Eval Loss:  0.3709004819393158\n",
      "Eval Loss:  0.45886701345443726\n",
      "Eval Loss:  0.35038307309150696\n",
      "Eval Loss:  0.37286943197250366\n",
      "[[17608   324]\n",
      " [ 4367  7180]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88     17932\n",
      "           1       0.96      0.62      0.75     11547\n",
      "\n",
      "    accuracy                           0.84     29479\n",
      "   macro avg       0.88      0.80      0.82     29479\n",
      "weighted avg       0.86      0.84      0.83     29479\n",
      "\n",
      "acc:  0.8408697717018895\n",
      "pre:  0.9568230277185501\n",
      "rec:  0.6218065298345891\n",
      "ma F1:  0.8181089533506591\n",
      "mi F1:  0.8408697717018895\n",
      "we F1:  0.8320452618635672\n",
      "29479 461\n",
      "Loss:  0.07121146470308304\n",
      "Loss:  0.08187101781368256\n",
      "Loss:  0.07442300021648407\n",
      "12 **********\n",
      "Epoch:  866.0523509979248  fold:  6  kers:  128\n",
      "epoch:  13\n",
      "29479 461\n",
      "Loss:  0.10060656815767288\n",
      "Loss:  0.0789833590388298\n",
      "Loss:  0.04941977187991142\n",
      "13 **********\n",
      "Epoch:  919.1364152431488  fold:  6  kers:  128\n",
      "epoch:  14\n",
      "29479 461\n",
      "Loss:  0.06378032267093658\n",
      "Loss:  0.05704937130212784\n",
      "Loss:  0.07160641998052597\n",
      "14 **********\n",
      "Epoch:  972.1586449146271  fold:  6  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.022632280364632607\n",
      "Eval Loss:  0.19613029062747955\n",
      "Eval Loss:  0.5048834085464478\n",
      "[[2121  111]\n",
      " [ 291  889]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      2232\n",
      "           1       0.89      0.75      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.88      0.85      0.86      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8821805392731535\n",
      "pre:  0.889\n",
      "rec:  0.7533898305084745\n",
      "ma F1:  0.8645165113908446\n",
      "mi F1:  0.8821805392731535\n",
      "we F1:  0.8795997559786604\n",
      "Eval Loss:  0.21048066020011902\n",
      "Eval Loss:  0.2997991144657135\n",
      "Eval Loss:  0.2701117694377899\n",
      "Eval Loss:  0.2463114708662033\n",
      "Eval Loss:  0.27065935730934143\n",
      "Eval Loss:  0.2599533498287201\n",
      "Eval Loss:  0.34417855739593506\n",
      "Eval Loss:  0.30007660388946533\n",
      "Eval Loss:  0.3125554919242859\n",
      "Eval Loss:  0.2855370044708252\n",
      "Eval Loss:  0.3000226318836212\n",
      "Eval Loss:  0.23476868867874146\n",
      "Eval Loss:  0.323555588722229\n",
      "Eval Loss:  0.30024176836013794\n",
      "Eval Loss:  0.30013468861579895\n",
      "Eval Loss:  0.1932147592306137\n",
      "Eval Loss:  0.34811487793922424\n",
      "Eval Loss:  0.30687448382377625\n",
      "Eval Loss:  0.22153130173683167\n",
      "Eval Loss:  0.42867404222488403\n",
      "Eval Loss:  0.2681855261325836\n",
      "Eval Loss:  0.30731165409088135\n",
      "Eval Loss:  0.3051386773586273\n",
      "Eval Loss:  0.26307299733161926\n",
      "Eval Loss:  0.28346148133277893\n",
      "Eval Loss:  0.3629823923110962\n",
      "Eval Loss:  0.28214889764785767\n",
      "Eval Loss:  0.2656398117542267\n",
      "[[17240   692]\n",
      " [ 2783  8764]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     17932\n",
      "           1       0.93      0.76      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.89      0.86      0.87     29479\n",
      "weighted avg       0.89      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8821194748804233\n",
      "pre:  0.926818950930626\n",
      "rec:  0.758985017753529\n",
      "ma F1:  0.8714958279259941\n",
      "mi F1:  0.8821194748804232\n",
      "we F1:  0.8794986577754549\n",
      "29479 461\n",
      "Loss:  0.07886794954538345\n",
      "Loss:  0.08774081617593765\n",
      "Loss:  0.08642281591892242\n",
      "15 **********\n",
      "Epoch:  1065.7723405361176  fold:  6  kers:  128\n",
      "epoch:  16\n",
      "29479 461\n",
      "Loss:  0.04679769650101662\n",
      "Loss:  0.0758119449019432\n",
      "Loss:  0.0631403923034668\n",
      "16 **********\n",
      "Epoch:  1118.8264849185944  fold:  6  kers:  128\n",
      "epoch:  17\n",
      "29479 461\n",
      "Loss:  0.03834722563624382\n",
      "Loss:  0.05118805170059204\n",
      "Loss:  0.060449179261922836\n",
      "17 **********\n",
      "Epoch:  1171.894591808319  fold:  6  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.017940450459718704\n",
      "Eval Loss:  0.1991509199142456\n",
      "Eval Loss:  0.46280771493911743\n",
      "[[2128  104]\n",
      " [ 341  839]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91      2232\n",
      "           1       0.89      0.71      0.79      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.88      0.83      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.86957796014068\n",
      "pre:  0.8897136797454931\n",
      "rec:  0.7110169491525423\n",
      "ma F1:  0.8478651228534673\n",
      "mi F1:  0.86957796014068\n",
      "we F1:  0.8655857627496253\n",
      "Eval Loss:  0.19202165305614471\n",
      "Eval Loss:  0.2609061300754547\n",
      "Eval Loss:  0.22986477613449097\n",
      "Eval Loss:  0.22425411641597748\n",
      "Eval Loss:  0.23747222125530243\n",
      "Eval Loss:  0.22416864335536957\n",
      "Eval Loss:  0.34776729345321655\n",
      "Eval Loss:  0.29671648144721985\n",
      "Eval Loss:  0.26868104934692383\n",
      "Eval Loss:  0.245059534907341\n",
      "Eval Loss:  0.24869507551193237\n",
      "Eval Loss:  0.17969325184822083\n",
      "Eval Loss:  0.28260213136672974\n",
      "Eval Loss:  0.2560158967971802\n",
      "Eval Loss:  0.2882453501224518\n",
      "Eval Loss:  0.1703694611787796\n",
      "Eval Loss:  0.2740055322647095\n",
      "Eval Loss:  0.29647254943847656\n",
      "Eval Loss:  0.2173236757516861\n",
      "Eval Loss:  0.426405131816864\n",
      "Eval Loss:  0.2447212189435959\n",
      "Eval Loss:  0.25651857256889343\n",
      "Eval Loss:  0.27484264969825745\n",
      "Eval Loss:  0.2259407341480255\n",
      "Eval Loss:  0.2646116614341736\n",
      "Eval Loss:  0.33396977186203003\n",
      "Eval Loss:  0.24305616319179535\n",
      "Eval Loss:  0.23818491399288177\n",
      "[[17240   692]\n",
      " [ 2377  9170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17932\n",
      "           1       0.93      0.79      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.88      0.89     29479\n",
      "weighted avg       0.90      0.90      0.89     29479\n",
      "\n",
      "acc:  0.8958919909087826\n",
      "pre:  0.9298316771445955\n",
      "rec:  0.7941456655408331\n",
      "ma F1:  0.8874579354351947\n",
      "mi F1:  0.8958919909087826\n",
      "we F1:  0.8941309768476925\n",
      "29479 461\n",
      "Loss:  0.08393122255802155\n",
      "Loss:  0.1029890701174736\n",
      "Loss:  0.06798164546489716\n",
      "18 **********\n",
      "Epoch:  1265.6558928489685  fold:  6  kers:  128\n",
      "epoch:  19\n",
      "29479 461\n",
      "Loss:  0.055029042065143585\n",
      "Loss:  0.0736568495631218\n",
      "Loss:  0.08525901287794113\n",
      "19 **********\n",
      "Epoch:  1318.648202419281  fold:  6  kers:  128\n",
      "epoch:  20\n",
      "29479 461\n",
      "Loss:  0.07551255077123642\n",
      "Loss:  0.0941622406244278\n",
      "Loss:  0.07644842565059662\n",
      "20 **********\n",
      "Epoch:  1371.5836634635925  fold:  6  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.01404406875371933\n",
      "Eval Loss:  0.12282907217741013\n",
      "Eval Loss:  0.5591737627983093\n",
      "[[2114  118]\n",
      " [ 313  867]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      2232\n",
      "           1       0.88      0.73      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.88      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8736811254396248\n",
      "pre:  0.8802030456852792\n",
      "rec:  0.7347457627118644\n",
      "ma F1:  0.8542073326998281\n",
      "mi F1:  0.8736811254396247\n",
      "we F1:  0.8706359052437465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17333175241947174\n",
      "Eval Loss:  0.25665977597236633\n",
      "Eval Loss:  0.21251659095287323\n",
      "Eval Loss:  0.22852183878421783\n",
      "Eval Loss:  0.2381061464548111\n",
      "Eval Loss:  0.20182786881923676\n",
      "Eval Loss:  0.38233742117881775\n",
      "Eval Loss:  0.26418405771255493\n",
      "Eval Loss:  0.24962320923805237\n",
      "Eval Loss:  0.2610766589641571\n",
      "Eval Loss:  0.2490100860595703\n",
      "Eval Loss:  0.17960214614868164\n",
      "Eval Loss:  0.2586773931980133\n",
      "Eval Loss:  0.25775283575057983\n",
      "Eval Loss:  0.2893264591693878\n",
      "Eval Loss:  0.16444315016269684\n",
      "Eval Loss:  0.2611001431941986\n",
      "Eval Loss:  0.28423160314559937\n",
      "Eval Loss:  0.20241357386112213\n",
      "Eval Loss:  0.4293637275695801\n",
      "Eval Loss:  0.2405635118484497\n",
      "Eval Loss:  0.23864203691482544\n",
      "Eval Loss:  0.2619176208972931\n",
      "Eval Loss:  0.213209331035614\n",
      "Eval Loss:  0.2539050281047821\n",
      "Eval Loss:  0.3269540071487427\n",
      "Eval Loss:  0.2565130889415741\n",
      "Eval Loss:  0.21715377271175385\n",
      "[[17227   705]\n",
      " [ 2274  9273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17932\n",
      "           1       0.93      0.80      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.91      0.88      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8989450117032464\n",
      "pre:  0.9293445580276608\n",
      "rec:  0.8030657313587944\n",
      "ma F1:  0.8910103003079788\n",
      "mi F1:  0.8989450117032464\n",
      "we F1:  0.8973798165587686\n",
      "29479 461\n",
      "Loss:  0.10229647904634476\n",
      "Loss:  0.05090019851922989\n",
      "Loss:  0.09383852034807205\n",
      "21 **********\n",
      "Epoch:  1465.0617220401764  fold:  6  kers:  128\n",
      "epoch:  22\n",
      "29479 461\n",
      "Loss:  0.05191439017653465\n",
      "Loss:  0.09045885503292084\n",
      "Loss:  0.0739525705575943\n",
      "22 **********\n",
      "Epoch:  1518.0510392189026  fold:  6  kers:  128\n",
      "epoch:  23\n",
      "29479 461\n",
      "Loss:  0.06752166152000427\n",
      "Loss:  0.06016787514090538\n",
      "Loss:  0.054197873920202255\n",
      "23 **********\n",
      "Epoch:  1570.9276583194733  fold:  6  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.015843449160456657\n",
      "Eval Loss:  0.16641618311405182\n",
      "Eval Loss:  0.2850848436355591\n",
      "[[2049  183]\n",
      " [ 291  889]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      2232\n",
      "           1       0.83      0.75      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.85      0.84      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8610785463071512\n",
      "pre:  0.8292910447761194\n",
      "rec:  0.7533898305084745\n",
      "ma F1:  0.8429229428026648\n",
      "mi F1:  0.8610785463071512\n",
      "we F1:  0.8593881970153542\n",
      "Eval Loss:  0.18424011766910553\n",
      "Eval Loss:  0.23561358451843262\n",
      "Eval Loss:  0.21007955074310303\n",
      "Eval Loss:  0.2296055406332016\n",
      "Eval Loss:  0.23588353395462036\n",
      "Eval Loss:  0.21922878921031952\n",
      "Eval Loss:  0.2904554307460785\n",
      "Eval Loss:  0.22124169766902924\n",
      "Eval Loss:  0.2488483041524887\n",
      "Eval Loss:  0.2683517336845398\n",
      "Eval Loss:  0.23246431350708008\n",
      "Eval Loss:  0.18407046794891357\n",
      "Eval Loss:  0.2655026912689209\n",
      "Eval Loss:  0.21770869195461273\n",
      "Eval Loss:  0.28647997975349426\n",
      "Eval Loss:  0.1537337452173233\n",
      "Eval Loss:  0.2617242932319641\n",
      "Eval Loss:  0.26879996061325073\n",
      "Eval Loss:  0.19817602634429932\n",
      "Eval Loss:  0.31952574849128723\n",
      "Eval Loss:  0.17152070999145508\n",
      "Eval Loss:  0.237161785364151\n",
      "Eval Loss:  0.247700035572052\n",
      "Eval Loss:  0.22945663332939148\n",
      "Eval Loss:  0.2592734396457672\n",
      "Eval Loss:  0.3117440938949585\n",
      "Eval Loss:  0.2476058453321457\n",
      "Eval Loss:  0.20079496502876282\n",
      "[[16921  1011]\n",
      " [ 1776  9771]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     17932\n",
      "           1       0.91      0.85      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.89      0.90     29479\n",
      "weighted avg       0.91      0.91      0.90     29479\n",
      "\n",
      "acc:  0.9054581227314359\n",
      "pre:  0.9062326099053979\n",
      "rec:  0.846193816575734\n",
      "ma F1:  0.8995487420339139\n",
      "mi F1:  0.9054581227314359\n",
      "we F1:  0.9048258603211417\n",
      "29479 461\n",
      "Loss:  0.0481574684381485\n",
      "Loss:  0.058717548847198486\n",
      "Loss:  0.05247128754854202\n",
      "24 **********\n",
      "Epoch:  1664.3349061012268  fold:  6  kers:  128\n",
      "epoch:  25\n",
      "29479 461\n",
      "Loss:  0.0385294146835804\n",
      "Loss:  0.10638802498579025\n",
      "Loss:  0.06114867702126503\n",
      "25 **********\n",
      "Epoch:  1717.1935727596283  fold:  6  kers:  128\n",
      "epoch:  26\n",
      "29479 461\n",
      "Loss:  0.07465234398841858\n",
      "Loss:  0.06196066737174988\n",
      "Loss:  0.03500184416770935\n",
      "26 **********\n",
      "Epoch:  1770.1021058559418  fold:  6  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.018965233117341995\n",
      "Eval Loss:  0.1222529411315918\n",
      "Eval Loss:  0.295142263174057\n",
      "[[2057  175]\n",
      " [ 232  948]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2232\n",
      "           1       0.84      0.80      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8807151230949589\n",
      "pre:  0.8441674087266251\n",
      "rec:  0.8033898305084746\n",
      "ma F1:  0.8666248297734997\n",
      "mi F1:  0.8807151230949589\n",
      "we F1:  0.879990915052287\n",
      "Eval Loss:  0.1554785668849945\n",
      "Eval Loss:  0.2612157166004181\n",
      "Eval Loss:  0.20030249655246735\n",
      "Eval Loss:  0.21881617605686188\n",
      "Eval Loss:  0.2047395408153534\n",
      "Eval Loss:  0.20576277375221252\n",
      "Eval Loss:  0.32196882367134094\n",
      "Eval Loss:  0.2338976263999939\n",
      "Eval Loss:  0.20445232093334198\n",
      "Eval Loss:  0.23139885067939758\n",
      "Eval Loss:  0.20602242648601532\n",
      "Eval Loss:  0.16671155393123627\n",
      "Eval Loss:  0.23355527222156525\n",
      "Eval Loss:  0.2259274274110794\n",
      "Eval Loss:  0.262288361787796\n",
      "Eval Loss:  0.12687551975250244\n",
      "Eval Loss:  0.23395845293998718\n",
      "Eval Loss:  0.2717396914958954\n",
      "Eval Loss:  0.16913442313671112\n",
      "Eval Loss:  0.3356035053730011\n",
      "Eval Loss:  0.17474457621574402\n",
      "Eval Loss:  0.1946539580821991\n",
      "Eval Loss:  0.21031413972377777\n",
      "Eval Loss:  0.17195488512516022\n",
      "Eval Loss:  0.21093620359897614\n",
      "Eval Loss:  0.2794768512248993\n",
      "Eval Loss:  0.19256530702114105\n",
      "Eval Loss:  0.17203523218631744\n",
      "[[16905  1027]\n",
      " [ 1504 10043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17932\n",
      "           1       0.91      0.87      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.914142270769022\n",
      "pre:  0.907226738934056\n",
      "rec:  0.8697497185416125\n",
      "ma F1:  0.9092235864121698\n",
      "mi F1:  0.914142270769022\n",
      "we F1:  0.9138003569773843\n",
      "29479 461\n",
      "Loss:  0.07215943932533264\n",
      "Loss:  0.06680016964673996\n",
      "Loss:  0.03806200623512268\n",
      "27 **********\n",
      "Epoch:  1863.4375457763672  fold:  6  kers:  128\n",
      "epoch:  28\n",
      "29479 461\n",
      "Loss:  0.03853142261505127\n",
      "Loss:  0.04610936716198921\n",
      "Loss:  0.05999993532896042\n",
      "28 **********\n",
      "Epoch:  1921.368651151657  fold:  6  kers:  128\n",
      "epoch:  29\n",
      "29479 461\n",
      "Loss:  0.05470949411392212\n",
      "Loss:  0.038857582956552505\n",
      "Loss:  0.07016076147556305\n",
      "29 **********\n",
      "Epoch:  1974.388884305954  fold:  6  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.017617065459489822\n",
      "Eval Loss:  0.09722951054573059\n",
      "Eval Loss:  0.3907082974910736\n",
      "[[2078  154]\n",
      " [ 310  870]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      2232\n",
      "           1       0.85      0.74      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8640093786635404\n",
      "pre:  0.849609375\n",
      "rec:  0.7372881355932204\n",
      "ma F1:  0.8445203918888129\n",
      "mi F1:  0.8640093786635404\n",
      "we F1:  0.8614925889807113\n",
      "Eval Loss:  0.18738402426242828\n",
      "Eval Loss:  0.25783464312553406\n",
      "Eval Loss:  0.18154487013816833\n",
      "Eval Loss:  0.21776200830936432\n",
      "Eval Loss:  0.18230605125427246\n",
      "Eval Loss:  0.18657146394252777\n",
      "Eval Loss:  0.28264957666397095\n",
      "Eval Loss:  0.2240237146615982\n",
      "Eval Loss:  0.22483085095882416\n",
      "Eval Loss:  0.26156482100486755\n",
      "Eval Loss:  0.2218385487794876\n",
      "Eval Loss:  0.18067608773708344\n",
      "Eval Loss:  0.22647744417190552\n",
      "Eval Loss:  0.21199265122413635\n",
      "Eval Loss:  0.26251280307769775\n",
      "Eval Loss:  0.1394370198249817\n",
      "Eval Loss:  0.23562851548194885\n",
      "Eval Loss:  0.2785295844078064\n",
      "Eval Loss:  0.16469496488571167\n",
      "Eval Loss:  0.3217392861843109\n",
      "Eval Loss:  0.17777831852436066\n",
      "Eval Loss:  0.17172595858573914\n",
      "Eval Loss:  0.2155262529850006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17132440209388733\n",
      "Eval Loss:  0.21128307282924652\n",
      "Eval Loss:  0.269000768661499\n",
      "Eval Loss:  0.19160540401935577\n",
      "Eval Loss:  0.1632317751646042\n",
      "[[16996   936]\n",
      " [ 1584  9963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     17932\n",
      "           1       0.91      0.86      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.914515417755012\n",
      "pre:  0.9141205615194055\n",
      "rec:  0.8628215120810601\n",
      "ma F1:  0.909356074210006\n",
      "mi F1:  0.914515417755012\n",
      "we F1:  0.9140400509674159\n",
      "29479 461\n",
      "Loss:  0.05555393919348717\n",
      "Loss:  0.07800941914319992\n",
      "Loss:  0.05240539833903313\n",
      "30 **********\n",
      "Epoch:  2073.242570400238  fold:  6  kers:  128\n",
      "epoch:  31\n",
      "29479 461\n",
      "Loss:  0.04826424643397331\n",
      "Loss:  0.08113168925046921\n",
      "Loss:  0.0812310129404068\n",
      "31 **********\n",
      "Epoch:  2126.2039618492126  fold:  6  kers:  128\n",
      "epoch:  32\n",
      "29479 461\n",
      "Loss:  0.05779168754816055\n",
      "Loss:  0.05119040235877037\n",
      "Loss:  0.05855339393019676\n",
      "32 **********\n",
      "Epoch:  2179.1902871131897  fold:  6  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.022181157022714615\n",
      "Eval Loss:  0.09432020783424377\n",
      "Eval Loss:  0.28318214416503906\n",
      "[[2036  196]\n",
      " [ 235  945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90      2232\n",
      "           1       0.83      0.80      0.81      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.86      0.86      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8736811254396248\n",
      "pre:  0.8282208588957055\n",
      "rec:  0.8008474576271186\n",
      "ma F1:  0.8592951053838109\n",
      "mi F1:  0.8736811254396247\n",
      "we F1:  0.8731668680774097\n",
      "Eval Loss:  0.17869576811790466\n",
      "Eval Loss:  0.2711062431335449\n",
      "Eval Loss:  0.18401461839675903\n",
      "Eval Loss:  0.22028271853923798\n",
      "Eval Loss:  0.19388751685619354\n",
      "Eval Loss:  0.17340658605098724\n",
      "Eval Loss:  0.3113693594932556\n",
      "Eval Loss:  0.239195317029953\n",
      "Eval Loss:  0.20622459053993225\n",
      "Eval Loss:  0.2582227885723114\n",
      "Eval Loss:  0.2018282413482666\n",
      "Eval Loss:  0.16911771893501282\n",
      "Eval Loss:  0.21024449169635773\n",
      "Eval Loss:  0.21534132957458496\n",
      "Eval Loss:  0.2604863941669464\n",
      "Eval Loss:  0.10618632286787033\n",
      "Eval Loss:  0.2311529517173767\n",
      "Eval Loss:  0.2439083755016327\n",
      "Eval Loss:  0.1514534205198288\n",
      "Eval Loss:  0.30204254388809204\n",
      "Eval Loss:  0.16013146936893463\n",
      "Eval Loss:  0.16814039647579193\n",
      "Eval Loss:  0.2082539051771164\n",
      "Eval Loss:  0.1672705113887787\n",
      "Eval Loss:  0.21159499883651733\n",
      "Eval Loss:  0.23396754264831543\n",
      "Eval Loss:  0.1834692507982254\n",
      "Eval Loss:  0.15718621015548706\n",
      "[[16731  1201]\n",
      " [ 1263 10284]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17932\n",
      "           1       0.90      0.89      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.916415075138234\n",
      "pre:  0.8954288202002612\n",
      "rec:  0.8906209405040271\n",
      "ma F1:  0.9122164917863951\n",
      "mi F1:  0.916415075138234\n",
      "we F1:  0.916374697882485\n",
      "29479 461\n",
      "Loss:  0.043188370764255524\n",
      "Loss:  0.07171795517206192\n",
      "Loss:  0.04578213021159172\n",
      "33 **********\n",
      "Epoch:  2272.8648207187653  fold:  6  kers:  128\n",
      "epoch:  34\n",
      "29479 461\n",
      "Loss:  0.04919616878032684\n",
      "Loss:  0.05552394688129425\n",
      "Loss:  0.07533422857522964\n",
      "34 **********\n",
      "Epoch:  2325.9269433021545  fold:  6  kers:  128\n",
      "epoch:  35\n",
      "29479 461\n",
      "Loss:  0.056130550801754\n",
      "Loss:  0.04907282069325447\n",
      "Loss:  0.0206107459962368\n",
      "35 **********\n",
      "Epoch:  2378.9741060733795  fold:  6  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.018310697749257088\n",
      "Eval Loss:  0.11244510859251022\n",
      "Eval Loss:  0.3324267268180847\n",
      "[[2100  132]\n",
      " [ 332  848]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      2232\n",
      "           1       0.87      0.72      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8640093786635404\n",
      "pre:  0.8653061224489796\n",
      "rec:  0.7186440677966102\n",
      "ma F1:  0.842849882472524\n",
      "mi F1:  0.8640093786635404\n",
      "we F1:  0.860629267450918\n",
      "Eval Loss:  0.160629004240036\n",
      "Eval Loss:  0.237131267786026\n",
      "Eval Loss:  0.16651524603366852\n",
      "Eval Loss:  0.2345675826072693\n",
      "Eval Loss:  0.17815254628658295\n",
      "Eval Loss:  0.15359513461589813\n",
      "Eval Loss:  0.29958376288414\n",
      "Eval Loss:  0.21975736320018768\n",
      "Eval Loss:  0.20864833891391754\n",
      "Eval Loss:  0.2623368203639984\n",
      "Eval Loss:  0.18806922435760498\n",
      "Eval Loss:  0.18216092884540558\n",
      "Eval Loss:  0.20699727535247803\n",
      "Eval Loss:  0.21675322949886322\n",
      "Eval Loss:  0.24426046013832092\n",
      "Eval Loss:  0.1470724493265152\n",
      "Eval Loss:  0.23308657109737396\n",
      "Eval Loss:  0.2702961266040802\n",
      "Eval Loss:  0.1779848337173462\n",
      "Eval Loss:  0.2911129593849182\n",
      "Eval Loss:  0.15520456433296204\n",
      "Eval Loss:  0.1609974056482315\n",
      "Eval Loss:  0.19399605691432953\n",
      "Eval Loss:  0.16437400877475739\n",
      "Eval Loss:  0.23602966964244843\n",
      "Eval Loss:  0.2574617266654968\n",
      "Eval Loss:  0.16999255120754242\n",
      "Eval Loss:  0.14906105399131775\n",
      "[[17008   924]\n",
      " [ 1453 10094]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     17932\n",
      "           1       0.92      0.87      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9193663285728824\n",
      "pre:  0.9161372299872935\n",
      "rec:  0.8741664501602148\n",
      "ma F1:  0.914672556574869\n",
      "mi F1:  0.9193663285728824\n",
      "we F1:  0.9190072013835637\n",
      "29479 461\n",
      "Loss:  0.040213167667388916\n",
      "Loss:  0.06273593008518219\n",
      "Loss:  0.062492989003658295\n",
      "36 **********\n",
      "Epoch:  2472.636671066284  fold:  6  kers:  128\n",
      "epoch:  37\n",
      "29479 461\n",
      "Loss:  0.03996841609477997\n",
      "Loss:  0.06151013448834419\n",
      "Loss:  0.03561259061098099\n",
      "37 **********\n",
      "Epoch:  2525.6150181293488  fold:  6  kers:  128\n",
      "epoch:  38\n",
      "29479 461\n",
      "Loss:  0.038225818425416946\n",
      "Loss:  0.04990581050515175\n",
      "Loss:  0.04444890096783638\n",
      "38 **********\n",
      "Epoch:  2578.639241695404  fold:  6  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.008339634165167809\n",
      "Eval Loss:  0.1223982498049736\n",
      "Eval Loss:  0.45652446150779724\n",
      "[[2137   95]\n",
      " [ 401  779]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      2232\n",
      "           1       0.89      0.66      0.76      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.87      0.81      0.83      3412\n",
      "weighted avg       0.86      0.85      0.85      3412\n",
      "\n",
      "acc:  0.854630715123095\n",
      "pre:  0.8913043478260869\n",
      "rec:  0.6601694915254237\n",
      "ma F1:  0.8272683662700382\n",
      "mi F1:  0.854630715123095\n",
      "we F1:  0.8484651195788863\n",
      "Eval Loss:  0.178529292345047\n",
      "Eval Loss:  0.21521063148975372\n",
      "Eval Loss:  0.17042329907417297\n",
      "Eval Loss:  0.2404850870370865\n",
      "Eval Loss:  0.16861282289028168\n",
      "Eval Loss:  0.16874563694000244\n",
      "Eval Loss:  0.32474401593208313\n",
      "Eval Loss:  0.23461562395095825\n",
      "Eval Loss:  0.22848960757255554\n",
      "Eval Loss:  0.25655266642570496\n",
      "Eval Loss:  0.19506774842739105\n",
      "Eval Loss:  0.21451693773269653\n",
      "Eval Loss:  0.23549507558345795\n",
      "Eval Loss:  0.1966855823993683\n",
      "Eval Loss:  0.2197367399930954\n",
      "Eval Loss:  0.15060769021511078\n",
      "Eval Loss:  0.246712327003479\n",
      "Eval Loss:  0.26283007860183716\n",
      "Eval Loss:  0.21525788307189941\n",
      "Eval Loss:  0.3558683693408966\n",
      "Eval Loss:  0.16375413537025452\n",
      "Eval Loss:  0.20546391606330872\n",
      "Eval Loss:  0.21042901277542114\n",
      "Eval Loss:  0.21701747179031372\n",
      "Eval Loss:  0.20141012966632843\n",
      "Eval Loss:  0.23549826443195343\n",
      "Eval Loss:  0.20001806318759918\n",
      "Eval Loss:  0.20456768572330475\n",
      "[[17347   585]\n",
      " [ 1935  9612]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93     17932\n",
      "           1       0.94      0.83      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.92      0.90      0.91     29479\n",
      "weighted avg       0.92      0.91      0.91     29479\n",
      "\n",
      "acc:  0.914515417755012\n",
      "pre:  0.942630185348632\n",
      "rec:  0.8324240062353858\n",
      "ma F1:  0.9081947547334069\n",
      "mi F1:  0.914515417755012\n",
      "we F1:  0.9134122638986234\n",
      "29479 461\n",
      "Loss:  0.035329096019268036\n",
      "Loss:  0.0620182566344738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.046491894870996475\n",
      "39 **********\n",
      "Epoch:  2672.311780691147  fold:  6  kers:  128\n",
      "epoch:  40\n",
      "29479 461\n",
      "Loss:  0.0811830535531044\n",
      "Loss:  0.031608156859874725\n",
      "Loss:  0.0444357767701149\n",
      "40 **********\n",
      "Epoch:  2725.3938496112823  fold:  6  kers:  128\n",
      "epoch:  41\n",
      "29479 461\n",
      "Loss:  0.07996596395969391\n",
      "Loss:  0.05616309121251106\n",
      "Loss:  0.09347870945930481\n",
      "41 **********\n",
      "Epoch:  2778.3831672668457  fold:  6  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.008837088011205196\n",
      "Eval Loss:  0.21678811311721802\n",
      "Eval Loss:  0.4604329764842987\n",
      "[[2179   53]\n",
      " [ 456  724]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90      2232\n",
      "           1       0.93      0.61      0.74      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.88      0.79      0.82      3412\n",
      "weighted avg       0.86      0.85      0.84      3412\n",
      "\n",
      "acc:  0.8508206330597889\n",
      "pre:  0.9317889317889317\n",
      "rec:  0.6135593220338983\n",
      "ma F1:  0.8176630722649141\n",
      "mi F1:  0.8508206330597889\n",
      "we F1:  0.8416367863241638\n",
      "Eval Loss:  0.22285068035125732\n",
      "Eval Loss:  0.22493034601211548\n",
      "Eval Loss:  0.19029822945594788\n",
      "Eval Loss:  0.28143593668937683\n",
      "Eval Loss:  0.1833910346031189\n",
      "Eval Loss:  0.20562973618507385\n",
      "Eval Loss:  0.39628490805625916\n",
      "Eval Loss:  0.2700648009777069\n",
      "Eval Loss:  0.22925809025764465\n",
      "Eval Loss:  0.29866787791252136\n",
      "Eval Loss:  0.2679762542247772\n",
      "Eval Loss:  0.22751621901988983\n",
      "Eval Loss:  0.2545536160469055\n",
      "Eval Loss:  0.2133893221616745\n",
      "Eval Loss:  0.28287646174430847\n",
      "Eval Loss:  0.16946449875831604\n",
      "Eval Loss:  0.2792081832885742\n",
      "Eval Loss:  0.2867332398891449\n",
      "Eval Loss:  0.25704094767570496\n",
      "Eval Loss:  0.37004637718200684\n",
      "Eval Loss:  0.16707102954387665\n",
      "Eval Loss:  0.23194913566112518\n",
      "Eval Loss:  0.22236678004264832\n",
      "Eval Loss:  0.2682245671749115\n",
      "Eval Loss:  0.2552100121974945\n",
      "Eval Loss:  0.2526828348636627\n",
      "Eval Loss:  0.2159692943096161\n",
      "Eval Loss:  0.21013401448726654\n",
      "[[17433   499]\n",
      " [ 2383  9164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     17932\n",
      "           1       0.95      0.79      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.91      0.88      0.89     29479\n",
      "weighted avg       0.91      0.90      0.90     29479\n",
      "\n",
      "acc:  0.902235489670613\n",
      "pre:  0.9483597226534203\n",
      "rec:  0.7936260500562917\n",
      "ma F1:  0.8938861409869776\n",
      "mi F1:  0.902235489670613\n",
      "we F1:  0.9003331831135966\n",
      "29479 461\n",
      "Loss:  0.06123988702893257\n",
      "Loss:  0.052467018365859985\n",
      "Loss:  0.038759879767894745\n",
      "42 **********\n",
      "Epoch:  2872.192340373993  fold:  6  kers:  128\n",
      "epoch:  43\n",
      "29479 461\n",
      "Loss:  0.037753306329250336\n",
      "Loss:  0.06707248836755753\n",
      "Loss:  0.056028906255960464\n",
      "43 **********\n",
      "Epoch:  2925.2385058403015  fold:  6  kers:  128\n",
      "epoch:  44\n",
      "29479 461\n",
      "Loss:  0.03485992178320885\n",
      "Loss:  0.05912984535098076\n",
      "Loss:  0.055880483239889145\n",
      "44 **********\n",
      "Epoch:  2978.338527441025  fold:  6  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.02636057883501053\n",
      "Eval Loss:  0.04319693148136139\n",
      "Eval Loss:  0.2827965319156647\n",
      "[[2016  216]\n",
      " [ 223  957]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      2232\n",
      "           1       0.82      0.81      0.81      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.86      0.86      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8713364595545134\n",
      "pre:  0.8158567774936062\n",
      "rec:  0.8110169491525424\n",
      "ma F1:  0.857620669749416\n",
      "mi F1:  0.8713364595545134\n",
      "we F1:  0.8712457980543853\n",
      "Eval Loss:  0.18063460290431976\n",
      "Eval Loss:  0.2635282874107361\n",
      "Eval Loss:  0.173359677195549\n",
      "Eval Loss:  0.22504019737243652\n",
      "Eval Loss:  0.16749657690525055\n",
      "Eval Loss:  0.17702074348926544\n",
      "Eval Loss:  0.2593024671077728\n",
      "Eval Loss:  0.22316788136959076\n",
      "Eval Loss:  0.19434480369091034\n",
      "Eval Loss:  0.2224004566669464\n",
      "Eval Loss:  0.1937476545572281\n",
      "Eval Loss:  0.1677369773387909\n",
      "Eval Loss:  0.1990169882774353\n",
      "Eval Loss:  0.20110248029232025\n",
      "Eval Loss:  0.22776572406291962\n",
      "Eval Loss:  0.10028946399688721\n",
      "Eval Loss:  0.22661234438419342\n",
      "Eval Loss:  0.2670837640762329\n",
      "Eval Loss:  0.14783251285552979\n",
      "Eval Loss:  0.24813663959503174\n",
      "Eval Loss:  0.16675060987472534\n",
      "Eval Loss:  0.12877331674098969\n",
      "Eval Loss:  0.19310025870800018\n",
      "Eval Loss:  0.13839899003505707\n",
      "Eval Loss:  0.2043529599905014\n",
      "Eval Loss:  0.20303618907928467\n",
      "Eval Loss:  0.16544705629348755\n",
      "Eval Loss:  0.13132695853710175\n",
      "[[16770  1162]\n",
      " [ 1120 10427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     17932\n",
      "           1       0.90      0.90      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.92      0.92     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9225889616337053\n",
      "pre:  0.8997325049616015\n",
      "rec:  0.9030051095522647\n",
      "ma F1:  0.9188309838302231\n",
      "mi F1:  0.9225889616337053\n",
      "we F1:  0.9226138449803467\n",
      "29479 461\n",
      "Loss:  0.07117700576782227\n",
      "Loss:  0.03782286122441292\n",
      "Loss:  0.04302835091948509\n",
      "45 **********\n",
      "Epoch:  3072.138725042343  fold:  6  kers:  128\n",
      "epoch:  46\n",
      "29479 461\n",
      "Loss:  0.03781215846538544\n",
      "Loss:  0.05306553095579147\n",
      "Loss:  0.050841234624385834\n",
      "46 **********\n",
      "Epoch:  3125.12903881073  fold:  6  kers:  128\n",
      "epoch:  47\n",
      "29479 461\n",
      "Loss:  0.03340347856283188\n",
      "Loss:  0.03132932633161545\n",
      "Loss:  0.05661722645163536\n",
      "47 **********\n",
      "Epoch:  3178.1193540096283  fold:  6  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.013115747831761837\n",
      "Eval Loss:  0.11853562295436859\n",
      "Eval Loss:  0.27987340092658997\n",
      "[[2094  138]\n",
      " [ 317  863]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      2232\n",
      "           1       0.86      0.73      0.79      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.83      0.85      3412\n",
      "weighted avg       0.87      0.87      0.86      3412\n",
      "\n",
      "acc:  0.8666471277842908\n",
      "pre:  0.8621378621378621\n",
      "rec:  0.7313559322033898\n",
      "ma F1:  0.8466915580814987\n",
      "mi F1:  0.8666471277842908\n",
      "we F1:  0.8637453836926582\n",
      "Eval Loss:  0.15600916743278503\n",
      "Eval Loss:  0.219099760055542\n",
      "Eval Loss:  0.17317745089530945\n",
      "Eval Loss:  0.22765083611011505\n",
      "Eval Loss:  0.17555908858776093\n",
      "Eval Loss:  0.14050614833831787\n",
      "Eval Loss:  0.30696901679039\n",
      "Eval Loss:  0.22340422868728638\n",
      "Eval Loss:  0.1783069372177124\n",
      "Eval Loss:  0.25891414284706116\n",
      "Eval Loss:  0.1913696676492691\n",
      "Eval Loss:  0.1805674433708191\n",
      "Eval Loss:  0.1968170702457428\n",
      "Eval Loss:  0.20028358697891235\n",
      "Eval Loss:  0.2607916593551636\n",
      "Eval Loss:  0.12054545432329178\n",
      "Eval Loss:  0.2434634566307068\n",
      "Eval Loss:  0.2521253526210785\n",
      "Eval Loss:  0.1807864010334015\n",
      "Eval Loss:  0.2808897793292999\n",
      "Eval Loss:  0.1406504511833191\n",
      "Eval Loss:  0.13228005170822144\n",
      "Eval Loss:  0.18488793075084686\n",
      "Eval Loss:  0.14916932582855225\n",
      "Eval Loss:  0.20476534962654114\n",
      "Eval Loss:  0.24377869069576263\n",
      "Eval Loss:  0.1437525898218155\n",
      "Eval Loss:  0.12983669340610504\n",
      "[[16934   998]\n",
      " [ 1242 10305]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     17932\n",
      "           1       0.91      0.89      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.92      0.92     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9240137046711218\n",
      "pre:  0.9117048571175794\n",
      "rec:  0.8924395946999221\n",
      "ma F1:  0.9199666257730577\n",
      "mi F1:  0.9240137046711218\n",
      "we F1:  0.9238647399326805\n",
      "29479 461\n",
      "Loss:  0.06948737800121307\n",
      "Loss:  0.052522093057632446\n",
      "Loss:  0.04843343794345856\n",
      "48 **********\n",
      "Epoch:  3271.829791545868  fold:  6  kers:  128\n",
      "epoch:  49\n",
      "29479 461\n",
      "Loss:  0.035423558205366135\n",
      "Loss:  0.041718821972608566\n",
      "Loss:  0.06175298988819122\n",
      "49 **********\n",
      "Epoch:  3324.897897720337  fold:  6  kers:  128\n",
      "epoch:  50\n",
      "29479 461\n",
      "Loss:  0.0586174800992012\n",
      "Loss:  0.037362925708293915\n",
      "Loss:  0.07983645796775818\n",
      "50 **********\n",
      "Epoch:  3377.970991373062  fold:  6  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.020512614399194717\n",
      "Eval Loss:  0.05631570890545845\n",
      "Eval Loss:  0.2779061794281006\n",
      "[[2039  193]\n",
      " [ 239  941]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90      2232\n",
      "           1       0.83      0.80      0.81      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.86      0.86      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8733880422039859\n",
      "pre:  0.8298059964726632\n",
      "rec:  0.7974576271186441\n",
      "ma F1:  0.8587615727654094\n",
      "mi F1:  0.8733880422039859\n",
      "we F1:  0.8727752757247741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1345110684633255\n",
      "Eval Loss:  0.27417701482772827\n",
      "Eval Loss:  0.16526897251605988\n",
      "Eval Loss:  0.20961757004261017\n",
      "Eval Loss:  0.16908960044384003\n",
      "Eval Loss:  0.16271139681339264\n",
      "Eval Loss:  0.2621033787727356\n",
      "Eval Loss:  0.19867190718650818\n",
      "Eval Loss:  0.17802447080612183\n",
      "Eval Loss:  0.22831858694553375\n",
      "Eval Loss:  0.1783106029033661\n",
      "Eval Loss:  0.1680149883031845\n",
      "Eval Loss:  0.17501933872699738\n",
      "Eval Loss:  0.18946240842342377\n",
      "Eval Loss:  0.2028365582227707\n",
      "Eval Loss:  0.11533069610595703\n",
      "Eval Loss:  0.22040590643882751\n",
      "Eval Loss:  0.2547987997531891\n",
      "Eval Loss:  0.13903236389160156\n",
      "Eval Loss:  0.2343391478061676\n",
      "Eval Loss:  0.16945640742778778\n",
      "Eval Loss:  0.12134268879890442\n",
      "Eval Loss:  0.1805274337530136\n",
      "Eval Loss:  0.11826687306165695\n",
      "Eval Loss:  0.1838354468345642\n",
      "Eval Loss:  0.22452500462532043\n",
      "Eval Loss:  0.17621932923793793\n",
      "Eval Loss:  0.12310238927602768\n",
      "[[16535  1397]\n",
      " [  829 10718]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     17932\n",
      "           1       0.88      0.93      0.91     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.93      0.92     29479\n",
      "weighted avg       0.93      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9244886190169272\n",
      "pre:  0.8846884028064383\n",
      "rec:  0.9282064605525244\n",
      "ma F1:  0.921429237773929\n",
      "mi F1:  0.9244886190169272\n",
      "we F1:  0.9247873517908696\n",
      "29479 461\n",
      "Loss:  0.03467181697487831\n",
      "Loss:  0.05803028866648674\n",
      "Loss:  0.05330473929643631\n",
      "51 **********\n",
      "Epoch:  3471.644527196884  fold:  6  kers:  128\n",
      "epoch:  52\n",
      "29479 461\n",
      "Loss:  0.04824163392186165\n",
      "Loss:  0.04317343607544899\n",
      "Loss:  0.05242503806948662\n",
      "52 **********\n",
      "Epoch:  3524.6268634796143  fold:  6  kers:  128\n",
      "epoch:  53\n",
      "29479 461\n",
      "Loss:  0.04084452614188194\n",
      "Loss:  0.05050372704863548\n",
      "Loss:  0.05886118859052658\n",
      "53 **********\n",
      "Epoch:  3577.7238924503326  fold:  6  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.01482592336833477\n",
      "Eval Loss:  0.035939041525125504\n",
      "Eval Loss:  0.2257479578256607\n",
      "[[2052  180]\n",
      " [ 288  892]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      2232\n",
      "           1       0.83      0.76      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.85      0.84      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8628370457209847\n",
      "pre:  0.832089552238806\n",
      "rec:  0.7559322033898305\n",
      "ma F1:  0.8449112599823778\n",
      "mi F1:  0.8628370457209847\n",
      "we F1:  0.8611680932556661\n",
      "Eval Loss:  0.12739616632461548\n",
      "Eval Loss:  0.23849938809871674\n",
      "Eval Loss:  0.154276043176651\n",
      "Eval Loss:  0.20656082034111023\n",
      "Eval Loss:  0.1647460013628006\n",
      "Eval Loss:  0.14805157482624054\n",
      "Eval Loss:  0.27844762802124023\n",
      "Eval Loss:  0.21858352422714233\n",
      "Eval Loss:  0.17247892916202545\n",
      "Eval Loss:  0.21327580511569977\n",
      "Eval Loss:  0.1808026134967804\n",
      "Eval Loss:  0.16517943143844604\n",
      "Eval Loss:  0.16394616663455963\n",
      "Eval Loss:  0.19351477921009064\n",
      "Eval Loss:  0.20810562372207642\n",
      "Eval Loss:  0.07845637947320938\n",
      "Eval Loss:  0.21009549498558044\n",
      "Eval Loss:  0.2154020071029663\n",
      "Eval Loss:  0.13555386662483215\n",
      "Eval Loss:  0.23868447542190552\n",
      "Eval Loss:  0.157708540558815\n",
      "Eval Loss:  0.10421069711446762\n",
      "Eval Loss:  0.16174840927124023\n",
      "Eval Loss:  0.12048257887363434\n",
      "Eval Loss:  0.1966853141784668\n",
      "Eval Loss:  0.2160799205303192\n",
      "Eval Loss:  0.14407064020633698\n",
      "Eval Loss:  0.12048672139644623\n",
      "[[16854  1078]\n",
      " [ 1016 10531]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     17932\n",
      "           1       0.91      0.91      0.91     11547\n",
      "\n",
      "    accuracy                           0.93     29479\n",
      "   macro avg       0.93      0.93      0.93     29479\n",
      "weighted avg       0.93      0.93      0.93     29479\n",
      "\n",
      "acc:  0.9289663828488076\n",
      "pre:  0.9071410112843483\n",
      "rec:  0.912011777950983\n",
      "ma F1:  0.925540760646387\n",
      "mi F1:  0.9289663828488076\n",
      "we F1:  0.9289999726916908\n",
      "29479 461\n",
      "Loss:  0.030890053138136864\n",
      "Loss:  0.05769691988825798\n",
      "Loss:  0.0593513622879982\n",
      "54 **********\n",
      "Epoch:  3671.3645164966583  fold:  6  kers:  128\n",
      "epoch:  55\n",
      "29479 461\n",
      "Loss:  0.0916413813829422\n",
      "Loss:  0.054601337760686874\n",
      "Loss:  0.048626504838466644\n",
      "55 **********\n",
      "Epoch:  3724.408687353134  fold:  6  kers:  128\n",
      "epoch:  56\n",
      "29479 461\n",
      "Loss:  0.07531057298183441\n",
      "Loss:  0.038039591163396835\n",
      "Loss:  0.06404813379049301\n",
      "56 **********\n",
      "Epoch:  3777.4747993946075  fold:  6  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.012483811937272549\n",
      "Eval Loss:  0.13531596958637238\n",
      "Eval Loss:  0.31885939836502075\n",
      "[[2107  125]\n",
      " [ 360  820]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.90      2232\n",
      "           1       0.87      0.69      0.77      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.86      0.82      0.83      3412\n",
      "weighted avg       0.86      0.86      0.85      3412\n",
      "\n",
      "acc:  0.8578546307151231\n",
      "pre:  0.8677248677248677\n",
      "rec:  0.6949152542372882\n",
      "ma F1:  0.834275628106105\n",
      "mi F1:  0.8578546307151231\n",
      "we F1:  0.8535492184283172\n",
      "Eval Loss:  0.15395742654800415\n",
      "Eval Loss:  0.22274114191532135\n",
      "Eval Loss:  0.15566106140613556\n",
      "Eval Loss:  0.2455628663301468\n",
      "Eval Loss:  0.17991121113300323\n",
      "Eval Loss:  0.16124053299427032\n",
      "Eval Loss:  0.2976355254650116\n",
      "Eval Loss:  0.23297050595283508\n",
      "Eval Loss:  0.1838887333869934\n",
      "Eval Loss:  0.2433708906173706\n",
      "Eval Loss:  0.2432316392660141\n",
      "Eval Loss:  0.18687517940998077\n",
      "Eval Loss:  0.19014804065227509\n",
      "Eval Loss:  0.21047112345695496\n",
      "Eval Loss:  0.2368314564228058\n",
      "Eval Loss:  0.1116173043847084\n",
      "Eval Loss:  0.24184562265872955\n",
      "Eval Loss:  0.2562290132045746\n",
      "Eval Loss:  0.2012006640434265\n",
      "Eval Loss:  0.25303709506988525\n",
      "Eval Loss:  0.1324467808008194\n",
      "Eval Loss:  0.14491359889507294\n",
      "Eval Loss:  0.17358548939228058\n",
      "Eval Loss:  0.16729165613651276\n",
      "Eval Loss:  0.20623821020126343\n",
      "Eval Loss:  0.23804494738578796\n",
      "Eval Loss:  0.13809862732887268\n",
      "Eval Loss:  0.17800085246562958\n",
      "[[17152   780]\n",
      " [ 1559  9988]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     17932\n",
      "           1       0.93      0.86      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.92     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9206553817972116\n",
      "pre:  0.9275631500742942\n",
      "rec:  0.8649865765999827\n",
      "ma F1:  0.9156752513880453\n",
      "mi F1:  0.9206553817972116\n",
      "we F1:  0.9201138517038644\n",
      "29479 461\n",
      "Loss:  0.031034212559461594\n",
      "Loss:  0.029157981276512146\n",
      "Loss:  0.0534081794321537\n",
      "57 **********\n",
      "Epoch:  3871.169280052185  fold:  6  kers:  128\n",
      "epoch:  58\n",
      "29479 461\n",
      "Loss:  0.04291372746229172\n",
      "Loss:  0.05438203364610672\n",
      "Loss:  0.06710192561149597\n",
      "58 **********\n",
      "Epoch:  3924.296228647232  fold:  6  kers:  128\n",
      "epoch:  59\n",
      "29479 461\n",
      "Loss:  0.04564773291349411\n",
      "Loss:  0.07098817080259323\n",
      "Loss:  0.028520723804831505\n",
      "59 **********\n",
      "Epoch:  3977.2885382175446  fold:  6  kers:  128\n",
      "Eval Loss:  0.014300692826509476\n",
      "Eval Loss:  0.04114682972431183\n",
      "Eval Loss:  0.3078213930130005\n",
      "[[2061  171]\n",
      " [ 335  845]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      2232\n",
      "           1       0.83      0.72      0.77      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.85      0.82      0.83      3412\n",
      "weighted avg       0.85      0.85      0.85      3412\n",
      "\n",
      "acc:  0.8516998827667057\n",
      "pre:  0.8316929133858267\n",
      "rec:  0.7161016949152542\n",
      "ma F1:  0.8301232853636611\n",
      "mi F1:  0.8516998827667057\n",
      "we F1:  0.8487898811432688\n",
      "update!  Acc:  0.8824736225087925\n",
      "Epoch:  3981.538175344467  fold:  6  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.15866532921791077\n",
      "Loss:  0.1618976593017578\n",
      "Loss:  0.13957884907722473\n",
      "0 **********\n",
      "Epoch:  65.49787163734436  fold:  7  kers:  128\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.11615493148565292\n",
      "Loss:  0.12697699666023254\n",
      "Loss:  0.1024334505200386\n",
      "1 **********\n",
      "Epoch:  118.6986231803894  fold:  7  kers:  128\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.10878762602806091\n",
      "Loss:  0.10980191081762314\n",
      "Loss:  0.10539527982473373\n",
      "2 **********\n",
      "Epoch:  171.93228721618652  fold:  7  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.7342475056648254\n",
      "Eval Loss:  0.13004712760448456\n",
      "Eval Loss:  2.144118070602417\n",
      "[[1718  409]\n",
      " [ 673  631]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76      2127\n",
      "           1       0.61      0.48      0.54      1304\n",
      "\n",
      "    accuracy                           0.68      3431\n",
      "   macro avg       0.66      0.65      0.65      3431\n",
      "weighted avg       0.68      0.68      0.68      3431\n",
      "\n",
      "acc:  0.6846400466336345\n",
      "pre:  0.6067307692307692\n",
      "rec:  0.4838957055214724\n",
      "ma F1:  0.649454702993109\n",
      "mi F1:  0.6846400466336345\n",
      "we F1:  0.6760945721892014\n",
      "update!  Acc:  0.6846400466336345\n",
      "Eval Loss:  0.308605432510376\n",
      "Eval Loss:  0.30448171496391296\n",
      "Eval Loss:  0.45747238397598267\n",
      "Eval Loss:  0.42970532178878784\n",
      "Eval Loss:  0.4546566307544708\n",
      "Eval Loss:  0.476343035697937\n",
      "Eval Loss:  0.42082634568214417\n",
      "Eval Loss:  0.3697527348995209\n",
      "Eval Loss:  0.407871276140213\n",
      "Eval Loss:  0.44403305649757385\n",
      "Eval Loss:  0.39803895354270935\n",
      "Eval Loss:  0.3512375056743622\n",
      "Eval Loss:  0.31744384765625\n",
      "Eval Loss:  0.43956875801086426\n",
      "Eval Loss:  0.29762956500053406\n",
      "Eval Loss:  0.43232110142707825\n",
      "Eval Loss:  0.3969431519508362\n",
      "Eval Loss:  0.41369137167930603\n",
      "Eval Loss:  0.507999062538147\n",
      "Eval Loss:  0.343232661485672\n",
      "Eval Loss:  0.3740030527114868\n",
      "Eval Loss:  0.344405859708786\n",
      "Eval Loss:  0.37922489643096924\n",
      "Eval Loss:  0.4518650770187378\n",
      "Eval Loss:  0.4550434947013855\n",
      "Eval Loss:  0.41465356945991516\n",
      "Eval Loss:  0.4177291989326477\n",
      "Eval Loss:  0.32783228158950806\n",
      "[[16021  2016]\n",
      " [ 2827  8596]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87     18037\n",
      "           1       0.81      0.75      0.78     11423\n",
      "\n",
      "    accuracy                           0.84     29460\n",
      "   macro avg       0.83      0.82      0.82     29460\n",
      "weighted avg       0.83      0.84      0.83     29460\n",
      "\n",
      "acc:  0.8356076035302105\n",
      "pre:  0.8100263852242744\n",
      "rec:  0.7525168519653331\n",
      "ma F1:  0.8244566552915511\n",
      "mi F1:  0.8356076035302105\n",
      "we F1:  0.8343896346384189\n",
      "29460 461\n",
      "Loss:  0.08223378658294678\n",
      "Loss:  0.10820323973894119\n",
      "Loss:  0.09725875407457352\n",
      "3 **********\n",
      "Epoch:  265.87510323524475  fold:  7  kers:  128\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.08455422520637512\n",
      "Loss:  0.10465365648269653\n",
      "Loss:  0.05836767330765724\n",
      "4 **********\n",
      "Epoch:  318.9731297492981  fold:  7  kers:  128\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.10852227360010147\n",
      "Loss:  0.06174604222178459\n",
      "Loss:  0.09723667800426483\n",
      "5 **********\n",
      "Epoch:  372.15692687034607  fold:  7  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.8114811182022095\n",
      "Eval Loss:  0.0834650918841362\n",
      "Eval Loss:  2.6491057872772217\n",
      "[[2002  125]\n",
      " [ 868  436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.80      2127\n",
      "           1       0.78      0.33      0.47      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.74      0.64      0.63      3431\n",
      "weighted avg       0.73      0.71      0.67      3431\n",
      "\n",
      "acc:  0.7105800058292043\n",
      "pre:  0.7771836007130125\n",
      "rec:  0.3343558282208589\n",
      "ma F1:  0.6344205450884473\n",
      "mi F1:  0.7105800058292043\n",
      "we F1:  0.6744456001265334\n",
      "update!  Acc:  0.7105800058292043\n",
      "Eval Loss:  0.2701229453086853\n",
      "Eval Loss:  0.28197887539863586\n",
      "Eval Loss:  0.43723636865615845\n",
      "Eval Loss:  0.3972606062889099\n",
      "Eval Loss:  0.4559408128261566\n",
      "Eval Loss:  0.42190441489219666\n",
      "Eval Loss:  0.40611517429351807\n",
      "Eval Loss:  0.3618513345718384\n",
      "Eval Loss:  0.3907746374607086\n",
      "Eval Loss:  0.4324415922164917\n",
      "Eval Loss:  0.3599126636981964\n",
      "Eval Loss:  0.299915075302124\n",
      "Eval Loss:  0.2995700538158417\n",
      "Eval Loss:  0.4178785979747772\n",
      "Eval Loss:  0.25117313861846924\n",
      "Eval Loss:  0.3907166123390198\n",
      "Eval Loss:  0.3562735319137573\n",
      "Eval Loss:  0.3878173530101776\n",
      "Eval Loss:  0.49113500118255615\n",
      "Eval Loss:  0.3016867935657501\n",
      "Eval Loss:  0.3601042628288269\n",
      "Eval Loss:  0.30627626180648804\n",
      "Eval Loss:  0.3524550199508667\n",
      "Eval Loss:  0.3624248802661896\n",
      "Eval Loss:  0.4363403022289276\n",
      "Eval Loss:  0.3907558023929596\n",
      "Eval Loss:  0.3732203245162964\n",
      "Eval Loss:  0.3334522545337677\n",
      "[[17202   835]\n",
      " [ 3528  7895]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     18037\n",
      "           1       0.90      0.69      0.78     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.87      0.82      0.84     29460\n",
      "weighted avg       0.86      0.85      0.85     29460\n",
      "\n",
      "acc:  0.8519008825526138\n",
      "pre:  0.9043528064146621\n",
      "rec:  0.6911494353497329\n",
      "ma F1:  0.8354810017857675\n",
      "mi F1:  0.8519008825526138\n",
      "we F1:  0.8471497555616266\n",
      "29460 461\n",
      "Loss:  0.06311815232038498\n",
      "Loss:  0.07826048880815506\n",
      "Loss:  0.053014278411865234\n",
      "6 **********\n",
      "Epoch:  466.04488945007324  fold:  7  kers:  128\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.10772398114204407\n",
      "Loss:  0.09249302744865417\n",
      "Loss:  0.05581597611308098\n",
      "7 **********\n",
      "Epoch:  519.1698446273804  fold:  7  kers:  128\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.0994911789894104\n",
      "Loss:  0.0854807123541832\n",
      "Loss:  0.07524462789297104\n",
      "8 **********\n",
      "Epoch:  572.2289750576019  fold:  7  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  1.1174101829528809\n",
      "Eval Loss:  0.041689470410346985\n",
      "Eval Loss:  3.8158059120178223\n",
      "[[2093   34]\n",
      " [1041  263]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.80      2127\n",
      "           1       0.89      0.20      0.33      1304\n",
      "\n",
      "    accuracy                           0.69      3431\n",
      "   macro avg       0.78      0.59      0.56      3431\n",
      "weighted avg       0.75      0.69      0.62      3431\n",
      "\n",
      "acc:  0.6866802681433984\n",
      "pre:  0.8855218855218855\n",
      "rec:  0.20168711656441718\n",
      "ma F1:  0.5621054413696248\n",
      "mi F1:  0.6866802681433984\n",
      "we F1:  0.6181300765799066\n",
      "Eval Loss:  0.304612398147583\n",
      "Eval Loss:  0.35815876722335815\n",
      "Eval Loss:  0.5073220729827881\n",
      "Eval Loss:  0.45587649941444397\n",
      "Eval Loss:  0.5609780550003052\n",
      "Eval Loss:  0.49997034668922424\n",
      "Eval Loss:  0.4077950417995453\n",
      "Eval Loss:  0.45068931579589844\n",
      "Eval Loss:  0.44086167216300964\n",
      "Eval Loss:  0.5157182812690735\n",
      "Eval Loss:  0.3980100452899933\n",
      "Eval Loss:  0.31797167658805847\n",
      "Eval Loss:  0.36382654309272766\n",
      "Eval Loss:  0.48114851117134094\n",
      "Eval Loss:  0.3178471326828003\n",
      "Eval Loss:  0.4080502688884735\n",
      "Eval Loss:  0.4756838381290436\n",
      "Eval Loss:  0.4245126247406006\n",
      "Eval Loss:  0.586252748966217\n",
      "Eval Loss:  0.31874409317970276\n",
      "Eval Loss:  0.373364120721817\n",
      "Eval Loss:  0.345890611410141\n",
      "Eval Loss:  0.43350595235824585\n",
      "Eval Loss:  0.4045223891735077\n",
      "Eval Loss:  0.506441056728363\n",
      "Eval Loss:  0.46824491024017334\n",
      "Eval Loss:  0.39546456933021545\n",
      "Eval Loss:  0.40607231855392456\n",
      "[[17668   369]\n",
      " [ 4740  6683]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87     18037\n",
      "           1       0.95      0.59      0.72     11423\n",
      "\n",
      "    accuracy                           0.83     29460\n",
      "   macro avg       0.87      0.78      0.80     29460\n",
      "weighted avg       0.85      0.83      0.82     29460\n",
      "\n",
      "acc:  0.8265784114052953\n",
      "pre:  0.9476744186046512\n",
      "rec:  0.585047710758995\n",
      "ma F1:  0.7985722236599562\n",
      "mi F1:  0.8265784114052953\n",
      "we F1:  0.8154345746611098\n",
      "29460 461\n",
      "Loss:  0.08030097931623459\n",
      "Loss:  0.0524485781788826\n",
      "Loss:  0.07777182012796402\n",
      "9 **********\n",
      "Epoch:  666.0660741329193  fold:  7  kers:  128\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.07769271731376648\n",
      "Loss:  0.08728469908237457\n",
      "Loss:  0.06795062869787216\n",
      "10 **********\n",
      "Epoch:  719.1102442741394  fold:  7  kers:  128\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.11249860376119614\n",
      "Loss:  0.10914643853902817\n",
      "Loss:  0.0681770071387291\n",
      "11 **********\n",
      "Epoch:  772.2411835193634  fold:  7  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.8720381259918213\n",
      "Eval Loss:  0.051106907427310944\n",
      "Eval Loss:  3.2562341690063477\n",
      "[[2060   67]\n",
      " [ 882  422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81      2127\n",
      "           1       0.86      0.32      0.47      1304\n",
      "\n",
      "    accuracy                           0.72      3431\n",
      "   macro avg       0.78      0.65      0.64      3431\n",
      "weighted avg       0.76      0.72      0.68      3431\n",
      "\n",
      "acc:  0.723404255319149\n",
      "pre:  0.8629856850715747\n",
      "rec:  0.3236196319018405\n",
      "ma F1:  0.6417515255453548\n",
      "mi F1:  0.723404255319149\n",
      "we F1:  0.6827772865977557\n",
      "update!  Acc:  0.723404255319149\n",
      "Eval Loss:  0.22890359163284302\n",
      "Eval Loss:  0.2640700936317444\n",
      "Eval Loss:  0.33880937099456787\n",
      "Eval Loss:  0.37368243932724\n",
      "Eval Loss:  0.38399797677993774\n",
      "Eval Loss:  0.3678799569606781\n",
      "Eval Loss:  0.3233483135700226\n",
      "Eval Loss:  0.32833734154701233\n",
      "Eval Loss:  0.3384113013744354\n",
      "Eval Loss:  0.40481531620025635\n",
      "Eval Loss:  0.32253697514533997\n",
      "Eval Loss:  0.2301284372806549\n",
      "Eval Loss:  0.2864542305469513\n",
      "Eval Loss:  0.34238672256469727\n",
      "Eval Loss:  0.23541341722011566\n",
      "Eval Loss:  0.30357882380485535\n",
      "Eval Loss:  0.33626383543014526\n",
      "Eval Loss:  0.32671961188316345\n",
      "Eval Loss:  0.41393646597862244\n",
      "Eval Loss:  0.23735922574996948\n",
      "Eval Loss:  0.27111130952835083\n",
      "Eval Loss:  0.29128798842430115\n",
      "Eval Loss:  0.32918569445610046\n",
      "Eval Loss:  0.25922009348869324\n",
      "Eval Loss:  0.3976590633392334\n",
      "Eval Loss:  0.3511544167995453\n",
      "Eval Loss:  0.30972135066986084\n",
      "Eval Loss:  0.3258107900619507\n",
      "[[17453   584]\n",
      " [ 3315  8108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     18037\n",
      "           1       0.93      0.71      0.81     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.89      0.84      0.85     29460\n",
      "weighted avg       0.88      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8676510522742702\n",
      "pre:  0.9328117809479981\n",
      "rec:  0.7097960255624617\n",
      "ma F1:  0.8528439055638813\n",
      "mi F1:  0.8676510522742702\n",
      "we F1:  0.8633237844662367\n",
      "29460 461\n",
      "Loss:  0.05905935913324356\n",
      "Loss:  0.05809057131409645\n",
      "Loss:  0.09886717051267624\n",
      "12 **********\n",
      "Epoch:  866.2159159183502  fold:  7  kers:  128\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.06659948825836182\n",
      "Loss:  0.07420384138822556\n",
      "Loss:  0.06265823543071747\n",
      "13 **********\n",
      "Epoch:  919.3408682346344  fold:  7  kers:  128\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.10289880633354187\n",
      "Loss:  0.07961205393075943\n",
      "Loss:  0.05975554138422012\n",
      "14 **********\n",
      "Epoch:  972.5426180362701  fold:  7  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.6749051809310913\n",
      "Eval Loss:  0.07083760201931\n",
      "Eval Loss:  2.305164337158203\n",
      "[[2003  124]\n",
      " [ 698  606]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83      2127\n",
      "           1       0.83      0.46      0.60      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.79      0.70      0.71      3431\n",
      "weighted avg       0.78      0.76      0.74      3431\n",
      "\n",
      "acc:  0.76041970271058\n",
      "pre:  0.8301369863013699\n",
      "rec:  0.4647239263803681\n",
      "ma F1:  0.712806685680629\n",
      "mi F1:  0.76041970271058\n",
      "we F1:  0.7408564444606215\n",
      "update!  Acc:  0.76041970271058\n",
      "Eval Loss:  0.18213380873203278\n",
      "Eval Loss:  0.23014919459819794\n",
      "Eval Loss:  0.25315970182418823\n",
      "Eval Loss:  0.31561824679374695\n",
      "Eval Loss:  0.31950002908706665\n",
      "Eval Loss:  0.2994278073310852\n",
      "Eval Loss:  0.29594263434410095\n",
      "Eval Loss:  0.26747646927833557\n",
      "Eval Loss:  0.28362613916397095\n",
      "Eval Loss:  0.33313316106796265\n",
      "Eval Loss:  0.2684674859046936\n",
      "Eval Loss:  0.17625750601291656\n",
      "Eval Loss:  0.25695669651031494\n",
      "Eval Loss:  0.26598623394966125\n",
      "Eval Loss:  0.17931483685970306\n",
      "Eval Loss:  0.25891757011413574\n",
      "Eval Loss:  0.28561660647392273\n",
      "Eval Loss:  0.2994671165943146\n",
      "Eval Loss:  0.33710265159606934\n",
      "Eval Loss:  0.19963784515857697\n",
      "Eval Loss:  0.24365831911563873\n",
      "Eval Loss:  0.23404766619205475\n",
      "Eval Loss:  0.30233126878738403\n",
      "Eval Loss:  0.21633169054985046\n",
      "Eval Loss:  0.3172767162322998\n",
      "Eval Loss:  0.3224143385887146\n",
      "Eval Loss:  0.25727149844169617\n",
      "Eval Loss:  0.29234594106674194\n",
      "[[17284   753]\n",
      " [ 2451  8972]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18037\n",
      "           1       0.92      0.79      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8912423625254583\n",
      "pre:  0.9225706940874036\n",
      "rec:  0.7854328985380373\n",
      "ma F1:  0.8818357869034361\n",
      "mi F1:  0.8912423625254583\n",
      "we F1:  0.8893207593726439\n",
      "29460 461\n",
      "Loss:  0.07040902972221375\n",
      "Loss:  0.05053424462676048\n",
      "Loss:  0.06303583830595016\n",
      "15 **********\n",
      "Epoch:  1066.3587727546692  fold:  7  kers:  128\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.05337823927402496\n",
      "Loss:  0.09328000992536545\n",
      "Loss:  0.055372145026922226\n",
      "16 **********\n",
      "Epoch:  1119.3351249694824  fold:  7  kers:  128\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.1062878966331482\n",
      "Loss:  0.05060390755534172\n",
      "Loss:  0.05521692708134651\n",
      "17 **********\n",
      "Epoch:  1172.2985107898712  fold:  7  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.5210382342338562\n",
      "Eval Loss:  0.0702882632613182\n",
      "Eval Loss:  2.0447638034820557\n",
      "[[1968  159]\n",
      " [ 644  660]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      2127\n",
      "           1       0.81      0.51      0.62      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.72      0.73      3431\n",
      "weighted avg       0.77      0.77      0.75      3431\n",
      "\n",
      "acc:  0.7659574468085106\n",
      "pre:  0.8058608058608059\n",
      "rec:  0.5061349693251533\n",
      "ma F1:  0.7261583137169578\n",
      "mi F1:  0.7659574468085105\n",
      "we F1:  0.7512001229939823\n",
      "update!  Acc:  0.7659574468085106\n",
      "Eval Loss:  0.18366381525993347\n",
      "Eval Loss:  0.20898397266864777\n",
      "Eval Loss:  0.2224213182926178\n",
      "Eval Loss:  0.2569354772567749\n",
      "Eval Loss:  0.26731082797050476\n",
      "Eval Loss:  0.24927493929862976\n",
      "Eval Loss:  0.2644619941711426\n",
      "Eval Loss:  0.241216242313385\n",
      "Eval Loss:  0.2571350038051605\n",
      "Eval Loss:  0.2985628545284271\n",
      "Eval Loss:  0.2655732333660126\n",
      "Eval Loss:  0.15332338213920593\n",
      "Eval Loss:  0.2313413918018341\n",
      "Eval Loss:  0.23812958598136902\n",
      "Eval Loss:  0.17044290900230408\n",
      "Eval Loss:  0.25884515047073364\n",
      "Eval Loss:  0.2525618076324463\n",
      "Eval Loss:  0.2737601697444916\n",
      "Eval Loss:  0.31801772117614746\n",
      "Eval Loss:  0.17519763112068176\n",
      "Eval Loss:  0.22175894677639008\n",
      "Eval Loss:  0.20074619352817535\n",
      "Eval Loss:  0.258888840675354\n",
      "Eval Loss:  0.19832533597946167\n",
      "Eval Loss:  0.2822679579257965\n",
      "Eval Loss:  0.2778569161891937\n",
      "Eval Loss:  0.23681217432022095\n",
      "Eval Loss:  0.25858473777770996\n",
      "[[17151   886]\n",
      " [ 1973  9450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18037\n",
      "           1       0.91      0.83      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9029531568228106\n",
      "pre:  0.9142801857585139\n",
      "rec:  0.827278298170358\n",
      "ma F1:  0.8958352985690768\n",
      "mi F1:  0.9029531568228106\n",
      "we F1:  0.9019484675718291\n",
      "29460 461\n",
      "Loss:  0.05095606669783592\n",
      "Loss:  0.09364091604948044\n",
      "Loss:  0.05443456396460533\n",
      "18 **********\n",
      "Epoch:  1265.7336847782135  fold:  7  kers:  128\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.0818059891462326\n",
      "Loss:  0.04572480916976929\n",
      "Loss:  0.04777707904577255\n",
      "19 **********\n",
      "Epoch:  1318.6322445869446  fold:  7  kers:  128\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.075960174202919\n",
      "Loss:  0.06566298753023148\n",
      "Loss:  0.055990029126405716\n",
      "20 **********\n",
      "Epoch:  1371.6235563755035  fold:  7  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.6604092717170715\n",
      "Eval Loss:  0.04261672869324684\n",
      "Eval Loss:  2.6849496364593506\n",
      "[[2052   75]\n",
      " [ 816  488]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      2127\n",
      "           1       0.87      0.37      0.52      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.79      0.67      0.67      3431\n",
      "weighted avg       0.77      0.74      0.71      3431\n",
      "\n",
      "acc:  0.7403089478286214\n",
      "pre:  0.866785079928952\n",
      "rec:  0.37423312883435583\n",
      "ma F1:  0.6721927069007947\n",
      "mi F1:  0.7403089478286216\n",
      "we F1:  0.7080364832969592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2026398479938507\n",
      "Eval Loss:  0.22578135132789612\n",
      "Eval Loss:  0.26966121792793274\n",
      "Eval Loss:  0.31699615716934204\n",
      "Eval Loss:  0.32848283648490906\n",
      "Eval Loss:  0.2733500897884369\n",
      "Eval Loss:  0.27084779739379883\n",
      "Eval Loss:  0.28536418080329895\n",
      "Eval Loss:  0.2591775357723236\n",
      "Eval Loss:  0.3421744108200073\n",
      "Eval Loss:  0.26606589555740356\n",
      "Eval Loss:  0.18121802806854248\n",
      "Eval Loss:  0.25890785455703735\n",
      "Eval Loss:  0.2627158761024475\n",
      "Eval Loss:  0.18261882662773132\n",
      "Eval Loss:  0.2628554701805115\n",
      "Eval Loss:  0.2934000492095947\n",
      "Eval Loss:  0.28736355900764465\n",
      "Eval Loss:  0.3817232847213745\n",
      "Eval Loss:  0.20910564064979553\n",
      "Eval Loss:  0.2226097583770752\n",
      "Eval Loss:  0.20830607414245605\n",
      "Eval Loss:  0.2727811932563782\n",
      "Eval Loss:  0.24416790902614594\n",
      "Eval Loss:  0.33007267117500305\n",
      "Eval Loss:  0.2999882698059082\n",
      "Eval Loss:  0.26665931940078735\n",
      "Eval Loss:  0.2916876971721649\n",
      "[[17525   512]\n",
      " [ 2823  8600]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     18037\n",
      "           1       0.94      0.75      0.84     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.86      0.88     29460\n",
      "weighted avg       0.89      0.89      0.88     29460\n",
      "\n",
      "acc:  0.886795655125594\n",
      "pre:  0.9438103599648815\n",
      "rec:  0.7528670226735533\n",
      "ma F1:  0.8753557270714523\n",
      "mi F1:  0.886795655125594\n",
      "we F1:  0.8838334507857486\n",
      "29460 461\n",
      "Loss:  0.040885426104068756\n",
      "Loss:  0.07693047821521759\n",
      "Loss:  0.06149786710739136\n",
      "21 **********\n",
      "Epoch:  1464.9131190776825  fold:  7  kers:  128\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.062172647565603256\n",
      "Loss:  0.04793339595198631\n",
      "Loss:  0.06953105330467224\n",
      "22 **********\n",
      "Epoch:  1517.6800315380096  fold:  7  kers:  128\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.040150195360183716\n",
      "Loss:  0.06025383621454239\n",
      "Loss:  0.04122335836291313\n",
      "23 **********\n",
      "Epoch:  1571.0952095985413  fold:  7  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.5323315262794495\n",
      "Eval Loss:  0.03837505355477333\n",
      "Eval Loss:  2.418186664581299\n",
      "[[2037   90]\n",
      " [ 742  562]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83      2127\n",
      "           1       0.86      0.43      0.57      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.80      0.69      0.70      3431\n",
      "weighted avg       0.78      0.76      0.73      3431\n",
      "\n",
      "acc:  0.7575051005537744\n",
      "pre:  0.8619631901840491\n",
      "rec:  0.43098159509202455\n",
      "ma F1:  0.7025269337575041\n",
      "mi F1:  0.7575051005537744\n",
      "we F1:  0.733202887163152\n",
      "Eval Loss:  0.1927468627691269\n",
      "Eval Loss:  0.21115531027317047\n",
      "Eval Loss:  0.23499730229377747\n",
      "Eval Loss:  0.28651851415634155\n",
      "Eval Loss:  0.28742942214012146\n",
      "Eval Loss:  0.24885065853595734\n",
      "Eval Loss:  0.27233731746673584\n",
      "Eval Loss:  0.24469414353370667\n",
      "Eval Loss:  0.2355635017156601\n",
      "Eval Loss:  0.33208075165748596\n",
      "Eval Loss:  0.2671565115451813\n",
      "Eval Loss:  0.1435767114162445\n",
      "Eval Loss:  0.24655646085739136\n",
      "Eval Loss:  0.2553507089614868\n",
      "Eval Loss:  0.16426227986812592\n",
      "Eval Loss:  0.27200624346733093\n",
      "Eval Loss:  0.2545945644378662\n",
      "Eval Loss:  0.26545774936676025\n",
      "Eval Loss:  0.3523487448692322\n",
      "Eval Loss:  0.18583397567272186\n",
      "Eval Loss:  0.21260176599025726\n",
      "Eval Loss:  0.20188239216804504\n",
      "Eval Loss:  0.2661345899105072\n",
      "Eval Loss:  0.22521038353443146\n",
      "Eval Loss:  0.3210853636264801\n",
      "Eval Loss:  0.25437283515930176\n",
      "Eval Loss:  0.2451358586549759\n",
      "Eval Loss:  0.2763233780860901\n",
      "[[17470   567]\n",
      " [ 2492  8931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18037\n",
      "           1       0.94      0.78      0.85     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.91      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.89     29460\n",
      "\n",
      "acc:  0.8961642905634759\n",
      "pre:  0.9403032217308908\n",
      "rec:  0.7818436487787797\n",
      "ma F1:  0.8866405807405675\n",
      "mi F1:  0.8961642905634759\n",
      "we F1:  0.8940173012896617\n",
      "29460 461\n",
      "Loss:  0.06414321810007095\n",
      "Loss:  0.07618848234415054\n",
      "Loss:  0.05267753824591637\n",
      "24 **********\n",
      "Epoch:  1670.4924426078796  fold:  7  kers:  128\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.05450870096683502\n",
      "Loss:  0.062177225947380066\n",
      "Loss:  0.06856382638216019\n",
      "25 **********\n",
      "Epoch:  1723.4368796348572  fold:  7  kers:  128\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.044240403920412064\n",
      "Loss:  0.05114862695336342\n",
      "Loss:  0.06505724787712097\n",
      "26 **********\n",
      "Epoch:  1776.371343612671  fold:  7  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.42164796590805054\n",
      "Eval Loss:  0.04926520586013794\n",
      "Eval Loss:  1.7588554620742798\n",
      "[[1905  222]\n",
      " [ 567  737]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83      2127\n",
      "           1       0.77      0.57      0.65      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.73      0.74      3431\n",
      "weighted avg       0.77      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7700378898280384\n",
      "pre:  0.7685088633993743\n",
      "rec:  0.5651840490797546\n",
      "ma F1:  0.7398943669381142\n",
      "mi F1:  0.7700378898280384\n",
      "we F1:  0.7611341951388059\n",
      "update!  Acc:  0.7700378898280384\n",
      "Eval Loss:  0.17002388834953308\n",
      "Eval Loss:  0.17500457167625427\n",
      "Eval Loss:  0.19835762679576874\n",
      "Eval Loss:  0.2518761456012726\n",
      "Eval Loss:  0.22997930645942688\n",
      "Eval Loss:  0.2121746987104416\n",
      "Eval Loss:  0.2728407084941864\n",
      "Eval Loss:  0.21131153404712677\n",
      "Eval Loss:  0.20046904683113098\n",
      "Eval Loss:  0.285604864358902\n",
      "Eval Loss:  0.2686137557029724\n",
      "Eval Loss:  0.1160748228430748\n",
      "Eval Loss:  0.17534169554710388\n",
      "Eval Loss:  0.20621049404144287\n",
      "Eval Loss:  0.16882091760635376\n",
      "Eval Loss:  0.24184787273406982\n",
      "Eval Loss:  0.20482151210308075\n",
      "Eval Loss:  0.2503284215927124\n",
      "Eval Loss:  0.2941379249095917\n",
      "Eval Loss:  0.14999614655971527\n",
      "Eval Loss:  0.23007550835609436\n",
      "Eval Loss:  0.1741190403699875\n",
      "Eval Loss:  0.2308347225189209\n",
      "Eval Loss:  0.20830559730529785\n",
      "Eval Loss:  0.2619520127773285\n",
      "Eval Loss:  0.3077770173549652\n",
      "Eval Loss:  0.23433871567249298\n",
      "Eval Loss:  0.27550753951072693\n",
      "[[17057   980]\n",
      " [ 1518  9905]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18037\n",
      "           1       0.91      0.87      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.91     29460\n",
      "\n",
      "acc:  0.9152070604209097\n",
      "pre:  0.909967845659164\n",
      "rec:  0.8671102162304123\n",
      "ma F1:  0.9098966191092355\n",
      "mi F1:  0.9152070604209097\n",
      "we F1:  0.9148075893043437\n",
      "29460 461\n",
      "Loss:  0.07307696342468262\n",
      "Loss:  0.043360721319913864\n",
      "Loss:  0.04495342820882797\n",
      "27 **********\n",
      "Epoch:  1870.530580997467  fold:  7  kers:  128\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.051834508776664734\n",
      "Loss:  0.04950380697846413\n",
      "Loss:  0.08627599477767944\n",
      "28 **********\n",
      "Epoch:  1923.8440313339233  fold:  7  kers:  128\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.0465804822742939\n",
      "Loss:  0.05877155810594559\n",
      "Loss:  0.05740126967430115\n",
      "29 **********\n",
      "Epoch:  1977.1674554347992  fold:  7  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.5114376544952393\n",
      "Eval Loss:  0.04263702407479286\n",
      "Eval Loss:  2.142014741897583\n",
      "[[2008  119]\n",
      " [ 677  627]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83      2127\n",
      "           1       0.84      0.48      0.61      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.71      0.72      3431\n",
      "weighted avg       0.78      0.77      0.75      3431\n",
      "\n",
      "acc:  0.7679976683182745\n",
      "pre:  0.8404825737265416\n",
      "rec:  0.4808282208588957\n",
      "ma F1:  0.7231437665997608\n",
      "mi F1:  0.7679976683182744\n",
      "we F1:  0.7498742235978323\n",
      "Eval Loss:  0.17890314757823944\n",
      "Eval Loss:  0.18273159861564636\n",
      "Eval Loss:  0.2100342959165573\n",
      "Eval Loss:  0.2641013562679291\n",
      "Eval Loss:  0.22530730068683624\n",
      "Eval Loss:  0.21837837994098663\n",
      "Eval Loss:  0.24881203472614288\n",
      "Eval Loss:  0.21640311181545258\n",
      "Eval Loss:  0.20790371298789978\n",
      "Eval Loss:  0.2835114896297455\n",
      "Eval Loss:  0.24729830026626587\n",
      "Eval Loss:  0.10647876560688019\n",
      "Eval Loss:  0.20889319479465485\n",
      "Eval Loss:  0.22478021681308746\n",
      "Eval Loss:  0.1445862203836441\n",
      "Eval Loss:  0.21410715579986572\n",
      "Eval Loss:  0.2084326446056366\n",
      "Eval Loss:  0.20939289033412933\n",
      "Eval Loss:  0.32264503836631775\n",
      "Eval Loss:  0.15914654731750488\n",
      "Eval Loss:  0.20300857722759247\n",
      "Eval Loss:  0.1724269688129425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21756860613822937\n",
      "Eval Loss:  0.21074514091014862\n",
      "Eval Loss:  0.2842360734939575\n",
      "Eval Loss:  0.2638092637062073\n",
      "Eval Loss:  0.19887134432792664\n",
      "Eval Loss:  0.2630457580089569\n",
      "[[17479   558]\n",
      " [ 2091  9332]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     18037\n",
      "           1       0.94      0.82      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.92      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.910081466395112\n",
      "pre:  0.9435793731041456\n",
      "rec:  0.8169482622778604\n",
      "ma F1:  0.9026353233785367\n",
      "mi F1:  0.910081466395112\n",
      "we F1:  0.9086803448479892\n",
      "29460 461\n",
      "Loss:  0.04893103241920471\n",
      "Loss:  0.05522831529378891\n",
      "Loss:  0.061493948101997375\n",
      "30 **********\n",
      "Epoch:  2070.7562177181244  fold:  7  kers:  128\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.07150077074766159\n",
      "Loss:  0.036405399441719055\n",
      "Loss:  0.033021487295627594\n",
      "31 **********\n",
      "Epoch:  2123.7325694561005  fold:  7  kers:  128\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.04809117317199707\n",
      "Loss:  0.035353876650333405\n",
      "Loss:  0.03309626504778862\n",
      "32 **********\n",
      "Epoch:  2176.6979513168335  fold:  7  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.426724374294281\n",
      "Eval Loss:  0.06345417350530624\n",
      "Eval Loss:  1.6151890754699707\n",
      "[[1937  190]\n",
      " [ 582  722]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83      2127\n",
      "           1       0.79      0.55      0.65      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.73      0.74      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.774992713494608\n",
      "pre:  0.7916666666666666\n",
      "rec:  0.553680981595092\n",
      "ma F1:  0.7427300531026262\n",
      "mi F1:  0.774992713494608\n",
      "we F1:  0.7645836905533268\n",
      "update!  Acc:  0.774992713494608\n",
      "Eval Loss:  0.16214926540851593\n",
      "Eval Loss:  0.16394805908203125\n",
      "Eval Loss:  0.17986074090003967\n",
      "Eval Loss:  0.21916328370571136\n",
      "Eval Loss:  0.22740066051483154\n",
      "Eval Loss:  0.18697074055671692\n",
      "Eval Loss:  0.22937317192554474\n",
      "Eval Loss:  0.18641819059848785\n",
      "Eval Loss:  0.1886490285396576\n",
      "Eval Loss:  0.23377946019172668\n",
      "Eval Loss:  0.2463202178478241\n",
      "Eval Loss:  0.0795571506023407\n",
      "Eval Loss:  0.18177430331707\n",
      "Eval Loss:  0.19866348803043365\n",
      "Eval Loss:  0.1320943534374237\n",
      "Eval Loss:  0.2121780663728714\n",
      "Eval Loss:  0.20769242942333221\n",
      "Eval Loss:  0.21808934211730957\n",
      "Eval Loss:  0.27169516682624817\n",
      "Eval Loss:  0.13714343309402466\n",
      "Eval Loss:  0.21995770931243896\n",
      "Eval Loss:  0.15811403095722198\n",
      "Eval Loss:  0.18856923282146454\n",
      "Eval Loss:  0.22827240824699402\n",
      "Eval Loss:  0.24225416779518127\n",
      "Eval Loss:  0.24493519961833954\n",
      "Eval Loss:  0.19418059289455414\n",
      "Eval Loss:  0.20099876821041107\n",
      "[[17208   829]\n",
      " [ 1570  9853]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18037\n",
      "           1       0.92      0.86      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9185675492192804\n",
      "pre:  0.9223928103351432\n",
      "rec:  0.862557997023549\n",
      "ma F1:  0.9131544307057703\n",
      "mi F1:  0.9185675492192804\n",
      "we F1:  0.9180221894886875\n",
      "29460 461\n",
      "Loss:  0.07158849388360977\n",
      "Loss:  0.059240542352199554\n",
      "Loss:  0.07728222757577896\n",
      "33 **********\n",
      "Epoch:  2270.1799993515015  fold:  7  kers:  128\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.07685433328151703\n",
      "Loss:  0.02544129639863968\n",
      "Loss:  0.04177623242139816\n",
      "34 **********\n",
      "Epoch:  2323.196244239807  fold:  7  kers:  128\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.04207699000835419\n",
      "Loss:  0.03751179948449135\n",
      "Loss:  0.058462195098400116\n",
      "35 **********\n",
      "Epoch:  2376.1317059993744  fold:  7  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.38454926013946533\n",
      "Eval Loss:  0.08782119303941727\n",
      "Eval Loss:  1.3270928859710693\n",
      "[[1854  273]\n",
      " [ 502  802]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83      2127\n",
      "           1       0.75      0.62      0.67      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.74      0.75      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7741183328475663\n",
      "pre:  0.746046511627907\n",
      "rec:  0.6150306748466258\n",
      "ma F1:  0.7506787821199643\n",
      "mi F1:  0.7741183328475664\n",
      "we F1:  0.7690159971853793\n",
      "Eval Loss:  0.17424257099628448\n",
      "Eval Loss:  0.1671919971704483\n",
      "Eval Loss:  0.191814586520195\n",
      "Eval Loss:  0.2004210650920868\n",
      "Eval Loss:  0.19086238741874695\n",
      "Eval Loss:  0.1789247840642929\n",
      "Eval Loss:  0.2346232384443283\n",
      "Eval Loss:  0.20513498783111572\n",
      "Eval Loss:  0.2014952003955841\n",
      "Eval Loss:  0.24397048354148865\n",
      "Eval Loss:  0.25156253576278687\n",
      "Eval Loss:  0.12289877980947495\n",
      "Eval Loss:  0.20196835696697235\n",
      "Eval Loss:  0.2058917135000229\n",
      "Eval Loss:  0.1498391181230545\n",
      "Eval Loss:  0.2100890874862671\n",
      "Eval Loss:  0.16955462098121643\n",
      "Eval Loss:  0.2373453676700592\n",
      "Eval Loss:  0.24325799942016602\n",
      "Eval Loss:  0.1517338901758194\n",
      "Eval Loss:  0.2250356674194336\n",
      "Eval Loss:  0.15898004174232483\n",
      "Eval Loss:  0.21491579711437225\n",
      "Eval Loss:  0.18110011518001556\n",
      "Eval Loss:  0.26432645320892334\n",
      "Eval Loss:  0.2446562945842743\n",
      "Eval Loss:  0.18553972244262695\n",
      "Eval Loss:  0.22869235277175903\n",
      "[[16863  1174]\n",
      " [ 1164 10259]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18037\n",
      "           1       0.90      0.90      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9206381534283775\n",
      "pre:  0.897314790518674\n",
      "rec:  0.8981003239079051\n",
      "ma F1:  0.9164390964113422\n",
      "mi F1:  0.9206381534283775\n",
      "we F1:  0.9206445117824312\n",
      "29460 461\n",
      "Loss:  0.03087036684155464\n",
      "Loss:  0.059515826404094696\n",
      "Loss:  0.08062832057476044\n",
      "36 **********\n",
      "Epoch:  2469.537956237793  fold:  7  kers:  128\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.07707615941762924\n",
      "Loss:  0.041283220052719116\n",
      "Loss:  0.05317465588450432\n",
      "37 **********\n",
      "Epoch:  2522.4544684886932  fold:  7  kers:  128\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.04415934532880783\n",
      "Loss:  0.047645289450883865\n",
      "Loss:  0.04841041564941406\n",
      "38 **********\n",
      "Epoch:  2575.4936521053314  fold:  7  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.39638447761535645\n",
      "Eval Loss:  0.059377722442150116\n",
      "Eval Loss:  1.4236359596252441\n",
      "[[1815  312]\n",
      " [ 499  805]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82      2127\n",
      "           1       0.72      0.62      0.67      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.75      0.74      0.74      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7636257650830661\n",
      "pre:  0.720680393912265\n",
      "rec:  0.6173312883435583\n",
      "ma F1:  0.7411989645134831\n",
      "mi F1:  0.7636257650830661\n",
      "we F1:  0.7594734762647375\n",
      "Eval Loss:  0.19466151297092438\n",
      "Eval Loss:  0.17586399614810944\n",
      "Eval Loss:  0.19637858867645264\n",
      "Eval Loss:  0.2329327017068863\n",
      "Eval Loss:  0.1999947875738144\n",
      "Eval Loss:  0.18609000742435455\n",
      "Eval Loss:  0.2653880715370178\n",
      "Eval Loss:  0.19208449125289917\n",
      "Eval Loss:  0.19114618003368378\n",
      "Eval Loss:  0.23753781616687775\n",
      "Eval Loss:  0.2901467978954315\n",
      "Eval Loss:  0.10236674547195435\n",
      "Eval Loss:  0.16369104385375977\n",
      "Eval Loss:  0.1931276023387909\n",
      "Eval Loss:  0.17395758628845215\n",
      "Eval Loss:  0.25746142864227295\n",
      "Eval Loss:  0.17873278260231018\n",
      "Eval Loss:  0.2336147278547287\n",
      "Eval Loss:  0.21928304433822632\n",
      "Eval Loss:  0.1362067461013794\n",
      "Eval Loss:  0.21433022618293762\n",
      "Eval Loss:  0.18898236751556396\n",
      "Eval Loss:  0.2082042396068573\n",
      "Eval Loss:  0.20777863264083862\n",
      "Eval Loss:  0.2784433364868164\n",
      "Eval Loss:  0.29601338505744934\n",
      "Eval Loss:  0.2191852629184723\n",
      "Eval Loss:  0.2239254117012024\n",
      "[[16634  1403]\n",
      " [  998 10425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     18037\n",
      "           1       0.88      0.91      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.92      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9184996605566871\n",
      "pre:  0.881383158606696\n",
      "rec:  0.9126324082990458\n",
      "ma F1:  0.9147111354711\n",
      "mi F1:  0.9184996605566871\n",
      "we F1:  0.918746778073141\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.045377153903245926\n",
      "Loss:  0.057699427008628845\n",
      "Loss:  0.05288983881473541\n",
      "39 **********\n",
      "Epoch:  2668.9647300243378  fold:  7  kers:  128\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.031012579798698425\n",
      "Loss:  0.0404304563999176\n",
      "Loss:  0.04037646949291229\n",
      "40 **********\n",
      "Epoch:  2721.883236885071  fold:  7  kers:  128\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.04139764606952667\n",
      "Loss:  0.04314742609858513\n",
      "Loss:  0.04857780411839485\n",
      "41 **********\n",
      "Epoch:  2774.7987518310547  fold:  7  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.38635724782943726\n",
      "Eval Loss:  0.07630883157253265\n",
      "Eval Loss:  1.6831893920898438\n",
      "[[1881  246]\n",
      " [ 544  760]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83      2127\n",
      "           1       0.76      0.58      0.66      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.73      0.74      3431\n",
      "weighted avg       0.77      0.77      0.76      3431\n",
      "\n",
      "acc:  0.769746429612358\n",
      "pre:  0.7554671968190855\n",
      "rec:  0.5828220858895705\n",
      "ma F1:  0.7422292850675979\n",
      "mi F1:  0.769746429612358\n",
      "we F1:  0.7624314348984075\n",
      "Eval Loss:  0.14657051861286163\n",
      "Eval Loss:  0.14323441684246063\n",
      "Eval Loss:  0.17866945266723633\n",
      "Eval Loss:  0.1917845457792282\n",
      "Eval Loss:  0.18648816645145416\n",
      "Eval Loss:  0.18802542984485626\n",
      "Eval Loss:  0.21643462777137756\n",
      "Eval Loss:  0.16213257610797882\n",
      "Eval Loss:  0.19495221972465515\n",
      "Eval Loss:  0.21924227476119995\n",
      "Eval Loss:  0.22819341719150543\n",
      "Eval Loss:  0.10960464179515839\n",
      "Eval Loss:  0.1626943200826645\n",
      "Eval Loss:  0.17552126944065094\n",
      "Eval Loss:  0.12927964329719543\n",
      "Eval Loss:  0.192038431763649\n",
      "Eval Loss:  0.1702786684036255\n",
      "Eval Loss:  0.16894786059856415\n",
      "Eval Loss:  0.23693883419036865\n",
      "Eval Loss:  0.13452167809009552\n",
      "Eval Loss:  0.17792807519435883\n",
      "Eval Loss:  0.1662014126777649\n",
      "Eval Loss:  0.17961634695529938\n",
      "Eval Loss:  0.19858011603355408\n",
      "Eval Loss:  0.22731062769889832\n",
      "Eval Loss:  0.24445182085037231\n",
      "Eval Loss:  0.17778755724430084\n",
      "Eval Loss:  0.22950506210327148\n",
      "[[17225   812]\n",
      " [ 1323 10100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18037\n",
      "           1       0.93      0.88      0.90     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9275288526816021\n",
      "pre:  0.9255865102639296\n",
      "rec:  0.8841810382561499\n",
      "ma F1:  0.9230264342043465\n",
      "mi F1:  0.9275288526816021\n",
      "we F1:  0.9272059423880054\n",
      "29460 461\n",
      "Loss:  0.06824267655611038\n",
      "Loss:  0.04810110107064247\n",
      "Loss:  0.04777572676539421\n",
      "42 **********\n",
      "Epoch:  2868.2997481822968  fold:  7  kers:  128\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.07451978325843811\n",
      "Loss:  0.028874993324279785\n",
      "Loss:  0.06502300500869751\n",
      "43 **********\n",
      "Epoch:  2921.249172449112  fold:  7  kers:  128\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.045473918318748474\n",
      "Loss:  0.04374834522604942\n",
      "Loss:  0.04402312636375427\n",
      "44 **********\n",
      "Epoch:  2974.1507239341736  fold:  7  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.4462164044380188\n",
      "Eval Loss:  0.12340302765369415\n",
      "Eval Loss:  1.5993953943252563\n",
      "[[1832  295]\n",
      " [ 510  794]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      2127\n",
      "           1       0.73      0.61      0.66      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.76      0.74      0.74      3431\n",
      "weighted avg       0.76      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7653745263771495\n",
      "pre:  0.72910927456382\n",
      "rec:  0.6088957055214724\n",
      "ma F1:  0.7417361950276956\n",
      "mi F1:  0.7653745263771495\n",
      "we F1:  0.7604783402113185\n",
      "Eval Loss:  0.17126412689685822\n",
      "Eval Loss:  0.15292207896709442\n",
      "Eval Loss:  0.17967279255390167\n",
      "Eval Loss:  0.19721125066280365\n",
      "Eval Loss:  0.19033372402191162\n",
      "Eval Loss:  0.17748616635799408\n",
      "Eval Loss:  0.20017077028751373\n",
      "Eval Loss:  0.16708433628082275\n",
      "Eval Loss:  0.18049204349517822\n",
      "Eval Loss:  0.20893792808055878\n",
      "Eval Loss:  0.23075374960899353\n",
      "Eval Loss:  0.09519665688276291\n",
      "Eval Loss:  0.17237672209739685\n",
      "Eval Loss:  0.1915328949689865\n",
      "Eval Loss:  0.13500209152698517\n",
      "Eval Loss:  0.19314834475517273\n",
      "Eval Loss:  0.19649642705917358\n",
      "Eval Loss:  0.23988616466522217\n",
      "Eval Loss:  0.21142922341823578\n",
      "Eval Loss:  0.13559593260288239\n",
      "Eval Loss:  0.19054129719734192\n",
      "Eval Loss:  0.15188083052635193\n",
      "Eval Loss:  0.18181517720222473\n",
      "Eval Loss:  0.18703991174697876\n",
      "Eval Loss:  0.24034321308135986\n",
      "Eval Loss:  0.28225547075271606\n",
      "Eval Loss:  0.1872212290763855\n",
      "Eval Loss:  0.1914396435022354\n",
      "[[17039   998]\n",
      " [ 1228 10195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18037\n",
      "           1       0.91      0.89      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9244399185336049\n",
      "pre:  0.9108371303493255\n",
      "rec:  0.892497592576381\n",
      "ma F1:  0.9201292746563507\n",
      "mi F1:  0.9244399185336049\n",
      "we F1:  0.9242950546978701\n",
      "29460 461\n",
      "Loss:  0.07657324522733688\n",
      "Loss:  0.05446978658437729\n",
      "Loss:  0.04893443360924721\n",
      "45 **********\n",
      "Epoch:  3067.701588869095  fold:  7  kers:  128\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.09246654808521271\n",
      "Loss:  0.07157401740550995\n",
      "Loss:  0.038831159472465515\n",
      "46 **********\n",
      "Epoch:  3120.6181004047394  fold:  7  kers:  128\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.04359005019068718\n",
      "Loss:  0.10024738311767578\n",
      "Loss:  0.05918486416339874\n",
      "47 **********\n",
      "Epoch:  3173.614399433136  fold:  7  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.3904133439064026\n",
      "Eval Loss:  0.08198342472314835\n",
      "Eval Loss:  1.3740569353103638\n",
      "[[1733  394]\n",
      " [ 488  816]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      2127\n",
      "           1       0.67      0.63      0.65      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.73      0.72      0.72      3431\n",
      "weighted avg       0.74      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7429320897697465\n",
      "pre:  0.6743801652892562\n",
      "rec:  0.6257668711656442\n",
      "ma F1:  0.7231563959398666\n",
      "mi F1:  0.7429320897697465\n",
      "we F1:  0.7409049194098679\n",
      "Eval Loss:  0.1948249340057373\n",
      "Eval Loss:  0.18220849335193634\n",
      "Eval Loss:  0.15404012799263\n",
      "Eval Loss:  0.2389780431985855\n",
      "Eval Loss:  0.18910463154315948\n",
      "Eval Loss:  0.23284365236759186\n",
      "Eval Loss:  0.24213433265686035\n",
      "Eval Loss:  0.2067340761423111\n",
      "Eval Loss:  0.19431453943252563\n",
      "Eval Loss:  0.21036139130592346\n",
      "Eval Loss:  0.3279118537902832\n",
      "Eval Loss:  0.13003575801849365\n",
      "Eval Loss:  0.1814567893743515\n",
      "Eval Loss:  0.19818535447120667\n",
      "Eval Loss:  0.17292827367782593\n",
      "Eval Loss:  0.27338674664497375\n",
      "Eval Loss:  0.1980488896369934\n",
      "Eval Loss:  0.26102983951568604\n",
      "Eval Loss:  0.2299467772245407\n",
      "Eval Loss:  0.15661604702472687\n",
      "Eval Loss:  0.20769035816192627\n",
      "Eval Loss:  0.19655950367450714\n",
      "Eval Loss:  0.18590062856674194\n",
      "Eval Loss:  0.2028484046459198\n",
      "Eval Loss:  0.2804495394229889\n",
      "Eval Loss:  0.343240886926651\n",
      "Eval Loss:  0.19341902434825897\n",
      "Eval Loss:  0.26402410864830017\n",
      "[[16550  1487]\n",
      " [  998 10425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     18037\n",
      "           1       0.88      0.91      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.92      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9156483367277665\n",
      "pre:  0.8751678979180658\n",
      "rec:  0.9126324082990458\n",
      "ma F1:  0.9118374059413268\n",
      "mi F1:  0.9156483367277665\n",
      "we F1:  0.9159525889979002\n",
      "29460 461\n",
      "Loss:  0.04424705356359482\n",
      "Loss:  0.06688734143972397\n",
      "Loss:  0.04749659448862076\n",
      "48 **********\n",
      "Epoch:  3267.114398956299  fold:  7  kers:  128\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.0742221474647522\n",
      "Loss:  0.05346681922674179\n",
      "Loss:  0.05534474551677704\n",
      "49 **********\n",
      "Epoch:  3320.042879343033  fold:  7  kers:  128\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.03864418715238571\n",
      "Loss:  0.06598741561174393\n",
      "Loss:  0.047228384763002396\n",
      "50 **********\n",
      "Epoch:  3373.034191131592  fold:  7  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.38528069853782654\n",
      "Eval Loss:  0.08648492395877838\n",
      "Eval Loss:  1.4403066635131836\n",
      "[[1823  304]\n",
      " [ 488  816]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82      2127\n",
      "           1       0.73      0.63      0.67      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.76      0.74      0.75      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7691635091809967\n",
      "pre:  0.7285714285714285\n",
      "rec:  0.6257668711656442\n",
      "ma F1:  0.7474042807615597\n",
      "mi F1:  0.7691635091809967\n",
      "we F1:  0.7651876422205435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1583082228899002\n",
      "Eval Loss:  0.13503894209861755\n",
      "Eval Loss:  0.1453268975019455\n",
      "Eval Loss:  0.19530518352985382\n",
      "Eval Loss:  0.1770210713148117\n",
      "Eval Loss:  0.18987056612968445\n",
      "Eval Loss:  0.20578224956989288\n",
      "Eval Loss:  0.16793301701545715\n",
      "Eval Loss:  0.17600414156913757\n",
      "Eval Loss:  0.1954033225774765\n",
      "Eval Loss:  0.23735682666301727\n",
      "Eval Loss:  0.09585629403591156\n",
      "Eval Loss:  0.1683778464794159\n",
      "Eval Loss:  0.17456753551959991\n",
      "Eval Loss:  0.13729603588581085\n",
      "Eval Loss:  0.23864540457725525\n",
      "Eval Loss:  0.17092999815940857\n",
      "Eval Loss:  0.19489577412605286\n",
      "Eval Loss:  0.1830906867980957\n",
      "Eval Loss:  0.13989810645580292\n",
      "Eval Loss:  0.17916961014270782\n",
      "Eval Loss:  0.1619928926229477\n",
      "Eval Loss:  0.16470836102962494\n",
      "Eval Loss:  0.16419728100299835\n",
      "Eval Loss:  0.24041025340557098\n",
      "Eval Loss:  0.2515479326248169\n",
      "Eval Loss:  0.18513299524784088\n",
      "Eval Loss:  0.20896384119987488\n",
      "[[17045   992]\n",
      " [ 1142 10281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18037\n",
      "           1       0.91      0.90      0.91     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9275627970128989\n",
      "pre:  0.9120021289807505\n",
      "rec:  0.9000262628031165\n",
      "ma F1:  0.923531700998666\n",
      "mi F1:  0.9275627970128989\n",
      "we F1:  0.9274734025122875\n",
      "29460 461\n",
      "Loss:  0.0580257922410965\n",
      "Loss:  0.038089461624622345\n",
      "Loss:  0.05601109191775322\n",
      "51 **********\n",
      "Epoch:  3466.642900466919  fold:  7  kers:  128\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.05222593620419502\n",
      "Loss:  0.050535909831523895\n",
      "Loss:  0.05473402887582779\n",
      "52 **********\n",
      "Epoch:  3519.6451830863953  fold:  7  kers:  128\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.0386248342692852\n",
      "Loss:  0.04609223082661629\n",
      "Loss:  0.05222535878419876\n",
      "53 **********\n",
      "Epoch:  3572.5716681480408  fold:  7  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.45198529958724976\n",
      "Eval Loss:  0.04768160358071327\n",
      "Eval Loss:  1.9708253145217896\n",
      "[[1963  164]\n",
      " [ 610  694]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.84      2127\n",
      "           1       0.81      0.53      0.64      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.73      0.74      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7744097930632469\n",
      "pre:  0.8088578088578089\n",
      "rec:  0.5322085889570553\n",
      "ma F1:  0.738658649398705\n",
      "mi F1:  0.7744097930632469\n",
      "we F1:  0.7618447733040778\n",
      "Eval Loss:  0.15986067056655884\n",
      "Eval Loss:  0.1531960666179657\n",
      "Eval Loss:  0.15804626047611237\n",
      "Eval Loss:  0.19108246266841888\n",
      "Eval Loss:  0.2099216729402542\n",
      "Eval Loss:  0.17668551206588745\n",
      "Eval Loss:  0.18931080400943756\n",
      "Eval Loss:  0.16812023520469666\n",
      "Eval Loss:  0.15961359441280365\n",
      "Eval Loss:  0.1903478056192398\n",
      "Eval Loss:  0.24383842945098877\n",
      "Eval Loss:  0.08296910673379898\n",
      "Eval Loss:  0.17243130505084991\n",
      "Eval Loss:  0.1679459512233734\n",
      "Eval Loss:  0.121055006980896\n",
      "Eval Loss:  0.1949913650751114\n",
      "Eval Loss:  0.16912151873111725\n",
      "Eval Loss:  0.1952897012233734\n",
      "Eval Loss:  0.2305292934179306\n",
      "Eval Loss:  0.13765573501586914\n",
      "Eval Loss:  0.19731123745441437\n",
      "Eval Loss:  0.13567382097244263\n",
      "Eval Loss:  0.161796435713768\n",
      "Eval Loss:  0.17107321321964264\n",
      "Eval Loss:  0.25156450271606445\n",
      "Eval Loss:  0.23189926147460938\n",
      "Eval Loss:  0.16654741764068604\n",
      "Eval Loss:  0.19641894102096558\n",
      "[[17315   722]\n",
      " [ 1402 10021]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     18037\n",
      "           1       0.93      0.88      0.90     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9279022403258655\n",
      "pre:  0.932793446895653\n",
      "rec:  0.8772651667687998\n",
      "ma F1:  0.9231939704552153\n",
      "mi F1:  0.9279022403258655\n",
      "we F1:  0.9274633009905158\n",
      "29460 461\n",
      "Loss:  0.05765857174992561\n",
      "Loss:  0.05427605286240578\n",
      "Loss:  0.0787554681301117\n",
      "54 **********\n",
      "Epoch:  3666.102585554123  fold:  7  kers:  128\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.0742902159690857\n",
      "Loss:  0.03285548463463783\n",
      "Loss:  0.03538390249013901\n",
      "55 **********\n",
      "Epoch:  3719.058990955353  fold:  7  kers:  128\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.049127668142318726\n",
      "Loss:  0.04125925153493881\n",
      "Loss:  0.023102356120944023\n",
      "56 **********\n",
      "Epoch:  3772.1081483364105  fold:  7  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.45270034670829773\n",
      "Eval Loss:  0.08952715992927551\n",
      "Eval Loss:  1.3182899951934814\n",
      "[[1921  206]\n",
      " [ 534  770]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84      2127\n",
      "           1       0.79      0.59      0.68      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.79      0.75      0.76      3431\n",
      "weighted avg       0.78      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7843194403963859\n",
      "pre:  0.7889344262295082\n",
      "rec:  0.5904907975460123\n",
      "ma F1:  0.7569685343870369\n",
      "mi F1:  0.7843194403963859\n",
      "we F1:  0.7765252638793864\n",
      "update!  Acc:  0.7843194403963859\n",
      "Eval Loss:  0.15409541130065918\n",
      "Eval Loss:  0.14391936361789703\n",
      "Eval Loss:  0.14834168553352356\n",
      "Eval Loss:  0.18875575065612793\n",
      "Eval Loss:  0.17946453392505646\n",
      "Eval Loss:  0.19811861217021942\n",
      "Eval Loss:  0.20686018466949463\n",
      "Eval Loss:  0.16815771162509918\n",
      "Eval Loss:  0.18233820796012878\n",
      "Eval Loss:  0.2122119814157486\n",
      "Eval Loss:  0.22864098846912384\n",
      "Eval Loss:  0.09877809137105942\n",
      "Eval Loss:  0.18022875487804413\n",
      "Eval Loss:  0.17471721768379211\n",
      "Eval Loss:  0.14287017285823822\n",
      "Eval Loss:  0.23442554473876953\n",
      "Eval Loss:  0.17065174877643585\n",
      "Eval Loss:  0.18590599298477173\n",
      "Eval Loss:  0.2053961604833603\n",
      "Eval Loss:  0.13610756397247314\n",
      "Eval Loss:  0.17081600427627563\n",
      "Eval Loss:  0.1712847650051117\n",
      "Eval Loss:  0.16851496696472168\n",
      "Eval Loss:  0.18171857297420502\n",
      "Eval Loss:  0.23471756279468536\n",
      "Eval Loss:  0.23409268260002136\n",
      "Eval Loss:  0.1849338561296463\n",
      "Eval Loss:  0.20488566160202026\n",
      "[[17166   871]\n",
      " [ 1271 10152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18037\n",
      "           1       0.92      0.89      0.90     11423\n",
      "\n",
      "    accuracy                           0.93     29460\n",
      "   macro avg       0.93      0.92      0.92     29460\n",
      "weighted avg       0.93      0.93      0.93     29460\n",
      "\n",
      "acc:  0.9272912423625255\n",
      "pre:  0.9209833983489069\n",
      "rec:  0.8887332574630132\n",
      "ma F1:  0.922922103029175\n",
      "mi F1:  0.9272912423625255\n",
      "we F1:  0.9270420755913049\n",
      "29460 461\n",
      "Loss:  0.0522746704518795\n",
      "Loss:  0.02897900715470314\n",
      "Loss:  0.029229216277599335\n",
      "57 **********\n",
      "Epoch:  3865.504426240921  fold:  7  kers:  128\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.032521139830350876\n",
      "Loss:  0.05552736297249794\n",
      "Loss:  0.02945619821548462\n",
      "58 **********\n",
      "Epoch:  3918.3501269817352  fold:  7  kers:  128\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.06470611691474915\n",
      "Loss:  0.06192706152796745\n",
      "Loss:  0.03150628134608269\n",
      "59 **********\n",
      "Epoch:  3971.2217588424683  fold:  7  kers:  128\n",
      "Eval Loss:  0.49712997674942017\n",
      "Eval Loss:  0.16507454216480255\n",
      "Eval Loss:  1.0257872343063354\n",
      "[[1756  371]\n",
      " [ 424  880]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      2127\n",
      "           1       0.70      0.67      0.69      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7682891285339551\n",
      "pre:  0.7034372501998402\n",
      "rec:  0.6748466257668712\n",
      "ma F1:  0.7521310822912866\n",
      "mi F1:  0.7682891285339551\n",
      "we F1:  0.7673115298457571\n",
      "update!  Acc:  0.7843194403963859\n",
      "Epoch:  3975.495332479477  fold:  7  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29817 3074\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29817 466\n",
      "Loss:  0.17291001975536346\n",
      "Loss:  0.16838914155960083\n",
      "Loss:  0.16278892755508423\n",
      "0 **********\n",
      "Epoch:  65.97160458564758  fold:  8  kers:  128\n",
      "epoch:  1\n",
      "29817 466\n",
      "Loss:  0.1337420791387558\n",
      "Loss:  0.13590490818023682\n",
      "Loss:  0.11816318333148956\n",
      "1 **********\n",
      "Epoch:  119.76178002357483  fold:  8  kers:  128\n",
      "epoch:  2\n",
      "29817 466\n",
      "Loss:  0.11229433119297028\n",
      "Loss:  0.13745608925819397\n",
      "Loss:  0.08970680087804794\n",
      "2 **********\n",
      "Epoch:  173.36844730377197  fold:  8  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.3697338402271271\n",
      "Eval Loss:  0.8003073930740356\n",
      "Eval Loss:  0.30688756704330444\n",
      "[[1803  270]\n",
      " [ 262  739]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      2073\n",
      "           1       0.73      0.74      0.74      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.80      0.80      0.80      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8269355888093689\n",
      "pre:  0.7324083250743311\n",
      "rec:  0.7382617382617382\n",
      "ma F1:  0.8033794295799879\n",
      "mi F1:  0.8269355888093689\n",
      "we F1:  0.8271127027885372\n",
      "update!  Acc:  0.8269355888093689\n",
      "Eval Loss:  0.4188354015350342\n",
      "Eval Loss:  0.41079181432724\n",
      "Eval Loss:  0.33056002855300903\n",
      "Eval Loss:  0.4268060028553009\n",
      "Eval Loss:  0.36123669147491455\n",
      "Eval Loss:  0.27281567454338074\n",
      "Eval Loss:  0.49961602687835693\n",
      "Eval Loss:  0.4129302501678467\n",
      "Eval Loss:  0.34852349758148193\n",
      "Eval Loss:  0.2832157015800476\n",
      "Eval Loss:  0.3868813216686249\n",
      "Eval Loss:  0.3175547122955322\n",
      "Eval Loss:  0.36414003372192383\n",
      "Eval Loss:  0.3424612283706665\n",
      "Eval Loss:  0.32040077447891235\n",
      "Eval Loss:  0.4172351658344269\n",
      "Eval Loss:  0.3688172698020935\n",
      "Eval Loss:  0.38891705870628357\n",
      "Eval Loss:  0.41032707691192627\n",
      "Eval Loss:  0.35116660594940186\n",
      "Eval Loss:  0.40201613306999207\n",
      "Eval Loss:  0.416172057390213\n",
      "Eval Loss:  0.3803134858608246\n",
      "Eval Loss:  0.3947514593601227\n",
      "Eval Loss:  0.37068209052085876\n",
      "Eval Loss:  0.483937531709671\n",
      "Eval Loss:  0.3042828142642975\n",
      "Eval Loss:  0.333192378282547\n",
      "Eval Loss:  0.42353126406669617\n",
      "[[15111  2980]\n",
      " [ 1958  9768]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86     18091\n",
      "           1       0.77      0.83      0.80     11726\n",
      "\n",
      "    accuracy                           0.83     29817\n",
      "   macro avg       0.83      0.83      0.83     29817\n",
      "weighted avg       0.84      0.83      0.84     29817\n",
      "\n",
      "acc:  0.8343897776436261\n",
      "pre:  0.7662378412299968\n",
      "rec:  0.8330206378986866\n",
      "ma F1:  0.8288955877394162\n",
      "mi F1:  0.8343897776436261\n",
      "we F1:  0.8354406969927001\n",
      "29817 466\n",
      "Loss:  0.10435766726732254\n",
      "Loss:  0.08967653661966324\n",
      "Loss:  0.10527035593986511\n",
      "3 **********\n",
      "Epoch:  267.88273549079895  fold:  8  kers:  128\n",
      "epoch:  4\n",
      "29817 466\n",
      "Loss:  0.08628394454717636\n",
      "Loss:  0.09727133810520172\n",
      "Loss:  0.11877739429473877\n",
      "4 **********\n",
      "Epoch:  321.5671935081482  fold:  8  kers:  128\n",
      "epoch:  5\n",
      "29817 466\n",
      "Loss:  0.0989113301038742\n",
      "Loss:  0.07054676115512848\n",
      "Loss:  0.07940278202295303\n",
      "5 **********\n",
      "Epoch:  375.2775831222534  fold:  8  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.4639408588409424\n",
      "Eval Loss:  1.3414372205734253\n",
      "Eval Loss:  0.1318679302930832\n",
      "[[1762  311]\n",
      " [ 391  610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83      2073\n",
      "           1       0.66      0.61      0.63      1001\n",
      "\n",
      "    accuracy                           0.77      3074\n",
      "   macro avg       0.74      0.73      0.73      3074\n",
      "weighted avg       0.77      0.77      0.77      3074\n",
      "\n",
      "acc:  0.7716330513988289\n",
      "pre:  0.6623235613463626\n",
      "rec:  0.6093906093906094\n",
      "ma F1:  0.734320466976888\n",
      "mi F1:  0.7716330513988289\n",
      "we F1:  0.7690418997028607\n",
      "Eval Loss:  0.39789891242980957\n",
      "Eval Loss:  0.3335793614387512\n",
      "Eval Loss:  0.24653270840644836\n",
      "Eval Loss:  0.3972092568874359\n",
      "Eval Loss:  0.27921539545059204\n",
      "Eval Loss:  0.24748049676418304\n",
      "Eval Loss:  0.5263633728027344\n",
      "Eval Loss:  0.38206860423088074\n",
      "Eval Loss:  0.3387691080570221\n",
      "Eval Loss:  0.21722234785556793\n",
      "Eval Loss:  0.36624595522880554\n",
      "Eval Loss:  0.23006722331047058\n",
      "Eval Loss:  0.3043072819709778\n",
      "Eval Loss:  0.3063116669654846\n",
      "Eval Loss:  0.327586829662323\n",
      "Eval Loss:  0.3688620924949646\n",
      "Eval Loss:  0.278974324464798\n",
      "Eval Loss:  0.40025022625923157\n",
      "Eval Loss:  0.40679651498794556\n",
      "Eval Loss:  0.26643475890159607\n",
      "Eval Loss:  0.36464986205101013\n",
      "Eval Loss:  0.2904766798019409\n",
      "Eval Loss:  0.35232263803482056\n",
      "Eval Loss:  0.4139685332775116\n",
      "Eval Loss:  0.3497927784919739\n",
      "Eval Loss:  0.4536535441875458\n",
      "Eval Loss:  0.2427900731563568\n",
      "Eval Loss:  0.3101026713848114\n",
      "Eval Loss:  0.4409956634044647\n",
      "[[16859  1232]\n",
      " [ 2789  8937]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89     18091\n",
      "           1       0.88      0.76      0.82     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.87      0.85      0.85     29817\n",
      "weighted avg       0.87      0.87      0.86     29817\n",
      "\n",
      "acc:  0.8651440453432605\n",
      "pre:  0.8788474776280853\n",
      "rec:  0.7621524816646768\n",
      "ma F1:  0.8549015808698586\n",
      "mi F1:  0.8651440453432605\n",
      "we F1:  0.8631309782913688\n",
      "29817 466\n",
      "Loss:  0.07125385105609894\n",
      "Loss:  0.0978977233171463\n",
      "Loss:  0.11941831558942795\n",
      "6 **********\n",
      "Epoch:  469.7888786792755  fold:  8  kers:  128\n",
      "epoch:  7\n",
      "29817 466\n",
      "Loss:  0.09670425206422806\n",
      "Loss:  0.04953686520457268\n",
      "Loss:  0.054592546075582504\n",
      "7 **********\n",
      "Epoch:  523.3137640953064  fold:  8  kers:  128\n",
      "epoch:  8\n",
      "29817 466\n",
      "Loss:  0.08514362573623657\n",
      "Loss:  0.07471482455730438\n",
      "Loss:  0.11363960802555084\n",
      "8 **********\n",
      "Epoch:  576.8516147136688  fold:  8  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.6170466542243958\n",
      "Eval Loss:  1.321092128753662\n",
      "Eval Loss:  0.12560807168483734\n",
      "[[1586  487]\n",
      " [ 323  678]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80      2073\n",
      "           1       0.58      0.68      0.63      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.71      0.72      0.71      3074\n",
      "weighted avg       0.75      0.74      0.74      3074\n",
      "\n",
      "acc:  0.7364996746909565\n",
      "pre:  0.5819742489270386\n",
      "rec:  0.6773226773226774\n",
      "ma F1:  0.7113117060011047\n",
      "mi F1:  0.7364996746909565\n",
      "we F1:  0.7410490434851588\n",
      "Eval Loss:  0.36136817932128906\n",
      "Eval Loss:  0.2866305708885193\n",
      "Eval Loss:  0.21269665658473969\n",
      "Eval Loss:  0.3306296467781067\n",
      "Eval Loss:  0.23917801678180695\n",
      "Eval Loss:  0.2234359085559845\n",
      "Eval Loss:  0.4249093234539032\n",
      "Eval Loss:  0.3252207338809967\n",
      "Eval Loss:  0.3039693832397461\n",
      "Eval Loss:  0.20143520832061768\n",
      "Eval Loss:  0.314190149307251\n",
      "Eval Loss:  0.15661202371120453\n",
      "Eval Loss:  0.2538764178752899\n",
      "Eval Loss:  0.29908570647239685\n",
      "Eval Loss:  0.28311964869499207\n",
      "Eval Loss:  0.30906039476394653\n",
      "Eval Loss:  0.263105183839798\n",
      "Eval Loss:  0.32671746611595154\n",
      "Eval Loss:  0.3316587209701538\n",
      "Eval Loss:  0.24115903675556183\n",
      "Eval Loss:  0.2901849150657654\n",
      "Eval Loss:  0.255778968334198\n",
      "Eval Loss:  0.32054051756858826\n",
      "Eval Loss:  0.3626660108566284\n",
      "Eval Loss:  0.31220170855522156\n",
      "Eval Loss:  0.41802847385406494\n",
      "Eval Loss:  0.23180504143238068\n",
      "Eval Loss:  0.26391732692718506\n",
      "Eval Loss:  0.3776233196258545\n",
      "[[16797  1294]\n",
      " [ 2268  9458]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     18091\n",
      "           1       0.88      0.81      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.88      0.87      0.87     29817\n",
      "weighted avg       0.88      0.88      0.88     29817\n",
      "\n",
      "acc:  0.880537948150384\n",
      "pre:  0.8796502976190477\n",
      "rec:  0.8065836602421969\n",
      "ma F1:  0.8728339330720672\n",
      "mi F1:  0.8805379481503841\n",
      "we F1:  0.8795155049447319\n",
      "29817 466\n",
      "Loss:  0.07907169312238693\n",
      "Loss:  0.0733599066734314\n",
      "Loss:  0.07569748908281326\n",
      "9 **********\n",
      "Epoch:  671.0736844539642  fold:  8  kers:  128\n",
      "epoch:  10\n",
      "29817 466\n",
      "Loss:  0.08199891448020935\n",
      "Loss:  0.06671132147312164\n",
      "Loss:  0.08607980608940125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 **********\n",
      "Epoch:  724.6105382442474  fold:  8  kers:  128\n",
      "epoch:  11\n",
      "29817 466\n",
      "Loss:  0.07101625949144363\n",
      "Loss:  0.07430063188076019\n",
      "Loss:  0.07153020799160004\n",
      "11 **********\n",
      "Epoch:  778.03568983078  fold:  8  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.6271085143089294\n",
      "Eval Loss:  1.2157909870147705\n",
      "Eval Loss:  0.11777196079492569\n",
      "[[1584  489]\n",
      " [ 304  697]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80      2073\n",
      "           1       0.59      0.70      0.64      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.71      0.73      0.72      3074\n",
      "weighted avg       0.76      0.74      0.75      3074\n",
      "\n",
      "acc:  0.7420299284320104\n",
      "pre:  0.5876897133220911\n",
      "rec:  0.6963036963036963\n",
      "ma F1:  0.718600432867001\n",
      "mi F1:  0.7420299284320104\n",
      "we F1:  0.7469165763232468\n",
      "Eval Loss:  0.3612699508666992\n",
      "Eval Loss:  0.2539438307285309\n",
      "Eval Loss:  0.17151959240436554\n",
      "Eval Loss:  0.27911320328712463\n",
      "Eval Loss:  0.21364207565784454\n",
      "Eval Loss:  0.23030497133731842\n",
      "Eval Loss:  0.38676917552948\n",
      "Eval Loss:  0.3146804869174957\n",
      "Eval Loss:  0.2831256687641144\n",
      "Eval Loss:  0.1798652857542038\n",
      "Eval Loss:  0.26140347123146057\n",
      "Eval Loss:  0.14353477954864502\n",
      "Eval Loss:  0.24681000411510468\n",
      "Eval Loss:  0.29197797179222107\n",
      "Eval Loss:  0.2934306561946869\n",
      "Eval Loss:  0.3080863356590271\n",
      "Eval Loss:  0.23708635568618774\n",
      "Eval Loss:  0.30315837264060974\n",
      "Eval Loss:  0.27829262614250183\n",
      "Eval Loss:  0.21548567712306976\n",
      "Eval Loss:  0.2597982585430145\n",
      "Eval Loss:  0.20778842270374298\n",
      "Eval Loss:  0.3001072108745575\n",
      "Eval Loss:  0.3415612280368805\n",
      "Eval Loss:  0.32114094495773315\n",
      "Eval Loss:  0.3927711844444275\n",
      "Eval Loss:  0.22044925391674042\n",
      "Eval Loss:  0.22167561948299408\n",
      "Eval Loss:  0.3444391191005707\n",
      "[[16716  1375]\n",
      " [ 1940  9786]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     18091\n",
      "           1       0.88      0.83      0.86     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.89      0.88      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8888218130596639\n",
      "pre:  0.8768031538392617\n",
      "rec:  0.8345556882142248\n",
      "ma F1:  0.8824732520477969\n",
      "mi F1:  0.8888218130596639\n",
      "we F1:  0.8883042175370515\n",
      "29817 466\n",
      "Loss:  0.05906926468014717\n",
      "Loss:  0.11149143427610397\n",
      "Loss:  0.07817152142524719\n",
      "12 **********\n",
      "Epoch:  872.17298579216  fold:  8  kers:  128\n",
      "epoch:  13\n",
      "29817 466\n",
      "Loss:  0.08666269481182098\n",
      "Loss:  0.050562627613544464\n",
      "Loss:  0.056060634553432465\n",
      "13 **********\n",
      "Epoch:  925.7168202400208  fold:  8  kers:  128\n",
      "epoch:  14\n",
      "29817 466\n",
      "Loss:  0.08704202622175217\n",
      "Loss:  0.056951526552438736\n",
      "Loss:  0.07912931591272354\n",
      "14 **********\n",
      "Epoch:  979.3314654827118  fold:  8  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.44764140248298645\n",
      "Eval Loss:  1.345360517501831\n",
      "Eval Loss:  0.09357398003339767\n",
      "[[1736  337]\n",
      " [ 322  679]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      2073\n",
      "           1       0.67      0.68      0.67      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.76      0.76      0.76      3074\n",
      "weighted avg       0.79      0.79      0.79      3074\n",
      "\n",
      "acc:  0.7856213402732596\n",
      "pre:  0.6683070866141733\n",
      "rec:  0.6783216783216783\n",
      "ma F1:  0.7568758028315841\n",
      "mi F1:  0.7856213402732596\n",
      "we F1:  0.7860292712681748\n",
      "Eval Loss:  0.3562467694282532\n",
      "Eval Loss:  0.2569122910499573\n",
      "Eval Loss:  0.15419796109199524\n",
      "Eval Loss:  0.2973631024360657\n",
      "Eval Loss:  0.20286424458026886\n",
      "Eval Loss:  0.20854276418685913\n",
      "Eval Loss:  0.37648624181747437\n",
      "Eval Loss:  0.27090275287628174\n",
      "Eval Loss:  0.2997369170188904\n",
      "Eval Loss:  0.15601453185081482\n",
      "Eval Loss:  0.2506083846092224\n",
      "Eval Loss:  0.13868702948093414\n",
      "Eval Loss:  0.23051276803016663\n",
      "Eval Loss:  0.2645835280418396\n",
      "Eval Loss:  0.2859458327293396\n",
      "Eval Loss:  0.26882630586624146\n",
      "Eval Loss:  0.23311026394367218\n",
      "Eval Loss:  0.2805064022541046\n",
      "Eval Loss:  0.26661500334739685\n",
      "Eval Loss:  0.22066247463226318\n",
      "Eval Loss:  0.25391632318496704\n",
      "Eval Loss:  0.21177756786346436\n",
      "Eval Loss:  0.280518114566803\n",
      "Eval Loss:  0.3054538369178772\n",
      "Eval Loss:  0.30029529333114624\n",
      "Eval Loss:  0.40005233883857727\n",
      "Eval Loss:  0.20420899987220764\n",
      "Eval Loss:  0.22457587718963623\n",
      "Eval Loss:  0.31364312767982483\n",
      "[[17011  1080]\n",
      " [ 2051  9675]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     18091\n",
      "           1       0.90      0.83      0.86     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.88      0.89     29817\n",
      "weighted avg       0.90      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8949927893483584\n",
      "pre:  0.899581589958159\n",
      "rec:  0.8250895446017398\n",
      "ma F1:  0.8882268475993365\n",
      "mi F1:  0.8949927893483584\n",
      "we F1:  0.8940972428055148\n",
      "29817 466\n",
      "Loss:  0.08027711510658264\n",
      "Loss:  0.06683945655822754\n",
      "Loss:  0.07383926957845688\n",
      "15 **********\n",
      "Epoch:  1073.4508092403412  fold:  8  kers:  128\n",
      "epoch:  16\n",
      "29817 466\n",
      "Loss:  0.052528075873851776\n",
      "Loss:  0.06110186129808426\n",
      "Loss:  0.0832880362868309\n",
      "16 **********\n",
      "Epoch:  1131.8217377662659  fold:  8  kers:  128\n",
      "epoch:  17\n",
      "29817 466\n",
      "Loss:  0.05253766477108002\n",
      "Loss:  0.035444434732198715\n",
      "Loss:  0.06231752783060074\n",
      "17 **********\n",
      "Epoch:  1185.22794008255  fold:  8  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.555076539516449\n",
      "Eval Loss:  1.0142993927001953\n",
      "Eval Loss:  0.09115658700466156\n",
      "[[1734  339]\n",
      " [ 317  684]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84      2073\n",
      "           1       0.67      0.68      0.68      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.76      0.76      0.76      3074\n",
      "weighted avg       0.79      0.79      0.79      3074\n",
      "\n",
      "acc:  0.7865972674040338\n",
      "pre:  0.6686217008797654\n",
      "rec:  0.6833166833166833\n",
      "ma F1:  0.7584102314419019\n",
      "mi F1:  0.7865972674040337\n",
      "we F1:  0.7871878529194309\n",
      "Eval Loss:  0.3093341886997223\n",
      "Eval Loss:  0.257006973028183\n",
      "Eval Loss:  0.15344244241714478\n",
      "Eval Loss:  0.23644043505191803\n",
      "Eval Loss:  0.21854044497013092\n",
      "Eval Loss:  0.17945632338523865\n",
      "Eval Loss:  0.35384494066238403\n",
      "Eval Loss:  0.259494811296463\n",
      "Eval Loss:  0.2880747616291046\n",
      "Eval Loss:  0.15179294347763062\n",
      "Eval Loss:  0.19772176444530487\n",
      "Eval Loss:  0.15650826692581177\n",
      "Eval Loss:  0.19134670495986938\n",
      "Eval Loss:  0.23621304333209991\n",
      "Eval Loss:  0.29058703780174255\n",
      "Eval Loss:  0.2540667951107025\n",
      "Eval Loss:  0.2366054356098175\n",
      "Eval Loss:  0.2515702247619629\n",
      "Eval Loss:  0.2239983230829239\n",
      "Eval Loss:  0.23693570494651794\n",
      "Eval Loss:  0.2584558129310608\n",
      "Eval Loss:  0.19263912737369537\n",
      "Eval Loss:  0.3016277551651001\n",
      "Eval Loss:  0.31621962785720825\n",
      "Eval Loss:  0.2813762128353119\n",
      "Eval Loss:  0.36376845836639404\n",
      "Eval Loss:  0.19289463758468628\n",
      "Eval Loss:  0.19592902064323425\n",
      "Eval Loss:  0.2647051215171814\n",
      "[[17097   994]\n",
      " [ 1868  9858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18091\n",
      "           1       0.91      0.84      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.90     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.9040144883791126\n",
      "pre:  0.9084039808330262\n",
      "rec:  0.8406958894763773\n",
      "ma F1:  0.8980024903305847\n",
      "mi F1:  0.9040144883791126\n",
      "we F1:  0.903288630347007\n",
      "29817 466\n",
      "Loss:  0.08166999369859695\n",
      "Loss:  0.11944496631622314\n",
      "Loss:  0.0662841647863388\n",
      "18 **********\n",
      "Epoch:  1282.9127507209778  fold:  8  kers:  128\n",
      "epoch:  19\n",
      "29817 466\n",
      "Loss:  0.08138760924339294\n",
      "Loss:  0.05010722577571869\n",
      "Loss:  0.060266271233558655\n",
      "19 **********\n",
      "Epoch:  1336.507449388504  fold:  8  kers:  128\n",
      "epoch:  20\n",
      "29817 466\n",
      "Loss:  0.052008919417858124\n",
      "Loss:  0.11554399132728577\n",
      "Loss:  0.052384596318006516\n",
      "20 **********\n",
      "Epoch:  1390.0393161773682  fold:  8  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.5944725275039673\n",
      "Eval Loss:  1.1693670749664307\n",
      "Eval Loss:  0.11232245713472366\n",
      "[[1639  434]\n",
      " [ 243  758]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      2073\n",
      "           1       0.64      0.76      0.69      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.75      0.77      0.76      3074\n",
      "weighted avg       0.79      0.78      0.78      3074\n",
      "\n",
      "acc:  0.7797657774886142\n",
      "pre:  0.6359060402684564\n",
      "rec:  0.7572427572427572\n",
      "ma F1:  0.7600573713741516\n",
      "mi F1:  0.7797657774886142\n",
      "we F1:  0.7840385420378336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2848629653453827\n",
      "Eval Loss:  0.24868200719356537\n",
      "Eval Loss:  0.1444597989320755\n",
      "Eval Loss:  0.24960826337337494\n",
      "Eval Loss:  0.17589153349399567\n",
      "Eval Loss:  0.1882849633693695\n",
      "Eval Loss:  0.3164598345756531\n",
      "Eval Loss:  0.24481868743896484\n",
      "Eval Loss:  0.2691479027271271\n",
      "Eval Loss:  0.13112469017505646\n",
      "Eval Loss:  0.19288276135921478\n",
      "Eval Loss:  0.1525408774614334\n",
      "Eval Loss:  0.20351654291152954\n",
      "Eval Loss:  0.23791296780109406\n",
      "Eval Loss:  0.26542869210243225\n",
      "Eval Loss:  0.24187365174293518\n",
      "Eval Loss:  0.24120953679084778\n",
      "Eval Loss:  0.22463084757328033\n",
      "Eval Loss:  0.21895553171634674\n",
      "Eval Loss:  0.20627768337726593\n",
      "Eval Loss:  0.23934981226921082\n",
      "Eval Loss:  0.19983826577663422\n",
      "Eval Loss:  0.2615862786769867\n",
      "Eval Loss:  0.2755529582500458\n",
      "Eval Loss:  0.3011086881160736\n",
      "Eval Loss:  0.35319003462791443\n",
      "Eval Loss:  0.19037176668643951\n",
      "Eval Loss:  0.1860656440258026\n",
      "Eval Loss:  0.2360493242740631\n",
      "[[16892  1199]\n",
      " [ 1484 10242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18091\n",
      "           1       0.90      0.87      0.88     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.90      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9100177750947446\n",
      "pre:  0.8952014684031117\n",
      "rec:  0.8734436295411905\n",
      "ma F1:  0.905307674503403\n",
      "mi F1:  0.9100177750947446\n",
      "we F1:  0.9098159136408299\n",
      "29817 466\n",
      "Loss:  0.052573997527360916\n",
      "Loss:  0.05052170529961586\n",
      "Loss:  0.06891904026269913\n",
      "21 **********\n",
      "Epoch:  1484.2524094581604  fold:  8  kers:  128\n",
      "epoch:  22\n",
      "29817 466\n",
      "Loss:  0.0626804530620575\n",
      "Loss:  0.08572202920913696\n",
      "Loss:  0.08846577256917953\n",
      "22 **********\n",
      "Epoch:  1537.7603402137756  fold:  8  kers:  128\n",
      "epoch:  23\n",
      "29817 466\n",
      "Loss:  0.08826402574777603\n",
      "Loss:  0.07796743512153625\n",
      "Loss:  0.07344283908605576\n",
      "23 **********\n",
      "Epoch:  1591.3261160850525  fold:  8  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.8285878896713257\n",
      "Eval Loss:  0.845372200012207\n",
      "Eval Loss:  0.09921566396951675\n",
      "[[1753  320]\n",
      " [ 205  796]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87      2073\n",
      "           1       0.71      0.80      0.75      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.80      0.82      0.81      3074\n",
      "weighted avg       0.84      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8292127521145087\n",
      "pre:  0.7132616487455197\n",
      "rec:  0.7952047952047953\n",
      "ma F1:  0.8108834613933794\n",
      "mi F1:  0.8292127521145087\n",
      "we F1:  0.8314153314592632\n",
      "update!  Acc:  0.8292127521145087\n",
      "Eval Loss:  0.3039586544036865\n",
      "Eval Loss:  0.23505227267742157\n",
      "Eval Loss:  0.1300007551908493\n",
      "Eval Loss:  0.20701727271080017\n",
      "Eval Loss:  0.17685912549495697\n",
      "Eval Loss:  0.18665166199207306\n",
      "Eval Loss:  0.28050073981285095\n",
      "Eval Loss:  0.23746024072170258\n",
      "Eval Loss:  0.2780159115791321\n",
      "Eval Loss:  0.12264940142631531\n",
      "Eval Loss:  0.15768933296203613\n",
      "Eval Loss:  0.18410980701446533\n",
      "Eval Loss:  0.22782227396965027\n",
      "Eval Loss:  0.2308836728334427\n",
      "Eval Loss:  0.26092544198036194\n",
      "Eval Loss:  0.2681894600391388\n",
      "Eval Loss:  0.2179432064294815\n",
      "Eval Loss:  0.19441217184066772\n",
      "Eval Loss:  0.1902005523443222\n",
      "Eval Loss:  0.20451635122299194\n",
      "Eval Loss:  0.22935648262500763\n",
      "Eval Loss:  0.20658276975154877\n",
      "Eval Loss:  0.274181604385376\n",
      "Eval Loss:  0.2916862666606903\n",
      "Eval Loss:  0.33174943923950195\n",
      "Eval Loss:  0.33728861808776855\n",
      "Eval Loss:  0.17322546243667603\n",
      "Eval Loss:  0.1646149903535843\n",
      "Eval Loss:  0.22067251801490784\n",
      "[[16479  1612]\n",
      " [ 1108 10618]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92     18091\n",
      "           1       0.87      0.91      0.89     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.90      0.91      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9087768722540832\n",
      "pre:  0.868192968111202\n",
      "rec:  0.9055091250213202\n",
      "ma F1:  0.9051105250033716\n",
      "mi F1:  0.9087768722540832\n",
      "we F1:  0.9090921493423545\n",
      "29817 466\n",
      "Loss:  0.08101408928632736\n",
      "Loss:  0.05444072559475899\n",
      "Loss:  0.09508159011602402\n",
      "24 **********\n",
      "Epoch:  1685.515273809433  fold:  8  kers:  128\n",
      "epoch:  25\n",
      "29817 466\n",
      "Loss:  0.04679235443472862\n",
      "Loss:  0.07478900253772736\n",
      "Loss:  0.07331940531730652\n",
      "25 **********\n",
      "Epoch:  1739.0072467327118  fold:  8  kers:  128\n",
      "epoch:  26\n",
      "29817 466\n",
      "Loss:  0.07330027222633362\n",
      "Loss:  0.05150051787495613\n",
      "Loss:  0.062465324997901917\n",
      "26 **********\n",
      "Epoch:  1792.5071992874146  fold:  8  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.6753939986228943\n",
      "Eval Loss:  0.9925122261047363\n",
      "Eval Loss:  0.09822532534599304\n",
      "[[1816  257]\n",
      " [ 249  752]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      2073\n",
      "           1       0.75      0.75      0.75      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.81      0.81      0.81      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8353936239427456\n",
      "pre:  0.7452923686818632\n",
      "rec:  0.7512487512487512\n",
      "ma F1:  0.8129887055779584\n",
      "mi F1:  0.8353936239427456\n",
      "we F1:  0.8355620819755637\n",
      "update!  Acc:  0.8353936239427456\n",
      "Eval Loss:  0.2880053222179413\n",
      "Eval Loss:  0.1988236904144287\n",
      "Eval Loss:  0.1263769268989563\n",
      "Eval Loss:  0.22038426995277405\n",
      "Eval Loss:  0.15585526823997498\n",
      "Eval Loss:  0.17870207130908966\n",
      "Eval Loss:  0.29200589656829834\n",
      "Eval Loss:  0.22917158901691437\n",
      "Eval Loss:  0.2471180558204651\n",
      "Eval Loss:  0.1476324200630188\n",
      "Eval Loss:  0.16908769309520721\n",
      "Eval Loss:  0.15797095000743866\n",
      "Eval Loss:  0.20757050812244415\n",
      "Eval Loss:  0.25078368186950684\n",
      "Eval Loss:  0.2289416640996933\n",
      "Eval Loss:  0.23194539546966553\n",
      "Eval Loss:  0.2268793284893036\n",
      "Eval Loss:  0.2075888216495514\n",
      "Eval Loss:  0.19663313031196594\n",
      "Eval Loss:  0.22006788849830627\n",
      "Eval Loss:  0.23108352720737457\n",
      "Eval Loss:  0.18475398421287537\n",
      "Eval Loss:  0.24445904791355133\n",
      "Eval Loss:  0.26559752225875854\n",
      "Eval Loss:  0.2816009521484375\n",
      "Eval Loss:  0.30970168113708496\n",
      "Eval Loss:  0.1640186756849289\n",
      "Eval Loss:  0.1831940859556198\n",
      "Eval Loss:  0.2338489443063736\n",
      "[[16881  1210]\n",
      " [ 1344 10382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18091\n",
      "           1       0.90      0.89      0.89     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9143441660797531\n",
      "pre:  0.8956176673567978\n",
      "rec:  0.8853829097731537\n",
      "ma F1:  0.9100718761630915\n",
      "mi F1:  0.9143441660797531\n",
      "we F1:  0.9142560776278633\n",
      "29817 466\n",
      "Loss:  0.06398500502109528\n",
      "Loss:  0.07171442359685898\n",
      "Loss:  0.07453380525112152\n",
      "27 **********\n",
      "Epoch:  1886.5677008628845  fold:  8  kers:  128\n",
      "epoch:  28\n",
      "29817 466\n",
      "Loss:  0.07552958279848099\n",
      "Loss:  0.05675412341952324\n",
      "Loss:  0.05065707489848137\n",
      "28 **********\n",
      "Epoch:  1940.0955777168274  fold:  8  kers:  128\n",
      "epoch:  29\n",
      "29817 466\n",
      "Loss:  0.030151836574077606\n",
      "Loss:  0.07235602289438248\n",
      "Loss:  0.02647426910698414\n",
      "29 **********\n",
      "Epoch:  1993.5656094551086  fold:  8  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.676821231842041\n",
      "Eval Loss:  0.866414487361908\n",
      "Eval Loss:  0.08745192736387253\n",
      "[[1833  240]\n",
      " [ 203  798]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      2073\n",
      "           1       0.77      0.80      0.78      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.83      0.84      0.84      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8558880936890045\n",
      "pre:  0.7687861271676301\n",
      "rec:  0.7972027972027972\n",
      "ma F1:  0.8374622579342634\n",
      "mi F1:  0.8558880936890045\n",
      "we F1:  0.8565467950638117\n",
      "update!  Acc:  0.8558880936890045\n",
      "Eval Loss:  0.2874770760536194\n",
      "Eval Loss:  0.23075832426548004\n",
      "Eval Loss:  0.13275529444217682\n",
      "Eval Loss:  0.21137592196464539\n",
      "Eval Loss:  0.16164027154445648\n",
      "Eval Loss:  0.1785602867603302\n",
      "Eval Loss:  0.2888830900192261\n",
      "Eval Loss:  0.25916433334350586\n",
      "Eval Loss:  0.2607825696468353\n",
      "Eval Loss:  0.12931647896766663\n",
      "Eval Loss:  0.13083842396736145\n",
      "Eval Loss:  0.21511071920394897\n",
      "Eval Loss:  0.2055114060640335\n",
      "Eval Loss:  0.23050548136234283\n",
      "Eval Loss:  0.2642544209957123\n",
      "Eval Loss:  0.30309510231018066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22342237830162048\n",
      "Eval Loss:  0.20154458284378052\n",
      "Eval Loss:  0.19721949100494385\n",
      "Eval Loss:  0.20059898495674133\n",
      "Eval Loss:  0.23075178265571594\n",
      "Eval Loss:  0.20985737442970276\n",
      "Eval Loss:  0.27101701498031616\n",
      "Eval Loss:  0.3006863296031952\n",
      "Eval Loss:  0.3384833335876465\n",
      "Eval Loss:  0.36204788088798523\n",
      "Eval Loss:  0.1746201515197754\n",
      "Eval Loss:  0.15718144178390503\n",
      "Eval Loss:  0.22063139081001282\n",
      "[[16461  1630]\n",
      " [ 1071 10655]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92     18091\n",
      "           1       0.87      0.91      0.89     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.90      0.91      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9094140926317201\n",
      "pre:  0.8673178673178673\n",
      "rec:  0.9086645062254818\n",
      "ma F1:  0.9058440453888432\n",
      "mi F1:  0.9094140926317201\n",
      "we F1:  0.9097578157472505\n",
      "29817 466\n",
      "Loss:  0.07183882594108582\n",
      "Loss:  0.05465921014547348\n",
      "Loss:  0.04755131155252457\n",
      "30 **********\n",
      "Epoch:  2087.6839559078217  fold:  8  kers:  128\n",
      "epoch:  31\n",
      "29817 466\n",
      "Loss:  0.04402795061469078\n",
      "Loss:  0.060610082000494\n",
      "Loss:  0.059716589748859406\n",
      "31 **********\n",
      "Epoch:  2141.3355026245117  fold:  8  kers:  128\n",
      "epoch:  32\n",
      "29817 466\n",
      "Loss:  0.06437411159276962\n",
      "Loss:  0.0681631863117218\n",
      "Loss:  0.046882305294275284\n",
      "32 **********\n",
      "Epoch:  2194.9212255477905  fold:  8  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.8932879567146301\n",
      "Eval Loss:  1.0252370834350586\n",
      "Eval Loss:  0.09125862270593643\n",
      "[[1781  292]\n",
      " [ 202  799]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88      2073\n",
      "           1       0.73      0.80      0.76      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.82      0.83      0.82      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8392973324658426\n",
      "pre:  0.7323556370302475\n",
      "rec:  0.7982017982017982\n",
      "ma F1:  0.8210337304505566\n",
      "mi F1:  0.8392973324658426\n",
      "we F1:  0.8409711860110318\n",
      "Eval Loss:  0.24140465259552002\n",
      "Eval Loss:  0.19626830518245697\n",
      "Eval Loss:  0.11363855004310608\n",
      "Eval Loss:  0.19760964810848236\n",
      "Eval Loss:  0.1554121971130371\n",
      "Eval Loss:  0.1778089553117752\n",
      "Eval Loss:  0.28187990188598633\n",
      "Eval Loss:  0.26279667019844055\n",
      "Eval Loss:  0.2481505572795868\n",
      "Eval Loss:  0.15094633400440216\n",
      "Eval Loss:  0.13481350243091583\n",
      "Eval Loss:  0.16409896314144135\n",
      "Eval Loss:  0.17380475997924805\n",
      "Eval Loss:  0.2144537717103958\n",
      "Eval Loss:  0.19310110807418823\n",
      "Eval Loss:  0.26103678345680237\n",
      "Eval Loss:  0.2191305309534073\n",
      "Eval Loss:  0.16307546198368073\n",
      "Eval Loss:  0.15288297832012177\n",
      "Eval Loss:  0.24203093349933624\n",
      "Eval Loss:  0.2279660999774933\n",
      "Eval Loss:  0.16034571826457977\n",
      "Eval Loss:  0.21547625958919525\n",
      "Eval Loss:  0.25201964378356934\n",
      "Eval Loss:  0.25675463676452637\n",
      "Eval Loss:  0.32715314626693726\n",
      "Eval Loss:  0.14927256107330322\n",
      "Eval Loss:  0.16258256137371063\n",
      "Eval Loss:  0.2247259020805359\n",
      "[[16756  1335]\n",
      " [ 1087 10639]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18091\n",
      "           1       0.89      0.91      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.91      0.92      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9187711708085992\n",
      "pre:  0.8885084349423752\n",
      "rec:  0.9073000170561146\n",
      "ma F1:  0.9152022801296047\n",
      "mi F1:  0.9187711708085992\n",
      "we F1:  0.9189158634501537\n",
      "29817 466\n",
      "Loss:  0.04453997686505318\n",
      "Loss:  0.06516110152006149\n",
      "Loss:  0.06350032985210419\n",
      "33 **********\n",
      "Epoch:  2289.2101159095764  fold:  8  kers:  128\n",
      "epoch:  34\n",
      "29817 466\n",
      "Loss:  0.06814683973789215\n",
      "Loss:  0.05286002904176712\n",
      "Loss:  0.04677208140492439\n",
      "34 **********\n",
      "Epoch:  2342.7778871059418  fold:  8  kers:  128\n",
      "epoch:  35\n",
      "29817 466\n",
      "Loss:  0.061341531574726105\n",
      "Loss:  0.06028125062584877\n",
      "Loss:  0.04419897496700287\n",
      "35 **********\n",
      "Epoch:  2396.4264414310455  fold:  8  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.4048477113246918\n",
      "Eval Loss:  1.1528106927871704\n",
      "Eval Loss:  0.09404724836349487\n",
      "[[1869  204]\n",
      " [ 234  767]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      2073\n",
      "           1       0.79      0.77      0.78      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.84      0.83      0.84      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8575146389069617\n",
      "pre:  0.7899073120494335\n",
      "rec:  0.7662337662337663\n",
      "ma F1:  0.8365027045300879\n",
      "mi F1:  0.8575146389069617\n",
      "we F1:  0.8569426261743789\n",
      "update!  Acc:  0.8575146389069617\n",
      "Eval Loss:  0.2647913992404938\n",
      "Eval Loss:  0.21975088119506836\n",
      "Eval Loss:  0.16176524758338928\n",
      "Eval Loss:  0.20772717893123627\n",
      "Eval Loss:  0.14893116056919098\n",
      "Eval Loss:  0.18321192264556885\n",
      "Eval Loss:  0.28850334882736206\n",
      "Eval Loss:  0.2698822021484375\n",
      "Eval Loss:  0.24765343964099884\n",
      "Eval Loss:  0.12865594029426575\n",
      "Eval Loss:  0.15811502933502197\n",
      "Eval Loss:  0.1874329149723053\n",
      "Eval Loss:  0.1889815330505371\n",
      "Eval Loss:  0.20594461262226105\n",
      "Eval Loss:  0.2609071135520935\n",
      "Eval Loss:  0.27075859904289246\n",
      "Eval Loss:  0.24427488446235657\n",
      "Eval Loss:  0.1766270101070404\n",
      "Eval Loss:  0.19361349940299988\n",
      "Eval Loss:  0.22878246009349823\n",
      "Eval Loss:  0.2276182919740677\n",
      "Eval Loss:  0.17567108571529388\n",
      "Eval Loss:  0.2602580487728119\n",
      "Eval Loss:  0.2639598548412323\n",
      "Eval Loss:  0.2861647605895996\n",
      "Eval Loss:  0.2952125072479248\n",
      "Eval Loss:  0.17135299742221832\n",
      "Eval Loss:  0.1595958024263382\n",
      "Eval Loss:  0.2030920684337616\n",
      "[[16661  1430]\n",
      " [ 1120 10606]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     18091\n",
      "           1       0.88      0.90      0.89     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.92      0.91      0.91     29817\n",
      "\n",
      "acc:  0.914478317738203\n",
      "pre:  0.8811897640412097\n",
      "rec:  0.9044857581442948\n",
      "ma F1:  0.9107998585024057\n",
      "mi F1:  0.914478317738203\n",
      "we F1:  0.9146666451309522\n",
      "29817 466\n",
      "Loss:  0.05758145824074745\n",
      "Loss:  0.03622536361217499\n",
      "Loss:  0.07202570140361786\n",
      "36 **********\n",
      "Epoch:  2490.5707190036774  fold:  8  kers:  128\n",
      "epoch:  37\n",
      "29817 466\n",
      "Loss:  0.046515531837940216\n",
      "Loss:  0.04561644047498703\n",
      "Loss:  0.07954934239387512\n",
      "37 **********\n",
      "Epoch:  2544.105577468872  fold:  8  kers:  128\n",
      "epoch:  38\n",
      "29817 466\n",
      "Loss:  0.08000054955482483\n",
      "Loss:  0.06293404847383499\n",
      "Loss:  0.037356358021497726\n",
      "38 **********\n",
      "Epoch:  2597.606526851654  fold:  8  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.846197247505188\n",
      "Eval Loss:  1.0502867698669434\n",
      "Eval Loss:  0.09921565651893616\n",
      "[[1707  366]\n",
      " [ 189  812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86      2073\n",
      "           1       0.69      0.81      0.75      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.79      0.82      0.80      3074\n",
      "weighted avg       0.83      0.82      0.82      3074\n",
      "\n",
      "acc:  0.8194534808067664\n",
      "pre:  0.6893039049235993\n",
      "rec:  0.8111888111888111\n",
      "ma F1:  0.8027311480402676\n",
      "mi F1:  0.8194534808067664\n",
      "we F1:  0.8227605790186886\n",
      "Eval Loss:  0.2423422634601593\n",
      "Eval Loss:  0.19216880202293396\n",
      "Eval Loss:  0.12549880146980286\n",
      "Eval Loss:  0.17571868002414703\n",
      "Eval Loss:  0.15077093243598938\n",
      "Eval Loss:  0.17502591013908386\n",
      "Eval Loss:  0.2780822515487671\n",
      "Eval Loss:  0.2454010248184204\n",
      "Eval Loss:  0.23734122514724731\n",
      "Eval Loss:  0.11206244677305222\n",
      "Eval Loss:  0.12895262241363525\n",
      "Eval Loss:  0.1716620922088623\n",
      "Eval Loss:  0.1711876094341278\n",
      "Eval Loss:  0.22314316034317017\n",
      "Eval Loss:  0.2264719307422638\n",
      "Eval Loss:  0.2747926115989685\n",
      "Eval Loss:  0.22787436842918396\n",
      "Eval Loss:  0.1713518500328064\n",
      "Eval Loss:  0.15614581108093262\n",
      "Eval Loss:  0.2210664302110672\n",
      "Eval Loss:  0.2255992889404297\n",
      "Eval Loss:  0.19082458317279816\n",
      "Eval Loss:  0.2246549278497696\n",
      "Eval Loss:  0.25811967253685\n",
      "Eval Loss:  0.30236852169036865\n",
      "Eval Loss:  0.2994109094142914\n",
      "Eval Loss:  0.1460319459438324\n",
      "Eval Loss:  0.14455607533454895\n",
      "Eval Loss:  0.19516733288764954\n",
      "[[16639  1452]\n",
      " [  929 10797]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93     18091\n",
      "           1       0.88      0.92      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.91      0.92      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9201462253077104\n",
      "pre:  0.8814597109968161\n",
      "rec:  0.9207743476036159\n",
      "ma F1:  0.9169584274120572\n",
      "mi F1:  0.9201462253077104\n",
      "we F1:  0.9204316101586906\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05121386796236038\n",
      "Loss:  0.05594203248620033\n",
      "Loss:  0.03832175210118294\n",
      "39 **********\n",
      "Epoch:  2691.762772321701  fold:  8  kers:  128\n",
      "epoch:  40\n",
      "29817 466\n",
      "Loss:  0.07566969096660614\n",
      "Loss:  0.06537731736898422\n",
      "Loss:  0.047097884118556976\n",
      "40 **********\n",
      "Epoch:  2745.2886548042297  fold:  8  kers:  128\n",
      "epoch:  41\n",
      "29817 466\n",
      "Loss:  0.04989781975746155\n",
      "Loss:  0.03521367907524109\n",
      "Loss:  0.06350623071193695\n",
      "41 **********\n",
      "Epoch:  2798.9910657405853  fold:  8  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.590155839920044\n",
      "Eval Loss:  1.1343982219696045\n",
      "Eval Loss:  0.08214446902275085\n",
      "[[1896  177]\n",
      " [ 295  706]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      2073\n",
      "           1       0.80      0.71      0.75      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.83      0.81      0.82      3074\n",
      "weighted avg       0.84      0.85      0.84      3074\n",
      "\n",
      "acc:  0.8464541314248536\n",
      "pre:  0.7995469988674971\n",
      "rec:  0.7052947052947053\n",
      "ma F1:  0.819387515286226\n",
      "mi F1:  0.8464541314248536\n",
      "we F1:  0.8437702148665697\n",
      "Eval Loss:  0.23909057676792145\n",
      "Eval Loss:  0.21025481820106506\n",
      "Eval Loss:  0.12482812255620956\n",
      "Eval Loss:  0.1699492633342743\n",
      "Eval Loss:  0.15495862066745758\n",
      "Eval Loss:  0.15936553478240967\n",
      "Eval Loss:  0.2982653081417084\n",
      "Eval Loss:  0.22520676255226135\n",
      "Eval Loss:  0.21951618790626526\n",
      "Eval Loss:  0.1204332634806633\n",
      "Eval Loss:  0.12712576985359192\n",
      "Eval Loss:  0.151191845536232\n",
      "Eval Loss:  0.1541547328233719\n",
      "Eval Loss:  0.20019644498825073\n",
      "Eval Loss:  0.22412459552288055\n",
      "Eval Loss:  0.2528599500656128\n",
      "Eval Loss:  0.2217802107334137\n",
      "Eval Loss:  0.1524803638458252\n",
      "Eval Loss:  0.1769203096628189\n",
      "Eval Loss:  0.20739059150218964\n",
      "Eval Loss:  0.20053979754447937\n",
      "Eval Loss:  0.13480189442634583\n",
      "Eval Loss:  0.22335298359394073\n",
      "Eval Loss:  0.2654038965702057\n",
      "Eval Loss:  0.2673473656177521\n",
      "Eval Loss:  0.3180895745754242\n",
      "Eval Loss:  0.14509908854961395\n",
      "Eval Loss:  0.16993312537670135\n",
      "Eval Loss:  0.2052859514951706\n",
      "[[17275   816]\n",
      " [ 1363 10363]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18091\n",
      "           1       0.93      0.88      0.90     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.92      0.92     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9269208840594292\n",
      "pre:  0.9270059933804454\n",
      "rec:  0.8837625788845301\n",
      "ma F1:  0.922770757474394\n",
      "mi F1:  0.9269208840594292\n",
      "we F1:  0.9265924524561285\n",
      "29817 466\n",
      "Loss:  0.02413249760866165\n",
      "Loss:  0.048712000250816345\n",
      "Loss:  0.03993121162056923\n",
      "42 **********\n",
      "Epoch:  2893.1682546138763  fold:  8  kers:  128\n",
      "epoch:  43\n",
      "29817 466\n",
      "Loss:  0.05408592149615288\n",
      "Loss:  0.03497356176376343\n",
      "Loss:  0.0363057404756546\n",
      "43 **********\n",
      "Epoch:  2946.6183404922485  fold:  8  kers:  128\n",
      "epoch:  44\n",
      "29817 466\n",
      "Loss:  0.028869500383734703\n",
      "Loss:  0.050770483911037445\n",
      "Loss:  0.03519801050424576\n",
      "44 **********\n",
      "Epoch:  3000.0943562984467  fold:  8  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.3856296241283417\n",
      "Eval Loss:  0.9488692283630371\n",
      "Eval Loss:  0.09608425945043564\n",
      "[[1904  169]\n",
      " [ 343  658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      2073\n",
      "           1       0.80      0.66      0.72      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.82      0.79      0.80      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8334417696811971\n",
      "pre:  0.7956469165659008\n",
      "rec:  0.6573426573426573\n",
      "ma F1:  0.800696977064592\n",
      "mi F1:  0.8334417696811971\n",
      "we F1:  0.8288690618840145\n",
      "Eval Loss:  0.24574723839759827\n",
      "Eval Loss:  0.22940388321876526\n",
      "Eval Loss:  0.13384045660495758\n",
      "Eval Loss:  0.16514024138450623\n",
      "Eval Loss:  0.16536466777324677\n",
      "Eval Loss:  0.1586989164352417\n",
      "Eval Loss:  0.27577337622642517\n",
      "Eval Loss:  0.22644735872745514\n",
      "Eval Loss:  0.21603231132030487\n",
      "Eval Loss:  0.10047520697116852\n",
      "Eval Loss:  0.12614434957504272\n",
      "Eval Loss:  0.16441260278224945\n",
      "Eval Loss:  0.14456354081630707\n",
      "Eval Loss:  0.17594052851200104\n",
      "Eval Loss:  0.21999627351760864\n",
      "Eval Loss:  0.2288862019777298\n",
      "Eval Loss:  0.20850194990634918\n",
      "Eval Loss:  0.14276841282844543\n",
      "Eval Loss:  0.16121333837509155\n",
      "Eval Loss:  0.20612099766731262\n",
      "Eval Loss:  0.20279820263385773\n",
      "Eval Loss:  0.15084059536457062\n",
      "Eval Loss:  0.22905457019805908\n",
      "Eval Loss:  0.26757606863975525\n",
      "Eval Loss:  0.23627668619155884\n",
      "Eval Loss:  0.2785644233226776\n",
      "Eval Loss:  0.1190718412399292\n",
      "Eval Loss:  0.16420546174049377\n",
      "Eval Loss:  0.18031316995620728\n",
      "[[17184   907]\n",
      " [ 1236 10490]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18091\n",
      "           1       0.92      0.89      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.92      0.92     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9281282489854781\n",
      "pre:  0.9204176537685356\n",
      "rec:  0.8945932116663824\n",
      "ma F1:  0.9243135371694557\n",
      "mi F1:  0.9281282489854781\n",
      "we F1:  0.9279407616554106\n",
      "29817 466\n",
      "Loss:  0.04344189912080765\n",
      "Loss:  0.050650183111429214\n",
      "Loss:  0.05328059196472168\n",
      "45 **********\n",
      "Epoch:  3094.2087137699127  fold:  8  kers:  128\n",
      "epoch:  46\n",
      "29817 466\n",
      "Loss:  0.04149985313415527\n",
      "Loss:  0.07181423902511597\n",
      "Loss:  0.03902104124426842\n",
      "46 **********\n",
      "Epoch:  3147.6957001686096  fold:  8  kers:  128\n",
      "epoch:  47\n",
      "29817 466\n",
      "Loss:  0.04838148504495621\n",
      "Loss:  0.028273064643144608\n",
      "Loss:  0.052272550761699677\n",
      "47 **********\n",
      "Epoch:  3201.2215831279755  fold:  8  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.7591763734817505\n",
      "Eval Loss:  1.0450481176376343\n",
      "Eval Loss:  0.08574991673231125\n",
      "[[1842  231]\n",
      " [ 237  764]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      2073\n",
      "           1       0.77      0.76      0.77      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.83      0.83      0.83      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8477553675992192\n",
      "pre:  0.7678391959798995\n",
      "rec:  0.7632367632367633\n",
      "ma F1:  0.8264071495592341\n",
      "mi F1:  0.8477553675992191\n",
      "we F1:  0.8476365463485329\n",
      "Eval Loss:  0.24644236266613007\n",
      "Eval Loss:  0.18873128294944763\n",
      "Eval Loss:  0.12188167124986649\n",
      "Eval Loss:  0.14767813682556152\n",
      "Eval Loss:  0.13020212948322296\n",
      "Eval Loss:  0.15516327321529388\n",
      "Eval Loss:  0.28021058440208435\n",
      "Eval Loss:  0.2576405704021454\n",
      "Eval Loss:  0.21693556010723114\n",
      "Eval Loss:  0.07837339490652084\n",
      "Eval Loss:  0.11460359394550323\n",
      "Eval Loss:  0.1697314828634262\n",
      "Eval Loss:  0.1629488319158554\n",
      "Eval Loss:  0.18602116405963898\n",
      "Eval Loss:  0.20455099642276764\n",
      "Eval Loss:  0.2601563036441803\n",
      "Eval Loss:  0.21217016875743866\n",
      "Eval Loss:  0.14082036912441254\n",
      "Eval Loss:  0.13905610144138336\n",
      "Eval Loss:  0.20662780106067657\n",
      "Eval Loss:  0.21330346167087555\n",
      "Eval Loss:  0.15429235994815826\n",
      "Eval Loss:  0.2278197556734085\n",
      "Eval Loss:  0.2772374749183655\n",
      "Eval Loss:  0.27447640895843506\n",
      "Eval Loss:  0.31145668029785156\n",
      "Eval Loss:  0.13347336649894714\n",
      "Eval Loss:  0.14374837279319763\n",
      "Eval Loss:  0.17116175591945648\n",
      "[[17015  1076]\n",
      " [ 1073 10653]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18091\n",
      "           1       0.91      0.91      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.92      0.92      0.92     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9279270214978033\n",
      "pre:  0.9082615738767158\n",
      "rec:  0.9084939450793109\n",
      "ma F1:  0.9244893228462808\n",
      "mi F1:  0.9279270214978033\n",
      "we F1:  0.9279286425440081\n",
      "29817 466\n",
      "Loss:  0.061790090054273605\n",
      "Loss:  0.08051571995019913\n",
      "Loss:  0.022041644901037216\n",
      "48 **********\n",
      "Epoch:  3295.2950496673584  fold:  8  kers:  128\n",
      "epoch:  49\n",
      "29817 466\n",
      "Loss:  0.04067562520503998\n",
      "Loss:  0.056262873113155365\n",
      "Loss:  0.04572252556681633\n",
      "49 **********\n",
      "Epoch:  3348.778046607971  fold:  8  kers:  128\n",
      "epoch:  50\n",
      "29817 466\n",
      "Loss:  0.02286645583808422\n",
      "Loss:  0.038654625415802\n",
      "Loss:  0.08454324305057526\n",
      "50 **********\n",
      "Epoch:  3402.372745513916  fold:  8  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.29340022802352905\n",
      "Eval Loss:  1.2304517030715942\n",
      "Eval Loss:  0.08004087209701538\n",
      "[[1912  161]\n",
      " [ 286  715]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90      2073\n",
      "           1       0.82      0.71      0.76      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.82      0.83      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8545868575146389\n",
      "pre:  0.8162100456621004\n",
      "rec:  0.7142857142857143\n",
      "ma F1:  0.8285973460042684\n",
      "mi F1:  0.8545868575146389\n",
      "we F1:  0.8518728316676913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2237449437379837\n",
      "Eval Loss:  0.19006337225437164\n",
      "Eval Loss:  0.14140568673610687\n",
      "Eval Loss:  0.1374512016773224\n",
      "Eval Loss:  0.18257901072502136\n",
      "Eval Loss:  0.1514497995376587\n",
      "Eval Loss:  0.28508901596069336\n",
      "Eval Loss:  0.23424865305423737\n",
      "Eval Loss:  0.21108898520469666\n",
      "Eval Loss:  0.09325845539569855\n",
      "Eval Loss:  0.12148168683052063\n",
      "Eval Loss:  0.17915403842926025\n",
      "Eval Loss:  0.17460785806179047\n",
      "Eval Loss:  0.1756783276796341\n",
      "Eval Loss:  0.21874207258224487\n",
      "Eval Loss:  0.26432469487190247\n",
      "Eval Loss:  0.2243032455444336\n",
      "Eval Loss:  0.16376729309558868\n",
      "Eval Loss:  0.17296265065670013\n",
      "Eval Loss:  0.2122957706451416\n",
      "Eval Loss:  0.21445339918136597\n",
      "Eval Loss:  0.16031157970428467\n",
      "Eval Loss:  0.23493194580078125\n",
      "Eval Loss:  0.281314879655838\n",
      "Eval Loss:  0.2643403112888336\n",
      "Eval Loss:  0.29632270336151123\n",
      "Eval Loss:  0.13988438248634338\n",
      "Eval Loss:  0.1431092768907547\n",
      "Eval Loss:  0.18771934509277344\n",
      "[[16960  1131]\n",
      " [ 1135 10591]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18091\n",
      "           1       0.90      0.90      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.92      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9240030854881444\n",
      "pre:  0.9035147585736223\n",
      "rec:  0.9032065495480129\n",
      "ma F1:  0.9203698623301954\n",
      "mi F1:  0.9240030854881444\n",
      "we F1:  0.9240008036711195\n",
      "29817 466\n",
      "Loss:  0.0697314664721489\n",
      "Loss:  0.09530456364154816\n",
      "Loss:  0.04894676432013512\n",
      "51 **********\n",
      "Epoch:  3496.482115983963  fold:  8  kers:  128\n",
      "epoch:  52\n",
      "29817 466\n",
      "Loss:  0.023489607498049736\n",
      "Loss:  0.04216806963086128\n",
      "Loss:  0.05395180732011795\n",
      "52 **********\n",
      "Epoch:  3549.943171977997  fold:  8  kers:  128\n",
      "epoch:  53\n",
      "29817 466\n",
      "Loss:  0.029839057475328445\n",
      "Loss:  0.04595232009887695\n",
      "Loss:  0.03263344243168831\n",
      "53 **********\n",
      "Epoch:  3603.4311561584473  fold:  8  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.5053841471672058\n",
      "Eval Loss:  1.0230094194412231\n",
      "Eval Loss:  0.09541849046945572\n",
      "[[1714  359]\n",
      " [ 189  812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86      2073\n",
      "           1       0.69      0.81      0.75      1001\n",
      "\n",
      "    accuracy                           0.82      3074\n",
      "   macro avg       0.80      0.82      0.80      3074\n",
      "weighted avg       0.83      0.82      0.82      3074\n",
      "\n",
      "acc:  0.8217306441119063\n",
      "pre:  0.6934244235695987\n",
      "rec:  0.8111888111888111\n",
      "ma F1:  0.8049355062233438\n",
      "mi F1:  0.8217306441119063\n",
      "we F1:  0.824896024866957\n",
      "Eval Loss:  0.21810007095336914\n",
      "Eval Loss:  0.186305433511734\n",
      "Eval Loss:  0.10454631596803665\n",
      "Eval Loss:  0.17292232811450958\n",
      "Eval Loss:  0.13625387847423553\n",
      "Eval Loss:  0.16006708145141602\n",
      "Eval Loss:  0.242721289396286\n",
      "Eval Loss:  0.20203766226768494\n",
      "Eval Loss:  0.2050730288028717\n",
      "Eval Loss:  0.10191026329994202\n",
      "Eval Loss:  0.10186970233917236\n",
      "Eval Loss:  0.17762701213359833\n",
      "Eval Loss:  0.15886269509792328\n",
      "Eval Loss:  0.183090478181839\n",
      "Eval Loss:  0.2149474173784256\n",
      "Eval Loss:  0.24544689059257507\n",
      "Eval Loss:  0.2317204773426056\n",
      "Eval Loss:  0.16548646986484528\n",
      "Eval Loss:  0.1362920105457306\n",
      "Eval Loss:  0.2050747275352478\n",
      "Eval Loss:  0.2271510809659958\n",
      "Eval Loss:  0.17189066112041473\n",
      "Eval Loss:  0.20818625390529633\n",
      "Eval Loss:  0.24728575348854065\n",
      "Eval Loss:  0.25308340787887573\n",
      "Eval Loss:  0.2712119221687317\n",
      "Eval Loss:  0.12842068076133728\n",
      "Eval Loss:  0.16279780864715576\n",
      "Eval Loss:  0.20395372807979584\n",
      "[[16781  1310]\n",
      " [  756 10970]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94     18091\n",
      "           1       0.89      0.94      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.93      0.93     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9307106684106382\n",
      "pre:  0.8933224755700325\n",
      "rec:  0.935527886747399\n",
      "ma F1:  0.9279750414366768\n",
      "mi F1:  0.9307106684106382\n",
      "we F1:  0.9309714733226283\n",
      "29817 466\n",
      "Loss:  0.04812672734260559\n",
      "Loss:  0.05730806291103363\n",
      "Loss:  0.04151606559753418\n",
      "54 **********\n",
      "Epoch:  3697.5664575099945  fold:  8  kers:  128\n",
      "epoch:  55\n",
      "29817 466\n",
      "Loss:  0.03463686257600784\n",
      "Loss:  0.03086407110095024\n",
      "Loss:  0.03999144583940506\n",
      "55 **********\n",
      "Epoch:  3751.0883507728577  fold:  8  kers:  128\n",
      "epoch:  56\n",
      "29817 466\n",
      "Loss:  0.060741085559129715\n",
      "Loss:  0.06680983304977417\n",
      "Loss:  0.05793276056647301\n",
      "56 **********\n",
      "Epoch:  3804.5723462104797  fold:  8  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.4552800953388214\n",
      "Eval Loss:  1.140270709991455\n",
      "Eval Loss:  0.09331373125314713\n",
      "[[1777  296]\n",
      " [ 226  775]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87      2073\n",
      "           1       0.72      0.77      0.75      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.81      0.82      0.81      3074\n",
      "weighted avg       0.83      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8301886792452831\n",
      "pre:  0.7236227824463118\n",
      "rec:  0.7742257742257742\n",
      "ma F1:  0.8100013829896067\n",
      "mi F1:  0.8301886792452831\n",
      "we F1:  0.8315989694028652\n",
      "Eval Loss:  0.21041913330554962\n",
      "Eval Loss:  0.1748461127281189\n",
      "Eval Loss:  0.10428793728351593\n",
      "Eval Loss:  0.1570706069469452\n",
      "Eval Loss:  0.1345343291759491\n",
      "Eval Loss:  0.15780173242092133\n",
      "Eval Loss:  0.24828901886940002\n",
      "Eval Loss:  0.21117089688777924\n",
      "Eval Loss:  0.20192381739616394\n",
      "Eval Loss:  0.07828844338655472\n",
      "Eval Loss:  0.10240141302347183\n",
      "Eval Loss:  0.15813051164150238\n",
      "Eval Loss:  0.14878901839256287\n",
      "Eval Loss:  0.18176154792308807\n",
      "Eval Loss:  0.20782694220542908\n",
      "Eval Loss:  0.24859555065631866\n",
      "Eval Loss:  0.19254375994205475\n",
      "Eval Loss:  0.16273675858974457\n",
      "Eval Loss:  0.13865430653095245\n",
      "Eval Loss:  0.2067026048898697\n",
      "Eval Loss:  0.2046421766281128\n",
      "Eval Loss:  0.14793460071086884\n",
      "Eval Loss:  0.22988367080688477\n",
      "Eval Loss:  0.22820629179477692\n",
      "Eval Loss:  0.232424795627594\n",
      "Eval Loss:  0.2687259912490845\n",
      "Eval Loss:  0.12684130668640137\n",
      "Eval Loss:  0.1470215916633606\n",
      "Eval Loss:  0.16080603003501892\n",
      "[[16886  1205]\n",
      " [  831 10895]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18091\n",
      "           1       0.90      0.93      0.91     11726\n",
      "\n",
      "    accuracy                           0.93     29817\n",
      "   macro avg       0.93      0.93      0.93     29817\n",
      "weighted avg       0.93      0.93      0.93     29817\n",
      "\n",
      "acc:  0.9317168058490123\n",
      "pre:  0.9004132231404959\n",
      "rec:  0.9291318437659901\n",
      "ma F1:  0.9288441654407322\n",
      "mi F1:  0.9317168058490123\n",
      "we F1:  0.9318961360964996\n",
      "29817 466\n",
      "Loss:  0.049881622195243835\n",
      "Loss:  0.04763659089803696\n",
      "Loss:  0.04061520844697952\n",
      "57 **********\n",
      "Epoch:  3898.6966757774353  fold:  8  kers:  128\n",
      "epoch:  58\n",
      "29817 466\n",
      "Loss:  0.046945687383413315\n",
      "Loss:  0.031140204519033432\n",
      "Loss:  0.05368608608841896\n",
      "58 **********\n",
      "Epoch:  3952.153742790222  fold:  8  kers:  128\n",
      "epoch:  59\n",
      "29817 466\n",
      "Loss:  0.041118863970041275\n",
      "Loss:  0.03921765834093094\n",
      "Loss:  0.0350714735686779\n",
      "59 **********\n",
      "Epoch:  4005.6995718479156  fold:  8  kers:  128\n",
      "Eval Loss:  0.515833854675293\n",
      "Eval Loss:  1.023481011390686\n",
      "Eval Loss:  0.11183290183544159\n",
      "[[1725  348]\n",
      " [ 182  819]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87      2073\n",
      "           1       0.70      0.82      0.76      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.80      0.83      0.81      3074\n",
      "weighted avg       0.84      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8275862068965517\n",
      "pre:  0.7017994858611826\n",
      "rec:  0.8181818181818182\n",
      "ma F1:  0.8111846131024124\n",
      "mi F1:  0.8275862068965517\n",
      "we F1:  0.8305913554283696\n",
      "update!  Acc:  0.8575146389069617\n",
      "Epoch:  4009.4964208602905  fold:  8  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29483 3408\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29483 461\n",
      "Loss:  0.16908271610736847\n",
      "Loss:  0.16566535830497742\n",
      "Loss:  0.160798579454422\n",
      "0 **********\n",
      "Epoch:  65.40212726593018  fold:  9  kers:  128\n",
      "epoch:  1\n",
      "29483 461\n",
      "Loss:  0.1492086946964264\n",
      "Loss:  0.14039811491966248\n",
      "Loss:  0.11628784984350204\n",
      "1 **********\n",
      "Epoch:  118.524090051651  fold:  9  kers:  128\n",
      "epoch:  2\n",
      "29483 461\n",
      "Loss:  0.11676986515522003\n",
      "Loss:  0.09178820252418518\n",
      "Loss:  0.08996215462684631\n",
      "2 **********\n",
      "Epoch:  171.54033589363098  fold:  9  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.16407990455627441\n",
      "Eval Loss:  1.3854403495788574\n",
      "Eval Loss:  0.39195674657821655\n",
      "[[1626  116]\n",
      " [ 581 1085]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82      1742\n",
      "           1       0.90      0.65      0.76      1666\n",
      "\n",
      "    accuracy                           0.80      3408\n",
      "   macro avg       0.82      0.79      0.79      3408\n",
      "weighted avg       0.82      0.80      0.79      3408\n",
      "\n",
      "acc:  0.795481220657277\n",
      "pre:  0.9034138218151541\n",
      "rec:  0.6512605042016807\n",
      "ma F1:  0.7901941770125783\n",
      "mi F1:  0.795481220657277\n",
      "we F1:  0.7909369040310573\n",
      "update!  Acc:  0.795481220657277\n",
      "Eval Loss:  0.3812161684036255\n",
      "Eval Loss:  0.40615102648735046\n",
      "Eval Loss:  0.436897337436676\n",
      "Eval Loss:  0.44512903690338135\n",
      "Eval Loss:  0.4848647117614746\n",
      "Eval Loss:  0.5288734436035156\n",
      "Eval Loss:  0.522197961807251\n",
      "Eval Loss:  0.49548593163490295\n",
      "Eval Loss:  0.4097253382205963\n",
      "Eval Loss:  0.41664695739746094\n",
      "Eval Loss:  0.5395943522453308\n",
      "Eval Loss:  0.4144563376903534\n",
      "Eval Loss:  0.4433247148990631\n",
      "Eval Loss:  0.4846331477165222\n",
      "Eval Loss:  0.45069265365600586\n",
      "Eval Loss:  0.4210207760334015\n",
      "Eval Loss:  0.43328866362571716\n",
      "Eval Loss:  0.3884650468826294\n",
      "Eval Loss:  0.4185514748096466\n",
      "Eval Loss:  0.4674239456653595\n",
      "Eval Loss:  0.4667015075683594\n",
      "Eval Loss:  0.3608470857143402\n",
      "Eval Loss:  0.3484182059764862\n",
      "Eval Loss:  0.5187622904777527\n",
      "Eval Loss:  0.4330137372016907\n",
      "Eval Loss:  0.42991581559181213\n",
      "Eval Loss:  0.41387224197387695\n",
      "Eval Loss:  0.38265368342399597\n",
      "[[17183  1239]\n",
      " [ 4402  6659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86     18422\n",
      "           1       0.84      0.60      0.70     11061\n",
      "\n",
      "    accuracy                           0.81     29483\n",
      "   macro avg       0.82      0.77      0.78     29483\n",
      "weighted avg       0.81      0.81      0.80     29483\n",
      "\n",
      "acc:  0.8086694027066446\n",
      "pre:  0.843124841732084\n",
      "rec:  0.6020251333514148\n",
      "ma F1:  0.7807314425708924\n",
      "mi F1:  0.8086694027066446\n",
      "we F1:  0.8002726174624992\n",
      "29483 461\n",
      "Loss:  0.14289239048957825\n",
      "Loss:  0.12164654582738876\n",
      "Loss:  0.11368976533412933\n",
      "3 **********\n",
      "Epoch:  264.99246311187744  fold:  9  kers:  128\n",
      "epoch:  4\n",
      "29483 461\n",
      "Loss:  0.07776893675327301\n",
      "Loss:  0.09370832145214081\n",
      "Loss:  0.07752377539873123\n",
      "4 **********\n",
      "Epoch:  317.9977397918701  fold:  9  kers:  128\n",
      "epoch:  5\n",
      "29483 461\n",
      "Loss:  0.10272395610809326\n",
      "Loss:  0.10555342584848404\n",
      "Loss:  0.09021197259426117\n",
      "5 **********\n",
      "Epoch:  370.84344005584717  fold:  9  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.06389064341783524\n",
      "Eval Loss:  2.146803617477417\n",
      "Eval Loss:  0.411080002784729\n",
      "[[1683   59]\n",
      " [ 784  882]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80      1742\n",
      "           1       0.94      0.53      0.68      1666\n",
      "\n",
      "    accuracy                           0.75      3408\n",
      "   macro avg       0.81      0.75      0.74      3408\n",
      "weighted avg       0.81      0.75      0.74      3408\n",
      "\n",
      "acc:  0.7526408450704225\n",
      "pre:  0.9373007438894793\n",
      "rec:  0.5294117647058824\n",
      "ma F1:  0.738177356265179\n",
      "mi F1:  0.7526408450704225\n",
      "we F1:  0.7395496723066253\n",
      "Eval Loss:  0.4443415105342865\n",
      "Eval Loss:  0.38275742530822754\n",
      "Eval Loss:  0.4382166266441345\n",
      "Eval Loss:  0.44900256395339966\n",
      "Eval Loss:  0.5289121270179749\n",
      "Eval Loss:  0.524107038974762\n",
      "Eval Loss:  0.5238804221153259\n",
      "Eval Loss:  0.49809980392456055\n",
      "Eval Loss:  0.4437941312789917\n",
      "Eval Loss:  0.44638222455978394\n",
      "Eval Loss:  0.5580625534057617\n",
      "Eval Loss:  0.4139089584350586\n",
      "Eval Loss:  0.45391374826431274\n",
      "Eval Loss:  0.49233800172805786\n",
      "Eval Loss:  0.5207769274711609\n",
      "Eval Loss:  0.44165679812431335\n",
      "Eval Loss:  0.4118501543998718\n",
      "Eval Loss:  0.3891901969909668\n",
      "Eval Loss:  0.4385296106338501\n",
      "Eval Loss:  0.49690869450569153\n",
      "Eval Loss:  0.45679599046707153\n",
      "Eval Loss:  0.37019747495651245\n",
      "Eval Loss:  0.407173752784729\n",
      "Eval Loss:  0.5470108389854431\n",
      "Eval Loss:  0.43972840905189514\n",
      "Eval Loss:  0.3804340064525604\n",
      "Eval Loss:  0.42975786328315735\n",
      "Eval Loss:  0.3491241931915283\n",
      "[[18036   386]\n",
      " [ 5139  5922]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87     18422\n",
      "           1       0.94      0.54      0.68     11061\n",
      "\n",
      "    accuracy                           0.81     29483\n",
      "   macro avg       0.86      0.76      0.77     29483\n",
      "weighted avg       0.84      0.81      0.80     29483\n",
      "\n",
      "acc:  0.8126038734185802\n",
      "pre:  0.9388078630310717\n",
      "rec:  0.5353946297803092\n",
      "ma F1:  0.774541232030288\n",
      "mi F1:  0.8126038734185802\n",
      "we F1:  0.7976697695289854\n",
      "29483 461\n",
      "Loss:  0.05953323468565941\n",
      "Loss:  0.0785389319062233\n",
      "Loss:  0.069571353495121\n",
      "6 **********\n",
      "Epoch:  464.20281529426575  fold:  9  kers:  128\n",
      "epoch:  7\n",
      "29483 461\n",
      "Loss:  0.09349985420703888\n",
      "Loss:  0.08958379179239273\n",
      "Loss:  0.08102122694253922\n",
      "7 **********\n",
      "Epoch:  517.0634768009186  fold:  9  kers:  128\n",
      "epoch:  8\n",
      "29483 461\n",
      "Loss:  0.06266654282808304\n",
      "Loss:  0.041143909096717834\n",
      "Loss:  0.06320606172084808\n",
      "8 **********\n",
      "Epoch:  569.9750020503998  fold:  9  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.08805429190397263\n",
      "Eval Loss:  1.29285728931427\n",
      "Eval Loss:  0.257350355386734\n",
      "[[1630  112]\n",
      " [ 511 1155]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      1742\n",
      "           1       0.91      0.69      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.84      0.81      0.81      3408\n",
      "weighted avg       0.83      0.82      0.81      3408\n",
      "\n",
      "acc:  0.8171948356807511\n",
      "pre:  0.9116022099447514\n",
      "rec:  0.6932773109243697\n",
      "ma F1:  0.8135732711648659\n",
      "mi F1:  0.8171948356807511\n",
      "we F1:  0.8141527214874074\n",
      "update!  Acc:  0.8171948356807511\n",
      "Eval Loss:  0.2862173020839691\n",
      "Eval Loss:  0.29819968342781067\n",
      "Eval Loss:  0.3090548515319824\n",
      "Eval Loss:  0.2867394685745239\n",
      "Eval Loss:  0.3080671429634094\n",
      "Eval Loss:  0.2724863290786743\n",
      "Eval Loss:  0.36566612124443054\n",
      "Eval Loss:  0.33255481719970703\n",
      "Eval Loss:  0.23455876111984253\n",
      "Eval Loss:  0.31214603781700134\n",
      "Eval Loss:  0.3425925374031067\n",
      "Eval Loss:  0.2875838279724121\n",
      "Eval Loss:  0.30981937050819397\n",
      "Eval Loss:  0.3543119430541992\n",
      "Eval Loss:  0.29390063881874084\n",
      "Eval Loss:  0.27185651659965515\n",
      "Eval Loss:  0.2742372453212738\n",
      "Eval Loss:  0.2564498484134674\n",
      "Eval Loss:  0.2914978265762329\n",
      "Eval Loss:  0.34134531021118164\n",
      "Eval Loss:  0.2775671184062958\n",
      "Eval Loss:  0.2758825719356537\n",
      "Eval Loss:  0.24308505654335022\n",
      "Eval Loss:  0.32461702823638916\n",
      "Eval Loss:  0.27371299266815186\n",
      "Eval Loss:  0.3079394996166229\n",
      "Eval Loss:  0.27928853034973145\n",
      "Eval Loss:  0.265635222196579\n",
      "[[17242  1180]\n",
      " [ 2459  8602]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.90     18422\n",
      "           1       0.88      0.78      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.88      0.86      0.86     29483\n",
      "weighted avg       0.88      0.88      0.87     29483\n",
      "\n",
      "acc:  0.8765729403385002\n",
      "pre:  0.8793702719280311\n",
      "rec:  0.7776873700388753\n",
      "ma F1:  0.8649774112292945\n",
      "mi F1:  0.8765729403385002\n",
      "we F1:  0.8748564262493017\n",
      "29483 461\n",
      "Loss:  0.06039806455373764\n",
      "Loss:  0.07419252395629883\n",
      "Loss:  0.09754628688097\n",
      "9 **********\n",
      "Epoch:  663.4281268119812  fold:  9  kers:  128\n",
      "epoch:  10\n",
      "29483 461\n",
      "Loss:  0.11390606313943863\n",
      "Loss:  0.0732237920165062\n",
      "Loss:  0.07227031141519547\n",
      "10 **********\n",
      "Epoch:  716.2788150310516  fold:  9  kers:  128\n",
      "epoch:  11\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08707727491855621\n",
      "Loss:  0.06280108541250229\n",
      "Loss:  0.06969244033098221\n",
      "11 **********\n",
      "Epoch:  769.11155128479  fold:  9  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.04311279207468033\n",
      "Eval Loss:  2.101079225540161\n",
      "Eval Loss:  0.2798062562942505\n",
      "[[1693   49]\n",
      " [ 679  987]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82      1742\n",
      "           1       0.95      0.59      0.73      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.83      0.78      0.78      3408\n",
      "weighted avg       0.83      0.79      0.78      3408\n",
      "\n",
      "acc:  0.7863849765258216\n",
      "pre:  0.9527027027027027\n",
      "rec:  0.592436974789916\n",
      "ma F1:  0.7768066075400313\n",
      "mi F1:  0.7863849765258216\n",
      "we F1:  0.7778377067509663\n",
      "Eval Loss:  0.3012029230594635\n",
      "Eval Loss:  0.3263109028339386\n",
      "Eval Loss:  0.31761032342910767\n",
      "Eval Loss:  0.29712048172950745\n",
      "Eval Loss:  0.4052899181842804\n",
      "Eval Loss:  0.28529059886932373\n",
      "Eval Loss:  0.3998371958732605\n",
      "Eval Loss:  0.3782673180103302\n",
      "Eval Loss:  0.2724214494228363\n",
      "Eval Loss:  0.28788620233535767\n",
      "Eval Loss:  0.36086806654930115\n",
      "Eval Loss:  0.26228082180023193\n",
      "Eval Loss:  0.3114526867866516\n",
      "Eval Loss:  0.3772399425506592\n",
      "Eval Loss:  0.32227885723114014\n",
      "Eval Loss:  0.3351435363292694\n",
      "Eval Loss:  0.29651859402656555\n",
      "Eval Loss:  0.22286739945411682\n",
      "Eval Loss:  0.3110547959804535\n",
      "Eval Loss:  0.37722018361091614\n",
      "Eval Loss:  0.3066816031932831\n",
      "Eval Loss:  0.2937834560871124\n",
      "Eval Loss:  0.2601838707923889\n",
      "Eval Loss:  0.33860495686531067\n",
      "Eval Loss:  0.27172037959098816\n",
      "Eval Loss:  0.265007346868515\n",
      "Eval Loss:  0.299968421459198\n",
      "Eval Loss:  0.2586747705936432\n",
      "[[17806   616]\n",
      " [ 3159  7902]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90     18422\n",
      "           1       0.93      0.71      0.81     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.89      0.84      0.86     29483\n",
      "weighted avg       0.88      0.87      0.87     29483\n",
      "\n",
      "acc:  0.8719601126072652\n",
      "pre:  0.9276825545902794\n",
      "rec:  0.7144019528071603\n",
      "ma F1:  0.8556737860928807\n",
      "mi F1:  0.8719601126072654\n",
      "we F1:  0.8677783549006739\n",
      "29483 461\n",
      "Loss:  0.08178950846195221\n",
      "Loss:  0.06121134012937546\n",
      "Loss:  0.08447438478469849\n",
      "12 **********\n",
      "Epoch:  862.4699301719666  fold:  9  kers:  128\n",
      "epoch:  13\n",
      "29483 461\n",
      "Loss:  0.04188508912920952\n",
      "Loss:  0.07493573427200317\n",
      "Loss:  0.06016877293586731\n",
      "13 **********\n",
      "Epoch:  920.9256310462952  fold:  9  kers:  128\n",
      "epoch:  14\n",
      "29483 461\n",
      "Loss:  0.07428420335054398\n",
      "Loss:  0.07663168758153915\n",
      "Loss:  0.048985984176397324\n",
      "14 **********\n",
      "Epoch:  973.932900428772  fold:  9  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.041236765682697296\n",
      "Eval Loss:  2.0992720127105713\n",
      "Eval Loss:  0.3196220397949219\n",
      "[[1702   40]\n",
      " [ 768  898]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81      1742\n",
      "           1       0.96      0.54      0.69      1666\n",
      "\n",
      "    accuracy                           0.76      3408\n",
      "   macro avg       0.82      0.76      0.75      3408\n",
      "weighted avg       0.82      0.76      0.75      3408\n",
      "\n",
      "acc:  0.7629107981220657\n",
      "pre:  0.9573560767590619\n",
      "rec:  0.539015606242497\n",
      "ma F1:  0.7489376414107597\n",
      "mi F1:  0.7629107981220657\n",
      "we F1:  0.7502584870700374\n",
      "Eval Loss:  0.29304394125938416\n",
      "Eval Loss:  0.3170444369316101\n",
      "Eval Loss:  0.29457002878189087\n",
      "Eval Loss:  0.31008222699165344\n",
      "Eval Loss:  0.39591753482818604\n",
      "Eval Loss:  0.31235116720199585\n",
      "Eval Loss:  0.3997039794921875\n",
      "Eval Loss:  0.3659275472164154\n",
      "Eval Loss:  0.2877247631549835\n",
      "Eval Loss:  0.29261577129364014\n",
      "Eval Loss:  0.3659985065460205\n",
      "Eval Loss:  0.2697574496269226\n",
      "Eval Loss:  0.30449602007865906\n",
      "Eval Loss:  0.38081541657447815\n",
      "Eval Loss:  0.3670470714569092\n",
      "Eval Loss:  0.34383052587509155\n",
      "Eval Loss:  0.2997994124889374\n",
      "Eval Loss:  0.23487307131290436\n",
      "Eval Loss:  0.29705163836479187\n",
      "Eval Loss:  0.3731677830219269\n",
      "Eval Loss:  0.296379953622818\n",
      "Eval Loss:  0.3195940852165222\n",
      "Eval Loss:  0.27174124121665955\n",
      "Eval Loss:  0.31769058108329773\n",
      "Eval Loss:  0.2696473002433777\n",
      "Eval Loss:  0.2696589529514313\n",
      "Eval Loss:  0.29407772421836853\n",
      "Eval Loss:  0.2581561207771301\n",
      "[[17930   492]\n",
      " [ 3349  7712]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     18422\n",
      "           1       0.94      0.70      0.80     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.89      0.84      0.85     29483\n",
      "weighted avg       0.88      0.87      0.86     29483\n",
      "\n",
      "acc:  0.8697215344435777\n",
      "pre:  0.9400292540224281\n",
      "rec:  0.6972244824156948\n",
      "ma F1:  0.851937349256416\n",
      "mi F1:  0.8697215344435777\n",
      "we F1:  0.8647489941147735\n",
      "29483 461\n",
      "Loss:  0.07658830285072327\n",
      "Loss:  0.05987686291337013\n",
      "Loss:  0.06097763776779175\n",
      "15 **********\n",
      "Epoch:  1067.2324364185333  fold:  9  kers:  128\n",
      "epoch:  16\n",
      "29483 461\n",
      "Loss:  0.10126659274101257\n",
      "Loss:  0.05140962079167366\n",
      "Loss:  0.07661408185958862\n",
      "16 **********\n",
      "Epoch:  1120.1499457359314  fold:  9  kers:  128\n",
      "epoch:  17\n",
      "29483 461\n",
      "Loss:  0.05752743408083916\n",
      "Loss:  0.09280302375555038\n",
      "Loss:  0.06554847955703735\n",
      "17 **********\n",
      "Epoch:  1173.1492369174957  fold:  9  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.06050792336463928\n",
      "Eval Loss:  1.1595640182495117\n",
      "Eval Loss:  0.17145968973636627\n",
      "[[1636  106]\n",
      " [ 437 1229]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      1742\n",
      "           1       0.92      0.74      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.840669014084507\n",
      "pre:  0.9205992509363295\n",
      "rec:  0.7376950780312125\n",
      "ma F1:  0.8383637083837934\n",
      "mi F1:  0.840669014084507\n",
      "we F1:  0.8387941831583737\n",
      "update!  Acc:  0.840669014084507\n",
      "Eval Loss:  0.23948365449905396\n",
      "Eval Loss:  0.2887061834335327\n",
      "Eval Loss:  0.24166935682296753\n",
      "Eval Loss:  0.28860417008399963\n",
      "Eval Loss:  0.23342883586883545\n",
      "Eval Loss:  0.18079139292240143\n",
      "Eval Loss:  0.3452703356742859\n",
      "Eval Loss:  0.2888355255126953\n",
      "Eval Loss:  0.1736215054988861\n",
      "Eval Loss:  0.2451997995376587\n",
      "Eval Loss:  0.2678256630897522\n",
      "Eval Loss:  0.23611947894096375\n",
      "Eval Loss:  0.2835446000099182\n",
      "Eval Loss:  0.29792457818984985\n",
      "Eval Loss:  0.2586802840232849\n",
      "Eval Loss:  0.27574706077575684\n",
      "Eval Loss:  0.2781203091144562\n",
      "Eval Loss:  0.19638420641422272\n",
      "Eval Loss:  0.26234811544418335\n",
      "Eval Loss:  0.28505823016166687\n",
      "Eval Loss:  0.2122289538383484\n",
      "Eval Loss:  0.26771974563598633\n",
      "Eval Loss:  0.19302044808864594\n",
      "Eval Loss:  0.23989278078079224\n",
      "Eval Loss:  0.24283389747142792\n",
      "Eval Loss:  0.25529563426971436\n",
      "Eval Loss:  0.2349342256784439\n",
      "Eval Loss:  0.21678166091442108\n",
      "[[17100  1322]\n",
      " [ 1666  9395]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18422\n",
      "           1       0.88      0.85      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.89      0.89      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.898653461316691\n",
      "pre:  0.8766445833722124\n",
      "rec:  0.8493807069885182\n",
      "ma F1:  0.8912244094393686\n",
      "mi F1:  0.898653461316691\n",
      "we F1:  0.8983217813886185\n",
      "29483 461\n",
      "Loss:  0.04079331085085869\n",
      "Loss:  0.04356582090258598\n",
      "Loss:  0.03745464235544205\n",
      "18 **********\n",
      "Epoch:  1266.7998340129852  fold:  9  kers:  128\n",
      "epoch:  19\n",
      "29483 461\n",
      "Loss:  0.09534282982349396\n",
      "Loss:  0.048056915402412415\n",
      "Loss:  0.05233744904398918\n",
      "19 **********\n",
      "Epoch:  1319.8031134605408  fold:  9  kers:  128\n",
      "epoch:  20\n",
      "29483 461\n",
      "Loss:  0.06466943770647049\n",
      "Loss:  0.0607486367225647\n",
      "Loss:  0.054723892360925674\n",
      "20 **********\n",
      "Epoch:  1372.8562605381012  fold:  9  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.03446974977850914\n",
      "Eval Loss:  1.8804223537445068\n",
      "Eval Loss:  0.28412291407585144\n",
      "[[1693   49]\n",
      " [ 684  982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82      1742\n",
      "           1       0.95      0.59      0.73      1666\n",
      "\n",
      "    accuracy                           0.78      3408\n",
      "   macro avg       0.83      0.78      0.78      3408\n",
      "weighted avg       0.83      0.78      0.78      3408\n",
      "\n",
      "acc:  0.7849178403755869\n",
      "pre:  0.9524733268671193\n",
      "rec:  0.5894357743097239\n",
      "ma F1:  0.7751303611873785\n",
      "mi F1:  0.7849178403755869\n",
      "we F1:  0.7761765614944162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23826497793197632\n",
      "Eval Loss:  0.3219217360019684\n",
      "Eval Loss:  0.2362232804298401\n",
      "Eval Loss:  0.25812992453575134\n",
      "Eval Loss:  0.30887535214424133\n",
      "Eval Loss:  0.22328996658325195\n",
      "Eval Loss:  0.327978253364563\n",
      "Eval Loss:  0.3496011197566986\n",
      "Eval Loss:  0.2412179857492447\n",
      "Eval Loss:  0.27673932909965515\n",
      "Eval Loss:  0.29380157589912415\n",
      "Eval Loss:  0.24011310935020447\n",
      "Eval Loss:  0.2729051411151886\n",
      "Eval Loss:  0.34602445363998413\n",
      "Eval Loss:  0.28131338953971863\n",
      "Eval Loss:  0.3000951409339905\n",
      "Eval Loss:  0.29763954877853394\n",
      "Eval Loss:  0.17801961302757263\n",
      "Eval Loss:  0.28147149085998535\n",
      "Eval Loss:  0.331788033246994\n",
      "Eval Loss:  0.21510818600654602\n",
      "Eval Loss:  0.2749193012714386\n",
      "Eval Loss:  0.23998616635799408\n",
      "Eval Loss:  0.26357904076576233\n",
      "Eval Loss:  0.2245449274778366\n",
      "Eval Loss:  0.2100062370300293\n",
      "Eval Loss:  0.2576735019683838\n",
      "Eval Loss:  0.2306899130344391\n",
      "[[17696   726]\n",
      " [ 2369  8692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18422\n",
      "           1       0.92      0.79      0.85     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.87      0.88     29483\n",
      "weighted avg       0.90      0.90      0.89     29483\n",
      "\n",
      "acc:  0.89502425126344\n",
      "pre:  0.922913569760034\n",
      "rec:  0.7858240665400958\n",
      "ma F1:  0.8842264048037447\n",
      "mi F1:  0.89502425126344\n",
      "we F1:  0.893053920106923\n",
      "29483 461\n",
      "Loss:  0.10298092663288116\n",
      "Loss:  0.06381663680076599\n",
      "Loss:  0.059393260627985\n",
      "21 **********\n",
      "Epoch:  1466.4300634860992  fold:  9  kers:  128\n",
      "epoch:  22\n",
      "29483 461\n",
      "Loss:  0.0853029116988182\n",
      "Loss:  0.07550476491451263\n",
      "Loss:  0.060418251901865005\n",
      "22 **********\n",
      "Epoch:  1519.4173860549927  fold:  9  kers:  128\n",
      "epoch:  23\n",
      "29483 461\n",
      "Loss:  0.0445362851023674\n",
      "Loss:  0.05484537035226822\n",
      "Loss:  0.06805984675884247\n",
      "23 **********\n",
      "Epoch:  1572.4276473522186  fold:  9  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.030374890193343163\n",
      "Eval Loss:  1.7709230184555054\n",
      "Eval Loss:  0.21715551614761353\n",
      "[[1688   54]\n",
      " [ 535 1131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85      1742\n",
      "           1       0.95      0.68      0.79      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.86      0.82      0.82      3408\n",
      "weighted avg       0.85      0.83      0.82      3408\n",
      "\n",
      "acc:  0.8271713615023474\n",
      "pre:  0.9544303797468354\n",
      "rec:  0.6788715486194478\n",
      "ma F1:  0.8224280058367608\n",
      "mi F1:  0.8271713615023474\n",
      "we F1:  0.8230752141501981\n",
      "Eval Loss:  0.19215543568134308\n",
      "Eval Loss:  0.2897224724292755\n",
      "Eval Loss:  0.20866788923740387\n",
      "Eval Loss:  0.24135722219944\n",
      "Eval Loss:  0.25520819425582886\n",
      "Eval Loss:  0.1912199705839157\n",
      "Eval Loss:  0.26182055473327637\n",
      "Eval Loss:  0.29218775033950806\n",
      "Eval Loss:  0.21291598677635193\n",
      "Eval Loss:  0.21890456974506378\n",
      "Eval Loss:  0.25682517886161804\n",
      "Eval Loss:  0.21068406105041504\n",
      "Eval Loss:  0.24497824907302856\n",
      "Eval Loss:  0.26989275217056274\n",
      "Eval Loss:  0.24813544750213623\n",
      "Eval Loss:  0.24937990307807922\n",
      "Eval Loss:  0.263412743806839\n",
      "Eval Loss:  0.19938121736049652\n",
      "Eval Loss:  0.2543792426586151\n",
      "Eval Loss:  0.2926309108734131\n",
      "Eval Loss:  0.21297718584537506\n",
      "Eval Loss:  0.2602269649505615\n",
      "Eval Loss:  0.19376502931118011\n",
      "Eval Loss:  0.23567651212215424\n",
      "Eval Loss:  0.21932455897331238\n",
      "Eval Loss:  0.1792621910572052\n",
      "Eval Loss:  0.22283270955085754\n",
      "Eval Loss:  0.22041963040828705\n",
      "[[17641   781]\n",
      " [ 2026  9035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18422\n",
      "           1       0.92      0.82      0.87     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.89      0.90     29483\n",
      "weighted avg       0.91      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9047925923413492\n",
      "pre:  0.9204360228198859\n",
      "rec:  0.8168339209836362\n",
      "ma F1:  0.8959249991397904\n",
      "mi F1:  0.9047925923413492\n",
      "we F1:  0.9035097485653859\n",
      "29483 461\n",
      "Loss:  0.10252442210912704\n",
      "Loss:  0.03981299325823784\n",
      "Loss:  0.020745009183883667\n",
      "24 **********\n",
      "Epoch:  1665.9645488262177  fold:  9  kers:  128\n",
      "epoch:  25\n",
      "29483 461\n",
      "Loss:  0.07470714300870895\n",
      "Loss:  0.08508779108524323\n",
      "Loss:  0.09212993830442429\n",
      "25 **********\n",
      "Epoch:  1718.9907674789429  fold:  9  kers:  128\n",
      "epoch:  26\n",
      "29483 461\n",
      "Loss:  0.09138688445091248\n",
      "Loss:  0.0967445820569992\n",
      "Loss:  0.06457408517599106\n",
      "26 **********\n",
      "Epoch:  1772.0538873672485  fold:  9  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.03471135348081589\n",
      "Eval Loss:  1.1174966096878052\n",
      "Eval Loss:  0.2121434211730957\n",
      "[[1654   88]\n",
      " [ 415 1251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87      1742\n",
      "           1       0.93      0.75      0.83      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.87      0.85      0.85      3408\n",
      "weighted avg       0.87      0.85      0.85      3408\n",
      "\n",
      "acc:  0.852406103286385\n",
      "pre:  0.9342793129200896\n",
      "rec:  0.7509003601440576\n",
      "ma F1:  0.8503129787623269\n",
      "mi F1:  0.852406103286385\n",
      "we F1:  0.8507077119231914\n",
      "update!  Acc:  0.852406103286385\n",
      "Eval Loss:  0.20370134711265564\n",
      "Eval Loss:  0.293378084897995\n",
      "Eval Loss:  0.2096794992685318\n",
      "Eval Loss:  0.23063349723815918\n",
      "Eval Loss:  0.206685408949852\n",
      "Eval Loss:  0.18386146426200867\n",
      "Eval Loss:  0.23117446899414062\n",
      "Eval Loss:  0.26310592889785767\n",
      "Eval Loss:  0.17229080200195312\n",
      "Eval Loss:  0.17789384722709656\n",
      "Eval Loss:  0.24219049513339996\n",
      "Eval Loss:  0.19036148488521576\n",
      "Eval Loss:  0.2541428804397583\n",
      "Eval Loss:  0.24997396767139435\n",
      "Eval Loss:  0.2258853018283844\n",
      "Eval Loss:  0.24654459953308105\n",
      "Eval Loss:  0.23593734204769135\n",
      "Eval Loss:  0.19618117809295654\n",
      "Eval Loss:  0.239674910902977\n",
      "Eval Loss:  0.267408162355423\n",
      "Eval Loss:  0.16892167925834656\n",
      "Eval Loss:  0.21740460395812988\n",
      "Eval Loss:  0.16674844920635223\n",
      "Eval Loss:  0.23967115581035614\n",
      "Eval Loss:  0.2362983226776123\n",
      "Eval Loss:  0.1960645467042923\n",
      "Eval Loss:  0.1808873564004898\n",
      "Eval Loss:  0.20480899512767792\n",
      "[[17493   929]\n",
      " [ 1619  9442]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18422\n",
      "           1       0.91      0.85      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.90      0.91     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9135773157412747\n",
      "pre:  0.9104232957284736\n",
      "rec:  0.8536298707169334\n",
      "ma F1:  0.9066136189315019\n",
      "mi F1:  0.9135773157412747\n",
      "we F1:  0.912980501581699\n",
      "29483 461\n",
      "Loss:  0.041205476969480515\n",
      "Loss:  0.06116490066051483\n",
      "Loss:  0.05721070244908333\n",
      "27 **********\n",
      "Epoch:  1865.706479549408  fold:  9  kers:  128\n",
      "epoch:  28\n",
      "29483 461\n",
      "Loss:  0.09436256438493729\n",
      "Loss:  0.04740989953279495\n",
      "Loss:  0.04696912690997124\n",
      "28 **********\n",
      "Epoch:  1918.7227244377136  fold:  9  kers:  128\n",
      "epoch:  29\n",
      "29483 461\n",
      "Loss:  0.04476223513484001\n",
      "Loss:  0.05875412002205849\n",
      "Loss:  0.06460537016391754\n",
      "29 **********\n",
      "Epoch:  1971.66117811203  fold:  9  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.031872957944869995\n",
      "Eval Loss:  1.3486318588256836\n",
      "Eval Loss:  0.17614395916461945\n",
      "[[1627  115]\n",
      " [ 408 1258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      1742\n",
      "           1       0.92      0.76      0.83      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.846537558685446\n",
      "pre:  0.9162418062636563\n",
      "rec:  0.7551020408163265\n",
      "ma F1:  0.8447171154133151\n",
      "mi F1:  0.846537558685446\n",
      "we F1:  0.8450920576590656\n",
      "Eval Loss:  0.18866820633411407\n",
      "Eval Loss:  0.26403433084487915\n",
      "Eval Loss:  0.2212565690279007\n",
      "Eval Loss:  0.2360612154006958\n",
      "Eval Loss:  0.23473824560642242\n",
      "Eval Loss:  0.18120253086090088\n",
      "Eval Loss:  0.2270682007074356\n",
      "Eval Loss:  0.26720330119132996\n",
      "Eval Loss:  0.16397953033447266\n",
      "Eval Loss:  0.18715885281562805\n",
      "Eval Loss:  0.22493764758110046\n",
      "Eval Loss:  0.1929446905851364\n",
      "Eval Loss:  0.23311220109462738\n",
      "Eval Loss:  0.22595509886741638\n",
      "Eval Loss:  0.24071849882602692\n",
      "Eval Loss:  0.2296641319990158\n",
      "Eval Loss:  0.25224265456199646\n",
      "Eval Loss:  0.21364980936050415\n",
      "Eval Loss:  0.2210267335176468\n",
      "Eval Loss:  0.26341569423675537\n",
      "Eval Loss:  0.16975997388362885\n",
      "Eval Loss:  0.2116161733865738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17573679983615875\n",
      "Eval Loss:  0.22639013826847076\n",
      "Eval Loss:  0.23239752650260925\n",
      "Eval Loss:  0.18171074986457825\n",
      "Eval Loss:  0.17390921711921692\n",
      "Eval Loss:  0.2085256576538086\n",
      "[[17516   906]\n",
      " [ 1638  9423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18422\n",
      "           1       0.91      0.85      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.90      0.91     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9137129871451345\n",
      "pre:  0.9122857972698228\n",
      "rec:  0.8519121236777868\n",
      "ma F1:  0.906681564819656\n",
      "mi F1:  0.9137129871451345\n",
      "we F1:  0.9130770052914029\n",
      "29483 461\n",
      "Loss:  0.07454202324151993\n",
      "Loss:  0.017911601811647415\n",
      "Loss:  0.04468369483947754\n",
      "30 **********\n",
      "Epoch:  2065.2678928375244  fold:  9  kers:  128\n",
      "epoch:  31\n",
      "29483 461\n",
      "Loss:  0.04557741805911064\n",
      "Loss:  0.057850539684295654\n",
      "Loss:  0.05230400338768959\n",
      "31 **********\n",
      "Epoch:  2118.2661859989166  fold:  9  kers:  128\n",
      "epoch:  32\n",
      "29483 461\n",
      "Loss:  0.06977620720863342\n",
      "Loss:  0.049088045954704285\n",
      "Loss:  0.07635726034641266\n",
      "32 **********\n",
      "Epoch:  2171.1178715229034  fold:  9  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.037051960825920105\n",
      "Eval Loss:  0.9111265540122986\n",
      "Eval Loss:  0.1971389353275299\n",
      "[[1532  210]\n",
      " [ 367 1299]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84      1742\n",
      "           1       0.86      0.78      0.82      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.83      0.83      0.83      3408\n",
      "weighted avg       0.83      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8306924882629108\n",
      "pre:  0.8608349900596421\n",
      "rec:  0.7797118847539015\n",
      "ma F1:  0.8298973847714244\n",
      "mi F1:  0.8306924882629108\n",
      "we F1:  0.8301567318330251\n",
      "Eval Loss:  0.1735776662826538\n",
      "Eval Loss:  0.2842925488948822\n",
      "Eval Loss:  0.2011231780052185\n",
      "Eval Loss:  0.2455223798751831\n",
      "Eval Loss:  0.1727304756641388\n",
      "Eval Loss:  0.14142948389053345\n",
      "Eval Loss:  0.24115855991840363\n",
      "Eval Loss:  0.2545916736125946\n",
      "Eval Loss:  0.1460922360420227\n",
      "Eval Loss:  0.20189514756202698\n",
      "Eval Loss:  0.2222103774547577\n",
      "Eval Loss:  0.19266100227832794\n",
      "Eval Loss:  0.26249346137046814\n",
      "Eval Loss:  0.19379335641860962\n",
      "Eval Loss:  0.2350388765335083\n",
      "Eval Loss:  0.245125412940979\n",
      "Eval Loss:  0.27505576610565186\n",
      "Eval Loss:  0.20059558749198914\n",
      "Eval Loss:  0.24707292020320892\n",
      "Eval Loss:  0.2484687864780426\n",
      "Eval Loss:  0.13280819356441498\n",
      "Eval Loss:  0.21689173579216003\n",
      "Eval Loss:  0.15483394265174866\n",
      "Eval Loss:  0.23520328104496002\n",
      "Eval Loss:  0.22661422193050385\n",
      "Eval Loss:  0.19847898185253143\n",
      "Eval Loss:  0.16368922591209412\n",
      "Eval Loss:  0.1758011132478714\n",
      "[[17166  1256]\n",
      " [ 1177  9884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18422\n",
      "           1       0.89      0.89      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9174778686022453\n",
      "pre:  0.8872531418312388\n",
      "rec:  0.8935900913118163\n",
      "ma F1:  0.9121166356465283\n",
      "mi F1:  0.9174778686022453\n",
      "we F1:  0.9175360308383758\n",
      "29483 461\n",
      "Loss:  0.049433618783950806\n",
      "Loss:  0.0575026236474514\n",
      "Loss:  0.05865158513188362\n",
      "33 **********\n",
      "Epoch:  2264.5670075416565  fold:  9  kers:  128\n",
      "epoch:  34\n",
      "29483 461\n",
      "Loss:  0.0331522598862648\n",
      "Loss:  0.04728797450661659\n",
      "Loss:  0.03811376914381981\n",
      "34 **********\n",
      "Epoch:  2317.4695568084717  fold:  9  kers:  128\n",
      "epoch:  35\n",
      "29483 461\n",
      "Loss:  0.06477712839841843\n",
      "Loss:  0.09968621283769608\n",
      "Loss:  0.05725027620792389\n",
      "35 **********\n",
      "Epoch:  2370.4648587703705  fold:  9  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.03868938237428665\n",
      "Eval Loss:  0.5866045355796814\n",
      "Eval Loss:  0.17467553913593292\n",
      "[[1564  178]\n",
      " [ 290 1376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1742\n",
      "           1       0.89      0.83      0.85      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.86      0.86      0.86      3408\n",
      "weighted avg       0.86      0.86      0.86      3408\n",
      "\n",
      "acc:  0.8626760563380281\n",
      "pre:  0.8854568854568855\n",
      "rec:  0.8259303721488596\n",
      "ma F1:  0.8622568899881857\n",
      "mi F1:  0.8626760563380281\n",
      "we F1:  0.8624263402147179\n",
      "update!  Acc:  0.8626760563380281\n",
      "Eval Loss:  0.18709085881710052\n",
      "Eval Loss:  0.2577126920223236\n",
      "Eval Loss:  0.19246597588062286\n",
      "Eval Loss:  0.22110801935195923\n",
      "Eval Loss:  0.17371457815170288\n",
      "Eval Loss:  0.15297821164131165\n",
      "Eval Loss:  0.20501215755939484\n",
      "Eval Loss:  0.24302470684051514\n",
      "Eval Loss:  0.12553761899471283\n",
      "Eval Loss:  0.19469720125198364\n",
      "Eval Loss:  0.2100193202495575\n",
      "Eval Loss:  0.2057984173297882\n",
      "Eval Loss:  0.20272810757160187\n",
      "Eval Loss:  0.19540594518184662\n",
      "Eval Loss:  0.2367023378610611\n",
      "Eval Loss:  0.18698133528232574\n",
      "Eval Loss:  0.2832573652267456\n",
      "Eval Loss:  0.20987680554389954\n",
      "Eval Loss:  0.22852151095867157\n",
      "Eval Loss:  0.22886471450328827\n",
      "Eval Loss:  0.13022330403327942\n",
      "Eval Loss:  0.20975762605667114\n",
      "Eval Loss:  0.16308251023292542\n",
      "Eval Loss:  0.24535609781742096\n",
      "Eval Loss:  0.21106600761413574\n",
      "Eval Loss:  0.1842820644378662\n",
      "Eval Loss:  0.17363415658473969\n",
      "Eval Loss:  0.1601630449295044\n",
      "[[17249  1173]\n",
      " [ 1145  9916]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18422\n",
      "           1       0.89      0.90      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9213784214632161\n",
      "pre:  0.8942194967986292\n",
      "rec:  0.8964831389566947\n",
      "ma F1:  0.9161940656874086\n",
      "mi F1:  0.9213784214632161\n",
      "we F1:  0.9213982171759835\n",
      "29483 461\n",
      "Loss:  0.04608447104692459\n",
      "Loss:  0.05910375714302063\n",
      "Loss:  0.04924450442194939\n",
      "36 **********\n",
      "Epoch:  2464.1363995075226  fold:  9  kers:  128\n",
      "epoch:  37\n",
      "29483 461\n",
      "Loss:  0.06292702257633209\n",
      "Loss:  0.0207756869494915\n",
      "Loss:  0.04513413831591606\n",
      "37 **********\n",
      "Epoch:  2517.163614988327  fold:  9  kers:  128\n",
      "epoch:  38\n",
      "29483 461\n",
      "Loss:  0.03238847479224205\n",
      "Loss:  0.05759425461292267\n",
      "Loss:  0.06031055748462677\n",
      "38 **********\n",
      "Epoch:  2570.1569216251373  fold:  9  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.03385250270366669\n",
      "Eval Loss:  1.174902081489563\n",
      "Eval Loss:  0.1460290402173996\n",
      "[[1591  151]\n",
      " [ 357 1309]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1742\n",
      "           1       0.90      0.79      0.84      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.86      0.85      0.85      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8509389671361502\n",
      "pre:  0.8965753424657534\n",
      "rec:  0.7857142857142857\n",
      "ma F1:  0.849911312932707\n",
      "mi F1:  0.8509389671361502\n",
      "we F1:  0.8501882693846988\n",
      "Eval Loss:  0.1659230887889862\n",
      "Eval Loss:  0.2727356255054474\n",
      "Eval Loss:  0.19450652599334717\n",
      "Eval Loss:  0.22001829743385315\n",
      "Eval Loss:  0.1841551810503006\n",
      "Eval Loss:  0.13651825487613678\n",
      "Eval Loss:  0.20796526968479156\n",
      "Eval Loss:  0.2690724730491638\n",
      "Eval Loss:  0.11395937949419022\n",
      "Eval Loss:  0.19193413853645325\n",
      "Eval Loss:  0.22576266527175903\n",
      "Eval Loss:  0.20545698702335358\n",
      "Eval Loss:  0.2502512037754059\n",
      "Eval Loss:  0.20254454016685486\n",
      "Eval Loss:  0.20569904148578644\n",
      "Eval Loss:  0.19996127486228943\n",
      "Eval Loss:  0.28528448939323425\n",
      "Eval Loss:  0.1940401792526245\n",
      "Eval Loss:  0.23049789667129517\n",
      "Eval Loss:  0.2369740903377533\n",
      "Eval Loss:  0.12487393617630005\n",
      "Eval Loss:  0.21128475666046143\n",
      "Eval Loss:  0.15003910660743713\n",
      "Eval Loss:  0.2351255863904953\n",
      "Eval Loss:  0.20870418846607208\n",
      "Eval Loss:  0.18381863832473755\n",
      "Eval Loss:  0.1593647301197052\n",
      "Eval Loss:  0.17209988832473755\n",
      "[[17151  1271]\n",
      " [ 1071  9990]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18422\n",
      "           1       0.89      0.90      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.920564393040057\n",
      "pre:  0.8871325814758902\n",
      "rec:  0.903173311635476\n",
      "ma F1:  0.9155844246344067\n",
      "mi F1:  0.920564393040057\n",
      "we F1:  0.9207034788773882\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04621906578540802\n",
      "Loss:  0.07087936997413635\n",
      "Loss:  0.04598904773592949\n",
      "39 **********\n",
      "Epoch:  2663.7008044719696  fold:  9  kers:  128\n",
      "epoch:  40\n",
      "29483 461\n",
      "Loss:  0.058462489396333694\n",
      "Loss:  0.03930460661649704\n",
      "Loss:  0.028598953038454056\n",
      "40 **********\n",
      "Epoch:  2716.6921162605286  fold:  9  kers:  128\n",
      "epoch:  41\n",
      "29483 461\n",
      "Loss:  0.07999680191278458\n",
      "Loss:  0.08009416610002518\n",
      "Loss:  0.06418716907501221\n",
      "41 **********\n",
      "Epoch:  2769.6574976444244  fold:  9  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.04705654829740524\n",
      "Eval Loss:  0.8822224140167236\n",
      "Eval Loss:  0.18525806069374084\n",
      "[[1582  160]\n",
      " [ 356 1310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1742\n",
      "           1       0.89      0.79      0.84      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.85      0.85      0.85      3408\n",
      "weighted avg       0.85      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8485915492957746\n",
      "pre:  0.891156462585034\n",
      "rec:  0.7863145258103241\n",
      "ma F1:  0.8476208961845608\n",
      "mi F1:  0.8485915492957746\n",
      "we F1:  0.8478921080832824\n",
      "Eval Loss:  0.16346633434295654\n",
      "Eval Loss:  0.24961869418621063\n",
      "Eval Loss:  0.18474440276622772\n",
      "Eval Loss:  0.21448436379432678\n",
      "Eval Loss:  0.17775499820709229\n",
      "Eval Loss:  0.14137443900108337\n",
      "Eval Loss:  0.21536880731582642\n",
      "Eval Loss:  0.25383469462394714\n",
      "Eval Loss:  0.122332863509655\n",
      "Eval Loss:  0.20206551253795624\n",
      "Eval Loss:  0.20965050160884857\n",
      "Eval Loss:  0.22207438945770264\n",
      "Eval Loss:  0.23030734062194824\n",
      "Eval Loss:  0.20322498679161072\n",
      "Eval Loss:  0.2102011889219284\n",
      "Eval Loss:  0.21636298298835754\n",
      "Eval Loss:  0.2959398627281189\n",
      "Eval Loss:  0.1767420470714569\n",
      "Eval Loss:  0.24722017347812653\n",
      "Eval Loss:  0.21816010773181915\n",
      "Eval Loss:  0.1354030966758728\n",
      "Eval Loss:  0.20719048380851746\n",
      "Eval Loss:  0.15189026296138763\n",
      "Eval Loss:  0.23705698549747467\n",
      "Eval Loss:  0.20913472771644592\n",
      "Eval Loss:  0.18289195001125336\n",
      "Eval Loss:  0.14954930543899536\n",
      "Eval Loss:  0.17394566535949707\n",
      "[[17136  1286]\n",
      " [  979 10082]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18422\n",
      "           1       0.89      0.91      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9231760675643591\n",
      "pre:  0.8868754398311048\n",
      "rec:  0.9114908236145014\n",
      "ma F1:  0.9185113575735868\n",
      "mi F1:  0.9231760675643591\n",
      "we F1:  0.9233790823031125\n",
      "29483 461\n",
      "Loss:  0.044259268790483475\n",
      "Loss:  0.06085330247879028\n",
      "Loss:  0.05614032223820686\n",
      "42 **********\n",
      "Epoch:  2863.2263140678406  fold:  9  kers:  128\n",
      "epoch:  43\n",
      "29483 461\n",
      "Loss:  0.0947447344660759\n",
      "Loss:  0.06261119991540909\n",
      "Loss:  0.05318006873130798\n",
      "43 **********\n",
      "Epoch:  2916.1198873519897  fold:  9  kers:  128\n",
      "epoch:  44\n",
      "29483 461\n",
      "Loss:  0.06314405053853989\n",
      "Loss:  0.04307779297232628\n",
      "Loss:  0.059753842651844025\n",
      "44 **********\n",
      "Epoch:  2969.057343006134  fold:  9  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.034627512097358704\n",
      "Eval Loss:  1.2827949523925781\n",
      "Eval Loss:  0.16655997931957245\n",
      "[[1665   77]\n",
      " [ 380 1286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      1742\n",
      "           1       0.94      0.77      0.85      1666\n",
      "\n",
      "    accuracy                           0.87      3408\n",
      "   macro avg       0.88      0.86      0.86      3408\n",
      "weighted avg       0.88      0.87      0.86      3408\n",
      "\n",
      "acc:  0.8659037558685446\n",
      "pre:  0.9435069699192957\n",
      "rec:  0.7719087635054022\n",
      "ma F1:  0.8642245634859853\n",
      "mi F1:  0.8659037558685446\n",
      "we F1:  0.8645612880798494\n",
      "update!  Acc:  0.8659037558685446\n",
      "Eval Loss:  0.17931151390075684\n",
      "Eval Loss:  0.30127355456352234\n",
      "Eval Loss:  0.18813961744308472\n",
      "Eval Loss:  0.21557776629924774\n",
      "Eval Loss:  0.1683073341846466\n",
      "Eval Loss:  0.13793401420116425\n",
      "Eval Loss:  0.22884586453437805\n",
      "Eval Loss:  0.25793659687042236\n",
      "Eval Loss:  0.13547083735466003\n",
      "Eval Loss:  0.168212428689003\n",
      "Eval Loss:  0.2055901437997818\n",
      "Eval Loss:  0.204965278506279\n",
      "Eval Loss:  0.2375352680683136\n",
      "Eval Loss:  0.2072007805109024\n",
      "Eval Loss:  0.1934501677751541\n",
      "Eval Loss:  0.2292860448360443\n",
      "Eval Loss:  0.24780477583408356\n",
      "Eval Loss:  0.1455022096633911\n",
      "Eval Loss:  0.24298584461212158\n",
      "Eval Loss:  0.24765123426914215\n",
      "Eval Loss:  0.13249412178993225\n",
      "Eval Loss:  0.1947370171546936\n",
      "Eval Loss:  0.16038481891155243\n",
      "Eval Loss:  0.23223736882209778\n",
      "Eval Loss:  0.19617587327957153\n",
      "Eval Loss:  0.1740553081035614\n",
      "Eval Loss:  0.15613332390785217\n",
      "Eval Loss:  0.17922165989875793\n",
      "[[17349  1073]\n",
      " [ 1217  9844]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18422\n",
      "           1       0.90      0.89      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.922328121290235\n",
      "pre:  0.9017129247961895\n",
      "rec:  0.8899737817557183\n",
      "ma F1:  0.916946462177348\n",
      "mi F1:  0.922328121290235\n",
      "we F1:  0.9222248622746114\n",
      "29483 461\n",
      "Loss:  0.03690453991293907\n",
      "Loss:  0.04656587168574333\n",
      "Loss:  0.09287026524543762\n",
      "45 **********\n",
      "Epoch:  3062.675028562546  fold:  9  kers:  128\n",
      "epoch:  46\n",
      "29483 461\n",
      "Loss:  0.044203732162714005\n",
      "Loss:  0.0529647171497345\n",
      "Loss:  0.050875887274742126\n",
      "46 **********\n",
      "Epoch:  3115.670329809189  fold:  9  kers:  128\n",
      "epoch:  47\n",
      "29483 461\n",
      "Loss:  0.04978940263390541\n",
      "Loss:  0.05769733339548111\n",
      "Loss:  0.03357395902276039\n",
      "47 **********\n",
      "Epoch:  3168.621748685837  fold:  9  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.035000383853912354\n",
      "Eval Loss:  1.3480359315872192\n",
      "Eval Loss:  0.11962492763996124\n",
      "[[1621  121]\n",
      " [ 364 1302]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      1742\n",
      "           1       0.91      0.78      0.84      1666\n",
      "\n",
      "    accuracy                           0.86      3408\n",
      "   macro avg       0.87      0.86      0.86      3408\n",
      "weighted avg       0.86      0.86      0.86      3408\n",
      "\n",
      "acc:  0.85768779342723\n",
      "pre:  0.9149683766690091\n",
      "rec:  0.7815126050420168\n",
      "ma F1:  0.8564298931363034\n",
      "mi F1:  0.85768779342723\n",
      "we F1:  0.8567295809799098\n",
      "Eval Loss:  0.17798864841461182\n",
      "Eval Loss:  0.28963953256607056\n",
      "Eval Loss:  0.20911340415477753\n",
      "Eval Loss:  0.22499389946460724\n",
      "Eval Loss:  0.15576015412807465\n",
      "Eval Loss:  0.1306026726961136\n",
      "Eval Loss:  0.22432880103588104\n",
      "Eval Loss:  0.29328784346580505\n",
      "Eval Loss:  0.12693533301353455\n",
      "Eval Loss:  0.17337243258953094\n",
      "Eval Loss:  0.24098022282123566\n",
      "Eval Loss:  0.20331081748008728\n",
      "Eval Loss:  0.29749277234077454\n",
      "Eval Loss:  0.2186368852853775\n",
      "Eval Loss:  0.1921241134405136\n",
      "Eval Loss:  0.26874005794525146\n",
      "Eval Loss:  0.29246148467063904\n",
      "Eval Loss:  0.14612218737602234\n",
      "Eval Loss:  0.23416924476623535\n",
      "Eval Loss:  0.23604491353034973\n",
      "Eval Loss:  0.1372709572315216\n",
      "Eval Loss:  0.2407180219888687\n",
      "Eval Loss:  0.1666812151670456\n",
      "Eval Loss:  0.2581018805503845\n",
      "Eval Loss:  0.2344386875629425\n",
      "Eval Loss:  0.1972566843032837\n",
      "Eval Loss:  0.17464189231395721\n",
      "Eval Loss:  0.1990644633769989\n",
      "[[16934  1488]\n",
      " [  983 10078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93     18422\n",
      "           1       0.87      0.91      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.92      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9161889902655768\n",
      "pre:  0.8713470517032682\n",
      "rec:  0.9111291926588916\n",
      "ma F1:  0.9113978074545115\n",
      "mi F1:  0.9161889902655768\n",
      "we F1:  0.9165418997345948\n",
      "29483 461\n",
      "Loss:  0.05652657523751259\n",
      "Loss:  0.03295529633760452\n",
      "Loss:  0.05365879461169243\n",
      "48 **********\n",
      "Epoch:  3261.9970819950104  fold:  9  kers:  128\n",
      "epoch:  49\n",
      "29483 461\n",
      "Loss:  0.08122746646404266\n",
      "Loss:  0.05534907057881355\n",
      "Loss:  0.07009871304035187\n",
      "49 **********\n",
      "Epoch:  3314.9624631404877  fold:  9  kers:  128\n",
      "epoch:  50\n",
      "29483 461\n",
      "Loss:  0.044072750955820084\n",
      "Loss:  0.044286224991083145\n",
      "Loss:  0.09532948583364487\n",
      "50 **********\n",
      "Epoch:  3367.7892150878906  fold:  9  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.040259744971990585\n",
      "Eval Loss:  0.8890824913978577\n",
      "Eval Loss:  0.2022024244070053\n",
      "[[1610  132]\n",
      " [ 397 1269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86      1742\n",
      "           1       0.91      0.76      0.83      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8447769953051644\n",
      "pre:  0.9057815845824411\n",
      "rec:  0.7617046818727491\n",
      "ma F1:  0.8432072267418251\n",
      "mi F1:  0.8447769953051644\n",
      "we F1:  0.8435570871840943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1484057903289795\n",
      "Eval Loss:  0.2709520757198334\n",
      "Eval Loss:  0.16549715399742126\n",
      "Eval Loss:  0.19185759127140045\n",
      "Eval Loss:  0.14797355234622955\n",
      "Eval Loss:  0.13584794104099274\n",
      "Eval Loss:  0.20253314077854156\n",
      "Eval Loss:  0.23627176880836487\n",
      "Eval Loss:  0.13439688086509705\n",
      "Eval Loss:  0.167933389544487\n",
      "Eval Loss:  0.1823214739561081\n",
      "Eval Loss:  0.19572164118289948\n",
      "Eval Loss:  0.1767854392528534\n",
      "Eval Loss:  0.20198610424995422\n",
      "Eval Loss:  0.2177746593952179\n",
      "Eval Loss:  0.21471194922924042\n",
      "Eval Loss:  0.24488505721092224\n",
      "Eval Loss:  0.15839913487434387\n",
      "Eval Loss:  0.21012167632579803\n",
      "Eval Loss:  0.21452385187149048\n",
      "Eval Loss:  0.12190603464841843\n",
      "Eval Loss:  0.17477235198020935\n",
      "Eval Loss:  0.1347496211528778\n",
      "Eval Loss:  0.2050105482339859\n",
      "Eval Loss:  0.19549037516117096\n",
      "Eval Loss:  0.16284820437431335\n",
      "Eval Loss:  0.1473466157913208\n",
      "Eval Loss:  0.15924715995788574\n",
      "[[17439   983]\n",
      " [ 1133  9928]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18422\n",
      "           1       0.91      0.90      0.90     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9282298273581386\n",
      "pre:  0.9099074328659151\n",
      "rec:  0.8975680318235241\n",
      "ma F1:  0.9232485739909841\n",
      "mi F1:  0.9282298273581386\n",
      "we F1:  0.9281303481935702\n",
      "29483 461\n",
      "Loss:  0.050147876143455505\n",
      "Loss:  0.06365745514631271\n",
      "Loss:  0.06913166493177414\n",
      "51 **********\n",
      "Epoch:  3461.1017162799835  fold:  9  kers:  128\n",
      "epoch:  52\n",
      "29483 461\n",
      "Loss:  0.04502962902188301\n",
      "Loss:  0.03152070567011833\n",
      "Loss:  0.04722120612859726\n",
      "52 **********\n",
      "Epoch:  3513.997284889221  fold:  9  kers:  128\n",
      "epoch:  53\n",
      "29483 461\n",
      "Loss:  0.03307952731847763\n",
      "Loss:  0.03845701739192009\n",
      "Loss:  0.04143258556723595\n",
      "53 **********\n",
      "Epoch:  3566.954687356949  fold:  9  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.04019453376531601\n",
      "Eval Loss:  0.9433549046516418\n",
      "Eval Loss:  0.19983553886413574\n",
      "[[1610  132]\n",
      " [ 375 1291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86      1742\n",
      "           1       0.91      0.77      0.84      1666\n",
      "\n",
      "    accuracy                           0.85      3408\n",
      "   macro avg       0.86      0.85      0.85      3408\n",
      "weighted avg       0.86      0.85      0.85      3408\n",
      "\n",
      "acc:  0.8512323943661971\n",
      "pre:  0.9072382290934645\n",
      "rec:  0.7749099639855942\n",
      "ma F1:  0.8499174346806306\n",
      "mi F1:  0.8512323943661971\n",
      "we F1:  0.8502307166119881\n",
      "Eval Loss:  0.15053553879261017\n",
      "Eval Loss:  0.23987522721290588\n",
      "Eval Loss:  0.17809849977493286\n",
      "Eval Loss:  0.19477194547653198\n",
      "Eval Loss:  0.14200857281684875\n",
      "Eval Loss:  0.1142384260892868\n",
      "Eval Loss:  0.20756328105926514\n",
      "Eval Loss:  0.24065957963466644\n",
      "Eval Loss:  0.1252402514219284\n",
      "Eval Loss:  0.1711844801902771\n",
      "Eval Loss:  0.18777619302272797\n",
      "Eval Loss:  0.18521952629089355\n",
      "Eval Loss:  0.18108156323432922\n",
      "Eval Loss:  0.18559828400611877\n",
      "Eval Loss:  0.20428511500358582\n",
      "Eval Loss:  0.1887812316417694\n",
      "Eval Loss:  0.23062920570373535\n",
      "Eval Loss:  0.1493181735277176\n",
      "Eval Loss:  0.24056269228458405\n",
      "Eval Loss:  0.20227199792861938\n",
      "Eval Loss:  0.11743896454572678\n",
      "Eval Loss:  0.17870044708251953\n",
      "Eval Loss:  0.13718771934509277\n",
      "Eval Loss:  0.21466554701328278\n",
      "Eval Loss:  0.20461846888065338\n",
      "Eval Loss:  0.17233611643314362\n",
      "Eval Loss:  0.156716987490654\n",
      "Eval Loss:  0.15781943500041962\n",
      "[[17559   863]\n",
      " [ 1182  9879]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94     18422\n",
      "           1       0.92      0.89      0.91     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.93      0.92      0.93     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.930637994776651\n",
      "pre:  0.9196611431763173\n",
      "rec:  0.8931380526173041\n",
      "ma F1:  0.9255888588799508\n",
      "mi F1:  0.9306379947766511\n",
      "we F1:  0.9304282715538582\n",
      "29483 461\n",
      "Loss:  0.04503341764211655\n",
      "Loss:  0.07081010192632675\n",
      "Loss:  0.08354230970144272\n",
      "54 **********\n",
      "Epoch:  3660.4367351531982  fold:  9  kers:  128\n",
      "epoch:  55\n",
      "29483 461\n",
      "Loss:  0.04540286213159561\n",
      "Loss:  0.033613502979278564\n",
      "Loss:  0.06630269438028336\n",
      "55 **********\n",
      "Epoch:  3713.3731939792633  fold:  9  kers:  128\n",
      "epoch:  56\n",
      "29483 461\n",
      "Loss:  0.06648266315460205\n",
      "Loss:  0.05312028527259827\n",
      "Loss:  0.027589235454797745\n",
      "56 **********\n",
      "Epoch:  3766.230863571167  fold:  9  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.03704579919576645\n",
      "Eval Loss:  1.097535252571106\n",
      "Eval Loss:  0.18105299770832062\n",
      "[[1602  140]\n",
      " [ 394 1272]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86      1742\n",
      "           1       0.90      0.76      0.83      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8433098591549296\n",
      "pre:  0.9008498583569405\n",
      "rec:  0.7635054021608644\n",
      "ma F1:  0.8418267891952103\n",
      "mi F1:  0.8433098591549296\n",
      "we F1:  0.842168344701085\n",
      "Eval Loss:  0.17313960194587708\n",
      "Eval Loss:  0.23385263979434967\n",
      "Eval Loss:  0.1771748960018158\n",
      "Eval Loss:  0.19924503564834595\n",
      "Eval Loss:  0.1458801031112671\n",
      "Eval Loss:  0.1082119345664978\n",
      "Eval Loss:  0.19571539759635925\n",
      "Eval Loss:  0.24333781003952026\n",
      "Eval Loss:  0.10562950372695923\n",
      "Eval Loss:  0.16306091845035553\n",
      "Eval Loss:  0.1917804330587387\n",
      "Eval Loss:  0.19366835057735443\n",
      "Eval Loss:  0.1962646245956421\n",
      "Eval Loss:  0.1618664413690567\n",
      "Eval Loss:  0.21133652329444885\n",
      "Eval Loss:  0.2058049738407135\n",
      "Eval Loss:  0.25070807337760925\n",
      "Eval Loss:  0.17907756567001343\n",
      "Eval Loss:  0.21273815631866455\n",
      "Eval Loss:  0.20744159817695618\n",
      "Eval Loss:  0.12164852023124695\n",
      "Eval Loss:  0.1496056765317917\n",
      "Eval Loss:  0.13239210844039917\n",
      "Eval Loss:  0.22662684321403503\n",
      "Eval Loss:  0.20489118993282318\n",
      "Eval Loss:  0.1673065572977066\n",
      "Eval Loss:  0.14651603996753693\n",
      "Eval Loss:  0.1673223376274109\n",
      "[[17393  1029]\n",
      " [ 1062  9999]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18422\n",
      "           1       0.91      0.90      0.91     11061\n",
      "\n",
      "    accuracy                           0.93     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.93      0.93      0.93     29483\n",
      "\n",
      "acc:  0.9290777736322626\n",
      "pre:  0.9066920565832427\n",
      "rec:  0.9039869812855981\n",
      "ma F1:  0.9243177444598902\n",
      "mi F1:  0.9290777736322626\n",
      "we F1:  0.9290565292499678\n",
      "29483 461\n",
      "Loss:  0.06738197058439255\n",
      "Loss:  0.039747290313243866\n",
      "Loss:  0.04861081391572952\n",
      "57 **********\n",
      "Epoch:  3859.614175081253  fold:  9  kers:  128\n",
      "epoch:  58\n",
      "29483 461\n",
      "Loss:  0.07029592990875244\n",
      "Loss:  0.06345592439174652\n",
      "Loss:  0.046801917254924774\n",
      "58 **********\n",
      "Epoch:  3912.66034078598  fold:  9  kers:  128\n",
      "epoch:  59\n",
      "29483 461\n",
      "Loss:  0.06071086600422859\n",
      "Loss:  0.058882154524326324\n",
      "Loss:  0.03587953373789787\n",
      "59 **********\n",
      "Epoch:  3965.613754272461  fold:  9  kers:  128\n",
      "Eval Loss:  0.038437165319919586\n",
      "Eval Loss:  1.4450454711914062\n",
      "Eval Loss:  0.16010606288909912\n",
      "[[1634  108]\n",
      " [ 422 1244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      1742\n",
      "           1       0.92      0.75      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.86      0.84      0.84      3408\n",
      "weighted avg       0.86      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8444835680751174\n",
      "pre:  0.9201183431952663\n",
      "rec:  0.7466986794717887\n",
      "ma F1:  0.8424199405986409\n",
      "mi F1:  0.8444835680751174\n",
      "we F1:  0.8428220833889286\n",
      "update!  Acc:  0.8659037558685446\n",
      "Epoch:  3969.8344690799713  fold:  9  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29871 3020\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29871 467\n",
      "Loss:  0.16106022894382477\n",
      "Loss:  0.16315191984176636\n",
      "Loss:  0.15196692943572998\n",
      "0 **********\n",
      "Epoch:  66.34460687637329  fold:  10  kers:  128\n",
      "epoch:  1\n",
      "29871 467\n",
      "Loss:  0.1283532679080963\n",
      "Loss:  0.1451466679573059\n",
      "Loss:  0.11504610627889633\n",
      "1 **********\n",
      "Epoch:  120.2634391784668  fold:  10  kers:  128\n",
      "epoch:  2\n",
      "29871 467\n",
      "Loss:  0.10290665179491043\n",
      "Loss:  0.09179035574197769\n",
      "Loss:  0.09300676733255386\n",
      "2 **********\n",
      "Epoch:  174.06658029556274  fold:  10  kers:  128\n",
      "epoch:  3\n",
      "Eval Loss:  0.578580915927887\n",
      "Eval Loss:  0.20355366170406342\n",
      "Eval Loss:  0.12155631929636002\n",
      "[[1600  151]\n",
      " [ 225 1044]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      1751\n",
      "           1       0.87      0.82      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.88      0.87      0.87      3020\n",
      "weighted avg       0.88      0.88      0.87      3020\n",
      "\n",
      "acc:  0.8754966887417218\n",
      "pre:  0.8736401673640167\n",
      "rec:  0.8226950354609929\n",
      "ma F1:  0.8711285917661755\n",
      "mi F1:  0.8754966887417218\n",
      "we F1:  0.8749153233169188\n",
      "update!  Acc:  0.8754966887417218\n",
      "Eval Loss:  0.43501392006874084\n",
      "Eval Loss:  0.41465339064598083\n",
      "Eval Loss:  0.3868933618068695\n",
      "Eval Loss:  0.36030369997024536\n",
      "Eval Loss:  0.38857653737068176\n",
      "Eval Loss:  0.44030553102493286\n",
      "Eval Loss:  0.39657992124557495\n",
      "Eval Loss:  0.4437459409236908\n",
      "Eval Loss:  0.48688599467277527\n",
      "Eval Loss:  0.41910967230796814\n",
      "Eval Loss:  0.29224008321762085\n",
      "Eval Loss:  0.3979519009590149\n",
      "Eval Loss:  0.49495169520378113\n",
      "Eval Loss:  0.4581269919872284\n",
      "Eval Loss:  0.4435819685459137\n",
      "Eval Loss:  0.44088417291641235\n",
      "Eval Loss:  0.33765947818756104\n",
      "Eval Loss:  0.4435696005821228\n",
      "Eval Loss:  0.35120272636413574\n",
      "Eval Loss:  0.44085901975631714\n",
      "Eval Loss:  0.37510085105895996\n",
      "Eval Loss:  0.2635440528392792\n",
      "Eval Loss:  0.38445258140563965\n",
      "Eval Loss:  0.39912688732147217\n",
      "Eval Loss:  0.3776989281177521\n",
      "Eval Loss:  0.43722212314605713\n",
      "Eval Loss:  0.4839508831501007\n",
      "Eval Loss:  0.34759965538978577\n",
      "Eval Loss:  0.5176666378974915\n",
      "[[16864  1549]\n",
      " [ 3514  7944]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87     18413\n",
      "           1       0.84      0.69      0.76     11458\n",
      "\n",
      "    accuracy                           0.83     29871\n",
      "   macro avg       0.83      0.80      0.81     29871\n",
      "weighted avg       0.83      0.83      0.83     29871\n",
      "\n",
      "acc:  0.8305045026949215\n",
      "pre:  0.836827135784262\n",
      "rec:  0.6933147146098796\n",
      "ma F1:  0.8139104623390614\n",
      "mi F1:  0.8305045026949215\n",
      "we F1:  0.8268489769887257\n",
      "29871 467\n",
      "Loss:  0.11355791240930557\n",
      "Loss:  0.08597216010093689\n",
      "Loss:  0.10861577838659286\n",
      "3 **********\n",
      "Epoch:  268.7793381214142  fold:  10  kers:  128\n",
      "epoch:  4\n",
      "29871 467\n",
      "Loss:  0.07620258629322052\n",
      "Loss:  0.09240099042654037\n",
      "Loss:  0.10345178097486496\n",
      "4 **********\n",
      "Epoch:  322.6024258136749  fold:  10  kers:  128\n",
      "epoch:  5\n",
      "29871 467\n",
      "Loss:  0.06554698944091797\n",
      "Loss:  0.07825496792793274\n",
      "Loss:  0.11325103044509888\n",
      "5 **********\n",
      "Epoch:  376.25696444511414  fold:  10  kers:  128\n",
      "epoch:  6\n",
      "Eval Loss:  0.6887153387069702\n",
      "Eval Loss:  0.11785855889320374\n",
      "Eval Loss:  0.08270090818405151\n",
      "[[1680   71]\n",
      " [ 315  954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      1751\n",
      "           1       0.93      0.75      0.83      1269\n",
      "\n",
      "    accuracy                           0.87      3020\n",
      "   macro avg       0.89      0.86      0.86      3020\n",
      "weighted avg       0.88      0.87      0.87      3020\n",
      "\n",
      "acc:  0.8721854304635761\n",
      "pre:  0.9307317073170732\n",
      "rec:  0.75177304964539\n",
      "ma F1:  0.8643458573190073\n",
      "mi F1:  0.8721854304635761\n",
      "we F1:  0.8695506427951535\n",
      "Eval Loss:  0.4375956058502197\n",
      "Eval Loss:  0.4482804238796234\n",
      "Eval Loss:  0.4140259325504303\n",
      "Eval Loss:  0.3918023705482483\n",
      "Eval Loss:  0.4743547737598419\n",
      "Eval Loss:  0.4558534622192383\n",
      "Eval Loss:  0.3813246488571167\n",
      "Eval Loss:  0.47422078251838684\n",
      "Eval Loss:  0.5007345080375671\n",
      "Eval Loss:  0.4273664057254791\n",
      "Eval Loss:  0.2634941339492798\n",
      "Eval Loss:  0.3916841745376587\n",
      "Eval Loss:  0.5352717638015747\n",
      "Eval Loss:  0.48138511180877686\n",
      "Eval Loss:  0.4612961411476135\n",
      "Eval Loss:  0.47246214747428894\n",
      "Eval Loss:  0.30853167176246643\n",
      "Eval Loss:  0.43244796991348267\n",
      "Eval Loss:  0.35151585936546326\n",
      "Eval Loss:  0.48280245065689087\n",
      "Eval Loss:  0.46295616030693054\n",
      "Eval Loss:  0.3130508363246918\n",
      "Eval Loss:  0.37530064582824707\n",
      "Eval Loss:  0.41539299488067627\n",
      "Eval Loss:  0.40885716676712036\n",
      "Eval Loss:  0.43294933438301086\n",
      "Eval Loss:  0.5384649634361267\n",
      "Eval Loss:  0.39262720942497253\n",
      "Eval Loss:  0.6385032534599304\n",
      "[[17789   624]\n",
      " [ 4446  7012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88     18413\n",
      "           1       0.92      0.61      0.73     11458\n",
      "\n",
      "    accuracy                           0.83     29871\n",
      "   macro avg       0.86      0.79      0.80     29871\n",
      "weighted avg       0.85      0.83      0.82     29871\n",
      "\n",
      "acc:  0.8302701616952898\n",
      "pre:  0.9182818229439497\n",
      "rec:  0.6119741665212078\n",
      "ma F1:  0.8048710888838069\n",
      "mi F1:  0.8302701616952899\n",
      "we F1:  0.8212625291179966\n",
      "29871 467\n",
      "Loss:  0.08036522567272186\n",
      "Loss:  0.08480921387672424\n",
      "Loss:  0.07361403852701187\n",
      "6 **********\n",
      "Epoch:  470.5697910785675  fold:  10  kers:  128\n",
      "epoch:  7\n",
      "29871 467\n",
      "Loss:  0.0715254545211792\n",
      "Loss:  0.08028998970985413\n",
      "Loss:  0.09470324963331223\n",
      "7 **********\n",
      "Epoch:  524.1784522533417  fold:  10  kers:  128\n",
      "epoch:  8\n",
      "29871 467\n",
      "Loss:  0.09419558942317963\n",
      "Loss:  0.07790078222751617\n",
      "Loss:  0.11622852832078934\n",
      "8 **********\n",
      "Epoch:  580.6853640079498  fold:  10  kers:  128\n",
      "epoch:  9\n",
      "Eval Loss:  0.35226351022720337\n",
      "Eval Loss:  0.15489113330841064\n",
      "Eval Loss:  0.1188979372382164\n",
      "[[1650  101]\n",
      " [ 185 1084]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      1751\n",
      "           1       0.91      0.85      0.88      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.90      3020\n",
      "\n",
      "acc:  0.9052980132450331\n",
      "pre:  0.9147679324894514\n",
      "rec:  0.8542159180457053\n",
      "ma F1:  0.9018504907475462\n",
      "mi F1:  0.9052980132450331\n",
      "we F1:  0.9047863667966427\n",
      "update!  Acc:  0.9052980132450331\n",
      "Eval Loss:  0.3087415099143982\n",
      "Eval Loss:  0.34402063488960266\n",
      "Eval Loss:  0.2752540707588196\n",
      "Eval Loss:  0.30754896998405457\n",
      "Eval Loss:  0.32681840658187866\n",
      "Eval Loss:  0.33612602949142456\n",
      "Eval Loss:  0.3233843743801117\n",
      "Eval Loss:  0.33840319514274597\n",
      "Eval Loss:  0.26612019538879395\n",
      "Eval Loss:  0.29546913504600525\n",
      "Eval Loss:  0.1838461011648178\n",
      "Eval Loss:  0.3787214756011963\n",
      "Eval Loss:  0.38318371772766113\n",
      "Eval Loss:  0.38588833808898926\n",
      "Eval Loss:  0.29526203870773315\n",
      "Eval Loss:  0.2917422950267792\n",
      "Eval Loss:  0.22493571043014526\n",
      "Eval Loss:  0.3025851547718048\n",
      "Eval Loss:  0.25612446665763855\n",
      "Eval Loss:  0.3701646625995636\n",
      "Eval Loss:  0.28422942757606506\n",
      "Eval Loss:  0.22938115894794464\n",
      "Eval Loss:  0.2835792005062103\n",
      "Eval Loss:  0.29730886220932007\n",
      "Eval Loss:  0.28418561816215515\n",
      "Eval Loss:  0.3421531319618225\n",
      "Eval Loss:  0.32264071702957153\n",
      "Eval Loss:  0.30889514088630676\n",
      "Eval Loss:  0.4140040874481201\n",
      "[[17199  1214]\n",
      " [ 2626  8832]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     18413\n",
      "           1       0.88      0.77      0.82     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.87      0.85      0.86     29871\n",
      "weighted avg       0.87      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8714472230591543\n",
      "pre:  0.879155882938483\n",
      "rec:  0.7708151509862106\n",
      "ma F1:  0.860502454551568\n",
      "mi F1:  0.8714472230591543\n",
      "we F1:  0.8696002034424803\n",
      "29871 467\n",
      "Loss:  0.11163049191236496\n",
      "Loss:  0.06344287842512131\n",
      "Loss:  0.06863677501678467\n",
      "9 **********\n",
      "Epoch:  675.0031774044037  fold:  10  kers:  128\n",
      "epoch:  10\n",
      "29871 467\n",
      "Loss:  0.0715683102607727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.040043238550424576\n",
      "Loss:  0.07986024767160416\n",
      "10 **********\n",
      "Epoch:  728.6357753276825  fold:  10  kers:  128\n",
      "epoch:  11\n",
      "29871 467\n",
      "Loss:  0.09913235902786255\n",
      "Loss:  0.09670507162809372\n",
      "Loss:  0.058847907930612564\n",
      "11 **********\n",
      "Epoch:  782.324223279953  fold:  10  kers:  128\n",
      "epoch:  12\n",
      "Eval Loss:  0.4009101986885071\n",
      "Eval Loss:  0.11418996006250381\n",
      "Eval Loss:  0.06256453692913055\n",
      "[[1680   71]\n",
      " [ 249 1020]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      1751\n",
      "           1       0.93      0.80      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.88      0.89      3020\n",
      "weighted avg       0.90      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8940397350993378\n",
      "pre:  0.9349220898258478\n",
      "rec:  0.8037825059101655\n",
      "ma F1:  0.8887251289609434\n",
      "mi F1:  0.8940397350993377\n",
      "we F1:  0.89260640192868\n",
      "Eval Loss:  0.28547403216362\n",
      "Eval Loss:  0.33058688044548035\n",
      "Eval Loss:  0.27131617069244385\n",
      "Eval Loss:  0.28597187995910645\n",
      "Eval Loss:  0.34569135308265686\n",
      "Eval Loss:  0.3359415531158447\n",
      "Eval Loss:  0.28962013125419617\n",
      "Eval Loss:  0.3085220456123352\n",
      "Eval Loss:  0.27932503819465637\n",
      "Eval Loss:  0.29548877477645874\n",
      "Eval Loss:  0.18118725717067719\n",
      "Eval Loss:  0.34152519702911377\n",
      "Eval Loss:  0.3868750333786011\n",
      "Eval Loss:  0.3812219202518463\n",
      "Eval Loss:  0.2604830861091614\n",
      "Eval Loss:  0.3078373670578003\n",
      "Eval Loss:  0.27433884143829346\n",
      "Eval Loss:  0.2860465943813324\n",
      "Eval Loss:  0.24441799521446228\n",
      "Eval Loss:  0.37416309118270874\n",
      "Eval Loss:  0.3219276964664459\n",
      "Eval Loss:  0.2351638823747635\n",
      "Eval Loss:  0.26311060786247253\n",
      "Eval Loss:  0.3032401204109192\n",
      "Eval Loss:  0.2615792751312256\n",
      "Eval Loss:  0.2673557698726654\n",
      "Eval Loss:  0.3886934816837311\n",
      "Eval Loss:  0.31723418831825256\n",
      "Eval Loss:  0.40860825777053833\n",
      "[[17626   787]\n",
      " [ 2874  8584]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18413\n",
      "           1       0.92      0.75      0.82     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.89      0.85      0.87     29871\n",
      "weighted avg       0.88      0.88      0.87     29871\n",
      "\n",
      "acc:  0.8774396571925949\n",
      "pre:  0.9160175008003415\n",
      "rec:  0.7491708849711992\n",
      "ma F1:  0.8650768858033643\n",
      "mi F1:  0.8774396571925949\n",
      "we F1:  0.8745861840794203\n",
      "29871 467\n",
      "Loss:  0.08797754347324371\n",
      "Loss:  0.09941931813955307\n",
      "Loss:  0.05471453070640564\n",
      "12 **********\n",
      "Epoch:  876.6899080276489  fold:  10  kers:  128\n",
      "epoch:  13\n",
      "29871 467\n",
      "Loss:  0.052133843302726746\n",
      "Loss:  0.0687163770198822\n",
      "Loss:  0.09939263761043549\n",
      "13 **********\n",
      "Epoch:  930.4102711677551  fold:  10  kers:  128\n",
      "epoch:  14\n",
      "29871 467\n",
      "Loss:  0.06554818153381348\n",
      "Loss:  0.07125312089920044\n",
      "Loss:  0.08419162780046463\n",
      "14 **********\n",
      "Epoch:  984.1316306591034  fold:  10  kers:  128\n",
      "epoch:  15\n",
      "Eval Loss:  0.272930383682251\n",
      "Eval Loss:  0.11515472084283829\n",
      "Eval Loss:  0.051873017102479935\n",
      "[[1689   62]\n",
      " [ 180 1089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      1751\n",
      "           1       0.95      0.86      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9198675496688742\n",
      "pre:  0.946133796698523\n",
      "rec:  0.8581560283687943\n",
      "ma F1:  0.9165745856353591\n",
      "mi F1:  0.9198675496688743\n",
      "we F1:  0.9192199334089496\n",
      "update!  Acc:  0.9198675496688742\n",
      "Eval Loss:  0.2724457383155823\n",
      "Eval Loss:  0.33003878593444824\n",
      "Eval Loss:  0.25478073954582214\n",
      "Eval Loss:  0.2705182731151581\n",
      "Eval Loss:  0.3567866086959839\n",
      "Eval Loss:  0.3233703672885895\n",
      "Eval Loss:  0.30903470516204834\n",
      "Eval Loss:  0.33125728368759155\n",
      "Eval Loss:  0.2581140697002411\n",
      "Eval Loss:  0.29375070333480835\n",
      "Eval Loss:  0.17301319539546967\n",
      "Eval Loss:  0.3619966208934784\n",
      "Eval Loss:  0.37991830706596375\n",
      "Eval Loss:  0.3441718518733978\n",
      "Eval Loss:  0.28084853291511536\n",
      "Eval Loss:  0.2905689477920532\n",
      "Eval Loss:  0.24163818359375\n",
      "Eval Loss:  0.26547884941101074\n",
      "Eval Loss:  0.2569580674171448\n",
      "Eval Loss:  0.3800770342350006\n",
      "Eval Loss:  0.30177026987075806\n",
      "Eval Loss:  0.21413332223892212\n",
      "Eval Loss:  0.2835860848426819\n",
      "Eval Loss:  0.3098682165145874\n",
      "Eval Loss:  0.24346522986888885\n",
      "Eval Loss:  0.26189857721328735\n",
      "Eval Loss:  0.3544321656227112\n",
      "Eval Loss:  0.31087687611579895\n",
      "Eval Loss:  0.3806297481060028\n",
      "[[17707   706]\n",
      " [ 2990  8468]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18413\n",
      "           1       0.92      0.74      0.82     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.89      0.85      0.86     29871\n",
      "weighted avg       0.88      0.88      0.87     29871\n",
      "\n",
      "acc:  0.8762679521944361\n",
      "pre:  0.9230433834750381\n",
      "rec:  0.73904695409321\n",
      "ma F1:  0.8631790570119235\n",
      "mi F1:  0.8762679521944361\n",
      "we F1:  0.8730322084346289\n",
      "29871 467\n",
      "Loss:  0.05513880401849747\n",
      "Loss:  0.07023388147354126\n",
      "Loss:  0.056722648441791534\n",
      "15 **********\n",
      "Epoch:  1078.4773700237274  fold:  10  kers:  128\n",
      "epoch:  16\n",
      "29871 467\n",
      "Loss:  0.08367925137281418\n",
      "Loss:  0.06096120923757553\n",
      "Loss:  0.05753917247056961\n",
      "16 **********\n",
      "Epoch:  1132.1787831783295  fold:  10  kers:  128\n",
      "epoch:  17\n",
      "29871 467\n",
      "Loss:  0.07723128795623779\n",
      "Loss:  0.09107978641986847\n",
      "Loss:  0.0870244950056076\n",
      "17 **********\n",
      "Epoch:  1185.8782019615173  fold:  10  kers:  128\n",
      "epoch:  18\n",
      "Eval Loss:  0.3171815574169159\n",
      "Eval Loss:  0.10725842416286469\n",
      "Eval Loss:  0.022218121215701103\n",
      "[[1695   56]\n",
      " [ 189 1080]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      1751\n",
      "           1       0.95      0.85      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.93      0.91      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9188741721854304\n",
      "pre:  0.9507042253521126\n",
      "rec:  0.851063829787234\n",
      "ma F1:  0.9153643115128672\n",
      "mi F1:  0.9188741721854304\n",
      "we F1:  0.918115129145673\n",
      "Eval Loss:  0.2458970844745636\n",
      "Eval Loss:  0.33105331659317017\n",
      "Eval Loss:  0.2621668577194214\n",
      "Eval Loss:  0.29384949803352356\n",
      "Eval Loss:  0.3771724998950958\n",
      "Eval Loss:  0.33181920647621155\n",
      "Eval Loss:  0.28672006726264954\n",
      "Eval Loss:  0.32556501030921936\n",
      "Eval Loss:  0.2707361578941345\n",
      "Eval Loss:  0.274600088596344\n",
      "Eval Loss:  0.16622783243656158\n",
      "Eval Loss:  0.3058866262435913\n",
      "Eval Loss:  0.3396540582180023\n",
      "Eval Loss:  0.3279995322227478\n",
      "Eval Loss:  0.28051838278770447\n",
      "Eval Loss:  0.2906368374824524\n",
      "Eval Loss:  0.23326405882835388\n",
      "Eval Loss:  0.2598297894001007\n",
      "Eval Loss:  0.23356997966766357\n",
      "Eval Loss:  0.38227394223213196\n",
      "Eval Loss:  0.3260774612426758\n",
      "Eval Loss:  0.19840238988399506\n",
      "Eval Loss:  0.27909621596336365\n",
      "Eval Loss:  0.2763368487358093\n",
      "Eval Loss:  0.22592106461524963\n",
      "Eval Loss:  0.2430078238248825\n",
      "Eval Loss:  0.35219597816467285\n",
      "Eval Loss:  0.33504563570022583\n",
      "Eval Loss:  0.40622738003730774\n",
      "[[17867   546]\n",
      " [ 2968  8490]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     18413\n",
      "           1       0.94      0.74      0.83     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.90      0.86      0.87     29871\n",
      "weighted avg       0.89      0.88      0.88     29871\n",
      "\n",
      "acc:  0.8823608181848616\n",
      "pre:  0.9395750332005313\n",
      "rec:  0.7409670099493804\n",
      "ma F1:  0.8695009782028416\n",
      "mi F1:  0.8823608181848616\n",
      "we F1:  0.8790392299971199\n",
      "29871 467\n",
      "Loss:  0.06941337138414383\n",
      "Loss:  0.1468355357646942\n",
      "Loss:  0.10752759873867035\n",
      "18 **********\n",
      "Epoch:  1280.0873057842255  fold:  10  kers:  128\n",
      "epoch:  19\n",
      "29871 467\n",
      "Loss:  0.04967106506228447\n",
      "Loss:  0.04988173022866249\n",
      "Loss:  0.07938732206821442\n",
      "19 **********\n",
      "Epoch:  1333.785727262497  fold:  10  kers:  128\n",
      "epoch:  20\n",
      "29871 467\n",
      "Loss:  0.06928137689828873\n",
      "Loss:  0.05951252952218056\n",
      "Loss:  0.0683496817946434\n",
      "20 **********\n",
      "Epoch:  1387.570916891098  fold:  10  kers:  128\n",
      "epoch:  21\n",
      "Eval Loss:  0.12691029906272888\n",
      "Eval Loss:  0.21354174613952637\n",
      "Eval Loss:  0.032601047307252884\n",
      "[[1671   80]\n",
      " [ 125 1144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1751\n",
      "           1       0.93      0.90      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9321192052980133\n",
      "pre:  0.934640522875817\n",
      "rec:  0.9014972419227738\n",
      "ma F1:  0.9299872176630795\n",
      "mi F1:  0.9321192052980133\n",
      "we F1:  0.9319371570179905\n",
      "update!  Acc:  0.9321192052980133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23356159031391144\n",
      "Eval Loss:  0.3340109586715698\n",
      "Eval Loss:  0.20861387252807617\n",
      "Eval Loss:  0.24506796896457672\n",
      "Eval Loss:  0.27210450172424316\n",
      "Eval Loss:  0.2420024573802948\n",
      "Eval Loss:  0.2918214797973633\n",
      "Eval Loss:  0.28461921215057373\n",
      "Eval Loss:  0.17978468537330627\n",
      "Eval Loss:  0.26269403100013733\n",
      "Eval Loss:  0.15290097892284393\n",
      "Eval Loss:  0.27216970920562744\n",
      "Eval Loss:  0.33613818883895874\n",
      "Eval Loss:  0.33434122800827026\n",
      "Eval Loss:  0.25220179557800293\n",
      "Eval Loss:  0.23445484042167664\n",
      "Eval Loss:  0.22298328578472137\n",
      "Eval Loss:  0.20641465485095978\n",
      "Eval Loss:  0.19669567048549652\n",
      "Eval Loss:  0.3047233819961548\n",
      "Eval Loss:  0.2562330663204193\n",
      "Eval Loss:  0.17912191152572632\n",
      "Eval Loss:  0.24678455293178558\n",
      "Eval Loss:  0.27898719906806946\n",
      "Eval Loss:  0.2031799703836441\n",
      "Eval Loss:  0.19614621996879578\n",
      "Eval Loss:  0.2827785909175873\n",
      "Eval Loss:  0.2390580177307129\n",
      "Eval Loss:  0.2738487124443054\n",
      "[[17387  1026]\n",
      " [ 1959  9499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18413\n",
      "           1       0.90      0.83      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9000703022998895\n",
      "pre:  0.9025178147268409\n",
      "rec:  0.8290277535346483\n",
      "ma F1:  0.892579627663406\n",
      "mi F1:  0.9000703022998895\n",
      "we F1:  0.8991842983146159\n",
      "29871 467\n",
      "Loss:  0.07815724611282349\n",
      "Loss:  0.07428684085607529\n",
      "Loss:  0.0774720087647438\n",
      "21 **********\n",
      "Epoch:  1481.8478391170502  fold:  10  kers:  128\n",
      "epoch:  22\n",
      "29871 467\n",
      "Loss:  0.039811450988054276\n",
      "Loss:  0.04876675456762314\n",
      "Loss:  0.04663285240530968\n",
      "22 **********\n",
      "Epoch:  1535.5332946777344  fold:  10  kers:  128\n",
      "epoch:  23\n",
      "29871 467\n",
      "Loss:  0.02921661175787449\n",
      "Loss:  0.06518730521202087\n",
      "Loss:  0.0862792357802391\n",
      "23 **********\n",
      "Epoch:  1589.1658926010132  fold:  10  kers:  128\n",
      "epoch:  24\n",
      "Eval Loss:  0.14135882258415222\n",
      "Eval Loss:  0.24720972776412964\n",
      "Eval Loss:  0.04358265548944473\n",
      "[[1613  138]\n",
      " [  80 1189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      1751\n",
      "           1       0.90      0.94      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.92      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9278145695364238\n",
      "pre:  0.8960060286360211\n",
      "rec:  0.9369582348305753\n",
      "ma F1:  0.9263630815925152\n",
      "mi F1:  0.9278145695364238\n",
      "we F1:  0.9280131221325245\n",
      "Eval Loss:  0.23159366846084595\n",
      "Eval Loss:  0.305328369140625\n",
      "Eval Loss:  0.17217880487442017\n",
      "Eval Loss:  0.25565099716186523\n",
      "Eval Loss:  0.21057967841625214\n",
      "Eval Loss:  0.22714757919311523\n",
      "Eval Loss:  0.29738232493400574\n",
      "Eval Loss:  0.26355212926864624\n",
      "Eval Loss:  0.15036454796791077\n",
      "Eval Loss:  0.22521871328353882\n",
      "Eval Loss:  0.16129499673843384\n",
      "Eval Loss:  0.2507536709308624\n",
      "Eval Loss:  0.25214678049087524\n",
      "Eval Loss:  0.3181074261665344\n",
      "Eval Loss:  0.25392386317253113\n",
      "Eval Loss:  0.18427395820617676\n",
      "Eval Loss:  0.20099331438541412\n",
      "Eval Loss:  0.2028527557849884\n",
      "Eval Loss:  0.1751721054315567\n",
      "Eval Loss:  0.3154234290122986\n",
      "Eval Loss:  0.22053705155849457\n",
      "Eval Loss:  0.18402452766895294\n",
      "Eval Loss:  0.2341771423816681\n",
      "Eval Loss:  0.2227155715227127\n",
      "Eval Loss:  0.20551227033138275\n",
      "Eval Loss:  0.21299368143081665\n",
      "Eval Loss:  0.24788214266300201\n",
      "Eval Loss:  0.2649361491203308\n",
      "Eval Loss:  0.25976574420928955\n",
      "[[16825  1588]\n",
      " [ 1269 10189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     18413\n",
      "           1       0.87      0.89      0.88     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.90      0.90     29871\n",
      "weighted avg       0.91      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9043553948645844\n",
      "pre:  0.8651609068523393\n",
      "rec:  0.889247687205446\n",
      "ma F1:  0.899389992912915\n",
      "mi F1:  0.9043553948645844\n",
      "we F1:  0.9045940873333279\n",
      "29871 467\n",
      "Loss:  0.07789283990859985\n",
      "Loss:  0.0375230498611927\n",
      "Loss:  0.07165402173995972\n",
      "24 **********\n",
      "Epoch:  1683.319146156311  fold:  10  kers:  128\n",
      "epoch:  25\n",
      "29871 467\n",
      "Loss:  0.05719348043203354\n",
      "Loss:  0.05494843050837517\n",
      "Loss:  0.045808836817741394\n",
      "25 **********\n",
      "Epoch:  1738.0866084098816  fold:  10  kers:  128\n",
      "epoch:  26\n",
      "29871 467\n",
      "Loss:  0.056954700499773026\n",
      "Loss:  0.05078229680657387\n",
      "Loss:  0.05354492366313934\n",
      "26 **********\n",
      "Epoch:  1791.9346296787262  fold:  10  kers:  128\n",
      "epoch:  27\n",
      "Eval Loss:  0.2043963372707367\n",
      "Eval Loss:  0.18459750711917877\n",
      "Eval Loss:  0.028542624786496162\n",
      "[[1649  102]\n",
      " [  96 1173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1751\n",
      "           1       0.92      0.92      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9344370860927153\n",
      "pre:  0.92\n",
      "rec:  0.9243498817966903\n",
      "ma F1:  0.9327668278571737\n",
      "mi F1:  0.9344370860927153\n",
      "we F1:  0.9344581397679531\n",
      "update!  Acc:  0.9344370860927153\n",
      "Eval Loss:  0.21567729115486145\n",
      "Eval Loss:  0.28884947299957275\n",
      "Eval Loss:  0.17440399527549744\n",
      "Eval Loss:  0.23696506023406982\n",
      "Eval Loss:  0.22346094250679016\n",
      "Eval Loss:  0.21927572786808014\n",
      "Eval Loss:  0.2477908730506897\n",
      "Eval Loss:  0.2426580935716629\n",
      "Eval Loss:  0.14361684024333954\n",
      "Eval Loss:  0.20511676371097565\n",
      "Eval Loss:  0.1265932023525238\n",
      "Eval Loss:  0.23992224037647247\n",
      "Eval Loss:  0.25352704524993896\n",
      "Eval Loss:  0.28283780813217163\n",
      "Eval Loss:  0.24574802815914154\n",
      "Eval Loss:  0.15937557816505432\n",
      "Eval Loss:  0.18586745858192444\n",
      "Eval Loss:  0.1896628886461258\n",
      "Eval Loss:  0.15167079865932465\n",
      "Eval Loss:  0.29642459750175476\n",
      "Eval Loss:  0.22042801976203918\n",
      "Eval Loss:  0.14843319356441498\n",
      "Eval Loss:  0.19574132561683655\n",
      "Eval Loss:  0.22256113588809967\n",
      "Eval Loss:  0.18568331003189087\n",
      "Eval Loss:  0.20079363882541656\n",
      "Eval Loss:  0.2223774492740631\n",
      "Eval Loss:  0.239399254322052\n",
      "Eval Loss:  0.1970522701740265\n",
      "[[17295  1118]\n",
      " [ 1556  9902]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18413\n",
      "           1       0.90      0.86      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9104817381406716\n",
      "pre:  0.8985480943738657\n",
      "rec:  0.8641996858090417\n",
      "ma F1:  0.9046404865082336\n",
      "mi F1:  0.9104817381406716\n",
      "we F1:  0.9101356718326764\n",
      "29871 467\n",
      "Loss:  0.05982707440853119\n",
      "Loss:  0.06232929229736328\n",
      "Loss:  0.04590431600809097\n",
      "27 **********\n",
      "Epoch:  1886.3312323093414  fold:  10  kers:  128\n",
      "epoch:  28\n",
      "29871 467\n",
      "Loss:  0.04252305626869202\n",
      "Loss:  0.10689825564622879\n",
      "Loss:  0.07279301434755325\n",
      "28 **********\n",
      "Epoch:  1940.0954778194427  fold:  10  kers:  128\n",
      "epoch:  29\n",
      "29871 467\n",
      "Loss:  0.06445109844207764\n",
      "Loss:  0.05255941301584244\n",
      "Loss:  0.06566347181797028\n",
      "29 **********\n",
      "Epoch:  1994.0651738643646  fold:  10  kers:  128\n",
      "epoch:  30\n",
      "Eval Loss:  0.22737102210521698\n",
      "Eval Loss:  0.1707247793674469\n",
      "Eval Loss:  0.021970078349113464\n",
      "[[1647  104]\n",
      " [  88 1181]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      1751\n",
      "           1       0.92      0.93      0.92      1269\n",
      "\n",
      "    accuracy                           0.94      3020\n",
      "   macro avg       0.93      0.94      0.93      3020\n",
      "weighted avg       0.94      0.94      0.94      3020\n",
      "\n",
      "acc:  0.9364238410596026\n",
      "pre:  0.9190661478599221\n",
      "rec:  0.9306540583136328\n",
      "ma F1:  0.9348731765635088\n",
      "mi F1:  0.9364238410596026\n",
      "we F1:  0.9364770827590394\n",
      "update!  Acc:  0.9364238410596026\n",
      "Eval Loss:  0.20769254863262177\n",
      "Eval Loss:  0.29571816325187683\n",
      "Eval Loss:  0.18110591173171997\n",
      "Eval Loss:  0.2409488409757614\n",
      "Eval Loss:  0.2304684817790985\n",
      "Eval Loss:  0.2079179883003235\n",
      "Eval Loss:  0.27360230684280396\n",
      "Eval Loss:  0.2620644271373749\n",
      "Eval Loss:  0.156946063041687\n",
      "Eval Loss:  0.18791069090366364\n",
      "Eval Loss:  0.14310340583324432\n",
      "Eval Loss:  0.26232990622520447\n",
      "Eval Loss:  0.24559922516345978\n",
      "Eval Loss:  0.29884645342826843\n",
      "Eval Loss:  0.26296621561050415\n",
      "Eval Loss:  0.13565778732299805\n",
      "Eval Loss:  0.18371498584747314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2014511376619339\n",
      "Eval Loss:  0.17008012533187866\n",
      "Eval Loss:  0.309742271900177\n",
      "Eval Loss:  0.21680934727191925\n",
      "Eval Loss:  0.17185723781585693\n",
      "Eval Loss:  0.19563530385494232\n",
      "Eval Loss:  0.21280328929424286\n",
      "Eval Loss:  0.17992419004440308\n",
      "Eval Loss:  0.21487507224082947\n",
      "Eval Loss:  0.21681171655654907\n",
      "Eval Loss:  0.24812544882297516\n",
      "Eval Loss:  0.22701770067214966\n",
      "[[17259  1154]\n",
      " [ 1574  9884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18413\n",
      "           1       0.90      0.86      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9086739647149409\n",
      "pre:  0.8954520746512049\n",
      "rec:  0.8626287310176296\n",
      "ma F1:  0.902745616415682\n",
      "mi F1:  0.9086739647149409\n",
      "we F1:  0.908336350303322\n",
      "29871 467\n",
      "Loss:  0.0718466266989708\n",
      "Loss:  0.06471309065818787\n",
      "Loss:  0.06030575931072235\n",
      "30 **********\n",
      "Epoch:  2088.181526184082  fold:  10  kers:  128\n",
      "epoch:  31\n",
      "29871 467\n",
      "Loss:  0.05984656885266304\n",
      "Loss:  0.0513288676738739\n",
      "Loss:  0.05185317248106003\n",
      "31 **********\n",
      "Epoch:  2141.8789498806  fold:  10  kers:  128\n",
      "epoch:  32\n",
      "29871 467\n",
      "Loss:  0.0601920560002327\n",
      "Loss:  0.061087533831596375\n",
      "Loss:  0.06321574002504349\n",
      "32 **********\n",
      "Epoch:  2195.5125448703766  fold:  10  kers:  128\n",
      "epoch:  33\n",
      "Eval Loss:  0.20219027996063232\n",
      "Eval Loss:  0.18033507466316223\n",
      "Eval Loss:  0.02925863303244114\n",
      "[[1634  117]\n",
      " [  88 1181]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1751\n",
      "           1       0.91      0.93      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9321192052980133\n",
      "pre:  0.9098613251155624\n",
      "rec:  0.9306540583136328\n",
      "ma F1:  0.9305567317626733\n",
      "mi F1:  0.9321192052980133\n",
      "we F1:  0.9322192311976266\n",
      "Eval Loss:  0.21436801552772522\n",
      "Eval Loss:  0.28270822763442993\n",
      "Eval Loss:  0.17635896801948547\n",
      "Eval Loss:  0.25089210271835327\n",
      "Eval Loss:  0.2106955647468567\n",
      "Eval Loss:  0.19871141016483307\n",
      "Eval Loss:  0.2543007731437683\n",
      "Eval Loss:  0.24348312616348267\n",
      "Eval Loss:  0.14656035602092743\n",
      "Eval Loss:  0.1959610879421234\n",
      "Eval Loss:  0.1400967836380005\n",
      "Eval Loss:  0.2227407991886139\n",
      "Eval Loss:  0.23758068680763245\n",
      "Eval Loss:  0.2601187825202942\n",
      "Eval Loss:  0.2690400779247284\n",
      "Eval Loss:  0.1182544156908989\n",
      "Eval Loss:  0.19988559186458588\n",
      "Eval Loss:  0.1948401778936386\n",
      "Eval Loss:  0.13052122294902802\n",
      "Eval Loss:  0.3010534942150116\n",
      "Eval Loss:  0.2072995901107788\n",
      "Eval Loss:  0.15886850655078888\n",
      "Eval Loss:  0.19687654078006744\n",
      "Eval Loss:  0.1930622011423111\n",
      "Eval Loss:  0.21201437711715698\n",
      "Eval Loss:  0.20311765372753143\n",
      "Eval Loss:  0.22432176768779755\n",
      "Eval Loss:  0.25551193952560425\n",
      "Eval Loss:  0.23186451196670532\n",
      "[[17028  1385]\n",
      " [ 1301 10157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     18413\n",
      "           1       0.88      0.89      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.90      0.91      0.91     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9100800107127314\n",
      "pre:  0.8800034656038814\n",
      "rec:  0.88645487868738\n",
      "ma F1:  0.9050565210291267\n",
      "mi F1:  0.9100800107127314\n",
      "we F1:  0.9101414243546208\n",
      "29871 467\n",
      "Loss:  0.06005866825580597\n",
      "Loss:  0.05347535014152527\n",
      "Loss:  0.055802181363105774\n",
      "33 **********\n",
      "Epoch:  2289.792459487915  fold:  10  kers:  128\n",
      "epoch:  34\n",
      "29871 467\n",
      "Loss:  0.044803645461797714\n",
      "Loss:  0.019517866894602776\n",
      "Loss:  0.0623367503285408\n",
      "34 **********\n",
      "Epoch:  2343.545734167099  fold:  10  kers:  128\n",
      "epoch:  35\n",
      "29871 467\n",
      "Loss:  0.04077545180916786\n",
      "Loss:  0.030347242951393127\n",
      "Loss:  0.045508306473493576\n",
      "35 **********\n",
      "Epoch:  2397.17932844162  fold:  10  kers:  128\n",
      "epoch:  36\n",
      "Eval Loss:  0.32514017820358276\n",
      "Eval Loss:  0.17084750533103943\n",
      "Eval Loss:  0.02289338782429695\n",
      "[[1650  101]\n",
      " [ 106 1163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1751\n",
      "           1       0.92      0.92      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9314569536423841\n",
      "pre:  0.9200949367088608\n",
      "rec:  0.9164696611505122\n",
      "ma F1:  0.9296269566782627\n",
      "mi F1:  0.9314569536423841\n",
      "we F1:  0.9314381651725265\n",
      "Eval Loss:  0.18916212022304535\n",
      "Eval Loss:  0.22852522134780884\n",
      "Eval Loss:  0.14396068453788757\n",
      "Eval Loss:  0.24817484617233276\n",
      "Eval Loss:  0.21717984974384308\n",
      "Eval Loss:  0.14773236215114594\n",
      "Eval Loss:  0.24031729996204376\n",
      "Eval Loss:  0.23183497786521912\n",
      "Eval Loss:  0.12031437456607819\n",
      "Eval Loss:  0.1778145134449005\n",
      "Eval Loss:  0.14565296471118927\n",
      "Eval Loss:  0.1919458508491516\n",
      "Eval Loss:  0.2003859132528305\n",
      "Eval Loss:  0.26210466027259827\n",
      "Eval Loss:  0.24618841707706451\n",
      "Eval Loss:  0.13056066632270813\n",
      "Eval Loss:  0.1537943035364151\n",
      "Eval Loss:  0.18107019364833832\n",
      "Eval Loss:  0.1435529887676239\n",
      "Eval Loss:  0.24010610580444336\n",
      "Eval Loss:  0.1984051764011383\n",
      "Eval Loss:  0.13681115210056305\n",
      "Eval Loss:  0.19474129378795624\n",
      "Eval Loss:  0.18348100781440735\n",
      "Eval Loss:  0.1859171837568283\n",
      "Eval Loss:  0.17726373672485352\n",
      "Eval Loss:  0.2192486822605133\n",
      "Eval Loss:  0.24178798496723175\n",
      "Eval Loss:  0.1947905272245407\n",
      "[[17115  1298]\n",
      " [ 1162 10296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18413\n",
      "           1       0.89      0.90      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9176458772722708\n",
      "pre:  0.888045540796964\n",
      "rec:  0.8985861406877291\n",
      "ma F1:  0.9131182527497645\n",
      "mi F1:  0.9176458772722708\n",
      "we F1:  0.9177361774533914\n",
      "29871 467\n",
      "Loss:  0.0519024059176445\n",
      "Loss:  0.04529475420713425\n",
      "Loss:  0.06296133249998093\n",
      "36 **********\n",
      "Epoch:  2491.3495366573334  fold:  10  kers:  128\n",
      "epoch:  37\n",
      "29871 467\n",
      "Loss:  0.05827829986810684\n",
      "Loss:  0.04875440523028374\n",
      "Loss:  0.06005118042230606\n",
      "37 **********\n",
      "Epoch:  2544.9711635112762  fold:  10  kers:  128\n",
      "epoch:  38\n",
      "29871 467\n",
      "Loss:  0.07704424113035202\n",
      "Loss:  0.06924184411764145\n",
      "Loss:  0.0760105699300766\n",
      "38 **********\n",
      "Epoch:  2598.7942514419556  fold:  10  kers:  128\n",
      "epoch:  39\n",
      "Eval Loss:  0.24498869478702545\n",
      "Eval Loss:  0.15329459309577942\n",
      "Eval Loss:  0.02127113752067089\n",
      "[[1631  120]\n",
      " [  98 1171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      1751\n",
      "           1       0.91      0.92      0.91      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9278145695364238\n",
      "pre:  0.9070487993803253\n",
      "rec:  0.9227738376674547\n",
      "ma F1:  0.9261000359195404\n",
      "mi F1:  0.9278145695364238\n",
      "we F1:  0.927896568970275\n",
      "Eval Loss:  0.17489099502563477\n",
      "Eval Loss:  0.2514911890029907\n",
      "Eval Loss:  0.15177534520626068\n",
      "Eval Loss:  0.222177192568779\n",
      "Eval Loss:  0.2202901691198349\n",
      "Eval Loss:  0.16182169318199158\n",
      "Eval Loss:  0.2519797384738922\n",
      "Eval Loss:  0.221856027841568\n",
      "Eval Loss:  0.11456584930419922\n",
      "Eval Loss:  0.17428243160247803\n",
      "Eval Loss:  0.12920710444450378\n",
      "Eval Loss:  0.16873864829540253\n",
      "Eval Loss:  0.19119508564472198\n",
      "Eval Loss:  0.26039600372314453\n",
      "Eval Loss:  0.2270616888999939\n",
      "Eval Loss:  0.12284952402114868\n",
      "Eval Loss:  0.16903193295001984\n",
      "Eval Loss:  0.18367108702659607\n",
      "Eval Loss:  0.14074090123176575\n",
      "Eval Loss:  0.21138416230678558\n",
      "Eval Loss:  0.19711345434188843\n",
      "Eval Loss:  0.12903288006782532\n",
      "Eval Loss:  0.19929832220077515\n",
      "Eval Loss:  0.1537921279668808\n",
      "Eval Loss:  0.16648752987384796\n",
      "Eval Loss:  0.16317175328731537\n",
      "Eval Loss:  0.2020568996667862\n",
      "Eval Loss:  0.20672573149204254\n",
      "Eval Loss:  0.18591246008872986\n",
      "[[17236  1177]\n",
      " [ 1125 10333]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18413\n",
      "           1       0.90      0.90      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9229352884068159\n",
      "pre:  0.8977410947002606\n",
      "rec:  0.9018153255367429\n",
      "ma F1:  0.9185875114846203\n",
      "mi F1:  0.9229352884068159\n",
      "we F1:  0.9229680400220492\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.04784002900123596\n",
      "Loss:  0.048557765781879425\n",
      "Loss:  0.060728155076503754\n",
      "39 **********\n",
      "Epoch:  2693.024299144745  fold:  10  kers:  128\n",
      "epoch:  40\n",
      "29871 467\n",
      "Loss:  0.032129306346178055\n",
      "Loss:  0.055251289159059525\n",
      "Loss:  0.04859500750899315\n",
      "40 **********\n",
      "Epoch:  2746.701776742935  fold:  10  kers:  128\n",
      "epoch:  41\n",
      "29871 467\n",
      "Loss:  0.04568713158369064\n",
      "Loss:  0.07170258462429047\n",
      "Loss:  0.07599787414073944\n",
      "41 **********\n",
      "Epoch:  2800.3692803382874  fold:  10  kers:  128\n",
      "epoch:  42\n",
      "Eval Loss:  0.3813977837562561\n",
      "Eval Loss:  0.12928548455238342\n",
      "Eval Loss:  0.02161078155040741\n",
      "[[1648  103]\n",
      " [ 114 1155]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1751\n",
      "           1       0.92      0.91      0.91      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9281456953642384\n",
      "pre:  0.9181240063593005\n",
      "rec:  0.9101654846335697\n",
      "ma F1:  0.926178428677654\n",
      "mi F1:  0.9281456953642384\n",
      "we F1:  0.9281018009756938\n",
      "Eval Loss:  0.18858587741851807\n",
      "Eval Loss:  0.2399352788925171\n",
      "Eval Loss:  0.16515493392944336\n",
      "Eval Loss:  0.2096761018037796\n",
      "Eval Loss:  0.22667478024959564\n",
      "Eval Loss:  0.17133329808712006\n",
      "Eval Loss:  0.21111935377120972\n",
      "Eval Loss:  0.21685181558132172\n",
      "Eval Loss:  0.13628098368644714\n",
      "Eval Loss:  0.16788826882839203\n",
      "Eval Loss:  0.12431943416595459\n",
      "Eval Loss:  0.18068349361419678\n",
      "Eval Loss:  0.19271281361579895\n",
      "Eval Loss:  0.2342776656150818\n",
      "Eval Loss:  0.24898141622543335\n",
      "Eval Loss:  0.10900043696165085\n",
      "Eval Loss:  0.17258821427822113\n",
      "Eval Loss:  0.20728954672813416\n",
      "Eval Loss:  0.13606715202331543\n",
      "Eval Loss:  0.23385722935199738\n",
      "Eval Loss:  0.20120754837989807\n",
      "Eval Loss:  0.13508370518684387\n",
      "Eval Loss:  0.18612712621688843\n",
      "Eval Loss:  0.16674958169460297\n",
      "Eval Loss:  0.17434343695640564\n",
      "Eval Loss:  0.18858949840068817\n",
      "Eval Loss:  0.21161219477653503\n",
      "Eval Loss:  0.26829251646995544\n",
      "Eval Loss:  0.18866470456123352\n",
      "[[17329  1084]\n",
      " [ 1323 10135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18413\n",
      "           1       0.90      0.88      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9194201734123397\n",
      "pre:  0.9033781977003298\n",
      "rec:  0.8845348228312097\n",
      "ma F1:  0.9144586209154382\n",
      "mi F1:  0.9194201734123397\n",
      "we F1:  0.9192553400725066\n",
      "29871 467\n",
      "Loss:  0.061566006392240524\n",
      "Loss:  0.032786816358566284\n",
      "Loss:  0.05456206947565079\n",
      "42 **********\n",
      "Epoch:  2894.750923395157  fold:  10  kers:  128\n",
      "epoch:  43\n",
      "29871 467\n",
      "Loss:  0.07934299856424332\n",
      "Loss:  0.05844774469733238\n",
      "Loss:  0.09240787476301193\n",
      "43 **********\n",
      "Epoch:  2948.448347568512  fold:  10  kers:  128\n",
      "epoch:  44\n",
      "29871 467\n",
      "Loss:  0.051740095019340515\n",
      "Loss:  0.08675548434257507\n",
      "Loss:  0.0659060925245285\n",
      "44 **********\n",
      "Epoch:  3002.099893808365  fold:  10  kers:  128\n",
      "epoch:  45\n",
      "Eval Loss:  0.3008885085582733\n",
      "Eval Loss:  0.13814643025398254\n",
      "Eval Loss:  0.019963694736361504\n",
      "[[1579  172]\n",
      " [  96 1173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1751\n",
      "           1       0.87      0.92      0.90      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9112582781456954\n",
      "pre:  0.8721189591078067\n",
      "rec:  0.9243498817966903\n",
      "ma F1:  0.9096248991129983\n",
      "mi F1:  0.9112582781456954\n",
      "we F1:  0.9115640338266928\n",
      "Eval Loss:  0.17848807573318481\n",
      "Eval Loss:  0.25405651330947876\n",
      "Eval Loss:  0.13217534124851227\n",
      "Eval Loss:  0.21297281980514526\n",
      "Eval Loss:  0.22390252351760864\n",
      "Eval Loss:  0.15318235754966736\n",
      "Eval Loss:  0.2384117692708969\n",
      "Eval Loss:  0.2159799188375473\n",
      "Eval Loss:  0.0919158011674881\n",
      "Eval Loss:  0.16337746381759644\n",
      "Eval Loss:  0.13566938042640686\n",
      "Eval Loss:  0.15982811152935028\n",
      "Eval Loss:  0.1657225638628006\n",
      "Eval Loss:  0.2475176453590393\n",
      "Eval Loss:  0.25693780183792114\n",
      "Eval Loss:  0.10768262296915054\n",
      "Eval Loss:  0.15739838778972626\n",
      "Eval Loss:  0.20916421711444855\n",
      "Eval Loss:  0.13403744995594025\n",
      "Eval Loss:  0.2148505598306656\n",
      "Eval Loss:  0.20245561003684998\n",
      "Eval Loss:  0.12684020400047302\n",
      "Eval Loss:  0.20464839041233063\n",
      "Eval Loss:  0.1447296142578125\n",
      "Eval Loss:  0.16679301857948303\n",
      "Eval Loss:  0.1715487390756607\n",
      "Eval Loss:  0.20807231962680817\n",
      "Eval Loss:  0.21014901995658875\n",
      "Eval Loss:  0.18669749796390533\n",
      "[[17195  1218]\n",
      " [ 1054 10404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18413\n",
      "           1       0.90      0.91      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9239396069766663\n",
      "pre:  0.895198760970573\n",
      "rec:  0.9080118694362018\n",
      "ma F1:  0.9197941341896327\n",
      "mi F1:  0.9239396069766663\n",
      "we F1:  0.9240397185268173\n",
      "29871 467\n",
      "Loss:  0.04709916189312935\n",
      "Loss:  0.05513090640306473\n",
      "Loss:  0.08699163794517517\n",
      "45 **********\n",
      "Epoch:  3096.236192703247  fold:  10  kers:  128\n",
      "epoch:  46\n",
      "29871 467\n",
      "Loss:  0.05211763083934784\n",
      "Loss:  0.09054438769817352\n",
      "Loss:  0.05562039464712143\n",
      "46 **********\n",
      "Epoch:  3149.88973402977  fold:  10  kers:  128\n",
      "epoch:  47\n",
      "29871 467\n",
      "Loss:  0.059746671468019485\n",
      "Loss:  0.08831918239593506\n",
      "Loss:  0.05129284784197807\n",
      "47 **********\n",
      "Epoch:  3203.613088607788  fold:  10  kers:  128\n",
      "epoch:  48\n",
      "Eval Loss:  0.5345717668533325\n",
      "Eval Loss:  0.11982014775276184\n",
      "Eval Loss:  0.027920838445425034\n",
      "[[1610  141]\n",
      " [ 124 1145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      1751\n",
      "           1       0.89      0.90      0.90      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9122516556291391\n",
      "pre:  0.890357698289269\n",
      "rec:  0.9022852639873916\n",
      "ma F1:  0.9101208141124809\n",
      "mi F1:  0.9122516556291391\n",
      "we F1:  0.9123295573620062\n",
      "Eval Loss:  0.1889313906431198\n",
      "Eval Loss:  0.22569328546524048\n",
      "Eval Loss:  0.14733828604221344\n",
      "Eval Loss:  0.2067366987466812\n",
      "Eval Loss:  0.21825382113456726\n",
      "Eval Loss:  0.12807130813598633\n",
      "Eval Loss:  0.2399742156267166\n",
      "Eval Loss:  0.1842808723449707\n",
      "Eval Loss:  0.08939830958843231\n",
      "Eval Loss:  0.14922761917114258\n",
      "Eval Loss:  0.1510949283838272\n",
      "Eval Loss:  0.15855075418949127\n",
      "Eval Loss:  0.16272711753845215\n",
      "Eval Loss:  0.24762925505638123\n",
      "Eval Loss:  0.23560771346092224\n",
      "Eval Loss:  0.09247296303510666\n",
      "Eval Loss:  0.17567671835422516\n",
      "Eval Loss:  0.1737840175628662\n",
      "Eval Loss:  0.14015954732894897\n",
      "Eval Loss:  0.18453238904476166\n",
      "Eval Loss:  0.17820577323436737\n",
      "Eval Loss:  0.1313500851392746\n",
      "Eval Loss:  0.18012814223766327\n",
      "Eval Loss:  0.1626858115196228\n",
      "Eval Loss:  0.18217934668064117\n",
      "Eval Loss:  0.1807965636253357\n",
      "Eval Loss:  0.18501496315002441\n",
      "Eval Loss:  0.20247392356395721\n",
      "Eval Loss:  0.16404838860034943\n",
      "[[17111  1302]\n",
      " [  913 10545]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18413\n",
      "           1       0.89      0.92      0.90     11458\n",
      "\n",
      "    accuracy                           0.93     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.93      0.93      0.93     29871\n",
      "\n",
      "acc:  0.9258478122593821\n",
      "pre:  0.8900987591795392\n",
      "rec:  0.92031768196893\n",
      "ma F1:  0.9220830807786505\n",
      "mi F1:  0.9258478122593821\n",
      "we F1:  0.9260708522450666\n",
      "29871 467\n",
      "Loss:  0.05771452188491821\n",
      "Loss:  0.053527940064668655\n",
      "Loss:  0.07219728082418442\n",
      "48 **********\n",
      "Epoch:  3297.7214615345  fold:  10  kers:  128\n",
      "epoch:  49\n",
      "29871 467\n",
      "Loss:  0.0634804517030716\n",
      "Loss:  0.03125109151005745\n",
      "Loss:  0.0694878026843071\n",
      "49 **********\n",
      "Epoch:  3351.411904811859  fold:  10  kers:  128\n",
      "epoch:  50\n",
      "29871 467\n",
      "Loss:  0.04629183188080788\n",
      "Loss:  0.0581354945898056\n",
      "Loss:  0.04051800072193146\n",
      "50 **********\n",
      "Epoch:  3405.0464963912964  fold:  10  kers:  128\n",
      "epoch:  51\n",
      "Eval Loss:  0.41974255442619324\n",
      "Eval Loss:  0.1321500539779663\n",
      "Eval Loss:  0.015319544821977615\n",
      "[[1640  111]\n",
      " [ 113 1156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1751\n",
      "           1       0.91      0.91      0.91      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.92      0.92      0.92      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9258278145695364\n",
      "pre:  0.9123914759273876\n",
      "rec:  0.9109535066981875\n",
      "ma F1:  0.9238724918254757\n",
      "mi F1:  0.9258278145695363\n",
      "we F1:  0.9258197347234866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17408375442028046\n",
      "Eval Loss:  0.23634961247444153\n",
      "Eval Loss:  0.14429320394992828\n",
      "Eval Loss:  0.23318523168563843\n",
      "Eval Loss:  0.20993231236934662\n",
      "Eval Loss:  0.12740099430084229\n",
      "Eval Loss:  0.21241699159145355\n",
      "Eval Loss:  0.196391299366951\n",
      "Eval Loss:  0.08012104034423828\n",
      "Eval Loss:  0.1473412960767746\n",
      "Eval Loss:  0.14938777685165405\n",
      "Eval Loss:  0.12901736795902252\n",
      "Eval Loss:  0.18273676931858063\n",
      "Eval Loss:  0.2636982798576355\n",
      "Eval Loss:  0.21582531929016113\n",
      "Eval Loss:  0.10781903564929962\n",
      "Eval Loss:  0.1469832956790924\n",
      "Eval Loss:  0.17715834081172943\n",
      "Eval Loss:  0.12792454659938812\n",
      "Eval Loss:  0.20314405858516693\n",
      "Eval Loss:  0.18282532691955566\n",
      "Eval Loss:  0.13016141951084137\n",
      "Eval Loss:  0.21418790519237518\n",
      "Eval Loss:  0.1598609983921051\n",
      "Eval Loss:  0.17524868249893188\n",
      "Eval Loss:  0.15612134337425232\n",
      "Eval Loss:  0.20981614291667938\n",
      "Eval Loss:  0.1935313493013382\n",
      "Eval Loss:  0.1723049432039261\n",
      "[[17183  1230]\n",
      " [  969 10489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18413\n",
      "           1       0.90      0.92      0.91     11458\n",
      "\n",
      "    accuracy                           0.93     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.93      0.93      0.93     29871\n",
      "\n",
      "acc:  0.9263834488299688\n",
      "pre:  0.8950422390988992\n",
      "rec:  0.9154302670623146\n",
      "ma F1:  0.9224909894869595\n",
      "mi F1:  0.9263834488299688\n",
      "we F1:  0.9265352163663486\n",
      "29871 467\n",
      "Loss:  0.04999879002571106\n",
      "Loss:  0.07543446123600006\n",
      "Loss:  0.04126378521323204\n",
      "51 **********\n",
      "Epoch:  3499.3323953151703  fold:  10  kers:  128\n",
      "epoch:  52\n",
      "29871 467\n",
      "Loss:  0.08045786619186401\n",
      "Loss:  0.05006027966737747\n",
      "Loss:  0.07305824756622314\n",
      "52 **********\n",
      "Epoch:  3553.0278248786926  fold:  10  kers:  128\n",
      "epoch:  53\n",
      "29871 467\n",
      "Loss:  0.06656495481729507\n",
      "Loss:  0.056966185569763184\n",
      "Loss:  0.038047682493925095\n",
      "53 **********\n",
      "Epoch:  3606.6324968338013  fold:  10  kers:  128\n",
      "epoch:  54\n",
      "Eval Loss:  0.3214379847049713\n",
      "Eval Loss:  0.1340470314025879\n",
      "Eval Loss:  0.031518761068582535\n",
      "[[1582  169]\n",
      " [  97 1172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1751\n",
      "           1       0.87      0.92      0.90      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9119205298013245\n",
      "pre:  0.8739746457867263\n",
      "rec:  0.9235618597320725\n",
      "ma F1:  0.9102666353897881\n",
      "mi F1:  0.9119205298013245\n",
      "we F1:  0.9122109697955455\n",
      "Eval Loss:  0.19738903641700745\n",
      "Eval Loss:  0.25120094418525696\n",
      "Eval Loss:  0.15436452627182007\n",
      "Eval Loss:  0.21871505677700043\n",
      "Eval Loss:  0.19300171732902527\n",
      "Eval Loss:  0.1509495973587036\n",
      "Eval Loss:  0.2502462863922119\n",
      "Eval Loss:  0.19397585093975067\n",
      "Eval Loss:  0.10503493249416351\n",
      "Eval Loss:  0.1738157719373703\n",
      "Eval Loss:  0.15842530131340027\n",
      "Eval Loss:  0.14760586619377136\n",
      "Eval Loss:  0.17896506190299988\n",
      "Eval Loss:  0.25657138228416443\n",
      "Eval Loss:  0.20479165017604828\n",
      "Eval Loss:  0.11153183877468109\n",
      "Eval Loss:  0.15880824625492096\n",
      "Eval Loss:  0.2041512280702591\n",
      "Eval Loss:  0.14404040575027466\n",
      "Eval Loss:  0.20163720846176147\n",
      "Eval Loss:  0.18122243881225586\n",
      "Eval Loss:  0.12546968460083008\n",
      "Eval Loss:  0.19835563004016876\n",
      "Eval Loss:  0.1685209572315216\n",
      "Eval Loss:  0.1579190492630005\n",
      "Eval Loss:  0.18143630027770996\n",
      "Eval Loss:  0.19729387760162354\n",
      "Eval Loss:  0.21226626634597778\n",
      "Eval Loss:  0.17611676454544067\n",
      "[[17031  1382]\n",
      " [  883 10575]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     18413\n",
      "           1       0.88      0.92      0.90     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.92      0.92     29871\n",
      "weighted avg       0.93      0.92      0.92     29871\n",
      "\n",
      "acc:  0.924173947976298\n",
      "pre:  0.8844191686877979\n",
      "rec:  0.9229359399546169\n",
      "ma F1:  0.9204584092528315\n",
      "mi F1:  0.924173947976298\n",
      "we F1:  0.9244611310343851\n",
      "29871 467\n",
      "Loss:  0.06258467584848404\n",
      "Loss:  0.06718392670154572\n",
      "Loss:  0.07016487419605255\n",
      "54 **********\n",
      "Epoch:  3700.78076338768  fold:  10  kers:  128\n",
      "epoch:  55\n",
      "29871 467\n",
      "Loss:  0.06045553833246231\n",
      "Loss:  0.07287518680095673\n",
      "Loss:  0.04378565028309822\n",
      "55 **********\n",
      "Epoch:  3754.352523326874  fold:  10  kers:  128\n",
      "epoch:  56\n",
      "29871 467\n",
      "Loss:  0.051655836403369904\n",
      "Loss:  0.02968333661556244\n",
      "Loss:  0.03852232173085213\n",
      "56 **********\n",
      "Epoch:  3808.324214220047  fold:  10  kers:  128\n",
      "epoch:  57\n",
      "Eval Loss:  0.5561141967773438\n",
      "Eval Loss:  0.10358268767595291\n",
      "Eval Loss:  0.011455286294221878\n",
      "[[1640  111]\n",
      " [ 126 1143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1751\n",
      "           1       0.91      0.90      0.91      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.92      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.921523178807947\n",
      "pre:  0.9114832535885168\n",
      "rec:  0.900709219858156\n",
      "ma F1:  0.9193386158684993\n",
      "mi F1:  0.921523178807947\n",
      "we F1:  0.9214572463248649\n",
      "Eval Loss:  0.14887873828411102\n",
      "Eval Loss:  0.19643175601959229\n",
      "Eval Loss:  0.12496672570705414\n",
      "Eval Loss:  0.18753769993782043\n",
      "Eval Loss:  0.20747600495815277\n",
      "Eval Loss:  0.11329426616430283\n",
      "Eval Loss:  0.19362854957580566\n",
      "Eval Loss:  0.18981797993183136\n",
      "Eval Loss:  0.08424215018749237\n",
      "Eval Loss:  0.14262275397777557\n",
      "Eval Loss:  0.12769180536270142\n",
      "Eval Loss:  0.1519240438938141\n",
      "Eval Loss:  0.17390602827072144\n",
      "Eval Loss:  0.23261182010173798\n",
      "Eval Loss:  0.241256982088089\n",
      "Eval Loss:  0.07584158331155777\n",
      "Eval Loss:  0.14275988936424255\n",
      "Eval Loss:  0.20674054324626923\n",
      "Eval Loss:  0.12802031636238098\n",
      "Eval Loss:  0.19669003784656525\n",
      "Eval Loss:  0.1675117164850235\n",
      "Eval Loss:  0.10933157056570053\n",
      "Eval Loss:  0.16976606845855713\n",
      "Eval Loss:  0.1574268788099289\n",
      "Eval Loss:  0.15710023045539856\n",
      "Eval Loss:  0.16348706185817719\n",
      "Eval Loss:  0.19895069301128387\n",
      "Eval Loss:  0.20883652567863464\n",
      "Eval Loss:  0.16007718443870544\n",
      "[[17382  1031]\n",
      " [ 1036 10422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18413\n",
      "           1       0.91      0.91      0.91     11458\n",
      "\n",
      "    accuracy                           0.93     29871\n",
      "   macro avg       0.93      0.93      0.93     29871\n",
      "weighted avg       0.93      0.93      0.93     29871\n",
      "\n",
      "acc:  0.9308024505373105\n",
      "pre:  0.9099799179254344\n",
      "rec:  0.9095828242276139\n",
      "ma F1:  0.9268300627491955\n",
      "mi F1:  0.9308024505373105\n",
      "we F1:  0.9307995968104511\n",
      "29871 467\n",
      "Loss:  0.03668970614671707\n",
      "Loss:  0.037651870399713516\n",
      "Loss:  0.02810446359217167\n",
      "57 **********\n",
      "Epoch:  3902.604128599167  fold:  10  kers:  128\n",
      "epoch:  58\n",
      "29871 467\n",
      "Loss:  0.0734672099351883\n",
      "Loss:  0.05556914210319519\n",
      "Loss:  0.05915449932217598\n",
      "58 **********\n",
      "Epoch:  3956.139984846115  fold:  10  kers:  128\n",
      "epoch:  59\n",
      "29871 467\n",
      "Loss:  0.048904791474342346\n",
      "Loss:  0.05870837718248367\n",
      "Loss:  0.0697031319141388\n",
      "59 **********\n",
      "Epoch:  4009.7107474803925  fold:  10  kers:  128\n",
      "Eval Loss:  0.6813321113586426\n",
      "Eval Loss:  0.08152157068252563\n",
      "Eval Loss:  0.0150066539645195\n",
      "[[1679   72]\n",
      " [ 167 1102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      1751\n",
      "           1       0.94      0.87      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.9208609271523179\n",
      "pre:  0.938671209540034\n",
      "rec:  0.8684003152088259\n",
      "ma F1:  0.9178626023346194\n",
      "mi F1:  0.9208609271523179\n",
      "we F1:  0.9203672688201145\n",
      "update!  Acc:  0.9364238410596026\n",
      "Epoch:  4013.3998835086823  fold:  10  kers:  128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "  \n",
      "kernel: 64\n",
      "  \n",
      "*********\n",
      "29459 3432\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29459 461\n",
      "Loss:  0.16132888197898865\n",
      "Loss:  0.15579402446746826\n",
      "Loss:  0.1442093849182129\n",
      "0 **********\n",
      "Epoch:  54.845354080200195  fold:  1  kers:  64\n",
      "epoch:  1\n",
      "29459 461\n",
      "Loss:  0.14491046965122223\n",
      "Loss:  0.10505252331495285\n",
      "Loss:  0.11218127608299255\n",
      "1 **********\n",
      "Epoch:  97.40256476402283  fold:  1  kers:  64\n",
      "epoch:  2\n",
      "29459 461\n",
      "Loss:  0.10461951792240143\n",
      "Loss:  0.10105080902576447\n",
      "Loss:  0.11203077435493469\n",
      "2 **********\n",
      "Epoch:  139.8341109752655  fold:  1  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.4233071804046631\n",
      "Eval Loss:  0.4816530644893646\n",
      "Eval Loss:  0.20588961243629456\n",
      "[[ 843  196]\n",
      " [ 726 1667]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.81      0.65      1039\n",
      "           1       0.89      0.70      0.78      2393\n",
      "\n",
      "    accuracy                           0.73      3432\n",
      "   macro avg       0.72      0.75      0.71      3432\n",
      "weighted avg       0.79      0.73      0.74      3432\n",
      "\n",
      "acc:  0.7313519813519813\n",
      "pre:  0.8947933440687064\n",
      "rec:  0.6966151274550773\n",
      "ma F1:  0.7149185271460861\n",
      "mi F1:  0.7313519813519813\n",
      "we F1:  0.7419220429164529\n",
      "update!  Acc:  0.7313519813519813\n",
      "Eval Loss:  0.43960294127464294\n",
      "Eval Loss:  0.4701050817966461\n",
      "Eval Loss:  0.3907645046710968\n",
      "Eval Loss:  0.35815441608428955\n",
      "Eval Loss:  0.3842381536960602\n",
      "Eval Loss:  0.3295874297618866\n",
      "Eval Loss:  0.4305994510650635\n",
      "Eval Loss:  0.38749945163726807\n",
      "Eval Loss:  0.36256200075149536\n",
      "Eval Loss:  0.36554229259490967\n",
      "Eval Loss:  0.4841548502445221\n",
      "Eval Loss:  0.3779429793357849\n",
      "Eval Loss:  0.4189566373825073\n",
      "Eval Loss:  0.5502364635467529\n",
      "Eval Loss:  0.34022897481918335\n",
      "Eval Loss:  0.43631842732429504\n",
      "Eval Loss:  0.4347451627254486\n",
      "Eval Loss:  0.43898341059684753\n",
      "Eval Loss:  0.4613727629184723\n",
      "Eval Loss:  0.40412086248397827\n",
      "Eval Loss:  0.5543451309204102\n",
      "Eval Loss:  0.45876169204711914\n",
      "Eval Loss:  0.3994860053062439\n",
      "Eval Loss:  0.3662584722042084\n",
      "Eval Loss:  0.3943420350551605\n",
      "Eval Loss:  0.37239351868629456\n",
      "Eval Loss:  0.3596287965774536\n",
      "Eval Loss:  0.39673134684562683\n",
      "[[17389  1736]\n",
      " [ 3341  6993]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87     19125\n",
      "           1       0.80      0.68      0.73     10334\n",
      "\n",
      "    accuracy                           0.83     29459\n",
      "   macro avg       0.82      0.79      0.80     29459\n",
      "weighted avg       0.83      0.83      0.82     29459\n",
      "\n",
      "acc:  0.8276587799993211\n",
      "pre:  0.8011226944667201\n",
      "rec:  0.676698277530482\n",
      "ma F1:  0.8031428911707053\n",
      "mi F1:  0.8276587799993212\n",
      "we F1:  0.8238738625724331\n",
      "29459 461\n",
      "Loss:  0.10314013808965683\n",
      "Loss:  0.0873039960861206\n",
      "Loss:  0.10628468543291092\n",
      "3 **********\n",
      "Epoch:  222.8800630569458  fold:  1  kers:  64\n",
      "epoch:  4\n",
      "29459 461\n",
      "Loss:  0.12342609465122223\n",
      "Loss:  0.11004701256752014\n",
      "Loss:  0.09755776077508926\n",
      "4 **********\n",
      "Epoch:  265.3754391670227  fold:  1  kers:  64\n",
      "epoch:  5\n",
      "29459 461\n",
      "Loss:  0.10075889527797699\n",
      "Loss:  0.12086530029773712\n",
      "Loss:  0.07959816604852676\n",
      "5 **********\n",
      "Epoch:  307.76609539985657  fold:  1  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.4472748339176178\n",
      "Eval Loss:  0.7475892901420593\n",
      "Eval Loss:  0.13827039301395416\n",
      "[[ 924  115]\n",
      " [ 945 1448]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.89      0.64      1039\n",
      "           1       0.93      0.61      0.73      2393\n",
      "\n",
      "    accuracy                           0.69      3432\n",
      "   macro avg       0.71      0.75      0.68      3432\n",
      "weighted avg       0.80      0.69      0.70      3432\n",
      "\n",
      "acc:  0.6911421911421911\n",
      "pre:  0.9264235444657709\n",
      "rec:  0.6050982030923527\n",
      "ma F1:  0.6837704432387626\n",
      "mi F1:  0.6911421911421911\n",
      "we F1:  0.7028188147296831\n",
      "Eval Loss:  0.4687134623527527\n",
      "Eval Loss:  0.5145635604858398\n",
      "Eval Loss:  0.3563324809074402\n",
      "Eval Loss:  0.3258787989616394\n",
      "Eval Loss:  0.45585936307907104\n",
      "Eval Loss:  0.332732230424881\n",
      "Eval Loss:  0.5178537964820862\n",
      "Eval Loss:  0.37693357467651367\n",
      "Eval Loss:  0.362638384103775\n",
      "Eval Loss:  0.4194457530975342\n",
      "Eval Loss:  0.5633949041366577\n",
      "Eval Loss:  0.37254607677459717\n",
      "Eval Loss:  0.459568053483963\n",
      "Eval Loss:  0.6471381783485413\n",
      "Eval Loss:  0.34706026315689087\n",
      "Eval Loss:  0.48339271545410156\n",
      "Eval Loss:  0.4220729470252991\n",
      "Eval Loss:  0.49626439809799194\n",
      "Eval Loss:  0.46424829959869385\n",
      "Eval Loss:  0.4553770422935486\n",
      "Eval Loss:  0.6072375774383545\n",
      "Eval Loss:  0.45248928666114807\n",
      "Eval Loss:  0.42181581258773804\n",
      "Eval Loss:  0.41946038603782654\n",
      "Eval Loss:  0.43023136258125305\n",
      "Eval Loss:  0.43678417801856995\n",
      "Eval Loss:  0.3388015627861023\n",
      "Eval Loss:  0.437743216753006\n",
      "[[18539   586]\n",
      " [ 4273  6061]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88     19125\n",
      "           1       0.91      0.59      0.71     10334\n",
      "\n",
      "    accuracy                           0.84     29459\n",
      "   macro avg       0.86      0.78      0.80     29459\n",
      "weighted avg       0.85      0.84      0.82     29459\n",
      "\n",
      "acc:  0.8350588954139652\n",
      "pre:  0.9118399277869715\n",
      "rec:  0.5865105477065996\n",
      "ma F1:  0.7989961953651143\n",
      "mi F1:  0.8350588954139652\n",
      "we F1:  0.8244030871850734\n",
      "29459 461\n",
      "Loss:  0.11172560602426529\n",
      "Loss:  0.12607918679714203\n",
      "Loss:  0.05841921269893646\n",
      "6 **********\n",
      "Epoch:  389.72595143318176  fold:  1  kers:  64\n",
      "epoch:  7\n",
      "29459 461\n",
      "Loss:  0.09484940767288208\n",
      "Loss:  0.07182073593139648\n",
      "Loss:  0.08725550025701523\n",
      "7 **********\n",
      "Epoch:  432.185423374176  fold:  1  kers:  64\n",
      "epoch:  8\n",
      "29459 461\n",
      "Loss:  0.07028091698884964\n",
      "Loss:  0.07935528457164764\n",
      "Loss:  0.0875798687338829\n",
      "8 **********\n",
      "Epoch:  474.5710928440094  fold:  1  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.49457019567489624\n",
      "Eval Loss:  0.7678378224372864\n",
      "Eval Loss:  0.14114028215408325\n",
      "[[ 948   91]\n",
      " [ 901 1492]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.91      0.66      1039\n",
      "           1       0.94      0.62      0.75      2393\n",
      "\n",
      "    accuracy                           0.71      3432\n",
      "   macro avg       0.73      0.77      0.70      3432\n",
      "weighted avg       0.81      0.71      0.72      3432\n",
      "\n",
      "acc:  0.710955710955711\n",
      "pre:  0.9425142135186355\n",
      "rec:  0.6234851650647723\n",
      "ma F1:  0.7035063566997554\n",
      "mi F1:  0.710955710955711\n",
      "we F1:  0.7220475803441743\n",
      "Eval Loss:  0.4107843041419983\n",
      "Eval Loss:  0.4562123715877533\n",
      "Eval Loss:  0.3131066858768463\n",
      "Eval Loss:  0.2608821988105774\n",
      "Eval Loss:  0.4014928340911865\n",
      "Eval Loss:  0.3082963824272156\n",
      "Eval Loss:  0.4898509681224823\n",
      "Eval Loss:  0.32776743173599243\n",
      "Eval Loss:  0.3388802409172058\n",
      "Eval Loss:  0.3976610600948334\n",
      "Eval Loss:  0.525557279586792\n",
      "Eval Loss:  0.30960920453071594\n",
      "Eval Loss:  0.43008774518966675\n",
      "Eval Loss:  0.5446531772613525\n",
      "Eval Loss:  0.32648590207099915\n",
      "Eval Loss:  0.44957977533340454\n",
      "Eval Loss:  0.38721030950546265\n",
      "Eval Loss:  0.4349360764026642\n",
      "Eval Loss:  0.4139169454574585\n",
      "Eval Loss:  0.38384076952934265\n",
      "Eval Loss:  0.5166095495223999\n",
      "Eval Loss:  0.38743507862091064\n",
      "Eval Loss:  0.36653950810432434\n",
      "Eval Loss:  0.38632863759994507\n",
      "Eval Loss:  0.3902186155319214\n",
      "Eval Loss:  0.4227837026119232\n",
      "Eval Loss:  0.3166239857673645\n",
      "Eval Loss:  0.40682464838027954\n",
      "[[18588   537]\n",
      " [ 3946  6388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     19125\n",
      "           1       0.92      0.62      0.74     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.87      0.80      0.82     29459\n",
      "weighted avg       0.86      0.85      0.84     29459\n",
      "\n",
      "acc:  0.8478223972300486\n",
      "pre:  0.9224548736462094\n",
      "rec:  0.6181536675053222\n",
      "ma F1:  0.8163198312167519\n",
      "mi F1:  0.8478223972300486\n",
      "we F1:  0.83901975398912\n",
      "29459 461\n",
      "Loss:  0.06481323391199112\n",
      "Loss:  0.07182252407073975\n",
      "Loss:  0.07543670386075974\n",
      "9 **********\n",
      "Epoch:  556.9338712692261  fold:  1  kers:  64\n",
      "epoch:  10\n",
      "29459 461\n",
      "Loss:  0.08699867129325867\n",
      "Loss:  0.07377277314662933\n",
      "Loss:  0.08470170199871063\n",
      "10 **********\n",
      "Epoch:  599.4641540050507  fold:  1  kers:  64\n",
      "epoch:  11\n",
      "29459 461\n",
      "Loss:  0.11418931931257248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09146663546562195\n",
      "Loss:  0.09056150168180466\n",
      "11 **********\n",
      "Epoch:  642.1350607872009  fold:  1  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.6123988628387451\n",
      "Eval Loss:  0.5485507845878601\n",
      "Eval Loss:  0.09388793259859085\n",
      "[[ 907  132]\n",
      " [ 673 1720]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.87      0.69      1039\n",
      "           1       0.93      0.72      0.81      2393\n",
      "\n",
      "    accuracy                           0.77      3432\n",
      "   macro avg       0.75      0.80      0.75      3432\n",
      "weighted avg       0.82      0.77      0.77      3432\n",
      "\n",
      "acc:  0.7654428904428905\n",
      "pre:  0.9287257019438445\n",
      "rec:  0.7187630589218554\n",
      "ma F1:  0.7514979552792382\n",
      "mi F1:  0.7654428904428905\n",
      "we F1:  0.7747223614435494\n",
      "update!  Acc:  0.7654428904428905\n",
      "Eval Loss:  0.335782915353775\n",
      "Eval Loss:  0.37828582525253296\n",
      "Eval Loss:  0.26716434955596924\n",
      "Eval Loss:  0.24204158782958984\n",
      "Eval Loss:  0.3478619456291199\n",
      "Eval Loss:  0.2834284007549286\n",
      "Eval Loss:  0.39562177658081055\n",
      "Eval Loss:  0.2637951076030731\n",
      "Eval Loss:  0.27463117241859436\n",
      "Eval Loss:  0.30329760909080505\n",
      "Eval Loss:  0.44622209668159485\n",
      "Eval Loss:  0.252172589302063\n",
      "Eval Loss:  0.3924010694026947\n",
      "Eval Loss:  0.4517331123352051\n",
      "Eval Loss:  0.3160156011581421\n",
      "Eval Loss:  0.37861886620521545\n",
      "Eval Loss:  0.3143969476222992\n",
      "Eval Loss:  0.3481636345386505\n",
      "Eval Loss:  0.3233068585395813\n",
      "Eval Loss:  0.31564319133758545\n",
      "Eval Loss:  0.4420783817768097\n",
      "Eval Loss:  0.357953280210495\n",
      "Eval Loss:  0.30269181728363037\n",
      "Eval Loss:  0.31861910223960876\n",
      "Eval Loss:  0.3130539655685425\n",
      "Eval Loss:  0.32789212465286255\n",
      "Eval Loss:  0.30677831172943115\n",
      "Eval Loss:  0.33323025703430176\n",
      "[[18389   736]\n",
      " [ 3095  7239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     19125\n",
      "           1       0.91      0.70      0.79     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.88      0.83      0.85     29459\n",
      "weighted avg       0.87      0.87      0.87     29459\n",
      "\n",
      "acc:  0.869954852506874\n",
      "pre:  0.9077115987460815\n",
      "rec:  0.700503193342365\n",
      "ma F1:  0.8482099749485474\n",
      "mi F1:  0.869954852506874\n",
      "we F1:  0.8653542994880317\n",
      "29459 461\n",
      "Loss:  0.06065807119011879\n",
      "Loss:  0.08638721704483032\n",
      "Loss:  0.05007508397102356\n",
      "12 **********\n",
      "Epoch:  724.0560204982758  fold:  1  kers:  64\n",
      "epoch:  13\n",
      "29459 461\n",
      "Loss:  0.08540913462638855\n",
      "Loss:  0.08064432442188263\n",
      "Loss:  0.0543687604367733\n",
      "13 **********\n",
      "Epoch:  766.4975414276123  fold:  1  kers:  64\n",
      "epoch:  14\n",
      "29459 461\n",
      "Loss:  0.07677411288022995\n",
      "Loss:  0.05995264649391174\n",
      "Loss:  0.06098511815071106\n",
      "14 **********\n",
      "Epoch:  808.8862016201019  fold:  1  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.6351290941238403\n",
      "Eval Loss:  0.4802563190460205\n",
      "Eval Loss:  0.08449315279722214\n",
      "[[ 888  151]\n",
      " [ 605 1788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.85      0.70      1039\n",
      "           1       0.92      0.75      0.83      2393\n",
      "\n",
      "    accuracy                           0.78      3432\n",
      "   macro avg       0.76      0.80      0.76      3432\n",
      "weighted avg       0.82      0.78      0.79      3432\n",
      "\n",
      "acc:  0.7797202797202797\n",
      "pre:  0.9221248066013409\n",
      "rec:  0.7471792728792311\n",
      "ma F1:  0.7634532827454018\n",
      "mi F1:  0.7797202797202797\n",
      "we F1:  0.7879260759720516\n",
      "update!  Acc:  0.7797202797202797\n",
      "Eval Loss:  0.31518030166625977\n",
      "Eval Loss:  0.39609742164611816\n",
      "Eval Loss:  0.26688265800476074\n",
      "Eval Loss:  0.24746327102184296\n",
      "Eval Loss:  0.35620176792144775\n",
      "Eval Loss:  0.2745026648044586\n",
      "Eval Loss:  0.3700401186943054\n",
      "Eval Loss:  0.27548977732658386\n",
      "Eval Loss:  0.29936885833740234\n",
      "Eval Loss:  0.30611568689346313\n",
      "Eval Loss:  0.425478458404541\n",
      "Eval Loss:  0.23683440685272217\n",
      "Eval Loss:  0.388943612575531\n",
      "Eval Loss:  0.4445078372955322\n",
      "Eval Loss:  0.3156486749649048\n",
      "Eval Loss:  0.3558848202228546\n",
      "Eval Loss:  0.3061271607875824\n",
      "Eval Loss:  0.3577466309070587\n",
      "Eval Loss:  0.32271698117256165\n",
      "Eval Loss:  0.28780150413513184\n",
      "Eval Loss:  0.4555172324180603\n",
      "Eval Loss:  0.35204416513442993\n",
      "Eval Loss:  0.2685774862766266\n",
      "Eval Loss:  0.30107027292251587\n",
      "Eval Loss:  0.31390100717544556\n",
      "Eval Loss:  0.34715571999549866\n",
      "Eval Loss:  0.309289813041687\n",
      "Eval Loss:  0.3391036093235016\n",
      "[[18501   624]\n",
      " [ 3218  7116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91     19125\n",
      "           1       0.92      0.69      0.79     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.89      0.83      0.85     29459\n",
      "weighted avg       0.88      0.87      0.86     29459\n",
      "\n",
      "acc:  0.8695814521877864\n",
      "pre:  0.9193798449612403\n",
      "rec:  0.6886007354364234\n",
      "ma F1:  0.8466821164499114\n",
      "mi F1:  0.8695814521877864\n",
      "we F1:  0.8643639838606852\n",
      "29459 461\n",
      "Loss:  0.06398262828588486\n",
      "Loss:  0.07628010213375092\n",
      "Loss:  0.05081150680780411\n",
      "15 **********\n",
      "Epoch:  890.659556388855  fold:  1  kers:  64\n",
      "epoch:  16\n",
      "29459 461\n",
      "Loss:  0.07826363295316696\n",
      "Loss:  0.06253258138895035\n",
      "Loss:  0.0719337910413742\n",
      "16 **********\n",
      "Epoch:  933.0202927589417  fold:  1  kers:  64\n",
      "epoch:  17\n",
      "29459 461\n",
      "Loss:  0.06994921714067459\n",
      "Loss:  0.09936689585447311\n",
      "Loss:  0.08783498406410217\n",
      "17 **********\n",
      "Epoch:  975.4767725467682  fold:  1  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.7571521997451782\n",
      "Eval Loss:  0.5279774069786072\n",
      "Eval Loss:  0.10146661102771759\n",
      "[[ 908  131]\n",
      " [ 711 1682]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.87      0.68      1039\n",
      "           1       0.93      0.70      0.80      2393\n",
      "\n",
      "    accuracy                           0.75      3432\n",
      "   macro avg       0.74      0.79      0.74      3432\n",
      "weighted avg       0.82      0.75      0.76      3432\n",
      "\n",
      "acc:  0.7546620046620046\n",
      "pre:  0.9277440706012134\n",
      "rec:  0.7028834099456749\n",
      "ma F1:  0.7415151310231862\n",
      "mi F1:  0.7546620046620047\n",
      "we F1:  0.7645136670786903\n",
      "Eval Loss:  0.29072684049606323\n",
      "Eval Loss:  0.37598735094070435\n",
      "Eval Loss:  0.2521411180496216\n",
      "Eval Loss:  0.235239639878273\n",
      "Eval Loss:  0.3559454083442688\n",
      "Eval Loss:  0.2729688584804535\n",
      "Eval Loss:  0.35630708932876587\n",
      "Eval Loss:  0.2876416742801666\n",
      "Eval Loss:  0.3065732717514038\n",
      "Eval Loss:  0.3007712960243225\n",
      "Eval Loss:  0.4246220886707306\n",
      "Eval Loss:  0.2317316085100174\n",
      "Eval Loss:  0.3716811537742615\n",
      "Eval Loss:  0.434099942445755\n",
      "Eval Loss:  0.3058907985687256\n",
      "Eval Loss:  0.3194967806339264\n",
      "Eval Loss:  0.321581095457077\n",
      "Eval Loss:  0.3422456979751587\n",
      "Eval Loss:  0.3014626204967499\n",
      "Eval Loss:  0.2860530614852905\n",
      "Eval Loss:  0.4777793884277344\n",
      "Eval Loss:  0.36261072754859924\n",
      "Eval Loss:  0.25394538044929504\n",
      "Eval Loss:  0.30959632992744446\n",
      "Eval Loss:  0.30865204334259033\n",
      "Eval Loss:  0.3389456570148468\n",
      "Eval Loss:  0.3136323094367981\n",
      "Eval Loss:  0.3348033130168915\n",
      "[[18577   548]\n",
      " [ 3307  7027]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91     19125\n",
      "           1       0.93      0.68      0.78     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.89      0.83      0.85     29459\n",
      "weighted avg       0.88      0.87      0.86     29459\n",
      "\n",
      "acc:  0.8691401609015921\n",
      "pre:  0.9276567656765676\n",
      "rec:  0.6799883878459454\n",
      "ma F1:  0.8453706724778511\n",
      "mi F1:  0.8691401609015921\n",
      "we F1:  0.8634622372166482\n",
      "29459 461\n",
      "Loss:  0.08716364204883575\n",
      "Loss:  0.066338911652565\n",
      "Loss:  0.0764288604259491\n",
      "18 **********\n",
      "Epoch:  1057.0915513038635  fold:  1  kers:  64\n",
      "epoch:  19\n",
      "29459 461\n",
      "Loss:  0.05691371485590935\n",
      "Loss:  0.0964299663901329\n",
      "Loss:  0.08488357067108154\n",
      "19 **********\n",
      "Epoch:  1099.434335231781  fold:  1  kers:  64\n",
      "epoch:  20\n",
      "29459 461\n",
      "Loss:  0.05418052151799202\n",
      "Loss:  0.049925073981285095\n",
      "Loss:  0.06230596825480461\n",
      "20 **********\n",
      "Epoch:  1141.7332365512848  fold:  1  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.8516431450843811\n",
      "Eval Loss:  0.4489334225654602\n",
      "Eval Loss:  0.15856419503688812\n",
      "[[ 878  161]\n",
      " [ 497 1896]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73      1039\n",
      "           1       0.92      0.79      0.85      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.82      0.79      3432\n",
      "weighted avg       0.84      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8082750582750583\n",
      "pre:  0.9217306757413709\n",
      "rec:  0.7923109068115336\n",
      "ma F1:  0.789779097586178\n",
      "mi F1:  0.8082750582750583\n",
      "we F1:  0.8143798154375963\n",
      "update!  Acc:  0.8082750582750583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.25256237387657166\n",
      "Eval Loss:  0.3065626323223114\n",
      "Eval Loss:  0.22111400961875916\n",
      "Eval Loss:  0.18526282906532288\n",
      "Eval Loss:  0.3009074926376343\n",
      "Eval Loss:  0.27275311946868896\n",
      "Eval Loss:  0.32955244183540344\n",
      "Eval Loss:  0.257525771856308\n",
      "Eval Loss:  0.2637341618537903\n",
      "Eval Loss:  0.3002556264400482\n",
      "Eval Loss:  0.39642438292503357\n",
      "Eval Loss:  0.19165697693824768\n",
      "Eval Loss:  0.3381785750389099\n",
      "Eval Loss:  0.3380619287490845\n",
      "Eval Loss:  0.2889847457408905\n",
      "Eval Loss:  0.29181715846061707\n",
      "Eval Loss:  0.32195353507995605\n",
      "Eval Loss:  0.3010871708393097\n",
      "Eval Loss:  0.2831955850124359\n",
      "Eval Loss:  0.2642204463481903\n",
      "Eval Loss:  0.3930903375148773\n",
      "Eval Loss:  0.28896746039390564\n",
      "Eval Loss:  0.23885098099708557\n",
      "Eval Loss:  0.2773424983024597\n",
      "Eval Loss:  0.2760380804538727\n",
      "Eval Loss:  0.3091348111629486\n",
      "Eval Loss:  0.261148065328598\n",
      "Eval Loss:  0.3085308074951172\n",
      "[[18442   683]\n",
      " [ 2775  7559]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     19125\n",
      "           1       0.92      0.73      0.81     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.89      0.85      0.86     29459\n",
      "weighted avg       0.89      0.88      0.88     29459\n",
      "\n",
      "acc:  0.8826165178722971\n",
      "pre:  0.9171317641349187\n",
      "rec:  0.731468937487904\n",
      "ma F1:  0.8640643519655439\n",
      "mi F1:  0.8826165178722971\n",
      "we F1:  0.8790503016564625\n",
      "29459 461\n",
      "Loss:  0.0860922709107399\n",
      "Loss:  0.05554835498332977\n",
      "Loss:  0.08490604907274246\n",
      "21 **********\n",
      "Epoch:  1223.4587190151215  fold:  1  kers:  64\n",
      "epoch:  22\n",
      "29459 461\n",
      "Loss:  0.11046841740608215\n",
      "Loss:  0.07404124736785889\n",
      "Loss:  0.07923897355794907\n",
      "22 **********\n",
      "Epoch:  1266.3111412525177  fold:  1  kers:  64\n",
      "epoch:  23\n",
      "29459 461\n",
      "Loss:  0.07784083485603333\n",
      "Loss:  0.0881500095129013\n",
      "Loss:  0.09412380307912827\n",
      "23 **********\n",
      "Epoch:  1309.4138922691345  fold:  1  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  1.199498176574707\n",
      "Eval Loss:  0.3056497275829315\n",
      "Eval Loss:  0.09530841559171677\n",
      "[[ 762  277]\n",
      " [ 316 2077]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      1039\n",
      "           1       0.88      0.87      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.79      0.80      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8272144522144522\n",
      "pre:  0.8823279524214104\n",
      "rec:  0.8679481821980777\n",
      "ma F1:  0.7974828146439406\n",
      "mi F1:  0.8272144522144522\n",
      "we F1:  0.8280962270169238\n",
      "update!  Acc:  0.8272144522144522\n",
      "Eval Loss:  0.23917874693870544\n",
      "Eval Loss:  0.280630499124527\n",
      "Eval Loss:  0.20529919862747192\n",
      "Eval Loss:  0.20983140170574188\n",
      "Eval Loss:  0.275821715593338\n",
      "Eval Loss:  0.22627322375774384\n",
      "Eval Loss:  0.2760923504829407\n",
      "Eval Loss:  0.201743483543396\n",
      "Eval Loss:  0.21755366027355194\n",
      "Eval Loss:  0.24054983258247375\n",
      "Eval Loss:  0.33730292320251465\n",
      "Eval Loss:  0.18126904964447021\n",
      "Eval Loss:  0.3026757836341858\n",
      "Eval Loss:  0.3243371546268463\n",
      "Eval Loss:  0.26718947291374207\n",
      "Eval Loss:  0.23212432861328125\n",
      "Eval Loss:  0.26921507716178894\n",
      "Eval Loss:  0.23774877190589905\n",
      "Eval Loss:  0.2301388680934906\n",
      "Eval Loss:  0.24185357987880707\n",
      "Eval Loss:  0.335223525762558\n",
      "Eval Loss:  0.27870285511016846\n",
      "Eval Loss:  0.21458129584789276\n",
      "Eval Loss:  0.23062846064567566\n",
      "Eval Loss:  0.2373373955488205\n",
      "Eval Loss:  0.2594069838523865\n",
      "Eval Loss:  0.2551942467689514\n",
      "Eval Loss:  0.26175129413604736\n",
      "[[18172   953]\n",
      " [ 2011  8323]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     19125\n",
      "           1       0.90      0.81      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.8993855867476832\n",
      "pre:  0.8972617507546357\n",
      "rec:  0.8053996516353784\n",
      "ma F1:  0.8867240641994832\n",
      "mi F1:  0.8993855867476832\n",
      "we F1:  0.898025459744333\n",
      "29459 461\n",
      "Loss:  0.08348332345485687\n",
      "Loss:  0.09752026200294495\n",
      "Loss:  0.03067481517791748\n",
      "24 **********\n",
      "Epoch:  1390.9977538585663  fold:  1  kers:  64\n",
      "epoch:  25\n",
      "29459 461\n",
      "Loss:  0.046587951481342316\n",
      "Loss:  0.06783963739871979\n",
      "Loss:  0.04877963662147522\n",
      "25 **********\n",
      "Epoch:  1433.319593667984  fold:  1  kers:  64\n",
      "epoch:  26\n",
      "29459 461\n",
      "Loss:  0.08065316826105118\n",
      "Loss:  0.06444507092237473\n",
      "Loss:  0.053381938487291336\n",
      "26 **********\n",
      "Epoch:  1475.9406342506409  fold:  1  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.912058413028717\n",
      "Eval Loss:  0.3690892159938812\n",
      "Eval Loss:  0.09512077271938324\n",
      "[[ 857  182]\n",
      " [ 443 1950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.82      0.73      1039\n",
      "           1       0.91      0.81      0.86      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.82      0.80      3432\n",
      "weighted avg       0.84      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8178904428904429\n",
      "pre:  0.9146341463414634\n",
      "rec:  0.8148767237776849\n",
      "ma F1:  0.7973351222012524\n",
      "mi F1:  0.8178904428904429\n",
      "we F1:  0.8227988954978341\n",
      "Eval Loss:  0.24380531907081604\n",
      "Eval Loss:  0.3136119544506073\n",
      "Eval Loss:  0.20764502882957458\n",
      "Eval Loss:  0.20498806238174438\n",
      "Eval Loss:  0.29957494139671326\n",
      "Eval Loss:  0.2340899109840393\n",
      "Eval Loss:  0.29502519965171814\n",
      "Eval Loss:  0.2073342502117157\n",
      "Eval Loss:  0.2447289228439331\n",
      "Eval Loss:  0.2704702913761139\n",
      "Eval Loss:  0.39469650387763977\n",
      "Eval Loss:  0.1826619654893875\n",
      "Eval Loss:  0.30827030539512634\n",
      "Eval Loss:  0.3729972243309021\n",
      "Eval Loss:  0.2514748275279999\n",
      "Eval Loss:  0.2678050994873047\n",
      "Eval Loss:  0.30952078104019165\n",
      "Eval Loss:  0.27190276980400085\n",
      "Eval Loss:  0.23623861372470856\n",
      "Eval Loss:  0.250700980424881\n",
      "Eval Loss:  0.3880864977836609\n",
      "Eval Loss:  0.3230780363082886\n",
      "Eval Loss:  0.21991193294525146\n",
      "Eval Loss:  0.2759580910205841\n",
      "Eval Loss:  0.2768775224685669\n",
      "Eval Loss:  0.3075350224971771\n",
      "Eval Loss:  0.2686736285686493\n",
      "Eval Loss:  0.2891871929168701\n",
      "[[18588   537]\n",
      " [ 2671  7663]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     19125\n",
      "           1       0.93      0.74      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.90      0.86      0.87     29459\n",
      "weighted avg       0.90      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8911028887606504\n",
      "pre:  0.9345121951219513\n",
      "rec:  0.7415328043352042\n",
      "ma F1:  0.8737376500155538\n",
      "mi F1:  0.8911028887606504\n",
      "we F1:  0.8877109052840338\n",
      "29459 461\n",
      "Loss:  0.059827014803886414\n",
      "Loss:  0.0630931705236435\n",
      "Loss:  0.06713277101516724\n",
      "27 **********\n",
      "Epoch:  1559.9909002780914  fold:  1  kers:  64\n",
      "epoch:  28\n",
      "29459 461\n",
      "Loss:  0.0905386358499527\n",
      "Loss:  0.0724615752696991\n",
      "Loss:  0.08431275188922882\n",
      "28 **********\n",
      "Epoch:  1603.2243030071259  fold:  1  kers:  64\n",
      "epoch:  29\n",
      "29459 461\n",
      "Loss:  0.07926366478204727\n",
      "Loss:  0.07097170501947403\n",
      "Loss:  0.07325346767902374\n",
      "29 **********\n",
      "Epoch:  1646.1106338500977  fold:  1  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  1.2374351024627686\n",
      "Eval Loss:  0.3118062913417816\n",
      "Eval Loss:  0.10283399373292923\n",
      "[[ 758  281]\n",
      " [ 311 2082]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      1039\n",
      "           1       0.88      0.87      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.80      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8275058275058275\n",
      "pre:  0.8810833685992383\n",
      "rec:  0.8700376096949436\n",
      "ma F1:  0.7973453685986183\n",
      "mi F1:  0.8275058275058275\n",
      "we F1:  0.8281892215898277\n",
      "update!  Acc:  0.8275058275058275\n",
      "Eval Loss:  0.21573056280612946\n",
      "Eval Loss:  0.2600237727165222\n",
      "Eval Loss:  0.18784722685813904\n",
      "Eval Loss:  0.1979941725730896\n",
      "Eval Loss:  0.22539305686950684\n",
      "Eval Loss:  0.2349759340286255\n",
      "Eval Loss:  0.2518535256385803\n",
      "Eval Loss:  0.19741137325763702\n",
      "Eval Loss:  0.22370873391628265\n",
      "Eval Loss:  0.24099178612232208\n",
      "Eval Loss:  0.3227863907814026\n",
      "Eval Loss:  0.15753191709518433\n",
      "Eval Loss:  0.2878207266330719\n",
      "Eval Loss:  0.29458969831466675\n",
      "Eval Loss:  0.2583167850971222\n",
      "Eval Loss:  0.23304851353168488\n",
      "Eval Loss:  0.23961089551448822\n",
      "Eval Loss:  0.22209155559539795\n",
      "Eval Loss:  0.2238216996192932\n",
      "Eval Loss:  0.22636812925338745\n",
      "Eval Loss:  0.3029959201812744\n",
      "Eval Loss:  0.2727676331996918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18501831591129303\n",
      "Eval Loss:  0.2189130336046219\n",
      "Eval Loss:  0.217064768075943\n",
      "Eval Loss:  0.24772559106349945\n",
      "Eval Loss:  0.23015935719013214\n",
      "Eval Loss:  0.23215632140636444\n",
      "[[18203   922]\n",
      " [ 1846  8488]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     19125\n",
      "           1       0.90      0.82      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.89      0.89     29459\n",
      "weighted avg       0.91      0.91      0.90     29459\n",
      "\n",
      "acc:  0.9060389015241522\n",
      "pre:  0.90201912858661\n",
      "rec:  0.8213663634604219\n",
      "ma F1:  0.8945731999501207\n",
      "mi F1:  0.9060389015241522\n",
      "we F1:  0.9049483911531377\n",
      "29459 461\n",
      "Loss:  0.09930142760276794\n",
      "Loss:  0.06249520182609558\n",
      "Loss:  0.0876886397600174\n",
      "30 **********\n",
      "Epoch:  1733.7716817855835  fold:  1  kers:  64\n",
      "epoch:  31\n",
      "29459 461\n",
      "Loss:  0.06902027875185013\n",
      "Loss:  0.04816341772675514\n",
      "Loss:  0.06502139568328857\n",
      "31 **********\n",
      "Epoch:  1778.430273771286  fold:  1  kers:  64\n",
      "epoch:  32\n",
      "29459 461\n",
      "Loss:  0.0743040218949318\n",
      "Loss:  0.0447414293885231\n",
      "Loss:  0.05088156834244728\n",
      "32 **********\n",
      "Epoch:  1821.6047163009644  fold:  1  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  1.354712724685669\n",
      "Eval Loss:  0.23559854924678802\n",
      "Eval Loss:  0.10586730390787125\n",
      "[[ 693  346]\n",
      " [ 222 2171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71      1039\n",
      "           1       0.86      0.91      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.81      0.79      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8344988344988346\n",
      "pre:  0.8625347636074692\n",
      "rec:  0.9072294191391559\n",
      "ma F1:  0.7968159730835698\n",
      "mi F1:  0.8344988344988347\n",
      "we F1:  0.8313373495086499\n",
      "update!  Acc:  0.8344988344988346\n",
      "Eval Loss:  0.20665597915649414\n",
      "Eval Loss:  0.2667970359325409\n",
      "Eval Loss:  0.1997208148241043\n",
      "Eval Loss:  0.20420800149440765\n",
      "Eval Loss:  0.2290685772895813\n",
      "Eval Loss:  0.2365627884864807\n",
      "Eval Loss:  0.2533060312271118\n",
      "Eval Loss:  0.20188932120800018\n",
      "Eval Loss:  0.20536044239997864\n",
      "Eval Loss:  0.21907852590084076\n",
      "Eval Loss:  0.31828927993774414\n",
      "Eval Loss:  0.1595214307308197\n",
      "Eval Loss:  0.2825303375720978\n",
      "Eval Loss:  0.2876473665237427\n",
      "Eval Loss:  0.2689940333366394\n",
      "Eval Loss:  0.22695444524288177\n",
      "Eval Loss:  0.2373749017715454\n",
      "Eval Loss:  0.21342632174491882\n",
      "Eval Loss:  0.1964135468006134\n",
      "Eval Loss:  0.2323821485042572\n",
      "Eval Loss:  0.28544554114341736\n",
      "Eval Loss:  0.23627275228500366\n",
      "Eval Loss:  0.19322918355464935\n",
      "Eval Loss:  0.22289413213729858\n",
      "Eval Loss:  0.19739919900894165\n",
      "Eval Loss:  0.23678326606750488\n",
      "Eval Loss:  0.2071043848991394\n",
      "Eval Loss:  0.22791481018066406\n",
      "[[18004  1121]\n",
      " [ 1566  8768]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     19125\n",
      "           1       0.89      0.85      0.87     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.89      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9087884856919787\n",
      "pre:  0.8866417231267064\n",
      "rec:  0.8484613895877685\n",
      "ma F1:  0.8988454938828879\n",
      "mi F1:  0.9087884856919787\n",
      "we F1:  0.9083094220978855\n",
      "29459 461\n",
      "Loss:  0.04708338901400566\n",
      "Loss:  0.06447970867156982\n",
      "Loss:  0.04413464292883873\n",
      "33 **********\n",
      "Epoch:  1909.359079837799  fold:  1  kers:  64\n",
      "epoch:  34\n",
      "29459 461\n",
      "Loss:  0.0692882314324379\n",
      "Loss:  0.043924275785684586\n",
      "Loss:  0.08078033477067947\n",
      "34 **********\n",
      "Epoch:  1956.894977092743  fold:  1  kers:  64\n",
      "epoch:  35\n",
      "29459 461\n",
      "Loss:  0.037104975432157516\n",
      "Loss:  0.053829625248909\n",
      "Loss:  0.08991525322198868\n",
      "35 **********\n",
      "Epoch:  2004.0658519268036  fold:  1  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  1.1886380910873413\n",
      "Eval Loss:  0.23947298526763916\n",
      "Eval Loss:  0.12295211106538773\n",
      "[[ 769  270]\n",
      " [ 294 2099]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73      1039\n",
      "           1       0.89      0.88      0.88      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.80      0.81      0.81      3432\n",
      "weighted avg       0.84      0.84      0.84      3432\n",
      "\n",
      "acc:  0.8356643356643356\n",
      "pre:  0.8860278598564796\n",
      "rec:  0.8771416631842875\n",
      "ma F1:  0.80662323956185\n",
      "mi F1:  0.8356643356643356\n",
      "we F1:  0.8361883855188165\n",
      "update!  Acc:  0.8356643356643356\n",
      "Eval Loss:  0.20390193164348602\n",
      "Eval Loss:  0.2831917405128479\n",
      "Eval Loss:  0.18579775094985962\n",
      "Eval Loss:  0.19077211618423462\n",
      "Eval Loss:  0.22363032400608063\n",
      "Eval Loss:  0.24907682836055756\n",
      "Eval Loss:  0.26486730575561523\n",
      "Eval Loss:  0.2107720971107483\n",
      "Eval Loss:  0.20755988359451294\n",
      "Eval Loss:  0.25427934527397156\n",
      "Eval Loss:  0.36652109026908875\n",
      "Eval Loss:  0.15182745456695557\n",
      "Eval Loss:  0.26150238513946533\n",
      "Eval Loss:  0.29543283581733704\n",
      "Eval Loss:  0.2634684145450592\n",
      "Eval Loss:  0.23645420372486115\n",
      "Eval Loss:  0.25347283482551575\n",
      "Eval Loss:  0.22859123349189758\n",
      "Eval Loss:  0.20513543486595154\n",
      "Eval Loss:  0.21561312675476074\n",
      "Eval Loss:  0.32088854908943176\n",
      "Eval Loss:  0.24234198033809662\n",
      "Eval Loss:  0.19529029726982117\n",
      "Eval Loss:  0.23767681419849396\n",
      "Eval Loss:  0.2168193757534027\n",
      "Eval Loss:  0.2571072280406952\n",
      "Eval Loss:  0.21579748392105103\n",
      "Eval Loss:  0.24220603704452515\n",
      "[[18373   752]\n",
      " [ 2021  8313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     19125\n",
      "           1       0.92      0.80      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.88      0.89     29459\n",
      "weighted avg       0.91      0.91      0.90     29459\n",
      "\n",
      "acc:  0.9058691741063851\n",
      "pre:  0.9170435741864313\n",
      "rec:  0.8044319721308303\n",
      "ma F1:  0.8934428538851633\n",
      "mi F1:  0.9058691741063851\n",
      "we F1:  0.9043016790407062\n",
      "29459 461\n",
      "Loss:  0.04339361935853958\n",
      "Loss:  0.07469866424798965\n",
      "Loss:  0.04242715984582901\n",
      "36 **********\n",
      "Epoch:  2093.207505464554  fold:  1  kers:  64\n",
      "epoch:  37\n",
      "29459 461\n",
      "Loss:  0.07620026916265488\n",
      "Loss:  0.048521459102630615\n",
      "Loss:  0.050636377185583115\n",
      "37 **********\n",
      "Epoch:  2138.1533303260803  fold:  1  kers:  64\n",
      "epoch:  38\n",
      "29459 461\n",
      "Loss:  0.04624432325363159\n",
      "Loss:  0.062388211488723755\n",
      "Loss:  0.055579449981451035\n",
      "38 **********\n",
      "Epoch:  2182.5216975212097  fold:  1  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  1.1438931226730347\n",
      "Eval Loss:  0.22506286203861237\n",
      "Eval Loss:  0.08385395258665085\n",
      "[[ 676  363]\n",
      " [ 185 2208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71      1039\n",
      "           1       0.86      0.92      0.89      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.82      0.79      0.80      3432\n",
      "weighted avg       0.84      0.84      0.84      3432\n",
      "\n",
      "acc:  0.8403263403263403\n",
      "pre:  0.8588098016336057\n",
      "rec:  0.9226911826159633\n",
      "ma F1:  0.8005920522498834\n",
      "mi F1:  0.8403263403263405\n",
      "we F1:  0.8357096932782926\n",
      "update!  Acc:  0.8403263403263403\n",
      "Eval Loss:  0.23209649324417114\n",
      "Eval Loss:  0.2643496096134186\n",
      "Eval Loss:  0.20504729449748993\n",
      "Eval Loss:  0.21597422659397125\n",
      "Eval Loss:  0.21423213183879852\n",
      "Eval Loss:  0.2209371030330658\n",
      "Eval Loss:  0.23702111840248108\n",
      "Eval Loss:  0.18975302577018738\n",
      "Eval Loss:  0.17578580975532532\n",
      "Eval Loss:  0.21273747086524963\n",
      "Eval Loss:  0.3054423928260803\n",
      "Eval Loss:  0.15667079389095306\n",
      "Eval Loss:  0.24606813490390778\n",
      "Eval Loss:  0.2720209062099457\n",
      "Eval Loss:  0.24387042224407196\n",
      "Eval Loss:  0.2124493420124054\n",
      "Eval Loss:  0.21476761996746063\n",
      "Eval Loss:  0.20145133137702942\n",
      "Eval Loss:  0.17108044028282166\n",
      "Eval Loss:  0.21623192727565765\n",
      "Eval Loss:  0.28671523928642273\n",
      "Eval Loss:  0.21817626059055328\n",
      "Eval Loss:  0.18451860547065735\n",
      "Eval Loss:  0.216435045003891\n",
      "Eval Loss:  0.18993011116981506\n",
      "Eval Loss:  0.22815093398094177\n",
      "Eval Loss:  0.19970674812793732\n",
      "Eval Loss:  0.21022556722164154\n",
      "[[17935  1190]\n",
      " [ 1327  9007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     19125\n",
      "           1       0.88      0.87      0.88     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.90      0.91     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.914559217896059\n",
      "pre:  0.8832990095126018\n",
      "rec:  0.871588929746468\n",
      "ma F1:  0.905917913522124\n",
      "mi F1:  0.914559217896059\n",
      "we F1:  0.9144266172353029\n",
      "29459 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05035567283630371\n",
      "Loss:  0.05245837941765785\n",
      "Loss:  0.06558508425951004\n",
      "39 **********\n",
      "Epoch:  2267.14243888855  fold:  1  kers:  64\n",
      "epoch:  40\n",
      "29459 461\n",
      "Loss:  0.04922940209507942\n",
      "Loss:  0.038215093314647675\n",
      "Loss:  0.05927372723817825\n",
      "40 **********\n",
      "Epoch:  2309.2518470287323  fold:  1  kers:  64\n",
      "epoch:  41\n",
      "29459 461\n",
      "Loss:  0.03879382088780403\n",
      "Loss:  0.07746326923370361\n",
      "Loss:  0.04502493515610695\n",
      "41 **********\n",
      "Epoch:  2351.3991537094116  fold:  1  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  1.5644822120666504\n",
      "Eval Loss:  0.258512407541275\n",
      "Eval Loss:  0.1835586279630661\n",
      "[[ 703  336]\n",
      " [ 204 2189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.72      1039\n",
      "           1       0.87      0.91      0.89      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.82      0.80      0.81      3432\n",
      "weighted avg       0.84      0.84      0.84      3432\n",
      "\n",
      "acc:  0.8426573426573427\n",
      "pre:  0.8669306930693069\n",
      "rec:  0.914751358127873\n",
      "ma F1:  0.8063534880571694\n",
      "mi F1:  0.8426573426573427\n",
      "we F1:  0.8394325049674215\n",
      "update!  Acc:  0.8426573426573427\n",
      "Eval Loss:  0.22336676716804504\n",
      "Eval Loss:  0.25902172923088074\n",
      "Eval Loss:  0.1870146244764328\n",
      "Eval Loss:  0.19405803084373474\n",
      "Eval Loss:  0.19807864725589752\n",
      "Eval Loss:  0.2463279664516449\n",
      "Eval Loss:  0.2511189579963684\n",
      "Eval Loss:  0.20250418782234192\n",
      "Eval Loss:  0.21061232686042786\n",
      "Eval Loss:  0.23445862531661987\n",
      "Eval Loss:  0.3107742965221405\n",
      "Eval Loss:  0.1414320468902588\n",
      "Eval Loss:  0.2541874945163727\n",
      "Eval Loss:  0.25372371077537537\n",
      "Eval Loss:  0.24544990062713623\n",
      "Eval Loss:  0.2149180918931961\n",
      "Eval Loss:  0.24450476467609406\n",
      "Eval Loss:  0.2131219506263733\n",
      "Eval Loss:  0.18137046694755554\n",
      "Eval Loss:  0.1941038817167282\n",
      "Eval Loss:  0.29321596026420593\n",
      "Eval Loss:  0.23790767788887024\n",
      "Eval Loss:  0.19628041982650757\n",
      "Eval Loss:  0.2155618667602539\n",
      "Eval Loss:  0.206924170255661\n",
      "Eval Loss:  0.21722011268138885\n",
      "Eval Loss:  0.21098212897777557\n",
      "Eval Loss:  0.23463016748428345\n",
      "[[18066  1059]\n",
      " [ 1432  8902]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     19125\n",
      "           1       0.89      0.86      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.91      0.90      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9154418004684477\n",
      "pre:  0.8936853729545227\n",
      "rec:  0.861428294948713\n",
      "ma F1:  0.9063825800113985\n",
      "mi F1:  0.9154418004684477\n",
      "we F1:  0.915073065283978\n",
      "29459 461\n",
      "Loss:  0.06301205605268478\n",
      "Loss:  0.0543484166264534\n",
      "Loss:  0.052068356424570084\n",
      "42 **********\n",
      "Epoch:  2432.6987748146057  fold:  1  kers:  64\n",
      "epoch:  43\n",
      "29459 461\n",
      "Loss:  0.05776825547218323\n",
      "Loss:  0.0432366244494915\n",
      "Loss:  0.058752454817295074\n",
      "43 **********\n",
      "Epoch:  2474.8041937351227  fold:  1  kers:  64\n",
      "epoch:  44\n",
      "29459 461\n",
      "Loss:  0.08239413797855377\n",
      "Loss:  0.06649750471115112\n",
      "Loss:  0.08913499116897583\n",
      "44 **********\n",
      "Epoch:  2516.950503349304  fold:  1  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  1.0951966047286987\n",
      "Eval Loss:  0.298112154006958\n",
      "Eval Loss:  0.13663630187511444\n",
      "[[ 774  265]\n",
      " [ 284 2109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74      1039\n",
      "           1       0.89      0.88      0.88      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.81      0.81      0.81      3432\n",
      "weighted avg       0.84      0.84      0.84      3432\n",
      "\n",
      "acc:  0.840034965034965\n",
      "pre:  0.888374052232519\n",
      "rec:  0.8813205181780193\n",
      "ma F1:  0.8115153266691336\n",
      "mi F1:  0.840034965034965\n",
      "we F1:  0.8404408625098345\n",
      "Eval Loss:  0.20299094915390015\n",
      "Eval Loss:  0.2721279561519623\n",
      "Eval Loss:  0.19414374232292175\n",
      "Eval Loss:  0.17888210713863373\n",
      "Eval Loss:  0.2159859985113144\n",
      "Eval Loss:  0.24023543298244476\n",
      "Eval Loss:  0.2827114164829254\n",
      "Eval Loss:  0.20358887314796448\n",
      "Eval Loss:  0.19245757162570953\n",
      "Eval Loss:  0.24747365713119507\n",
      "Eval Loss:  0.3770044445991516\n",
      "Eval Loss:  0.14728787541389465\n",
      "Eval Loss:  0.2569250166416168\n",
      "Eval Loss:  0.2825135588645935\n",
      "Eval Loss:  0.24635064601898193\n",
      "Eval Loss:  0.2483936846256256\n",
      "Eval Loss:  0.25149059295654297\n",
      "Eval Loss:  0.22468878328800201\n",
      "Eval Loss:  0.19504868984222412\n",
      "Eval Loss:  0.20374266803264618\n",
      "Eval Loss:  0.308708518743515\n",
      "Eval Loss:  0.22115230560302734\n",
      "Eval Loss:  0.194339781999588\n",
      "Eval Loss:  0.24127908051013947\n",
      "Eval Loss:  0.2360822856426239\n",
      "Eval Loss:  0.2801615297794342\n",
      "Eval Loss:  0.2056785523891449\n",
      "Eval Loss:  0.2472735047340393\n",
      "[[18459   666]\n",
      " [ 1987  8347]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93     19125\n",
      "           1       0.93      0.81      0.86     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.91      0.89      0.90     29459\n",
      "weighted avg       0.91      0.91      0.91     29459\n",
      "\n",
      "acc:  0.9099426321327947\n",
      "pre:  0.9261067347165206\n",
      "rec:  0.8077220824462937\n",
      "ma F1:  0.897914374703794\n",
      "mi F1:  0.9099426321327947\n",
      "we F1:  0.9083712982657347\n",
      "29459 461\n",
      "Loss:  0.04352470487356186\n",
      "Loss:  0.062013089656829834\n",
      "Loss:  0.0757589340209961\n",
      "45 **********\n",
      "Epoch:  2598.071601867676  fold:  1  kers:  64\n",
      "epoch:  46\n",
      "29459 461\n",
      "Loss:  0.04015231132507324\n",
      "Loss:  0.046056319028139114\n",
      "Loss:  0.04936760291457176\n",
      "46 **********\n",
      "Epoch:  2640.155078649521  fold:  1  kers:  64\n",
      "epoch:  47\n",
      "29459 461\n",
      "Loss:  0.050119549036026\n",
      "Loss:  0.05878603830933571\n",
      "Loss:  0.07714194059371948\n",
      "47 **********\n",
      "Epoch:  2684.1973190307617  fold:  1  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  1.4891139268875122\n",
      "Eval Loss:  0.2608926296234131\n",
      "Eval Loss:  0.1361299604177475\n",
      "[[ 620  419]\n",
      " [ 172 2221]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.60      0.68      1039\n",
      "           1       0.84      0.93      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.81      0.76      0.78      3432\n",
      "weighted avg       0.82      0.83      0.82      3432\n",
      "\n",
      "acc:  0.8277972027972028\n",
      "pre:  0.8412878787878788\n",
      "rec:  0.9281236941078145\n",
      "ma F1:  0.7799002823853012\n",
      "mi F1:  0.8277972027972028\n",
      "we F1:  0.8204077341265347\n",
      "Eval Loss:  0.228575199842453\n",
      "Eval Loss:  0.24795794486999512\n",
      "Eval Loss:  0.20599044859409332\n",
      "Eval Loss:  0.21006633341312408\n",
      "Eval Loss:  0.16791200637817383\n",
      "Eval Loss:  0.24161887168884277\n",
      "Eval Loss:  0.2414149045944214\n",
      "Eval Loss:  0.20869222283363342\n",
      "Eval Loss:  0.17511434853076935\n",
      "Eval Loss:  0.21221692860126495\n",
      "Eval Loss:  0.27941372990608215\n",
      "Eval Loss:  0.14154325425624847\n",
      "Eval Loss:  0.2633114457130432\n",
      "Eval Loss:  0.2719776928424835\n",
      "Eval Loss:  0.25657644867897034\n",
      "Eval Loss:  0.19999702274799347\n",
      "Eval Loss:  0.19394564628601074\n",
      "Eval Loss:  0.1830708235502243\n",
      "Eval Loss:  0.16175469756126404\n",
      "Eval Loss:  0.2040644884109497\n",
      "Eval Loss:  0.2642884850502014\n",
      "Eval Loss:  0.21551470458507538\n",
      "Eval Loss:  0.1819959282875061\n",
      "Eval Loss:  0.20660915970802307\n",
      "Eval Loss:  0.1996193826198578\n",
      "Eval Loss:  0.22187717258930206\n",
      "Eval Loss:  0.19325754046440125\n",
      "Eval Loss:  0.21071983873844147\n",
      "[[17738  1387]\n",
      " [ 1120  9214]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     19125\n",
      "           1       0.87      0.89      0.88     10334\n",
      "\n",
      "    accuracy                           0.91     29459\n",
      "   macro avg       0.90      0.91      0.91     29459\n",
      "weighted avg       0.92      0.91      0.92     29459\n",
      "\n",
      "acc:  0.9148986727315931\n",
      "pre:  0.8691632864824074\n",
      "rec:  0.8916198954906135\n",
      "ma F1:  0.9071225879519806\n",
      "mi F1:  0.9148986727315931\n",
      "we F1:  0.915142245542029\n",
      "29459 461\n",
      "Loss:  0.06328825652599335\n",
      "Loss:  0.04495862126350403\n",
      "Loss:  0.06281925737857819\n",
      "48 **********\n",
      "Epoch:  2771.6913781166077  fold:  1  kers:  64\n",
      "epoch:  49\n",
      "29459 461\n",
      "Loss:  0.04589683189988136\n",
      "Loss:  0.06737184524536133\n",
      "Loss:  0.09816619753837585\n",
      "49 **********\n",
      "Epoch:  2817.180748462677  fold:  1  kers:  64\n",
      "epoch:  50\n",
      "29459 461\n",
      "Loss:  0.058841582387685776\n",
      "Loss:  0.05538978427648544\n",
      "Loss:  0.04176363721489906\n",
      "50 **********\n",
      "Epoch:  2862.1844177246094  fold:  1  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  1.4261605739593506\n",
      "Eval Loss:  0.25628605484962463\n",
      "Eval Loss:  0.1980491727590561\n",
      "[[ 731  308]\n",
      " [ 246 2147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.73      1039\n",
      "           1       0.87      0.90      0.89      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.81      0.80      0.81      3432\n",
      "weighted avg       0.84      0.84      0.84      3432\n",
      "\n",
      "acc:  0.8385780885780886\n",
      "pre:  0.8745417515274949\n",
      "rec:  0.8972001671541997\n",
      "ma F1:  0.8054622426528367\n",
      "mi F1:  0.8385780885780886\n",
      "we F1:  0.8371281009740168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21354562044143677\n",
      "Eval Loss:  0.23233181238174438\n",
      "Eval Loss:  0.17310656607151031\n",
      "Eval Loss:  0.16084949672222137\n",
      "Eval Loss:  0.18875399231910706\n",
      "Eval Loss:  0.23764625191688538\n",
      "Eval Loss:  0.2560373544692993\n",
      "Eval Loss:  0.20944678783416748\n",
      "Eval Loss:  0.18342837691307068\n",
      "Eval Loss:  0.2276822179555893\n",
      "Eval Loss:  0.32215455174446106\n",
      "Eval Loss:  0.11904144287109375\n",
      "Eval Loss:  0.22549009323120117\n",
      "Eval Loss:  0.2598128616809845\n",
      "Eval Loss:  0.252248615026474\n",
      "Eval Loss:  0.2256470024585724\n",
      "Eval Loss:  0.2266777902841568\n",
      "Eval Loss:  0.20139992237091064\n",
      "Eval Loss:  0.16555164754390717\n",
      "Eval Loss:  0.17211106419563293\n",
      "Eval Loss:  0.28259289264678955\n",
      "Eval Loss:  0.23746807873249054\n",
      "Eval Loss:  0.18883904814720154\n",
      "Eval Loss:  0.21602772176265717\n",
      "Eval Loss:  0.21015062928199768\n",
      "Eval Loss:  0.22759909927845\n",
      "Eval Loss:  0.20874328911304474\n",
      "Eval Loss:  0.23456937074661255\n",
      "[[18302   823]\n",
      " [ 1587  8747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     19125\n",
      "           1       0.91      0.85      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.90      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9181913846362741\n",
      "pre:  0.9140020898641589\n",
      "rec:  0.8464292626282175\n",
      "ma F1:  0.908573056654409\n",
      "mi F1:  0.9181913846362741\n",
      "we F1:  0.917422321048818\n",
      "29459 461\n",
      "Loss:  0.06662368774414062\n",
      "Loss:  0.05974981188774109\n",
      "Loss:  0.08512669056653976\n",
      "51 **********\n",
      "Epoch:  2952.7891590595245  fold:  1  kers:  64\n",
      "epoch:  52\n",
      "29459 461\n",
      "Loss:  0.05865659564733505\n",
      "Loss:  0.049241259694099426\n",
      "Loss:  0.07019735127687454\n",
      "52 **********\n",
      "Epoch:  2999.686764717102  fold:  1  kers:  64\n",
      "epoch:  53\n",
      "29459 461\n",
      "Loss:  0.051251400262117386\n",
      "Loss:  0.07287564128637314\n",
      "Loss:  0.04809387028217316\n",
      "53 **********\n",
      "Epoch:  3044.4929616451263  fold:  1  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  1.5337555408477783\n",
      "Eval Loss:  0.2650046944618225\n",
      "Eval Loss:  0.13056109845638275\n",
      "[[ 726  313]\n",
      " [ 240 2153]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72      1039\n",
      "           1       0.87      0.90      0.89      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.81      0.80      0.81      3432\n",
      "weighted avg       0.84      0.84      0.84      3432\n",
      "\n",
      "acc:  0.8388694638694638\n",
      "pre:  0.8730738037307381\n",
      "rec:  0.8997074801504388\n",
      "ma F1:  0.8051900501883797\n",
      "mi F1:  0.8388694638694638\n",
      "we F1:  0.8371465506257925\n",
      "Eval Loss:  0.2024383246898651\n",
      "Eval Loss:  0.23120972514152527\n",
      "Eval Loss:  0.1816396862268448\n",
      "Eval Loss:  0.15616244077682495\n",
      "Eval Loss:  0.18104493618011475\n",
      "Eval Loss:  0.24005518853664398\n",
      "Eval Loss:  0.24068285524845123\n",
      "Eval Loss:  0.20606611669063568\n",
      "Eval Loss:  0.17311881482601166\n",
      "Eval Loss:  0.22594231367111206\n",
      "Eval Loss:  0.278042733669281\n",
      "Eval Loss:  0.12199382483959198\n",
      "Eval Loss:  0.21430617570877075\n",
      "Eval Loss:  0.23692966997623444\n",
      "Eval Loss:  0.24176760017871857\n",
      "Eval Loss:  0.21046806871891022\n",
      "Eval Loss:  0.1977318525314331\n",
      "Eval Loss:  0.18828026950359344\n",
      "Eval Loss:  0.1685599684715271\n",
      "Eval Loss:  0.1784399449825287\n",
      "Eval Loss:  0.25576141476631165\n",
      "Eval Loss:  0.20613610744476318\n",
      "Eval Loss:  0.17366479337215424\n",
      "Eval Loss:  0.20064614713191986\n",
      "Eval Loss:  0.18251842260360718\n",
      "Eval Loss:  0.2214788794517517\n",
      "Eval Loss:  0.2156682163476944\n",
      "Eval Loss:  0.21017777919769287\n",
      "[[18136   989]\n",
      " [ 1379  8955]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.90      0.87      0.88     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.91      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9196170949455175\n",
      "pre:  0.9005430410297667\n",
      "rec:  0.8665569963228179\n",
      "ma F1:  0.91096977683083\n",
      "mi F1:  0.9196170949455174\n",
      "we F1:  0.9192497652358206\n",
      "29459 461\n",
      "Loss:  0.038993291556835175\n",
      "Loss:  0.06688530743122101\n",
      "Loss:  0.0712900459766388\n",
      "54 **********\n",
      "Epoch:  3133.350978374481  fold:  1  kers:  64\n",
      "epoch:  55\n",
      "29459 461\n",
      "Loss:  0.08025453984737396\n",
      "Loss:  0.0653558149933815\n",
      "Loss:  0.05780639126896858\n",
      "55 **********\n",
      "Epoch:  3179.9792568683624  fold:  1  kers:  64\n",
      "epoch:  56\n",
      "29459 461\n",
      "Loss:  0.04740756005048752\n",
      "Loss:  0.04755328595638275\n",
      "Loss:  0.06529656797647476\n",
      "56 **********\n",
      "Epoch:  3227.3416199684143  fold:  1  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  1.4461296796798706\n",
      "Eval Loss:  0.24104133248329163\n",
      "Eval Loss:  0.2007501870393753\n",
      "[[ 710  329]\n",
      " [ 247 2146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71      1039\n",
      "           1       0.87      0.90      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.79      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8321678321678322\n",
      "pre:  0.8670707070707071\n",
      "rec:  0.8967822816548265\n",
      "ma F1:  0.7965495493863651\n",
      "mi F1:  0.8321678321678322\n",
      "we F1:  0.8301339190842107\n",
      "Eval Loss:  0.18619497120380402\n",
      "Eval Loss:  0.22148343920707703\n",
      "Eval Loss:  0.17733094096183777\n",
      "Eval Loss:  0.14168012142181396\n",
      "Eval Loss:  0.17101599276065826\n",
      "Eval Loss:  0.23604314029216766\n",
      "Eval Loss:  0.2606864869594574\n",
      "Eval Loss:  0.21427686512470245\n",
      "Eval Loss:  0.16155079007148743\n",
      "Eval Loss:  0.2376568615436554\n",
      "Eval Loss:  0.2803618311882019\n",
      "Eval Loss:  0.12393385171890259\n",
      "Eval Loss:  0.21111303567886353\n",
      "Eval Loss:  0.2441990077495575\n",
      "Eval Loss:  0.23973491787910461\n",
      "Eval Loss:  0.20510311424732208\n",
      "Eval Loss:  0.2089589387178421\n",
      "Eval Loss:  0.19315111637115479\n",
      "Eval Loss:  0.16147160530090332\n",
      "Eval Loss:  0.1666214019060135\n",
      "Eval Loss:  0.26611441373825073\n",
      "Eval Loss:  0.213626891374588\n",
      "Eval Loss:  0.16854804754257202\n",
      "Eval Loss:  0.19728240370750427\n",
      "Eval Loss:  0.19824719429016113\n",
      "Eval Loss:  0.21717698872089386\n",
      "Eval Loss:  0.20781210064888\n",
      "Eval Loss:  0.22003237903118134\n",
      "[[18199   926]\n",
      " [ 1395  8939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     19125\n",
      "           1       0.91      0.87      0.89     10334\n",
      "\n",
      "    accuracy                           0.92     29459\n",
      "   macro avg       0.92      0.91      0.91     29459\n",
      "weighted avg       0.92      0.92      0.92     29459\n",
      "\n",
      "acc:  0.9212125326725279\n",
      "pre:  0.9061327927014698\n",
      "rec:  0.865008709115541\n",
      "ma F1:  0.9125742957370134\n",
      "mi F1:  0.9212125326725279\n",
      "we F1:  0.9207750236959884\n",
      "29459 461\n",
      "Loss:  0.04771294444799423\n",
      "Loss:  0.05418192595243454\n",
      "Loss:  0.05971159785985947\n",
      "57 **********\n",
      "Epoch:  3311.867556333542  fold:  1  kers:  64\n",
      "epoch:  58\n",
      "29459 461\n",
      "Loss:  0.06922493875026703\n",
      "Loss:  0.08595596253871918\n",
      "Loss:  0.056289490312337875\n",
      "58 **********\n",
      "Epoch:  3355.388190984726  fold:  1  kers:  64\n",
      "epoch:  59\n",
      "29459 461\n",
      "Loss:  0.06185184791684151\n",
      "Loss:  0.04754282161593437\n",
      "Loss:  0.099335677921772\n",
      "59 **********\n",
      "Epoch:  3399.8154015541077  fold:  1  kers:  64\n",
      "Eval Loss:  1.4492199420928955\n",
      "Eval Loss:  0.2660173177719116\n",
      "Eval Loss:  0.19055818021297455\n",
      "[[ 702  337]\n",
      " [ 203 2190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.72      1039\n",
      "           1       0.87      0.92      0.89      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.82      0.80      0.81      3432\n",
      "weighted avg       0.84      0.84      0.84      3432\n",
      "\n",
      "acc:  0.8426573426573427\n",
      "pre:  0.8666402849228334\n",
      "rec:  0.9151692436272462\n",
      "ma F1:  0.8062330623306233\n",
      "mi F1:  0.8426573426573427\n",
      "we F1:  0.8393771991332967\n",
      "update!  Acc:  0.8426573426573427\n",
      "Epoch:  3403.884521484375  fold:  1  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29797 3094\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29797 466\n",
      "Loss:  0.16796597838401794\n",
      "Loss:  0.16163432598114014\n",
      "Loss:  0.16095997393131256\n",
      "0 **********\n",
      "Epoch:  55.12061810493469  fold:  2  kers:  64\n",
      "epoch:  1\n",
      "29797 466\n",
      "Loss:  0.1491450071334839\n",
      "Loss:  0.1360141485929489\n",
      "Loss:  0.13052405416965485\n",
      "1 **********\n",
      "Epoch:  98.8756263256073  fold:  2  kers:  64\n",
      "epoch:  2\n",
      "29797 466\n",
      "Loss:  0.10670167207717896\n",
      "Loss:  0.14084912836551666\n",
      "Loss:  0.11842162907123566\n",
      "2 **********\n",
      "Epoch:  277.7950813770294  fold:  2  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  1.2631655931472778\n",
      "Eval Loss:  0.061026688665151596\n",
      "Eval Loss:  1.155139684677124\n",
      "[[1308  122]\n",
      " [ 965  699]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.91      0.71      1430\n",
      "           1       0.85      0.42      0.56      1664\n",
      "\n",
      "    accuracy                           0.65      3094\n",
      "   macro avg       0.71      0.67      0.63      3094\n",
      "weighted avg       0.72      0.65      0.63      3094\n",
      "\n",
      "acc:  0.6486748545572075\n",
      "pre:  0.8514007308160779\n",
      "rec:  0.42007211538461536\n",
      "ma F1:  0.6345148395096476\n",
      "mi F1:  0.6486748545572075\n",
      "we F1:  0.6290740455504867\n",
      "update!  Acc:  0.6486748545572075\n",
      "Eval Loss:  0.5125664472579956\n",
      "Eval Loss:  0.4434296488761902\n",
      "Eval Loss:  0.5263843536376953\n",
      "Eval Loss:  0.5751434564590454\n",
      "Eval Loss:  0.43528348207473755\n",
      "Eval Loss:  0.452375590801239\n",
      "Eval Loss:  0.4707529544830322\n",
      "Eval Loss:  0.5421231985092163\n",
      "Eval Loss:  0.3925231695175171\n",
      "Eval Loss:  0.5306825041770935\n",
      "Eval Loss:  0.5174726843833923\n",
      "Eval Loss:  0.4298938810825348\n",
      "Eval Loss:  0.5248119235038757\n",
      "Eval Loss:  0.3906075358390808\n",
      "Eval Loss:  0.4895068109035492\n",
      "Eval Loss:  0.47241345047950745\n",
      "Eval Loss:  0.3809664845466614\n",
      "Eval Loss:  0.5474541187286377\n",
      "Eval Loss:  0.5522931218147278\n",
      "Eval Loss:  0.44530189037323\n",
      "Eval Loss:  0.4362649917602539\n",
      "Eval Loss:  0.5142378211021423\n",
      "Eval Loss:  0.554973840713501\n",
      "Eval Loss:  0.499201238155365\n",
      "Eval Loss:  0.4741775393486023\n",
      "Eval Loss:  0.5530005693435669\n",
      "Eval Loss:  0.5867088437080383\n",
      "Eval Loss:  0.47102364897727966\n",
      "Eval Loss:  0.4110105037689209\n",
      "[[17215  1519]\n",
      " [ 4025  7038]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86     18734\n",
      "           1       0.82      0.64      0.72     11063\n",
      "\n",
      "    accuracy                           0.81     29797\n",
      "   macro avg       0.82      0.78      0.79     29797\n",
      "weighted avg       0.81      0.81      0.81     29797\n",
      "\n",
      "acc:  0.8139410007718898\n",
      "pre:  0.8224845156012621\n",
      "rec:  0.6361746361746362\n",
      "ma F1:  0.7893705220319813\n",
      "mi F1:  0.8139410007718898\n",
      "we F1:  0.8078907286168137\n",
      "29797 466\n",
      "Loss:  0.09381360560655594\n",
      "Loss:  0.1224418431520462\n",
      "Loss:  0.11050828546285629\n",
      "3 **********\n",
      "Epoch:  439.229505777359  fold:  2  kers:  64\n",
      "epoch:  4\n",
      "29797 466\n",
      "Loss:  0.0880226269364357\n",
      "Loss:  0.07111387699842453\n",
      "Loss:  0.07699888944625854\n",
      "4 **********\n",
      "Epoch:  482.15074372291565  fold:  2  kers:  64\n",
      "epoch:  5\n",
      "29797 466\n",
      "Loss:  0.07243681699037552\n",
      "Loss:  0.07098999619483948\n",
      "Loss:  0.07592133432626724\n",
      "5 **********\n",
      "Epoch:  525.1118741035461  fold:  2  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.9185243248939514\n",
      "Eval Loss:  0.14511702954769135\n",
      "Eval Loss:  0.6652368307113647\n",
      "[[1270  160]\n",
      " [ 691  973]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75      1430\n",
      "           1       0.86      0.58      0.70      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.75      0.74      0.72      3094\n",
      "weighted avg       0.76      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7249515190691661\n",
      "pre:  0.8587819947043248\n",
      "rec:  0.5847355769230769\n",
      "ma F1:  0.722393511099593\n",
      "mi F1:  0.724951519069166\n",
      "we F1:  0.7203781108811416\n",
      "update!  Acc:  0.7249515190691661\n",
      "Eval Loss:  0.3642309010028839\n",
      "Eval Loss:  0.2514980733394623\n",
      "Eval Loss:  0.29947274923324585\n",
      "Eval Loss:  0.43388092517852783\n",
      "Eval Loss:  0.371612548828125\n",
      "Eval Loss:  0.341636598110199\n",
      "Eval Loss:  0.31937548518180847\n",
      "Eval Loss:  0.3747910261154175\n",
      "Eval Loss:  0.276795893907547\n",
      "Eval Loss:  0.3363773226737976\n",
      "Eval Loss:  0.3783818781375885\n",
      "Eval Loss:  0.27653416991233826\n",
      "Eval Loss:  0.39494839310646057\n",
      "Eval Loss:  0.22527457773685455\n",
      "Eval Loss:  0.2992537319660187\n",
      "Eval Loss:  0.39295485615730286\n",
      "Eval Loss:  0.2736642062664032\n",
      "Eval Loss:  0.353154718875885\n",
      "Eval Loss:  0.34627705812454224\n",
      "Eval Loss:  0.3215380012989044\n",
      "Eval Loss:  0.3309148848056793\n",
      "Eval Loss:  0.3213888108730316\n",
      "Eval Loss:  0.3688731789588928\n",
      "Eval Loss:  0.3093368113040924\n",
      "Eval Loss:  0.34457114338874817\n",
      "Eval Loss:  0.36451607942581177\n",
      "Eval Loss:  0.3932151198387146\n",
      "Eval Loss:  0.34245601296424866\n",
      "Eval Loss:  0.2889825105667114\n",
      "[[17520  1214]\n",
      " [ 2741  8322]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     18734\n",
      "           1       0.87      0.75      0.81     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.87      0.84      0.85     29797\n",
      "weighted avg       0.87      0.87      0.86     29797\n",
      "\n",
      "acc:  0.8672685169647951\n",
      "pre:  0.8726929530201343\n",
      "rec:  0.7522371870197957\n",
      "ma F1:  0.8532885644880688\n",
      "mi F1:  0.8672685169647951\n",
      "we F1:  0.8649476442281174\n",
      "29797 466\n",
      "Loss:  0.08376134186983109\n",
      "Loss:  0.04995916038751602\n",
      "Loss:  0.09964136779308319\n",
      "6 **********\n",
      "Epoch:  607.9387581348419  fold:  2  kers:  64\n",
      "epoch:  7\n",
      "29797 466\n",
      "Loss:  0.06810366362333298\n",
      "Loss:  0.07952972501516342\n",
      "Loss:  0.09622261673212051\n",
      "7 **********\n",
      "Epoch:  651.3234436511993  fold:  2  kers:  64\n",
      "epoch:  8\n",
      "29797 466\n",
      "Loss:  0.07696458697319031\n",
      "Loss:  0.06103116646409035\n",
      "Loss:  0.08593118190765381\n",
      "8 **********\n",
      "Epoch:  696.4659180641174  fold:  2  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  1.35700523853302\n",
      "Eval Loss:  0.047723188996315\n",
      "Eval Loss:  1.216495394706726\n",
      "[[1383   47]\n",
      " [1083  581]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71      1430\n",
      "           1       0.93      0.35      0.51      1664\n",
      "\n",
      "    accuracy                           0.63      3094\n",
      "   macro avg       0.74      0.66      0.61      3094\n",
      "weighted avg       0.76      0.63      0.60      3094\n",
      "\n",
      "acc:  0.6347769877181642\n",
      "pre:  0.9251592356687898\n",
      "rec:  0.34915865384615385\n",
      "ma F1:  0.6084698675152571\n",
      "mi F1:  0.6347769877181642\n",
      "we F1:  0.600794223964783\n",
      "Eval Loss:  0.43869179487228394\n",
      "Eval Loss:  0.38962477445602417\n",
      "Eval Loss:  0.44844213128089905\n",
      "Eval Loss:  0.5470150709152222\n",
      "Eval Loss:  0.3727821707725525\n",
      "Eval Loss:  0.4107854664325714\n",
      "Eval Loss:  0.3870611786842346\n",
      "Eval Loss:  0.5185760259628296\n",
      "Eval Loss:  0.3729279041290283\n",
      "Eval Loss:  0.5039957761764526\n",
      "Eval Loss:  0.45454636216163635\n",
      "Eval Loss:  0.3803372383117676\n",
      "Eval Loss:  0.4798959493637085\n",
      "Eval Loss:  0.3177216053009033\n",
      "Eval Loss:  0.3818817138671875\n",
      "Eval Loss:  0.4804384410381317\n",
      "Eval Loss:  0.3846164345741272\n",
      "Eval Loss:  0.5234606862068176\n",
      "Eval Loss:  0.46797093749046326\n",
      "Eval Loss:  0.36228707432746887\n",
      "Eval Loss:  0.4276030659675598\n",
      "Eval Loss:  0.5043408870697021\n",
      "Eval Loss:  0.49030226469039917\n",
      "Eval Loss:  0.3977862298488617\n",
      "Eval Loss:  0.40947064757347107\n",
      "Eval Loss:  0.49862226843833923\n",
      "Eval Loss:  0.5341816544532776\n",
      "Eval Loss:  0.4277455806732178\n",
      "Eval Loss:  0.3485634922981262\n",
      "[[18327   407]\n",
      " [ 4372  6691]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.88     18734\n",
      "           1       0.94      0.60      0.74     11063\n",
      "\n",
      "    accuracy                           0.84     29797\n",
      "   macro avg       0.88      0.79      0.81     29797\n",
      "weighted avg       0.86      0.84      0.83     29797\n",
      "\n",
      "acc:  0.8396147263147297\n",
      "pre:  0.9426599041983658\n",
      "rec:  0.6048088222001266\n",
      "ma F1:  0.810755427410986\n",
      "mi F1:  0.8396147263147297\n",
      "we F1:  0.8297808383675533\n",
      "29797 466\n",
      "Loss:  0.07965037971735\n",
      "Loss:  0.06287107616662979\n",
      "Loss:  0.08730214834213257\n",
      "9 **********\n",
      "Epoch:  787.9247906208038  fold:  2  kers:  64\n",
      "epoch:  10\n",
      "29797 466\n",
      "Loss:  0.08106683194637299\n",
      "Loss:  0.0894322618842125\n",
      "Loss:  0.0822824165225029\n",
      "10 **********\n",
      "Epoch:  832.1854465007782  fold:  2  kers:  64\n",
      "epoch:  11\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06035277247428894\n",
      "Loss:  0.06708958745002747\n",
      "Loss:  0.0776333212852478\n",
      "11 **********\n",
      "Epoch:  876.1631700992584  fold:  2  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.8262110352516174\n",
      "Eval Loss:  0.13778823614120483\n",
      "Eval Loss:  0.5668264627456665\n",
      "[[1341   89]\n",
      " [ 778  886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.94      0.76      1430\n",
      "           1       0.91      0.53      0.67      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.77      0.74      0.71      3094\n",
      "weighted avg       0.78      0.72      0.71      3094\n",
      "\n",
      "acc:  0.7197802197802198\n",
      "pre:  0.9087179487179488\n",
      "rec:  0.5324519230769231\n",
      "ma F1:  0.7135861485994113\n",
      "mi F1:  0.7197802197802198\n",
      "we F1:  0.7104006262778525\n",
      "Eval Loss:  0.27741971611976624\n",
      "Eval Loss:  0.23032380640506744\n",
      "Eval Loss:  0.26424044370651245\n",
      "Eval Loss:  0.35922881960868835\n",
      "Eval Loss:  0.30334779620170593\n",
      "Eval Loss:  0.2641352117061615\n",
      "Eval Loss:  0.31235435605049133\n",
      "Eval Loss:  0.3542986810207367\n",
      "Eval Loss:  0.2625790238380432\n",
      "Eval Loss:  0.32124876976013184\n",
      "Eval Loss:  0.30111077427864075\n",
      "Eval Loss:  0.2520999312400818\n",
      "Eval Loss:  0.35944631695747375\n",
      "Eval Loss:  0.16938699781894684\n",
      "Eval Loss:  0.25373876094818115\n",
      "Eval Loss:  0.35023316740989685\n",
      "Eval Loss:  0.2663341462612152\n",
      "Eval Loss:  0.3271976411342621\n",
      "Eval Loss:  0.30342984199523926\n",
      "Eval Loss:  0.2992226779460907\n",
      "Eval Loss:  0.30172795057296753\n",
      "Eval Loss:  0.31385746598243713\n",
      "Eval Loss:  0.3272835314273834\n",
      "Eval Loss:  0.23296916484832764\n",
      "Eval Loss:  0.32238641381263733\n",
      "Eval Loss:  0.2883603572845459\n",
      "Eval Loss:  0.3676782548427582\n",
      "Eval Loss:  0.28528502583503723\n",
      "Eval Loss:  0.2724493741989136\n",
      "[[17881   853]\n",
      " [ 2612  8451]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18734\n",
      "           1       0.91      0.76      0.83     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.89      0.86      0.87     29797\n",
      "weighted avg       0.89      0.88      0.88     29797\n",
      "\n",
      "acc:  0.8837131254824311\n",
      "pre:  0.9083190025795357\n",
      "rec:  0.7638976769411552\n",
      "ma F1:  0.8707699176556012\n",
      "mi F1:  0.8837131254824311\n",
      "we F1:  0.8812987985929938\n",
      "29797 466\n",
      "Loss:  0.08842216432094574\n",
      "Loss:  0.06071946769952774\n",
      "Loss:  0.056695226579904556\n",
      "12 **********\n",
      "Epoch:  960.8447487354279  fold:  2  kers:  64\n",
      "epoch:  13\n",
      "29797 466\n",
      "Loss:  0.06667720526456833\n",
      "Loss:  0.06269088387489319\n",
      "Loss:  0.061155758798122406\n",
      "13 **********\n",
      "Epoch:  1004.8480932712555  fold:  2  kers:  64\n",
      "epoch:  14\n",
      "29797 466\n",
      "Loss:  0.05759572982788086\n",
      "Loss:  0.05401600897312164\n",
      "Loss:  0.09510136395692825\n",
      "14 **********\n",
      "Epoch:  1048.8464498519897  fold:  2  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.5407092571258545\n",
      "Eval Loss:  0.1807621717453003\n",
      "Eval Loss:  0.39181268215179443\n",
      "[[1321  109]\n",
      " [ 693  971]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.92      0.77      1430\n",
      "           1       0.90      0.58      0.71      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.78      0.75      0.74      3094\n",
      "weighted avg       0.79      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7407886231415644\n",
      "pre:  0.899074074074074\n",
      "rec:  0.5835336538461539\n",
      "ma F1:  0.7374285951314323\n",
      "mi F1:  0.7407886231415642\n",
      "we F1:  0.7351821764046583\n",
      "update!  Acc:  0.7407886231415644\n",
      "Eval Loss:  0.25537434220314026\n",
      "Eval Loss:  0.20504812896251678\n",
      "Eval Loss:  0.20743869245052338\n",
      "Eval Loss:  0.28707948327064514\n",
      "Eval Loss:  0.2578662633895874\n",
      "Eval Loss:  0.2637716829776764\n",
      "Eval Loss:  0.29779085516929626\n",
      "Eval Loss:  0.30840617418289185\n",
      "Eval Loss:  0.25603869557380676\n",
      "Eval Loss:  0.2636150121688843\n",
      "Eval Loss:  0.2578597962856293\n",
      "Eval Loss:  0.24042940139770508\n",
      "Eval Loss:  0.32859838008880615\n",
      "Eval Loss:  0.13138452172279358\n",
      "Eval Loss:  0.26185300946235657\n",
      "Eval Loss:  0.3177092969417572\n",
      "Eval Loss:  0.24394652247428894\n",
      "Eval Loss:  0.255764365196228\n",
      "Eval Loss:  0.2681753635406494\n",
      "Eval Loss:  0.3064282536506653\n",
      "Eval Loss:  0.26402023434638977\n",
      "Eval Loss:  0.29999974370002747\n",
      "Eval Loss:  0.32386305928230286\n",
      "Eval Loss:  0.21191218495368958\n",
      "Eval Loss:  0.2447826862335205\n",
      "Eval Loss:  0.27281588315963745\n",
      "Eval Loss:  0.3740139603614807\n",
      "Eval Loss:  0.2397967129945755\n",
      "Eval Loss:  0.22383949160575867\n",
      "[[17908   826]\n",
      " [ 2412  8651]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18734\n",
      "           1       0.91      0.78      0.84     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.90      0.87      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8913313420814176\n",
      "pre:  0.9128416165453203\n",
      "rec:  0.7819759558889994\n",
      "ma F1:  0.8797227682001637\n",
      "mi F1:  0.8913313420814176\n",
      "we F1:  0.8893424473881403\n",
      "29797 466\n",
      "Loss:  0.08765648305416107\n",
      "Loss:  0.07393129914999008\n",
      "Loss:  0.07147267460823059\n",
      "15 **********\n",
      "Epoch:  1133.1490421295166  fold:  2  kers:  64\n",
      "epoch:  16\n",
      "29797 466\n",
      "Loss:  0.08147916942834854\n",
      "Loss:  0.04954587295651436\n",
      "Loss:  0.08544651418924332\n",
      "16 **********\n",
      "Epoch:  1177.193276643753  fold:  2  kers:  64\n",
      "epoch:  17\n",
      "29797 466\n",
      "Loss:  0.07571355253458023\n",
      "Loss:  0.10470277070999146\n",
      "Loss:  0.051363054662942886\n",
      "17 **********\n",
      "Epoch:  1221.061294555664  fold:  2  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.43901312351226807\n",
      "Eval Loss:  0.2946222126483917\n",
      "Eval Loss:  0.23983940482139587\n",
      "[[1297  133]\n",
      " [ 613 1051]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78      1430\n",
      "           1       0.89      0.63      0.74      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.78      0.77      0.76      3094\n",
      "weighted avg       0.79      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7588881706528765\n",
      "pre:  0.887668918918919\n",
      "rec:  0.6316105769230769\n",
      "ma F1:  0.7573542521698178\n",
      "mi F1:  0.7588881706528765\n",
      "we F1:  0.7558951589786154\n",
      "update!  Acc:  0.7588881706528765\n",
      "Eval Loss:  0.25160861015319824\n",
      "Eval Loss:  0.20439714193344116\n",
      "Eval Loss:  0.16392609477043152\n",
      "Eval Loss:  0.23296105861663818\n",
      "Eval Loss:  0.23282302916049957\n",
      "Eval Loss:  0.23187823593616486\n",
      "Eval Loss:  0.27706512808799744\n",
      "Eval Loss:  0.243329256772995\n",
      "Eval Loss:  0.21141695976257324\n",
      "Eval Loss:  0.22788237035274506\n",
      "Eval Loss:  0.22476544976234436\n",
      "Eval Loss:  0.20470529794692993\n",
      "Eval Loss:  0.31097862124443054\n",
      "Eval Loss:  0.11550988256931305\n",
      "Eval Loss:  0.2567039132118225\n",
      "Eval Loss:  0.27672967314720154\n",
      "Eval Loss:  0.22068452835083008\n",
      "Eval Loss:  0.18858705461025238\n",
      "Eval Loss:  0.24892134964466095\n",
      "Eval Loss:  0.2674615979194641\n",
      "Eval Loss:  0.2258596122264862\n",
      "Eval Loss:  0.2724682092666626\n",
      "Eval Loss:  0.3140418529510498\n",
      "Eval Loss:  0.18653957545757294\n",
      "Eval Loss:  0.20980224013328552\n",
      "Eval Loss:  0.28076502680778503\n",
      "Eval Loss:  0.3229425549507141\n",
      "Eval Loss:  0.22114640474319458\n",
      "Eval Loss:  0.21739038825035095\n",
      "[[17831   903]\n",
      " [ 2059  9004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18734\n",
      "           1       0.91      0.81      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.88      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9005940195321677\n",
      "pre:  0.9088523266377309\n",
      "rec:  0.8138841182319443\n",
      "ma F1:  0.8910312632478086\n",
      "mi F1:  0.9005940195321677\n",
      "we F1:  0.8993416635488529\n",
      "29797 466\n",
      "Loss:  0.052940916270017624\n",
      "Loss:  0.059246815741062164\n",
      "Loss:  0.042974550276994705\n",
      "18 **********\n",
      "Epoch:  1306.025118112564  fold:  2  kers:  64\n",
      "epoch:  19\n",
      "29797 466\n",
      "Loss:  0.03995693475008011\n",
      "Loss:  0.07556429505348206\n",
      "Loss:  0.05198514461517334\n",
      "19 **********\n",
      "Epoch:  1350.0863072872162  fold:  2  kers:  64\n",
      "epoch:  20\n",
      "29797 466\n",
      "Loss:  0.07342270761728287\n",
      "Loss:  0.03758629038929939\n",
      "Loss:  0.06358987838029861\n",
      "20 **********\n",
      "Epoch:  1394.2143185138702  fold:  2  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.40996649861335754\n",
      "Eval Loss:  0.25385916233062744\n",
      "Eval Loss:  0.4955000579357147\n",
      "[[1310  120]\n",
      " [ 681  983]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.92      0.77      1430\n",
      "           1       0.89      0.59      0.71      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.77      0.75      0.74      3094\n",
      "weighted avg       0.78      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7411118293471235\n",
      "pre:  0.8912058023572076\n",
      "rec:  0.5907451923076923\n",
      "ma F1:  0.7381873707400675\n",
      "mi F1:  0.7411118293471235\n",
      "we F1:  0.7360946388928165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2856721580028534\n",
      "Eval Loss:  0.1903621107339859\n",
      "Eval Loss:  0.19169726967811584\n",
      "Eval Loss:  0.2655157148838043\n",
      "Eval Loss:  0.24665507674217224\n",
      "Eval Loss:  0.2609511613845825\n",
      "Eval Loss:  0.28937456011772156\n",
      "Eval Loss:  0.30561918020248413\n",
      "Eval Loss:  0.23288823664188385\n",
      "Eval Loss:  0.23944728076457977\n",
      "Eval Loss:  0.2652822732925415\n",
      "Eval Loss:  0.2091110199689865\n",
      "Eval Loss:  0.33475521206855774\n",
      "Eval Loss:  0.12067610770463943\n",
      "Eval Loss:  0.24019496142864227\n",
      "Eval Loss:  0.31680169701576233\n",
      "Eval Loss:  0.22578006982803345\n",
      "Eval Loss:  0.21985945105552673\n",
      "Eval Loss:  0.2871066927909851\n",
      "Eval Loss:  0.24801456928253174\n",
      "Eval Loss:  0.23304033279418945\n",
      "Eval Loss:  0.288774698972702\n",
      "Eval Loss:  0.34635311365127563\n",
      "Eval Loss:  0.20163670182228088\n",
      "Eval Loss:  0.23147957026958466\n",
      "Eval Loss:  0.3253086805343628\n",
      "Eval Loss:  0.38884371519088745\n",
      "Eval Loss:  0.22121623158454895\n",
      "Eval Loss:  0.21066522598266602\n",
      "[[18102   632]\n",
      " [ 2497  8566]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18734\n",
      "           1       0.93      0.77      0.85     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.91      0.87      0.88     29797\n",
      "weighted avg       0.90      0.89      0.89     29797\n",
      "\n",
      "acc:  0.894989428465953\n",
      "pre:  0.9312894107414655\n",
      "rec:  0.7742926873361656\n",
      "ma F1:  0.8830069251368414\n",
      "mi F1:  0.894989428465953\n",
      "we F1:  0.8926459543983363\n",
      "29797 466\n",
      "Loss:  0.06616202741861343\n",
      "Loss:  0.03615260124206543\n",
      "Loss:  0.05382563918828964\n",
      "21 **********\n",
      "Epoch:  1478.9128522872925  fold:  2  kers:  64\n",
      "epoch:  22\n",
      "29797 466\n",
      "Loss:  0.04589215666055679\n",
      "Loss:  0.04841316118836403\n",
      "Loss:  0.09491074085235596\n",
      "22 **********\n",
      "Epoch:  1522.9580841064453  fold:  2  kers:  64\n",
      "epoch:  23\n",
      "29797 466\n",
      "Loss:  0.04274555295705795\n",
      "Loss:  0.08070772141218185\n",
      "Loss:  0.05601033940911293\n",
      "23 **********\n",
      "Epoch:  1566.9394862651825  fold:  2  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.37527626752853394\n",
      "Eval Loss:  0.16828082501888275\n",
      "Eval Loss:  0.449453741312027\n",
      "[[1329  101]\n",
      " [ 655 1009]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.93      0.78      1430\n",
      "           1       0.91      0.61      0.73      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.79      0.77      0.75      3094\n",
      "weighted avg       0.80      0.76      0.75      3094\n",
      "\n",
      "acc:  0.755656108597285\n",
      "pre:  0.909009009009009\n",
      "rec:  0.6063701923076923\n",
      "ma F1:  0.7530141167735043\n",
      "mi F1:  0.755656108597285\n",
      "we F1:  0.7510821602523648\n",
      "Eval Loss:  0.28522437810897827\n",
      "Eval Loss:  0.21401454508304596\n",
      "Eval Loss:  0.21482881903648376\n",
      "Eval Loss:  0.2731378674507141\n",
      "Eval Loss:  0.23803691565990448\n",
      "Eval Loss:  0.25472551584243774\n",
      "Eval Loss:  0.3157997727394104\n",
      "Eval Loss:  0.28147974610328674\n",
      "Eval Loss:  0.2166586071252823\n",
      "Eval Loss:  0.248747318983078\n",
      "Eval Loss:  0.2361527532339096\n",
      "Eval Loss:  0.2074570506811142\n",
      "Eval Loss:  0.31861889362335205\n",
      "Eval Loss:  0.1203225702047348\n",
      "Eval Loss:  0.25874772667884827\n",
      "Eval Loss:  0.3135368227958679\n",
      "Eval Loss:  0.2230909913778305\n",
      "Eval Loss:  0.1867692619562149\n",
      "Eval Loss:  0.27758273482322693\n",
      "Eval Loss:  0.253416508436203\n",
      "Eval Loss:  0.24438108503818512\n",
      "Eval Loss:  0.30557119846343994\n",
      "Eval Loss:  0.3420335650444031\n",
      "Eval Loss:  0.21537461876869202\n",
      "Eval Loss:  0.20696371793746948\n",
      "Eval Loss:  0.2903926968574524\n",
      "Eval Loss:  0.34296470880508423\n",
      "Eval Loss:  0.25642630457878113\n",
      "Eval Loss:  0.19977721571922302\n",
      "[[18153   581]\n",
      " [ 2536  8527]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18734\n",
      "           1       0.94      0.77      0.85     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.87      0.88     29797\n",
      "weighted avg       0.90      0.90      0.89     29797\n",
      "\n",
      "acc:  0.8953921535725073\n",
      "pre:  0.9362099253403601\n",
      "rec:  0.7707674229413359\n",
      "ma F1:  0.8832028504660466\n",
      "mi F1:  0.8953921535725073\n",
      "we F1:  0.8929165575229403\n",
      "29797 466\n",
      "Loss:  0.06628508865833282\n",
      "Loss:  0.0495133176445961\n",
      "Loss:  0.045942679047584534\n",
      "24 **********\n",
      "Epoch:  1651.7587554454803  fold:  2  kers:  64\n",
      "epoch:  25\n",
      "29797 466\n",
      "Loss:  0.04692523926496506\n",
      "Loss:  0.07827654480934143\n",
      "Loss:  0.06729543954133987\n",
      "25 **********\n",
      "Epoch:  1695.8468270301819  fold:  2  kers:  64\n",
      "epoch:  26\n",
      "29797 466\n",
      "Loss:  0.046628110110759735\n",
      "Loss:  0.058635372668504715\n",
      "Loss:  0.0777316763997078\n",
      "26 **********\n",
      "Epoch:  1739.9439203739166  fold:  2  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.5097238421440125\n",
      "Eval Loss:  0.13582094013690948\n",
      "Eval Loss:  0.608070433139801\n",
      "[[1329  101]\n",
      " [ 726  938]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.76      1430\n",
      "           1       0.90      0.56      0.69      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.77      0.75      0.73      3094\n",
      "weighted avg       0.78      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7327084680025856\n",
      "pre:  0.9027911453320501\n",
      "rec:  0.5637019230769231\n",
      "ma F1:  0.7283704646147461\n",
      "mi F1:  0.7327084680025856\n",
      "we F1:  0.7257743193647347\n",
      "Eval Loss:  0.31678563356399536\n",
      "Eval Loss:  0.15933528542518616\n",
      "Eval Loss:  0.21798469126224518\n",
      "Eval Loss:  0.27454450726509094\n",
      "Eval Loss:  0.233485609292984\n",
      "Eval Loss:  0.24541884660720825\n",
      "Eval Loss:  0.31500792503356934\n",
      "Eval Loss:  0.2776821553707123\n",
      "Eval Loss:  0.21653670072555542\n",
      "Eval Loss:  0.24261625111103058\n",
      "Eval Loss:  0.24697256088256836\n",
      "Eval Loss:  0.2005157768726349\n",
      "Eval Loss:  0.31487396359443665\n",
      "Eval Loss:  0.12667720019817352\n",
      "Eval Loss:  0.23396991193294525\n",
      "Eval Loss:  0.33088165521621704\n",
      "Eval Loss:  0.21343165636062622\n",
      "Eval Loss:  0.203207328915596\n",
      "Eval Loss:  0.2699987292289734\n",
      "Eval Loss:  0.2354985773563385\n",
      "Eval Loss:  0.2254340499639511\n",
      "Eval Loss:  0.2798747420310974\n",
      "Eval Loss:  0.3701511025428772\n",
      "Eval Loss:  0.1881883144378662\n",
      "Eval Loss:  0.20428793132305145\n",
      "Eval Loss:  0.328401118516922\n",
      "Eval Loss:  0.39018622040748596\n",
      "Eval Loss:  0.2313857078552246\n",
      "Eval Loss:  0.1954701840877533\n",
      "[[18206   528]\n",
      " [ 2584  8479]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     18734\n",
      "           1       0.94      0.77      0.84     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.91      0.87      0.88     29797\n",
      "weighted avg       0.90      0.90      0.89     29797\n",
      "\n",
      "acc:  0.8955599557002383\n",
      "pre:  0.9413789275008327\n",
      "rec:  0.7664286359938534\n",
      "ma F1:  0.8831028653028841\n",
      "mi F1:  0.8955599557002383\n",
      "we F1:  0.8929268953674574\n",
      "29797 466\n",
      "Loss:  0.05007941648364067\n",
      "Loss:  0.049107909202575684\n",
      "Loss:  0.05368972569704056\n",
      "27 **********\n",
      "Epoch:  1824.7354443073273  fold:  2  kers:  64\n",
      "epoch:  28\n",
      "29797 466\n",
      "Loss:  0.05109524354338646\n",
      "Loss:  0.046823687851428986\n",
      "Loss:  0.08250515908002853\n",
      "28 **********\n",
      "Epoch:  1868.8362851142883  fold:  2  kers:  64\n",
      "epoch:  29\n",
      "29797 466\n",
      "Loss:  0.09925523400306702\n",
      "Loss:  0.06403403729200363\n",
      "Loss:  0.03504194691777229\n",
      "29 **********\n",
      "Epoch:  1912.993302822113  fold:  2  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.41443243622779846\n",
      "Eval Loss:  0.19684067368507385\n",
      "Eval Loss:  0.5508001446723938\n",
      "[[1279  151]\n",
      " [ 612 1052]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      1430\n",
      "           1       0.87      0.63      0.73      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.78      0.76      0.75      3094\n",
      "weighted avg       0.78      0.75      0.75      3094\n",
      "\n",
      "acc:  0.753393665158371\n",
      "pre:  0.8744804655029094\n",
      "rec:  0.6322115384615384\n",
      "ma F1:  0.7520590397935913\n",
      "mi F1:  0.753393665158371\n",
      "we F1:  0.7506832585805585\n",
      "Eval Loss:  0.2847099006175995\n",
      "Eval Loss:  0.14683212339878082\n",
      "Eval Loss:  0.16910281777381897\n",
      "Eval Loss:  0.22737912833690643\n",
      "Eval Loss:  0.20622394979000092\n",
      "Eval Loss:  0.22276628017425537\n",
      "Eval Loss:  0.25212937593460083\n",
      "Eval Loss:  0.23827607929706573\n",
      "Eval Loss:  0.20157542824745178\n",
      "Eval Loss:  0.23001153767108917\n",
      "Eval Loss:  0.2429763674736023\n",
      "Eval Loss:  0.16907374560832977\n",
      "Eval Loss:  0.29521632194519043\n",
      "Eval Loss:  0.09705932438373566\n",
      "Eval Loss:  0.22168776392936707\n",
      "Eval Loss:  0.2841089367866516\n",
      "Eval Loss:  0.18717819452285767\n",
      "Eval Loss:  0.18157202005386353\n",
      "Eval Loss:  0.2383134961128235\n",
      "Eval Loss:  0.19235308468341827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18044179677963257\n",
      "Eval Loss:  0.2542590796947479\n",
      "Eval Loss:  0.32054024934768677\n",
      "Eval Loss:  0.16558344662189484\n",
      "Eval Loss:  0.1832430213689804\n",
      "Eval Loss:  0.29967543482780457\n",
      "Eval Loss:  0.3632892668247223\n",
      "Eval Loss:  0.2152094542980194\n",
      "Eval Loss:  0.18459883332252502\n",
      "[[18016   718]\n",
      " [ 2072  8991]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18734\n",
      "           1       0.93      0.81      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.89      0.90     29797\n",
      "weighted avg       0.91      0.91      0.90     29797\n",
      "\n",
      "acc:  0.9063664127261134\n",
      "pre:  0.926047996704089\n",
      "rec:  0.8127090301003345\n",
      "ma F1:  0.8969090539615239\n",
      "mi F1:  0.9063664127261134\n",
      "we F1:  0.9049475469347278\n",
      "29797 466\n",
      "Loss:  0.07882636785507202\n",
      "Loss:  0.03983483463525772\n",
      "Loss:  0.08818056434392929\n",
      "30 **********\n",
      "Epoch:  1997.5980920791626  fold:  2  kers:  64\n",
      "epoch:  31\n",
      "29797 466\n",
      "Loss:  0.04143790900707245\n",
      "Loss:  0.0429055318236351\n",
      "Loss:  0.0430394671857357\n",
      "31 **********\n",
      "Epoch:  2041.782951116562  fold:  2  kers:  64\n",
      "epoch:  32\n",
      "29797 466\n",
      "Loss:  0.0641857162117958\n",
      "Loss:  0.07626177370548248\n",
      "Loss:  0.0522012785077095\n",
      "32 **********\n",
      "Epoch:  2085.7932765483856  fold:  2  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.42843806743621826\n",
      "Eval Loss:  0.19523018598556519\n",
      "Eval Loss:  0.7514667510986328\n",
      "[[1277  153]\n",
      " [ 607 1057]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      1430\n",
      "           1       0.87      0.64      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.78      0.76      0.75      3094\n",
      "weighted avg       0.78      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7543632837750485\n",
      "pre:  0.8735537190082645\n",
      "rec:  0.6352163461538461\n",
      "ma F1:  0.7531150400926627\n",
      "mi F1:  0.7543632837750485\n",
      "we F1:  0.7517873627213978\n",
      "Eval Loss:  0.2919067144393921\n",
      "Eval Loss:  0.12738144397735596\n",
      "Eval Loss:  0.15376538038253784\n",
      "Eval Loss:  0.2231556475162506\n",
      "Eval Loss:  0.21417264640331268\n",
      "Eval Loss:  0.1961909830570221\n",
      "Eval Loss:  0.2515157163143158\n",
      "Eval Loss:  0.20860207080841064\n",
      "Eval Loss:  0.1687323898077011\n",
      "Eval Loss:  0.2051132470369339\n",
      "Eval Loss:  0.24874843657016754\n",
      "Eval Loss:  0.1685018092393875\n",
      "Eval Loss:  0.27743834257125854\n",
      "Eval Loss:  0.09469086676836014\n",
      "Eval Loss:  0.20402640104293823\n",
      "Eval Loss:  0.276401162147522\n",
      "Eval Loss:  0.19115573167800903\n",
      "Eval Loss:  0.14833779633045197\n",
      "Eval Loss:  0.21387694776058197\n",
      "Eval Loss:  0.1841903030872345\n",
      "Eval Loss:  0.1715080291032791\n",
      "Eval Loss:  0.23874340951442719\n",
      "Eval Loss:  0.30104687809944153\n",
      "Eval Loss:  0.15596488118171692\n",
      "Eval Loss:  0.16437268257141113\n",
      "Eval Loss:  0.2847675085067749\n",
      "Eval Loss:  0.31496068835258484\n",
      "Eval Loss:  0.18597757816314697\n",
      "Eval Loss:  0.1706467717885971\n",
      "[[17992   742]\n",
      " [ 1844  9219]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18734\n",
      "           1       0.93      0.83      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.92      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9132127395375373\n",
      "pre:  0.9255094869992972\n",
      "rec:  0.8333182681008768\n",
      "ma F1:  0.9049753946154948\n",
      "mi F1:  0.9132127395375373\n",
      "we F1:  0.9121780246048928\n",
      "29797 466\n",
      "Loss:  0.07030004262924194\n",
      "Loss:  0.09293700009584427\n",
      "Loss:  0.07853582501411438\n",
      "33 **********\n",
      "Epoch:  2170.4505438804626  fold:  2  kers:  64\n",
      "epoch:  34\n",
      "29797 466\n",
      "Loss:  0.06109384074807167\n",
      "Loss:  0.07655153423547745\n",
      "Loss:  0.04397384077310562\n",
      "34 **********\n",
      "Epoch:  2214.7240817546844  fold:  2  kers:  64\n",
      "epoch:  35\n",
      "29797 466\n",
      "Loss:  0.05162479728460312\n",
      "Loss:  0.06151629984378815\n",
      "Loss:  0.05819291993975639\n",
      "35 **********\n",
      "Epoch:  2258.7762565612793  fold:  2  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.9151596426963806\n",
      "Eval Loss:  0.5262758135795593\n",
      "Eval Loss:  0.6598719954490662\n",
      "[[1107  323]\n",
      " [ 444 1220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74      1430\n",
      "           1       0.79      0.73      0.76      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.75      0.75      0.75      3094\n",
      "weighted avg       0.76      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7521008403361344\n",
      "pre:  0.7906675307841866\n",
      "rec:  0.7331730769230769\n",
      "ma F1:  0.7517697313209206\n",
      "mi F1:  0.7521008403361344\n",
      "we F1:  0.7524553906975581\n",
      "Eval Loss:  0.2631900906562805\n",
      "Eval Loss:  0.11772723495960236\n",
      "Eval Loss:  0.13538581132888794\n",
      "Eval Loss:  0.18711890280246735\n",
      "Eval Loss:  0.21699348092079163\n",
      "Eval Loss:  0.15832802653312683\n",
      "Eval Loss:  0.2364780306816101\n",
      "Eval Loss:  0.17759019136428833\n",
      "Eval Loss:  0.154314324259758\n",
      "Eval Loss:  0.22750724852085114\n",
      "Eval Loss:  0.2534729242324829\n",
      "Eval Loss:  0.1449929177761078\n",
      "Eval Loss:  0.2659943997859955\n",
      "Eval Loss:  0.12121199071407318\n",
      "Eval Loss:  0.22552599012851715\n",
      "Eval Loss:  0.23928439617156982\n",
      "Eval Loss:  0.21638236939907074\n",
      "Eval Loss:  0.14689300954341888\n",
      "Eval Loss:  0.20122087001800537\n",
      "Eval Loss:  0.1895594298839569\n",
      "Eval Loss:  0.14903809130191803\n",
      "Eval Loss:  0.22845518589019775\n",
      "Eval Loss:  0.2817765772342682\n",
      "Eval Loss:  0.12442347407341003\n",
      "Eval Loss:  0.16576725244522095\n",
      "Eval Loss:  0.28498518466949463\n",
      "Eval Loss:  0.3128596246242523\n",
      "Eval Loss:  0.1761542707681656\n",
      "Eval Loss:  0.16779187321662903\n",
      "[[17418  1316]\n",
      " [ 1273  9790]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18734\n",
      "           1       0.88      0.88      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.91      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9131120582608987\n",
      "pre:  0.8815054925265622\n",
      "rec:  0.8849317544969719\n",
      "ma F1:  0.907018471965809\n",
      "mi F1:  0.9131120582608987\n",
      "we F1:  0.9131464085769304\n",
      "29797 466\n",
      "Loss:  0.04151417315006256\n",
      "Loss:  0.068942129611969\n",
      "Loss:  0.05899394303560257\n",
      "36 **********\n",
      "Epoch:  2343.4139699935913  fold:  2  kers:  64\n",
      "epoch:  37\n",
      "29797 466\n",
      "Loss:  0.049059707671403885\n",
      "Loss:  0.047650035470724106\n",
      "Loss:  0.03896300494670868\n",
      "37 **********\n",
      "Epoch:  2387.5762922763824  fold:  2  kers:  64\n",
      "epoch:  38\n",
      "29797 466\n",
      "Loss:  0.047482457011938095\n",
      "Loss:  0.03525156527757645\n",
      "Loss:  0.026311248540878296\n",
      "38 **********\n",
      "Epoch:  2431.6809368133545  fold:  2  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.5245971083641052\n",
      "Eval Loss:  0.23964592814445496\n",
      "Eval Loss:  0.9012882709503174\n",
      "[[1189  241]\n",
      " [ 557 1107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.83      0.75      1430\n",
      "           1       0.82      0.67      0.74      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7420814479638009\n",
      "pre:  0.8212166172106825\n",
      "rec:  0.6652644230769231\n",
      "ma F1:  0.7419001575561732\n",
      "mi F1:  0.7420814479638009\n",
      "we F1:  0.7413828166368457\n",
      "Eval Loss:  0.2971690595149994\n",
      "Eval Loss:  0.10767160356044769\n",
      "Eval Loss:  0.15357953310012817\n",
      "Eval Loss:  0.20932592451572418\n",
      "Eval Loss:  0.21153268218040466\n",
      "Eval Loss:  0.17876560986042023\n",
      "Eval Loss:  0.23064753413200378\n",
      "Eval Loss:  0.21415811777114868\n",
      "Eval Loss:  0.1669655293226242\n",
      "Eval Loss:  0.1966252624988556\n",
      "Eval Loss:  0.2535758912563324\n",
      "Eval Loss:  0.1442565768957138\n",
      "Eval Loss:  0.2678178548812866\n",
      "Eval Loss:  0.11633197963237762\n",
      "Eval Loss:  0.20480914413928986\n",
      "Eval Loss:  0.2538791596889496\n",
      "Eval Loss:  0.20234403014183044\n",
      "Eval Loss:  0.16237564384937286\n",
      "Eval Loss:  0.21544557809829712\n",
      "Eval Loss:  0.15987661480903625\n",
      "Eval Loss:  0.16622024774551392\n",
      "Eval Loss:  0.21504613757133484\n",
      "Eval Loss:  0.30746564269065857\n",
      "Eval Loss:  0.12490278482437134\n",
      "Eval Loss:  0.19832365214824677\n",
      "Eval Loss:  0.31251779198646545\n",
      "Eval Loss:  0.3515218496322632\n",
      "Eval Loss:  0.17200292646884918\n",
      "Eval Loss:  0.17165058851242065\n",
      "[[17796   938]\n",
      " [ 1640  9423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18734\n",
      "           1       0.91      0.85      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.91     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9134812229419069\n",
      "pre:  0.9094681980503813\n",
      "rec:  0.8517581126276779\n",
      "ma F1:  0.9060638547960532\n",
      "mi F1:  0.9134812229419069\n",
      "we F1:  0.9128593439930967\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.061359673738479614\n",
      "Loss:  0.06927288323640823\n",
      "Loss:  0.03450625762343407\n",
      "39 **********\n",
      "Epoch:  2516.321158885956  fold:  2  kers:  64\n",
      "epoch:  40\n",
      "29797 466\n",
      "Loss:  0.05978669971227646\n",
      "Loss:  0.052077990025281906\n",
      "Loss:  0.05177704617381096\n",
      "40 **********\n",
      "Epoch:  2560.52197432518  fold:  2  kers:  64\n",
      "epoch:  41\n",
      "29797 466\n",
      "Loss:  0.06986326724290848\n",
      "Loss:  0.05537818372249603\n",
      "Loss:  0.037058696150779724\n",
      "41 **********\n",
      "Epoch:  2604.571195602417  fold:  2  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.5014936327934265\n",
      "Eval Loss:  0.23655134439468384\n",
      "Eval Loss:  0.891647219657898\n",
      "[[1258  172]\n",
      " [ 590 1074]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77      1430\n",
      "           1       0.86      0.65      0.74      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.77      0.76      0.75      3094\n",
      "weighted avg       0.78      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7537168713639302\n",
      "pre:  0.8619582664526485\n",
      "rec:  0.6454326923076923\n",
      "ma F1:  0.7528427567727367\n",
      "mi F1:  0.7537168713639302\n",
      "we F1:  0.7517311110426319\n",
      "Eval Loss:  0.2945035994052887\n",
      "Eval Loss:  0.12648063898086548\n",
      "Eval Loss:  0.12211599946022034\n",
      "Eval Loss:  0.20779158174991608\n",
      "Eval Loss:  0.1828683614730835\n",
      "Eval Loss:  0.152402862906456\n",
      "Eval Loss:  0.26221615076065063\n",
      "Eval Loss:  0.20029479265213013\n",
      "Eval Loss:  0.16956232488155365\n",
      "Eval Loss:  0.1909453123807907\n",
      "Eval Loss:  0.23253405094146729\n",
      "Eval Loss:  0.15474550426006317\n",
      "Eval Loss:  0.2711106538772583\n",
      "Eval Loss:  0.102753184735775\n",
      "Eval Loss:  0.18103577196598053\n",
      "Eval Loss:  0.2306697517633438\n",
      "Eval Loss:  0.2012701779603958\n",
      "Eval Loss:  0.15485358238220215\n",
      "Eval Loss:  0.19568876922130585\n",
      "Eval Loss:  0.1717519611120224\n",
      "Eval Loss:  0.14875473082065582\n",
      "Eval Loss:  0.22149839997291565\n",
      "Eval Loss:  0.2958156168460846\n",
      "Eval Loss:  0.13831190764904022\n",
      "Eval Loss:  0.1576005518436432\n",
      "Eval Loss:  0.2766258716583252\n",
      "Eval Loss:  0.3163057565689087\n",
      "Eval Loss:  0.19573470950126648\n",
      "Eval Loss:  0.15705546736717224\n",
      "[[17994   740]\n",
      " [ 1726  9337]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     18734\n",
      "           1       0.93      0.84      0.88     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.90      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9172399906030808\n",
      "pre:  0.9265654460652972\n",
      "rec:  0.8439844526801048\n",
      "ma F1:  0.9096102660151664\n",
      "mi F1:  0.9172399906030808\n",
      "we F1:  0.9163709934396658\n",
      "29797 466\n",
      "Loss:  0.0663653090596199\n",
      "Loss:  0.05073543265461922\n",
      "Loss:  0.057191651314496994\n",
      "42 **********\n",
      "Epoch:  2689.3704590797424  fold:  2  kers:  64\n",
      "epoch:  43\n",
      "29797 466\n",
      "Loss:  0.03577326238155365\n",
      "Loss:  0.07294070720672607\n",
      "Loss:  0.0370752289891243\n",
      "43 **********\n",
      "Epoch:  2733.513430118561  fold:  2  kers:  64\n",
      "epoch:  44\n",
      "29797 466\n",
      "Loss:  0.051541656255722046\n",
      "Loss:  0.046143949031829834\n",
      "Loss:  0.057676009833812714\n",
      "44 **********\n",
      "Epoch:  2777.5392394065857  fold:  2  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.4375112056732178\n",
      "Eval Loss:  0.2501755356788635\n",
      "Eval Loss:  1.159420371055603\n",
      "[[1287  143]\n",
      " [ 659 1005]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      1430\n",
      "           1       0.88      0.60      0.71      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.77      0.75      0.74      3094\n",
      "weighted avg       0.78      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7407886231415644\n",
      "pre:  0.8754355400696864\n",
      "rec:  0.6039663461538461\n",
      "ma F1:  0.7386172497016847\n",
      "mi F1:  0.7407886231415642\n",
      "we F1:  0.7368154717409335\n",
      "Eval Loss:  0.2746714651584625\n",
      "Eval Loss:  0.11473969370126724\n",
      "Eval Loss:  0.12551075220108032\n",
      "Eval Loss:  0.20942716300487518\n",
      "Eval Loss:  0.15987257659435272\n",
      "Eval Loss:  0.16540488600730896\n",
      "Eval Loss:  0.2604670822620392\n",
      "Eval Loss:  0.2176869958639145\n",
      "Eval Loss:  0.16906017065048218\n",
      "Eval Loss:  0.19295424222946167\n",
      "Eval Loss:  0.2360512912273407\n",
      "Eval Loss:  0.1596013307571411\n",
      "Eval Loss:  0.28280526399612427\n",
      "Eval Loss:  0.1120985746383667\n",
      "Eval Loss:  0.1648411750793457\n",
      "Eval Loss:  0.23098379373550415\n",
      "Eval Loss:  0.1791359782218933\n",
      "Eval Loss:  0.15438498556613922\n",
      "Eval Loss:  0.2106069028377533\n",
      "Eval Loss:  0.17944571375846863\n",
      "Eval Loss:  0.1454705148935318\n",
      "Eval Loss:  0.22920502722263336\n",
      "Eval Loss:  0.2729742228984833\n",
      "Eval Loss:  0.15404443442821503\n",
      "Eval Loss:  0.15800727903842926\n",
      "Eval Loss:  0.2740670442581177\n",
      "Eval Loss:  0.3149053752422333\n",
      "Eval Loss:  0.17994628846645355\n",
      "Eval Loss:  0.16592800617218018\n",
      "[[18107   627]\n",
      " [ 1821  9242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     18734\n",
      "           1       0.94      0.84      0.88     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.90      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9178440782629124\n",
      "pre:  0.9364677272266694\n",
      "rec:  0.8353972701798789\n",
      "ma F1:  0.9098659445673525\n",
      "mi F1:  0.9178440782629124\n",
      "we F1:  0.9167695275993479\n",
      "29797 466\n",
      "Loss:  0.04047785699367523\n",
      "Loss:  0.05488573759794235\n",
      "Loss:  0.061807986348867416\n",
      "45 **********\n",
      "Epoch:  2862.1619753837585  fold:  2  kers:  64\n",
      "epoch:  46\n",
      "29797 466\n",
      "Loss:  0.06099717691540718\n",
      "Loss:  0.02515811286866665\n",
      "Loss:  0.06398812681436539\n",
      "46 **********\n",
      "Epoch:  2906.2092020511627  fold:  2  kers:  64\n",
      "epoch:  47\n",
      "29797 466\n",
      "Loss:  0.09299545735120773\n",
      "Loss:  0.07963060587644577\n",
      "Loss:  0.062234412878751755\n",
      "47 **********\n",
      "Epoch:  2950.2923328876495  fold:  2  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.8902783989906311\n",
      "Eval Loss:  0.4128974974155426\n",
      "Eval Loss:  0.6293667554855347\n",
      "[[1093  337]\n",
      " [ 421 1243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      1430\n",
      "           1       0.79      0.75      0.77      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.75      0.76      0.75      3094\n",
      "weighted avg       0.76      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7550096961861668\n",
      "pre:  0.7867088607594936\n",
      "rec:  0.7469951923076923\n",
      "ma F1:  0.75443251420683\n",
      "mi F1:  0.7550096961861668\n",
      "we F1:  0.7553329180945952\n",
      "Eval Loss:  0.28250324726104736\n",
      "Eval Loss:  0.11568526923656464\n",
      "Eval Loss:  0.15812741219997406\n",
      "Eval Loss:  0.17943261563777924\n",
      "Eval Loss:  0.2146635502576828\n",
      "Eval Loss:  0.1635364145040512\n",
      "Eval Loss:  0.22362294793128967\n",
      "Eval Loss:  0.1965777575969696\n",
      "Eval Loss:  0.14320212602615356\n",
      "Eval Loss:  0.19902168214321136\n",
      "Eval Loss:  0.24810022115707397\n",
      "Eval Loss:  0.1327306628227234\n",
      "Eval Loss:  0.2594372630119324\n",
      "Eval Loss:  0.1168682724237442\n",
      "Eval Loss:  0.2129027545452118\n",
      "Eval Loss:  0.21296049654483795\n",
      "Eval Loss:  0.21525005996227264\n",
      "Eval Loss:  0.1410778909921646\n",
      "Eval Loss:  0.17927344143390656\n",
      "Eval Loss:  0.16256104409694672\n",
      "Eval Loss:  0.14844632148742676\n",
      "Eval Loss:  0.21538130939006805\n",
      "Eval Loss:  0.2930387556552887\n",
      "Eval Loss:  0.12213023006916046\n",
      "Eval Loss:  0.16313722729682922\n",
      "Eval Loss:  0.28142067790031433\n",
      "Eval Loss:  0.3269961178302765\n",
      "Eval Loss:  0.16068875789642334\n",
      "Eval Loss:  0.1505354344844818\n",
      "[[17687  1047]\n",
      " [ 1420  9643]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18734\n",
      "           1       0.90      0.87      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.91      0.91      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9172064301775347\n",
      "pre:  0.9020579981290926\n",
      "rec:  0.8716442194703065\n",
      "ma F1:  0.910698258990561\n",
      "mi F1:  0.9172064301775347\n",
      "we F1:  0.9169046465061347\n",
      "29797 466\n",
      "Loss:  0.030290137976408005\n",
      "Loss:  0.042658306658267975\n",
      "Loss:  0.0943891778588295\n",
      "48 **********\n",
      "Epoch:  3034.9818897247314  fold:  2  kers:  64\n",
      "epoch:  49\n",
      "29797 466\n",
      "Loss:  0.06825216114521027\n",
      "Loss:  0.04987838491797447\n",
      "Loss:  0.05110398307442665\n",
      "49 **********\n",
      "Epoch:  3079.073996782303  fold:  2  kers:  64\n",
      "epoch:  50\n",
      "29797 466\n",
      "Loss:  0.04382028430700302\n",
      "Loss:  0.058648139238357544\n",
      "Loss:  0.08531264215707779\n",
      "50 **********\n",
      "Epoch:  3123.121223449707  fold:  2  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.525109589099884\n",
      "Eval Loss:  0.20019538700580597\n",
      "Eval Loss:  1.472024917602539\n",
      "[[1238  192]\n",
      " [ 631 1033]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.75      1430\n",
      "           1       0.84      0.62      0.72      1664\n",
      "\n",
      "    accuracy                           0.73      3094\n",
      "   macro avg       0.75      0.74      0.73      3094\n",
      "weighted avg       0.76      0.73      0.73      3094\n",
      "\n",
      "acc:  0.7340012928248222\n",
      "pre:  0.843265306122449\n",
      "rec:  0.6207932692307693\n",
      "ma F1:  0.7328284025357339\n",
      "mi F1:  0.7340012928248222\n",
      "we F1:  0.7314895911813599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2926919162273407\n",
      "Eval Loss:  0.11779917031526566\n",
      "Eval Loss:  0.1197555735707283\n",
      "Eval Loss:  0.20302559435367584\n",
      "Eval Loss:  0.179756298661232\n",
      "Eval Loss:  0.14631016552448273\n",
      "Eval Loss:  0.20136071741580963\n",
      "Eval Loss:  0.20922936499118805\n",
      "Eval Loss:  0.14684756100177765\n",
      "Eval Loss:  0.18787230551242828\n",
      "Eval Loss:  0.23725980520248413\n",
      "Eval Loss:  0.13478577136993408\n",
      "Eval Loss:  0.27286502718925476\n",
      "Eval Loss:  0.10405712574720383\n",
      "Eval Loss:  0.17916809022426605\n",
      "Eval Loss:  0.16990289092063904\n",
      "Eval Loss:  0.1858006715774536\n",
      "Eval Loss:  0.14799487590789795\n",
      "Eval Loss:  0.1939806193113327\n",
      "Eval Loss:  0.14824983477592468\n",
      "Eval Loss:  0.12474469840526581\n",
      "Eval Loss:  0.21668171882629395\n",
      "Eval Loss:  0.2706484794616699\n",
      "Eval Loss:  0.11366789788007736\n",
      "Eval Loss:  0.15927967429161072\n",
      "Eval Loss:  0.26111677289009094\n",
      "Eval Loss:  0.29913175106048584\n",
      "Eval Loss:  0.15407614409923553\n",
      "Eval Loss:  0.16091394424438477\n",
      "[[17973   761]\n",
      " [ 1502  9561]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18734\n",
      "           1       0.93      0.86      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.91      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9240527569889586\n",
      "pre:  0.9262739779112575\n",
      "rec:  0.8642321251016903\n",
      "ma F1:  0.9174756392723865\n",
      "mi F1:  0.9240527569889586\n",
      "we F1:  0.9234733889162079\n",
      "29797 466\n",
      "Loss:  0.061510246247053146\n",
      "Loss:  0.0404321551322937\n",
      "Loss:  0.07235321402549744\n",
      "51 **********\n",
      "Epoch:  3207.8726150989532  fold:  2  kers:  64\n",
      "epoch:  52\n",
      "29797 466\n",
      "Loss:  0.05468904972076416\n",
      "Loss:  0.08646593987941742\n",
      "Loss:  0.04249570891261101\n",
      "52 **********\n",
      "Epoch:  3251.920839548111  fold:  2  kers:  64\n",
      "epoch:  53\n",
      "29797 466\n",
      "Loss:  0.07566433399915695\n",
      "Loss:  0.08239749073982239\n",
      "Loss:  0.06546816974878311\n",
      "53 **********\n",
      "Epoch:  3296.207426071167  fold:  2  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.45916080474853516\n",
      "Eval Loss:  0.1470564752817154\n",
      "Eval Loss:  1.2528221607208252\n",
      "[[1277  153]\n",
      " [ 621 1043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.77      1430\n",
      "           1       0.87      0.63      0.73      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.77      0.76      0.75      3094\n",
      "weighted avg       0.78      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7498383968972204\n",
      "pre:  0.8720735785953178\n",
      "rec:  0.6268028846153846\n",
      "ma F1:  0.748399256993007\n",
      "mi F1:  0.7498383968972204\n",
      "we F1:  0.7469601170887936\n",
      "Eval Loss:  0.2770320475101471\n",
      "Eval Loss:  0.10964978486299515\n",
      "Eval Loss:  0.11514896899461746\n",
      "Eval Loss:  0.2034134715795517\n",
      "Eval Loss:  0.16577984392642975\n",
      "Eval Loss:  0.15568257868289948\n",
      "Eval Loss:  0.22465473413467407\n",
      "Eval Loss:  0.210706889629364\n",
      "Eval Loss:  0.16892175376415253\n",
      "Eval Loss:  0.18303656578063965\n",
      "Eval Loss:  0.21540430188179016\n",
      "Eval Loss:  0.15073361992835999\n",
      "Eval Loss:  0.27782702445983887\n",
      "Eval Loss:  0.09315019100904465\n",
      "Eval Loss:  0.171316459774971\n",
      "Eval Loss:  0.18853332102298737\n",
      "Eval Loss:  0.15805038809776306\n",
      "Eval Loss:  0.16766095161437988\n",
      "Eval Loss:  0.1839493066072464\n",
      "Eval Loss:  0.168935164809227\n",
      "Eval Loss:  0.1361486166715622\n",
      "Eval Loss:  0.2270006239414215\n",
      "Eval Loss:  0.2590925097465515\n",
      "Eval Loss:  0.12159869819879532\n",
      "Eval Loss:  0.14558683335781097\n",
      "Eval Loss:  0.25063666701316833\n",
      "Eval Loss:  0.31805217266082764\n",
      "Eval Loss:  0.15712714195251465\n",
      "Eval Loss:  0.17629525065422058\n",
      "[[18009   725]\n",
      " [ 1573  9490]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     18734\n",
      "           1       0.93      0.86      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.91      0.92     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9228781420948418\n",
      "pre:  0.9290259422418012\n",
      "rec:  0.8578143360752056\n",
      "ma F1:  0.916013091366474\n",
      "mi F1:  0.9228781420948418\n",
      "we F1:  0.922194779843679\n",
      "29797 466\n",
      "Loss:  0.059968601912260056\n",
      "Loss:  0.04197602719068527\n",
      "Loss:  0.06204438954591751\n",
      "54 **********\n",
      "Epoch:  3380.7623438835144  fold:  2  kers:  64\n",
      "epoch:  55\n",
      "29797 466\n",
      "Loss:  0.03223627060651779\n",
      "Loss:  0.0775977224111557\n",
      "Loss:  0.05568064749240875\n",
      "55 **********\n",
      "Epoch:  3424.7407541275024  fold:  2  kers:  64\n",
      "epoch:  56\n",
      "29797 466\n",
      "Loss:  0.05033610016107559\n",
      "Loss:  0.06785116344690323\n",
      "Loss:  0.057517848908901215\n",
      "56 **********\n",
      "Epoch:  3468.7091908454895  fold:  2  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.5361975431442261\n",
      "Eval Loss:  0.2931143343448639\n",
      "Eval Loss:  0.8975188136100769\n",
      "[[1176  254]\n",
      " [ 525 1139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75      1430\n",
      "           1       0.82      0.68      0.75      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.75      0.75      0.75      3094\n",
      "weighted avg       0.76      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7482223658694247\n",
      "pre:  0.8176597272074659\n",
      "rec:  0.6844951923076923\n",
      "ma F1:  0.7481863542965775\n",
      "mi F1:  0.7482223658694247\n",
      "we F1:  0.747958605430463\n",
      "Eval Loss:  0.26592838764190674\n",
      "Eval Loss:  0.11385452002286911\n",
      "Eval Loss:  0.13318833708763123\n",
      "Eval Loss:  0.18016883730888367\n",
      "Eval Loss:  0.21055617928504944\n",
      "Eval Loss:  0.14450235664844513\n",
      "Eval Loss:  0.2019025683403015\n",
      "Eval Loss:  0.21274824440479279\n",
      "Eval Loss:  0.13640350103378296\n",
      "Eval Loss:  0.1736430525779724\n",
      "Eval Loss:  0.21547232568264008\n",
      "Eval Loss:  0.12554681301116943\n",
      "Eval Loss:  0.24389028549194336\n",
      "Eval Loss:  0.1014518290758133\n",
      "Eval Loss:  0.17490780353546143\n",
      "Eval Loss:  0.20464172959327698\n",
      "Eval Loss:  0.2030990868806839\n",
      "Eval Loss:  0.1537822037935257\n",
      "Eval Loss:  0.20580074191093445\n",
      "Eval Loss:  0.17468394339084625\n",
      "Eval Loss:  0.145056813955307\n",
      "Eval Loss:  0.2025373876094818\n",
      "Eval Loss:  0.2560078501701355\n",
      "Eval Loss:  0.11781490594148636\n",
      "Eval Loss:  0.17697909474372864\n",
      "Eval Loss:  0.2598663568496704\n",
      "Eval Loss:  0.3208608031272888\n",
      "Eval Loss:  0.15718404948711395\n",
      "Eval Loss:  0.1767980009317398\n",
      "[[17814   920]\n",
      " [ 1429  9634]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18734\n",
      "           1       0.91      0.87      0.89     11063\n",
      "\n",
      "    accuracy                           0.92     29797\n",
      "   macro avg       0.92      0.91      0.91     29797\n",
      "weighted avg       0.92      0.92      0.92     29797\n",
      "\n",
      "acc:  0.9211665603919857\n",
      "pre:  0.9128292590487019\n",
      "rec:  0.8708306969176535\n",
      "ma F1:  0.9147411480074392\n",
      "mi F1:  0.9211665603919856\n",
      "we F1:  0.9207667394991087\n",
      "29797 466\n",
      "Loss:  0.061774179339408875\n",
      "Loss:  0.05232720449566841\n",
      "Loss:  0.0527789443731308\n",
      "57 **********\n",
      "Epoch:  3553.2431647777557  fold:  2  kers:  64\n",
      "epoch:  58\n",
      "29797 466\n",
      "Loss:  0.03335094451904297\n",
      "Loss:  0.051097322255373\n",
      "Loss:  0.01737063378095627\n",
      "58 **********\n",
      "Epoch:  3597.411068677902  fold:  2  kers:  64\n",
      "epoch:  59\n",
      "29797 466\n",
      "Loss:  0.025184769183397293\n",
      "Loss:  0.050852447748184204\n",
      "Loss:  0.0317191518843174\n",
      "59 **********\n",
      "Epoch:  3641.499187231064  fold:  2  kers:  64\n",
      "Eval Loss:  0.42183956503868103\n",
      "Eval Loss:  0.25366896390914917\n",
      "Eval Loss:  0.9912043213844299\n",
      "[[1201  229]\n",
      " [ 540 1124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1430\n",
      "           1       0.83      0.68      0.75      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.77      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7514544279250162\n",
      "pre:  0.8307464892830746\n",
      "rec:  0.6754807692307693\n",
      "ma F1:  0.7513003941608296\n",
      "mi F1:  0.7514544279250162\n",
      "we F1:  0.7508322915527821\n",
      "update!  Acc:  0.7588881706528765\n",
      "Epoch:  3645.315980911255  fold:  2  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.1692742258310318\n",
      "Loss:  0.16327667236328125\n",
      "Loss:  0.1539754420518875\n",
      "0 **********\n",
      "Epoch:  64.35193514823914  fold:  3  kers:  64\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.14103253185749054\n",
      "Loss:  0.1500866711139679\n",
      "Loss:  0.12195885181427002\n",
      "1 **********\n",
      "Epoch:  108.19869780540466  fold:  3  kers:  64\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.1221524327993393\n",
      "Loss:  0.10506720095872879\n",
      "Loss:  0.14766350388526917\n",
      "2 **********\n",
      "Epoch:  151.99958276748657  fold:  3  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.9357452988624573\n",
      "Eval Loss:  0.9027650952339172\n",
      "Eval Loss:  0.3454551100730896\n",
      "[[1322  214]\n",
      " [ 625 1270]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76      1536\n",
      "           1       0.86      0.67      0.75      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.78      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7554648790440105\n",
      "pre:  0.8557951482479784\n",
      "rec:  0.6701846965699209\n",
      "ma F1:  0.7554086958708757\n",
      "mi F1:  0.7554648790440105\n",
      "we F1:  0.7550208158871178\n",
      "update!  Acc:  0.7554648790440105\n",
      "Eval Loss:  0.3499508202075958\n",
      "Eval Loss:  0.44307228922843933\n",
      "Eval Loss:  0.3851737976074219\n",
      "Eval Loss:  0.4304291009902954\n",
      "Eval Loss:  0.38769418001174927\n",
      "Eval Loss:  0.38534098863601685\n",
      "Eval Loss:  0.3440919518470764\n",
      "Eval Loss:  0.43301042914390564\n",
      "Eval Loss:  0.5277677178382874\n",
      "Eval Loss:  0.4356524646282196\n",
      "Eval Loss:  0.44764724373817444\n",
      "Eval Loss:  0.3883654773235321\n",
      "Eval Loss:  0.3879642188549042\n",
      "Eval Loss:  0.5817363858222961\n",
      "Eval Loss:  0.4958502948284149\n",
      "Eval Loss:  0.41438010334968567\n",
      "Eval Loss:  0.42887598276138306\n",
      "Eval Loss:  0.3946317434310913\n",
      "Eval Loss:  0.4115005135536194\n",
      "Eval Loss:  0.37761446833610535\n",
      "Eval Loss:  0.4905635714530945\n",
      "Eval Loss:  0.3825529217720032\n",
      "Eval Loss:  0.4500657916069031\n",
      "Eval Loss:  0.4865180253982544\n",
      "Eval Loss:  0.4725131392478943\n",
      "Eval Loss:  0.43945610523223877\n",
      "Eval Loss:  0.4378812313079834\n",
      "Eval Loss:  0.25825151801109314\n",
      "[[16425  2203]\n",
      " [ 3109  7723]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86     18628\n",
      "           1       0.78      0.71      0.74     10832\n",
      "\n",
      "    accuracy                           0.82     29460\n",
      "   macro avg       0.81      0.80      0.80     29460\n",
      "weighted avg       0.82      0.82      0.82     29460\n",
      "\n",
      "acc:  0.8196877121520706\n",
      "pre:  0.7780576264356236\n",
      "rec:  0.7129800590841949\n",
      "ma F1:  0.8024513009252662\n",
      "mi F1:  0.8196877121520706\n",
      "we F1:  0.8178931604890638\n",
      "29460 461\n",
      "Loss:  0.12429945915937424\n",
      "Loss:  0.09558156877756119\n",
      "Loss:  0.10608474910259247\n",
      "3 **********\n",
      "Epoch:  236.82876706123352  fold:  3  kers:  64\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.10412631183862686\n",
      "Loss:  0.1259230077266693\n",
      "Loss:  0.08758080005645752\n",
      "4 **********\n",
      "Epoch:  280.7922179698944  fold:  3  kers:  64\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.06147602200508118\n",
      "Loss:  0.06594665348529816\n",
      "Loss:  0.07919105142354965\n",
      "5 **********\n",
      "Epoch:  324.7337272167206  fold:  3  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  1.0016449689865112\n",
      "Eval Loss:  0.4018036723136902\n",
      "Eval Loss:  0.5464861989021301\n",
      "[[1389  147]\n",
      " [ 653 1242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.78      1536\n",
      "           1       0.89      0.66      0.76      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.78      0.77      3431\n",
      "weighted avg       0.80      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7668318274555523\n",
      "pre:  0.8941684665226782\n",
      "rec:  0.6554089709762533\n",
      "ma F1:  0.7664030218502706\n",
      "mi F1:  0.7668318274555523\n",
      "we F1:  0.7653558027190043\n",
      "update!  Acc:  0.7668318274555523\n",
      "Eval Loss:  0.287723183631897\n",
      "Eval Loss:  0.44181469082832336\n",
      "Eval Loss:  0.3904534578323364\n",
      "Eval Loss:  0.3739536702632904\n",
      "Eval Loss:  0.36839592456817627\n",
      "Eval Loss:  0.321511834859848\n",
      "Eval Loss:  0.33364546298980713\n",
      "Eval Loss:  0.41168639063835144\n",
      "Eval Loss:  0.4938204288482666\n",
      "Eval Loss:  0.41186973452568054\n",
      "Eval Loss:  0.3861868381500244\n",
      "Eval Loss:  0.3115459382534027\n",
      "Eval Loss:  0.3754645586013794\n",
      "Eval Loss:  0.46905937790870667\n",
      "Eval Loss:  0.42672184109687805\n",
      "Eval Loss:  0.3445594608783722\n",
      "Eval Loss:  0.39485982060432434\n",
      "Eval Loss:  0.3471081852912903\n",
      "Eval Loss:  0.36071592569351196\n",
      "Eval Loss:  0.3300584554672241\n",
      "Eval Loss:  0.4045470058917999\n",
      "Eval Loss:  0.3240252137184143\n",
      "Eval Loss:  0.4504879117012024\n",
      "Eval Loss:  0.4058114290237427\n",
      "Eval Loss:  0.4015083909034729\n",
      "Eval Loss:  0.3951547145843506\n",
      "Eval Loss:  0.4174191653728485\n",
      "Eval Loss:  0.22565720975399017\n",
      "[[17632   996]\n",
      " [ 3234  7598]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.89     18628\n",
      "           1       0.88      0.70      0.78     10832\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.86      0.82      0.84     29460\n",
      "weighted avg       0.86      0.86      0.85     29460\n",
      "\n",
      "acc:  0.8564154786150713\n",
      "pre:  0.8841051896672096\n",
      "rec:  0.7014401772525849\n",
      "ma F1:  0.837572857649993\n",
      "mi F1:  0.8564154786150713\n",
      "we F1:  0.8522127891871416\n",
      "29460 461\n",
      "Loss:  0.07409802079200745\n",
      "Loss:  0.08283034712076187\n",
      "Loss:  0.07597999274730682\n",
      "6 **********\n",
      "Epoch:  409.67560958862305  fold:  3  kers:  64\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.0582985058426857\n",
      "Loss:  0.07104524224996567\n",
      "Loss:  0.0892738327383995\n",
      "7 **********\n",
      "Epoch:  453.5572774410248  fold:  3  kers:  64\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.07540136575698853\n",
      "Loss:  0.08334819972515106\n",
      "Loss:  0.0752003863453865\n",
      "8 **********\n",
      "Epoch:  497.4150106906891  fold:  3  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.9420347213745117\n",
      "Eval Loss:  0.28388404846191406\n",
      "Eval Loss:  0.5769734382629395\n",
      "[[1328  208]\n",
      " [ 598 1297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.77      1536\n",
      "           1       0.86      0.68      0.76      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.77      0.77      3431\n",
      "weighted avg       0.78      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7650830661614689\n",
      "pre:  0.8617940199335549\n",
      "rec:  0.6844327176781002\n",
      "ma F1:  0.7650638869065824\n",
      "mi F1:  0.7650830661614688\n",
      "we F1:  0.7648417787612831\n",
      "Eval Loss:  0.23983250558376312\n",
      "Eval Loss:  0.4039604067802429\n",
      "Eval Loss:  0.35884082317352295\n",
      "Eval Loss:  0.3509838581085205\n",
      "Eval Loss:  0.34610694646835327\n",
      "Eval Loss:  0.29149308800697327\n",
      "Eval Loss:  0.29974445700645447\n",
      "Eval Loss:  0.3405537009239197\n",
      "Eval Loss:  0.44023340940475464\n",
      "Eval Loss:  0.35654041171073914\n",
      "Eval Loss:  0.34720340371131897\n",
      "Eval Loss:  0.26815274357795715\n",
      "Eval Loss:  0.35646679997444153\n",
      "Eval Loss:  0.37554746866226196\n",
      "Eval Loss:  0.39497110247612\n",
      "Eval Loss:  0.3091357350349426\n",
      "Eval Loss:  0.37448495626449585\n",
      "Eval Loss:  0.3150196075439453\n",
      "Eval Loss:  0.3488357365131378\n",
      "Eval Loss:  0.27936851978302\n",
      "Eval Loss:  0.37991660833358765\n",
      "Eval Loss:  0.3008550703525543\n",
      "Eval Loss:  0.4131353497505188\n",
      "Eval Loss:  0.36952635645866394\n",
      "Eval Loss:  0.3724280893802643\n",
      "Eval Loss:  0.36645999550819397\n",
      "Eval Loss:  0.3855650722980499\n",
      "Eval Loss:  0.2230256050825119\n",
      "[[17666   962]\n",
      " [ 2944  7888]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18628\n",
      "           1       0.89      0.73      0.80     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.87      0.84      0.85     29460\n",
      "weighted avg       0.87      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8674134419551934\n",
      "pre:  0.8912994350282486\n",
      "rec:  0.7282127031019202\n",
      "ma F1:  0.8509991001788004\n",
      "mi F1:  0.8674134419551934\n",
      "we F1:  0.8640862558843393\n",
      "29460 461\n",
      "Loss:  0.08283920586109161\n",
      "Loss:  0.09987934678792953\n",
      "Loss:  0.09359542280435562\n",
      "9 **********\n",
      "Epoch:  582.5304293632507  fold:  3  kers:  64\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.09554360806941986\n",
      "Loss:  0.08584412187337875\n",
      "Loss:  0.06769613921642303\n",
      "10 **********\n",
      "Epoch:  626.1539285182953  fold:  3  kers:  64\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08401267230510712\n",
      "Loss:  0.058215245604515076\n",
      "Loss:  0.08214226365089417\n",
      "11 **********\n",
      "Epoch:  669.799230337143  fold:  3  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  1.2575609683990479\n",
      "Eval Loss:  0.3754345774650574\n",
      "Eval Loss:  0.715817391872406\n",
      "[[1414  122]\n",
      " [ 791 1104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.92      0.76      1536\n",
      "           1       0.90      0.58      0.71      1895\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.77      0.75      0.73      3431\n",
      "weighted avg       0.78      0.73      0.73      3431\n",
      "\n",
      "acc:  0.7338968230836491\n",
      "pre:  0.9004893964110929\n",
      "rec:  0.5825857519788918\n",
      "ma F1:  0.73170658175156\n",
      "mi F1:  0.7338968230836491\n",
      "we F1:  0.7291701409831084\n",
      "Eval Loss:  0.2845573425292969\n",
      "Eval Loss:  0.4735051989555359\n",
      "Eval Loss:  0.44531768560409546\n",
      "Eval Loss:  0.4028710424900055\n",
      "Eval Loss:  0.41287973523139954\n",
      "Eval Loss:  0.3534962832927704\n",
      "Eval Loss:  0.35253268480300903\n",
      "Eval Loss:  0.3866593539714813\n",
      "Eval Loss:  0.5681473612785339\n",
      "Eval Loss:  0.4593248963356018\n",
      "Eval Loss:  0.4399975836277008\n",
      "Eval Loss:  0.3720048666000366\n",
      "Eval Loss:  0.40331587195396423\n",
      "Eval Loss:  0.4579934775829315\n",
      "Eval Loss:  0.4902975261211395\n",
      "Eval Loss:  0.4015408754348755\n",
      "Eval Loss:  0.40837833285331726\n",
      "Eval Loss:  0.38609832525253296\n",
      "Eval Loss:  0.39807558059692383\n",
      "Eval Loss:  0.3611036539077759\n",
      "Eval Loss:  0.5149145722389221\n",
      "Eval Loss:  0.34588247537612915\n",
      "Eval Loss:  0.5265702605247498\n",
      "Eval Loss:  0.4735974371433258\n",
      "Eval Loss:  0.4816514253616333\n",
      "Eval Loss:  0.43180084228515625\n",
      "Eval Loss:  0.4676054120063782\n",
      "Eval Loss:  0.26883113384246826\n",
      "[[18272   356]\n",
      " [ 4269  6563]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     18628\n",
      "           1       0.95      0.61      0.74     10832\n",
      "\n",
      "    accuracy                           0.84     29460\n",
      "   macro avg       0.88      0.79      0.81     29460\n",
      "weighted avg       0.86      0.84      0.83     29460\n",
      "\n",
      "acc:  0.8430074677528853\n",
      "pre:  0.9485474779592427\n",
      "rec:  0.6058899556868538\n",
      "ma F1:  0.8135547439663793\n",
      "mi F1:  0.8430074677528853\n",
      "we F1:  0.8331647392383581\n",
      "29460 461\n",
      "Loss:  0.04146077483892441\n",
      "Loss:  0.06880690902471542\n",
      "Loss:  0.06262318789958954\n",
      "12 **********\n",
      "Epoch:  754.3107581138611  fold:  3  kers:  64\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.08134644478559494\n",
      "Loss:  0.058538153767585754\n",
      "Loss:  0.0660891905426979\n",
      "13 **********\n",
      "Epoch:  798.0727474689484  fold:  3  kers:  64\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.07950146496295929\n",
      "Loss:  0.06721793860197067\n",
      "Loss:  0.054716452956199646\n",
      "14 **********\n",
      "Epoch:  841.830747127533  fold:  3  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.9337854385375977\n",
      "Eval Loss:  0.27453818917274475\n",
      "Eval Loss:  0.7747681140899658\n",
      "[[1332  204]\n",
      " [ 651 1244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76      1536\n",
      "           1       0.86      0.66      0.74      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.76      0.75      3431\n",
      "weighted avg       0.78      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7508015155931216\n",
      "pre:  0.8591160220994475\n",
      "rec:  0.6564643799472295\n",
      "ma F1:  0.7506374735772654\n",
      "mi F1:  0.7508015155931217\n",
      "we F1:  0.7499682567171247\n",
      "Eval Loss:  0.22394093871116638\n",
      "Eval Loss:  0.34361186623573303\n",
      "Eval Loss:  0.3677726686000824\n",
      "Eval Loss:  0.31545042991638184\n",
      "Eval Loss:  0.3125340938568115\n",
      "Eval Loss:  0.27122437953948975\n",
      "Eval Loss:  0.28995388746261597\n",
      "Eval Loss:  0.29935622215270996\n",
      "Eval Loss:  0.42561185359954834\n",
      "Eval Loss:  0.3568843901157379\n",
      "Eval Loss:  0.32059091329574585\n",
      "Eval Loss:  0.27766209840774536\n",
      "Eval Loss:  0.34082239866256714\n",
      "Eval Loss:  0.3680473268032074\n",
      "Eval Loss:  0.3707106411457062\n",
      "Eval Loss:  0.31259727478027344\n",
      "Eval Loss:  0.35289958119392395\n",
      "Eval Loss:  0.29698851704597473\n",
      "Eval Loss:  0.28083932399749756\n",
      "Eval Loss:  0.2791629135608673\n",
      "Eval Loss:  0.3877514600753784\n",
      "Eval Loss:  0.28368350863456726\n",
      "Eval Loss:  0.4303114116191864\n",
      "Eval Loss:  0.337903767824173\n",
      "Eval Loss:  0.3774079978466034\n",
      "Eval Loss:  0.34838998317718506\n",
      "Eval Loss:  0.37331831455230713\n",
      "Eval Loss:  0.1886959969997406\n",
      "[[18060   568]\n",
      " [ 3160  7672]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91     18628\n",
      "           1       0.93      0.71      0.80     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.89      0.84      0.86     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8734555329260013\n",
      "pre:  0.9310679611650485\n",
      "rec:  0.7082717872968981\n",
      "ma F1:  0.855487345200352\n",
      "mi F1:  0.8734555329260013\n",
      "we F1:  0.8689721345254543\n",
      "29460 461\n",
      "Loss:  0.09674634784460068\n",
      "Loss:  0.07601038366556168\n",
      "Loss:  0.06533712148666382\n",
      "15 **********\n",
      "Epoch:  926.2809448242188  fold:  3  kers:  64\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.07172340154647827\n",
      "Loss:  0.04940514639019966\n",
      "Loss:  0.062106043100357056\n",
      "16 **********\n",
      "Epoch:  969.9591579437256  fold:  3  kers:  64\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.07943134754896164\n",
      "Loss:  0.09061013162136078\n",
      "Loss:  0.05725473165512085\n",
      "17 **********\n",
      "Epoch:  1013.6493394374847  fold:  3  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.8978736400604248\n",
      "Eval Loss:  0.21187035739421844\n",
      "Eval Loss:  0.8158432245254517\n",
      "[[1278  258]\n",
      " [ 609 1286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.83      0.75      1536\n",
      "           1       0.83      0.68      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7473039930049549\n",
      "pre:  0.832901554404145\n",
      "rec:  0.6786279683377309\n",
      "ma F1:  0.7473026191550802\n",
      "mi F1:  0.7473039930049548\n",
      "we F1:  0.7473642706682043\n",
      "Eval Loss:  0.19103819131851196\n",
      "Eval Loss:  0.3089839816093445\n",
      "Eval Loss:  0.3379247784614563\n",
      "Eval Loss:  0.27051883935928345\n",
      "Eval Loss:  0.2957605719566345\n",
      "Eval Loss:  0.2299741804599762\n",
      "Eval Loss:  0.25034746527671814\n",
      "Eval Loss:  0.28806838393211365\n",
      "Eval Loss:  0.4045819342136383\n",
      "Eval Loss:  0.3193190395832062\n",
      "Eval Loss:  0.2675768733024597\n",
      "Eval Loss:  0.27139154076576233\n",
      "Eval Loss:  0.3193231523036957\n",
      "Eval Loss:  0.28557318449020386\n",
      "Eval Loss:  0.30230939388275146\n",
      "Eval Loss:  0.2802450656890869\n",
      "Eval Loss:  0.3199373185634613\n",
      "Eval Loss:  0.25296109914779663\n",
      "Eval Loss:  0.2508713901042938\n",
      "Eval Loss:  0.238912433385849\n",
      "Eval Loss:  0.3445236384868622\n",
      "Eval Loss:  0.2546120285987854\n",
      "Eval Loss:  0.37682121992111206\n",
      "Eval Loss:  0.30609631538391113\n",
      "Eval Loss:  0.3572066128253937\n",
      "Eval Loss:  0.3263768255710602\n",
      "Eval Loss:  0.29449984431266785\n",
      "Eval Loss:  0.17926685512065887\n",
      "[[17961   667]\n",
      " [ 2577  8255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92     18628\n",
      "           1       0.93      0.76      0.84     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.86      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8898845892735913\n",
      "pre:  0.9252409773593365\n",
      "rec:  0.7620937961595273\n",
      "ma F1:  0.87647657671771\n",
      "mi F1:  0.8898845892735913\n",
      "we F1:  0.887246086905805\n",
      "29460 461\n",
      "Loss:  0.05879906192421913\n",
      "Loss:  0.08550052344799042\n",
      "Loss:  0.06426268815994263\n",
      "18 **********\n",
      "Epoch:  1098.336995124817  fold:  3  kers:  64\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.04325895756483078\n",
      "Loss:  0.06053430214524269\n",
      "Loss:  0.05469673499464989\n",
      "19 **********\n",
      "Epoch:  1142.1827595233917  fold:  3  kers:  64\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.10522972792387009\n",
      "Loss:  0.04990800470113754\n",
      "Loss:  0.09499303251504898\n",
      "20 **********\n",
      "Epoch:  1185.9417569637299  fold:  3  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.6083666682243347\n",
      "Eval Loss:  0.1519881635904312\n",
      "Eval Loss:  0.534766674041748\n",
      "[[1221  315]\n",
      " [ 487 1408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75      1536\n",
      "           1       0.82      0.74      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7662489070241912\n",
      "pre:  0.8171793383633198\n",
      "rec:  0.7430079155672823\n",
      "ma F1:  0.7655524610131967\n",
      "mi F1:  0.7662489070241914\n",
      "we F1:  0.7668894883818972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19470544159412384\n",
      "Eval Loss:  0.2773257791996002\n",
      "Eval Loss:  0.2894067168235779\n",
      "Eval Loss:  0.22880296409130096\n",
      "Eval Loss:  0.2746853828430176\n",
      "Eval Loss:  0.20342454314231873\n",
      "Eval Loss:  0.21630799770355225\n",
      "Eval Loss:  0.24633829295635223\n",
      "Eval Loss:  0.3361438512802124\n",
      "Eval Loss:  0.24140650033950806\n",
      "Eval Loss:  0.2185530662536621\n",
      "Eval Loss:  0.2673623859882355\n",
      "Eval Loss:  0.27485719323158264\n",
      "Eval Loss:  0.24455080926418304\n",
      "Eval Loss:  0.2287365347146988\n",
      "Eval Loss:  0.25421059131622314\n",
      "Eval Loss:  0.2765916883945465\n",
      "Eval Loss:  0.1943926066160202\n",
      "Eval Loss:  0.23109732568264008\n",
      "Eval Loss:  0.22686165571212769\n",
      "Eval Loss:  0.2845243513584137\n",
      "Eval Loss:  0.22406898438930511\n",
      "Eval Loss:  0.3079472780227661\n",
      "Eval Loss:  0.24405428767204285\n",
      "Eval Loss:  0.3256787359714508\n",
      "Eval Loss:  0.29066017270088196\n",
      "Eval Loss:  0.2412489950656891\n",
      "Eval Loss:  0.17934323847293854\n",
      "[[17405  1223]\n",
      " [ 1664  9168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18628\n",
      "           1       0.88      0.85      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9020027155465037\n",
      "pre:  0.8823019921085555\n",
      "rec:  0.8463810930576071\n",
      "ma F1:  0.8936919963286343\n",
      "mi F1:  0.9020027155465037\n",
      "we F1:  0.9015577686999479\n",
      "29460 461\n",
      "Loss:  0.05193125456571579\n",
      "Loss:  0.04988435283303261\n",
      "Loss:  0.04794441908597946\n",
      "21 **********\n",
      "Epoch:  1270.6053836345673  fold:  3  kers:  64\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.05659323185682297\n",
      "Loss:  0.05042559280991554\n",
      "Loss:  0.09520231187343597\n",
      "22 **********\n",
      "Epoch:  1314.0781462192535  fold:  3  kers:  64\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.040155984461307526\n",
      "Loss:  0.0870133638381958\n",
      "Loss:  0.049718890339136124\n",
      "23 **********\n",
      "Epoch:  1357.6257090568542  fold:  3  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.5533624291419983\n",
      "Eval Loss:  0.18981969356536865\n",
      "Eval Loss:  0.7723404169082642\n",
      "[[1206  330]\n",
      " [ 470 1425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75      1536\n",
      "           1       0.81      0.75      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7668318274555523\n",
      "pre:  0.811965811965812\n",
      "rec:  0.7519788918205804\n",
      "ma F1:  0.7658779576587795\n",
      "mi F1:  0.7668318274555523\n",
      "we F1:  0.7674416072343111\n",
      "Eval Loss:  0.1909109503030777\n",
      "Eval Loss:  0.2563546895980835\n",
      "Eval Loss:  0.27187249064445496\n",
      "Eval Loss:  0.21583721041679382\n",
      "Eval Loss:  0.27238306403160095\n",
      "Eval Loss:  0.17998428642749786\n",
      "Eval Loss:  0.2026498168706894\n",
      "Eval Loss:  0.22534507513046265\n",
      "Eval Loss:  0.32324445247650146\n",
      "Eval Loss:  0.2280859351158142\n",
      "Eval Loss:  0.19673208892345428\n",
      "Eval Loss:  0.2479899823665619\n",
      "Eval Loss:  0.2711721658706665\n",
      "Eval Loss:  0.2222348153591156\n",
      "Eval Loss:  0.1946464478969574\n",
      "Eval Loss:  0.25513985753059387\n",
      "Eval Loss:  0.2820807993412018\n",
      "Eval Loss:  0.20548659563064575\n",
      "Eval Loss:  0.21024703979492188\n",
      "Eval Loss:  0.2020442634820938\n",
      "Eval Loss:  0.2837400436401367\n",
      "Eval Loss:  0.24403537809848785\n",
      "Eval Loss:  0.308687299489975\n",
      "Eval Loss:  0.22359699010849\n",
      "Eval Loss:  0.3306125998497009\n",
      "Eval Loss:  0.2839433252811432\n",
      "Eval Loss:  0.23286259174346924\n",
      "Eval Loss:  0.15932601690292358\n",
      "[[17371  1257]\n",
      " [ 1535  9297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18628\n",
      "           1       0.88      0.86      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.90      0.91      0.90     29460\n",
      "\n",
      "acc:  0.9052274270196877\n",
      "pre:  0.8808982376350198\n",
      "rec:  0.8582902511078286\n",
      "ma F1:  0.897530705923484\n",
      "mi F1:  0.9052274270196877\n",
      "we F1:  0.904962417301488\n",
      "29460 461\n",
      "Loss:  0.06970591098070145\n",
      "Loss:  0.035174474120140076\n",
      "Loss:  0.07528368383646011\n",
      "24 **********\n",
      "Epoch:  1441.9761729240417  fold:  3  kers:  64\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.04807649925351143\n",
      "Loss:  0.08405683934688568\n",
      "Loss:  0.03899350389838219\n",
      "25 **********\n",
      "Epoch:  1485.648155450821  fold:  3  kers:  64\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.10082204639911652\n",
      "Loss:  0.08613155782222748\n",
      "Loss:  0.055130258202552795\n",
      "26 **********\n",
      "Epoch:  1529.2854783535004  fold:  3  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.5640882253646851\n",
      "Eval Loss:  0.19269302487373352\n",
      "Eval Loss:  0.7474133968353271\n",
      "[[1240  296]\n",
      " [ 568 1327]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74      1536\n",
      "           1       0.82      0.70      0.75      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7481783736519965\n",
      "pre:  0.8176216882316697\n",
      "rec:  0.700263852242744\n",
      "ma F1:  0.7480163533543145\n",
      "mi F1:  0.7481783736519965\n",
      "we F1:  0.7486849198700367\n",
      "Eval Loss:  0.1767975389957428\n",
      "Eval Loss:  0.2249636948108673\n",
      "Eval Loss:  0.27058619260787964\n",
      "Eval Loss:  0.21101829409599304\n",
      "Eval Loss:  0.25523364543914795\n",
      "Eval Loss:  0.17177221179008484\n",
      "Eval Loss:  0.20156966149806976\n",
      "Eval Loss:  0.20177215337753296\n",
      "Eval Loss:  0.30376166105270386\n",
      "Eval Loss:  0.22139017283916473\n",
      "Eval Loss:  0.19905053079128265\n",
      "Eval Loss:  0.2663385570049286\n",
      "Eval Loss:  0.26761147379875183\n",
      "Eval Loss:  0.2342141568660736\n",
      "Eval Loss:  0.20630145072937012\n",
      "Eval Loss:  0.2491125613451004\n",
      "Eval Loss:  0.2551383376121521\n",
      "Eval Loss:  0.19669009745121002\n",
      "Eval Loss:  0.23587298393249512\n",
      "Eval Loss:  0.20926037430763245\n",
      "Eval Loss:  0.25247442722320557\n",
      "Eval Loss:  0.22274918854236603\n",
      "Eval Loss:  0.3113076984882355\n",
      "Eval Loss:  0.24130535125732422\n",
      "Eval Loss:  0.31645649671554565\n",
      "Eval Loss:  0.27498289942741394\n",
      "Eval Loss:  0.2391284853219986\n",
      "Eval Loss:  0.15539859235286713\n",
      "[[17499  1129]\n",
      " [ 1638  9194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18628\n",
      "           1       0.89      0.85      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9060760353021046\n",
      "pre:  0.8906325680519229\n",
      "rec:  0.848781388478582\n",
      "ma F1:  0.8979672991080474\n",
      "mi F1:  0.9060760353021046\n",
      "we F1:  0.9055790639929203\n",
      "29460 461\n",
      "Loss:  0.05556575953960419\n",
      "Loss:  0.051455337554216385\n",
      "Loss:  0.043893784284591675\n",
      "27 **********\n",
      "Epoch:  1613.8755679130554  fold:  3  kers:  64\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.06235945597290993\n",
      "Loss:  0.08516345918178558\n",
      "Loss:  0.05477939918637276\n",
      "28 **********\n",
      "Epoch:  1657.491292476654  fold:  3  kers:  64\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.06007423996925354\n",
      "Loss:  0.039860986173152924\n",
      "Loss:  0.04430336505174637\n",
      "29 **********\n",
      "Epoch:  1700.9959700107574  fold:  3  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.2658501863479614\n",
      "Eval Loss:  0.16497017443180084\n",
      "Eval Loss:  0.7525213360786438\n",
      "[[1118  418]\n",
      " [ 395 1500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.73      1536\n",
      "           1       0.78      0.79      0.79      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.763042844651705\n",
      "pre:  0.7820646506777894\n",
      "rec:  0.7915567282321899\n",
      "ma F1:  0.7600686298973571\n",
      "mi F1:  0.763042844651705\n",
      "we F1:  0.7628637688942443\n",
      "Eval Loss:  0.22787457704544067\n",
      "Eval Loss:  0.2173997312784195\n",
      "Eval Loss:  0.27616530656814575\n",
      "Eval Loss:  0.20958876609802246\n",
      "Eval Loss:  0.25488370656967163\n",
      "Eval Loss:  0.19819940626621246\n",
      "Eval Loss:  0.225361168384552\n",
      "Eval Loss:  0.21563269197940826\n",
      "Eval Loss:  0.2441292107105255\n",
      "Eval Loss:  0.20218628644943237\n",
      "Eval Loss:  0.20018541812896729\n",
      "Eval Loss:  0.25133365392684937\n",
      "Eval Loss:  0.26219871640205383\n",
      "Eval Loss:  0.20915623009204865\n",
      "Eval Loss:  0.1827707290649414\n",
      "Eval Loss:  0.2503170073032379\n",
      "Eval Loss:  0.28531312942504883\n",
      "Eval Loss:  0.22329294681549072\n",
      "Eval Loss:  0.21125565469264984\n",
      "Eval Loss:  0.22106455266475677\n",
      "Eval Loss:  0.2562648057937622\n",
      "Eval Loss:  0.255817174911499\n",
      "Eval Loss:  0.2963564693927765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24233651161193848\n",
      "Eval Loss:  0.3514406979084015\n",
      "Eval Loss:  0.3164931833744049\n",
      "Eval Loss:  0.2258674055337906\n",
      "Eval Loss:  0.15294340252876282\n",
      "[[16658  1970]\n",
      " [  905  9927]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92     18628\n",
      "           1       0.83      0.92      0.87     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.89      0.91      0.90     29460\n",
      "weighted avg       0.91      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9024100475220638\n",
      "pre:  0.8344120366478944\n",
      "rec:  0.9164512555391433\n",
      "ma F1:  0.8970349867899831\n",
      "mi F1:  0.9024100475220638\n",
      "we F1:  0.9032605065444477\n",
      "29460 461\n",
      "Loss:  0.04064643755555153\n",
      "Loss:  0.0808725655078888\n",
      "Loss:  0.04865574836730957\n",
      "30 **********\n",
      "Epoch:  1785.1507670879364  fold:  3  kers:  64\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.050434011965990067\n",
      "Loss:  0.050440382212400436\n",
      "Loss:  0.09148585796356201\n",
      "31 **********\n",
      "Epoch:  1828.5918543338776  fold:  3  kers:  64\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.05779470130801201\n",
      "Loss:  0.056658826768398285\n",
      "Loss:  0.10056140273809433\n",
      "32 **********\n",
      "Epoch:  1872.0847795009613  fold:  3  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.5870962142944336\n",
      "Eval Loss:  0.14207576215267181\n",
      "Eval Loss:  0.6807476878166199\n",
      "[[1253  283]\n",
      " [ 603 1292]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74      1536\n",
      "           1       0.82      0.68      0.74      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.75      0.75      0.74      3431\n",
      "weighted avg       0.76      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7417662489070241\n",
      "pre:  0.8203174603174603\n",
      "rec:  0.6817941952506597\n",
      "ma F1:  0.7417328788537871\n",
      "mi F1:  0.741766248907024\n",
      "we F1:  0.7420400544720459\n",
      "Eval Loss:  0.1615169793367386\n",
      "Eval Loss:  0.2008265107870102\n",
      "Eval Loss:  0.23726873099803925\n",
      "Eval Loss:  0.19315986335277557\n",
      "Eval Loss:  0.25419774651527405\n",
      "Eval Loss:  0.17464634776115417\n",
      "Eval Loss:  0.18215498328208923\n",
      "Eval Loss:  0.17944465577602386\n",
      "Eval Loss:  0.29271283745765686\n",
      "Eval Loss:  0.17489224672317505\n",
      "Eval Loss:  0.17512089014053345\n",
      "Eval Loss:  0.228835329413414\n",
      "Eval Loss:  0.23585271835327148\n",
      "Eval Loss:  0.2244584709405899\n",
      "Eval Loss:  0.20436757802963257\n",
      "Eval Loss:  0.21362243592739105\n",
      "Eval Loss:  0.23050865530967712\n",
      "Eval Loss:  0.18547338247299194\n",
      "Eval Loss:  0.23256345093250275\n",
      "Eval Loss:  0.17439503967761993\n",
      "Eval Loss:  0.23227722942829132\n",
      "Eval Loss:  0.2199571132659912\n",
      "Eval Loss:  0.27526819705963135\n",
      "Eval Loss:  0.221093088388443\n",
      "Eval Loss:  0.27951568365097046\n",
      "Eval Loss:  0.2843617796897888\n",
      "Eval Loss:  0.21441076695919037\n",
      "Eval Loss:  0.1678333580493927\n",
      "[[17470  1158]\n",
      " [ 1411  9421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18628\n",
      "           1       0.89      0.87      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9127970128988458\n",
      "pre:  0.8905378580206068\n",
      "rec:  0.8697378138847858\n",
      "ma F1:  0.9057623582885062\n",
      "mi F1:  0.9127970128988458\n",
      "we F1:  0.9125758962860473\n",
      "29460 461\n",
      "Loss:  0.07258544862270355\n",
      "Loss:  0.043651033192873\n",
      "Loss:  0.06126825138926506\n",
      "33 **********\n",
      "Epoch:  1956.133052110672  fold:  3  kers:  64\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.07274004071950912\n",
      "Loss:  0.05989176779985428\n",
      "Loss:  0.056015223264694214\n",
      "34 **********\n",
      "Epoch:  1999.5719046592712  fold:  3  kers:  64\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.05698829144239426\n",
      "Loss:  0.06277993321418762\n",
      "Loss:  0.06870701909065247\n",
      "35 **********\n",
      "Epoch:  2043.1154775619507  fold:  3  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.6042500734329224\n",
      "Eval Loss:  0.15501032769680023\n",
      "Eval Loss:  0.8113181591033936\n",
      "[[1245  291]\n",
      " [ 548 1347]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75      1536\n",
      "           1       0.82      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7554648790440105\n",
      "pre:  0.8223443223443223\n",
      "rec:  0.7108179419525066\n",
      "ma F1:  0.7552485652803499\n",
      "mi F1:  0.7554648790440105\n",
      "we F1:  0.7560099048995084\n",
      "Eval Loss:  0.17667372524738312\n",
      "Eval Loss:  0.2151593565940857\n",
      "Eval Loss:  0.2548893392086029\n",
      "Eval Loss:  0.18623259663581848\n",
      "Eval Loss:  0.23906907439231873\n",
      "Eval Loss:  0.15613308548927307\n",
      "Eval Loss:  0.21472948789596558\n",
      "Eval Loss:  0.18853040039539337\n",
      "Eval Loss:  0.2850450575351715\n",
      "Eval Loss:  0.19423383474349976\n",
      "Eval Loss:  0.16925811767578125\n",
      "Eval Loss:  0.23557154834270477\n",
      "Eval Loss:  0.26151710748672485\n",
      "Eval Loss:  0.20485398173332214\n",
      "Eval Loss:  0.18344610929489136\n",
      "Eval Loss:  0.22497965395450592\n",
      "Eval Loss:  0.23906266689300537\n",
      "Eval Loss:  0.18958565592765808\n",
      "Eval Loss:  0.21817949414253235\n",
      "Eval Loss:  0.1706068068742752\n",
      "Eval Loss:  0.269801527261734\n",
      "Eval Loss:  0.21823100745677948\n",
      "Eval Loss:  0.2850287854671478\n",
      "Eval Loss:  0.22550269961357117\n",
      "Eval Loss:  0.2958521842956543\n",
      "Eval Loss:  0.2904233932495117\n",
      "Eval Loss:  0.22194692492485046\n",
      "Eval Loss:  0.1600874364376068\n",
      "[[17455  1173]\n",
      " [ 1396  9436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18628\n",
      "           1       0.89      0.87      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9127970128988458\n",
      "pre:  0.8894334998586106\n",
      "rec:  0.8711225997045791\n",
      "ma F1:  0.9058188876988874\n",
      "mi F1:  0.9127970128988458\n",
      "we F1:  0.9126029585380041\n",
      "29460 461\n",
      "Loss:  0.09690040349960327\n",
      "Loss:  0.0585273876786232\n",
      "Loss:  0.057090289890766144\n",
      "36 **********\n",
      "Epoch:  2127.5946452617645  fold:  3  kers:  64\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.09111732244491577\n",
      "Loss:  0.059034183621406555\n",
      "Loss:  0.09453418105840683\n",
      "37 **********\n",
      "Epoch:  2171.1955182552338  fold:  3  kers:  64\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.04889649525284767\n",
      "Loss:  0.06616673618555069\n",
      "Loss:  0.06706169247627258\n",
      "38 **********\n",
      "Epoch:  2214.8298501968384  fold:  3  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.4007219970226288\n",
      "Eval Loss:  0.1344853937625885\n",
      "Eval Loss:  0.875847578048706\n",
      "[[1215  321]\n",
      " [ 578 1317]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73      1536\n",
      "           1       0.80      0.69      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.74      0.74      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7379772661031769\n",
      "pre:  0.8040293040293041\n",
      "rec:  0.6949868073878628\n",
      "ma F1:  0.7377454829404464\n",
      "mi F1:  0.737977266103177\n",
      "we F1:  0.7385612687778997\n",
      "Eval Loss:  0.18453969061374664\n",
      "Eval Loss:  0.20977555215358734\n",
      "Eval Loss:  0.2517916262149811\n",
      "Eval Loss:  0.17103558778762817\n",
      "Eval Loss:  0.2423846572637558\n",
      "Eval Loss:  0.1605767160654068\n",
      "Eval Loss:  0.1979285180568695\n",
      "Eval Loss:  0.16216234862804413\n",
      "Eval Loss:  0.24966636300086975\n",
      "Eval Loss:  0.19165664911270142\n",
      "Eval Loss:  0.1769619882106781\n",
      "Eval Loss:  0.24962657690048218\n",
      "Eval Loss:  0.23262155055999756\n",
      "Eval Loss:  0.21055403351783752\n",
      "Eval Loss:  0.18722759187221527\n",
      "Eval Loss:  0.23120589554309845\n",
      "Eval Loss:  0.2549533247947693\n",
      "Eval Loss:  0.20813806354999542\n",
      "Eval Loss:  0.17709481716156006\n",
      "Eval Loss:  0.18878041207790375\n",
      "Eval Loss:  0.24259169399738312\n",
      "Eval Loss:  0.25066888332366943\n",
      "Eval Loss:  0.30929920077323914\n",
      "Eval Loss:  0.22194305062294006\n",
      "Eval Loss:  0.29388508200645447\n",
      "Eval Loss:  0.32465898990631104\n",
      "Eval Loss:  0.21948681771755219\n",
      "Eval Loss:  0.140996515750885\n",
      "[[17241  1387]\n",
      " [ 1234  9598]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18628\n",
      "           1       0.87      0.89      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.91      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9110319076714188\n",
      "pre:  0.8737369139736003\n",
      "rec:  0.8860782865583456\n",
      "ma F1:  0.9046115689701153\n",
      "mi F1:  0.9110319076714187\n",
      "we F1:  0.9111604320494509\n",
      "29460 461\n",
      "Loss:  0.06702157109975815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.03862834349274635\n",
      "Loss:  0.06260540336370468\n",
      "39 **********\n",
      "Epoch:  2299.086541891098  fold:  3  kers:  64\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.06707850843667984\n",
      "Loss:  0.06738662719726562\n",
      "Loss:  0.03450535237789154\n",
      "40 **********\n",
      "Epoch:  2342.759918689728  fold:  3  kers:  64\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.07178597897291183\n",
      "Loss:  0.03976865112781525\n",
      "Loss:  0.036307670176029205\n",
      "41 **********\n",
      "Epoch:  2386.4707622528076  fold:  3  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.30530786514282227\n",
      "Eval Loss:  0.08411525189876556\n",
      "Eval Loss:  0.6939490437507629\n",
      "[[1151  385]\n",
      " [ 443 1452]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      1536\n",
      "           1       0.79      0.77      0.78      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7586709414164966\n",
      "pre:  0.7904191616766467\n",
      "rec:  0.7662269129287599\n",
      "ma F1:  0.756799153508727\n",
      "mi F1:  0.7586709414164966\n",
      "we F1:  0.7590316181561998\n",
      "Eval Loss:  0.23124973475933075\n",
      "Eval Loss:  0.19829320907592773\n",
      "Eval Loss:  0.2287294715642929\n",
      "Eval Loss:  0.1649649292230606\n",
      "Eval Loss:  0.2597816586494446\n",
      "Eval Loss:  0.19349120557308197\n",
      "Eval Loss:  0.21688711643218994\n",
      "Eval Loss:  0.1848747432231903\n",
      "Eval Loss:  0.2676483690738678\n",
      "Eval Loss:  0.17427314817905426\n",
      "Eval Loss:  0.18298688530921936\n",
      "Eval Loss:  0.2527240216732025\n",
      "Eval Loss:  0.23083871603012085\n",
      "Eval Loss:  0.1969020962715149\n",
      "Eval Loss:  0.1665060669183731\n",
      "Eval Loss:  0.24986602365970612\n",
      "Eval Loss:  0.2650214731693268\n",
      "Eval Loss:  0.2038346529006958\n",
      "Eval Loss:  0.19626252353191376\n",
      "Eval Loss:  0.22450114786624908\n",
      "Eval Loss:  0.2546626627445221\n",
      "Eval Loss:  0.24926459789276123\n",
      "Eval Loss:  0.2856065630912781\n",
      "Eval Loss:  0.1804930865764618\n",
      "Eval Loss:  0.32654115557670593\n",
      "Eval Loss:  0.3286469876766205\n",
      "Eval Loss:  0.2117229700088501\n",
      "Eval Loss:  0.15460751950740814\n",
      "[[16848  1780]\n",
      " [  820 10012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93     18628\n",
      "           1       0.85      0.92      0.89     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.91      0.91     29460\n",
      "weighted avg       0.92      0.91      0.91     29460\n",
      "\n",
      "acc:  0.911744738628649\n",
      "pre:  0.8490502035278155\n",
      "rec:  0.9242983751846381\n",
      "ma F1:  0.9067222778356427\n",
      "mi F1:  0.9117447386286489\n",
      "we F1:  0.9124500578740097\n",
      "29460 461\n",
      "Loss:  0.047616731375455856\n",
      "Loss:  0.050675537437200546\n",
      "Loss:  0.04370976984500885\n",
      "42 **********\n",
      "Epoch:  2470.8582372665405  fold:  3  kers:  64\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.069542296230793\n",
      "Loss:  0.06123201549053192\n",
      "Loss:  0.06532363593578339\n",
      "43 **********\n",
      "Epoch:  2514.4864230155945  fold:  3  kers:  64\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.0828992947936058\n",
      "Loss:  0.027914918959140778\n",
      "Loss:  0.047356508672237396\n",
      "44 **********\n",
      "Epoch:  2558.1387321949005  fold:  3  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.385873943567276\n",
      "Eval Loss:  0.11699847877025604\n",
      "Eval Loss:  0.939041256904602\n",
      "[[1197  339]\n",
      " [ 543 1352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73      1536\n",
      "           1       0.80      0.71      0.75      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.74      0.75      0.74      3431\n",
      "weighted avg       0.75      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7429320897697465\n",
      "pre:  0.7995269071555293\n",
      "rec:  0.7134564643799473\n",
      "ma F1:  0.7424063666394954\n",
      "mi F1:  0.7429320897697465\n",
      "we F1:  0.7436240092443992\n",
      "Eval Loss:  0.19251133501529694\n",
      "Eval Loss:  0.18565550446510315\n",
      "Eval Loss:  0.214621901512146\n",
      "Eval Loss:  0.14849509298801422\n",
      "Eval Loss:  0.24328631162643433\n",
      "Eval Loss:  0.15870383381843567\n",
      "Eval Loss:  0.1862838864326477\n",
      "Eval Loss:  0.17055369913578033\n",
      "Eval Loss:  0.2537350356578827\n",
      "Eval Loss:  0.15234005451202393\n",
      "Eval Loss:  0.16412629187107086\n",
      "Eval Loss:  0.21440009772777557\n",
      "Eval Loss:  0.21373067796230316\n",
      "Eval Loss:  0.16975267231464386\n",
      "Eval Loss:  0.1621035486459732\n",
      "Eval Loss:  0.21364235877990723\n",
      "Eval Loss:  0.2407100647687912\n",
      "Eval Loss:  0.19441573321819305\n",
      "Eval Loss:  0.1738535314798355\n",
      "Eval Loss:  0.19460518658161163\n",
      "Eval Loss:  0.24142786860466003\n",
      "Eval Loss:  0.24035876989364624\n",
      "Eval Loss:  0.2691645622253418\n",
      "Eval Loss:  0.17974449694156647\n",
      "Eval Loss:  0.28054243326187134\n",
      "Eval Loss:  0.2995730936527252\n",
      "Eval Loss:  0.17806461453437805\n",
      "Eval Loss:  0.13416752219200134\n",
      "[[17301  1327]\n",
      " [ 1052  9780]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18628\n",
      "           1       0.88      0.90      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.92      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9192464358452138\n",
      "pre:  0.8805257945439813\n",
      "rec:  0.9028803545051699\n",
      "ma F1:  0.9136163191306643\n",
      "mi F1:  0.9192464358452138\n",
      "we F1:  0.9194522970467166\n",
      "29460 461\n",
      "Loss:  0.06916186958551407\n",
      "Loss:  0.061356402933597565\n",
      "Loss:  0.06881728768348694\n",
      "45 **********\n",
      "Epoch:  2642.4981718063354  fold:  3  kers:  64\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.047673922032117844\n",
      "Loss:  0.04783506691455841\n",
      "Loss:  0.04752246290445328\n",
      "46 **********\n",
      "Epoch:  2686.14746260643  fold:  3  kers:  64\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.06101652979850769\n",
      "Loss:  0.05028163641691208\n",
      "Loss:  0.059876345098018646\n",
      "47 **********\n",
      "Epoch:  2729.7768063545227  fold:  3  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.4289255440235138\n",
      "Eval Loss:  0.12450621277093887\n",
      "Eval Loss:  1.0203684568405151\n",
      "[[1232  304]\n",
      " [ 547 1348]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74      1536\n",
      "           1       0.82      0.71      0.76      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.76      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7519673564558438\n",
      "pre:  0.8159806295399515\n",
      "rec:  0.7113456464379947\n",
      "ma F1:  0.751683512206904\n",
      "mi F1:  0.7519673564558438\n",
      "we F1:  0.7525619612187091\n",
      "Eval Loss:  0.1648169904947281\n",
      "Eval Loss:  0.17359618842601776\n",
      "Eval Loss:  0.21283067762851715\n",
      "Eval Loss:  0.13279186189174652\n",
      "Eval Loss:  0.23500563204288483\n",
      "Eval Loss:  0.1333020180463791\n",
      "Eval Loss:  0.18051296472549438\n",
      "Eval Loss:  0.15281756222248077\n",
      "Eval Loss:  0.2440175712108612\n",
      "Eval Loss:  0.1506587266921997\n",
      "Eval Loss:  0.16586612164974213\n",
      "Eval Loss:  0.2168923169374466\n",
      "Eval Loss:  0.21234218776226044\n",
      "Eval Loss:  0.16207745671272278\n",
      "Eval Loss:  0.17025050520896912\n",
      "Eval Loss:  0.20289942622184753\n",
      "Eval Loss:  0.23139479756355286\n",
      "Eval Loss:  0.17511442303657532\n",
      "Eval Loss:  0.1676425039768219\n",
      "Eval Loss:  0.18105733394622803\n",
      "Eval Loss:  0.25437915325164795\n",
      "Eval Loss:  0.21958963572978973\n",
      "Eval Loss:  0.2716885209083557\n",
      "Eval Loss:  0.16903385519981384\n",
      "Eval Loss:  0.2664421796798706\n",
      "Eval Loss:  0.29003843665122986\n",
      "Eval Loss:  0.1844637393951416\n",
      "Eval Loss:  0.12659679353237152\n",
      "[[17521  1107]\n",
      " [ 1166  9666]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18628\n",
      "           1       0.90      0.89      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9228445349626613\n",
      "pre:  0.8972431077694235\n",
      "rec:  0.8923559822747416\n",
      "ma F1:  0.9169395152008568\n",
      "mi F1:  0.9228445349626614\n",
      "we F1:  0.9228001815360608\n",
      "29460 461\n",
      "Loss:  0.05371715500950813\n",
      "Loss:  0.058418646454811096\n",
      "Loss:  0.024809997528791428\n",
      "48 **********\n",
      "Epoch:  2814.083387851715  fold:  3  kers:  64\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.049455657601356506\n",
      "Loss:  0.06484198570251465\n",
      "Loss:  0.062284067273139954\n",
      "49 **********\n",
      "Epoch:  2857.718715906143  fold:  3  kers:  64\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.06080944463610649\n",
      "Loss:  0.049348872154951096\n",
      "Loss:  0.06955157220363617\n",
      "50 **********\n",
      "Epoch:  2901.3739902973175  fold:  3  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.41527029871940613\n",
      "Eval Loss:  0.1158066913485527\n",
      "Eval Loss:  0.9881649613380432\n",
      "[[1227  309]\n",
      " [ 521 1374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75      1536\n",
      "           1       0.82      0.73      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7580880209851355\n",
      "pre:  0.8163992869875223\n",
      "rec:  0.725065963060686\n",
      "ma F1:  0.7576431351696558\n",
      "mi F1:  0.7580880209851355\n",
      "we F1:  0.7587296250183446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1806587129831314\n",
      "Eval Loss:  0.14864151179790497\n",
      "Eval Loss:  0.22625206410884857\n",
      "Eval Loss:  0.14343775808811188\n",
      "Eval Loss:  0.2319495528936386\n",
      "Eval Loss:  0.1583729386329651\n",
      "Eval Loss:  0.17256568372249603\n",
      "Eval Loss:  0.14330697059631348\n",
      "Eval Loss:  0.2265043556690216\n",
      "Eval Loss:  0.16297365725040436\n",
      "Eval Loss:  0.15187528729438782\n",
      "Eval Loss:  0.20467565953731537\n",
      "Eval Loss:  0.21525712311267853\n",
      "Eval Loss:  0.16771343350410461\n",
      "Eval Loss:  0.15759900212287903\n",
      "Eval Loss:  0.22964002192020416\n",
      "Eval Loss:  0.23859089612960815\n",
      "Eval Loss:  0.18035273253917694\n",
      "Eval Loss:  0.15285183489322662\n",
      "Eval Loss:  0.16309703886508942\n",
      "Eval Loss:  0.2316868007183075\n",
      "Eval Loss:  0.22433693706989288\n",
      "Eval Loss:  0.2596254348754883\n",
      "Eval Loss:  0.1955239623785019\n",
      "Eval Loss:  0.25106802582740784\n",
      "Eval Loss:  0.27846425771713257\n",
      "Eval Loss:  0.19085286557674408\n",
      "Eval Loss:  0.11649211496114731\n",
      "[[17387  1241]\n",
      " [ 1042  9790]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18628\n",
      "           1       0.89      0.90      0.90     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9225050916496945\n",
      "pre:  0.8874988668298431\n",
      "rec:  0.9038035450516987\n",
      "ma F1:  0.9169846044209359\n",
      "mi F1:  0.9225050916496945\n",
      "we F1:  0.922649698331085\n",
      "29460 461\n",
      "Loss:  0.03648557886481285\n",
      "Loss:  0.06107007712125778\n",
      "Loss:  0.08362477272748947\n",
      "51 **********\n",
      "Epoch:  2985.6875529289246  fold:  3  kers:  64\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.06619294732809067\n",
      "Loss:  0.0768674910068512\n",
      "Loss:  0.05426561087369919\n",
      "52 **********\n",
      "Epoch:  3029.537307739258  fold:  3  kers:  64\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.047577861696481705\n",
      "Loss:  0.06328406184911728\n",
      "Loss:  0.02664835751056671\n",
      "53 **********\n",
      "Epoch:  3073.1606678962708  fold:  3  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.39764878153800964\n",
      "Eval Loss:  0.10308151692152023\n",
      "Eval Loss:  0.898768961429596\n",
      "[[1184  352]\n",
      " [ 499 1396]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.74      1536\n",
      "           1       0.80      0.74      0.77      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7519673564558438\n",
      "pre:  0.7986270022883295\n",
      "rec:  0.7366754617414248\n",
      "ma F1:  0.7510167507517173\n",
      "mi F1:  0.7519673564558438\n",
      "we F1:  0.7526265028638939\n",
      "Eval Loss:  0.21494948863983154\n",
      "Eval Loss:  0.17725206911563873\n",
      "Eval Loss:  0.21826763451099396\n",
      "Eval Loss:  0.14116211235523224\n",
      "Eval Loss:  0.23768100142478943\n",
      "Eval Loss:  0.15722166001796722\n",
      "Eval Loss:  0.1598077267408371\n",
      "Eval Loss:  0.16624851524829865\n",
      "Eval Loss:  0.2345564365386963\n",
      "Eval Loss:  0.17152714729309082\n",
      "Eval Loss:  0.15413349866867065\n",
      "Eval Loss:  0.208657369017601\n",
      "Eval Loss:  0.2186088114976883\n",
      "Eval Loss:  0.16775177419185638\n",
      "Eval Loss:  0.14544080197811127\n",
      "Eval Loss:  0.22046339511871338\n",
      "Eval Loss:  0.23114801943302155\n",
      "Eval Loss:  0.194523885846138\n",
      "Eval Loss:  0.14071650803089142\n",
      "Eval Loss:  0.17389515042304993\n",
      "Eval Loss:  0.2448926866054535\n",
      "Eval Loss:  0.21948523819446564\n",
      "Eval Loss:  0.2778971493244171\n",
      "Eval Loss:  0.18824414908885956\n",
      "Eval Loss:  0.27058690786361694\n",
      "Eval Loss:  0.2853018045425415\n",
      "Eval Loss:  0.17948594689369202\n",
      "Eval Loss:  0.12331094592809677\n",
      "[[17277  1351]\n",
      " [  922  9910]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     18628\n",
      "           1       0.88      0.91      0.90     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9228445349626613\n",
      "pre:  0.8800284166592665\n",
      "rec:  0.9148818316100443\n",
      "ma F1:  0.9176978569516068\n",
      "mi F1:  0.9228445349626614\n",
      "we F1:  0.9231442397090631\n",
      "29460 461\n",
      "Loss:  0.05145210027694702\n",
      "Loss:  0.047350045293569565\n",
      "Loss:  0.04460733383893967\n",
      "54 **********\n",
      "Epoch:  3157.3824758529663  fold:  3  kers:  64\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.039849478751420975\n",
      "Loss:  0.033357471227645874\n",
      "Loss:  0.05346420779824257\n",
      "55 **********\n",
      "Epoch:  3200.9848918914795  fold:  3  kers:  64\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.0559290386736393\n",
      "Loss:  0.06250113993883133\n",
      "Loss:  0.06331489980220795\n",
      "56 **********\n",
      "Epoch:  3244.718956232071  fold:  3  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.3078727722167969\n",
      "Eval Loss:  0.1403656303882599\n",
      "Eval Loss:  1.1207513809204102\n",
      "[[1145  391]\n",
      " [ 507 1388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72      1536\n",
      "           1       0.78      0.73      0.76      1895\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.74      0.74      0.74      3431\n",
      "weighted avg       0.74      0.74      0.74      3431\n",
      "\n",
      "acc:  0.7382687263188574\n",
      "pre:  0.7802136031478358\n",
      "rec:  0.7324538258575198\n",
      "ma F1:  0.7369492223491878\n",
      "mi F1:  0.7382687263188574\n",
      "we F1:  0.7388986129875064\n",
      "Eval Loss:  0.2031051069498062\n",
      "Eval Loss:  0.15865807235240936\n",
      "Eval Loss:  0.20567969977855682\n",
      "Eval Loss:  0.13760162889957428\n",
      "Eval Loss:  0.23158612847328186\n",
      "Eval Loss:  0.15888962149620056\n",
      "Eval Loss:  0.1733447015285492\n",
      "Eval Loss:  0.1496344953775406\n",
      "Eval Loss:  0.20906971395015717\n",
      "Eval Loss:  0.1647740602493286\n",
      "Eval Loss:  0.15297849476337433\n",
      "Eval Loss:  0.21572528779506683\n",
      "Eval Loss:  0.21060296893119812\n",
      "Eval Loss:  0.17461025714874268\n",
      "Eval Loss:  0.14635977149009705\n",
      "Eval Loss:  0.20612111687660217\n",
      "Eval Loss:  0.21473300457000732\n",
      "Eval Loss:  0.18961435556411743\n",
      "Eval Loss:  0.13477617502212524\n",
      "Eval Loss:  0.16046416759490967\n",
      "Eval Loss:  0.22778445482254028\n",
      "Eval Loss:  0.23624485731124878\n",
      "Eval Loss:  0.2647361159324646\n",
      "Eval Loss:  0.18958121538162231\n",
      "Eval Loss:  0.25419852137565613\n",
      "Eval Loss:  0.29013678431510925\n",
      "Eval Loss:  0.18462654948234558\n",
      "Eval Loss:  0.13897962868213654\n",
      "[[17125  1503]\n",
      " [  849  9983]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     18628\n",
      "           1       0.87      0.92      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.920162932790224\n",
      "pre:  0.8691450461431308\n",
      "rec:  0.9216211225997046\n",
      "ma F1:  0.915177714535027\n",
      "mi F1:  0.920162932790224\n",
      "we F1:  0.9206194341538335\n",
      "29460 461\n",
      "Loss:  0.07338490337133408\n",
      "Loss:  0.06524060666561127\n",
      "Loss:  0.047473784536123276\n",
      "57 **********\n",
      "Epoch:  3329.0783960819244  fold:  3  kers:  64\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.0354468934237957\n",
      "Loss:  0.06660879403352737\n",
      "Loss:  0.0344749316573143\n",
      "58 **********\n",
      "Epoch:  3372.7556121349335  fold:  3  kers:  64\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.0829264223575592\n",
      "Loss:  0.044414155185222626\n",
      "Loss:  0.06610852479934692\n",
      "59 **********\n",
      "Epoch:  3416.304172039032  fold:  3  kers:  64\n",
      "Eval Loss:  0.535854160785675\n",
      "Eval Loss:  0.08667390048503876\n",
      "Eval Loss:  0.8590710163116455\n",
      "[[1248  288]\n",
      " [ 541 1354]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      1536\n",
      "           1       0.82      0.71      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7583794812008161\n",
      "pre:  0.8246041412911084\n",
      "rec:  0.7145118733509235\n",
      "ma F1:  0.7581486370718994\n",
      "mi F1:  0.758379481200816\n",
      "we F1:  0.7589304582254945\n",
      "update!  Acc:  0.7668318274555523\n",
      "Epoch:  3420.534859418869  fold:  3  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0AElEQVR4nO3deXhU5dnA4d+TkIDsW1gEJGyKuCFERMEFBQvSFm21xbrg9lFUtFat4lqq1qJ1qVUqFaXVVkVErVSoG6KCsgVkRySEAAGEsIV9CXm/P+ZMODNzZubMnsk893XlysxZ3zOTnOe8uxhjUEoplXmyUp0ApZRSqaEBQCmlMpQGAKWUylAaAJRSKkNpAFBKqQxVK9UJiETz5s1Nfn5+qpOhlFJpZcGCBduMMXn+y9MqAOTn51NYWJjqZCilVFoRkXVOy7UISCmlMpQGAKWUylAaAJRSKkNpAFBKqQylAUAppTKUBgCllMpQGgCUUipDaQCIk8pKw6TCDVQcrUx1UpRSyhUNAHHyzoIN3Dt5CeNnrk11UpRSyhUNAHGya/8RAHbuP5zilCillDsaAJRSKkNpAFBKqQylAUAppTKUBgCllMpQGgCUUipDaQBQSqkMpQFAKaUylAYApZTKUBoA4swYk+okKKWUKxoA4kQk1SlQSqnIaABQSqkMpQFAKaUylKsAICIDRWSViBSJyCiH9V1FZLaIHBKRe2zLTxKRRbaf3SJyp7VutIhstK27NG5XpZRSKqywAUBEsoGxwCCgG3CViHTz22wHcAfwtH2hMWaVMaa7MaY70BPYD7xv2+Q573pjzLToLyO0e95ZTP6oqYk6vFJKpSU3OYBeQJExptgYcxiYCAyxb2CM2WqMmQ8cCXGci4E1xph1Uac2SpMXlCb7lEopVe25CQBtgA2296XWskgNBd7yWzZSRJaIyAQRaeK0k4gMF5FCESksKyuL4rTHlB8IFZ+UUiqzuAkATg0cI2rsLiK5wE+Bd2yLXwI6Ad2BzcAzTvsaY142xhQYYwry8vIiOW2AM/7wSUz7K6VUTeImAJQC7Wzv2wKbIjzPIGChMWaLd4ExZosx5qgxphIYj6eoKeHyR03l0xVbwm8YJe0HppRKF24CwHygi4h0sJ7khwJTIjzPVfgV/4hIa9vby4FlER7TtQZ1avm8f3VWMZWV8b1Ti2NGSSmlqq+wAcAYUwGMBD4GVgKTjDHLRWSEiIwAEJFWIlIK3AU8JCKlItLQWlcXGAC853fop0RkqYgsAfoBv43bVfkZd01Pn/dzinfQ+0/TmVu8nbnF2xN1WqWUqtZqhd8ErCaa0/yWjbO9/gFP0ZDTvvuBZg7Lr40opTHo07l5wLKtew7xy5fnAFAyZnCykqKUUtWG9gRWSqkMpQFAKaUylAYApZTKUBkTAF67MSmtTJVSKm1kTABo1+S4pJ3rvslL+PL72HotK6VUomVMAMhvVi9p53q7cAPDJsxL2vmUUioaGRMAsrKS01FLOwIrpdJFxgSAcDbuOsAHizZGvb9OCamUSjeuOoJlgitf+oZN5Qf58enHk52k3IJSSqWS5gAsP+w+mOokKKVUUmVUAOjZ3nHKAZ779HviPDacUkpVexkVAF781ZmOy5+fvrrq9SXPfcltbyz0WV+6cz879x0OeWwdBloplW4yKgC0bhS+L8Casn1MXbrZZ1nfJ2dwzpjprs6htQfO1m7bx5AXZ+msbEpVIxkVAGJx8EhlqpOQ1v46fTWLS8uZvjJxk/EopSKjASCBlpTuYvxXxalOhlJKOdJmoAn00xe/BuD/zu+Y4pQopVQgzQEEsbn8QFT7aV2wUipdaAAIonRnZAFAewIrpdKNBoAIDHp+Jlv3aIcxpVTN4CoAiMhAEVklIkUiMsphfVcRmS0ih0TkHr91Jdbk74tEpNC2vKmIfCoiq63fzr20qpGVm3czeUFpqpOhlFJxETYAiEg2MBYYBHQDrhKRbn6b7QDuAJ4Ocph+xpjuxpgC27JRwHRjTBdguvW+2ti06wDLNpYHLP90xRZMknt9bdl9kO17DyX1nEqpms9NDqAXUGSMKTbGHAYmAkPsGxhjthpj5gOR9PIZArxmvX4NuCyCfRPuNxMX8eMXZgUs/3b9Lj5buTWpaTn7ien0fPwzAL78voxxX65J6vmVUjWTmwDQBthge19qLXPLAJ+IyAIRGW5b3tIYsxnA+t3CaWcRGS4ihSJSWFYW+yxb8Rjoc8e+1D2ND5swjzH/+y5l54+VDpkRnUMVR8kfNZVXZ61NdVJUDeImADjdMiP5N+5jjOmBpwjpNhE5P4J9Mca8bIwpMMYU5OXlRbKroxv6dIj5GCpy2kgqNnsPVgAwdkZRilOiahI3AaAUaGd73xbY5PYExphN1u+twPt4ipQAtohIawDrd1LKVR4afHJE2+ePmpqglCh1zAeLNpI/aioHDh9NdVJUBnETAOYDXUSkg4jkAkOBKW4OLiL1RKSB9zVwCbDMWj0FGGa9HgZ8EEnCoyVxaLAfTTHG2BlF/HexJ26+t7CU/FFTOXgkff7Zy/cf4dpX57JV501IiOc+/R7QeSlUcoUNAMaYCmAk8DGwEphkjFkuIiNEZASAiLQSkVLgLuAhESkVkYZAS2CWiCwG5gFTjTEfWYceAwwQkdXAAOt92gsWHP788Spuf+tbAJ77zPPPvnX3Iev3waS0LBo9ZTk/cajYduOdBRuYuXobf9exjZSqMVyNBWSMmQZM81s2zvb6BzxFQ/52A2cEOeZ24GLXKa3GPlr2A49PXRnVvmu37aPf018walBXRlzQKc4p8/XPb0oSenylVHrRnsBR8H9WHz8z+qfi0p37AZi1elsMKVI1RbL7mKjMpgEghYwOHacsbuumNECoeNIAkAKSho0i9b6TWvFovKCUv4wMAMHmBq7uzvmTu2kpE0lvQ0rVHBkZAJrWy41p/2nWnMEHjxxlw479YW+KlZXxeXzeXB5dE8HKShPzXLzxKq7SjERo+vmoZMrIGcFysmOLezNXb+Obom28Mmstn3+3lW6tG4bcvuMD0xyXJ6tY5bnPvueFz517kL67oJTPVm7hpWt6ujpW1CURmnUIST8elQoZGQAK2sc+8vRjU1fy3Q+7AVixebfr/XYfPOJzE41nEDhcUUmlMdTJyfZZ7s2xOLn7ncWuju2Uzpe/WsPpbRvTu2OziNKpVKIcPHKUg0eO0rhubLn8TJGRRUDxqFBbGcFN3+7OiYscl8ejju+iZ76g68Mfhd8wBvbP7olp3zH05TkJPV+m0cr22Fw29mu6P/ppqpORNjIyB5BI4crKS7btq3q991AFR45Wxu3ckU5j6cZLX6yhY169uB9X+dEyoLj47oc9qU5CWtEAEAOnp7U1ZfsCF/rx/q87zTdQ3Tz5kWfo6fsHdU1xSpRS8ZaRRUCJ9NX34ecsCFUEtWv/4YTP/nW4IvJchzfWCbBj3+G0GshOKeUsYwPAg5dGNix0os1cvY29hyro/uinVbN/Jcolz30Z8T7GFgF6PPZpQNn/+K+K+Xj5D3FIXabTSgCVPBlbBHRGu8apTkKAGd8lZ6rJku37Yz7Gog27fN7/cZpnMLySMYNjPnYm0ioAlQoZmwNI2ZgqKfhPr07DCCT7cy8s2cG8tTuSek6l0kXGBoA4dc6NSvW5HTt79pNVATOhxdoTONbxjyqOVrL/cEXE+10xbja/+PvsmM6tVE2VsQGgQZ2MLf0K669Beg1D6gay+83ERXR75OOUnDuZwmWQamINQfmBI0yavyHVychIGRsATm3TKNVJiMlr35SwbGN5qpPh2rsLS2Paf2qI3sxHjlam/Vy64YrpnNYu2rCLzeXx7/uRbPdNXsK97y5Jq7/nmiJjA0B1F66s/PdTlie1H0E8i+4PHjkaVVPUYK55ZS4nPxLfHtBFW/eSP2oqX6xKTsV8NC4b+zXnPzUj1cmIWZnV7FmbFiefBoAkE2Cfi7LsSYXussTXvDI3xhRFJtb65MkLSun68Ef0e/oLwFNJe/NrhRyNoVJmbgIqeRes8xwz1DhKiRDpp3DkaE0sFFLJ4ioAiMhAEVklIkUiMsphfVcRmS0ih0TkHtvydiIyQ0RWishyEfmNbd1oEdkoIousn0vjc0nVX7Cn6Rm2p82Nu9wN/TyrKPxUkvEstY/1WN6b9cZdnqKLW95YyGcrtyS881t1V90bBqiaKWxNqIhkA2OBAUApMF9EphhjVtg22wHcAVzmt3sFcLcxZqGINAAWiMintn2fM8Y8HetFpJNQz2vvLdyYtHS4odMPKlWzuckB9AKKjDHFxpjDwERgiH0DY8xWY8x84Ijf8s3GmIXW6z3ASqBNXFKexqpRs/yI/e2LNXE7Vv6oqZTtyewnf5U5du5L/DAvkXITANoA9gLpUqK4iYtIPnAmYC+0HikiS0Rkgog4DtIvIsNFpFBECsvKwo+zU90Vl+2LqCnluu3hB5eLh6esQd927DvsuD6W3MCwCfOi3jfVIrns8v1H6PHYpyxcvzPkdsNfL+SfX6+N+XyRem9hadL+nqJR0/ObZz6W+GFeIuUmADjdrSL6rkSkPvAucKcxxjuQ/ktAJ6A7sBl4xmlfY8zLxpgCY0xBXl5eJKettn7YHb5833vDnbk6fBl/PHif7IPd6L8u2h71sb90MUBedfvnj6a/w/ySHezYd5ixIfpRAHyyYguj/7vCZ1kycoV3TVpcLUegTeMMcdpzEwBKgXa2922BTW5PICI5eG7+bxhj3vMuN8ZsMcYcNcZUAuPxFDUpi3cKx3cWxNZ+Pl5mFwcPAPdOPjarWDKKdJ766Dsu/HP6N39MhT0HI+9NXRPsP1zBvZMXU74/trmxaxo3AWA+0EVEOohILjAUmOLm4OLp3fIqsNIY86zfuta2t5cDy9wlOX5+esbxyT5lxBb7DbpWHU0qPBakPlgUW0W2MYa73l4Ucvyev32xJi4D2iXajFVbdYRUF5KR+3tr3gYmFZbyl+nfJ+Fs6SNsKyBjTIWIjAQ+BrKBCcaY5SIywlo/TkRaAYVAQ6BSRO4EugGnA9cCS0VkkXXIB4wx04CnRKQ7nu+/BPh1HK/LlXq1M2M4iGiLF1LRCOhQRSXvfbuRD5du5vvHByU/AZZoxj7y3+OGf8wHIhshNdYxl9KZFgUln6s7oHXDnua3bJzt9Q94iob8zSLI92qMudZ9MlUsvt+y19V25Qdizx7v2HeY29/6lj/97DTqV6MAe7iiktxa7vo9Li0t5753l0Z9rmABd9OuA0E77qVqjKVMoy2bfWlP4GrMbcub/FFTmb3mWBm9MYYfyg/yl8++Z+sedx3KwHPji7Vn6d++WMN/F2+K6+BepTtjL+45d8znrrd12ws7UhPnb6B4W/hWOIcqjjJswjxWbt4ddtt0MODZL7n+H+FbgiXy3qzh1Vn1eURTAXZFUGFlL3ufsngT/56zjvklO/nH1yWO2w9/vZCre7f3WXbNq3O54MT4tLSK+Z/ZdoC+T8Ze4butmrW/DsYYTyD+8vsy9h6q4N1bzg1Yn25Wb93L6q3Bc6F6c04dzQFUYx8ucd3YyqfYoXTnAQ5YA2vtPugcRD5ZscWxfb49JxGLaPsNpHMnuWDX7KbtvdN1L1i3s+qYoT6Xz7/bktRe2z+UH0z70VeVhwaAauzhD5a73vateceKLTbtin6I4MNHj43SuSKJRRDV6ck2miC0bvs+DlWNcOp7gAv+/EXQQBzOgnWhO5UB3PjPQv63LHmtjXr/aTrXvhrdIISvzCwOmGwoGdL5wSKRNADUQG/MXc+yjbHfvGPpNLTv0FEe+s9S9h2Krt15IlrDuJ1RbK2tnN6eisKSHY71EQcOH+WCP3/B3e8sDljndTDKJ+ZDLofN3rr7INv2HuKURz5KStPhQheBycnjU1fGOSUqFhoAarhUPVm/MquYf89Zzym/j2wWr0hawyzfFNkEIt6WPf2e/oJH/Xri2gXrfX3FuNmO9RHeuQ3iMcdBtN+XAb5Zs519h48yfmZxzOlIlh37DkcdTKKhAxz60gCgEiKW8f3B3Y1w8F8jy6GUbNvHH6euYO22fUwIMhZPdfPV6rKIe1eH++gmzlsflya/8ZCs+Ra0BMiZBgCVEJE+aFUaQ+nO/Qkvqx0/MwE3fr80x3oN62y9nP/+ZTFn/TH8AGLlB464vsmNem8pvwtRXAWeJ/MjVn3QfZOX0PdJ981o08WRo5Vc/cocV/UsNZUGAFUtjJ1RRN8nZ1S1mKkuGfVQN9VDFUeDBi239Q1OQtUlBPOXz1Yfe+PiwwvXLLbHY59y58RFALxduIHSnQc4eOQoY/73nes0vTB9NWvK3HVCTBb7R7Nu+z6+LtruM5ZVptEAoKqFb6zmp5vLj3Vc6//slxHdcPYdqmD0lOVMKtzA6CnLWVoa+yTj80uCj0l096TF9H1yRkDZ/9LScro94lv34XRPHvJifEfmjCTn4SbATvUrnnllZjHjvnQ3H8Su/Yd55tPvuerlOe4TlUCizYAcZXRHsGb1clOdBGVZ69BDtmjrXor8OhDt2u88XwHA378q5p/flFS9nzh/vc/6pRsjDwjeQeecKg9nfOeZwnPUu0t8lgcb7tv/FrQ4DgHKSaLGEwpVyX200pAlx2603o/L3qzYiT2l2/Yc4milITtLb9bJktE5gNsv7szg01uH31BFLNabULBK5CFjvw6xT+ytcIIJNTzEZyu3Bl2XTPYWVLNWb/Npgtv/2S8d9zlaaaiMscIeoNMD03jg/ejHTwLP/NBj/pfYZqLh6qZGvrmQ3k9MT2gaqpOMDgC1a2Xz/C+7pzoZNVK095SKMDuuS9Ew0PbB4ZZFkZNw+0wbLnCWHzgStoVV6c4DXPPqXO6x6hKMMQE5Ke+NsNMD0+j4wDRXzSPDbWHvjBit6QkKpt4SIPvn63TJHy7ZHHbCpiNHK3l11tqqSvJ0ltEBAKBWdsZ/BAkR7T/H8ihurl7RNPFev30/d09aHFF63cxwFqlIyqgnzHJuyeQ9xF7ryd9bAfv89NUB227ZfdAnN/XBIvfDjqSjaAqVNu06wJLSXQHLX5+9jsc+XME/g4yz5W+LixkAU0XvfsCYn52W6iTUONH2t/lwSfzahbvpVHbP5MW8u7C0ak5kNw4eOcrRysgLudxs/+ePV4Xd5o/TVoZsZVRc5qlP8ZbZ/3dx4M19c/lBnx7Dwdrj3zVpUdj0xJMBCh7/jFeDBLlgtu4+SLGLFkfGwOQFpQx9eXbYbc8d8zk/fTGwyHGPNazHHhe93Get3sbZT0znI5dDdTz+4Qq+KUrONLCgAQCAob1OSHUSlOW7H/ZEtP3rs0uCrvMOiOfG+Jlrg95UNzqMrdTpgWnsj2B4hx92H3RVzPLFKne5i7EzAucd9g93kVz/Jyu2VL22p/O9hbHN8BaWw2eybe8hHvsweE9tJ72emM5FzzjXcwA+TaTueWcxc4qDt+6KRmWlcRz2ZNEGTx+Dbze462vwyqy1/OqVuUyav4FFSRjSI6NbAan090gEA+b5W+9Xn3C4opK6Dg3DKuJQ1uv0JBkJ/9zM8k2BYz0luqVjJLm6cHU51YH98zpcUcn6He7ql3z6XFie/mQVf/tiDUtHX0KDOjm25dFNQXmv1bIsktnkoqE5AFVjRHrLOf/PM3wmSZ+xaisHHZ6a/W98ibjPRnpM55yC71G27D7EW/PWJ6xTnbf1kFNnL6fey7GMAmqMYebqspjH8vHN6Rxb/vB/lgVtKeWGtw6lugyx4ZarACAiA0VklYgUicgoh/VdRWS2iBwSkXvc7CsiTUXkUxFZbf1uEvvlKBUZ+6xbv317MX8IMUic17Z9wfsiRGPvoQpWb42s6MuJUw7g/veWsv+Qu6Kg12eXsHB98KKKF/2KnTo+MI3yA0e4OFTRS4TsN/j5JTv41krP5AWlXPvqPCYvKHV1nD/9byVf28rSvR9NsHGVvl4Tebn7gnXxKUbasGN/XJriRiNsABCRbGAsMAjPRO9XiUg3v812AHcAT0ew7yhgujGmCzDdeq9USq3fEX7yljfnrg+7TSRu/Mf8mKfiDCVcs0avRz5Yzs/+9o3rmyzA036V1sFaKAUT6qqvHDeby//2DeBp2mr/Hc7fvyzm6iDzL3tNtE1b6va4dl8XbeeT5T+QP2qqYz2RG2vK9nLeUzMc63SSwU0OoBdQZIwpNsYcBiYCQ+wbGGO2GmPmA/75n1D7DgFes16/BlwW3SUolVjXTohu8hM3bvn3AuaFGG7C650F4dvYx6to6neTl4TfyPKvOet83j/qsvK2dOd+x6KjEod+Hmu37atqymrw9Lw+50/TY66b8bY0imWYiFlRtNixzynhnbxp7tr4Vkq75SYAtAHsf32l1jI3Qu3b0hizGcD63cLlMZVylKih3jfsiH6GtXDczuRV0yZS6fvkDNdFR/4T3Eycv4HN5QcjClTJHgpoSekun6Ez7JX4fZ+cUTWXxaL1u0Ie5/ste8gfNTVhTUPdBACnj87tv1os+3oOIDJcRApFpLCsLP4dcJSqKarLgGffbzlWn7Frf3wrRdfYejR/sCjBTVRdcHroWFO2l5+++DVPTDsWtP0bF6zfvp9FG3bxzKehWwnNKfYMkpioKT/dBIBSoJ3tfVvAbbfBUPtuEZHWANZvxz7gxpiXjTEFxpiCvLw8l6eN3BltGyXs2Cp97D0Y/TDOysMeAMJx04zX3uXOf4TScJ53aLIZcPwIso7+Hbr2OrT932E1ErAPGWIfpBA8zWSnr7S1SErRAOhuAsB8oIuIdBCRXGAoMMXl8UPtOwUYZr0eBnzgPtnx98HIvqk8vYoDt0MVh5KoETqToXo8/8PIN79NdRKqPPeZ5wk7kqlGwbln9MP/WcaIfy/wWbbdr0WYiFTlCpaFmLL09re+5YXPw1f8JnoGy7AdwYwxFSIyEvgYyAYmGGOWi8gIa/04EWkFFAINgUoRuRPoZozZ7bSvdegxwCQRuQlYD1wZ52tTStUAb811rgD33hvDPcGHm5Rm6+7ApqG3vrGw6vWyjeV0aVk/oMIb4CuHcaG86Tl4JLJK6lCDDCaqdM9VT2BjzDRgmt+ycbbXP+Ap3nG1r7V8O3BxJIlVSgX31eqaWUcWrpVUuCacI9/8lmt6Bx/uJdyYPj9+YRa/KHC8vQUwJrrCnAXrdvLjF+I7QZAb2hPY5s2bz051EpSK2uuzA59Qlaez34PvL4vpGIs3uC8a3FweeauxYLmFWHs+h6MBwKZFwzqpToJSqhpa5bJiW0T4VxwD8WirZ3qi6nc0ACil0lKiK0gzgQYAH/oXpVQ62bqn+k22kk53EQ0ANvpEoVR6uXzsN6lOQoA0GAm7igYAmzT63pRSOE/Wk3Jp9CSpAcCmunSkUUq59/b82Cejj5cJs9Ym5EFyUYI6KOqMYDadW9RPdRKUUhHyn6cglSKdy9gt/wHx4kVzADbVZTAtpZRKBg0ASimVoTQABPH53RekOglKKZVQGgCC6JhXnzo5+vEopWouvcOFMP66glQnQSmlEkYDQAh1crJTnQSllEoYDQBKKZWhNAD40akhlVLVUdFW91NtuqUdwfy8/etzAiZwVkqpVFtSWk7nFg3iekwNAH7q5GRr2b9SKiNoEVAI2i9YKVVdJGKMOVcBQEQGisgqESkSkVEO60VE/mqtXyIiPazlJ4nIItvPbmvCeERktIhstK27NK5XppRSKqSwRUAikg2MBQYApcB8EZlijFlh22wQ0MX6ORt4CTjbGLMK6G47zkbgfdt+zxljno7DdSilVI2WiFFG3eQAegFFxphiY8xhYCIwxG+bIcDrxmMO0FhEWvttczGwxhijM1crpVQ14CYAtAHsA26XWssi3WYo8JbfspFWkdEEEWnidHIRGS4ihSJSWFZW5iK5SilV8ySiTtJNAHA6r39uJOQ2IpIL/BR4x7b+JaATniKizcAzTic3xrxsjCkwxhTk5eW5SK5SStU8qSoCKgXa2d63BTZFuM0gYKExZot3gTFmizHmqDGmEhiPp6hJKaWUg70Hj8T9mG4CwHygi4h0sJ7khwJT/LaZAlxntQbqDZQbYzbb1l+FX/GPXx3B5cCyiFOvlFIZYsH6XXE/ZthWQMaYChEZCXwMZAMTjDHLRWSEtX4cMA24FCgC9gM3ePcXkbp4WhD92u/QT4lIdzw5mxKH9dVGz/ZNWLBuZ6qToZRSceWqJ7AxZhqem7x92TjbawPcFmTf/UAzh+XXRpRSpZTKYKmqBFZKKZViqaoEVkD/k1twQtO6qU6GUkrFjQYAl14ZdhbjrumZ6mQopTKUFgGlmElIJkwppcJLxN1Hh4MOoXu7xlzRsy239euc6qQopVTcaQAIoVZ2Fk9feUaqk6GUUgmhRUBKKZUGNu06EPdjagBQSqk0YBIwI4wGgAgkYkYepZRyQ/sBKKVUhkrZlJBKKaVqHg0ASimVBtZt3xf3Y2oAiNIZbRulOglKqQyyc39q5gNQlrZNjgNg9E+68cHIvrxw1ZkpTpFSSkVPO4JFoHHdXErGDK56f1xONgDtm9Vl3fb9qUqWUkpFRXMAcdA5r77Pe29OQSmlqjMNAHHg1Drr1DYNk54OpZSKhAaAGEiI8VklIYO3KqVU/GgASBAdOlopVd25CgAiMlBEVolIkYiMclgvIvJXa/0SEelhW1ciIktFZJGIFNqWNxWRT0VktfW7SXwuSSmllBthA4CIZANjgUFAN+AqEenmt9kgoIv1Mxx4yW99P2NMd2NMgW3ZKGC6MaYLMN16n5bsgzRdd057Jlx/VtBtz8rXOKeUqh7c5AB6AUXGmGJjzGFgIjDEb5shwOvGYw7QWERahznuEOA16/VrwGXuk1092OsAnvvlGfz7prN5dMipnNiyAV1aNACgVpZvXUCdnGwev+zUoMc8o13jRCRVKaUCuAkAbYANtvel1jK32xjgExFZICLDbdu0NMZsBrB+t3A6uYgMF5FCESksKytzkdzUuPzMtvTt0rzq/ROXn8YbN5/NrPsu4qkrTvfZ9pre7SkZM5ipd/QNOM7on/hnrpRSKjHcBACn5iz+NZyhtuljjOmBp5joNhE5P4L0YYx52RhTYIwpyMvLi2TXlDouN5s+nZvTqlEdflHQznGbU45vxIktj/UhGHxauEyTUkrFj5uewKWA/Q7WFtjkdhtjjPf3VhF5H0+R0lfAFhFpbYzZbBUXbY3uElKnQZ0cAFo3jr7j1z9u6MX/lm5mSPc2NDouh217D8UreUopFZKbHMB8oIuIdBCRXGAoMMVvmynAdVZroN5AuXVjryciDQBEpB5wCbDMts8w6/Uw4IMYryXpzspvyou/OpNHfhx9sU2bxsdx83kdyWtQm9xaWRzf+Djm3H9xHFOplFLOwuYAjDEVIjIS+BjIBiYYY5aLyAhr/ThgGnApUATsB26wdm8JvC+e2tJawJvGmI+sdWOASSJyE7AeuDJuV5VEPz79+Ii2b+Mit9CqUZ2q142Oy6H8QPxHAVRKKVeDwRljpuG5yduXjbO9NsBtDvsVA2cEOeZ2IGMedWvXyuJQRSX3DzrZ1fbN6+eybe9hvn14AHdNWsTPerTlugnzEpxKpVQm0dFAk6x2jrvO1+/f2oc5xdvJyhL+MlSHnVZKxZ8OBZEkT1x+mqecP9vdR96uaV2u9Gs9ZB+KWimlYqU5gCT5ec+2/Lxn21QnQymlqmgOoAb5fZhOZL/tf2KSUqKUSgcaAGqQG/p0qBp64pYLOwWs73Z8QxrW0UyfUspDA0ANdXqbwEnrL+rawqcL96WntQrY5utRF/Hh7YFDVCilah4NAGkqWIVwdlbwiWj81114UuDwS7nZWZxyfOBsZppzUCq1GtfNifsxNQDUMO/f2oc7Lu5Cjl9roxYNagds29AaysIeF0RAHKY6+2l3T4e3dk2dO7KN+dlp0SZZKeXCTyLsdOqGBoA09thlp3L7RZ19lnU7viF3DTgxYLrKeQ/2D3qc/ie3pGm93JDnat+0HgCtGzoHgJYN6zguV0rFRxfbwJHxogEgjV3buz13X3ISA7q1dL1P7Vqer/y2foGVxOA8rCvATX078MbNZ9O/m+Oo3VxwYuBIrZEMbd2tdWCxk1LqmHZN68b9mBoAaoCxv+pB4UO+T/i9OjSlU149Lj+zjc8w0xOH9+a3/U/kdz/qWtViKLdWls+sZgDfPjzAZ/ayrCyhT+fm9O7YDIA3bz6bd285x2f9TX07+ByjZ/umrq+hfwRBTCkVHxoAaoDcWlk0r+9bxt+gTg7T776Q537ZnbFXV03RTOcWDfhN/y4A9Ovaglsu7MSjQ47NUOYt/29SL5d3RpwbcK7T2zamZMxgzu3cPOAGH7z6OTKPDTnF5/1TPz89YJsVj/4oTmdTKj3E6//LTgNABsvOEu4b2JWm9XIDZviJB4e6ZFeuPSff5/0vzgqcUKdurrZKUipWGgCUj1ieMqK94UerXm42QNA6kDsu6szYX/VwXJcoJWMGM/66gqSeU6loaQBQAHRp4WlhkJ0d2V38s7vO5x/Xn+W4LlxAOM3WWe2KHpGPk+QdWynYTf6uS05i8OmB02y6mZMhFs3rh25RpVR1ofnoNJSIJ+3x1xWwpLS8qm+AW51bNKBziwYAnODXSqGVX9PQk1s3ZOXm3VXvc2zB5oRmvvuecnxDlm/aTSi//8kp3DewK7m1InuOaRCmU1u93Gz2HT4a0THtElGcplQiaA4gzXx21wXMfSD+8+g0rpvL+Q5NOSNxTe/2/OumXlXvm9WvzdvDe1e9H39dz4BzAjxzpWfOoPkP9uer3/UD3AW57CyhXu3Am3mTujkMPCVwmAuvTnmh21N/4zAlp9thvAGMRgCVJjQApJnOLerTokH17HQlIpzXxTeI2CtrGx3nnLvwdnHPa1C7KieQneX7p3n12Se4Tke/ri0Yd23P8Bva/OiU0M1QuzkMjxGMf5PacB4afDJf3HNhRPvEw+s39gq/kao2nHrox0oDgAqpcd0cn/4AkfIOHTH6J91oEEHx0otXncnVZ5/AqscHAvDHy09j5r39ok6HV26tLMea7pNaHbvBi0C/k3wDmb0pLVCVU3ESaQagZ/sm5DevF3KboQ4toexGXODcsS+Yf990dsw5PpX+XAUAERkoIqtEpEhERjmsFxH5q7V+iYj0sJa3E5EZIrJSRJaLyG9s+4wWkY0issj6uTR+l6XiZdEjlzj2BwjHO/Bc47q5lIwZzPV9OgRsc6F1k+3gcPNr17Quf7z8NGrXyvZZ9u4t5zLtjvMiTg/AktGX8O3DAxzXjbigo8/7Bwf79mK2Vxz36dwsoM7CLlgG4Hc/OomLugb2pA4VMLz1JJ1bBC+2emjwyYwa1DXEUQL17dI8ou39DT6tNed2auaz7JcFzkHqCoeJkPp0buawpUq2sAFARLKBscAgoBtwlYj49/EfBHSxfoYDL1nLK4C7jTEnA72B2/z2fc4Y09368Zl0XqWvCdcXMOPuCx3Xeecp+PzuC7i2d3sWPTKAjmHK5O16tm8SUXGMXcM6OT51Blfabkx1c2vRwKE+wckbN/cOuT5YEdBt/Trz6rCCsBP32J1sDZERLPvfqmEdbj6vo+O6aHlPdVLLBkG3GXt1D978P9/PoWf7wJzi45edWtXCzE6bylYPbnIAvYAiY0yxMeYwMBEY4rfNEOB14zEHaCwirY0xm40xCwGMMXuAlUCbOKZfVUMXdW0Z9An5voFdKRkzmI559RGRqorgRLrnkhMpsN2cvLfS80IWgRy7iUdaVBLqiV5EAgLeaQ5zN4Cn2Of1G3sxcXhvjsvJdtzmtLbH9r3unPY+62qFGBo8lL6dPbmDG/rkR7Sfcbjya3q3p0/nwNxGJJXqKnHcfAttgA2296UE3sTDbiMi+cCZwFzb4pFWkdEEEXEsaBaR4SJSKCKFZWVlLpKrMp1/K5+RF3Vh8i3hi7Fu7ecZWdX/Zhth14iIWwH5D90NcEbbRoz5+ek0rptL747NuKJnW4afH/ikb28C61+8NOu+iwCob8vZXNy1BdPvvsBnu0Gn+raY8uY2WjZybmzw/NDuQa/lyZ8HDgvun3n57rGB1PK7Zv+mvPbWZMG8OuxYLuJvtjoa//qbWDSzRskNFoCTqVe++7G13HITAJz+/P3/xENuIyL1gXeBO40x3sbdLwGdgO7AZuAZp5MbY142xhQYYwry8rTSSoV214ATXVeI+hfV3HJhJ0rGDCYnO4v6tY9VWF93br6r43kH5Iu0X4IbubWyeODSkwHPDf2Fq84Mu0+rRnWYcH0BH915rM7k1evP8gmQCx7qz/NDwx/Lq/iJSxnS3TkT366Jb67P20FPbLeHcdf0oE6Ym2mLBrU59fhjORs3GZlLbQMe/uOGXky4PnwR0/I//KiqN7mTkf068+W9/fjw9r7UivQpIM6e++UZHBcirdFyU+hZCthrd9oCm9xuIyI5eG7+bxhj3vNuYIzZ4n0tIuOBDyNKuVIO7ri4S9ht3DSna9WoDv+5rQ9dWzUIesNq0/g4Nu46AHhuyt4B+Xqc0Jh7LjmRFg3qsKh0F2/OXe+zX+MgzWHvG9iVaUs3s3RjedB0PXXF6ZyV35RlIbYBuHfgSYCnOA48nfTW79gfsF2z+oETBYX6dLL87saLf38JudlZrCnby6ltGvH2/GPX2qaJp+Lc/nEPPDWwZzZ4Wn29Pnsds4q2kVsriyb1cln1+EC+27yHerWz6f/sV4HpDJHQczs1J0ugMkRurF7tWhw+Wln1vv/JLflsZdVtibM6NKV+7Vqc2qYRA09pxTsLSoMfLALndWnOzNXb4nKsWLkJAPOBLiLSAdgIDAV+5bfNFDzFOROBs4FyY8xm8fynvQqsNMY8a9/BW0dgvb0cWBbDdagM9/SVZ7DvUEVcj9m9XWOf9y9f25MVtp7MM+/tx9KN5QwZ+zX5zY89/YoIIy/yBKJfnNWOWlnC6W2PHesMv+N63XJhJ3p3bMrlf/sm6N3tF1ZLm9aN6jCk+/E+rX9aNzrWUunWC30nCnr/1nMdA0A4H97el/klO/jDf1c4rvf27TjVoR7Dm8Pq3KI+Z7RtxNBewftyFOQ3ZUC3lvzls9VcdqYnh1G7VjZntGvMuu37Arb//O4LKPFbPveBi6uK3+rkZFP8p8Hkj5oa8vo6t2hQ1Tv9lWEFPtvb57h44mencXrbRnyyYovjzbtb64Y+fxuhPPfL7hQ8/pnjukbH5VB+4EjAcknIWKAuioCMMRXASOBjPJW4k4wxy0VkhIiMsDabBhQDRcB44FZreR/gWuAih+aeT4nIUhFZAvQDfhu3q1IZ54qebRnmsqjmPKtSskuL4K1cnFxySivu7H9i1fusLKGJVYkdakKbR4ecGtAU8p83eMZP8h/HqKF1Q3VqOWNXJyeb54ee6XPTP6lV8OtpVr82Z54Qvj/HC1edyS+tPgcnt2rIqW0acYNDE95I5GRn8cHIvlwVJADMvLcfTevlIiL8dsCJAc2CnW5+HfPq07WV72fesmEdWgWptwBob2uY8P3jgwB40CpW87rTGir9RL/Zt3Kys7j2nHyfgQfn3H9xVVHTVb3aseCh/jzy427MC9NTv36I1mYLbc2UO4bpGxIPrtq9WU00p/ktG2d7bYDbHPabRZAcpTHm2ohSqlScXFnQlv7dwk+D6cYJzery7i3ncMrxzi15grnwpBaUjBkcsLxTXn3e/L+z6eHiZh1PHZvXo3ib54n60tNaO6YtUm57rrqd6apd0+PYsONA1fvjIxjU78Y+Hbj5vA7sO1TBoYrKqnqa2jm+z8AjLujEO4WlAf1AvAad2ppHPlhO3dxsWjXyBBz7Z3WjNSlSyZjBVFYaOj7g27p9zROXVvWRAU/F/effba16b1835fa+rPphNy9+XhTRrH+R0MHgVMYRkaqb/yM/7kavDrG1rohk5jM3zu0UWyetaPxlaHeufmVuQOeu6qBJPU+u6Bc923Fqm0a0bnzsKb9TXr2QT9Tg6YB3W7/Ojuta++UY6uRk8/Woi4Iey3t/DleRDYH1JeB7gwfnPiNz7r+YwxWV1K9di57tm/KPGxI3ZIcGAJXRbuwbW/FGTXF628YsHR18lrW7BpzoU4QSjL2FUaRjIgXToE4ORX8cRHaWBOQqpgfpcOgVLicTj1xgLC44MY8Zq3ybt4cqxoo37Y2hlArrjou7BG3+aVeQ37RqcL94qpWdlZDB0CLlTUPtODX1HXZuPgv85vNOJs0BKKXiqn2zeuzavyvVyXAl0kxK03q53D3gRMeJhkI5qWUDVm3ZU/W+Xm4253XJQ0Qcm+ImiwYApZSKwO0u+pp4tWhQm9aN6vDuLef69ElY/ujABKQschoAlKpBJo84x3GSHOXMWyl7etvIWnG5Ne/B1BXvuKF/KUrVIAUJGC8mUrf368zNrxfSKUxfhuqgTk42r9/Yy7EjWzL9+vyOnHlC46SfVwOAUiqu+ndrGZd+BMlSHSbGud+vQ1qyaABQSqXEmzefzdY9h1KdjIymAUAplRLnOswToJJL+wEopVSG0gCglFIZSgOAUkplKA0ASimVoTQAKKVUhtIAoJRSGUoDgFJKZSgNAEoplaEkXpM2JIOIlAHroty9ORA4m3PNoNeWnvTa0lM6Xlt7Y0zAmBdpFQBiISKFxpiCVKcjEfTa0pNeW3qqSdemRUBKKZWhNAAopVSGyqQA8HKqE5BAem3pSa8tPdWYa8uYOgCllFK+MikHoJRSykYDgFJKZaiMCAAiMlBEVolIkYiMSnV63BCREhFZKiKLRKTQWtZURD4VkdXW7ya27e+3rm+ViPzItryndZwiEfmriEgKrmWCiGwVkWW2ZXG7FhGpLSJvW8vnikh+iq9ttIhstL67RSJyaZpeWzsRmSEiK0VkuYj8xlqe9t9diGurEd+da8aYGv0DZANrgI5ALrAY6JbqdLlIdwnQ3G/ZU8Ao6/Uo4EnrdTfrumoDHazrzbbWzQPOAQT4HzAoBddyPtADWJaIawFuBcZZr4cCb6f42kYD9zhsm27X1hroYb1uAHxvXUPaf3chrq1GfHdufzIhB9ALKDLGFBtjDgMTgSEpTlO0hgCvWa9fAy6zLZ9ojDlkjFkLFAG9RKQ10NAYM9t4/gpft+2TNMaYr4AdfovjeS32Y00GLk5WTifItQWTbte22Riz0Hq9B1gJtKEGfHchri2YtLm2SGRCAGgDbLC9LyX0F11dGOATEVkgIsOtZS2NMZvB8wcMtLCWB7vGNtZr/+XVQTyvpWofY0wFUA40S1jK3RkpIkusIiJvEUnaXptVfHEmMJca9t35XRvUsO8ulEwIAE4RNx3avvYxxvQABgG3icj5IbYNdo3peO3RXEt1u86XgE5Ad2Az8Iy1PC2vTUTqA+8Cdxpjdofa1GFZtb4+h2urUd9dOJkQAEqBdrb3bYFNKUqLa8aYTdbvrcD7eIqytlhZTqzfW63Ng11jqfXaf3l1EM9rqdpHRGoBjXBfLBN3xpgtxpijxphKYDye7w7S8NpEJAfPDfINY8x71uIa8d05XVtN+u7cyIQAMB/oIiIdRCQXT2XMlBSnKSQRqSciDbyvgUuAZXjSPczabBjwgfV6CjDUanXQAegCzLOy53tEpLdV9nidbZ9Ui+e12I91BfC5VR6bEt6bo+VyPN8dpNm1WWl5FVhpjHnWtirtv7tg11ZTvjvXUl0LnYwf4FI8tfxrgAdTnR4X6e2Ip8XBYmC5N814yg+nA6ut301t+zxoXd8qbC19gAI8f8RrgBexen8n+XrewpOdPoLnqeimeF4LUAd4B0/F3DygY4qv7V/AUmAJnptA6zS9tr54iiyWAIusn0trwncX4tpqxHfn9keHglBKqQyVCUVASimlHGgAUEqpDKUBQCmlMpQGAKWUylAaAJRSKkNpAFBKqQylAUAppTLU/wM5HlTtUQar3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29520 3371\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29520 462\n",
      "Loss:  0.17029014229774475\n",
      "Loss:  0.16691747307777405\n",
      "Loss:  0.16163873672485352\n",
      "0 **********\n",
      "Epoch:  56.50491666793823  fold:  4  kers:  64\n",
      "epoch:  1\n",
      "29520 462\n",
      "Loss:  0.1510513573884964\n",
      "Loss:  0.12880265712738037\n",
      "Loss:  0.12221792340278625\n",
      "1 **********\n",
      "Epoch:  100.38060212135315  fold:  4  kers:  64\n",
      "epoch:  2\n",
      "29520 462\n",
      "Loss:  0.10673146694898605\n",
      "Loss:  0.09953870624303818\n",
      "Loss:  0.0971193015575409\n",
      "2 **********\n",
      "Epoch:  144.25927877426147  fold:  4  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.4851263463497162\n",
      "Eval Loss:  0.40126457810401917\n",
      "Eval Loss:  0.11534677445888519\n",
      "[[2689  448]\n",
      " [ 148   86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90      3137\n",
      "           1       0.16      0.37      0.22       234\n",
      "\n",
      "    accuracy                           0.82      3371\n",
      "   macro avg       0.55      0.61      0.56      3371\n",
      "weighted avg       0.89      0.82      0.85      3371\n",
      "\n",
      "acc:  0.8231978641352714\n",
      "pre:  0.16104868913857678\n",
      "rec:  0.36752136752136755\n",
      "ma F1:  0.5620963410891642\n",
      "mi F1:  0.8231978641352714\n",
      "we F1:  0.8532902409750072\n",
      "update!  Acc:  0.8231978641352714\n",
      "Eval Loss:  0.37627309560775757\n",
      "Eval Loss:  0.43347954750061035\n",
      "Eval Loss:  0.4748201072216034\n",
      "Eval Loss:  0.3962424099445343\n",
      "Eval Loss:  0.3973299264907837\n",
      "Eval Loss:  0.35883307456970215\n",
      "Eval Loss:  0.4693894684314728\n",
      "Eval Loss:  0.46096089482307434\n",
      "Eval Loss:  0.3345812261104584\n",
      "Eval Loss:  0.4102010428905487\n",
      "Eval Loss:  0.32436034083366394\n",
      "Eval Loss:  0.46541768312454224\n",
      "Eval Loss:  0.4117352366447449\n",
      "Eval Loss:  0.4737519919872284\n",
      "Eval Loss:  0.4712619483470917\n",
      "Eval Loss:  0.3907489478588104\n",
      "Eval Loss:  0.38493612408638\n",
      "Eval Loss:  0.39069631695747375\n",
      "Eval Loss:  0.36899247765541077\n",
      "Eval Loss:  0.4527415335178375\n",
      "Eval Loss:  0.4622650444507599\n",
      "Eval Loss:  0.4322385787963867\n",
      "Eval Loss:  0.4862879514694214\n",
      "Eval Loss:  0.4696156680583954\n",
      "Eval Loss:  0.5043095350265503\n",
      "Eval Loss:  0.5444146990776062\n",
      "Eval Loss:  0.5449903011322021\n",
      "Eval Loss:  0.4103853404521942\n",
      "[[14215  2812]\n",
      " [ 2781  9712]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84     17027\n",
      "           1       0.78      0.78      0.78     12493\n",
      "\n",
      "    accuracy                           0.81     29520\n",
      "   macro avg       0.81      0.81      0.81     29520\n",
      "weighted avg       0.81      0.81      0.81     29520\n",
      "\n",
      "acc:  0.8105352303523036\n",
      "pre:  0.7754710954966464\n",
      "rec:  0.777395341391179\n",
      "ma F1:  0.8060216152037865\n",
      "mi F1:  0.8105352303523036\n",
      "we F1:  0.8105663034301637\n",
      "29520 462\n",
      "Loss:  0.0980176255106926\n",
      "Loss:  0.09601297974586487\n",
      "Loss:  0.09772680699825287\n",
      "3 **********\n",
      "Epoch:  228.96479320526123  fold:  4  kers:  64\n",
      "epoch:  4\n",
      "29520 462\n",
      "Loss:  0.08851879835128784\n",
      "Loss:  0.11315783113241196\n",
      "Loss:  0.08754368871450424\n",
      "4 **********\n",
      "Epoch:  272.7975935935974  fold:  4  kers:  64\n",
      "epoch:  5\n",
      "29520 462\n",
      "Loss:  0.08988065272569656\n",
      "Loss:  0.1035502478480339\n",
      "Loss:  0.09495772421360016\n",
      "5 **********\n",
      "Epoch:  316.6962180137634  fold:  4  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.15157803893089294\n",
      "Eval Loss:  0.1886764019727707\n",
      "Eval Loss:  0.04447605460882187\n",
      "[[3057   80]\n",
      " [ 222   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3137\n",
      "           1       0.13      0.05      0.07       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.53      0.51      0.51      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.910412340551765\n",
      "pre:  0.13043478260869565\n",
      "rec:  0.05128205128205128\n",
      "ma F1:  0.5132749032327157\n",
      "mi F1:  0.910412340551765\n",
      "we F1:  0.8918923024239145\n",
      "update!  Acc:  0.910412340551765\n",
      "Eval Loss:  0.36379846930503845\n",
      "Eval Loss:  0.3890511691570282\n",
      "Eval Loss:  0.460281103849411\n",
      "Eval Loss:  0.27906209230422974\n",
      "Eval Loss:  0.31988289952278137\n",
      "Eval Loss:  0.30518588423728943\n",
      "Eval Loss:  0.356298565864563\n",
      "Eval Loss:  0.4292522966861725\n",
      "Eval Loss:  0.3139854967594147\n",
      "Eval Loss:  0.389873206615448\n",
      "Eval Loss:  0.35617145895957947\n",
      "Eval Loss:  0.37953290343284607\n",
      "Eval Loss:  0.37469205260276794\n",
      "Eval Loss:  0.35250020027160645\n",
      "Eval Loss:  0.4147932827472687\n",
      "Eval Loss:  0.3599527180194855\n",
      "Eval Loss:  0.3365006446838379\n",
      "Eval Loss:  0.38030943274497986\n",
      "Eval Loss:  0.34120598435401917\n",
      "Eval Loss:  0.4355645477771759\n",
      "Eval Loss:  0.3022315204143524\n",
      "Eval Loss:  0.3841525912284851\n",
      "Eval Loss:  0.4584740102291107\n",
      "Eval Loss:  0.32525333762168884\n",
      "Eval Loss:  0.4828347861766815\n",
      "Eval Loss:  0.4860038161277771\n",
      "Eval Loss:  0.460794597864151\n",
      "Eval Loss:  0.29889413714408875\n",
      "[[16040   987]\n",
      " [ 3598  8895]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87     17027\n",
      "           1       0.90      0.71      0.80     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.86      0.83      0.84     29520\n",
      "weighted avg       0.85      0.84      0.84     29520\n",
      "\n",
      "acc:  0.8446815718157181\n",
      "pre:  0.9001214329083181\n",
      "rec:  0.7119987192827983\n",
      "ma F1:  0.8350163300972797\n",
      "mi F1:  0.8446815718157181\n",
      "we F1:  0.8411495989498199\n",
      "29520 462\n",
      "Loss:  0.09322914481163025\n",
      "Loss:  0.10162856429815292\n",
      "Loss:  0.07199395447969437\n",
      "6 **********\n",
      "Epoch:  401.3379030227661  fold:  4  kers:  64\n",
      "epoch:  7\n",
      "29520 462\n",
      "Loss:  0.07512839138507843\n",
      "Loss:  0.07518037408590317\n",
      "Loss:  0.06501208990812302\n",
      "7 **********\n",
      "Epoch:  445.25248432159424  fold:  4  kers:  64\n",
      "epoch:  8\n",
      "29520 462\n",
      "Loss:  0.07835601270198822\n",
      "Loss:  0.07280022650957108\n",
      "Loss:  0.09864357858896255\n",
      "8 **********\n",
      "Epoch:  489.1710548400879  fold:  4  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.06392158567905426\n",
      "Eval Loss:  0.12308868765830994\n",
      "Eval Loss:  0.036527957767248154\n",
      "[[3087   50]\n",
      " [ 209   25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.33      0.11      0.16       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.63      0.55      0.56      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9231681993473747\n",
      "pre:  0.3333333333333333\n",
      "rec:  0.10683760683760683\n",
      "ma F1:  0.5607755721534946\n",
      "mi F1:  0.9231681993473747\n",
      "we F1:  0.9043502934937409\n",
      "update!  Acc:  0.9231681993473747\n",
      "Eval Loss:  0.37015026807785034\n",
      "Eval Loss:  0.4564114511013031\n",
      "Eval Loss:  0.44908884167671204\n",
      "Eval Loss:  0.3238483667373657\n",
      "Eval Loss:  0.3488476276397705\n",
      "Eval Loss:  0.31473779678344727\n",
      "Eval Loss:  0.3701840937137604\n",
      "Eval Loss:  0.45490753650665283\n",
      "Eval Loss:  0.399733304977417\n",
      "Eval Loss:  0.40433967113494873\n",
      "Eval Loss:  0.3720747232437134\n",
      "Eval Loss:  0.4444127082824707\n",
      "Eval Loss:  0.4296562969684601\n",
      "Eval Loss:  0.38802197575569153\n",
      "Eval Loss:  0.4668826758861542\n",
      "Eval Loss:  0.4213304817676544\n",
      "Eval Loss:  0.4123862683773041\n",
      "Eval Loss:  0.43517351150512695\n",
      "Eval Loss:  0.366784006357193\n",
      "Eval Loss:  0.483846515417099\n",
      "Eval Loss:  0.2719820737838745\n",
      "Eval Loss:  0.37739330530166626\n",
      "Eval Loss:  0.4535316228866577\n",
      "Eval Loss:  0.4093610346317291\n",
      "Eval Loss:  0.4471851587295532\n",
      "Eval Loss:  0.43858781456947327\n",
      "Eval Loss:  0.5070351362228394\n",
      "Eval Loss:  0.30815789103507996\n",
      "[[16558   469]\n",
      " [ 4367  8126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     17027\n",
      "           1       0.95      0.65      0.77     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.87      0.81      0.82     29520\n",
      "weighted avg       0.86      0.84      0.83     29520\n",
      "\n",
      "acc:  0.8361788617886179\n",
      "pre:  0.9454333915066899\n",
      "rec:  0.6504442487793164\n",
      "ma F1:  0.8216255754413528\n",
      "mi F1:  0.8361788617886179\n",
      "we F1:  0.8294510735792204\n",
      "29520 462\n",
      "Loss:  0.04876910150051117\n",
      "Loss:  0.10718914121389389\n",
      "Loss:  0.08286462724208832\n",
      "9 **********\n",
      "Epoch:  573.9743084907532  fold:  4  kers:  64\n",
      "epoch:  10\n",
      "29520 462\n",
      "Loss:  0.08487430959939957\n",
      "Loss:  0.0726672112941742\n",
      "Loss:  0.07857721298933029\n",
      "10 **********\n",
      "Epoch:  617.9128255844116  fold:  4  kers:  64\n",
      "epoch:  11\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.11128748953342438\n",
      "Loss:  0.08656901866197586\n",
      "Loss:  0.05298846587538719\n",
      "11 **********\n",
      "Epoch:  661.8204255104065  fold:  4  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.028743524104356766\n",
      "Eval Loss:  0.13895025849342346\n",
      "Eval Loss:  0.03884027898311615\n",
      "[[3076   61]\n",
      " [ 218   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.21      0.07      0.10       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.57      0.52      0.53      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9172352417680214\n",
      "pre:  0.2077922077922078\n",
      "rec:  0.06837606837606838\n",
      "ma F1:  0.5297551400196295\n",
      "mi F1:  0.9172352417680214\n",
      "we F1:  0.8973547267436758\n",
      "Eval Loss:  0.29783132672309875\n",
      "Eval Loss:  0.3591923713684082\n",
      "Eval Loss:  0.3352407217025757\n",
      "Eval Loss:  0.21866251528263092\n",
      "Eval Loss:  0.24711638689041138\n",
      "Eval Loss:  0.228504478931427\n",
      "Eval Loss:  0.2812517583370209\n",
      "Eval Loss:  0.3365817964076996\n",
      "Eval Loss:  0.3048330843448639\n",
      "Eval Loss:  0.2977016866207123\n",
      "Eval Loss:  0.29105934500694275\n",
      "Eval Loss:  0.34751614928245544\n",
      "Eval Loss:  0.32670682668685913\n",
      "Eval Loss:  0.2858230769634247\n",
      "Eval Loss:  0.3234878480434418\n",
      "Eval Loss:  0.3125847280025482\n",
      "Eval Loss:  0.2623348534107208\n",
      "Eval Loss:  0.325361043214798\n",
      "Eval Loss:  0.29403257369995117\n",
      "Eval Loss:  0.38265809416770935\n",
      "Eval Loss:  0.2134123146533966\n",
      "Eval Loss:  0.3063691258430481\n",
      "Eval Loss:  0.32475244998931885\n",
      "Eval Loss:  0.2837543487548828\n",
      "Eval Loss:  0.3388812839984894\n",
      "Eval Loss:  0.35420578718185425\n",
      "Eval Loss:  0.41351914405822754\n",
      "Eval Loss:  0.25737065076828003\n",
      "[[16219   808]\n",
      " [ 2978  9515]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.90     17027\n",
      "           1       0.92      0.76      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.88      0.86      0.86     29520\n",
      "weighted avg       0.88      0.87      0.87     29520\n",
      "\n",
      "acc:  0.8717479674796748\n",
      "pre:  0.921728179792696\n",
      "rec:  0.7616265108460738\n",
      "ma F1:  0.8647737360552883\n",
      "mi F1:  0.8717479674796748\n",
      "we F1:  0.8694904969858026\n",
      "29520 462\n",
      "Loss:  0.0676618218421936\n",
      "Loss:  0.10333507508039474\n",
      "Loss:  0.05358188599348068\n",
      "12 **********\n",
      "Epoch:  752.3483810424805  fold:  4  kers:  64\n",
      "epoch:  13\n",
      "29520 462\n",
      "Loss:  0.09152866899967194\n",
      "Loss:  0.05570410192012787\n",
      "Loss:  0.058054450899362564\n",
      "13 **********\n",
      "Epoch:  796.0894258022308  fold:  4  kers:  64\n",
      "epoch:  14\n",
      "29520 462\n",
      "Loss:  0.057269126176834106\n",
      "Loss:  0.11220210790634155\n",
      "Loss:  0.06830489635467529\n",
      "14 **********\n",
      "Epoch:  839.9110720157623  fold:  4  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.030067812651395798\n",
      "Eval Loss:  0.1544564813375473\n",
      "Eval Loss:  0.0357208177447319\n",
      "[[3066   71]\n",
      " [ 212   22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3137\n",
      "           1       0.24      0.09      0.13       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.59      0.54      0.55      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9160486502521507\n",
      "pre:  0.23655913978494625\n",
      "rec:  0.09401709401709402\n",
      "ma F1:  0.5452206101429896\n",
      "mi F1:  0.9160486502521507\n",
      "we F1:  0.8988716615348736\n",
      "Eval Loss:  0.2672945261001587\n",
      "Eval Loss:  0.3522789478302002\n",
      "Eval Loss:  0.32310187816619873\n",
      "Eval Loss:  0.20952585339546204\n",
      "Eval Loss:  0.24222633242607117\n",
      "Eval Loss:  0.23683302104473114\n",
      "Eval Loss:  0.2706911563873291\n",
      "Eval Loss:  0.3162996768951416\n",
      "Eval Loss:  0.3076229989528656\n",
      "Eval Loss:  0.3072246015071869\n",
      "Eval Loss:  0.25986769795417786\n",
      "Eval Loss:  0.3316214084625244\n",
      "Eval Loss:  0.33401602506637573\n",
      "Eval Loss:  0.2917965352535248\n",
      "Eval Loss:  0.31103914976119995\n",
      "Eval Loss:  0.29612261056900024\n",
      "Eval Loss:  0.2622528374195099\n",
      "Eval Loss:  0.30152297019958496\n",
      "Eval Loss:  0.29678407311439514\n",
      "Eval Loss:  0.41975852847099304\n",
      "Eval Loss:  0.23175276815891266\n",
      "Eval Loss:  0.3122407793998718\n",
      "Eval Loss:  0.3228187561035156\n",
      "Eval Loss:  0.29383283853530884\n",
      "Eval Loss:  0.33841320872306824\n",
      "Eval Loss:  0.34888702630996704\n",
      "Eval Loss:  0.3894370496273041\n",
      "Eval Loss:  0.2926782965660095\n",
      "[[16282   745]\n",
      " [ 2973  9520]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     17027\n",
      "           1       0.93      0.76      0.84     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.89      0.86      0.87     29520\n",
      "weighted avg       0.88      0.87      0.87     29520\n",
      "\n",
      "acc:  0.8740514905149052\n",
      "pre:  0.927423283000487\n",
      "rec:  0.7620267349715841\n",
      "ma F1:  0.8670769106277127\n",
      "mi F1:  0.8740514905149052\n",
      "we F1:  0.8717534479256319\n",
      "29520 462\n",
      "Loss:  0.06177617982029915\n",
      "Loss:  0.0799962654709816\n",
      "Loss:  0.054047681391239166\n",
      "15 **********\n",
      "Epoch:  924.1049587726593  fold:  4  kers:  64\n",
      "epoch:  16\n",
      "29520 462\n",
      "Loss:  0.05396927893161774\n",
      "Loss:  0.09528754651546478\n",
      "Loss:  0.09613858908414841\n",
      "16 **********\n",
      "Epoch:  967.755247592926  fold:  4  kers:  64\n",
      "epoch:  17\n",
      "29520 462\n",
      "Loss:  0.09557989984750748\n",
      "Loss:  0.05548461154103279\n",
      "Loss:  0.04530934989452362\n",
      "17 **********\n",
      "Epoch:  1011.5830602645874  fold:  4  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.03439795970916748\n",
      "Eval Loss:  0.2181345522403717\n",
      "Eval Loss:  0.025744227692484856\n",
      "[[3038   99]\n",
      " [ 211   23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.19      0.10      0.13       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.56      0.53      0.54      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9080391575200237\n",
      "pre:  0.1885245901639344\n",
      "rec:  0.09829059829059829\n",
      "ma F1:  0.5403348969128395\n",
      "mi F1:  0.9080391575200237\n",
      "we F1:  0.8943798284361083\n",
      "Eval Loss:  0.28466692566871643\n",
      "Eval Loss:  0.3326365649700165\n",
      "Eval Loss:  0.2814502716064453\n",
      "Eval Loss:  0.2019032984972\n",
      "Eval Loss:  0.22370584309101105\n",
      "Eval Loss:  0.21585574746131897\n",
      "Eval Loss:  0.23494268953800201\n",
      "Eval Loss:  0.29835233092308044\n",
      "Eval Loss:  0.27982527017593384\n",
      "Eval Loss:  0.3025316596031189\n",
      "Eval Loss:  0.2526437044143677\n",
      "Eval Loss:  0.32898014783859253\n",
      "Eval Loss:  0.3339614272117615\n",
      "Eval Loss:  0.31712305545806885\n",
      "Eval Loss:  0.28107479214668274\n",
      "Eval Loss:  0.2988172769546509\n",
      "Eval Loss:  0.22046127915382385\n",
      "Eval Loss:  0.29467010498046875\n",
      "Eval Loss:  0.26628461480140686\n",
      "Eval Loss:  0.4095272421836853\n",
      "Eval Loss:  0.2331060916185379\n",
      "Eval Loss:  0.2880377471446991\n",
      "Eval Loss:  0.31724977493286133\n",
      "Eval Loss:  0.2610325515270233\n",
      "Eval Loss:  0.3180687129497528\n",
      "Eval Loss:  0.3402267396450043\n",
      "Eval Loss:  0.37333714962005615\n",
      "Eval Loss:  0.2615405023097992\n",
      "[[16255   772]\n",
      " [ 2748  9745]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     17027\n",
      "           1       0.93      0.78      0.85     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.89      0.87      0.87     29520\n",
      "weighted avg       0.89      0.88      0.88     29520\n",
      "\n",
      "acc:  0.8807588075880759\n",
      "pre:  0.9265950366073975\n",
      "rec:  0.7800368206195469\n",
      "ma F1:  0.874663334661359\n",
      "mi F1:  0.8807588075880759\n",
      "we F1:  0.8789086302450355\n",
      "29520 462\n",
      "Loss:  0.055941708385944366\n",
      "Loss:  0.07184775918722153\n",
      "Loss:  0.09278714656829834\n",
      "18 **********\n",
      "Epoch:  1095.9963562488556  fold:  4  kers:  64\n",
      "epoch:  19\n",
      "29520 462\n",
      "Loss:  0.05147996172308922\n",
      "Loss:  0.08315929025411606\n",
      "Loss:  0.043550509959459305\n",
      "19 **********\n",
      "Epoch:  1139.6845571994781  fold:  4  kers:  64\n",
      "epoch:  20\n",
      "29520 462\n",
      "Loss:  0.060704588890075684\n",
      "Loss:  0.07991119474172592\n",
      "Loss:  0.06191541999578476\n",
      "20 **********\n",
      "Epoch:  1183.4485411643982  fold:  4  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.04302544146776199\n",
      "Eval Loss:  0.33106255531311035\n",
      "Eval Loss:  0.017662325873970985\n",
      "[[2968  169]\n",
      " [ 205   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      3137\n",
      "           1       0.15      0.12      0.13       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.54      0.54      0.54      3371\n",
      "weighted avg       0.88      0.89      0.88      3371\n",
      "\n",
      "acc:  0.8890536932660932\n",
      "pre:  0.14646464646464646\n",
      "rec:  0.12393162393162394\n",
      "ma F1:  0.5374941304220225\n",
      "mi F1:  0.8890536932660932\n",
      "we F1:  0.8847474175728686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2953416407108307\n",
      "Eval Loss:  0.2754749357700348\n",
      "Eval Loss:  0.2589183747768402\n",
      "Eval Loss:  0.15408848226070404\n",
      "Eval Loss:  0.18415148556232452\n",
      "Eval Loss:  0.18561038374900818\n",
      "Eval Loss:  0.19729828834533691\n",
      "Eval Loss:  0.25959697365760803\n",
      "Eval Loss:  0.2293921262025833\n",
      "Eval Loss:  0.2850068509578705\n",
      "Eval Loss:  0.22865915298461914\n",
      "Eval Loss:  0.2956671118736267\n",
      "Eval Loss:  0.28916826844215393\n",
      "Eval Loss:  0.26822298765182495\n",
      "Eval Loss:  0.22346116602420807\n",
      "Eval Loss:  0.25331631302833557\n",
      "Eval Loss:  0.1759406179189682\n",
      "Eval Loss:  0.2632487714290619\n",
      "Eval Loss:  0.22386129200458527\n",
      "Eval Loss:  0.34559082984924316\n",
      "Eval Loss:  0.2067459374666214\n",
      "Eval Loss:  0.2706902325153351\n",
      "Eval Loss:  0.2973172664642334\n",
      "Eval Loss:  0.22843244671821594\n",
      "Eval Loss:  0.28822067379951477\n",
      "Eval Loss:  0.2910906970500946\n",
      "Eval Loss:  0.2962729036808014\n",
      "Eval Loss:  0.27260205149650574\n",
      "[[15829  1198]\n",
      " [ 1829 10664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     17027\n",
      "           1       0.90      0.85      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.89      0.89     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.8974593495934959\n",
      "pre:  0.8990052267745743\n",
      "rec:  0.8535980148883374\n",
      "ma F1:  0.8942211255968349\n",
      "mi F1:  0.8974593495934959\n",
      "we F1:  0.8970637408148137\n",
      "29520 462\n",
      "Loss:  0.05390822887420654\n",
      "Loss:  0.06333836168050766\n",
      "Loss:  0.07373577356338501\n",
      "21 **********\n",
      "Epoch:  1267.8398954868317  fold:  4  kers:  64\n",
      "epoch:  22\n",
      "29520 462\n",
      "Loss:  0.07675748318433762\n",
      "Loss:  0.049920495599508286\n",
      "Loss:  0.10367657989263535\n",
      "22 **********\n",
      "Epoch:  1311.64177775383  fold:  4  kers:  64\n",
      "epoch:  23\n",
      "29520 462\n",
      "Loss:  0.03750064969062805\n",
      "Loss:  0.0654401108622551\n",
      "Loss:  0.09228914231061935\n",
      "23 **********\n",
      "Epoch:  1355.3209879398346  fold:  4  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.03110995888710022\n",
      "Eval Loss:  0.22400954365730286\n",
      "Eval Loss:  0.00936928391456604\n",
      "[[3050   87]\n",
      " [ 220   14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3137\n",
      "           1       0.14      0.06      0.08       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.54      0.52      0.52      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9089291011569267\n",
      "pre:  0.13861386138613863\n",
      "rec:  0.05982905982905983\n",
      "ma F1:  0.517832874025378\n",
      "mi F1:  0.9089291011569267\n",
      "we F1:  0.8917960977944446\n",
      "Eval Loss:  0.3082236051559448\n",
      "Eval Loss:  0.3694315552711487\n",
      "Eval Loss:  0.3275362551212311\n",
      "Eval Loss:  0.22603739798069\n",
      "Eval Loss:  0.2423103004693985\n",
      "Eval Loss:  0.255743145942688\n",
      "Eval Loss:  0.24804602563381195\n",
      "Eval Loss:  0.3522506654262543\n",
      "Eval Loss:  0.3159792125225067\n",
      "Eval Loss:  0.31077080965042114\n",
      "Eval Loss:  0.30834999680519104\n",
      "Eval Loss:  0.34975743293762207\n",
      "Eval Loss:  0.35469138622283936\n",
      "Eval Loss:  0.35443395376205444\n",
      "Eval Loss:  0.3444424867630005\n",
      "Eval Loss:  0.30070391297340393\n",
      "Eval Loss:  0.2543010115623474\n",
      "Eval Loss:  0.28660139441490173\n",
      "Eval Loss:  0.2806212902069092\n",
      "Eval Loss:  0.44863879680633545\n",
      "Eval Loss:  0.2715507447719574\n",
      "Eval Loss:  0.30063316226005554\n",
      "Eval Loss:  0.36535748839378357\n",
      "Eval Loss:  0.2975313663482666\n",
      "Eval Loss:  0.3699842393398285\n",
      "Eval Loss:  0.3564217686653137\n",
      "Eval Loss:  0.4504188895225525\n",
      "Eval Loss:  0.3029768764972687\n",
      "[[16545   482]\n",
      " [ 3411  9082]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89     17027\n",
      "           1       0.95      0.73      0.82     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.89      0.85      0.86     29520\n",
      "weighted avg       0.88      0.87      0.86     29520\n",
      "\n",
      "acc:  0.8681233062330623\n",
      "pre:  0.9496026767043079\n",
      "rec:  0.726967101576883\n",
      "ma F1:  0.8591190809348495\n",
      "mi F1:  0.8681233062330623\n",
      "we F1:  0.8645894222857937\n",
      "29520 462\n",
      "Loss:  0.09230325371026993\n",
      "Loss:  0.07689124345779419\n",
      "Loss:  0.06897590309381485\n",
      "24 **********\n",
      "Epoch:  1439.7482080459595  fold:  4  kers:  64\n",
      "epoch:  25\n",
      "29520 462\n",
      "Loss:  0.031190000474452972\n",
      "Loss:  0.06993917375802994\n",
      "Loss:  0.06367458403110504\n",
      "25 **********\n",
      "Epoch:  1483.4862215518951  fold:  4  kers:  64\n",
      "epoch:  26\n",
      "29520 462\n",
      "Loss:  0.047761157155036926\n",
      "Loss:  0.0561654195189476\n",
      "Loss:  0.045507028698921204\n",
      "26 **********\n",
      "Epoch:  1527.1786324977875  fold:  4  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.06408172845840454\n",
      "Eval Loss:  0.49235326051712036\n",
      "Eval Loss:  0.016135165467858315\n",
      "[[2868  269]\n",
      " [ 207   27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      3137\n",
      "           1       0.09      0.12      0.10       234\n",
      "\n",
      "    accuracy                           0.86      3371\n",
      "   macro avg       0.51      0.51      0.51      3371\n",
      "weighted avg       0.87      0.86      0.87      3371\n",
      "\n",
      "acc:  0.8587956096113912\n",
      "pre:  0.09121621621621621\n",
      "rec:  0.11538461538461539\n",
      "ma F1:  0.5126304535348504\n",
      "mi F1:  0.8587956096113912\n",
      "we F1:  0.8663500762346736\n",
      "Eval Loss:  0.27486610412597656\n",
      "Eval Loss:  0.26542413234710693\n",
      "Eval Loss:  0.2391791194677353\n",
      "Eval Loss:  0.14593994617462158\n",
      "Eval Loss:  0.15271484851837158\n",
      "Eval Loss:  0.1719883680343628\n",
      "Eval Loss:  0.18990656733512878\n",
      "Eval Loss:  0.25156235694885254\n",
      "Eval Loss:  0.2071346640586853\n",
      "Eval Loss:  0.26406967639923096\n",
      "Eval Loss:  0.20124906301498413\n",
      "Eval Loss:  0.2639111280441284\n",
      "Eval Loss:  0.2566772401332855\n",
      "Eval Loss:  0.26192742586135864\n",
      "Eval Loss:  0.1942353993654251\n",
      "Eval Loss:  0.23336468636989594\n",
      "Eval Loss:  0.17531639337539673\n",
      "Eval Loss:  0.2667989134788513\n",
      "Eval Loss:  0.21345923840999603\n",
      "Eval Loss:  0.26581084728240967\n",
      "Eval Loss:  0.18810510635375977\n",
      "Eval Loss:  0.2642335295677185\n",
      "Eval Loss:  0.2795872986316681\n",
      "Eval Loss:  0.2181376814842224\n",
      "Eval Loss:  0.28093770146369934\n",
      "Eval Loss:  0.29140371084213257\n",
      "Eval Loss:  0.27669650316238403\n",
      "Eval Loss:  0.2418566346168518\n",
      "[[15770  1257]\n",
      " [ 1596 10897]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     17027\n",
      "           1       0.90      0.87      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.90      0.90     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9033536585365853\n",
      "pre:  0.896577258515715\n",
      "rec:  0.8722484591371168\n",
      "ma F1:  0.9006463103289077\n",
      "mi F1:  0.9033536585365853\n",
      "we F1:  0.9031653164388216\n",
      "29520 462\n",
      "Loss:  0.08322729915380478\n",
      "Loss:  0.07111674547195435\n",
      "Loss:  0.09572391957044601\n",
      "27 **********\n",
      "Epoch:  1611.8038818836212  fold:  4  kers:  64\n",
      "epoch:  28\n",
      "29520 462\n",
      "Loss:  0.09321849048137665\n",
      "Loss:  0.08098731189966202\n",
      "Loss:  0.07659337669610977\n",
      "28 **********\n",
      "Epoch:  1655.6536376476288  fold:  4  kers:  64\n",
      "epoch:  29\n",
      "29520 462\n",
      "Loss:  0.037518538534641266\n",
      "Loss:  0.052452243864536285\n",
      "Loss:  0.05194142460823059\n",
      "29 **********\n",
      "Epoch:  1699.390496969223  fold:  4  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.11410781741142273\n",
      "Eval Loss:  0.40820181369781494\n",
      "Eval Loss:  0.035887282341718674\n",
      "[[2934  203]\n",
      " [ 206   28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      3137\n",
      "           1       0.12      0.12      0.12       234\n",
      "\n",
      "    accuracy                           0.88      3371\n",
      "   macro avg       0.53      0.53      0.53      3371\n",
      "weighted avg       0.88      0.88      0.88      3371\n",
      "\n",
      "acc:  0.8786710175022249\n",
      "pre:  0.12121212121212122\n",
      "rec:  0.11965811965811966\n",
      "ma F1:  0.5276357961563036\n",
      "mi F1:  0.878671017502225\n",
      "we F1:  0.8783086273907184\n",
      "Eval Loss:  0.26769116520881653\n",
      "Eval Loss:  0.2650076448917389\n",
      "Eval Loss:  0.22804978489875793\n",
      "Eval Loss:  0.16790349781513214\n",
      "Eval Loss:  0.18452051281929016\n",
      "Eval Loss:  0.14788177609443665\n",
      "Eval Loss:  0.16972456872463226\n",
      "Eval Loss:  0.2512686550617218\n",
      "Eval Loss:  0.2055066078901291\n",
      "Eval Loss:  0.2684507369995117\n",
      "Eval Loss:  0.1799103021621704\n",
      "Eval Loss:  0.2936847507953644\n",
      "Eval Loss:  0.2438030242919922\n",
      "Eval Loss:  0.26131540536880493\n",
      "Eval Loss:  0.1887187510728836\n",
      "Eval Loss:  0.25338858366012573\n",
      "Eval Loss:  0.17080791294574738\n",
      "Eval Loss:  0.22450728714466095\n",
      "Eval Loss:  0.20652715861797333\n",
      "Eval Loss:  0.26194676756858826\n",
      "Eval Loss:  0.18079781532287598\n",
      "Eval Loss:  0.25095468759536743\n",
      "Eval Loss:  0.2551525831222534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20217624306678772\n",
      "Eval Loss:  0.3018087148666382\n",
      "Eval Loss:  0.272352397441864\n",
      "Eval Loss:  0.2883571982383728\n",
      "Eval Loss:  0.21523363888263702\n",
      "[[16062   965]\n",
      " [ 1820 10673]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17027\n",
      "           1       0.92      0.85      0.88     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.90     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9056571815718157\n",
      "pre:  0.9170819728475683\n",
      "rec:  0.854318418314256\n",
      "ma F1:  0.9024047176660989\n",
      "mi F1:  0.9056571815718157\n",
      "we F1:  0.9051411569588286\n",
      "29520 462\n",
      "Loss:  0.06334812194108963\n",
      "Loss:  0.08744069933891296\n",
      "Loss:  0.04193483293056488\n",
      "30 **********\n",
      "Epoch:  1783.9234738349915  fold:  4  kers:  64\n",
      "epoch:  31\n",
      "29520 462\n",
      "Loss:  0.04946322739124298\n",
      "Loss:  0.04400407895445824\n",
      "Loss:  0.08574401587247849\n",
      "31 **********\n",
      "Epoch:  1827.668508052826  fold:  4  kers:  64\n",
      "epoch:  32\n",
      "29520 462\n",
      "Loss:  0.0755949541926384\n",
      "Loss:  0.041493307799100876\n",
      "Loss:  0.04228900372982025\n",
      "32 **********\n",
      "Epoch:  1871.5421986579895  fold:  4  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.24862666428089142\n",
      "Eval Loss:  0.18081405758857727\n",
      "Eval Loss:  0.027165286242961884\n",
      "[[3017  120]\n",
      " [ 204   30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.20      0.13      0.16       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.57      0.54      0.55      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9038860872144764\n",
      "pre:  0.2\n",
      "rec:  0.1282051282051282\n",
      "ma F1:  0.5526452893991822\n",
      "mi F1:  0.9038860872144765\n",
      "we F1:  0.8940085421805011\n",
      "Eval Loss:  0.26757001876831055\n",
      "Eval Loss:  0.294868141412735\n",
      "Eval Loss:  0.24999186396598816\n",
      "Eval Loss:  0.174891859292984\n",
      "Eval Loss:  0.18410393595695496\n",
      "Eval Loss:  0.15290239453315735\n",
      "Eval Loss:  0.17014284431934357\n",
      "Eval Loss:  0.2769295573234558\n",
      "Eval Loss:  0.23460660874843597\n",
      "Eval Loss:  0.2445712685585022\n",
      "Eval Loss:  0.20745934545993805\n",
      "Eval Loss:  0.28522688150405884\n",
      "Eval Loss:  0.2118467539548874\n",
      "Eval Loss:  0.2595921456813812\n",
      "Eval Loss:  0.20321643352508545\n",
      "Eval Loss:  0.23132961988449097\n",
      "Eval Loss:  0.18544597923755646\n",
      "Eval Loss:  0.24772068858146667\n",
      "Eval Loss:  0.22370080649852753\n",
      "Eval Loss:  0.2952907085418701\n",
      "Eval Loss:  0.16394802927970886\n",
      "Eval Loss:  0.24713172018527985\n",
      "Eval Loss:  0.24910014867782593\n",
      "Eval Loss:  0.24201452732086182\n",
      "Eval Loss:  0.32511910796165466\n",
      "Eval Loss:  0.2683209478855133\n",
      "Eval Loss:  0.31110623478889465\n",
      "Eval Loss:  0.21388177573680878\n",
      "[[16218   809]\n",
      " [ 2048 10445]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17027\n",
      "           1       0.93      0.84      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.91      0.89      0.90     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9032181571815718\n",
      "pre:  0.9281144481961969\n",
      "rec:  0.836068198190987\n",
      "ma F1:  0.8993695846676082\n",
      "mi F1:  0.9032181571815718\n",
      "we F1:  0.9023921773886044\n",
      "29520 462\n",
      "Loss:  0.04639820754528046\n",
      "Loss:  0.0653403252363205\n",
      "Loss:  0.045011162757873535\n",
      "33 **********\n",
      "Epoch:  1956.1290302276611  fold:  4  kers:  64\n",
      "epoch:  34\n",
      "29520 462\n",
      "Loss:  0.06635284423828125\n",
      "Loss:  0.04536391422152519\n",
      "Loss:  0.07919974625110626\n",
      "34 **********\n",
      "Epoch:  1999.768347978592  fold:  4  kers:  64\n",
      "epoch:  35\n",
      "29520 462\n",
      "Loss:  0.07838302850723267\n",
      "Loss:  0.05472477898001671\n",
      "Loss:  0.05180063471198082\n",
      "35 **********\n",
      "Epoch:  2043.4236226081848  fold:  4  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.6492778658866882\n",
      "Eval Loss:  0.3221794664859772\n",
      "Eval Loss:  0.13646908104419708\n",
      "[[2713  424]\n",
      " [ 174   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      3137\n",
      "           1       0.12      0.26      0.17       234\n",
      "\n",
      "    accuracy                           0.82      3371\n",
      "   macro avg       0.53      0.56      0.53      3371\n",
      "weighted avg       0.88      0.82      0.85      3371\n",
      "\n",
      "acc:  0.8226045683773361\n",
      "pre:  0.12396694214876033\n",
      "rec:  0.2564102564102564\n",
      "ma F1:  0.5339306654533214\n",
      "mi F1:  0.8226045683773361\n",
      "we F1:  0.8498071600588301\n",
      "Eval Loss:  0.2580348551273346\n",
      "Eval Loss:  0.24036628007888794\n",
      "Eval Loss:  0.22531017661094666\n",
      "Eval Loss:  0.14750078320503235\n",
      "Eval Loss:  0.15860073268413544\n",
      "Eval Loss:  0.16029693186283112\n",
      "Eval Loss:  0.17631089687347412\n",
      "Eval Loss:  0.25036823749542236\n",
      "Eval Loss:  0.19830337166786194\n",
      "Eval Loss:  0.23690490424633026\n",
      "Eval Loss:  0.17104583978652954\n",
      "Eval Loss:  0.27792149782180786\n",
      "Eval Loss:  0.1898564249277115\n",
      "Eval Loss:  0.23044359683990479\n",
      "Eval Loss:  0.1883234679698944\n",
      "Eval Loss:  0.25079235434532166\n",
      "Eval Loss:  0.18644802272319794\n",
      "Eval Loss:  0.23473390936851501\n",
      "Eval Loss:  0.23563389480113983\n",
      "Eval Loss:  0.24423345923423767\n",
      "Eval Loss:  0.1982070654630661\n",
      "Eval Loss:  0.24364620447158813\n",
      "Eval Loss:  0.25614890456199646\n",
      "Eval Loss:  0.2205502688884735\n",
      "Eval Loss:  0.2853158712387085\n",
      "Eval Loss:  0.2710273563861847\n",
      "Eval Loss:  0.2508772313594818\n",
      "Eval Loss:  0.21267764270305634\n",
      "[[15615  1412]\n",
      " [ 1307 11186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     17027\n",
      "           1       0.89      0.90      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.91      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9078929539295393\n",
      "pre:  0.8879187172567075\n",
      "rec:  0.8953814135916113\n",
      "ma F1:  0.9057718631390199\n",
      "mi F1:  0.9078929539295393\n",
      "we F1:  0.9079432394416198\n",
      "29520 462\n",
      "Loss:  0.07333438843488693\n",
      "Loss:  0.060713011771440506\n",
      "Loss:  0.07091191411018372\n",
      "36 **********\n",
      "Epoch:  2127.7052705287933  fold:  4  kers:  64\n",
      "epoch:  37\n",
      "29520 462\n",
      "Loss:  0.05720347911119461\n",
      "Loss:  0.06415621191263199\n",
      "Loss:  0.07633329182863235\n",
      "37 **********\n",
      "Epoch:  2171.4961824417114  fold:  4  kers:  64\n",
      "epoch:  38\n",
      "29520 462\n",
      "Loss:  0.05259360745549202\n",
      "Loss:  0.05021330341696739\n",
      "Loss:  0.09314873814582825\n",
      "38 **********\n",
      "Epoch:  2215.3050470352173  fold:  4  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.20284593105316162\n",
      "Eval Loss:  0.2059238702058792\n",
      "Eval Loss:  0.0073965080082416534\n",
      "[[3035  102]\n",
      " [ 215   19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3137\n",
      "           1       0.16      0.08      0.11       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.55      0.52      0.53      3371\n",
      "weighted avg       0.88      0.91      0.89      3371\n",
      "\n",
      "acc:  0.9059626223672501\n",
      "pre:  0.15702479338842976\n",
      "rec:  0.0811965811965812\n",
      "ma F1:  0.5287050941944134\n",
      "mi F1:  0.9059626223672501\n",
      "we F1:  0.8918279735995012\n",
      "Eval Loss:  0.25529277324676514\n",
      "Eval Loss:  0.26800695061683655\n",
      "Eval Loss:  0.23957471549510956\n",
      "Eval Loss:  0.17963474988937378\n",
      "Eval Loss:  0.1687801331281662\n",
      "Eval Loss:  0.1573489010334015\n",
      "Eval Loss:  0.17218387126922607\n",
      "Eval Loss:  0.260985404253006\n",
      "Eval Loss:  0.24129138886928558\n",
      "Eval Loss:  0.2387402355670929\n",
      "Eval Loss:  0.22867318987846375\n",
      "Eval Loss:  0.28201568126678467\n",
      "Eval Loss:  0.22330516576766968\n",
      "Eval Loss:  0.25932127237319946\n",
      "Eval Loss:  0.22017675638198853\n",
      "Eval Loss:  0.24761930108070374\n",
      "Eval Loss:  0.1874917894601822\n",
      "Eval Loss:  0.22567853331565857\n",
      "Eval Loss:  0.2287251204252243\n",
      "Eval Loss:  0.2613619863986969\n",
      "Eval Loss:  0.18272903561592102\n",
      "Eval Loss:  0.25710293650627136\n",
      "Eval Loss:  0.24277903139591217\n",
      "Eval Loss:  0.23881711065769196\n",
      "Eval Loss:  0.2922496497631073\n",
      "Eval Loss:  0.2730180621147156\n",
      "Eval Loss:  0.31790077686309814\n",
      "Eval Loss:  0.243008553981781\n",
      "[[16366   661]\n",
      " [ 2232 10261]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17027\n",
      "           1       0.94      0.82      0.88     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.91      0.89      0.90     29520\n",
      "weighted avg       0.91      0.90      0.90     29520\n",
      "\n",
      "acc:  0.9019986449864499\n",
      "pre:  0.9394799487273393\n",
      "rec:  0.8213399503722084\n",
      "ma F1:  0.8976198523213864\n",
      "mi F1:  0.9019986449864499\n",
      "we F1:  0.9008718500189127\n",
      "29520 462\n",
      "Loss:  0.05751519650220871\n",
      "Loss:  0.0728166475892067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.050137922167778015\n",
      "39 **********\n",
      "Epoch:  2299.72332906723  fold:  4  kers:  64\n",
      "epoch:  40\n",
      "29520 462\n",
      "Loss:  0.07234103232622147\n",
      "Loss:  0.02839195728302002\n",
      "Loss:  0.06500238925218582\n",
      "40 **********\n",
      "Epoch:  2343.5092544555664  fold:  4  kers:  64\n",
      "epoch:  41\n",
      "29520 462\n",
      "Loss:  0.05819166824221611\n",
      "Loss:  0.07188442349433899\n",
      "Loss:  0.04222925007343292\n",
      "41 **********\n",
      "Epoch:  2387.4537556171417  fold:  4  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.34629058837890625\n",
      "Eval Loss:  0.19717703759670258\n",
      "Eval Loss:  0.00939076580107212\n",
      "[[2979  158]\n",
      " [ 218   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3137\n",
      "           1       0.09      0.07      0.08       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.51      0.51      0.51      3371\n",
      "weighted avg       0.87      0.89      0.88      3371\n",
      "\n",
      "acc:  0.8884603975081579\n",
      "pre:  0.09195402298850575\n",
      "rec:  0.06837606837606838\n",
      "ma F1:  0.5095346000730574\n",
      "mi F1:  0.8884603975081579\n",
      "we F1:  0.8807872460244908\n",
      "Eval Loss:  0.23360532522201538\n",
      "Eval Loss:  0.2465839833021164\n",
      "Eval Loss:  0.23387150466442108\n",
      "Eval Loss:  0.18022313714027405\n",
      "Eval Loss:  0.15841713547706604\n",
      "Eval Loss:  0.14062640070915222\n",
      "Eval Loss:  0.14926908910274506\n",
      "Eval Loss:  0.2529434859752655\n",
      "Eval Loss:  0.21041418612003326\n",
      "Eval Loss:  0.252543181180954\n",
      "Eval Loss:  0.20851437747478485\n",
      "Eval Loss:  0.26169997453689575\n",
      "Eval Loss:  0.18628744781017303\n",
      "Eval Loss:  0.24029922485351562\n",
      "Eval Loss:  0.17770300805568695\n",
      "Eval Loss:  0.24587523937225342\n",
      "Eval Loss:  0.17320406436920166\n",
      "Eval Loss:  0.2230411320924759\n",
      "Eval Loss:  0.2155803143978119\n",
      "Eval Loss:  0.22062599658966064\n",
      "Eval Loss:  0.1506534069776535\n",
      "Eval Loss:  0.24479377269744873\n",
      "Eval Loss:  0.2360961139202118\n",
      "Eval Loss:  0.2161622941493988\n",
      "Eval Loss:  0.27522704005241394\n",
      "Eval Loss:  0.26691290736198425\n",
      "Eval Loss:  0.29072651267051697\n",
      "Eval Loss:  0.19454745948314667\n",
      "[[16221   806]\n",
      " [ 1887 10606]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17027\n",
      "           1       0.93      0.85      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9087737127371274\n",
      "pre:  0.929372590255871\n",
      "rec:  0.8489554150324181\n",
      "ma F1:  0.9053492628471882\n",
      "mi F1:  0.9087737127371274\n",
      "we F1:  0.9081144375223413\n",
      "29520 462\n",
      "Loss:  0.08322571963071823\n",
      "Loss:  0.03531912714242935\n",
      "Loss:  0.03907604143023491\n",
      "42 **********\n",
      "Epoch:  2471.884006500244  fold:  4  kers:  64\n",
      "epoch:  43\n",
      "29520 462\n",
      "Loss:  0.0658595860004425\n",
      "Loss:  0.05319693312048912\n",
      "Loss:  0.04389582574367523\n",
      "43 **********\n",
      "Epoch:  2515.644998550415  fold:  4  kers:  64\n",
      "epoch:  44\n",
      "29520 462\n",
      "Loss:  0.05762355029582977\n",
      "Loss:  0.059265121817588806\n",
      "Loss:  0.06548447906970978\n",
      "44 **********\n",
      "Epoch:  2559.3272013664246  fold:  4  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.5490902662277222\n",
      "Eval Loss:  0.19056183099746704\n",
      "Eval Loss:  0.016170870512723923\n",
      "[[2872  265]\n",
      " [ 206   28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      3137\n",
      "           1       0.10      0.12      0.11       234\n",
      "\n",
      "    accuracy                           0.86      3371\n",
      "   macro avg       0.51      0.52      0.52      3371\n",
      "weighted avg       0.87      0.86      0.87      3371\n",
      "\n",
      "acc:  0.8602788490062296\n",
      "pre:  0.09556313993174062\n",
      "rec:  0.11965811965811966\n",
      "ma F1:  0.5152387334919953\n",
      "mi F1:  0.8602788490062296\n",
      "we F1:  0.8674368542155615\n",
      "Eval Loss:  0.24766361713409424\n",
      "Eval Loss:  0.25441303849220276\n",
      "Eval Loss:  0.23228943347930908\n",
      "Eval Loss:  0.18286557495594025\n",
      "Eval Loss:  0.15869878232479095\n",
      "Eval Loss:  0.14853651821613312\n",
      "Eval Loss:  0.1586180329322815\n",
      "Eval Loss:  0.23052911460399628\n",
      "Eval Loss:  0.2189219444990158\n",
      "Eval Loss:  0.21861444413661957\n",
      "Eval Loss:  0.20486867427825928\n",
      "Eval Loss:  0.26827293634414673\n",
      "Eval Loss:  0.17002223432064056\n",
      "Eval Loss:  0.250211238861084\n",
      "Eval Loss:  0.18961259722709656\n",
      "Eval Loss:  0.23768064379692078\n",
      "Eval Loss:  0.1771327406167984\n",
      "Eval Loss:  0.21472544968128204\n",
      "Eval Loss:  0.21288545429706573\n",
      "Eval Loss:  0.23813606798648834\n",
      "Eval Loss:  0.1559673249721527\n",
      "Eval Loss:  0.2061137557029724\n",
      "Eval Loss:  0.21894684433937073\n",
      "Eval Loss:  0.23692753911018372\n",
      "Eval Loss:  0.2789914906024933\n",
      "Eval Loss:  0.2459067404270172\n",
      "Eval Loss:  0.2869322597980499\n",
      "Eval Loss:  0.17679652571678162\n",
      "[[16263   764]\n",
      " [ 1878 10615]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.92     17027\n",
      "           1       0.93      0.85      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.90      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9105013550135501\n",
      "pre:  0.9328587749362861\n",
      "rec:  0.8496758184583366\n",
      "ma F1:  0.9071006468834695\n",
      "mi F1:  0.9105013550135501\n",
      "we F1:  0.9098306062782615\n",
      "29520 462\n",
      "Loss:  0.0380302332341671\n",
      "Loss:  0.0707918331027031\n",
      "Loss:  0.0648656040430069\n",
      "45 **********\n",
      "Epoch:  2643.7075850963593  fold:  4  kers:  64\n",
      "epoch:  46\n",
      "29520 462\n",
      "Loss:  0.08693720400333405\n",
      "Loss:  0.02870403230190277\n",
      "Loss:  0.06274927407503128\n",
      "46 **********\n",
      "Epoch:  2687.4586050510406  fold:  4  kers:  64\n",
      "epoch:  47\n",
      "29520 462\n",
      "Loss:  0.03734374791383743\n",
      "Loss:  0.05499260500073433\n",
      "Loss:  0.04738261550664902\n",
      "47 **********\n",
      "Epoch:  2731.3630867004395  fold:  4  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.7186821103096008\n",
      "Eval Loss:  0.48952746391296387\n",
      "Eval Loss:  0.02127820998430252\n",
      "[[2580  557]\n",
      " [ 196   38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      3137\n",
      "           1       0.06      0.16      0.09       234\n",
      "\n",
      "    accuracy                           0.78      3371\n",
      "   macro avg       0.50      0.49      0.48      3371\n",
      "weighted avg       0.87      0.78      0.82      3371\n",
      "\n",
      "acc:  0.776624147137348\n",
      "pre:  0.06386554621848739\n",
      "rec:  0.1623931623931624\n",
      "ma F1:  0.4821650971658407\n",
      "mi F1:  0.776624147137348\n",
      "we F1:  0.8184415023850719\n",
      "Eval Loss:  0.24601833522319794\n",
      "Eval Loss:  0.23370231688022614\n",
      "Eval Loss:  0.22256773710250854\n",
      "Eval Loss:  0.1728600114583969\n",
      "Eval Loss:  0.1626429557800293\n",
      "Eval Loss:  0.15247054398059845\n",
      "Eval Loss:  0.17938056588172913\n",
      "Eval Loss:  0.2313927859067917\n",
      "Eval Loss:  0.18317997455596924\n",
      "Eval Loss:  0.1988295316696167\n",
      "Eval Loss:  0.18018585443496704\n",
      "Eval Loss:  0.2548117935657501\n",
      "Eval Loss:  0.14870360493659973\n",
      "Eval Loss:  0.25128471851348877\n",
      "Eval Loss:  0.19451671838760376\n",
      "Eval Loss:  0.2412092238664627\n",
      "Eval Loss:  0.18317468464374542\n",
      "Eval Loss:  0.22418899834156036\n",
      "Eval Loss:  0.20877805352210999\n",
      "Eval Loss:  0.21574999392032623\n",
      "Eval Loss:  0.15513743460178375\n",
      "Eval Loss:  0.23338596522808075\n",
      "Eval Loss:  0.23217937350273132\n",
      "Eval Loss:  0.23039036989212036\n",
      "Eval Loss:  0.2867995798587799\n",
      "Eval Loss:  0.2693115770816803\n",
      "Eval Loss:  0.28477978706359863\n",
      "Eval Loss:  0.18524977564811707\n",
      "[[15979  1048]\n",
      " [ 1579 10914]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     17027\n",
      "           1       0.91      0.87      0.89     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.91      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9110094850948509\n",
      "pre:  0.9123892325698044\n",
      "rec:  0.8736092211638518\n",
      "ma F1:  0.9083102098495504\n",
      "mi F1:  0.9110094850948509\n",
      "we F1:  0.9107265008588676\n",
      "29520 462\n",
      "Loss:  0.059993892908096313\n",
      "Loss:  0.05666285753250122\n",
      "Loss:  0.05377575382590294\n",
      "48 **********\n",
      "Epoch:  2815.7833638191223  fold:  4  kers:  64\n",
      "epoch:  49\n",
      "29520 462\n",
      "Loss:  0.0571986623108387\n",
      "Loss:  0.050482191145420074\n",
      "Loss:  0.05391612648963928\n",
      "49 **********\n",
      "Epoch:  2859.67400932312  fold:  4  kers:  64\n",
      "epoch:  50\n",
      "29520 462\n",
      "Loss:  0.04526703059673309\n",
      "Loss:  0.05632121488451958\n",
      "Loss:  0.0655004233121872\n",
      "50 **********\n",
      "Epoch:  2903.375160932541  fold:  4  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.5764607787132263\n",
      "Eval Loss:  0.4057605564594269\n",
      "Eval Loss:  0.03350568190217018\n",
      "[[2689  448]\n",
      " [ 171   63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      3137\n",
      "           1       0.12      0.27      0.17       234\n",
      "\n",
      "    accuracy                           0.82      3371\n",
      "   macro avg       0.53      0.56      0.53      3371\n",
      "weighted avg       0.88      0.82      0.85      3371\n",
      "\n",
      "acc:  0.8163749629190151\n",
      "pre:  0.1232876712328767\n",
      "rec:  0.2692307692307692\n",
      "ma F1:  0.5329546204869773\n",
      "mi F1:  0.8163749629190151\n",
      "we F1:  0.8462711681184342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24733757972717285\n",
      "Eval Loss:  0.22159342467784882\n",
      "Eval Loss:  0.2091800570487976\n",
      "Eval Loss:  0.1321888417005539\n",
      "Eval Loss:  0.15566317737102509\n",
      "Eval Loss:  0.1439763605594635\n",
      "Eval Loss:  0.18123528361320496\n",
      "Eval Loss:  0.19829000532627106\n",
      "Eval Loss:  0.20360299944877625\n",
      "Eval Loss:  0.21363230049610138\n",
      "Eval Loss:  0.19058731198310852\n",
      "Eval Loss:  0.2502875030040741\n",
      "Eval Loss:  0.18486908078193665\n",
      "Eval Loss:  0.22040370106697083\n",
      "Eval Loss:  0.15038181841373444\n",
      "Eval Loss:  0.21176482737064362\n",
      "Eval Loss:  0.1871621310710907\n",
      "Eval Loss:  0.197956383228302\n",
      "Eval Loss:  0.22321000695228577\n",
      "Eval Loss:  0.22124561667442322\n",
      "Eval Loss:  0.1584094762802124\n",
      "Eval Loss:  0.215431809425354\n",
      "Eval Loss:  0.23326469957828522\n",
      "Eval Loss:  0.22400212287902832\n",
      "Eval Loss:  0.2429022341966629\n",
      "Eval Loss:  0.25798261165618896\n",
      "Eval Loss:  0.2594677805900574\n",
      "Eval Loss:  0.18497656285762787\n",
      "[[15791  1236]\n",
      " [ 1276 11217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17027\n",
      "           1       0.90      0.90      0.90     12493\n",
      "\n",
      "    accuracy                           0.91     29520\n",
      "   macro avg       0.91      0.91      0.91     29520\n",
      "weighted avg       0.91      0.91      0.91     29520\n",
      "\n",
      "acc:  0.9149051490514906\n",
      "pre:  0.9007468079980727\n",
      "rec:  0.8978628031697751\n",
      "ma F1:  0.912811920125132\n",
      "mi F1:  0.9149051490514905\n",
      "we F1:  0.914886843595204\n",
      "29520 462\n",
      "Loss:  0.043894946575164795\n",
      "Loss:  0.03992827236652374\n",
      "Loss:  0.03949538618326187\n",
      "51 **********\n",
      "Epoch:  2987.6707725524902  fold:  4  kers:  64\n",
      "epoch:  52\n",
      "29520 462\n",
      "Loss:  0.055111199617385864\n",
      "Loss:  0.053152136504650116\n",
      "Loss:  0.05146028846502304\n",
      "52 **********\n",
      "Epoch:  3031.4038383960724  fold:  4  kers:  64\n",
      "epoch:  53\n",
      "29520 462\n",
      "Loss:  0.057133376598358154\n",
      "Loss:  0.04229135066270828\n",
      "Loss:  0.06373831629753113\n",
      "53 **********\n",
      "Epoch:  3075.2176892757416  fold:  4  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.7982116341590881\n",
      "Eval Loss:  0.4599889814853668\n",
      "Eval Loss:  0.018653545528650284\n",
      "[[2509  628]\n",
      " [ 186   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      3137\n",
      "           1       0.07      0.21      0.11       234\n",
      "\n",
      "    accuracy                           0.76      3371\n",
      "   macro avg       0.50      0.50      0.48      3371\n",
      "weighted avg       0.87      0.76      0.81      3371\n",
      "\n",
      "acc:  0.7585286265203204\n",
      "pre:  0.07100591715976332\n",
      "rec:  0.20512820512820512\n",
      "ma F1:  0.48295987277468766\n",
      "mi F1:  0.7585286265203204\n",
      "we F1:  0.8080212673799587\n",
      "Eval Loss:  0.24218006432056427\n",
      "Eval Loss:  0.19920864701271057\n",
      "Eval Loss:  0.21592888236045837\n",
      "Eval Loss:  0.13899464905261993\n",
      "Eval Loss:  0.12627950310707092\n",
      "Eval Loss:  0.14296698570251465\n",
      "Eval Loss:  0.1688501238822937\n",
      "Eval Loss:  0.19309169054031372\n",
      "Eval Loss:  0.17189377546310425\n",
      "Eval Loss:  0.1800173968076706\n",
      "Eval Loss:  0.1598825752735138\n",
      "Eval Loss:  0.22665496170520782\n",
      "Eval Loss:  0.17937622964382172\n",
      "Eval Loss:  0.21939720213413239\n",
      "Eval Loss:  0.14706557989120483\n",
      "Eval Loss:  0.20273913443088531\n",
      "Eval Loss:  0.16321653127670288\n",
      "Eval Loss:  0.20614977180957794\n",
      "Eval Loss:  0.20382854342460632\n",
      "Eval Loss:  0.19873324036598206\n",
      "Eval Loss:  0.16326355934143066\n",
      "Eval Loss:  0.20237797498703003\n",
      "Eval Loss:  0.2225453406572342\n",
      "Eval Loss:  0.23034246265888214\n",
      "Eval Loss:  0.23397502303123474\n",
      "Eval Loss:  0.24731148779392242\n",
      "Eval Loss:  0.2353997677564621\n",
      "Eval Loss:  0.1783725768327713\n",
      "[[15766  1261]\n",
      " [ 1112 11381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     17027\n",
      "           1       0.90      0.91      0.91     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.92      0.92      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9196138211382113\n",
      "pre:  0.9002531245056162\n",
      "rec:  0.9109901544865124\n",
      "ma F1:  0.9178000689801104\n",
      "mi F1:  0.9196138211382113\n",
      "we F1:  0.9196754514852028\n",
      "29520 462\n",
      "Loss:  0.06288651376962662\n",
      "Loss:  0.040856294333934784\n",
      "Loss:  0.06839548796415329\n",
      "54 **********\n",
      "Epoch:  3159.8344416618347  fold:  4  kers:  64\n",
      "epoch:  55\n",
      "29520 462\n",
      "Loss:  0.059140197932720184\n",
      "Loss:  0.05955401808023453\n",
      "Loss:  0.04838218539953232\n",
      "55 **********\n",
      "Epoch:  3203.62535405159  fold:  4  kers:  64\n",
      "epoch:  56\n",
      "29520 462\n",
      "Loss:  0.039918579161167145\n",
      "Loss:  0.052621178328990936\n",
      "Loss:  0.05693277716636658\n",
      "56 **********\n",
      "Epoch:  3247.4611451625824  fold:  4  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.6571381092071533\n",
      "Eval Loss:  0.48883792757987976\n",
      "Eval Loss:  0.11048383265733719\n",
      "[[2244  893]\n",
      " [ 104  130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.72      0.82      3137\n",
      "           1       0.13      0.56      0.21       234\n",
      "\n",
      "    accuracy                           0.70      3371\n",
      "   macro avg       0.54      0.64      0.51      3371\n",
      "weighted avg       0.90      0.70      0.78      3371\n",
      "\n",
      "acc:  0.7042420646692377\n",
      "pre:  0.1270772238514174\n",
      "rec:  0.5555555555555556\n",
      "ma F1:  0.5125366135602341\n",
      "mi F1:  0.7042420646692377\n",
      "we F1:  0.7757915447662118\n",
      "Eval Loss:  0.26547202467918396\n",
      "Eval Loss:  0.213362455368042\n",
      "Eval Loss:  0.19915969669818878\n",
      "Eval Loss:  0.14861640334129333\n",
      "Eval Loss:  0.13236889243125916\n",
      "Eval Loss:  0.13854189217090607\n",
      "Eval Loss:  0.17488513886928558\n",
      "Eval Loss:  0.192010760307312\n",
      "Eval Loss:  0.18851570785045624\n",
      "Eval Loss:  0.1828918755054474\n",
      "Eval Loss:  0.1878046691417694\n",
      "Eval Loss:  0.22064203023910522\n",
      "Eval Loss:  0.17999690771102905\n",
      "Eval Loss:  0.21962082386016846\n",
      "Eval Loss:  0.16429129242897034\n",
      "Eval Loss:  0.22391733527183533\n",
      "Eval Loss:  0.1821427345275879\n",
      "Eval Loss:  0.20320110023021698\n",
      "Eval Loss:  0.2318446785211563\n",
      "Eval Loss:  0.1967991292476654\n",
      "Eval Loss:  0.1674497276544571\n",
      "Eval Loss:  0.22106939554214478\n",
      "Eval Loss:  0.20281952619552612\n",
      "Eval Loss:  0.2317621409893036\n",
      "Eval Loss:  0.2484489381313324\n",
      "Eval Loss:  0.2612878978252411\n",
      "Eval Loss:  0.26275303959846497\n",
      "Eval Loss:  0.20541591942310333\n",
      "[[15681  1346]\n",
      " [ 1109 11384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     17027\n",
      "           1       0.89      0.91      0.90     12493\n",
      "\n",
      "    accuracy                           0.92     29520\n",
      "   macro avg       0.91      0.92      0.92     29520\n",
      "weighted avg       0.92      0.92      0.92     29520\n",
      "\n",
      "acc:  0.9168360433604336\n",
      "pre:  0.8942655145326002\n",
      "rec:  0.9112302889618186\n",
      "ma F1:  0.9150357883293876\n",
      "mi F1:  0.9168360433604336\n",
      "we F1:  0.9169353359930512\n",
      "29520 462\n",
      "Loss:  0.052402231842279434\n",
      "Loss:  0.053010329604148865\n",
      "Loss:  0.0818604901432991\n",
      "57 **********\n",
      "Epoch:  3331.793657541275  fold:  4  kers:  64\n",
      "epoch:  58\n",
      "29520 462\n",
      "Loss:  0.04283900558948517\n",
      "Loss:  0.03000238910317421\n",
      "Loss:  0.049896448850631714\n",
      "58 **********\n",
      "Epoch:  3375.469876050949  fold:  4  kers:  64\n",
      "epoch:  59\n",
      "29520 462\n",
      "Loss:  0.043115198612213135\n",
      "Loss:  0.05777115747332573\n",
      "Loss:  0.06268163025379181\n",
      "59 **********\n",
      "Epoch:  3419.241838693619  fold:  4  kers:  64\n",
      "Eval Loss:  0.9838932156562805\n",
      "Eval Loss:  0.5388416647911072\n",
      "Eval Loss:  0.024028748273849487\n",
      "[[2367  770]\n",
      " [ 153   81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.84      3137\n",
      "           1       0.10      0.35      0.15       234\n",
      "\n",
      "    accuracy                           0.73      3371\n",
      "   macro avg       0.52      0.55      0.49      3371\n",
      "weighted avg       0.88      0.73      0.79      3371\n",
      "\n",
      "acc:  0.7261940077128448\n",
      "pre:  0.09518213866039953\n",
      "rec:  0.34615384615384615\n",
      "ma F1:  0.49307403494223134\n",
      "mi F1:  0.7261940077128448\n",
      "we F1:  0.7891139653679056\n",
      "update!  Acc:  0.9231681993473747\n",
      "Epoch:  3423.3827669620514  fold:  4  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29673 3218\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29673 464\n",
      "Loss:  0.17216897010803223\n",
      "Loss:  0.16597811877727509\n",
      "Loss:  0.15697763860225677\n",
      "0 **********\n",
      "Epoch:  56.8819100856781  fold:  5  kers:  64\n",
      "epoch:  1\n",
      "29673 464\n",
      "Loss:  0.14137254655361176\n",
      "Loss:  0.14431317150592804\n",
      "Loss:  0.12834222614765167\n",
      "1 **********\n",
      "Epoch:  101.04981327056885  fold:  5  kers:  64\n",
      "epoch:  2\n",
      "29673 464\n",
      "Loss:  0.1195196732878685\n",
      "Loss:  0.12537026405334473\n",
      "Loss:  0.10794138163328171\n",
      "2 **********\n",
      "Epoch:  145.15089583396912  fold:  5  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.1788640022277832\n",
      "Eval Loss:  0.37000572681427\n",
      "Eval Loss:  0.29124587774276733\n",
      "[[2742  355]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.93      3097\n",
      "           1       0.20      0.73      0.31       121\n",
      "\n",
      "    accuracy                           0.88      3218\n",
      "   macro avg       0.59      0.81      0.62      3218\n",
      "weighted avg       0.96      0.88      0.91      3218\n",
      "\n",
      "acc:  0.8794282162834058\n",
      "pre:  0.1986455981941309\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.6229902216553618\n",
      "mi F1:  0.879428216283406\n",
      "we F1:  0.9105408893317218\n",
      "update!  Acc:  0.8794282162834058\n",
      "Eval Loss:  0.4211117625236511\n",
      "Eval Loss:  0.5103436708450317\n",
      "Eval Loss:  0.47234970331192017\n",
      "Eval Loss:  0.40357375144958496\n",
      "Eval Loss:  0.42433130741119385\n",
      "Eval Loss:  0.33281612396240234\n",
      "Eval Loss:  0.37291035056114197\n",
      "Eval Loss:  0.41203927993774414\n",
      "Eval Loss:  0.3210861086845398\n",
      "Eval Loss:  0.43871060013771057\n",
      "Eval Loss:  0.43875595927238464\n",
      "Eval Loss:  0.41344523429870605\n",
      "Eval Loss:  0.4314071834087372\n",
      "Eval Loss:  0.39576008915901184\n",
      "Eval Loss:  0.4194891154766083\n",
      "Eval Loss:  0.37727639079093933\n",
      "Eval Loss:  0.4750117361545563\n",
      "Eval Loss:  0.3643542528152466\n",
      "Eval Loss:  0.4186115264892578\n",
      "Eval Loss:  0.40284493565559387\n",
      "Eval Loss:  0.42508208751678467\n",
      "Eval Loss:  0.45024603605270386\n",
      "Eval Loss:  0.42532655596733093\n",
      "Eval Loss:  0.41263261437416077\n",
      "Eval Loss:  0.3778976798057556\n",
      "Eval Loss:  0.5085198879241943\n",
      "Eval Loss:  0.49672406911849976\n",
      "Eval Loss:  0.38097521662712097\n",
      "Eval Loss:  0.4489332437515259\n",
      "[[14219  2848]\n",
      " [ 2652  9954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84     17067\n",
      "           1       0.78      0.79      0.78     12606\n",
      "\n",
      "    accuracy                           0.81     29673\n",
      "   macro avg       0.81      0.81      0.81     29673\n",
      "weighted avg       0.82      0.81      0.81     29673\n",
      "\n",
      "acc:  0.814646311461598\n",
      "pre:  0.7775347601937197\n",
      "rec:  0.7896239885768681\n",
      "ma F1:  0.8107362590591556\n",
      "mi F1:  0.814646311461598\n",
      "we F1:  0.8148259996845475\n",
      "29673 464\n",
      "Loss:  0.09460625052452087\n",
      "Loss:  0.11774170398712158\n",
      "Loss:  0.09927578270435333\n",
      "3 **********\n",
      "Epoch:  230.39197826385498  fold:  5  kers:  64\n",
      "epoch:  4\n",
      "29673 464\n",
      "Loss:  0.16192090511322021\n",
      "Loss:  0.08131085336208344\n",
      "Loss:  0.11447419226169586\n",
      "4 **********\n",
      "Epoch:  274.6516375541687  fold:  5  kers:  64\n",
      "epoch:  5\n",
      "29673 464\n",
      "Loss:  0.11884329468011856\n",
      "Loss:  0.14327436685562134\n",
      "Loss:  0.07365025579929352\n",
      "5 **********\n",
      "Epoch:  318.96016550064087  fold:  5  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.12339145690202713\n",
      "Eval Loss:  0.3226820230484009\n",
      "Eval Loss:  0.14706675708293915\n",
      "[[2950  147]\n",
      " [  38   83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      3097\n",
      "           1       0.36      0.69      0.47       121\n",
      "\n",
      "    accuracy                           0.94      3218\n",
      "   macro avg       0.67      0.82      0.72      3218\n",
      "weighted avg       0.96      0.94      0.95      3218\n",
      "\n",
      "acc:  0.9425108763206961\n",
      "pre:  0.36086956521739133\n",
      "rec:  0.6859504132231405\n",
      "ma F1:  0.7212659217589374\n",
      "mi F1:  0.9425108763206961\n",
      "we F1:  0.9509223517470063\n",
      "update!  Acc:  0.9425108763206961\n",
      "Eval Loss:  0.40871626138687134\n",
      "Eval Loss:  0.46631142497062683\n",
      "Eval Loss:  0.3953286111354828\n",
      "Eval Loss:  0.3488479554653168\n",
      "Eval Loss:  0.36905497312545776\n",
      "Eval Loss:  0.2750447690486908\n",
      "Eval Loss:  0.2917008101940155\n",
      "Eval Loss:  0.43767550587654114\n",
      "Eval Loss:  0.27488502860069275\n",
      "Eval Loss:  0.38277721405029297\n",
      "Eval Loss:  0.390793114900589\n",
      "Eval Loss:  0.3306065797805786\n",
      "Eval Loss:  0.346185564994812\n",
      "Eval Loss:  0.3899153470993042\n",
      "Eval Loss:  0.32729998230934143\n",
      "Eval Loss:  0.3288746178150177\n",
      "Eval Loss:  0.44585052132606506\n",
      "Eval Loss:  0.3332785665988922\n",
      "Eval Loss:  0.3817594051361084\n",
      "Eval Loss:  0.3579418957233429\n",
      "Eval Loss:  0.38323211669921875\n",
      "Eval Loss:  0.42694035172462463\n",
      "Eval Loss:  0.36732596158981323\n",
      "Eval Loss:  0.4337855279445648\n",
      "Eval Loss:  0.3216562569141388\n",
      "Eval Loss:  0.41540244221687317\n",
      "Eval Loss:  0.4828537702560425\n",
      "Eval Loss:  0.33399173617362976\n",
      "Eval Loss:  0.40394940972328186\n",
      "[[15709  1358]\n",
      " [ 3273  9333]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87     17067\n",
      "           1       0.87      0.74      0.80     12606\n",
      "\n",
      "    accuracy                           0.84     29673\n",
      "   macro avg       0.85      0.83      0.84     29673\n",
      "weighted avg       0.85      0.84      0.84     29673\n",
      "\n",
      "acc:  0.8439321942506656\n",
      "pre:  0.8729772706014405\n",
      "rec:  0.7403617325083294\n",
      "ma F1:  0.8363775030074323\n",
      "mi F1:  0.8439321942506656\n",
      "we F1:  0.8416631801774549\n",
      "29673 464\n",
      "Loss:  0.07969827204942703\n",
      "Loss:  0.05174964666366577\n",
      "Loss:  0.08372385799884796\n",
      "6 **********\n",
      "Epoch:  404.10749864578247  fold:  5  kers:  64\n",
      "epoch:  7\n",
      "29673 464\n",
      "Loss:  0.08884464204311371\n",
      "Loss:  0.11635184288024902\n",
      "Loss:  0.08654634654521942\n",
      "7 **********\n",
      "Epoch:  448.24847412109375  fold:  5  kers:  64\n",
      "epoch:  8\n",
      "29673 464\n",
      "Loss:  0.10649528354406357\n",
      "Loss:  0.11506585776805878\n",
      "Loss:  0.08726407587528229\n",
      "8 **********\n",
      "Epoch:  492.44230914115906  fold:  5  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.10437534004449844\n",
      "Eval Loss:  0.2891460061073303\n",
      "Eval Loss:  0.09671016782522202\n",
      "[[2986  111]\n",
      " [  34   87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      3097\n",
      "           1       0.44      0.72      0.55       121\n",
      "\n",
      "    accuracy                           0.95      3218\n",
      "   macro avg       0.71      0.84      0.76      3218\n",
      "weighted avg       0.97      0.95      0.96      3218\n",
      "\n",
      "acc:  0.9549409571162213\n",
      "pre:  0.4393939393939394\n",
      "rec:  0.71900826446281\n",
      "ma F1:  0.7608750575891331\n",
      "mi F1:  0.9549409571162213\n",
      "we F1:  0.9600955187801005\n",
      "update!  Acc:  0.9549409571162213\n",
      "Eval Loss:  0.3656245172023773\n",
      "Eval Loss:  0.41859865188598633\n",
      "Eval Loss:  0.3404293656349182\n",
      "Eval Loss:  0.31909361481666565\n",
      "Eval Loss:  0.3260228931903839\n",
      "Eval Loss:  0.2687269151210785\n",
      "Eval Loss:  0.2638644576072693\n",
      "Eval Loss:  0.33462175726890564\n",
      "Eval Loss:  0.2562871277332306\n",
      "Eval Loss:  0.35485076904296875\n",
      "Eval Loss:  0.37029990553855896\n",
      "Eval Loss:  0.2836235463619232\n",
      "Eval Loss:  0.32801148295402527\n",
      "Eval Loss:  0.3608914315700531\n",
      "Eval Loss:  0.2972928285598755\n",
      "Eval Loss:  0.3156247138977051\n",
      "Eval Loss:  0.4069388508796692\n",
      "Eval Loss:  0.3520614206790924\n",
      "Eval Loss:  0.3397621214389801\n",
      "Eval Loss:  0.3326982259750366\n",
      "Eval Loss:  0.331708163022995\n",
      "Eval Loss:  0.37655705213546753\n",
      "Eval Loss:  0.3162803053855896\n",
      "Eval Loss:  0.3873429596424103\n",
      "Eval Loss:  0.3000525236129761\n",
      "Eval Loss:  0.39986303448677063\n",
      "Eval Loss:  0.434591144323349\n",
      "Eval Loss:  0.3243928849697113\n",
      "Eval Loss:  0.3518470525741577\n",
      "[[15924  1143]\n",
      " [ 3185  9421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88     17067\n",
      "           1       0.89      0.75      0.81     12606\n",
      "\n",
      "    accuracy                           0.85     29673\n",
      "   macro avg       0.86      0.84      0.85     29673\n",
      "weighted avg       0.86      0.85      0.85     29673\n",
      "\n",
      "acc:  0.8541434974555994\n",
      "pre:  0.8918023475956077\n",
      "rec:  0.7473425353006505\n",
      "ma F1:  0.8467847021142691\n",
      "mi F1:  0.8541434974555994\n",
      "we F1:  0.8518327700856169\n",
      "29673 464\n",
      "Loss:  0.06953216344118118\n",
      "Loss:  0.06316324323415756\n",
      "Loss:  0.08875007927417755\n",
      "9 **********\n",
      "Epoch:  577.5746827125549  fold:  5  kers:  64\n",
      "epoch:  10\n",
      "29673 464\n",
      "Loss:  0.05550131946802139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08900798857212067\n",
      "Loss:  0.09476111084222794\n",
      "10 **********\n",
      "Epoch:  621.7565491199493  fold:  5  kers:  64\n",
      "epoch:  11\n",
      "29673 464\n",
      "Loss:  0.0783526673913002\n",
      "Loss:  0.10099383443593979\n",
      "Loss:  0.1055571660399437\n",
      "11 **********\n",
      "Epoch:  665.878576040268  fold:  5  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.09899690747261047\n",
      "Eval Loss:  0.28617241978645325\n",
      "Eval Loss:  0.05584665387868881\n",
      "[[3007   90]\n",
      " [  27   94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.51      0.78      0.62       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.75      0.87      0.80      3218\n",
      "weighted avg       0.97      0.96      0.97      3218\n",
      "\n",
      "acc:  0.9636420136730889\n",
      "pre:  0.5108695652173914\n",
      "rec:  0.7768595041322314\n",
      "ma F1:  0.7986550478487451\n",
      "mi F1:  0.9636420136730889\n",
      "we F1:  0.9672102178773229\n",
      "update!  Acc:  0.9636420136730889\n",
      "Eval Loss:  0.29521453380584717\n",
      "Eval Loss:  0.3772188723087311\n",
      "Eval Loss:  0.2716154456138611\n",
      "Eval Loss:  0.30100247263908386\n",
      "Eval Loss:  0.322665810585022\n",
      "Eval Loss:  0.24940955638885498\n",
      "Eval Loss:  0.24821607768535614\n",
      "Eval Loss:  0.27913764119148254\n",
      "Eval Loss:  0.22669704258441925\n",
      "Eval Loss:  0.2956550717353821\n",
      "Eval Loss:  0.30917325615882874\n",
      "Eval Loss:  0.26187771558761597\n",
      "Eval Loss:  0.3163525462150574\n",
      "Eval Loss:  0.3301130533218384\n",
      "Eval Loss:  0.2652052044868469\n",
      "Eval Loss:  0.3010450303554535\n",
      "Eval Loss:  0.3631194531917572\n",
      "Eval Loss:  0.3481590151786804\n",
      "Eval Loss:  0.3106288015842438\n",
      "Eval Loss:  0.3030236065387726\n",
      "Eval Loss:  0.2974225878715515\n",
      "Eval Loss:  0.35898998379707336\n",
      "Eval Loss:  0.2903851270675659\n",
      "Eval Loss:  0.3292859196662903\n",
      "Eval Loss:  0.2748851776123047\n",
      "Eval Loss:  0.3350565731525421\n",
      "Eval Loss:  0.4018059968948364\n",
      "Eval Loss:  0.28693029284477234\n",
      "Eval Loss:  0.31653234362602234\n",
      "[[15861  1206]\n",
      " [ 2745  9861]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     17067\n",
      "           1       0.89      0.78      0.83     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.87      0.86      0.86     29673\n",
      "weighted avg       0.87      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8668486502881407\n",
      "pre:  0.8910273786934129\n",
      "rec:  0.7822465492622561\n",
      "ma F1:  0.8611724835826322\n",
      "mi F1:  0.8668486502881407\n",
      "we F1:  0.8653927135281778\n",
      "29673 464\n",
      "Loss:  0.09964539110660553\n",
      "Loss:  0.0644216537475586\n",
      "Loss:  0.07234930247068405\n",
      "12 **********\n",
      "Epoch:  751.071786403656  fold:  5  kers:  64\n",
      "epoch:  13\n",
      "29673 464\n",
      "Loss:  0.07190728187561035\n",
      "Loss:  0.11820679903030396\n",
      "Loss:  0.10672686249017715\n",
      "13 **********\n",
      "Epoch:  795.2913644313812  fold:  5  kers:  64\n",
      "epoch:  14\n",
      "29673 464\n",
      "Loss:  0.07612890005111694\n",
      "Loss:  0.0911419466137886\n",
      "Loss:  0.08979877829551697\n",
      "14 **********\n",
      "Epoch:  839.4413163661957  fold:  5  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.08183172345161438\n",
      "Eval Loss:  0.177889883518219\n",
      "Eval Loss:  0.05033939331769943\n",
      "[[3036   61]\n",
      " [  41   80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.57      0.66      0.61       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.82      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9683032939714108\n",
      "pre:  0.5673758865248227\n",
      "rec:  0.6611570247933884\n",
      "ma F1:  0.7970830644144244\n",
      "mi F1:  0.9683032939714108\n",
      "we F1:  0.9694617528994012\n",
      "update!  Acc:  0.9683032939714108\n",
      "Eval Loss:  0.28370070457458496\n",
      "Eval Loss:  0.4170588254928589\n",
      "Eval Loss:  0.2867102026939392\n",
      "Eval Loss:  0.2855845093727112\n",
      "Eval Loss:  0.3407473862171173\n",
      "Eval Loss:  0.2572510838508606\n",
      "Eval Loss:  0.2287665754556656\n",
      "Eval Loss:  0.30671578645706177\n",
      "Eval Loss:  0.2121054083108902\n",
      "Eval Loss:  0.3082408607006073\n",
      "Eval Loss:  0.33000123500823975\n",
      "Eval Loss:  0.26185929775238037\n",
      "Eval Loss:  0.31673991680145264\n",
      "Eval Loss:  0.3188401460647583\n",
      "Eval Loss:  0.2546008825302124\n",
      "Eval Loss:  0.2613776922225952\n",
      "Eval Loss:  0.33786922693252563\n",
      "Eval Loss:  0.34058985114097595\n",
      "Eval Loss:  0.30250483751296997\n",
      "Eval Loss:  0.3282647728919983\n",
      "Eval Loss:  0.3151058554649353\n",
      "Eval Loss:  0.3490181565284729\n",
      "Eval Loss:  0.30260077118873596\n",
      "Eval Loss:  0.37616002559661865\n",
      "Eval Loss:  0.2664352357387543\n",
      "Eval Loss:  0.3548150360584259\n",
      "Eval Loss:  0.3962661027908325\n",
      "Eval Loss:  0.3229224681854248\n",
      "Eval Loss:  0.3242220878601074\n",
      "[[16260   807]\n",
      " [ 3274  9332]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     17067\n",
      "           1       0.92      0.74      0.82     12606\n",
      "\n",
      "    accuracy                           0.86     29673\n",
      "   macro avg       0.88      0.85      0.85     29673\n",
      "weighted avg       0.87      0.86      0.86     29673\n",
      "\n",
      "acc:  0.8624675631045058\n",
      "pre:  0.9204063517112141\n",
      "rec:  0.7402824052038711\n",
      "ma F1:  0.854538132478737\n",
      "mi F1:  0.8624675631045058\n",
      "we F1:  0.8596439624472061\n",
      "29673 464\n",
      "Loss:  0.09058405458927155\n",
      "Loss:  0.08831584453582764\n",
      "Loss:  0.07122067362070084\n",
      "15 **********\n",
      "Epoch:  929.430703163147  fold:  5  kers:  64\n",
      "epoch:  16\n",
      "29673 464\n",
      "Loss:  0.08982677012681961\n",
      "Loss:  0.06756847351789474\n",
      "Loss:  0.09149419516324997\n",
      "16 **********\n",
      "Epoch:  973.5367724895477  fold:  5  kers:  64\n",
      "epoch:  17\n",
      "29673 464\n",
      "Loss:  0.07412436604499817\n",
      "Loss:  0.08753088116645813\n",
      "Loss:  0.07648596167564392\n",
      "17 **********\n",
      "Epoch:  1017.7126553058624  fold:  5  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.07006658613681793\n",
      "Eval Loss:  0.14724892377853394\n",
      "Eval Loss:  0.04423728585243225\n",
      "[[3050   47]\n",
      " [  50   71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3097\n",
      "           1       0.60      0.59      0.59       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.79      0.79      0.79      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9698570540708514\n",
      "pre:  0.6016949152542372\n",
      "rec:  0.5867768595041323\n",
      "ma F1:  0.7892447621098885\n",
      "mi F1:  0.9698570540708514\n",
      "we F1:  0.9696751685804577\n",
      "update!  Acc:  0.9698570540708514\n",
      "Eval Loss:  0.27013567090034485\n",
      "Eval Loss:  0.4355713725090027\n",
      "Eval Loss:  0.27081674337387085\n",
      "Eval Loss:  0.27317023277282715\n",
      "Eval Loss:  0.36942195892333984\n",
      "Eval Loss:  0.2733212113380432\n",
      "Eval Loss:  0.24869778752326965\n",
      "Eval Loss:  0.3060823976993561\n",
      "Eval Loss:  0.22645686566829681\n",
      "Eval Loss:  0.30115026235580444\n",
      "Eval Loss:  0.34141892194747925\n",
      "Eval Loss:  0.2721835970878601\n",
      "Eval Loss:  0.3339956998825073\n",
      "Eval Loss:  0.329497754573822\n",
      "Eval Loss:  0.24217765033245087\n",
      "Eval Loss:  0.25147387385368347\n",
      "Eval Loss:  0.3406808376312256\n",
      "Eval Loss:  0.325982928276062\n",
      "Eval Loss:  0.29413193464279175\n",
      "Eval Loss:  0.31949687004089355\n",
      "Eval Loss:  0.31953057646751404\n",
      "Eval Loss:  0.35047486424446106\n",
      "Eval Loss:  0.31334465742111206\n",
      "Eval Loss:  0.356624960899353\n",
      "Eval Loss:  0.30029964447021484\n",
      "Eval Loss:  0.3515540361404419\n",
      "Eval Loss:  0.3925299346446991\n",
      "Eval Loss:  0.3488430380821228\n",
      "Eval Loss:  0.33812278509140015\n",
      "[[16466   601]\n",
      " [ 3565  9041]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89     17067\n",
      "           1       0.94      0.72      0.81     12606\n",
      "\n",
      "    accuracy                           0.86     29673\n",
      "   macro avg       0.88      0.84      0.85     29673\n",
      "weighted avg       0.87      0.86      0.86     29673\n",
      "\n",
      "acc:  0.8596030060998214\n",
      "pre:  0.937668533499274\n",
      "rec:  0.7171981596065365\n",
      "ma F1:  0.8502250271780804\n",
      "mi F1:  0.8596030060998214\n",
      "we F1:  0.8558593926959103\n",
      "29673 464\n",
      "Loss:  0.06305158138275146\n",
      "Loss:  0.10934462398290634\n",
      "Loss:  0.05775175243616104\n",
      "18 **********\n",
      "Epoch:  1102.5488204956055  fold:  5  kers:  64\n",
      "epoch:  19\n",
      "29673 464\n",
      "Loss:  0.09543131291866302\n",
      "Loss:  0.08205867558717728\n",
      "Loss:  0.06129305809736252\n",
      "19 **********\n",
      "Epoch:  1146.6349432468414  fold:  5  kers:  64\n",
      "epoch:  20\n",
      "29673 464\n",
      "Loss:  0.06494201719760895\n",
      "Loss:  0.0732167437672615\n",
      "Loss:  0.0586901530623436\n",
      "20 **********\n",
      "Epoch:  1190.7759194374084  fold:  5  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.06436967104673386\n",
      "Eval Loss:  0.1509636491537094\n",
      "Eval Loss:  0.04042457044124603\n",
      "[[3052   45]\n",
      " [  55   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3097\n",
      "           1       0.59      0.55      0.57       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.79      0.77      0.78      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.968924798011187\n",
      "pre:  0.5945945945945946\n",
      "rec:  0.5454545454545454\n",
      "ma F1:  0.7764234420507348\n",
      "mi F1:  0.968924798011187\n",
      "we F1:  0.968280118319424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.24445313215255737\n",
      "Eval Loss:  0.38507702946662903\n",
      "Eval Loss:  0.24279898405075073\n",
      "Eval Loss:  0.2573867440223694\n",
      "Eval Loss:  0.3373316526412964\n",
      "Eval Loss:  0.2424667328596115\n",
      "Eval Loss:  0.21415868401527405\n",
      "Eval Loss:  0.2804758846759796\n",
      "Eval Loss:  0.21158762276172638\n",
      "Eval Loss:  0.2802545428276062\n",
      "Eval Loss:  0.29689592123031616\n",
      "Eval Loss:  0.23136310279369354\n",
      "Eval Loss:  0.3122371435165405\n",
      "Eval Loss:  0.2944508194923401\n",
      "Eval Loss:  0.22566592693328857\n",
      "Eval Loss:  0.23583897948265076\n",
      "Eval Loss:  0.32410335540771484\n",
      "Eval Loss:  0.32374119758605957\n",
      "Eval Loss:  0.2661815583705902\n",
      "Eval Loss:  0.3009659945964813\n",
      "Eval Loss:  0.30580154061317444\n",
      "Eval Loss:  0.33411315083503723\n",
      "Eval Loss:  0.28603681921958923\n",
      "Eval Loss:  0.347929447889328\n",
      "Eval Loss:  0.25205299258232117\n",
      "Eval Loss:  0.3142993748188019\n",
      "Eval Loss:  0.3529804050922394\n",
      "Eval Loss:  0.31606757640838623\n",
      "Eval Loss:  0.3015967309474945\n",
      "[[16360   707]\n",
      " [ 3153  9453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89     17067\n",
      "           1       0.93      0.75      0.83     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.85      0.86     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8699154113166851\n",
      "pre:  0.9304133858267717\n",
      "rec:  0.7498810090433127\n",
      "ma F1:  0.8624633859005404\n",
      "mi F1:  0.8699154113166851\n",
      "we F1:  0.8672763995651447\n",
      "29673 464\n",
      "Loss:  0.09402171522378922\n",
      "Loss:  0.07550930231809616\n",
      "Loss:  0.0878237932920456\n",
      "21 **********\n",
      "Epoch:  1275.7005560398102  fold:  5  kers:  64\n",
      "epoch:  22\n",
      "29673 464\n",
      "Loss:  0.06767058372497559\n",
      "Loss:  0.07315967231988907\n",
      "Loss:  0.06836038827896118\n",
      "22 **********\n",
      "Epoch:  1319.8180766105652  fold:  5  kers:  64\n",
      "epoch:  23\n",
      "29673 464\n",
      "Loss:  0.08961214125156403\n",
      "Loss:  0.08069902658462524\n",
      "Loss:  0.06699474155902863\n",
      "23 **********\n",
      "Epoch:  1363.9275574684143  fold:  5  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.05954919382929802\n",
      "Eval Loss:  0.10355670750141144\n",
      "Eval Loss:  0.03756202012300491\n",
      "[[3066   31]\n",
      " [  63   58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3097\n",
      "           1       0.65      0.48      0.55       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.82      0.73      0.77      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9707893101305158\n",
      "pre:  0.651685393258427\n",
      "rec:  0.4793388429752066\n",
      "ma F1:  0.768641488076117\n",
      "mi F1:  0.9707893101305158\n",
      "we F1:  0.9686388013852563\n",
      "update!  Acc:  0.9707893101305158\n",
      "Eval Loss:  0.2741287648677826\n",
      "Eval Loss:  0.38420408964157104\n",
      "Eval Loss:  0.2502887547016144\n",
      "Eval Loss:  0.24790407717227936\n",
      "Eval Loss:  0.3619879484176636\n",
      "Eval Loss:  0.27062973380088806\n",
      "Eval Loss:  0.2466932088136673\n",
      "Eval Loss:  0.30790331959724426\n",
      "Eval Loss:  0.22069182991981506\n",
      "Eval Loss:  0.3121890425682068\n",
      "Eval Loss:  0.31961122155189514\n",
      "Eval Loss:  0.24652805924415588\n",
      "Eval Loss:  0.31175824999809265\n",
      "Eval Loss:  0.3229002058506012\n",
      "Eval Loss:  0.24943330883979797\n",
      "Eval Loss:  0.2423044890165329\n",
      "Eval Loss:  0.35086509585380554\n",
      "Eval Loss:  0.3094044327735901\n",
      "Eval Loss:  0.27343910932540894\n",
      "Eval Loss:  0.30503299832344055\n",
      "Eval Loss:  0.3448721468448639\n",
      "Eval Loss:  0.3422371745109558\n",
      "Eval Loss:  0.3112519383430481\n",
      "Eval Loss:  0.348247766494751\n",
      "Eval Loss:  0.27098625898361206\n",
      "Eval Loss:  0.3291724920272827\n",
      "Eval Loss:  0.38142988085746765\n",
      "Eval Loss:  0.35421642661094666\n",
      "Eval Loss:  0.32471486926078796\n",
      "[[16535   532]\n",
      " [ 3553  9053]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     17067\n",
      "           1       0.94      0.72      0.82     12606\n",
      "\n",
      "    accuracy                           0.86     29673\n",
      "   macro avg       0.88      0.84      0.85     29673\n",
      "weighted avg       0.87      0.86      0.86     29673\n",
      "\n",
      "acc:  0.8623327604219324\n",
      "pre:  0.9444966092853416\n",
      "rec:  0.7181500872600349\n",
      "ma F1:  0.8529857683796238\n",
      "mi F1:  0.8623327604219324\n",
      "we F1:  0.8585587343647533\n",
      "29673 464\n",
      "Loss:  0.059508755803108215\n",
      "Loss:  0.05191321298480034\n",
      "Loss:  0.08616184443235397\n",
      "24 **********\n",
      "Epoch:  1448.5999248027802  fold:  5  kers:  64\n",
      "epoch:  25\n",
      "29673 464\n",
      "Loss:  0.07106535881757736\n",
      "Loss:  0.056315403431653976\n",
      "Loss:  0.07556190341711044\n",
      "25 **********\n",
      "Epoch:  1492.8402926921844  fold:  5  kers:  64\n",
      "epoch:  26\n",
      "29673 464\n",
      "Loss:  0.06332580000162125\n",
      "Loss:  0.06106948480010033\n",
      "Loss:  0.06316385418176651\n",
      "26 **********\n",
      "Epoch:  1536.8360800743103  fold:  5  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.061582356691360474\n",
      "Eval Loss:  0.11590021848678589\n",
      "Eval Loss:  0.03415384143590927\n",
      "[[3052   45]\n",
      " [  48   73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3097\n",
      "           1       0.62      0.60      0.61       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.80      0.79      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.971100062150404\n",
      "pre:  0.6186440677966102\n",
      "rec:  0.6033057851239669\n",
      "ma F1:  0.7979356997548415\n",
      "mi F1:  0.971100062150404\n",
      "we F1:  0.9709256770926037\n",
      "update!  Acc:  0.971100062150404\n",
      "Eval Loss:  0.2360055148601532\n",
      "Eval Loss:  0.3350193202495575\n",
      "Eval Loss:  0.22002963721752167\n",
      "Eval Loss:  0.24504253268241882\n",
      "Eval Loss:  0.318430632352829\n",
      "Eval Loss:  0.20380425453186035\n",
      "Eval Loss:  0.20442548394203186\n",
      "Eval Loss:  0.2881416976451874\n",
      "Eval Loss:  0.19970281422138214\n",
      "Eval Loss:  0.2690412104129791\n",
      "Eval Loss:  0.25985607504844666\n",
      "Eval Loss:  0.21646377444267273\n",
      "Eval Loss:  0.27764007449150085\n",
      "Eval Loss:  0.2797779440879822\n",
      "Eval Loss:  0.20481441915035248\n",
      "Eval Loss:  0.22030526399612427\n",
      "Eval Loss:  0.3020018935203552\n",
      "Eval Loss:  0.2843807637691498\n",
      "Eval Loss:  0.25236284732818604\n",
      "Eval Loss:  0.2777586877346039\n",
      "Eval Loss:  0.2663346230983734\n",
      "Eval Loss:  0.31952014565467834\n",
      "Eval Loss:  0.2705680727958679\n",
      "Eval Loss:  0.32165104150772095\n",
      "Eval Loss:  0.22777661681175232\n",
      "Eval Loss:  0.28270477056503296\n",
      "Eval Loss:  0.3052194118499756\n",
      "Eval Loss:  0.30238890647888184\n",
      "Eval Loss:  0.28077685832977295\n",
      "[[16361   706]\n",
      " [ 2856  9750]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     17067\n",
      "           1       0.93      0.77      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.87      0.87     29673\n",
      "weighted avg       0.89      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8799582111684022\n",
      "pre:  0.9324789594491201\n",
      "rec:  0.7734412184673964\n",
      "ma F1:  0.8736883973195548\n",
      "mi F1:  0.8799582111684022\n",
      "we F1:  0.8779191702101475\n",
      "29673 464\n",
      "Loss:  0.059652045369148254\n",
      "Loss:  0.050657711923122406\n",
      "Loss:  0.11181895434856415\n",
      "27 **********\n",
      "Epoch:  1621.6163940429688  fold:  5  kers:  64\n",
      "epoch:  28\n",
      "29673 464\n",
      "Loss:  0.06177874654531479\n",
      "Loss:  0.07870598137378693\n",
      "Loss:  0.0661480650305748\n",
      "28 **********\n",
      "Epoch:  1665.5569062232971  fold:  5  kers:  64\n",
      "epoch:  29\n",
      "29673 464\n",
      "Loss:  0.05866847559809685\n",
      "Loss:  0.05497341603040695\n",
      "Loss:  0.08255600184202194\n",
      "29 **********\n",
      "Epoch:  1709.6021387577057  fold:  5  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.05579378455877304\n",
      "Eval Loss:  0.0472063310444355\n",
      "Eval Loss:  0.029312415048480034\n",
      "[[3075   22]\n",
      " [  67   54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.71      0.45      0.55       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.84      0.72      0.77      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9723430702299565\n",
      "pre:  0.7105263157894737\n",
      "rec:  0.4462809917355372\n",
      "ma F1:  0.7669791218331065\n",
      "mi F1:  0.9723430702299565\n",
      "we F1:  0.9692840243253361\n",
      "update!  Acc:  0.9723430702299565\n",
      "Eval Loss:  0.24871112406253815\n",
      "Eval Loss:  0.35951802134513855\n",
      "Eval Loss:  0.24075424671173096\n",
      "Eval Loss:  0.24461902678012848\n",
      "Eval Loss:  0.3529984951019287\n",
      "Eval Loss:  0.2423068881034851\n",
      "Eval Loss:  0.23309172689914703\n",
      "Eval Loss:  0.31736400723457336\n",
      "Eval Loss:  0.21933753788471222\n",
      "Eval Loss:  0.2925342917442322\n",
      "Eval Loss:  0.311682790517807\n",
      "Eval Loss:  0.23809893429279327\n",
      "Eval Loss:  0.3099532425403595\n",
      "Eval Loss:  0.3224857747554779\n",
      "Eval Loss:  0.22496896982192993\n",
      "Eval Loss:  0.2415720671415329\n",
      "Eval Loss:  0.3369712829589844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3099837005138397\n",
      "Eval Loss:  0.24680474400520325\n",
      "Eval Loss:  0.31396302580833435\n",
      "Eval Loss:  0.31917575001716614\n",
      "Eval Loss:  0.358474463224411\n",
      "Eval Loss:  0.3040141761302948\n",
      "Eval Loss:  0.34282317757606506\n",
      "Eval Loss:  0.2790512144565582\n",
      "Eval Loss:  0.3388845920562744\n",
      "Eval Loss:  0.362076073884964\n",
      "Eval Loss:  0.3468879759311676\n",
      "Eval Loss:  0.30943918228149414\n",
      "[[16582   485]\n",
      " [ 3451  9155]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89     17067\n",
      "           1       0.95      0.73      0.82     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.89      0.85      0.86     29673\n",
      "weighted avg       0.88      0.87      0.86     29673\n",
      "\n",
      "acc:  0.8673541603477909\n",
      "pre:  0.9496887966804979\n",
      "rec:  0.7262414723147708\n",
      "ma F1:  0.858488835813604\n",
      "mi F1:  0.8673541603477909\n",
      "we F1:  0.8638137601096869\n",
      "29673 464\n",
      "Loss:  0.063650943338871\n",
      "Loss:  0.06269650161266327\n",
      "Loss:  0.06960313767194748\n",
      "30 **********\n",
      "Epoch:  1794.5410294532776  fold:  5  kers:  64\n",
      "epoch:  31\n",
      "29673 464\n",
      "Loss:  0.07835490256547928\n",
      "Loss:  0.05908145383000374\n",
      "Loss:  0.07063893228769302\n",
      "31 **********\n",
      "Epoch:  1838.5433757305145  fold:  5  kers:  64\n",
      "epoch:  32\n",
      "29673 464\n",
      "Loss:  0.04175914451479912\n",
      "Loss:  0.07678566873073578\n",
      "Loss:  0.11039384454488754\n",
      "32 **********\n",
      "Epoch:  1882.5407359600067  fold:  5  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.06020215153694153\n",
      "Eval Loss:  0.08560118079185486\n",
      "Eval Loss:  0.03322469815611839\n",
      "[[3056   41]\n",
      " [  34   87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.68      0.72      0.70       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.83      0.85      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9766935985083903\n",
      "pre:  0.6796875\n",
      "rec:  0.71900826446281\n",
      "ma F1:  0.8433364945153168\n",
      "mi F1:  0.9766935985083903\n",
      "we F1:  0.9770080140449182\n",
      "update!  Acc:  0.9766935985083903\n",
      "Eval Loss:  0.1806091070175171\n",
      "Eval Loss:  0.28289633989334106\n",
      "Eval Loss:  0.2028219848871231\n",
      "Eval Loss:  0.22502808272838593\n",
      "Eval Loss:  0.2786366641521454\n",
      "Eval Loss:  0.1945183426141739\n",
      "Eval Loss:  0.1869964599609375\n",
      "Eval Loss:  0.23683032393455505\n",
      "Eval Loss:  0.20471623539924622\n",
      "Eval Loss:  0.2512076199054718\n",
      "Eval Loss:  0.21190936863422394\n",
      "Eval Loss:  0.1859503537416458\n",
      "Eval Loss:  0.22766271233558655\n",
      "Eval Loss:  0.23917928338050842\n",
      "Eval Loss:  0.1831096112728119\n",
      "Eval Loss:  0.22288653254508972\n",
      "Eval Loss:  0.26683133840560913\n",
      "Eval Loss:  0.25470462441444397\n",
      "Eval Loss:  0.22672666609287262\n",
      "Eval Loss:  0.2604137659072876\n",
      "Eval Loss:  0.21641340851783752\n",
      "Eval Loss:  0.2848142385482788\n",
      "Eval Loss:  0.2194427251815796\n",
      "Eval Loss:  0.2799175977706909\n",
      "Eval Loss:  0.2083098292350769\n",
      "Eval Loss:  0.2713073790073395\n",
      "Eval Loss:  0.27350401878356934\n",
      "Eval Loss:  0.25359076261520386\n",
      "Eval Loss:  0.22566093504428864\n",
      "[[16072   995]\n",
      " [ 2115 10491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     17067\n",
      "           1       0.91      0.83      0.87     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.89     29673\n",
      "\n",
      "acc:  0.8951909142991945\n",
      "pre:  0.9133728016716002\n",
      "rec:  0.8322227510709186\n",
      "ma F1:  0.8913472829861808\n",
      "mi F1:  0.8951909142991944\n",
      "we F1:  0.8944195709788978\n",
      "29673 464\n",
      "Loss:  0.0769059881567955\n",
      "Loss:  0.089911088347435\n",
      "Loss:  0.061465583741664886\n",
      "33 **********\n",
      "Epoch:  1967.3998401165009  fold:  5  kers:  64\n",
      "epoch:  34\n",
      "29673 464\n",
      "Loss:  0.07394298911094666\n",
      "Loss:  0.06730430573225021\n",
      "Loss:  0.10359863191843033\n",
      "34 **********\n",
      "Epoch:  2011.598661184311  fold:  5  kers:  64\n",
      "epoch:  35\n",
      "29673 464\n",
      "Loss:  0.06509043276309967\n",
      "Loss:  0.06541112810373306\n",
      "Loss:  0.0910727009177208\n",
      "35 **********\n",
      "Epoch:  2055.6927633285522  fold:  5  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.05550863593816757\n",
      "Eval Loss:  0.05240892991423607\n",
      "Eval Loss:  0.024902580305933952\n",
      "[[3076   21]\n",
      " [  86   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3097\n",
      "           1       0.62      0.29      0.40       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.80      0.64      0.69      3218\n",
      "weighted avg       0.96      0.97      0.96      3218\n",
      "\n",
      "acc:  0.9667495338719702\n",
      "pre:  0.625\n",
      "rec:  0.2892561983471074\n",
      "ma F1:  0.6891924216698575\n",
      "mi F1:  0.96674953387197\n",
      "we F1:  0.9608168760971799\n",
      "Eval Loss:  0.2908630073070526\n",
      "Eval Loss:  0.33800023794174194\n",
      "Eval Loss:  0.23877574503421783\n",
      "Eval Loss:  0.2077476978302002\n",
      "Eval Loss:  0.35096022486686707\n",
      "Eval Loss:  0.2493973821401596\n",
      "Eval Loss:  0.26460984349250793\n",
      "Eval Loss:  0.3176722526550293\n",
      "Eval Loss:  0.22113282978534698\n",
      "Eval Loss:  0.2711227238178253\n",
      "Eval Loss:  0.3054400384426117\n",
      "Eval Loss:  0.26738739013671875\n",
      "Eval Loss:  0.2576202154159546\n",
      "Eval Loss:  0.35460230708122253\n",
      "Eval Loss:  0.20992493629455566\n",
      "Eval Loss:  0.23522669076919556\n",
      "Eval Loss:  0.3371117413043976\n",
      "Eval Loss:  0.32663729786872864\n",
      "Eval Loss:  0.26011890172958374\n",
      "Eval Loss:  0.2911666929721832\n",
      "Eval Loss:  0.34097620844841003\n",
      "Eval Loss:  0.33348727226257324\n",
      "Eval Loss:  0.2993811070919037\n",
      "Eval Loss:  0.318450391292572\n",
      "Eval Loss:  0.2698849141597748\n",
      "Eval Loss:  0.32027533650398254\n",
      "Eval Loss:  0.3320414423942566\n",
      "Eval Loss:  0.35425978899002075\n",
      "Eval Loss:  0.30368363857269287\n",
      "[[16585   482]\n",
      " [ 3309  9297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     17067\n",
      "           1       0.95      0.74      0.83     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.89      0.85      0.86     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8722407575910761\n",
      "pre:  0.9507107066162185\n",
      "rec:  0.7375059495478343\n",
      "ma F1:  0.864038975165445\n",
      "mi F1:  0.8722407575910762\n",
      "we F1:  0.8690593032939767\n",
      "29673 464\n",
      "Loss:  0.07936287671327591\n",
      "Loss:  0.09276258200407028\n",
      "Loss:  0.06941714882850647\n",
      "36 **********\n",
      "Epoch:  2140.527930498123  fold:  5  kers:  64\n",
      "epoch:  37\n",
      "29673 464\n",
      "Loss:  0.06972426921129227\n",
      "Loss:  0.06868764758110046\n",
      "Loss:  0.05059947818517685\n",
      "37 **********\n",
      "Epoch:  2184.553215742111  fold:  5  kers:  64\n",
      "epoch:  38\n",
      "29673 464\n",
      "Loss:  0.06996112316846848\n",
      "Loss:  0.07147641479969025\n",
      "Loss:  0.04028742015361786\n",
      "38 **********\n",
      "Epoch:  2228.709151983261  fold:  5  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.05957253649830818\n",
      "Eval Loss:  0.04691797494888306\n",
      "Eval Loss:  0.02357688918709755\n",
      "[[3074   23]\n",
      " [  47   74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.76      0.61      0.68       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.80      0.83      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.978247358607831\n",
      "pre:  0.7628865979381443\n",
      "rec:  0.6115702479338843\n",
      "ma F1:  0.8338207217282763\n",
      "mi F1:  0.978247358607831\n",
      "we F1:  0.9770919455127947\n",
      "update!  Acc:  0.978247358607831\n",
      "Eval Loss:  0.20220401883125305\n",
      "Eval Loss:  0.28532877564430237\n",
      "Eval Loss:  0.21221329271793365\n",
      "Eval Loss:  0.21501991152763367\n",
      "Eval Loss:  0.28601348400115967\n",
      "Eval Loss:  0.2315465360879898\n",
      "Eval Loss:  0.22549380362033844\n",
      "Eval Loss:  0.24940185248851776\n",
      "Eval Loss:  0.19645842909812927\n",
      "Eval Loss:  0.23177286982536316\n",
      "Eval Loss:  0.22700008749961853\n",
      "Eval Loss:  0.18959073722362518\n",
      "Eval Loss:  0.2322794795036316\n",
      "Eval Loss:  0.26492294669151306\n",
      "Eval Loss:  0.18668097257614136\n",
      "Eval Loss:  0.2310791313648224\n",
      "Eval Loss:  0.2754739224910736\n",
      "Eval Loss:  0.2731141149997711\n",
      "Eval Loss:  0.2105138599872589\n",
      "Eval Loss:  0.24560314416885376\n",
      "Eval Loss:  0.2674163579940796\n",
      "Eval Loss:  0.2913244068622589\n",
      "Eval Loss:  0.21307334303855896\n",
      "Eval Loss:  0.275701642036438\n",
      "Eval Loss:  0.2152678221464157\n",
      "Eval Loss:  0.29058533906936646\n",
      "Eval Loss:  0.25082600116729736\n",
      "Eval Loss:  0.2778279483318329\n",
      "Eval Loss:  0.24904325604438782\n",
      "[[16389   678]\n",
      " [ 2478 10128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17067\n",
      "           1       0.94      0.80      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.88      0.89     29673\n",
      "weighted avg       0.90      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8936406834496007\n",
      "pre:  0.9372570794003331\n",
      "rec:  0.803426939552594\n",
      "ma F1:  0.88868482530633\n",
      "mi F1:  0.8936406834496007\n",
      "we F1:  0.8922159039163173\n",
      "29673 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07835027575492859\n",
      "Loss:  0.05263790488243103\n",
      "Loss:  0.0703079029917717\n",
      "39 **********\n",
      "Epoch:  2313.440597295761  fold:  5  kers:  64\n",
      "epoch:  40\n",
      "29673 464\n",
      "Loss:  0.08121863752603531\n",
      "Loss:  0.08486060053110123\n",
      "Loss:  0.0575544536113739\n",
      "40 **********\n",
      "Epoch:  2357.44394159317  fold:  5  kers:  64\n",
      "epoch:  41\n",
      "29673 464\n",
      "Loss:  0.07509753853082657\n",
      "Loss:  0.07630477845668793\n",
      "Loss:  0.10374534875154495\n",
      "41 **********\n",
      "Epoch:  2401.424346923828  fold:  5  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.05758441984653473\n",
      "Eval Loss:  0.05005260929465294\n",
      "Eval Loss:  0.024821842089295387\n",
      "[[3081   16]\n",
      " [  51   70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.81      0.58      0.68       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.90      0.79      0.83      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9791796146674954\n",
      "pre:  0.813953488372093\n",
      "rec:  0.5785123966942148\n",
      "ma F1:  0.8327861808914668\n",
      "mi F1:  0.9791796146674954\n",
      "we F1:  0.9774779307810253\n",
      "update!  Acc:  0.9791796146674954\n",
      "Eval Loss:  0.17576222121715546\n",
      "Eval Loss:  0.2710625231266022\n",
      "Eval Loss:  0.21559610962867737\n",
      "Eval Loss:  0.20496685802936554\n",
      "Eval Loss:  0.2700825035572052\n",
      "Eval Loss:  0.1989729106426239\n",
      "Eval Loss:  0.1947505623102188\n",
      "Eval Loss:  0.2392112910747528\n",
      "Eval Loss:  0.1854378581047058\n",
      "Eval Loss:  0.24045178294181824\n",
      "Eval Loss:  0.2358814924955368\n",
      "Eval Loss:  0.1952861249446869\n",
      "Eval Loss:  0.2183234989643097\n",
      "Eval Loss:  0.25068798661231995\n",
      "Eval Loss:  0.1642635017633438\n",
      "Eval Loss:  0.21575722098350525\n",
      "Eval Loss:  0.24880532920360565\n",
      "Eval Loss:  0.27222737669944763\n",
      "Eval Loss:  0.22404441237449646\n",
      "Eval Loss:  0.23485508561134338\n",
      "Eval Loss:  0.24543102085590363\n",
      "Eval Loss:  0.2561211884021759\n",
      "Eval Loss:  0.21032772958278656\n",
      "Eval Loss:  0.2540211081504822\n",
      "Eval Loss:  0.22137689590454102\n",
      "Eval Loss:  0.26713594794273376\n",
      "Eval Loss:  0.24257230758666992\n",
      "Eval Loss:  0.27533942461013794\n",
      "Eval Loss:  0.23962077498435974\n",
      "[[16404   663]\n",
      " [ 2434 10172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17067\n",
      "           1       0.94      0.81      0.87     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.88      0.89     29673\n",
      "weighted avg       0.90      0.90      0.89     29673\n",
      "\n",
      "acc:  0.8956290230175581\n",
      "pre:  0.9388094139363174\n",
      "rec:  0.8069173409487546\n",
      "ma F1:  0.8908128334551012\n",
      "mi F1:  0.8956290230175581\n",
      "we F1:  0.8942603658103837\n",
      "29673 464\n",
      "Loss:  0.057687174528837204\n",
      "Loss:  0.07376842200756073\n",
      "Loss:  0.06666221469640732\n",
      "42 **********\n",
      "Epoch:  2486.069814682007  fold:  5  kers:  64\n",
      "epoch:  43\n",
      "29673 464\n",
      "Loss:  0.07161653786897659\n",
      "Loss:  0.07205823808908463\n",
      "Loss:  0.06797440350055695\n",
      "43 **********\n",
      "Epoch:  2530.013161420822  fold:  5  kers:  64\n",
      "epoch:  44\n",
      "29673 464\n",
      "Loss:  0.06725907325744629\n",
      "Loss:  0.06773817539215088\n",
      "Loss:  0.07428105175495148\n",
      "44 **********\n",
      "Epoch:  2573.9746174812317  fold:  5  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.0715649425983429\n",
      "Eval Loss:  0.06426762789487839\n",
      "Eval Loss:  0.028381193056702614\n",
      "[[3064   33]\n",
      " [  44   77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.70      0.64      0.67       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.84      0.81      0.83      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9760720944686141\n",
      "pre:  0.7\n",
      "rec:  0.6363636363636364\n",
      "ma F1:  0.8271286596830513\n",
      "mi F1:  0.9760720944686141\n",
      "we F1:  0.9755235916957178\n",
      "Eval Loss:  0.16517198085784912\n",
      "Eval Loss:  0.2373218536376953\n",
      "Eval Loss:  0.20499569177627563\n",
      "Eval Loss:  0.18690913915634155\n",
      "Eval Loss:  0.24997541308403015\n",
      "Eval Loss:  0.19413958489894867\n",
      "Eval Loss:  0.2006034553050995\n",
      "Eval Loss:  0.21337302029132843\n",
      "Eval Loss:  0.1913878619670868\n",
      "Eval Loss:  0.22831743955612183\n",
      "Eval Loss:  0.1643628031015396\n",
      "Eval Loss:  0.17399606108665466\n",
      "Eval Loss:  0.19328491389751434\n",
      "Eval Loss:  0.21433022618293762\n",
      "Eval Loss:  0.1689717024564743\n",
      "Eval Loss:  0.2114640474319458\n",
      "Eval Loss:  0.2378283143043518\n",
      "Eval Loss:  0.2548746168613434\n",
      "Eval Loss:  0.20774078369140625\n",
      "Eval Loss:  0.2176673859357834\n",
      "Eval Loss:  0.19645866751670837\n",
      "Eval Loss:  0.23831027746200562\n",
      "Eval Loss:  0.18689227104187012\n",
      "Eval Loss:  0.23737239837646484\n",
      "Eval Loss:  0.215499609708786\n",
      "Eval Loss:  0.27308547496795654\n",
      "Eval Loss:  0.2205442190170288\n",
      "Eval Loss:  0.24233326315879822\n",
      "Eval Loss:  0.20941032469272614\n",
      "[[16128   939]\n",
      " [ 1931 10675]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     17067\n",
      "           1       0.92      0.85      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.91      0.90      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9032790752535975\n",
      "pre:  0.9191493025658688\n",
      "rec:  0.8468189750912264\n",
      "ma F1:  0.8998985156327395\n",
      "mi F1:  0.9032790752535975\n",
      "we F1:  0.9026640898980335\n",
      "29673 464\n",
      "Loss:  0.05782410502433777\n",
      "Loss:  0.07729087769985199\n",
      "Loss:  0.06766599416732788\n",
      "45 **********\n",
      "Epoch:  2658.6979534626007  fold:  5  kers:  64\n",
      "epoch:  46\n",
      "29673 464\n",
      "Loss:  0.06898768991231918\n",
      "Loss:  0.07744334638118744\n",
      "Loss:  0.062256164848804474\n",
      "46 **********\n",
      "Epoch:  2702.748172044754  fold:  5  kers:  64\n",
      "epoch:  47\n",
      "29673 464\n",
      "Loss:  0.04727089777588844\n",
      "Loss:  0.05766438692808151\n",
      "Loss:  0.05220707505941391\n",
      "47 **********\n",
      "Epoch:  2746.7554972171783  fold:  5  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.05824096500873566\n",
      "Eval Loss:  0.04185635969042778\n",
      "Eval Loss:  0.026523543521761894\n",
      "[[3069   28]\n",
      " [  41   80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.74      0.66      0.70       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.83      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9785581106277191\n",
      "pre:  0.7407407407407407\n",
      "rec:  0.6611570247933884\n",
      "ma F1:  0.8437867374699505\n",
      "mi F1:  0.9785581106277191\n",
      "we F1:  0.9779719520960862\n",
      "Eval Loss:  0.15783609449863434\n",
      "Eval Loss:  0.25429004430770874\n",
      "Eval Loss:  0.20687700808048248\n",
      "Eval Loss:  0.19263529777526855\n",
      "Eval Loss:  0.26319509744644165\n",
      "Eval Loss:  0.20241452753543854\n",
      "Eval Loss:  0.17578125\n",
      "Eval Loss:  0.2206483781337738\n",
      "Eval Loss:  0.2003512680530548\n",
      "Eval Loss:  0.20125092566013336\n",
      "Eval Loss:  0.1609407514333725\n",
      "Eval Loss:  0.16432617604732513\n",
      "Eval Loss:  0.17343762516975403\n",
      "Eval Loss:  0.23254194855690002\n",
      "Eval Loss:  0.1614898443222046\n",
      "Eval Loss:  0.20230764150619507\n",
      "Eval Loss:  0.26605096459388733\n",
      "Eval Loss:  0.25329726934432983\n",
      "Eval Loss:  0.2043289691209793\n",
      "Eval Loss:  0.22754955291748047\n",
      "Eval Loss:  0.21635255217552185\n",
      "Eval Loss:  0.24477262794971466\n",
      "Eval Loss:  0.17404723167419434\n",
      "Eval Loss:  0.23163069784641266\n",
      "Eval Loss:  0.19678905606269836\n",
      "Eval Loss:  0.24318517744541168\n",
      "Eval Loss:  0.21478189527988434\n",
      "Eval Loss:  0.2395407110452652\n",
      "Eval Loss:  0.22976519167423248\n",
      "[[16121   946]\n",
      " [ 1902 10704]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     17067\n",
      "           1       0.92      0.85      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.91      0.90      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9040204900077512\n",
      "pre:  0.9187982832618026\n",
      "rec:  0.849119466920514\n",
      "ma F1:  0.9007115137779896\n",
      "mi F1:  0.9040204900077512\n",
      "we F1:  0.9034365170936561\n",
      "29673 464\n",
      "Loss:  0.0605459101498127\n",
      "Loss:  0.05223968252539635\n",
      "Loss:  0.04608837887644768\n",
      "48 **********\n",
      "Epoch:  2831.3822226524353  fold:  5  kers:  64\n",
      "epoch:  49\n",
      "29673 464\n",
      "Loss:  0.05272519588470459\n",
      "Loss:  0.03977561742067337\n",
      "Loss:  0.0595904104411602\n",
      "49 **********\n",
      "Epoch:  2875.279852628708  fold:  5  kers:  64\n",
      "epoch:  50\n",
      "29673 464\n",
      "Loss:  0.04304618015885353\n",
      "Loss:  0.060424450784921646\n",
      "Loss:  0.05628116801381111\n",
      "50 **********\n",
      "Epoch:  2919.210742712021  fold:  5  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.05833513289690018\n",
      "Eval Loss:  0.02282262034714222\n",
      "Eval Loss:  0.019983788952231407\n",
      "[[3080   17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [  76   45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3097\n",
      "           1       0.73      0.37      0.49       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.85      0.68      0.74      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.971100062150404\n",
      "pre:  0.7258064516129032\n",
      "rec:  0.371900826446281\n",
      "ma F1:  0.7384652088309087\n",
      "mi F1:  0.971100062150404\n",
      "we F1:  0.9665776712621502\n",
      "Eval Loss:  0.22387275099754333\n",
      "Eval Loss:  0.3277823328971863\n",
      "Eval Loss:  0.22805118560791016\n",
      "Eval Loss:  0.21234457194805145\n",
      "Eval Loss:  0.305595725774765\n",
      "Eval Loss:  0.23892971873283386\n",
      "Eval Loss:  0.21982437372207642\n",
      "Eval Loss:  0.2842733561992645\n",
      "Eval Loss:  0.22430501878261566\n",
      "Eval Loss:  0.2415294647216797\n",
      "Eval Loss:  0.2686420679092407\n",
      "Eval Loss:  0.23565372824668884\n",
      "Eval Loss:  0.2526213526725769\n",
      "Eval Loss:  0.28825297951698303\n",
      "Eval Loss:  0.16654585301876068\n",
      "Eval Loss:  0.22293801605701447\n",
      "Eval Loss:  0.28967076539993286\n",
      "Eval Loss:  0.2757885158061981\n",
      "Eval Loss:  0.2545774579048157\n",
      "Eval Loss:  0.24714313447475433\n",
      "Eval Loss:  0.31741419434547424\n",
      "Eval Loss:  0.2877683639526367\n",
      "Eval Loss:  0.24456697702407837\n",
      "Eval Loss:  0.28776097297668457\n",
      "Eval Loss:  0.24521155655384064\n",
      "Eval Loss:  0.28916436433792114\n",
      "Eval Loss:  0.25936177372932434\n",
      "Eval Loss:  0.3331458866596222\n",
      "Eval Loss:  0.25797370076179504\n",
      "[[16601   466]\n",
      " [ 2944  9662]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91     17067\n",
      "           1       0.95      0.77      0.85     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.87      0.88     29673\n",
      "weighted avg       0.89      0.89      0.88     29673\n",
      "\n",
      "acc:  0.8850807131061909\n",
      "pre:  0.9539889415481833\n",
      "rec:  0.7664604156750754\n",
      "ma F1:  0.8784327685612727\n",
      "mi F1:  0.8850807131061909\n",
      "we F1:  0.8827066524948192\n",
      "29673 464\n",
      "Loss:  0.05809926986694336\n",
      "Loss:  0.06268683075904846\n",
      "Loss:  0.04265957325696945\n",
      "51 **********\n",
      "Epoch:  3003.975828886032  fold:  5  kers:  64\n",
      "epoch:  52\n",
      "29673 464\n",
      "Loss:  0.07617508620023727\n",
      "Loss:  0.07382692396640778\n",
      "Loss:  0.07412732392549515\n",
      "52 **********\n",
      "Epoch:  3047.9835374355316  fold:  5  kers:  64\n",
      "epoch:  53\n",
      "29673 464\n",
      "Loss:  0.03143543004989624\n",
      "Loss:  0.059713300317525864\n",
      "Loss:  0.0728713721036911\n",
      "53 **********\n",
      "Epoch:  3091.9812111854553  fold:  5  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.06157372146844864\n",
      "Eval Loss:  0.05017951875925064\n",
      "Eval Loss:  0.022727899253368378\n",
      "[[3075   22]\n",
      " [  39   82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.79      0.68      0.73       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.89      0.84      0.86      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9810441267868241\n",
      "pre:  0.7884615384615384\n",
      "rec:  0.6776859504132231\n",
      "ma F1:  0.8595338020358145\n",
      "mi F1:  0.981044126786824\n",
      "we F1:  0.9803539578857993\n",
      "update!  Acc:  0.9810441267868241\n",
      "Eval Loss:  0.16402675211429596\n",
      "Eval Loss:  0.23609451949596405\n",
      "Eval Loss:  0.19823849201202393\n",
      "Eval Loss:  0.19628676772117615\n",
      "Eval Loss:  0.24062895774841309\n",
      "Eval Loss:  0.1910536140203476\n",
      "Eval Loss:  0.18050892651081085\n",
      "Eval Loss:  0.21448387205600739\n",
      "Eval Loss:  0.17654266953468323\n",
      "Eval Loss:  0.18975786864757538\n",
      "Eval Loss:  0.16233937442302704\n",
      "Eval Loss:  0.18385189771652222\n",
      "Eval Loss:  0.16306011378765106\n",
      "Eval Loss:  0.21887019276618958\n",
      "Eval Loss:  0.15946151316165924\n",
      "Eval Loss:  0.19354766607284546\n",
      "Eval Loss:  0.2427799254655838\n",
      "Eval Loss:  0.2340766340494156\n",
      "Eval Loss:  0.20688384771347046\n",
      "Eval Loss:  0.20381401479244232\n",
      "Eval Loss:  0.21140211820602417\n",
      "Eval Loss:  0.23540975153446198\n",
      "Eval Loss:  0.1804736703634262\n",
      "Eval Loss:  0.211359903216362\n",
      "Eval Loss:  0.18092243373394012\n",
      "Eval Loss:  0.258129358291626\n",
      "Eval Loss:  0.20506131649017334\n",
      "Eval Loss:  0.23672281205654144\n",
      "Eval Loss:  0.2052382528781891\n",
      "[[16233   834]\n",
      " [ 1928 10678]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17067\n",
      "           1       0.93      0.85      0.89     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.90      0.90     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9069187476830789\n",
      "pre:  0.9275538568450312\n",
      "rec:  0.8470569570046009\n",
      "ma F1:  0.9035380910252083\n",
      "mi F1:  0.9069187476830789\n",
      "we F1:  0.9062529621954623\n",
      "29673 464\n",
      "Loss:  0.06251734495162964\n",
      "Loss:  0.07902415841817856\n",
      "Loss:  0.053884316235780716\n",
      "54 **********\n",
      "Epoch:  3176.936307668686  fold:  5  kers:  64\n",
      "epoch:  55\n",
      "29673 464\n",
      "Loss:  0.0457620695233345\n",
      "Loss:  0.07100078463554382\n",
      "Loss:  0.05801093205809593\n",
      "55 **********\n",
      "Epoch:  3220.9915125370026  fold:  5  kers:  64\n",
      "epoch:  56\n",
      "29673 464\n",
      "Loss:  0.08158551901578903\n",
      "Loss:  0.048934999853372574\n",
      "Loss:  0.0397535115480423\n",
      "56 **********\n",
      "Epoch:  3265.0636727809906  fold:  5  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.0629369467496872\n",
      "Eval Loss:  0.06247706711292267\n",
      "Eval Loss:  0.0367329940199852\n",
      "[[3066   31]\n",
      " [  37   84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.73      0.69      0.71       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.86      0.84      0.85      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.9788688626476072\n",
      "pre:  0.7304347826086957\n",
      "rec:  0.6942148760330579\n",
      "ma F1:  0.8504483324220886\n",
      "mi F1:  0.9788688626476072\n",
      "we F1:  0.9786104712387029\n",
      "Eval Loss:  0.15445320308208466\n",
      "Eval Loss:  0.22342944145202637\n",
      "Eval Loss:  0.19250831007957458\n",
      "Eval Loss:  0.17628486454486847\n",
      "Eval Loss:  0.2456493079662323\n",
      "Eval Loss:  0.1830379068851471\n",
      "Eval Loss:  0.16026154160499573\n",
      "Eval Loss:  0.21082386374473572\n",
      "Eval Loss:  0.16150373220443726\n",
      "Eval Loss:  0.2090337872505188\n",
      "Eval Loss:  0.1502605527639389\n",
      "Eval Loss:  0.17270633578300476\n",
      "Eval Loss:  0.1596953123807907\n",
      "Eval Loss:  0.20723184943199158\n",
      "Eval Loss:  0.1736607402563095\n",
      "Eval Loss:  0.18900099396705627\n",
      "Eval Loss:  0.2411384880542755\n",
      "Eval Loss:  0.22285349667072296\n",
      "Eval Loss:  0.19237004220485687\n",
      "Eval Loss:  0.2083144187927246\n",
      "Eval Loss:  0.19713588058948517\n",
      "Eval Loss:  0.21246647834777832\n",
      "Eval Loss:  0.15494319796562195\n",
      "Eval Loss:  0.2062443494796753\n",
      "Eval Loss:  0.2091396003961563\n",
      "Eval Loss:  0.22865405678749084\n",
      "Eval Loss:  0.1969059407711029\n",
      "Eval Loss:  0.21248015761375427\n",
      "Eval Loss:  0.2293016016483307\n",
      "[[16020  1047]\n",
      " [ 1523 11083]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     17067\n",
      "           1       0.91      0.88      0.90     12606\n",
      "\n",
      "    accuracy                           0.91     29673\n",
      "   macro avg       0.91      0.91      0.91     29673\n",
      "weighted avg       0.91      0.91      0.91     29673\n",
      "\n",
      "acc:  0.9133892764466013\n",
      "pre:  0.9136850783182193\n",
      "rec:  0.8791845153101697\n",
      "ma F1:  0.9109234253386376\n",
      "mi F1:  0.9133892764466013\n",
      "we F1:  0.9131515318390683\n",
      "29673 464\n",
      "Loss:  0.04273274913430214\n",
      "Loss:  0.035643890500068665\n",
      "Loss:  0.07115545123815536\n",
      "57 **********\n",
      "Epoch:  3350.0377774238586  fold:  5  kers:  64\n",
      "epoch:  58\n",
      "29673 464\n",
      "Loss:  0.03848165646195412\n",
      "Loss:  0.0628952831029892\n",
      "Loss:  0.08301931619644165\n",
      "58 **********\n",
      "Epoch:  3394.1782178878784  fold:  5  kers:  64\n",
      "epoch:  59\n",
      "29673 464\n",
      "Loss:  0.054734084755182266\n",
      "Loss:  0.07896869629621506\n",
      "Loss:  0.0761353075504303\n",
      "59 **********\n",
      "Epoch:  3438.3237121105194  fold:  5  kers:  64\n",
      "Eval Loss:  0.058105602860450745\n",
      "Eval Loss:  0.05311264842748642\n",
      "Eval Loss:  0.027810439467430115\n",
      "[[3073   24]\n",
      " [  46   75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.76      0.62      0.68       121\n",
      "\n",
      "    accuracy                           0.98      3218\n",
      "   macro avg       0.87      0.81      0.84      3218\n",
      "weighted avg       0.98      0.98      0.98      3218\n",
      "\n",
      "acc:  0.978247358607831\n",
      "pre:  0.7575757575757576\n",
      "rec:  0.6198347107438017\n",
      "ma F1:  0.8352784602784604\n",
      "mi F1:  0.978247358607831\n",
      "we F1:  0.9771982205947403\n",
      "update!  Acc:  0.9810441267868241\n",
      "Epoch:  3442.2980856895447  fold:  5  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29479 3412\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29479 461\n",
      "Loss:  0.16376829147338867\n",
      "Loss:  0.16542237997055054\n",
      "Loss:  0.1703963577747345\n",
      "0 **********\n",
      "Epoch:  56.587695360183716  fold:  6  kers:  64\n",
      "epoch:  1\n",
      "29479 461\n",
      "Loss:  0.15462327003479004\n",
      "Loss:  0.14560984075069427\n",
      "Loss:  0.12713757157325745\n",
      "1 **********\n",
      "Epoch:  100.57607936859131  fold:  6  kers:  64\n",
      "epoch:  2\n",
      "29479 461\n",
      "Loss:  0.139032244682312\n",
      "Loss:  0.10697974264621735\n",
      "Loss:  0.1222558468580246\n",
      "2 **********\n",
      "Epoch:  144.62431478500366  fold:  6  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.09686534106731415\n",
      "Eval Loss:  0.35690194368362427\n",
      "Eval Loss:  0.5847145318984985\n",
      "[[1897  335]\n",
      " [ 160 1020]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88      2232\n",
      "           1       0.75      0.86      0.80      1180\n",
      "\n",
      "    accuracy                           0.85      3412\n",
      "   macro avg       0.84      0.86      0.84      3412\n",
      "weighted avg       0.86      0.85      0.86      3412\n",
      "\n",
      "acc:  0.8549237983587339\n",
      "pre:  0.7527675276752768\n",
      "rec:  0.864406779661017\n",
      "ma F1:  0.8446611049871628\n",
      "mi F1:  0.8549237983587339\n",
      "we F1:  0.8569716562150907\n",
      "update!  Acc:  0.8549237983587339\n",
      "Eval Loss:  0.399212121963501\n",
      "Eval Loss:  0.4180285334587097\n",
      "Eval Loss:  0.4417332410812378\n",
      "Eval Loss:  0.4324241280555725\n",
      "Eval Loss:  0.417706161737442\n",
      "Eval Loss:  0.470630943775177\n",
      "Eval Loss:  0.49073734879493713\n",
      "Eval Loss:  0.38213494420051575\n",
      "Eval Loss:  0.5602973103523254\n",
      "Eval Loss:  0.5412099957466125\n",
      "Eval Loss:  0.43303200602531433\n",
      "Eval Loss:  0.48328888416290283\n",
      "Eval Loss:  0.49033600091934204\n",
      "Eval Loss:  0.48833438754081726\n",
      "Eval Loss:  0.42431265115737915\n",
      "Eval Loss:  0.3980677127838135\n",
      "Eval Loss:  0.4858337938785553\n",
      "Eval Loss:  0.45535510778427124\n",
      "Eval Loss:  0.4351825416088104\n",
      "Eval Loss:  0.40986138582229614\n",
      "Eval Loss:  0.3955516815185547\n",
      "Eval Loss:  0.4174748659133911\n",
      "Eval Loss:  0.42795178294181824\n",
      "Eval Loss:  0.4528394341468811\n",
      "Eval Loss:  0.39750245213508606\n",
      "Eval Loss:  0.44424358010292053\n",
      "Eval Loss:  0.4591813385486603\n",
      "Eval Loss:  0.43404269218444824\n",
      "[[15945  1987]\n",
      " [ 4233  7314]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84     17932\n",
      "           1       0.79      0.63      0.70     11547\n",
      "\n",
      "    accuracy                           0.79     29479\n",
      "   macro avg       0.79      0.76      0.77     29479\n",
      "weighted avg       0.79      0.79      0.78     29479\n",
      "\n",
      "acc:  0.7890023406492758\n",
      "pre:  0.786367057305666\n",
      "rec:  0.6334112756560145\n",
      "ma F1:  0.7692191414641101\n",
      "mi F1:  0.7890023406492758\n",
      "we F1:  0.7838542621682328\n",
      "29479 461\n",
      "Loss:  0.12749074399471283\n",
      "Loss:  0.10197329521179199\n",
      "Loss:  0.12865138053894043\n",
      "3 **********\n",
      "Epoch:  229.37215065956116  fold:  6  kers:  64\n",
      "epoch:  4\n",
      "29479 461\n",
      "Loss:  0.10869719088077545\n",
      "Loss:  0.06877343356609344\n",
      "Loss:  0.09146974980831146\n",
      "4 **********\n",
      "Epoch:  273.1558132171631  fold:  6  kers:  64\n",
      "epoch:  5\n",
      "29479 461\n",
      "Loss:  0.0980348065495491\n",
      "Loss:  0.10149157047271729\n",
      "Loss:  0.08382391929626465\n",
      "5 **********\n",
      "Epoch:  317.01313877105713  fold:  6  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.04934542998671532\n",
      "Eval Loss:  0.29530203342437744\n",
      "Eval Loss:  0.48326432704925537\n",
      "[[2089  143]\n",
      " [ 262  918]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      2232\n",
      "           1       0.87      0.78      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.88      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8813012895662368\n",
      "pre:  0.8652214891611687\n",
      "rec:  0.7779661016949152\n",
      "ma F1:  0.8654535225782028\n",
      "mi F1:  0.8813012895662368\n",
      "we F1:  0.8796907991549849\n",
      "update!  Acc:  0.8813012895662368\n",
      "Eval Loss:  0.39981698989868164\n",
      "Eval Loss:  0.3913097679615021\n",
      "Eval Loss:  0.4510948956012726\n",
      "Eval Loss:  0.4170427918434143\n",
      "Eval Loss:  0.3249830901622772\n",
      "Eval Loss:  0.41510242223739624\n",
      "Eval Loss:  0.4877766966819763\n",
      "Eval Loss:  0.3093249499797821\n",
      "Eval Loss:  0.5236594080924988\n",
      "Eval Loss:  0.5370762348175049\n",
      "Eval Loss:  0.35560110211372375\n",
      "Eval Loss:  0.49715498089790344\n",
      "Eval Loss:  0.472149133682251\n",
      "Eval Loss:  0.46866360306739807\n",
      "Eval Loss:  0.35883933305740356\n",
      "Eval Loss:  0.3783186674118042\n",
      "Eval Loss:  0.4522707462310791\n",
      "Eval Loss:  0.5178927183151245\n",
      "Eval Loss:  0.4535646438598633\n",
      "Eval Loss:  0.4171057939529419\n",
      "Eval Loss:  0.30856314301490784\n",
      "Eval Loss:  0.35633039474487305\n",
      "Eval Loss:  0.42137208580970764\n",
      "Eval Loss:  0.38271141052246094\n",
      "Eval Loss:  0.3377411365509033\n",
      "Eval Loss:  0.43396949768066406\n",
      "Eval Loss:  0.35683098435401917\n",
      "Eval Loss:  0.40343794226646423\n",
      "[[17221   711]\n",
      " [ 4531  7016]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87     17932\n",
      "           1       0.91      0.61      0.73     11547\n",
      "\n",
      "    accuracy                           0.82     29479\n",
      "   macro avg       0.85      0.78      0.80     29479\n",
      "weighted avg       0.84      0.82      0.81     29479\n",
      "\n",
      "acc:  0.8221784999491163\n",
      "pre:  0.9079849877054484\n",
      "rec:  0.6076037065904564\n",
      "ma F1:  0.7979669277297917\n",
      "mi F1:  0.8221784999491162\n",
      "we F1:  0.8131154714456553\n",
      "29479 461\n",
      "Loss:  0.0891837477684021\n",
      "Loss:  0.0630345419049263\n",
      "Loss:  0.07199730724096298\n",
      "6 **********\n",
      "Epoch:  401.6606035232544  fold:  6  kers:  64\n",
      "epoch:  7\n",
      "29479 461\n",
      "Loss:  0.09053553640842438\n",
      "Loss:  0.09169195592403412\n",
      "Loss:  0.08453964442014694\n",
      "7 **********\n",
      "Epoch:  445.565678358078  fold:  6  kers:  64\n",
      "epoch:  8\n",
      "29479 461\n",
      "Loss:  0.09156783670186996\n",
      "Loss:  0.0798635482788086\n",
      "Loss:  0.05159132182598114\n",
      "8 **********\n",
      "Epoch:  489.36556601524353  fold:  6  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.037818439304828644\n",
      "Eval Loss:  0.3361063003540039\n",
      "Eval Loss:  0.42882388830184937\n",
      "[[2116  116]\n",
      " [ 311  869]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      2232\n",
      "           1       0.88      0.74      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.88      0.84      0.86      3412\n",
      "weighted avg       0.88      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8748534583821805\n",
      "pre:  0.8822335025380711\n",
      "rec:  0.7364406779661017\n",
      "ma F1:  0.8555603968975094\n",
      "mi F1:  0.8748534583821805\n",
      "we F1:  0.8718365000906722\n",
      "Eval Loss:  0.3976043164730072\n",
      "Eval Loss:  0.3595026731491089\n",
      "Eval Loss:  0.4443662166595459\n",
      "Eval Loss:  0.375282883644104\n",
      "Eval Loss:  0.3181999921798706\n",
      "Eval Loss:  0.39377453923225403\n",
      "Eval Loss:  0.5343564748764038\n",
      "Eval Loss:  0.3007776439189911\n",
      "Eval Loss:  0.5160605907440186\n",
      "Eval Loss:  0.5009469389915466\n",
      "Eval Loss:  0.3194921910762787\n",
      "Eval Loss:  0.4975613057613373\n",
      "Eval Loss:  0.4536167085170746\n",
      "Eval Loss:  0.4723599851131439\n",
      "Eval Loss:  0.35411351919174194\n",
      "Eval Loss:  0.38963162899017334\n",
      "Eval Loss:  0.44028717279434204\n",
      "Eval Loss:  0.5281592607498169\n",
      "Eval Loss:  0.47163164615631104\n",
      "Eval Loss:  0.4058801829814911\n",
      "Eval Loss:  0.274263471364975\n",
      "Eval Loss:  0.36316409707069397\n",
      "Eval Loss:  0.4133802652359009\n",
      "Eval Loss:  0.3756667971611023\n",
      "Eval Loss:  0.32013076543807983\n",
      "Eval Loss:  0.46481841802597046\n",
      "Eval Loss:  0.34082040190696716\n",
      "Eval Loss:  0.42101261019706726\n",
      "[[17481   451]\n",
      " [ 4727  6820]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     17932\n",
      "           1       0.94      0.59      0.72     11547\n",
      "\n",
      "    accuracy                           0.82     29479\n",
      "   macro avg       0.86      0.78      0.80     29479\n",
      "weighted avg       0.85      0.82      0.81     29479\n",
      "\n",
      "acc:  0.8243495369585129\n",
      "pre:  0.9379727685325264\n",
      "rec:  0.5906296007621027\n",
      "ma F1:  0.7979197079538227\n",
      "mi F1:  0.8243495369585129\n",
      "we F1:  0.8137488476400573\n",
      "29479 461\n",
      "Loss:  0.08887650817632675\n",
      "Loss:  0.07183795422315598\n",
      "Loss:  0.11013557016849518\n",
      "9 **********\n",
      "Epoch:  574.0052568912506  fold:  6  kers:  64\n",
      "epoch:  10\n",
      "29479 461\n",
      "Loss:  0.08962137252092361\n",
      "Loss:  0.07510409504175186\n",
      "Loss:  0.057250015437603\n",
      "10 **********\n",
      "Epoch:  617.7911825180054  fold:  6  kers:  64\n",
      "epoch:  11\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0683475211262703\n",
      "Loss:  0.081648088991642\n",
      "Loss:  0.09674070030450821\n",
      "11 **********\n",
      "Epoch:  661.5850865840912  fold:  6  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.032339029014110565\n",
      "Eval Loss:  0.27516064047813416\n",
      "Eval Loss:  0.4046888053417206\n",
      "[[2086  146]\n",
      " [ 244  936]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      2232\n",
      "           1       0.87      0.79      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.86      0.87      3412\n",
      "weighted avg       0.88      0.89      0.88      3412\n",
      "\n",
      "acc:  0.8856975381008206\n",
      "pre:  0.8650646950092421\n",
      "rec:  0.7932203389830509\n",
      "ma F1:  0.8710486931019366\n",
      "mi F1:  0.8856975381008206\n",
      "we F1:  0.8844492017443939\n",
      "update!  Acc:  0.8856975381008206\n",
      "Eval Loss:  0.3113957345485687\n",
      "Eval Loss:  0.30117282271385193\n",
      "Eval Loss:  0.3642456829547882\n",
      "Eval Loss:  0.3318505585193634\n",
      "Eval Loss:  0.27469196915626526\n",
      "Eval Loss:  0.2855260670185089\n",
      "Eval Loss:  0.47562819719314575\n",
      "Eval Loss:  0.2512546479701996\n",
      "Eval Loss:  0.4265349209308624\n",
      "Eval Loss:  0.42615827918052673\n",
      "Eval Loss:  0.2866789996623993\n",
      "Eval Loss:  0.44159647822380066\n",
      "Eval Loss:  0.3789217472076416\n",
      "Eval Loss:  0.4116009473800659\n",
      "Eval Loss:  0.2958991527557373\n",
      "Eval Loss:  0.3283691108226776\n",
      "Eval Loss:  0.34575551748275757\n",
      "Eval Loss:  0.45749449729919434\n",
      "Eval Loss:  0.40481892228126526\n",
      "Eval Loss:  0.35018375515937805\n",
      "Eval Loss:  0.22805145382881165\n",
      "Eval Loss:  0.3089964687824249\n",
      "Eval Loss:  0.3516436815261841\n",
      "Eval Loss:  0.2937503457069397\n",
      "Eval Loss:  0.2767638564109802\n",
      "Eval Loss:  0.36098936200141907\n",
      "Eval Loss:  0.27077460289001465\n",
      "Eval Loss:  0.37388673424720764\n",
      "[[17390   542]\n",
      " [ 3962  7585]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89     17932\n",
      "           1       0.93      0.66      0.77     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.87      0.81      0.83     29479\n",
      "weighted avg       0.86      0.85      0.84     29479\n",
      "\n",
      "acc:  0.84721327046372\n",
      "pre:  0.9333087240063984\n",
      "rec:  0.6568805750411362\n",
      "ma F1:  0.8282080697157788\n",
      "mi F1:  0.84721327046372\n",
      "we F1:  0.8405842254297619\n",
      "29479 461\n",
      "Loss:  0.10423120111227036\n",
      "Loss:  0.09999502450227737\n",
      "Loss:  0.09150396287441254\n",
      "12 **********\n",
      "Epoch:  746.5936918258667  fold:  6  kers:  64\n",
      "epoch:  13\n",
      "29479 461\n",
      "Loss:  0.10262415558099747\n",
      "Loss:  0.09572256356477737\n",
      "Loss:  0.05935811251401901\n",
      "13 **********\n",
      "Epoch:  790.6159846782684  fold:  6  kers:  64\n",
      "epoch:  14\n",
      "29479 461\n",
      "Loss:  0.09108246862888336\n",
      "Loss:  0.06575655937194824\n",
      "Loss:  0.0617079958319664\n",
      "14 **********\n",
      "Epoch:  834.4767105579376  fold:  6  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.02896430343389511\n",
      "Eval Loss:  0.24200649559497833\n",
      "Eval Loss:  0.4060055911540985\n",
      "[[2109  123]\n",
      " [ 263  917]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      2232\n",
      "           1       0.88      0.78      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.86      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8868698710433763\n",
      "pre:  0.8817307692307692\n",
      "rec:  0.7771186440677966\n",
      "ma F1:  0.8711429935582846\n",
      "mi F1:  0.8868698710433763\n",
      "we F1:  0.885022754560228\n",
      "update!  Acc:  0.8868698710433763\n",
      "Eval Loss:  0.27732399106025696\n",
      "Eval Loss:  0.27663102746009827\n",
      "Eval Loss:  0.32376745343208313\n",
      "Eval Loss:  0.3252655863761902\n",
      "Eval Loss:  0.23606358468532562\n",
      "Eval Loss:  0.2804178297519684\n",
      "Eval Loss:  0.44087696075439453\n",
      "Eval Loss:  0.24646621942520142\n",
      "Eval Loss:  0.37021496891975403\n",
      "Eval Loss:  0.40687310695648193\n",
      "Eval Loss:  0.24810631573200226\n",
      "Eval Loss:  0.40018928050994873\n",
      "Eval Loss:  0.308369904756546\n",
      "Eval Loss:  0.33331093192100525\n",
      "Eval Loss:  0.23751433193683624\n",
      "Eval Loss:  0.2836645543575287\n",
      "Eval Loss:  0.30517974495887756\n",
      "Eval Loss:  0.4385245740413666\n",
      "Eval Loss:  0.35627132654190063\n",
      "Eval Loss:  0.306573748588562\n",
      "Eval Loss:  0.1957295536994934\n",
      "Eval Loss:  0.2848886251449585\n",
      "Eval Loss:  0.3199305236339569\n",
      "Eval Loss:  0.27860525250434875\n",
      "Eval Loss:  0.27239224314689636\n",
      "Eval Loss:  0.31580471992492676\n",
      "Eval Loss:  0.24217194318771362\n",
      "Eval Loss:  0.36035481095314026\n",
      "[[17353   579]\n",
      " [ 3438  8109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     17932\n",
      "           1       0.93      0.70      0.80     11547\n",
      "\n",
      "    accuracy                           0.86     29479\n",
      "   macro avg       0.88      0.83      0.85     29479\n",
      "weighted avg       0.87      0.86      0.86     29479\n",
      "\n",
      "acc:  0.8637335052070966\n",
      "pre:  0.9333563535911602\n",
      "rec:  0.7022603273577552\n",
      "ma F1:  0.8488728912181897\n",
      "mi F1:  0.8637335052070966\n",
      "we F1:  0.8591373893055081\n",
      "29479 461\n",
      "Loss:  0.07167742401361465\n",
      "Loss:  0.09561749547719955\n",
      "Loss:  0.09566103667020798\n",
      "15 **********\n",
      "Epoch:  919.2091529369354  fold:  6  kers:  64\n",
      "epoch:  16\n",
      "29479 461\n",
      "Loss:  0.08834876865148544\n",
      "Loss:  0.03941052034497261\n",
      "Loss:  0.060677945613861084\n",
      "16 **********\n",
      "Epoch:  962.9721393585205  fold:  6  kers:  64\n",
      "epoch:  17\n",
      "29479 461\n",
      "Loss:  0.08357115834951401\n",
      "Loss:  0.04920552670955658\n",
      "Loss:  0.06183970719575882\n",
      "17 **********\n",
      "Epoch:  1006.820897102356  fold:  6  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.029884740710258484\n",
      "Eval Loss:  0.23121006786823273\n",
      "Eval Loss:  0.36876070499420166\n",
      "[[2107  125]\n",
      " [ 251  929]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      2232\n",
      "           1       0.88      0.79      0.83      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.87      0.87      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8898007033997656\n",
      "pre:  0.881404174573055\n",
      "rec:  0.7872881355932203\n",
      "ma F1:  0.8748874104501045\n",
      "mi F1:  0.8898007033997656\n",
      "we F1:  0.8882055634068475\n",
      "update!  Acc:  0.8898007033997656\n",
      "Eval Loss:  0.22502008080482483\n",
      "Eval Loss:  0.24521565437316895\n",
      "Eval Loss:  0.2755516469478607\n",
      "Eval Loss:  0.3124634027481079\n",
      "Eval Loss:  0.2241317182779312\n",
      "Eval Loss:  0.24658460915088654\n",
      "Eval Loss:  0.36301350593566895\n",
      "Eval Loss:  0.23000340163707733\n",
      "Eval Loss:  0.3007184863090515\n",
      "Eval Loss:  0.37307262420654297\n",
      "Eval Loss:  0.21275575459003448\n",
      "Eval Loss:  0.3157171607017517\n",
      "Eval Loss:  0.2692582607269287\n",
      "Eval Loss:  0.2756764590740204\n",
      "Eval Loss:  0.2149851769208908\n",
      "Eval Loss:  0.2582075893878937\n",
      "Eval Loss:  0.2762107253074646\n",
      "Eval Loss:  0.3751848042011261\n",
      "Eval Loss:  0.3228444457054138\n",
      "Eval Loss:  0.278886079788208\n",
      "Eval Loss:  0.19005054235458374\n",
      "Eval Loss:  0.24294526875019073\n",
      "Eval Loss:  0.28901445865631104\n",
      "Eval Loss:  0.26213666796684265\n",
      "Eval Loss:  0.23904135823249817\n",
      "Eval Loss:  0.25752419233322144\n",
      "Eval Loss:  0.2140628844499588\n",
      "Eval Loss:  0.29826295375823975\n",
      "[[17220   712]\n",
      " [ 2825  8722]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     17932\n",
      "           1       0.92      0.76      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.89      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8800162827775705\n",
      "pre:  0.9245283018867925\n",
      "rec:  0.755347709361739\n",
      "ma F1:  0.8691417920356388\n",
      "mi F1:  0.8800162827775705\n",
      "we F1:  0.8773123761009758\n",
      "29479 461\n",
      "Loss:  0.0692947506904602\n",
      "Loss:  0.10446732491254807\n",
      "Loss:  0.08449560403823853\n",
      "18 **********\n",
      "Epoch:  1091.5493505001068  fold:  6  kers:  64\n",
      "epoch:  19\n",
      "29479 461\n",
      "Loss:  0.06161168962717056\n",
      "Loss:  0.06512244790792465\n",
      "Loss:  0.07192173600196838\n",
      "19 **********\n",
      "Epoch:  1135.1697182655334  fold:  6  kers:  64\n",
      "epoch:  20\n",
      "29479 461\n",
      "Loss:  0.07091724127531052\n",
      "Loss:  0.049237508326768875\n",
      "Loss:  0.07981140166521072\n",
      "20 **********\n",
      "Epoch:  1178.8748593330383  fold:  6  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.018318865448236465\n",
      "Eval Loss:  0.26661258935928345\n",
      "Eval Loss:  0.3797047734260559\n",
      "[[2134   98]\n",
      " [ 286  894]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      2232\n",
      "           1       0.90      0.76      0.82      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.89      0.86      0.87      3412\n",
      "weighted avg       0.89      0.89      0.88      3412\n",
      "\n",
      "acc:  0.8874560375146542\n",
      "pre:  0.9012096774193549\n",
      "rec:  0.7576271186440678\n",
      "ma F1:  0.8703296390075201\n",
      "mi F1:  0.8874560375146543\n",
      "we F1:  0.8848594545151854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.25210633873939514\n",
      "Eval Loss:  0.24849069118499756\n",
      "Eval Loss:  0.3052586615085602\n",
      "Eval Loss:  0.32788586616516113\n",
      "Eval Loss:  0.22462047636508942\n",
      "Eval Loss:  0.2666938304901123\n",
      "Eval Loss:  0.3983553946018219\n",
      "Eval Loss:  0.26302236318588257\n",
      "Eval Loss:  0.34084856510162354\n",
      "Eval Loss:  0.4068398177623749\n",
      "Eval Loss:  0.23173488676548004\n",
      "Eval Loss:  0.3546220064163208\n",
      "Eval Loss:  0.3303180932998657\n",
      "Eval Loss:  0.3238900303840637\n",
      "Eval Loss:  0.20781689882278442\n",
      "Eval Loss:  0.26476991176605225\n",
      "Eval Loss:  0.3172987997531891\n",
      "Eval Loss:  0.4087575674057007\n",
      "Eval Loss:  0.33788979053497314\n",
      "Eval Loss:  0.2885213792324066\n",
      "Eval Loss:  0.19341853260993958\n",
      "Eval Loss:  0.24885901808738708\n",
      "Eval Loss:  0.3054371178150177\n",
      "Eval Loss:  0.28267890214920044\n",
      "Eval Loss:  0.24275630712509155\n",
      "Eval Loss:  0.2709766626358032\n",
      "Eval Loss:  0.24144503474235535\n",
      "Eval Loss:  0.3134053945541382\n",
      "[[17397   535]\n",
      " [ 3254  8293]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     17932\n",
      "           1       0.94      0.72      0.81     11547\n",
      "\n",
      "    accuracy                           0.87     29479\n",
      "   macro avg       0.89      0.84      0.86     29479\n",
      "weighted avg       0.88      0.87      0.87     29479\n",
      "\n",
      "acc:  0.8714678245530717\n",
      "pre:  0.9393973719981876\n",
      "rec:  0.718195202217026\n",
      "ma F1:  0.8579164688221346\n",
      "mi F1:  0.8714678245530717\n",
      "we F1:  0.8674205776031135\n",
      "29479 461\n",
      "Loss:  0.047351595014333725\n",
      "Loss:  0.06936246156692505\n",
      "Loss:  0.05475128814578056\n",
      "21 **********\n",
      "Epoch:  1263.3134679794312  fold:  6  kers:  64\n",
      "epoch:  22\n",
      "29479 461\n",
      "Loss:  0.08144787698984146\n",
      "Loss:  0.061923857778310776\n",
      "Loss:  0.05519399791955948\n",
      "22 **********\n",
      "Epoch:  1307.0309360027313  fold:  6  kers:  64\n",
      "epoch:  23\n",
      "29479 461\n",
      "Loss:  0.043018538504838943\n",
      "Loss:  0.08620965480804443\n",
      "Loss:  0.04339102283120155\n",
      "23 **********\n",
      "Epoch:  1350.7789628505707  fold:  6  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.02251116931438446\n",
      "Eval Loss:  0.20305709540843964\n",
      "Eval Loss:  0.32884275913238525\n",
      "[[2084  148]\n",
      " [ 254  926]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      2232\n",
      "           1       0.86      0.78      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.88      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8821805392731535\n",
      "pre:  0.8621973929236499\n",
      "rec:  0.7847457627118644\n",
      "ma F1:  0.866842705115535\n",
      "mi F1:  0.8821805392731535\n",
      "we F1:  0.8807765579081211\n",
      "Eval Loss:  0.1877589076757431\n",
      "Eval Loss:  0.19063176214694977\n",
      "Eval Loss:  0.21735656261444092\n",
      "Eval Loss:  0.2960032820701599\n",
      "Eval Loss:  0.1949969381093979\n",
      "Eval Loss:  0.20055821537971497\n",
      "Eval Loss:  0.35009559988975525\n",
      "Eval Loss:  0.2310958206653595\n",
      "Eval Loss:  0.2490822821855545\n",
      "Eval Loss:  0.33489906787872314\n",
      "Eval Loss:  0.21328102052211761\n",
      "Eval Loss:  0.2649379074573517\n",
      "Eval Loss:  0.2562234401702881\n",
      "Eval Loss:  0.27828991413116455\n",
      "Eval Loss:  0.15616297721862793\n",
      "Eval Loss:  0.21632923185825348\n",
      "Eval Loss:  0.23326006531715393\n",
      "Eval Loss:  0.27404966950416565\n",
      "Eval Loss:  0.2749311923980713\n",
      "Eval Loss:  0.2395789921283722\n",
      "Eval Loss:  0.18708083033561707\n",
      "Eval Loss:  0.20052644610404968\n",
      "Eval Loss:  0.229749858379364\n",
      "Eval Loss:  0.22146329283714294\n",
      "Eval Loss:  0.24078629910945892\n",
      "Eval Loss:  0.21899591386318207\n",
      "Eval Loss:  0.17613598704338074\n",
      "Eval Loss:  0.2591463029384613\n",
      "[[17010   922]\n",
      " [ 2093  9454]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17932\n",
      "           1       0.91      0.82      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.88      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8977238033854609\n",
      "pre:  0.9111410948342329\n",
      "rec:  0.8187407984757946\n",
      "ma F1:  0.8905318620695466\n",
      "mi F1:  0.8977238033854609\n",
      "we F1:  0.8966092238088414\n",
      "29479 461\n",
      "Loss:  0.04911816865205765\n",
      "Loss:  0.05635424703359604\n",
      "Loss:  0.060513779520988464\n",
      "24 **********\n",
      "Epoch:  1435.3134093284607  fold:  6  kers:  64\n",
      "epoch:  25\n",
      "29479 461\n",
      "Loss:  0.0559544712305069\n",
      "Loss:  0.050002653151750565\n",
      "Loss:  0.04881754890084267\n",
      "25 **********\n",
      "Epoch:  1478.9845435619354  fold:  6  kers:  64\n",
      "epoch:  26\n",
      "29479 461\n",
      "Loss:  0.06769854575395584\n",
      "Loss:  0.06403519213199615\n",
      "Loss:  0.06532330065965652\n",
      "26 **********\n",
      "Epoch:  1522.6707122325897  fold:  6  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.015526182949543\n",
      "Eval Loss:  0.2249874323606491\n",
      "Eval Loss:  0.4429210126399994\n",
      "[[2128  104]\n",
      " [ 333  847]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91      2232\n",
      "           1       0.89      0.72      0.79      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.88      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8719226260257913\n",
      "pre:  0.8906414300736067\n",
      "rec:  0.7177966101694915\n",
      "ma F1:  0.8509072739604489\n",
      "mi F1:  0.8719226260257913\n",
      "we F1:  0.8681657832287862\n",
      "Eval Loss:  0.20211119949817657\n",
      "Eval Loss:  0.2006647288799286\n",
      "Eval Loss:  0.24096952378749847\n",
      "Eval Loss:  0.2938905954360962\n",
      "Eval Loss:  0.19641031324863434\n",
      "Eval Loss:  0.18824583292007446\n",
      "Eval Loss:  0.36045172810554504\n",
      "Eval Loss:  0.22390732169151306\n",
      "Eval Loss:  0.2531369924545288\n",
      "Eval Loss:  0.33769890666007996\n",
      "Eval Loss:  0.1939840465784073\n",
      "Eval Loss:  0.2770543694496155\n",
      "Eval Loss:  0.24102085828781128\n",
      "Eval Loss:  0.29442182183265686\n",
      "Eval Loss:  0.16774752736091614\n",
      "Eval Loss:  0.21410337090492249\n",
      "Eval Loss:  0.2282099574804306\n",
      "Eval Loss:  0.31166547536849976\n",
      "Eval Loss:  0.28241991996765137\n",
      "Eval Loss:  0.24262621998786926\n",
      "Eval Loss:  0.17146062850952148\n",
      "Eval Loss:  0.21279053390026093\n",
      "Eval Loss:  0.24576357007026672\n",
      "Eval Loss:  0.23218809068202972\n",
      "Eval Loss:  0.26088666915893555\n",
      "Eval Loss:  0.21355462074279785\n",
      "Eval Loss:  0.18962368369102478\n",
      "Eval Loss:  0.266749769449234\n",
      "[[17172   760]\n",
      " [ 2358  9189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17932\n",
      "           1       0.92      0.80      0.85     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.90      0.88      0.89     29479\n",
      "weighted avg       0.90      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8942297906984633\n",
      "pre:  0.9236104131068449\n",
      "rec:  0.7957911145752143\n",
      "ma F1:  0.885859375336838\n",
      "mi F1:  0.8942297906984633\n",
      "we F1:  0.892554239684073\n",
      "29479 461\n",
      "Loss:  0.04185482859611511\n",
      "Loss:  0.07309278845787048\n",
      "Loss:  0.06931968778371811\n",
      "27 **********\n",
      "Epoch:  1606.9137742519379  fold:  6  kers:  64\n",
      "epoch:  28\n",
      "29479 461\n",
      "Loss:  0.0820283442735672\n",
      "Loss:  0.08065168559551239\n",
      "Loss:  0.07214955240488052\n",
      "28 **********\n",
      "Epoch:  1650.6418552398682  fold:  6  kers:  64\n",
      "epoch:  29\n",
      "29479 461\n",
      "Loss:  0.09974189847707748\n",
      "Loss:  0.07309088855981827\n",
      "Loss:  0.05698385089635849\n",
      "29 **********\n",
      "Epoch:  1694.2702009677887  fold:  6  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.011727645993232727\n",
      "Eval Loss:  0.26352325081825256\n",
      "Eval Loss:  0.28681695461273193\n",
      "[[2082  150]\n",
      " [ 279  901]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      2232\n",
      "           1       0.86      0.76      0.81      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.85      0.86      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8742672919109027\n",
      "pre:  0.857278782112274\n",
      "rec:  0.7635593220338983\n",
      "ma F1:  0.8571532713580181\n",
      "mi F1:  0.8742672919109027\n",
      "we F1:  0.8723979365753208\n",
      "Eval Loss:  0.18370778858661652\n",
      "Eval Loss:  0.2015790492296219\n",
      "Eval Loss:  0.21882717311382294\n",
      "Eval Loss:  0.29159340262413025\n",
      "Eval Loss:  0.20004436373710632\n",
      "Eval Loss:  0.2074470818042755\n",
      "Eval Loss:  0.33848699927330017\n",
      "Eval Loss:  0.22335468232631683\n",
      "Eval Loss:  0.27997735142707825\n",
      "Eval Loss:  0.3263565003871918\n",
      "Eval Loss:  0.21298688650131226\n",
      "Eval Loss:  0.2630055844783783\n",
      "Eval Loss:  0.30069246888160706\n",
      "Eval Loss:  0.3029074966907501\n",
      "Eval Loss:  0.1727566421031952\n",
      "Eval Loss:  0.2115052342414856\n",
      "Eval Loss:  0.2493756115436554\n",
      "Eval Loss:  0.30012500286102295\n",
      "Eval Loss:  0.26823896169662476\n",
      "Eval Loss:  0.23984238505363464\n",
      "Eval Loss:  0.17536987364292145\n",
      "Eval Loss:  0.20192493498325348\n",
      "Eval Loss:  0.23629041016101837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23271125555038452\n",
      "Eval Loss:  0.22750011086463928\n",
      "Eval Loss:  0.1940990537405014\n",
      "Eval Loss:  0.1578993946313858\n",
      "Eval Loss:  0.25201213359832764\n",
      "[[17190   742]\n",
      " [ 2313  9234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     17932\n",
      "           1       0.93      0.80      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.88      0.89     29479\n",
      "weighted avg       0.90      0.90      0.89     29479\n",
      "\n",
      "acc:  0.8963669052545881\n",
      "pre:  0.9256214915797915\n",
      "rec:  0.7996882307092751\n",
      "ma F1:  0.8882253500268684\n",
      "mi F1:  0.8963669052545881\n",
      "we F1:  0.8947592653271436\n",
      "29479 461\n",
      "Loss:  0.06562264263629913\n",
      "Loss:  0.05906664952635765\n",
      "Loss:  0.0799616202712059\n",
      "30 **********\n",
      "Epoch:  1778.6834971904755  fold:  6  kers:  64\n",
      "epoch:  31\n",
      "29479 461\n",
      "Loss:  0.06506197154521942\n",
      "Loss:  0.07370559126138687\n",
      "Loss:  0.06256061792373657\n",
      "31 **********\n",
      "Epoch:  1822.4225482940674  fold:  6  kers:  64\n",
      "epoch:  32\n",
      "29479 461\n",
      "Loss:  0.03378976136445999\n",
      "Loss:  0.06128004193305969\n",
      "Loss:  0.054424431174993515\n",
      "32 **********\n",
      "Epoch:  1866.1246974468231  fold:  6  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.011890788562595844\n",
      "Eval Loss:  0.16258201003074646\n",
      "Eval Loss:  0.3517278730869293\n",
      "[[2099  133]\n",
      " [ 309  871]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      2232\n",
      "           1       0.87      0.74      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8704572098475967\n",
      "pre:  0.8675298804780877\n",
      "rec:  0.738135593220339\n",
      "ma F1:  0.8511802134646962\n",
      "mi F1:  0.8704572098475967\n",
      "we F1:  0.8676943830044448\n",
      "Eval Loss:  0.17833605408668518\n",
      "Eval Loss:  0.18623827397823334\n",
      "Eval Loss:  0.19856767356395721\n",
      "Eval Loss:  0.28644993901252747\n",
      "Eval Loss:  0.18432018160820007\n",
      "Eval Loss:  0.1868377923965454\n",
      "Eval Loss:  0.3109636604785919\n",
      "Eval Loss:  0.2393171489238739\n",
      "Eval Loss:  0.24862860143184662\n",
      "Eval Loss:  0.30588963627815247\n",
      "Eval Loss:  0.21566662192344666\n",
      "Eval Loss:  0.25323987007141113\n",
      "Eval Loss:  0.24217857420444489\n",
      "Eval Loss:  0.28882133960723877\n",
      "Eval Loss:  0.14999602735042572\n",
      "Eval Loss:  0.2174670696258545\n",
      "Eval Loss:  0.19976258277893066\n",
      "Eval Loss:  0.2719711661338806\n",
      "Eval Loss:  0.25845658779144287\n",
      "Eval Loss:  0.22713997960090637\n",
      "Eval Loss:  0.1700337678194046\n",
      "Eval Loss:  0.19069050252437592\n",
      "Eval Loss:  0.22310031950473785\n",
      "Eval Loss:  0.2379368096590042\n",
      "Eval Loss:  0.25781551003456116\n",
      "Eval Loss:  0.1875980794429779\n",
      "Eval Loss:  0.1667855829000473\n",
      "Eval Loss:  0.25489944219589233\n",
      "[[16948   984]\n",
      " [ 1870  9677]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17932\n",
      "           1       0.91      0.84      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.89      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9031853183622239\n",
      "pre:  0.9077009661382609\n",
      "rec:  0.8380531739845848\n",
      "ma F1:  0.8969139441079026\n",
      "mi F1:  0.9031853183622239\n",
      "we F1:  0.9024211266981711\n",
      "29479 461\n",
      "Loss:  0.042803503572940826\n",
      "Loss:  0.07049337029457092\n",
      "Loss:  0.044820286333560944\n",
      "33 **********\n",
      "Epoch:  1950.5689101219177  fold:  6  kers:  64\n",
      "epoch:  34\n",
      "29479 461\n",
      "Loss:  0.091923289000988\n",
      "Loss:  0.03801809996366501\n",
      "Loss:  0.05699783191084862\n",
      "34 **********\n",
      "Epoch:  1994.401710987091  fold:  6  kers:  64\n",
      "epoch:  35\n",
      "29479 461\n",
      "Loss:  0.056523922830820084\n",
      "Loss:  0.06268420070409775\n",
      "Loss:  0.0677604004740715\n",
      "35 **********\n",
      "Epoch:  2038.1178226470947  fold:  6  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.010415296070277691\n",
      "Eval Loss:  0.12420844286680222\n",
      "Eval Loss:  0.30178433656692505\n",
      "[[2074  158]\n",
      " [ 246  934]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      2232\n",
      "           1       0.86      0.79      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8815943728018757\n",
      "pre:  0.8553113553113553\n",
      "rec:  0.7915254237288135\n",
      "ma F1:  0.866715450877497\n",
      "mi F1:  0.8815943728018757\n",
      "we F1:  0.880445824442801\n",
      "Eval Loss:  0.16060981154441833\n",
      "Eval Loss:  0.15978647768497467\n",
      "Eval Loss:  0.18458089232444763\n",
      "Eval Loss:  0.2589930295944214\n",
      "Eval Loss:  0.17925074696540833\n",
      "Eval Loss:  0.1885737180709839\n",
      "Eval Loss:  0.27314329147338867\n",
      "Eval Loss:  0.21493589878082275\n",
      "Eval Loss:  0.21371537446975708\n",
      "Eval Loss:  0.3049112558364868\n",
      "Eval Loss:  0.1987546980381012\n",
      "Eval Loss:  0.2360897958278656\n",
      "Eval Loss:  0.25401076674461365\n",
      "Eval Loss:  0.2575986683368683\n",
      "Eval Loss:  0.12668080627918243\n",
      "Eval Loss:  0.18139521777629852\n",
      "Eval Loss:  0.20948277413845062\n",
      "Eval Loss:  0.2600729167461395\n",
      "Eval Loss:  0.23884791135787964\n",
      "Eval Loss:  0.22134461998939514\n",
      "Eval Loss:  0.1610359400510788\n",
      "Eval Loss:  0.18993744254112244\n",
      "Eval Loss:  0.21303313970565796\n",
      "Eval Loss:  0.23538722097873688\n",
      "Eval Loss:  0.21600010991096497\n",
      "Eval Loss:  0.15933078527450562\n",
      "Eval Loss:  0.1538834422826767\n",
      "Eval Loss:  0.19430337846279144\n",
      "[[17005   927]\n",
      " [ 1760  9787]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     17932\n",
      "           1       0.91      0.85      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.908850368058618\n",
      "pre:  0.913477692738473\n",
      "rec:  0.8475794578678445\n",
      "ma F1:  0.9030371924418872\n",
      "mi F1:  0.9088503680586179\n",
      "we F1:  0.9081794931225226\n",
      "29479 461\n",
      "Loss:  0.05494237691164017\n",
      "Loss:  0.05742509290575981\n",
      "Loss:  0.04224091395735741\n",
      "36 **********\n",
      "Epoch:  2122.575001001358  fold:  6  kers:  64\n",
      "epoch:  37\n",
      "29479 461\n",
      "Loss:  0.06311164796352386\n",
      "Loss:  0.054957661777734756\n",
      "Loss:  0.07110689580440521\n",
      "37 **********\n",
      "Epoch:  2166.2781484127045  fold:  6  kers:  64\n",
      "epoch:  38\n",
      "29479 461\n",
      "Loss:  0.051892876625061035\n",
      "Loss:  0.04220481961965561\n",
      "Loss:  0.06474284827709198\n",
      "38 **********\n",
      "Epoch:  2209.9773049354553  fold:  6  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.006517135072499514\n",
      "Eval Loss:  0.21748626232147217\n",
      "Eval Loss:  0.30492711067199707\n",
      "[[2129  103]\n",
      " [ 355  825]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      2232\n",
      "           1       0.89      0.70      0.78      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.83      0.84      3412\n",
      "weighted avg       0.87      0.87      0.86      3412\n",
      "\n",
      "acc:  0.865767878077374\n",
      "pre:  0.8890086206896551\n",
      "rec:  0.6991525423728814\n",
      "ma F1:  0.8428081238241008\n",
      "mi F1:  0.865767878077374\n",
      "we F1:  0.8613308703535818\n",
      "Eval Loss:  0.18825997412204742\n",
      "Eval Loss:  0.19286738336086273\n",
      "Eval Loss:  0.20702622830867767\n",
      "Eval Loss:  0.2913518249988556\n",
      "Eval Loss:  0.17231203615665436\n",
      "Eval Loss:  0.18405365943908691\n",
      "Eval Loss:  0.3137626647949219\n",
      "Eval Loss:  0.22621968388557434\n",
      "Eval Loss:  0.23089434206485748\n",
      "Eval Loss:  0.30803439021110535\n",
      "Eval Loss:  0.20328618586063385\n",
      "Eval Loss:  0.2408413141965866\n",
      "Eval Loss:  0.2607477307319641\n",
      "Eval Loss:  0.305993914604187\n",
      "Eval Loss:  0.13565565645694733\n",
      "Eval Loss:  0.19808833301067352\n",
      "Eval Loss:  0.24256572127342224\n",
      "Eval Loss:  0.281371146440506\n",
      "Eval Loss:  0.28082919120788574\n",
      "Eval Loss:  0.21348148584365845\n",
      "Eval Loss:  0.16883689165115356\n",
      "Eval Loss:  0.20343497395515442\n",
      "Eval Loss:  0.23791927099227905\n",
      "Eval Loss:  0.23934917151927948\n",
      "Eval Loss:  0.220517098903656\n",
      "Eval Loss:  0.1809367686510086\n",
      "Eval Loss:  0.16562201082706451\n",
      "Eval Loss:  0.23596201837062836\n",
      "[[17290   642]\n",
      " [ 2245  9302]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     17932\n",
      "           1       0.94      0.81      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.91      0.88      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9020658774042539\n",
      "pre:  0.9354384553499597\n",
      "rec:  0.8055772062007448\n",
      "ma F1:  0.8943051111227629\n",
      "mi F1:  0.902065877404254\n",
      "we F1:  0.9005084777611355\n",
      "29479 461\n",
      "Loss:  0.08198382705450058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05635882914066315\n",
      "Loss:  0.11597996205091476\n",
      "39 **********\n",
      "Epoch:  2294.3965849876404  fold:  6  kers:  64\n",
      "epoch:  40\n",
      "29479 461\n",
      "Loss:  0.04103963449597359\n",
      "Loss:  0.03239286690950394\n",
      "Loss:  0.05706159397959709\n",
      "40 **********\n",
      "Epoch:  2338.1166863441467  fold:  6  kers:  64\n",
      "epoch:  41\n",
      "29479 461\n",
      "Loss:  0.07712407410144806\n",
      "Loss:  0.04823921620845795\n",
      "Loss:  0.04587782174348831\n",
      "41 **********\n",
      "Epoch:  2381.8477590084076  fold:  6  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.007043694145977497\n",
      "Eval Loss:  0.17355464398860931\n",
      "Eval Loss:  0.2934514880180359\n",
      "[[2099  133]\n",
      " [ 301  879]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91      2232\n",
      "           1       0.87      0.74      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8728018757327081\n",
      "pre:  0.8685770750988142\n",
      "rec:  0.7449152542372881\n",
      "ma F1:  0.8541556358181108\n",
      "mi F1:  0.8728018757327081\n",
      "we F1:  0.8702341967936488\n",
      "Eval Loss:  0.13742828369140625\n",
      "Eval Loss:  0.1727994680404663\n",
      "Eval Loss:  0.20766720175743103\n",
      "Eval Loss:  0.2600611448287964\n",
      "Eval Loss:  0.16558825969696045\n",
      "Eval Loss:  0.20761770009994507\n",
      "Eval Loss:  0.26283177733421326\n",
      "Eval Loss:  0.21544158458709717\n",
      "Eval Loss:  0.24417459964752197\n",
      "Eval Loss:  0.28027230501174927\n",
      "Eval Loss:  0.20777368545532227\n",
      "Eval Loss:  0.218657985329628\n",
      "Eval Loss:  0.272388756275177\n",
      "Eval Loss:  0.24490375816822052\n",
      "Eval Loss:  0.12403509020805359\n",
      "Eval Loss:  0.20444032549858093\n",
      "Eval Loss:  0.21196672320365906\n",
      "Eval Loss:  0.25711503624916077\n",
      "Eval Loss:  0.2223494052886963\n",
      "Eval Loss:  0.21586717665195465\n",
      "Eval Loss:  0.16572442650794983\n",
      "Eval Loss:  0.17985330522060394\n",
      "Eval Loss:  0.20586907863616943\n",
      "Eval Loss:  0.2023535817861557\n",
      "Eval Loss:  0.1899692416191101\n",
      "Eval Loss:  0.14618968963623047\n",
      "Eval Loss:  0.1507985144853592\n",
      "Eval Loss:  0.2079523652791977\n",
      "[[17132   800]\n",
      " [ 1854  9693]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     17932\n",
      "           1       0.92      0.84      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9099698090165881\n",
      "pre:  0.9237586962737063\n",
      "rec:  0.8394388152766953\n",
      "ma F1:  0.9038467628606254\n",
      "mi F1:  0.9099698090165881\n",
      "we F1:  0.9091022608718933\n",
      "29479 461\n",
      "Loss:  0.049524419009685516\n",
      "Loss:  0.060653604567050934\n",
      "Loss:  0.0833396464586258\n",
      "42 **********\n",
      "Epoch:  2466.0925056934357  fold:  6  kers:  64\n",
      "epoch:  43\n",
      "29479 461\n",
      "Loss:  0.08414370566606522\n",
      "Loss:  0.0781908631324768\n",
      "Loss:  0.08158957213163376\n",
      "43 **********\n",
      "Epoch:  2509.7727138996124  fold:  6  kers:  64\n",
      "epoch:  44\n",
      "29479 461\n",
      "Loss:  0.05288521572947502\n",
      "Loss:  0.07876259088516235\n",
      "Loss:  0.06447955220937729\n",
      "44 **********\n",
      "Epoch:  2553.4509267807007  fold:  6  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.009828868322074413\n",
      "Eval Loss:  0.11274231970310211\n",
      "Eval Loss:  0.2825171947479248\n",
      "[[2054  178]\n",
      " [ 274  906]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      2232\n",
      "           1       0.84      0.77      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8675263774912075\n",
      "pre:  0.8357933579335793\n",
      "rec:  0.7677966101694915\n",
      "ma F1:  0.8506152749364577\n",
      "mi F1:  0.8675263774912075\n",
      "we F1:  0.8661122086364549\n",
      "Eval Loss:  0.12776245176792145\n",
      "Eval Loss:  0.17621244490146637\n",
      "Eval Loss:  0.19179540872573853\n",
      "Eval Loss:  0.2567180097103119\n",
      "Eval Loss:  0.1570994257926941\n",
      "Eval Loss:  0.20145387947559357\n",
      "Eval Loss:  0.2714497745037079\n",
      "Eval Loss:  0.20835168659687042\n",
      "Eval Loss:  0.24083025753498077\n",
      "Eval Loss:  0.26032909750938416\n",
      "Eval Loss:  0.21770134568214417\n",
      "Eval Loss:  0.2152417153120041\n",
      "Eval Loss:  0.24877852201461792\n",
      "Eval Loss:  0.24806666374206543\n",
      "Eval Loss:  0.12467415630817413\n",
      "Eval Loss:  0.20464178919792175\n",
      "Eval Loss:  0.1824917048215866\n",
      "Eval Loss:  0.2239965945482254\n",
      "Eval Loss:  0.20037806034088135\n",
      "Eval Loss:  0.20503896474838257\n",
      "Eval Loss:  0.175545334815979\n",
      "Eval Loss:  0.19881393015384674\n",
      "Eval Loss:  0.19680821895599365\n",
      "Eval Loss:  0.21459665894508362\n",
      "Eval Loss:  0.19797180593013763\n",
      "Eval Loss:  0.14162389934062958\n",
      "Eval Loss:  0.1625605821609497\n",
      "Eval Loss:  0.2020568698644638\n",
      "[[16877  1055]\n",
      " [ 1574  9973]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     17932\n",
      "           1       0.90      0.86      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.90      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9108178703483836\n",
      "pre:  0.9043344214726151\n",
      "rec:  0.8636875378886291\n",
      "ma F1:  0.9056423605039396\n",
      "mi F1:  0.9108178703483836\n",
      "we F1:  0.9104288075428698\n",
      "29479 461\n",
      "Loss:  0.052855413407087326\n",
      "Loss:  0.051926009356975555\n",
      "Loss:  0.054848261177539825\n",
      "45 **********\n",
      "Epoch:  2637.789422750473  fold:  6  kers:  64\n",
      "epoch:  46\n",
      "29479 461\n",
      "Loss:  0.07781171798706055\n",
      "Loss:  0.030630571767687798\n",
      "Loss:  0.03592156618833542\n",
      "46 **********\n",
      "Epoch:  2681.4127826690674  fold:  6  kers:  64\n",
      "epoch:  47\n",
      "29479 461\n",
      "Loss:  0.07099135220050812\n",
      "Loss:  0.062154363840818405\n",
      "Loss:  0.0557740144431591\n",
      "47 **********\n",
      "Epoch:  2725.1104197502136  fold:  6  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.010797157883644104\n",
      "Eval Loss:  0.14096900820732117\n",
      "Eval Loss:  0.2996780574321747\n",
      "[[2037  195]\n",
      " [ 275  905]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      2232\n",
      "           1       0.82      0.77      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.85      0.84      0.85      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8622508792497069\n",
      "pre:  0.8227272727272728\n",
      "rec:  0.7669491525423728\n",
      "ma F1:  0.845213275265629\n",
      "mi F1:  0.8622508792497069\n",
      "we F1:  0.8610468082967685\n",
      "Eval Loss:  0.13370372354984283\n",
      "Eval Loss:  0.17739294469356537\n",
      "Eval Loss:  0.19650296866893768\n",
      "Eval Loss:  0.25635600090026855\n",
      "Eval Loss:  0.16559100151062012\n",
      "Eval Loss:  0.19151164591312408\n",
      "Eval Loss:  0.25901395082473755\n",
      "Eval Loss:  0.17459797859191895\n",
      "Eval Loss:  0.23302051424980164\n",
      "Eval Loss:  0.2619537115097046\n",
      "Eval Loss:  0.2174989879131317\n",
      "Eval Loss:  0.20242220163345337\n",
      "Eval Loss:  0.2427353858947754\n",
      "Eval Loss:  0.22968709468841553\n",
      "Eval Loss:  0.14565952122211456\n",
      "Eval Loss:  0.19931140542030334\n",
      "Eval Loss:  0.17770341038703918\n",
      "Eval Loss:  0.2231251299381256\n",
      "Eval Loss:  0.1930163949728012\n",
      "Eval Loss:  0.19482074677944183\n",
      "Eval Loss:  0.16398406028747559\n",
      "Eval Loss:  0.18917906284332275\n",
      "Eval Loss:  0.1983570158481598\n",
      "Eval Loss:  0.20107267796993256\n",
      "Eval Loss:  0.21720319986343384\n",
      "Eval Loss:  0.13404245674610138\n",
      "Eval Loss:  0.1525411605834961\n",
      "Eval Loss:  0.17828857898712158\n",
      "[[16892  1040]\n",
      " [ 1475 10072]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     17932\n",
      "           1       0.91      0.87      0.89     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.91      0.91     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9146850300213711\n",
      "pre:  0.906407487401008\n",
      "rec:  0.8722611933835628\n",
      "ma F1:  0.9098604602506764\n",
      "mi F1:  0.9146850300213711\n",
      "we F1:  0.9143773045301317\n",
      "29479 461\n",
      "Loss:  0.06324080377817154\n",
      "Loss:  0.054338905960321426\n",
      "Loss:  0.05098268389701843\n",
      "48 **********\n",
      "Epoch:  2809.55544757843  fold:  6  kers:  64\n",
      "epoch:  49\n",
      "29479 461\n",
      "Loss:  0.0550372451543808\n",
      "Loss:  0.05182288959622383\n",
      "Loss:  0.07366804778575897\n",
      "49 **********\n",
      "Epoch:  2853.241639614105  fold:  6  kers:  64\n",
      "epoch:  50\n",
      "29479 461\n",
      "Loss:  0.050126224756240845\n",
      "Loss:  0.045762524008750916\n",
      "Loss:  0.05367770418524742\n",
      "50 **********\n",
      "Epoch:  2896.972711801529  fold:  6  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.008298064582049847\n",
      "Eval Loss:  0.20490311086177826\n",
      "Eval Loss:  0.30404403805732727\n",
      "[[2103  129]\n",
      " [ 334  846]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      2232\n",
      "           1       0.87      0.72      0.79      1180\n",
      "\n",
      "    accuracy                           0.86      3412\n",
      "   macro avg       0.87      0.83      0.84      3412\n",
      "weighted avg       0.86      0.86      0.86      3412\n",
      "\n",
      "acc:  0.8643024618991794\n",
      "pre:  0.8676923076923077\n",
      "rec:  0.7169491525423729\n",
      "ma F1:  0.8429930543511803\n",
      "mi F1:  0.8643024618991794\n",
      "we F1:  0.8608271806363791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1334172934293747\n",
      "Eval Loss:  0.17060144245624542\n",
      "Eval Loss:  0.18795998394489288\n",
      "Eval Loss:  0.23888131976127625\n",
      "Eval Loss:  0.14417579770088196\n",
      "Eval Loss:  0.18017491698265076\n",
      "Eval Loss:  0.23450249433517456\n",
      "Eval Loss:  0.18888795375823975\n",
      "Eval Loss:  0.1850605458021164\n",
      "Eval Loss:  0.24982020258903503\n",
      "Eval Loss:  0.2027091234922409\n",
      "Eval Loss:  0.19539520144462585\n",
      "Eval Loss:  0.25688159465789795\n",
      "Eval Loss:  0.23014988005161285\n",
      "Eval Loss:  0.11962371319532394\n",
      "Eval Loss:  0.17080862820148468\n",
      "Eval Loss:  0.19561386108398438\n",
      "Eval Loss:  0.23637855052947998\n",
      "Eval Loss:  0.18862780928611755\n",
      "Eval Loss:  0.17891830205917358\n",
      "Eval Loss:  0.154351606965065\n",
      "Eval Loss:  0.17999768257141113\n",
      "Eval Loss:  0.18964649736881256\n",
      "Eval Loss:  0.19730672240257263\n",
      "Eval Loss:  0.19639834761619568\n",
      "Eval Loss:  0.13799700140953064\n",
      "Eval Loss:  0.1487235575914383\n",
      "Eval Loss:  0.1779433786869049\n",
      "[[17096   836]\n",
      " [ 1577  9970]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     17932\n",
      "           1       0.92      0.86      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9181451202550969\n",
      "pre:  0.9226355728299093\n",
      "rec:  0.8634277301463583\n",
      "ma F1:  0.9130651638940377\n",
      "mi F1:  0.9181451202550969\n",
      "we F1:  0.9176168789326796\n",
      "29479 461\n",
      "Loss:  0.05248574540019035\n",
      "Loss:  0.06546642631292343\n",
      "Loss:  0.051887765526771545\n",
      "51 **********\n",
      "Epoch:  2981.3191866874695  fold:  6  kers:  64\n",
      "epoch:  52\n",
      "29479 461\n",
      "Loss:  0.05796394497156143\n",
      "Loss:  0.07890036702156067\n",
      "Loss:  0.04832838475704193\n",
      "52 **********\n",
      "Epoch:  3024.9744613170624  fold:  6  kers:  64\n",
      "epoch:  53\n",
      "29479 461\n",
      "Loss:  0.08398783206939697\n",
      "Loss:  0.05820128321647644\n",
      "Loss:  0.033356163650751114\n",
      "53 **********\n",
      "Epoch:  3068.6048023700714  fold:  6  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.011032860726118088\n",
      "Eval Loss:  0.16605855524539948\n",
      "Eval Loss:  0.3143489360809326\n",
      "[[2126  106]\n",
      " [ 347  833]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      2232\n",
      "           1       0.89      0.71      0.79      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.83      0.84      3412\n",
      "weighted avg       0.87      0.87      0.86      3412\n",
      "\n",
      "acc:  0.8672332942555686\n",
      "pre:  0.8871139510117146\n",
      "rec:  0.7059322033898305\n",
      "ma F1:  0.8449696812253289\n",
      "mi F1:  0.8672332942555686\n",
      "we F1:  0.8630836185090196\n",
      "Eval Loss:  0.13314807415008545\n",
      "Eval Loss:  0.17059071362018585\n",
      "Eval Loss:  0.18615233898162842\n",
      "Eval Loss:  0.27093076705932617\n",
      "Eval Loss:  0.14419013261795044\n",
      "Eval Loss:  0.196872279047966\n",
      "Eval Loss:  0.24266904592514038\n",
      "Eval Loss:  0.17343513667583466\n",
      "Eval Loss:  0.17635692656040192\n",
      "Eval Loss:  0.24343405663967133\n",
      "Eval Loss:  0.20340418815612793\n",
      "Eval Loss:  0.18978849053382874\n",
      "Eval Loss:  0.2133363038301468\n",
      "Eval Loss:  0.21974007785320282\n",
      "Eval Loss:  0.1222897619009018\n",
      "Eval Loss:  0.17778778076171875\n",
      "Eval Loss:  0.1776941865682602\n",
      "Eval Loss:  0.23266348242759705\n",
      "Eval Loss:  0.2034839391708374\n",
      "Eval Loss:  0.17281454801559448\n",
      "Eval Loss:  0.15313264727592468\n",
      "Eval Loss:  0.1891573965549469\n",
      "Eval Loss:  0.1840517520904541\n",
      "Eval Loss:  0.2018056958913803\n",
      "Eval Loss:  0.1955011636018753\n",
      "Eval Loss:  0.1378621906042099\n",
      "Eval Loss:  0.16478267312049866\n",
      "Eval Loss:  0.17811159789562225\n",
      "[[17018   914]\n",
      " [ 1491 10056]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     17932\n",
      "           1       0.92      0.87      0.89     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.91      0.91     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9184164998812714\n",
      "pre:  0.9166818596171377\n",
      "rec:  0.8708755520914523\n",
      "ma F1:  0.9135973597217353\n",
      "mi F1:  0.9184164998812714\n",
      "we F1:  0.9180170968545476\n",
      "29479 461\n",
      "Loss:  0.06919359415769577\n",
      "Loss:  0.0488257072865963\n",
      "Loss:  0.06470797955989838\n",
      "54 **********\n",
      "Epoch:  3152.9792020320892  fold:  6  kers:  64\n",
      "epoch:  55\n",
      "29479 461\n",
      "Loss:  0.05634063482284546\n",
      "Loss:  0.0527440570294857\n",
      "Loss:  0.035156987607479095\n",
      "55 **********\n",
      "Epoch:  3196.5706474781036  fold:  6  kers:  64\n",
      "epoch:  56\n",
      "29479 461\n",
      "Loss:  0.07032342255115509\n",
      "Loss:  0.06674729287624359\n",
      "Loss:  0.07667206972837448\n",
      "56 **********\n",
      "Epoch:  3240.164087533951  fold:  6  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.011186040006577969\n",
      "Eval Loss:  0.14511564373970032\n",
      "Eval Loss:  0.3159341514110565\n",
      "[[2067  165]\n",
      " [ 244  936]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      2232\n",
      "           1       0.85      0.79      0.82      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.86      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8801289566236812\n",
      "pre:  0.8501362397820164\n",
      "rec:  0.7932203389830509\n",
      "ma F1:  0.8653320315986854\n",
      "mi F1:  0.8801289566236812\n",
      "we F1:  0.8790953959897513\n",
      "Eval Loss:  0.13035932183265686\n",
      "Eval Loss:  0.1770593374967575\n",
      "Eval Loss:  0.17817385494709015\n",
      "Eval Loss:  0.2372831404209137\n",
      "Eval Loss:  0.1435755491256714\n",
      "Eval Loss:  0.19017064571380615\n",
      "Eval Loss:  0.2441110610961914\n",
      "Eval Loss:  0.16614031791687012\n",
      "Eval Loss:  0.2012268304824829\n",
      "Eval Loss:  0.2475970983505249\n",
      "Eval Loss:  0.20236045122146606\n",
      "Eval Loss:  0.1940864622592926\n",
      "Eval Loss:  0.22165687382221222\n",
      "Eval Loss:  0.20268821716308594\n",
      "Eval Loss:  0.12664978206157684\n",
      "Eval Loss:  0.16709308326244354\n",
      "Eval Loss:  0.15703880786895752\n",
      "Eval Loss:  0.22721630334854126\n",
      "Eval Loss:  0.19247344136238098\n",
      "Eval Loss:  0.18616996705532074\n",
      "Eval Loss:  0.15642735362052917\n",
      "Eval Loss:  0.17126858234405518\n",
      "Eval Loss:  0.20094025135040283\n",
      "Eval Loss:  0.18035688996315002\n",
      "Eval Loss:  0.19519297778606415\n",
      "Eval Loss:  0.10984554886817932\n",
      "Eval Loss:  0.14349575340747833\n",
      "Eval Loss:  0.16353268921375275\n",
      "[[16895  1037]\n",
      " [ 1289 10258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     17932\n",
      "           1       0.91      0.89      0.90     11547\n",
      "\n",
      "    accuracy                           0.92     29479\n",
      "   macro avg       0.92      0.92      0.92     29479\n",
      "weighted avg       0.92      0.92      0.92     29479\n",
      "\n",
      "acc:  0.9210963736897453\n",
      "pre:  0.9081894643647632\n",
      "rec:  0.8883692734043475\n",
      "ma F1:  0.9168832246063428\n",
      "mi F1:  0.9210963736897453\n",
      "we F1:  0.9209364047928013\n",
      "29479 461\n",
      "Loss:  0.046461742371320724\n",
      "Loss:  0.03993121162056923\n",
      "Loss:  0.052273012697696686\n",
      "57 **********\n",
      "Epoch:  3324.557436943054  fold:  6  kers:  64\n",
      "epoch:  58\n",
      "29479 461\n",
      "Loss:  0.051038868725299835\n",
      "Loss:  0.07607275247573853\n",
      "Loss:  0.05367908626794815\n",
      "58 **********\n",
      "Epoch:  3368.2575919628143  fold:  6  kers:  64\n",
      "epoch:  59\n",
      "29479 461\n",
      "Loss:  0.08121688663959503\n",
      "Loss:  0.05071524158120155\n",
      "Loss:  0.06981972604990005\n",
      "59 **********\n",
      "Epoch:  3411.979687690735  fold:  6  kers:  64\n",
      "Eval Loss:  0.008114608004689217\n",
      "Eval Loss:  0.18737511336803436\n",
      "Eval Loss:  0.3010692894458771\n",
      "[[2111  121]\n",
      " [ 318  862]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      2232\n",
      "           1       0.88      0.73      0.80      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.87      0.84      0.85      3412\n",
      "weighted avg       0.87      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8713364595545134\n",
      "pre:  0.8769074262461851\n",
      "rec:  0.7305084745762712\n",
      "ma F1:  0.8514276747582238\n",
      "mi F1:  0.8713364595545134\n",
      "we F1:  0.8681963229613436\n",
      "update!  Acc:  0.8898007033997656\n",
      "Epoch:  3416.1964132785797  fold:  6  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.16980792582035065\n",
      "Loss:  0.16336099803447723\n",
      "Loss:  0.14710186421871185\n",
      "0 **********\n",
      "Epoch:  56.668479204177856  fold:  7  kers:  64\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.13028527796268463\n",
      "Loss:  0.13771285116672516\n",
      "Loss:  0.09815096110105515\n",
      "1 **********\n",
      "Epoch:  100.60699653625488  fold:  7  kers:  64\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.09484244138002396\n",
      "Loss:  0.09589570760726929\n",
      "Loss:  0.10328377038240433\n",
      "2 **********\n",
      "Epoch:  144.44777536392212  fold:  7  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.7062596082687378\n",
      "Eval Loss:  0.21134448051452637\n",
      "Eval Loss:  1.400739073753357\n",
      "[[1580  547]\n",
      " [ 531  773]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75      2127\n",
      "           1       0.59      0.59      0.59      1304\n",
      "\n",
      "    accuracy                           0.69      3431\n",
      "   macro avg       0.67      0.67      0.67      3431\n",
      "weighted avg       0.69      0.69      0.69      3431\n",
      "\n",
      "acc:  0.6858058874963567\n",
      "pre:  0.5856060606060606\n",
      "rec:  0.5927914110429447\n",
      "ma F1:  0.6674057813165437\n",
      "mi F1:  0.6858058874963567\n",
      "we F1:  0.6861706975321399\n",
      "update!  Acc:  0.6858058874963567\n",
      "Eval Loss:  0.40512561798095703\n",
      "Eval Loss:  0.3165261745452881\n",
      "Eval Loss:  0.3380354940891266\n",
      "Eval Loss:  0.4513039290904999\n",
      "Eval Loss:  0.32888272404670715\n",
      "Eval Loss:  0.4394983947277069\n",
      "Eval Loss:  0.4080941677093506\n",
      "Eval Loss:  0.3221202492713928\n",
      "Eval Loss:  0.32772448658943176\n",
      "Eval Loss:  0.3248979449272156\n",
      "Eval Loss:  0.32906806468963623\n",
      "Eval Loss:  0.3031253516674042\n",
      "Eval Loss:  0.41684460639953613\n",
      "Eval Loss:  0.32937148213386536\n",
      "Eval Loss:  0.4052068889141083\n",
      "Eval Loss:  0.3866133391857147\n",
      "Eval Loss:  0.36271774768829346\n",
      "Eval Loss:  0.4502902925014496\n",
      "Eval Loss:  0.32745683193206787\n",
      "Eval Loss:  0.3859627842903137\n",
      "Eval Loss:  0.36794888973236084\n",
      "Eval Loss:  0.3554067611694336\n",
      "Eval Loss:  0.3314424455165863\n",
      "Eval Loss:  0.42478787899017334\n",
      "Eval Loss:  0.3102792203426361\n",
      "Eval Loss:  0.4108670949935913\n",
      "Eval Loss:  0.3695305585861206\n",
      "Eval Loss:  0.35006797313690186\n",
      "[[15291  2746]\n",
      " [ 2003  9420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87     18037\n",
      "           1       0.77      0.82      0.80     11423\n",
      "\n",
      "    accuracy                           0.84     29460\n",
      "   macro avg       0.83      0.84      0.83     29460\n",
      "weighted avg       0.84      0.84      0.84     29460\n",
      "\n",
      "acc:  0.8387983706720977\n",
      "pre:  0.7742890021371034\n",
      "rec:  0.8246520178587061\n",
      "ma F1:  0.8321314064015364\n",
      "mi F1:  0.8387983706720977\n",
      "we F1:  0.8396421033331483\n",
      "29460 461\n",
      "Loss:  0.090784452855587\n",
      "Loss:  0.08708925545215607\n",
      "Loss:  0.0931958332657814\n",
      "3 **********\n",
      "Epoch:  229.6589379310608  fold:  7  kers:  64\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.1082167774438858\n",
      "Loss:  0.1293543428182602\n",
      "Loss:  0.09051509201526642\n",
      "4 **********\n",
      "Epoch:  273.66726875305176  fold:  7  kers:  64\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.08546410501003265\n",
      "Loss:  0.13719408214092255\n",
      "Loss:  0.10049157589673996\n",
      "5 **********\n",
      "Epoch:  317.5060522556305  fold:  7  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.8619346022605896\n",
      "Eval Loss:  0.13933797180652618\n",
      "Eval Loss:  2.398383855819702\n",
      "[[2016  111]\n",
      " [ 848  456]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81      2127\n",
      "           1       0.80      0.35      0.49      1304\n",
      "\n",
      "    accuracy                           0.72      3431\n",
      "   macro avg       0.75      0.65      0.65      3431\n",
      "weighted avg       0.74      0.72      0.69      3431\n",
      "\n",
      "acc:  0.7204896531623434\n",
      "pre:  0.8042328042328042\n",
      "rec:  0.3496932515337423\n",
      "ma F1:  0.6476470045868775\n",
      "mi F1:  0.7204896531623433\n",
      "we F1:  0.6860761711109855\n",
      "update!  Acc:  0.7204896531623434\n",
      "Eval Loss:  0.46016523241996765\n",
      "Eval Loss:  0.32982903718948364\n",
      "Eval Loss:  0.3793538510799408\n",
      "Eval Loss:  0.4475747048854828\n",
      "Eval Loss:  0.28487345576286316\n",
      "Eval Loss:  0.4580357074737549\n",
      "Eval Loss:  0.461193710565567\n",
      "Eval Loss:  0.32640770077705383\n",
      "Eval Loss:  0.32155200839042664\n",
      "Eval Loss:  0.33246731758117676\n",
      "Eval Loss:  0.28739485144615173\n",
      "Eval Loss:  0.29702457785606384\n",
      "Eval Loss:  0.4109266400337219\n",
      "Eval Loss:  0.32025834918022156\n",
      "Eval Loss:  0.38400065898895264\n",
      "Eval Loss:  0.36645931005477905\n",
      "Eval Loss:  0.3489311933517456\n",
      "Eval Loss:  0.39758893847465515\n",
      "Eval Loss:  0.29830479621887207\n",
      "Eval Loss:  0.41280755400657654\n",
      "Eval Loss:  0.3896839916706085\n",
      "Eval Loss:  0.3814367651939392\n",
      "Eval Loss:  0.31141266226768494\n",
      "Eval Loss:  0.41705256700515747\n",
      "Eval Loss:  0.2953128218650818\n",
      "Eval Loss:  0.41943714022636414\n",
      "Eval Loss:  0.49017056822776794\n",
      "Eval Loss:  0.3391505181789398\n",
      "[[17250   787]\n",
      " [ 3512  7911]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18037\n",
      "           1       0.91      0.69      0.79     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.87      0.82      0.84     29460\n",
      "weighted avg       0.86      0.85      0.85     29460\n",
      "\n",
      "acc:  0.8540733197556009\n",
      "pre:  0.9095194297539664\n",
      "rec:  0.692550118182614\n",
      "ma F1:  0.837770401158355\n",
      "mi F1:  0.8540733197556009\n",
      "we F1:  0.8493163379398287\n",
      "29460 461\n",
      "Loss:  0.10704896599054337\n",
      "Loss:  0.07667077332735062\n",
      "Loss:  0.0779937133193016\n",
      "6 **********\n",
      "Epoch:  402.38709807395935  fold:  7  kers:  64\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.07854365557432175\n",
      "Loss:  0.0980655625462532\n",
      "Loss:  0.06861516833305359\n",
      "7 **********\n",
      "Epoch:  446.15307664871216  fold:  7  kers:  64\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.11451085656881332\n",
      "Loss:  0.06648624688386917\n",
      "Loss:  0.07681333273649216\n",
      "8 **********\n",
      "Epoch:  489.87616991996765  fold:  7  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.6286152005195618\n",
      "Eval Loss:  0.21545526385307312\n",
      "Eval Loss:  1.8190882205963135\n",
      "[[1946  181]\n",
      " [ 686  618]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82      2127\n",
      "           1       0.77      0.47      0.59      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.69      0.70      3431\n",
      "weighted avg       0.75      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7473039930049549\n",
      "pre:  0.7734668335419274\n",
      "rec:  0.47392638036809814\n",
      "ma F1:  0.7027753406039882\n",
      "mi F1:  0.7473039930049548\n",
      "we F1:  0.7303710340723584\n",
      "update!  Acc:  0.7473039930049549\n",
      "Eval Loss:  0.4000905454158783\n",
      "Eval Loss:  0.252402663230896\n",
      "Eval Loss:  0.2448316514492035\n",
      "Eval Loss:  0.31704390048980713\n",
      "Eval Loss:  0.25070735812187195\n",
      "Eval Loss:  0.3659250736236572\n",
      "Eval Loss:  0.36153727769851685\n",
      "Eval Loss:  0.24068647623062134\n",
      "Eval Loss:  0.28382137417793274\n",
      "Eval Loss:  0.2675202190876007\n",
      "Eval Loss:  0.22686460614204407\n",
      "Eval Loss:  0.1960112452507019\n",
      "Eval Loss:  0.3299870193004608\n",
      "Eval Loss:  0.266963928937912\n",
      "Eval Loss:  0.2994126081466675\n",
      "Eval Loss:  0.31160569190979004\n",
      "Eval Loss:  0.2798997759819031\n",
      "Eval Loss:  0.3563961684703827\n",
      "Eval Loss:  0.27511993050575256\n",
      "Eval Loss:  0.33487260341644287\n",
      "Eval Loss:  0.29309993982315063\n",
      "Eval Loss:  0.3061239719390869\n",
      "Eval Loss:  0.26298797130584717\n",
      "Eval Loss:  0.32951486110687256\n",
      "Eval Loss:  0.2534412145614624\n",
      "Eval Loss:  0.33728209137916565\n",
      "Eval Loss:  0.374711811542511\n",
      "Eval Loss:  0.2817438840866089\n",
      "[[16860  1177]\n",
      " [ 2441  8982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     18037\n",
      "           1       0.88      0.79      0.83     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.88      0.86      0.87     29460\n",
      "weighted avg       0.88      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8771894093686354\n",
      "pre:  0.8841421399744069\n",
      "rec:  0.786308325308588\n",
      "ma F1:  0.8677308491448696\n",
      "mi F1:  0.8771894093686354\n",
      "we F1:  0.8756718135165359\n",
      "29460 461\n",
      "Loss:  0.06570728868246078\n",
      "Loss:  0.08100110292434692\n",
      "Loss:  0.08902119100093842\n",
      "9 **********\n",
      "Epoch:  574.3333485126495  fold:  7  kers:  64\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.06928311288356781\n",
      "Loss:  0.09289498627185822\n",
      "Loss:  0.08373242616653442\n",
      "10 **********\n",
      "Epoch:  618.094322681427  fold:  7  kers:  64\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07533161342144012\n",
      "Loss:  0.07147708535194397\n",
      "Loss:  0.10204943269491196\n",
      "11 **********\n",
      "Epoch:  661.8433468341827  fold:  7  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  1.005646824836731\n",
      "Eval Loss:  0.08281362801790237\n",
      "Eval Loss:  2.8746001720428467\n",
      "[[2070   57]\n",
      " [ 928  376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81      2127\n",
      "           1       0.87      0.29      0.43      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.78      0.63      0.62      3431\n",
      "weighted avg       0.76      0.71      0.67      3431\n",
      "\n",
      "acc:  0.7129116875546488\n",
      "pre:  0.8683602771362586\n",
      "rec:  0.2883435582822086\n",
      "ma F1:  0.6203676088574357\n",
      "mi F1:  0.7129116875546487\n",
      "we F1:  0.6653285160403202\n",
      "Eval Loss:  0.4670485556125641\n",
      "Eval Loss:  0.3401625454425812\n",
      "Eval Loss:  0.41791272163391113\n",
      "Eval Loss:  0.4149775803089142\n",
      "Eval Loss:  0.28113648295402527\n",
      "Eval Loss:  0.46136870980262756\n",
      "Eval Loss:  0.4567681849002838\n",
      "Eval Loss:  0.33301082253456116\n",
      "Eval Loss:  0.33771583437919617\n",
      "Eval Loss:  0.3288298547267914\n",
      "Eval Loss:  0.32799476385116577\n",
      "Eval Loss:  0.30742761492729187\n",
      "Eval Loss:  0.4581669270992279\n",
      "Eval Loss:  0.3438459038734436\n",
      "Eval Loss:  0.34085285663604736\n",
      "Eval Loss:  0.4196467399597168\n",
      "Eval Loss:  0.3690972328186035\n",
      "Eval Loss:  0.39534977078437805\n",
      "Eval Loss:  0.2748430371284485\n",
      "Eval Loss:  0.4366235136985779\n",
      "Eval Loss:  0.4017193019390106\n",
      "Eval Loss:  0.40902289748191833\n",
      "Eval Loss:  0.32809212803840637\n",
      "Eval Loss:  0.43526938557624817\n",
      "Eval Loss:  0.3488115668296814\n",
      "Eval Loss:  0.4139212965965271\n",
      "Eval Loss:  0.5099035501480103\n",
      "Eval Loss:  0.34492164850234985\n",
      "[[17623   414]\n",
      " [ 4033  7390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89     18037\n",
      "           1       0.95      0.65      0.77     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.88      0.81      0.83     29460\n",
      "weighted avg       0.87      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8490495587236931\n",
      "pre:  0.9469502819067145\n",
      "rec:  0.6469403834369255\n",
      "ma F1:  0.8283378998409454\n",
      "mi F1:  0.8490495587236931\n",
      "we F1:  0.8417246790699587\n",
      "29460 461\n",
      "Loss:  0.08954776078462601\n",
      "Loss:  0.06917504221200943\n",
      "Loss:  0.0642520859837532\n",
      "12 **********\n",
      "Epoch:  746.3035175800323  fold:  7  kers:  64\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.03906993195414543\n",
      "Loss:  0.06006760522723198\n",
      "Loss:  0.059182725846767426\n",
      "13 **********\n",
      "Epoch:  789.9358532428741  fold:  7  kers:  64\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.061267901211977005\n",
      "Loss:  0.06491386145353317\n",
      "Loss:  0.08435370028018951\n",
      "14 **********\n",
      "Epoch:  833.6020984649658  fold:  7  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.7928205728530884\n",
      "Eval Loss:  0.08578641712665558\n",
      "Eval Loss:  2.543494701385498\n",
      "[[2067   60]\n",
      " [ 874  430]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.82      2127\n",
      "           1       0.88      0.33      0.48      1304\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.79      0.65      0.65      3431\n",
      "weighted avg       0.77      0.73      0.69      3431\n",
      "\n",
      "acc:  0.7277761585543573\n",
      "pre:  0.8775510204081632\n",
      "rec:  0.32975460122699385\n",
      "ma F1:  0.6475410449107302\n",
      "mi F1:  0.7277761585543573\n",
      "we F1:  0.6878791625214236\n",
      "Eval Loss:  0.40464258193969727\n",
      "Eval Loss:  0.27857524156570435\n",
      "Eval Loss:  0.2854919731616974\n",
      "Eval Loss:  0.3139728605747223\n",
      "Eval Loss:  0.27140626311302185\n",
      "Eval Loss:  0.3971919119358063\n",
      "Eval Loss:  0.37544530630111694\n",
      "Eval Loss:  0.2563232481479645\n",
      "Eval Loss:  0.3124506175518036\n",
      "Eval Loss:  0.2833995223045349\n",
      "Eval Loss:  0.2732360363006592\n",
      "Eval Loss:  0.25113993883132935\n",
      "Eval Loss:  0.41122326254844666\n",
      "Eval Loss:  0.29203471541404724\n",
      "Eval Loss:  0.3136124312877655\n",
      "Eval Loss:  0.3505557179450989\n",
      "Eval Loss:  0.3378376066684723\n",
      "Eval Loss:  0.35208427906036377\n",
      "Eval Loss:  0.2515968084335327\n",
      "Eval Loss:  0.36866626143455505\n",
      "Eval Loss:  0.31955966353416443\n",
      "Eval Loss:  0.33875542879104614\n",
      "Eval Loss:  0.2769714295864105\n",
      "Eval Loss:  0.3789612352848053\n",
      "Eval Loss:  0.28036025166511536\n",
      "Eval Loss:  0.3411175310611725\n",
      "Eval Loss:  0.44332975149154663\n",
      "Eval Loss:  0.28604796528816223\n",
      "[[17513   524]\n",
      " [ 3377  8046]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     18037\n",
      "           1       0.94      0.70      0.80     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.89      0.84      0.85     29460\n",
      "weighted avg       0.88      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8675831636116769\n",
      "pre:  0.9388564760793465\n",
      "rec:  0.7043683795850477\n",
      "ma F1:  0.8523342444909023\n",
      "mi F1:  0.8675831636116769\n",
      "we F1:  0.8629877092701146\n",
      "29460 461\n",
      "Loss:  0.05721455439925194\n",
      "Loss:  0.0649091973900795\n",
      "Loss:  0.07254404574632645\n",
      "15 **********\n",
      "Epoch:  917.8378694057465  fold:  7  kers:  64\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.0672975555062294\n",
      "Loss:  0.06194474175572395\n",
      "Loss:  0.0684940442442894\n",
      "16 **********\n",
      "Epoch:  961.4482641220093  fold:  7  kers:  64\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.0721844881772995\n",
      "Loss:  0.07920226454734802\n",
      "Loss:  0.0870995745062828\n",
      "17 **********\n",
      "Epoch:  1005.0666377544403  fold:  7  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.6449143290519714\n",
      "Eval Loss:  0.10761243104934692\n",
      "Eval Loss:  2.1959891319274902\n",
      "[[2011  116]\n",
      " [ 730  574]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.83      2127\n",
      "           1       0.83      0.44      0.58      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.69      0.70      3431\n",
      "weighted avg       0.77      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7534246575342466\n",
      "pre:  0.8318840579710145\n",
      "rec:  0.4401840490797546\n",
      "ma F1:  0.7009695891289315\n",
      "mi F1:  0.7534246575342466\n",
      "we F1:  0.7310117055503471\n",
      "update!  Acc:  0.7534246575342466\n",
      "Eval Loss:  0.3551076352596283\n",
      "Eval Loss:  0.23499184846878052\n",
      "Eval Loss:  0.200680673122406\n",
      "Eval Loss:  0.23512311279773712\n",
      "Eval Loss:  0.247950479388237\n",
      "Eval Loss:  0.3299397826194763\n",
      "Eval Loss:  0.31676048040390015\n",
      "Eval Loss:  0.19402314722537994\n",
      "Eval Loss:  0.2697640359401703\n",
      "Eval Loss:  0.2449709177017212\n",
      "Eval Loss:  0.22694183886051178\n",
      "Eval Loss:  0.20160633325576782\n",
      "Eval Loss:  0.3247377276420593\n",
      "Eval Loss:  0.2656162977218628\n",
      "Eval Loss:  0.2639240026473999\n",
      "Eval Loss:  0.31967538595199585\n",
      "Eval Loss:  0.3044978976249695\n",
      "Eval Loss:  0.2918635308742523\n",
      "Eval Loss:  0.254565566778183\n",
      "Eval Loss:  0.3055045008659363\n",
      "Eval Loss:  0.26018330454826355\n",
      "Eval Loss:  0.271620512008667\n",
      "Eval Loss:  0.22194074094295502\n",
      "Eval Loss:  0.29406097531318665\n",
      "Eval Loss:  0.22979575395584106\n",
      "Eval Loss:  0.2688561677932739\n",
      "Eval Loss:  0.33842599391937256\n",
      "Eval Loss:  0.2516007721424103\n",
      "[[17228   809]\n",
      " [ 2430  8993]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91     18037\n",
      "           1       0.92      0.79      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8900543109300747\n",
      "pre:  0.9174658233013671\n",
      "rec:  0.7872712947561936\n",
      "ma F1:  0.880735211060319\n",
      "mi F1:  0.8900543109300747\n",
      "we F1:  0.8882199137365259\n",
      "29460 461\n",
      "Loss:  0.06750789284706116\n",
      "Loss:  0.06908521056175232\n",
      "Loss:  0.06344866752624512\n",
      "18 **********\n",
      "Epoch:  1089.5746808052063  fold:  7  kers:  64\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.045647017657756805\n",
      "Loss:  0.07229606062173843\n",
      "Loss:  0.06642170250415802\n",
      "19 **********\n",
      "Epoch:  1133.3077466487885  fold:  7  kers:  64\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.06274840235710144\n",
      "Loss:  0.07294941693544388\n",
      "Loss:  0.041797589510679245\n",
      "20 **********\n",
      "Epoch:  1177.0760962963104  fold:  7  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.5981931686401367\n",
      "Eval Loss:  0.16126705706119537\n",
      "Eval Loss:  2.0315663814544678\n",
      "[[1931  196]\n",
      " [ 652  652]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82      2127\n",
      "           1       0.77      0.50      0.61      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.70      0.71      3431\n",
      "weighted avg       0.76      0.75      0.74      3431\n",
      "\n",
      "acc:  0.7528417371028855\n",
      "pre:  0.7688679245283019\n",
      "rec:  0.5\n",
      "ma F1:  0.7129527462726619\n",
      "mi F1:  0.7528417371028855\n",
      "we F1:  0.7386201735230716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3379649519920349\n",
      "Eval Loss:  0.21836385130882263\n",
      "Eval Loss:  0.1636641025543213\n",
      "Eval Loss:  0.21288998425006866\n",
      "Eval Loss:  0.24791577458381653\n",
      "Eval Loss:  0.30131492018699646\n",
      "Eval Loss:  0.281747967004776\n",
      "Eval Loss:  0.17163300514221191\n",
      "Eval Loss:  0.24395111203193665\n",
      "Eval Loss:  0.22724542021751404\n",
      "Eval Loss:  0.17798541486263275\n",
      "Eval Loss:  0.1785229742527008\n",
      "Eval Loss:  0.2873977720737457\n",
      "Eval Loss:  0.2434203326702118\n",
      "Eval Loss:  0.24617761373519897\n",
      "Eval Loss:  0.29574844241142273\n",
      "Eval Loss:  0.26143890619277954\n",
      "Eval Loss:  0.2785983383655548\n",
      "Eval Loss:  0.25701776146888733\n",
      "Eval Loss:  0.28612637519836426\n",
      "Eval Loss:  0.23169808089733124\n",
      "Eval Loss:  0.2420782446861267\n",
      "Eval Loss:  0.2037985920906067\n",
      "Eval Loss:  0.2656099796295166\n",
      "Eval Loss:  0.20389424264431\n",
      "Eval Loss:  0.2555772662162781\n",
      "Eval Loss:  0.29662805795669556\n",
      "Eval Loss:  0.2510731518268585\n",
      "[[16980  1057]\n",
      " [ 1907  9516]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18037\n",
      "           1       0.90      0.83      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.8993890020366598\n",
      "pre:  0.9000283741605978\n",
      "rec:  0.8330561148559923\n",
      "ma F1:  0.892487616887592\n",
      "mi F1:  0.8993890020366598\n",
      "we F1:  0.8986030725917634\n",
      "29460 461\n",
      "Loss:  0.06554406881332397\n",
      "Loss:  0.06853079050779343\n",
      "Loss:  0.08275826275348663\n",
      "21 **********\n",
      "Epoch:  1266.1070454120636  fold:  7  kers:  64\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.06538106501102448\n",
      "Loss:  0.06505801528692245\n",
      "Loss:  0.06108824908733368\n",
      "22 **********\n",
      "Epoch:  1309.9528114795685  fold:  7  kers:  64\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.06540846079587936\n",
      "Loss:  0.05508030205965042\n",
      "Loss:  0.05908643454313278\n",
      "23 **********\n",
      "Epoch:  1353.7686567306519  fold:  7  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.6134587526321411\n",
      "Eval Loss:  0.13397908210754395\n",
      "Eval Loss:  1.9884979724884033\n",
      "[[1919  208]\n",
      " [ 642  662]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82      2127\n",
      "           1       0.76      0.51      0.61      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.76      0.70      0.71      3431\n",
      "weighted avg       0.75      0.75      0.74      3431\n",
      "\n",
      "acc:  0.7522588166715244\n",
      "pre:  0.7609195402298851\n",
      "rec:  0.5076687116564417\n",
      "ma F1:  0.7138508231001818\n",
      "mi F1:  0.7522588166715244\n",
      "we F1:  0.7389978228688491\n",
      "Eval Loss:  0.31348928809165955\n",
      "Eval Loss:  0.23172761499881744\n",
      "Eval Loss:  0.1783422827720642\n",
      "Eval Loss:  0.21900106966495514\n",
      "Eval Loss:  0.2376173585653305\n",
      "Eval Loss:  0.30899083614349365\n",
      "Eval Loss:  0.2717764377593994\n",
      "Eval Loss:  0.1658451408147812\n",
      "Eval Loss:  0.22602905333042145\n",
      "Eval Loss:  0.23329532146453857\n",
      "Eval Loss:  0.2048918455839157\n",
      "Eval Loss:  0.17786867916584015\n",
      "Eval Loss:  0.2813742160797119\n",
      "Eval Loss:  0.2549249529838562\n",
      "Eval Loss:  0.24090103805065155\n",
      "Eval Loss:  0.30992749333381653\n",
      "Eval Loss:  0.2625126540660858\n",
      "Eval Loss:  0.27953052520751953\n",
      "Eval Loss:  0.24896670877933502\n",
      "Eval Loss:  0.2882555425167084\n",
      "Eval Loss:  0.23825865983963013\n",
      "Eval Loss:  0.25165244936943054\n",
      "Eval Loss:  0.19292870163917542\n",
      "Eval Loss:  0.27281829714775085\n",
      "Eval Loss:  0.20772217214107513\n",
      "Eval Loss:  0.23953953385353088\n",
      "Eval Loss:  0.2945832312107086\n",
      "Eval Loss:  0.2507125437259674\n",
      "[[17125   912]\n",
      " [ 2026  9397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18037\n",
      "           1       0.91      0.82      0.86     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9002715546503733\n",
      "pre:  0.911533611407508\n",
      "rec:  0.8226385362864397\n",
      "ma F1:  0.8929018385665218\n",
      "mi F1:  0.9002715546503733\n",
      "we F1:  0.89920920168487\n",
      "29460 461\n",
      "Loss:  0.07146316021680832\n",
      "Loss:  0.061156921088695526\n",
      "Loss:  0.0603707879781723\n",
      "24 **********\n",
      "Epoch:  1438.5050888061523  fold:  7  kers:  64\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.05625427886843681\n",
      "Loss:  0.05743696540594101\n",
      "Loss:  0.07457367330789566\n",
      "25 **********\n",
      "Epoch:  1482.333898305893  fold:  7  kers:  64\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.05841252952814102\n",
      "Loss:  0.061261337250471115\n",
      "Loss:  0.055694326758384705\n",
      "26 **********\n",
      "Epoch:  1526.1427628993988  fold:  7  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.6922432780265808\n",
      "Eval Loss:  0.08069209009408951\n",
      "Eval Loss:  2.5480051040649414\n",
      "[[1962  165]\n",
      " [ 748  556]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81      2127\n",
      "           1       0.77      0.43      0.55      1304\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.75      0.67      0.68      3431\n",
      "weighted avg       0.74      0.73      0.71      3431\n",
      "\n",
      "acc:  0.7338968230836491\n",
      "pre:  0.7711511789181692\n",
      "rec:  0.4263803680981595\n",
      "ma F1:  0.6801912214743859\n",
      "mi F1:  0.7338968230836491\n",
      "we F1:  0.7116277151617426\n",
      "Eval Loss:  0.3153463304042816\n",
      "Eval Loss:  0.2321949452161789\n",
      "Eval Loss:  0.2028397023677826\n",
      "Eval Loss:  0.2502967417240143\n",
      "Eval Loss:  0.23614269495010376\n",
      "Eval Loss:  0.34921392798423767\n",
      "Eval Loss:  0.27788761258125305\n",
      "Eval Loss:  0.17351670563220978\n",
      "Eval Loss:  0.24102061986923218\n",
      "Eval Loss:  0.21680207550525665\n",
      "Eval Loss:  0.1953454613685608\n",
      "Eval Loss:  0.19856299459934235\n",
      "Eval Loss:  0.3064074218273163\n",
      "Eval Loss:  0.27390530705451965\n",
      "Eval Loss:  0.23765884339809418\n",
      "Eval Loss:  0.30823564529418945\n",
      "Eval Loss:  0.26427528262138367\n",
      "Eval Loss:  0.333709716796875\n",
      "Eval Loss:  0.2171313464641571\n",
      "Eval Loss:  0.2970377504825592\n",
      "Eval Loss:  0.26825934648513794\n",
      "Eval Loss:  0.26090341806411743\n",
      "Eval Loss:  0.19828999042510986\n",
      "Eval Loss:  0.31381359696388245\n",
      "Eval Loss:  0.22804884612560272\n",
      "Eval Loss:  0.2730197012424469\n",
      "Eval Loss:  0.33192071318626404\n",
      "Eval Loss:  0.2706006169319153\n",
      "[[17315   722]\n",
      " [ 2388  9035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18037\n",
      "           1       0.93      0.79      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8944331296673456\n",
      "pre:  0.9260018448293533\n",
      "rec:  0.7909480871925063\n",
      "ma F1:  0.8853787131574167\n",
      "mi F1:  0.8944331296673456\n",
      "we F1:  0.8926113110797198\n",
      "29460 461\n",
      "Loss:  0.07535760849714279\n",
      "Loss:  0.03949996083974838\n",
      "Loss:  0.045224323868751526\n",
      "27 **********\n",
      "Epoch:  1610.8702189922333  fold:  7  kers:  64\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.07028395682573318\n",
      "Loss:  0.06645261496305466\n",
      "Loss:  0.05221723020076752\n",
      "28 **********\n",
      "Epoch:  1654.6451754570007  fold:  7  kers:  64\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.07330021262168884\n",
      "Loss:  0.09533266723155975\n",
      "Loss:  0.06505955755710602\n",
      "29 **********\n",
      "Epoch:  1698.4520437717438  fold:  7  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.555746853351593\n",
      "Eval Loss:  0.1600189059972763\n",
      "Eval Loss:  1.958605408668518\n",
      "[[1884  243]\n",
      " [ 567  737]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82      2127\n",
      "           1       0.75      0.57      0.65      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.73      0.73      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7639172252987467\n",
      "pre:  0.7520408163265306\n",
      "rec:  0.5651840490797546\n",
      "ma F1:  0.7342129303399567\n",
      "mi F1:  0.7639172252987467\n",
      "we F1:  0.755526474150841\n",
      "update!  Acc:  0.7639172252987467\n",
      "Eval Loss:  0.3230348825454712\n",
      "Eval Loss:  0.20894218981266022\n",
      "Eval Loss:  0.14556199312210083\n",
      "Eval Loss:  0.20898759365081787\n",
      "Eval Loss:  0.21641956269741058\n",
      "Eval Loss:  0.3119705021381378\n",
      "Eval Loss:  0.24336853623390198\n",
      "Eval Loss:  0.13831056654453278\n",
      "Eval Loss:  0.21109674870967865\n",
      "Eval Loss:  0.20026357471942902\n",
      "Eval Loss:  0.18659409880638123\n",
      "Eval Loss:  0.18962419033050537\n",
      "Eval Loss:  0.2518264949321747\n",
      "Eval Loss:  0.23514370620250702\n",
      "Eval Loss:  0.2152496576309204\n",
      "Eval Loss:  0.29894936084747314\n",
      "Eval Loss:  0.22976399958133698\n",
      "Eval Loss:  0.25938111543655396\n",
      "Eval Loss:  0.23611757159233093\n",
      "Eval Loss:  0.26572558283805847\n",
      "Eval Loss:  0.22417844831943512\n",
      "Eval Loss:  0.228735089302063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.15425720810890198\n",
      "Eval Loss:  0.2487364411354065\n",
      "Eval Loss:  0.1827702671289444\n",
      "Eval Loss:  0.24421149492263794\n",
      "Eval Loss:  0.25887447595596313\n",
      "Eval Loss:  0.2316236048936844\n",
      "[[16933  1104]\n",
      " [ 1558  9865]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18037\n",
      "           1       0.90      0.86      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9096401900882553\n",
      "pre:  0.8993527213054973\n",
      "rec:  0.8636085091482097\n",
      "ma F1:  0.9041213271212405\n",
      "mi F1:  0.9096401900882554\n",
      "we F1:  0.9092856960606627\n",
      "29460 461\n",
      "Loss:  0.052311889827251434\n",
      "Loss:  0.09920202940702438\n",
      "Loss:  0.05951973795890808\n",
      "30 **********\n",
      "Epoch:  1783.092730998993  fold:  7  kers:  64\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.036597855389118195\n",
      "Loss:  0.0739327222108841\n",
      "Loss:  0.07603208720684052\n",
      "31 **********\n",
      "Epoch:  1826.8417546749115  fold:  7  kers:  64\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.08320719748735428\n",
      "Loss:  0.05811832845211029\n",
      "Loss:  0.07840458303689957\n",
      "32 **********\n",
      "Epoch:  1870.578810930252  fold:  7  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.5971895456314087\n",
      "Eval Loss:  0.13307417929172516\n",
      "Eval Loss:  2.009852170944214\n",
      "[[1898  229]\n",
      " [ 576  728]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83      2127\n",
      "           1       0.76      0.56      0.64      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.76      0.73      0.73      3431\n",
      "weighted avg       0.76      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7653745263771495\n",
      "pre:  0.7607105538140021\n",
      "rec:  0.558282208588957\n",
      "ma F1:  0.7345004417534753\n",
      "mi F1:  0.7653745263771495\n",
      "we F1:  0.756217853416111\n",
      "update!  Acc:  0.7653745263771495\n",
      "Eval Loss:  0.3060617446899414\n",
      "Eval Loss:  0.1933770328760147\n",
      "Eval Loss:  0.14637047052383423\n",
      "Eval Loss:  0.21819381415843964\n",
      "Eval Loss:  0.20508785545825958\n",
      "Eval Loss:  0.3006160259246826\n",
      "Eval Loss:  0.23826199769973755\n",
      "Eval Loss:  0.12838798761367798\n",
      "Eval Loss:  0.22165681421756744\n",
      "Eval Loss:  0.19571848213672638\n",
      "Eval Loss:  0.16880321502685547\n",
      "Eval Loss:  0.18050900101661682\n",
      "Eval Loss:  0.25574252009391785\n",
      "Eval Loss:  0.24009503424167633\n",
      "Eval Loss:  0.22463925182819366\n",
      "Eval Loss:  0.28784358501434326\n",
      "Eval Loss:  0.22169463336467743\n",
      "Eval Loss:  0.23219525814056396\n",
      "Eval Loss:  0.2276521474123001\n",
      "Eval Loss:  0.25457414984703064\n",
      "Eval Loss:  0.2121277004480362\n",
      "Eval Loss:  0.21552683413028717\n",
      "Eval Loss:  0.15403829514980316\n",
      "Eval Loss:  0.2515387237071991\n",
      "Eval Loss:  0.16135001182556152\n",
      "Eval Loss:  0.24369531869888306\n",
      "Eval Loss:  0.262524276971817\n",
      "Eval Loss:  0.22800682485103607\n",
      "[[17058   979]\n",
      " [ 1651  9772]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18037\n",
      "           1       0.91      0.86      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9107264086897489\n",
      "pre:  0.9089387033764301\n",
      "rec:  0.8554670401820887\n",
      "ma F1:  0.904910102972217\n",
      "mi F1:  0.9107264086897489\n",
      "we F1:  0.910189961058376\n",
      "29460 461\n",
      "Loss:  0.05703474581241608\n",
      "Loss:  0.06710366904735565\n",
      "Loss:  0.07432850450277328\n",
      "33 **********\n",
      "Epoch:  1955.2753500938416  fold:  7  kers:  64\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.07727503031492233\n",
      "Loss:  0.04219783470034599\n",
      "Loss:  0.07710888981819153\n",
      "34 **********\n",
      "Epoch:  1999.053296327591  fold:  7  kers:  64\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.047964226454496384\n",
      "Loss:  0.046360667794942856\n",
      "Loss:  0.08070479333400726\n",
      "35 **********\n",
      "Epoch:  2042.8112959861755  fold:  7  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.5559938549995422\n",
      "Eval Loss:  0.06362685561180115\n",
      "Eval Loss:  1.8605908155441284\n",
      "[[1929  198]\n",
      " [ 627  677]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82      2127\n",
      "           1       0.77      0.52      0.62      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.71      0.72      3431\n",
      "weighted avg       0.76      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7595453220635383\n",
      "pre:  0.7737142857142857\n",
      "rec:  0.5191717791411042\n",
      "ma F1:  0.7226084172517411\n",
      "mi F1:  0.7595453220635383\n",
      "we F1:  0.7468888267246716\n",
      "Eval Loss:  0.3057686984539032\n",
      "Eval Loss:  0.21346431970596313\n",
      "Eval Loss:  0.1751570701599121\n",
      "Eval Loss:  0.25421643257141113\n",
      "Eval Loss:  0.24961619079113007\n",
      "Eval Loss:  0.3235247731208801\n",
      "Eval Loss:  0.2532530725002289\n",
      "Eval Loss:  0.1433238834142685\n",
      "Eval Loss:  0.24432724714279175\n",
      "Eval Loss:  0.20176635682582855\n",
      "Eval Loss:  0.18728727102279663\n",
      "Eval Loss:  0.1741083860397339\n",
      "Eval Loss:  0.27088382840156555\n",
      "Eval Loss:  0.24401111900806427\n",
      "Eval Loss:  0.20275753736495972\n",
      "Eval Loss:  0.30020153522491455\n",
      "Eval Loss:  0.22524377703666687\n",
      "Eval Loss:  0.31946733593940735\n",
      "Eval Loss:  0.22144019603729248\n",
      "Eval Loss:  0.26724597811698914\n",
      "Eval Loss:  0.2186383754014969\n",
      "Eval Loss:  0.25020095705986023\n",
      "Eval Loss:  0.17554248869419098\n",
      "Eval Loss:  0.2844964265823364\n",
      "Eval Loss:  0.18335439264774323\n",
      "Eval Loss:  0.24871592223644257\n",
      "Eval Loss:  0.26165634393692017\n",
      "Eval Loss:  0.24697190523147583\n",
      "[[17298   739]\n",
      " [ 2017  9406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18037\n",
      "           1       0.93      0.82      0.87     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.906449422946368\n",
      "pre:  0.9271562345983243\n",
      "rec:  0.8234264203799352\n",
      "ma F1:  0.8992167822934654\n",
      "mi F1:  0.906449422946368\n",
      "we F1:  0.9052781970524997\n",
      "29460 461\n",
      "Loss:  0.033966101706027985\n",
      "Loss:  0.04955120012164116\n",
      "Loss:  0.041327059268951416\n",
      "36 **********\n",
      "Epoch:  2127.269472837448  fold:  7  kers:  64\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.06349597126245499\n",
      "Loss:  0.04734162613749504\n",
      "Loss:  0.06185325235128403\n",
      "37 **********\n",
      "Epoch:  2171.0204911231995  fold:  7  kers:  64\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.07153569906949997\n",
      "Loss:  0.057226214557886124\n",
      "Loss:  0.05143295228481293\n",
      "38 **********\n",
      "Epoch:  2214.6887304782867  fold:  7  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.5231567621231079\n",
      "Eval Loss:  0.14607064425945282\n",
      "Eval Loss:  1.015133261680603\n",
      "[[1754  373]\n",
      " [ 427  877]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      2127\n",
      "           1       0.70      0.67      0.69      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7668318274555523\n",
      "pre:  0.7016\n",
      "rec:  0.6725460122699386\n",
      "ma F1:  0.7505324180614239\n",
      "mi F1:  0.7668318274555523\n",
      "we F1:  0.7658282150185137\n",
      "update!  Acc:  0.7668318274555523\n",
      "Eval Loss:  0.3015177249908447\n",
      "Eval Loss:  0.2119848132133484\n",
      "Eval Loss:  0.1295143961906433\n",
      "Eval Loss:  0.21593990921974182\n",
      "Eval Loss:  0.2158702313899994\n",
      "Eval Loss:  0.28680577874183655\n",
      "Eval Loss:  0.23799075186252594\n",
      "Eval Loss:  0.12277728319168091\n",
      "Eval Loss:  0.20097975432872772\n",
      "Eval Loss:  0.1981678605079651\n",
      "Eval Loss:  0.16943641006946564\n",
      "Eval Loss:  0.18796932697296143\n",
      "Eval Loss:  0.2348291575908661\n",
      "Eval Loss:  0.20479834079742432\n",
      "Eval Loss:  0.24009910225868225\n",
      "Eval Loss:  0.2749001979827881\n",
      "Eval Loss:  0.22964945435523987\n",
      "Eval Loss:  0.2777863144874573\n",
      "Eval Loss:  0.25038328766822815\n",
      "Eval Loss:  0.2526722550392151\n",
      "Eval Loss:  0.17982518672943115\n",
      "Eval Loss:  0.21373531222343445\n",
      "Eval Loss:  0.15270352363586426\n",
      "Eval Loss:  0.24740968644618988\n",
      "Eval Loss:  0.1720033437013626\n",
      "Eval Loss:  0.2337978184223175\n",
      "Eval Loss:  0.23167265951633453\n",
      "Eval Loss:  0.22584450244903564\n",
      "[[16608  1429]\n",
      " [ 1160 10263]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     18037\n",
      "           1       0.88      0.90      0.89     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9121181262729124\n",
      "pre:  0.8777796784125899\n",
      "rec:  0.8984504946161254\n",
      "ma F1:  0.9078432358707003\n",
      "mi F1:  0.9121181262729124\n",
      "we F1:  0.9122993627612017\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06555237621068954\n",
      "Loss:  0.04276733472943306\n",
      "Loss:  0.05099937319755554\n",
      "39 **********\n",
      "Epoch:  2299.5248963832855  fold:  7  kers:  64\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.08319881558418274\n",
      "Loss:  0.03665397688746452\n",
      "Loss:  0.021779173985123634\n",
      "40 **********\n",
      "Epoch:  2343.169200181961  fold:  7  kers:  64\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.043868064880371094\n",
      "Loss:  0.06181439384818077\n",
      "Loss:  0.07146953046321869\n",
      "41 **********\n",
      "Epoch:  2386.9072535037994  fold:  7  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.5774862170219421\n",
      "Eval Loss:  0.1369742602109909\n",
      "Eval Loss:  1.3408631086349487\n",
      "[[1822  305]\n",
      " [ 500  804]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      2127\n",
      "           1       0.72      0.62      0.67      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.75      0.74      0.74      3431\n",
      "weighted avg       0.76      0.77      0.76      3431\n",
      "\n",
      "acc:  0.7653745263771495\n",
      "pre:  0.7249774571686204\n",
      "rec:  0.6165644171779141\n",
      "ma F1:  0.7427254242188743\n",
      "mi F1:  0.7653745263771495\n",
      "we F1:  0.7610360441366154\n",
      "Eval Loss:  0.27123114466667175\n",
      "Eval Loss:  0.19786040484905243\n",
      "Eval Loss:  0.15024520456790924\n",
      "Eval Loss:  0.22373875975608826\n",
      "Eval Loss:  0.21103063225746155\n",
      "Eval Loss:  0.29543596506118774\n",
      "Eval Loss:  0.23609672486782074\n",
      "Eval Loss:  0.1185808926820755\n",
      "Eval Loss:  0.19222430884838104\n",
      "Eval Loss:  0.18862710893154144\n",
      "Eval Loss:  0.145904541015625\n",
      "Eval Loss:  0.16402380168437958\n",
      "Eval Loss:  0.2458467036485672\n",
      "Eval Loss:  0.21015797555446625\n",
      "Eval Loss:  0.1956317275762558\n",
      "Eval Loss:  0.27275216579437256\n",
      "Eval Loss:  0.20496872067451477\n",
      "Eval Loss:  0.3033803403377533\n",
      "Eval Loss:  0.22463299334049225\n",
      "Eval Loss:  0.23107220232486725\n",
      "Eval Loss:  0.17089277505874634\n",
      "Eval Loss:  0.21428632736206055\n",
      "Eval Loss:  0.13389259576797485\n",
      "Eval Loss:  0.2495332956314087\n",
      "Eval Loss:  0.15897104144096375\n",
      "Eval Loss:  0.2353854775428772\n",
      "Eval Loss:  0.22906950116157532\n",
      "Eval Loss:  0.22874276340007782\n",
      "[[16997  1040]\n",
      " [ 1469  9954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18037\n",
      "           1       0.91      0.87      0.89     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9148336727766463\n",
      "pre:  0.9054029470620338\n",
      "rec:  0.8713998074061104\n",
      "ma F1:  0.9096709685441693\n",
      "mi F1:  0.9148336727766463\n",
      "we F1:  0.9145192044938504\n",
      "29460 461\n",
      "Loss:  0.050975870341062546\n",
      "Loss:  0.0351724773645401\n",
      "Loss:  0.04792914167046547\n",
      "42 **********\n",
      "Epoch:  2471.5399630069733  fold:  7  kers:  64\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.05684220418334007\n",
      "Loss:  0.08624788373708725\n",
      "Loss:  0.09180603176355362\n",
      "43 **********\n",
      "Epoch:  2515.2301445007324  fold:  7  kers:  64\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.06604707986116409\n",
      "Loss:  0.05705263465642929\n",
      "Loss:  0.054703108966350555\n",
      "44 **********\n",
      "Epoch:  2559.017066717148  fold:  7  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.4939185678958893\n",
      "Eval Loss:  0.16484729945659637\n",
      "Eval Loss:  1.6838264465332031\n",
      "[[1779  348]\n",
      " [ 491  813]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      2127\n",
      "           1       0.70      0.62      0.66      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.74      0.73      0.73      3431\n",
      "weighted avg       0.75      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7554648790440105\n",
      "pre:  0.7002583979328165\n",
      "rec:  0.6234662576687117\n",
      "ma F1:  0.7344114856109251\n",
      "mi F1:  0.7554648790440105\n",
      "we F1:  0.7523482793950135\n",
      "Eval Loss:  0.28942298889160156\n",
      "Eval Loss:  0.1893913447856903\n",
      "Eval Loss:  0.13957379758358002\n",
      "Eval Loss:  0.202373206615448\n",
      "Eval Loss:  0.20887130498886108\n",
      "Eval Loss:  0.29067692160606384\n",
      "Eval Loss:  0.23133531212806702\n",
      "Eval Loss:  0.11334272474050522\n",
      "Eval Loss:  0.21318402886390686\n",
      "Eval Loss:  0.17384149134159088\n",
      "Eval Loss:  0.13405393064022064\n",
      "Eval Loss:  0.1855427324771881\n",
      "Eval Loss:  0.21980439126491547\n",
      "Eval Loss:  0.19760122895240784\n",
      "Eval Loss:  0.2068370133638382\n",
      "Eval Loss:  0.25643908977508545\n",
      "Eval Loss:  0.2209722250699997\n",
      "Eval Loss:  0.28052738308906555\n",
      "Eval Loss:  0.23925188183784485\n",
      "Eval Loss:  0.22715221345424652\n",
      "Eval Loss:  0.1815473884344101\n",
      "Eval Loss:  0.18889978528022766\n",
      "Eval Loss:  0.13532967865467072\n",
      "Eval Loss:  0.2189175933599472\n",
      "Eval Loss:  0.1510036289691925\n",
      "Eval Loss:  0.23043574392795563\n",
      "Eval Loss:  0.21775022149085999\n",
      "Eval Loss:  0.22308817505836487\n",
      "[[16752  1285]\n",
      " [ 1191 10232]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18037\n",
      "           1       0.89      0.90      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9159538357094366\n",
      "pre:  0.8884258053312495\n",
      "rec:  0.8957366716274183\n",
      "ma F1:  0.9116251254571827\n",
      "mi F1:  0.9159538357094366\n",
      "we F1:  0.9160162434952819\n",
      "29460 461\n",
      "Loss:  0.04037105292081833\n",
      "Loss:  0.04330865666270256\n",
      "Loss:  0.05934841185808182\n",
      "45 **********\n",
      "Epoch:  2643.4084219932556  fold:  7  kers:  64\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.07177911698818207\n",
      "Loss:  0.04972682520747185\n",
      "Loss:  0.05048419535160065\n",
      "46 **********\n",
      "Epoch:  2687.10857629776  fold:  7  kers:  64\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.05189656838774681\n",
      "Loss:  0.05043698847293854\n",
      "Loss:  0.045611921697854996\n",
      "47 **********\n",
      "Epoch:  2730.8556056022644  fold:  7  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.5265284776687622\n",
      "Eval Loss:  0.07820651680231094\n",
      "Eval Loss:  1.3576079607009888\n",
      "[[1901  226]\n",
      " [ 528  776]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      2127\n",
      "           1       0.77      0.60      0.67      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.74      0.75      3431\n",
      "weighted avg       0.78      0.78      0.77      3431\n",
      "\n",
      "acc:  0.7802389973768581\n",
      "pre:  0.7744510978043913\n",
      "rec:  0.5950920245398773\n",
      "ma F1:  0.7537654186087064\n",
      "mi F1:  0.7802389973768582\n",
      "we F1:  0.7731323122319854\n",
      "update!  Acc:  0.7802389973768581\n",
      "Eval Loss:  0.25771966576576233\n",
      "Eval Loss:  0.2103171944618225\n",
      "Eval Loss:  0.15338034927845\n",
      "Eval Loss:  0.22295960783958435\n",
      "Eval Loss:  0.20660839974880219\n",
      "Eval Loss:  0.29461586475372314\n",
      "Eval Loss:  0.23132355511188507\n",
      "Eval Loss:  0.121639683842659\n",
      "Eval Loss:  0.21024784445762634\n",
      "Eval Loss:  0.18071752786636353\n",
      "Eval Loss:  0.1606372445821762\n",
      "Eval Loss:  0.1883818805217743\n",
      "Eval Loss:  0.22079870104789734\n",
      "Eval Loss:  0.2026139199733734\n",
      "Eval Loss:  0.1800289899110794\n",
      "Eval Loss:  0.2467138171195984\n",
      "Eval Loss:  0.20375439524650574\n",
      "Eval Loss:  0.23846596479415894\n",
      "Eval Loss:  0.1990286260843277\n",
      "Eval Loss:  0.22587066888809204\n",
      "Eval Loss:  0.17712748050689697\n",
      "Eval Loss:  0.19495971500873566\n",
      "Eval Loss:  0.12198655307292938\n",
      "Eval Loss:  0.21400998532772064\n",
      "Eval Loss:  0.1495574563741684\n",
      "Eval Loss:  0.2061760127544403\n",
      "Eval Loss:  0.21564316749572754\n",
      "Eval Loss:  0.21297943592071533\n",
      "[[17144   893]\n",
      " [ 1464  9959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18037\n",
      "           1       0.92      0.87      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9199932111337407\n",
      "pre:  0.917711021009952\n",
      "rec:  0.8718375207913858\n",
      "ma F1:  0.9149332410841484\n",
      "mi F1:  0.9199932111337407\n",
      "we F1:  0.9195910896447613\n",
      "29460 461\n",
      "Loss:  0.05566020309925079\n",
      "Loss:  0.03494280204176903\n",
      "Loss:  0.08501965552568436\n",
      "48 **********\n",
      "Epoch:  2815.295829772949  fold:  7  kers:  64\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.046369899064302444\n",
      "Loss:  0.03950586915016174\n",
      "Loss:  0.02679171785712242\n",
      "49 **********\n",
      "Epoch:  2858.949109315872  fold:  7  kers:  64\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.07439599186182022\n",
      "Loss:  0.04553927108645439\n",
      "Loss:  0.07614371925592422\n",
      "50 **********\n",
      "Epoch:  2902.601430416107  fold:  7  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.5622108578681946\n",
      "Eval Loss:  0.09043794870376587\n",
      "Eval Loss:  1.224639654159546\n",
      "[[1836  291]\n",
      " [ 523  781]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      2127\n",
      "           1       0.73      0.60      0.66      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.75      0.73      0.74      3431\n",
      "weighted avg       0.76      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7627513844360245\n",
      "pre:  0.7285447761194029\n",
      "rec:  0.5989263803680982\n",
      "ma F1:  0.7379769983983091\n",
      "mi F1:  0.7627513844360245\n",
      "we F1:  0.7573033677907637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2578619718551636\n",
      "Eval Loss:  0.20104598999023438\n",
      "Eval Loss:  0.14379943907260895\n",
      "Eval Loss:  0.21909289062023163\n",
      "Eval Loss:  0.19913476705551147\n",
      "Eval Loss:  0.293770968914032\n",
      "Eval Loss:  0.22575345635414124\n",
      "Eval Loss:  0.12522318959236145\n",
      "Eval Loss:  0.21560071408748627\n",
      "Eval Loss:  0.1667931228876114\n",
      "Eval Loss:  0.14237111806869507\n",
      "Eval Loss:  0.18852904438972473\n",
      "Eval Loss:  0.2352864295244217\n",
      "Eval Loss:  0.2084944248199463\n",
      "Eval Loss:  0.1774602234363556\n",
      "Eval Loss:  0.23969291150569916\n",
      "Eval Loss:  0.227195605635643\n",
      "Eval Loss:  0.2620939612388611\n",
      "Eval Loss:  0.2021111100912094\n",
      "Eval Loss:  0.23056840896606445\n",
      "Eval Loss:  0.16097848117351532\n",
      "Eval Loss:  0.1955801099538803\n",
      "Eval Loss:  0.12963534891605377\n",
      "Eval Loss:  0.23240403831005096\n",
      "Eval Loss:  0.1405145227909088\n",
      "Eval Loss:  0.2182619720697403\n",
      "Eval Loss:  0.1860032081604004\n",
      "Eval Loss:  0.20914995670318604\n",
      "[[17176   861]\n",
      " [ 1501  9922]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18037\n",
      "           1       0.92      0.87      0.89     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9198234894772573\n",
      "pre:  0.9201520912547528\n",
      "rec:  0.8685984417403484\n",
      "ma F1:  0.9146486103019937\n",
      "mi F1:  0.9198234894772573\n",
      "we F1:  0.9193669244549015\n",
      "29460 461\n",
      "Loss:  0.05095309019088745\n",
      "Loss:  0.04284290596842766\n",
      "Loss:  0.06014985963702202\n",
      "51 **********\n",
      "Epoch:  2987.037502527237  fold:  7  kers:  64\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.050457775592803955\n",
      "Loss:  0.042014624923467636\n",
      "Loss:  0.031981006264686584\n",
      "52 **********\n",
      "Epoch:  3030.8693056106567  fold:  7  kers:  64\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.06372199207544327\n",
      "Loss:  0.051892902702093124\n",
      "Loss:  0.042177192866802216\n",
      "53 **********\n",
      "Epoch:  3074.6719942092896  fold:  7  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.46728765964508057\n",
      "Eval Loss:  0.12767554819583893\n",
      "Eval Loss:  1.071592926979065\n",
      "[[1693  434]\n",
      " [ 426  878]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      2127\n",
      "           1       0.67      0.67      0.67      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.73      0.73      0.73      3431\n",
      "weighted avg       0.75      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7493442145147188\n",
      "pre:  0.6692073170731707\n",
      "rec:  0.6733128834355828\n",
      "ma F1:  0.7343551261053757\n",
      "mi F1:  0.7493442145147187\n",
      "we F1:  0.7494913466708841\n",
      "Eval Loss:  0.2845021188259125\n",
      "Eval Loss:  0.2142440229654312\n",
      "Eval Loss:  0.12364286929368973\n",
      "Eval Loss:  0.17401762306690216\n",
      "Eval Loss:  0.18508444726467133\n",
      "Eval Loss:  0.26816803216934204\n",
      "Eval Loss:  0.202097088098526\n",
      "Eval Loss:  0.12396243214607239\n",
      "Eval Loss:  0.20742061734199524\n",
      "Eval Loss:  0.16835257411003113\n",
      "Eval Loss:  0.1336730271577835\n",
      "Eval Loss:  0.1924096643924713\n",
      "Eval Loss:  0.18134823441505432\n",
      "Eval Loss:  0.19897495210170746\n",
      "Eval Loss:  0.17255724966526031\n",
      "Eval Loss:  0.22104163467884064\n",
      "Eval Loss:  0.20365965366363525\n",
      "Eval Loss:  0.26507192850112915\n",
      "Eval Loss:  0.22104321420192719\n",
      "Eval Loss:  0.21599483489990234\n",
      "Eval Loss:  0.146040678024292\n",
      "Eval Loss:  0.17928193509578705\n",
      "Eval Loss:  0.1431795060634613\n",
      "Eval Loss:  0.2094028890132904\n",
      "Eval Loss:  0.144845649600029\n",
      "Eval Loss:  0.21001827716827393\n",
      "Eval Loss:  0.1771722286939621\n",
      "Eval Loss:  0.20180672407150269\n",
      "[[16735  1302]\n",
      " [  994 10429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18037\n",
      "           1       0.89      0.91      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9220638153428378\n",
      "pre:  0.8890120194356832\n",
      "rec:  0.9129825790072661\n",
      "ma F1:  0.9183214113064567\n",
      "mi F1:  0.9220638153428378\n",
      "we F1:  0.9222466032342436\n",
      "29460 461\n",
      "Loss:  0.047199711203575134\n",
      "Loss:  0.03661418706178665\n",
      "Loss:  0.064984031021595\n",
      "54 **********\n",
      "Epoch:  3159.158095598221  fold:  7  kers:  64\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.1009984090924263\n",
      "Loss:  0.06069941818714142\n",
      "Loss:  0.058154091238975525\n",
      "55 **********\n",
      "Epoch:  3202.904127597809  fold:  7  kers:  64\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.06753205507993698\n",
      "Loss:  0.07472161203622818\n",
      "Loss:  0.06695796549320221\n",
      "56 **********\n",
      "Epoch:  3246.640634059906  fold:  7  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.49661967158317566\n",
      "Eval Loss:  0.115850530564785\n",
      "Eval Loss:  1.0286527872085571\n",
      "[[1802  325]\n",
      " [ 435  869]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      2127\n",
      "           1       0.73      0.67      0.70      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.77      0.76      0.76      3431\n",
      "weighted avg       0.78      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7784902360827747\n",
      "pre:  0.7278056951423786\n",
      "rec:  0.6664110429447853\n",
      "ma F1:  0.7608022256485298\n",
      "mi F1:  0.7784902360827746\n",
      "we F1:  0.7764048329233246\n",
      "Eval Loss:  0.26044464111328125\n",
      "Eval Loss:  0.20724403858184814\n",
      "Eval Loss:  0.12762737274169922\n",
      "Eval Loss:  0.20797528326511383\n",
      "Eval Loss:  0.1774774044752121\n",
      "Eval Loss:  0.2876777648925781\n",
      "Eval Loss:  0.2005547434091568\n",
      "Eval Loss:  0.11146705597639084\n",
      "Eval Loss:  0.21631073951721191\n",
      "Eval Loss:  0.17372079193592072\n",
      "Eval Loss:  0.12047913670539856\n",
      "Eval Loss:  0.18816493451595306\n",
      "Eval Loss:  0.18907202780246735\n",
      "Eval Loss:  0.1893118917942047\n",
      "Eval Loss:  0.162338986992836\n",
      "Eval Loss:  0.24525584280490875\n",
      "Eval Loss:  0.19018147885799408\n",
      "Eval Loss:  0.2319619059562683\n",
      "Eval Loss:  0.23112595081329346\n",
      "Eval Loss:  0.1991470605134964\n",
      "Eval Loss:  0.14963193237781525\n",
      "Eval Loss:  0.16841991245746613\n",
      "Eval Loss:  0.1207166388630867\n",
      "Eval Loss:  0.20986996591091156\n",
      "Eval Loss:  0.13882075250148773\n",
      "Eval Loss:  0.19269391894340515\n",
      "Eval Loss:  0.18937139213085175\n",
      "Eval Loss:  0.19741623103618622\n",
      "[[16930  1107]\n",
      " [ 1152 10271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18037\n",
      "           1       0.90      0.90      0.90     11423\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.92      0.92      0.92     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9233197556008147\n",
      "pre:  0.9027069783793286\n",
      "rec:  0.8991508360325658\n",
      "ma F1:  0.9191910691143441\n",
      "mi F1:  0.9233197556008147\n",
      "we F1:  0.9232918548812035\n",
      "29460 461\n",
      "Loss:  0.04743965342640877\n",
      "Loss:  0.05699882656335831\n",
      "Loss:  0.03376208245754242\n",
      "57 **********\n",
      "Epoch:  3331.311836242676  fold:  7  kers:  64\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.03332929313182831\n",
      "Loss:  0.052306391298770905\n",
      "Loss:  0.06717080622911453\n",
      "58 **********\n",
      "Epoch:  3375.0937724113464  fold:  7  kers:  64\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.03587115556001663\n",
      "Loss:  0.05634007230401039\n",
      "Loss:  0.06886851042509079\n",
      "59 **********\n",
      "Epoch:  3418.824850797653  fold:  7  kers:  64\n",
      "Eval Loss:  0.5591421723365784\n",
      "Eval Loss:  0.056942418217659\n",
      "Eval Loss:  1.2254356145858765\n",
      "[[1831  296]\n",
      " [ 559  745]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81      2127\n",
      "           1       0.72      0.57      0.64      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.74      0.72      0.72      3431\n",
      "weighted avg       0.75      0.75      0.74      3431\n",
      "\n",
      "acc:  0.7508015155931216\n",
      "pre:  0.7156580211335255\n",
      "rec:  0.571319018404908\n",
      "ma F1:  0.723054766334053\n",
      "mi F1:  0.7508015155931217\n",
      "we F1:  0.7440819989677669\n",
      "update!  Acc:  0.7802389973768581\n",
      "Epoch:  3423.0894479751587  fold:  7  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29817 3074\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29817 466\n",
      "Loss:  0.16911372542381287\n",
      "Loss:  0.17005234956741333\n",
      "Loss:  0.1557096391916275\n",
      "0 **********\n",
      "Epoch:  57.04547119140625  fold:  8  kers:  64\n",
      "epoch:  1\n",
      "29817 466\n",
      "Loss:  0.1302487850189209\n",
      "Loss:  0.122116319835186\n",
      "Loss:  0.11512050032615662\n",
      "1 **********\n",
      "Epoch:  101.53152465820312  fold:  8  kers:  64\n",
      "epoch:  2\n",
      "29817 466\n",
      "Loss:  0.12102889269590378\n",
      "Loss:  0.11309485137462616\n",
      "Loss:  0.09848809987306595\n",
      "2 **********\n",
      "Epoch:  145.8769543170929  fold:  8  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.27534228563308716\n",
      "Eval Loss:  0.8643774390220642\n",
      "Eval Loss:  0.2726857364177704\n",
      "[[1831  242]\n",
      " [ 362  639]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86      2073\n",
      "           1       0.73      0.64      0.68      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.78      0.76      0.77      3074\n",
      "weighted avg       0.80      0.80      0.80      3074\n",
      "\n",
      "acc:  0.8035133376707873\n",
      "pre:  0.7253121452894438\n",
      "rec:  0.6383616383616384\n",
      "ma F1:  0.768740101028671\n",
      "mi F1:  0.8035133376707873\n",
      "we F1:  0.8000126762638629\n",
      "update!  Acc:  0.8035133376707873\n",
      "Eval Loss:  0.3144068121910095\n",
      "Eval Loss:  0.39678555727005005\n",
      "Eval Loss:  0.42999333143234253\n",
      "Eval Loss:  0.4217872619628906\n",
      "Eval Loss:  0.4002102017402649\n",
      "Eval Loss:  0.47718706727027893\n",
      "Eval Loss:  0.4628865718841553\n",
      "Eval Loss:  0.5111788511276245\n",
      "Eval Loss:  0.42770570516586304\n",
      "Eval Loss:  0.3332308530807495\n",
      "Eval Loss:  0.3641066253185272\n",
      "Eval Loss:  0.3742719888687134\n",
      "Eval Loss:  0.4206911623477936\n",
      "Eval Loss:  0.40354880690574646\n",
      "Eval Loss:  0.40108194947242737\n",
      "Eval Loss:  0.3943731486797333\n",
      "Eval Loss:  0.3672991096973419\n",
      "Eval Loss:  0.42572852969169617\n",
      "Eval Loss:  0.3508760631084442\n",
      "Eval Loss:  0.3695951998233795\n",
      "Eval Loss:  0.4663969874382019\n",
      "Eval Loss:  0.4301590919494629\n",
      "Eval Loss:  0.399506151676178\n",
      "Eval Loss:  0.3841756582260132\n",
      "Eval Loss:  0.49370184540748596\n",
      "Eval Loss:  0.43030795454978943\n",
      "Eval Loss:  0.43398183584213257\n",
      "Eval Loss:  0.3986673355102539\n",
      "Eval Loss:  0.3605746328830719\n",
      "[[15401  2690]\n",
      " [ 2661  9065]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     18091\n",
      "           1       0.77      0.77      0.77     11726\n",
      "\n",
      "    accuracy                           0.82     29817\n",
      "   macro avg       0.81      0.81      0.81     29817\n",
      "weighted avg       0.82      0.82      0.82     29817\n",
      "\n",
      "acc:  0.8205386189086763\n",
      "pre:  0.7711612079965972\n",
      "rec:  0.7730683950196146\n",
      "ma F1:  0.812051888370978\n",
      "mi F1:  0.8205386189086763\n",
      "we F1:  0.8205774628457964\n",
      "29817 466\n",
      "Loss:  0.12271281331777573\n",
      "Loss:  0.09459799528121948\n",
      "Loss:  0.09101294726133347\n",
      "3 **********\n",
      "Epoch:  231.36936450004578  fold:  8  kers:  64\n",
      "epoch:  4\n",
      "29817 466\n",
      "Loss:  0.10802242904901505\n",
      "Loss:  0.10963009297847748\n",
      "Loss:  0.09423485398292542\n",
      "4 **********\n",
      "Epoch:  275.6300208568573  fold:  8  kers:  64\n",
      "epoch:  5\n",
      "29817 466\n",
      "Loss:  0.06149576976895332\n",
      "Loss:  0.1238940879702568\n",
      "Loss:  0.05866403505206108\n",
      "5 **********\n",
      "Epoch:  319.99938583374023  fold:  8  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.3619888126850128\n",
      "Eval Loss:  1.5216686725616455\n",
      "Eval Loss:  0.13513365387916565\n",
      "[[1708  365]\n",
      " [ 427  574]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      2073\n",
      "           1       0.61      0.57      0.59      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.71      0.70      0.70      3074\n",
      "weighted avg       0.74      0.74      0.74      3074\n",
      "\n",
      "acc:  0.7423552374756018\n",
      "pre:  0.6112886048988285\n",
      "rec:  0.5734265734265734\n",
      "ma F1:  0.7017698247814669\n",
      "mi F1:  0.7423552374756018\n",
      "we F1:  0.7401362819314781\n",
      "Eval Loss:  0.2783867120742798\n",
      "Eval Loss:  0.29873502254486084\n",
      "Eval Loss:  0.38606274127960205\n",
      "Eval Loss:  0.4123295545578003\n",
      "Eval Loss:  0.3290438950061798\n",
      "Eval Loss:  0.3873482346534729\n",
      "Eval Loss:  0.4018113613128662\n",
      "Eval Loss:  0.4180389940738678\n",
      "Eval Loss:  0.3807670772075653\n",
      "Eval Loss:  0.2773963510990143\n",
      "Eval Loss:  0.2667330503463745\n",
      "Eval Loss:  0.33365297317504883\n",
      "Eval Loss:  0.35214102268218994\n",
      "Eval Loss:  0.3081558048725128\n",
      "Eval Loss:  0.3534015119075775\n",
      "Eval Loss:  0.35575342178344727\n",
      "Eval Loss:  0.3207615911960602\n",
      "Eval Loss:  0.3350454568862915\n",
      "Eval Loss:  0.24123620986938477\n",
      "Eval Loss:  0.29977351427078247\n",
      "Eval Loss:  0.4303397536277771\n",
      "Eval Loss:  0.4196767807006836\n",
      "Eval Loss:  0.32057827711105347\n",
      "Eval Loss:  0.3440709710121155\n",
      "Eval Loss:  0.439927875995636\n",
      "Eval Loss:  0.3195003569126129\n",
      "Eval Loss:  0.38224533200263977\n",
      "Eval Loss:  0.3389225900173187\n",
      "Eval Loss:  0.30069419741630554\n",
      "[[16641  1450]\n",
      " [ 2533  9193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89     18091\n",
      "           1       0.86      0.78      0.82     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.87      0.85      0.86     29817\n",
      "weighted avg       0.87      0.87      0.87     29817\n",
      "\n",
      "acc:  0.8664184860985344\n",
      "pre:  0.8637602179836512\n",
      "rec:  0.7839843083745522\n",
      "ma F1:  0.8575289724318681\n",
      "mi F1:  0.8664184860985344\n",
      "we F1:  0.8651258782439426\n",
      "29817 466\n",
      "Loss:  0.10074734687805176\n",
      "Loss:  0.08829787373542786\n",
      "Loss:  0.07315876334905624\n",
      "6 **********\n",
      "Epoch:  405.28208351135254  fold:  8  kers:  64\n",
      "epoch:  7\n",
      "29817 466\n",
      "Loss:  0.08865141123533249\n",
      "Loss:  0.051553063094615936\n",
      "Loss:  0.08485472947359085\n",
      "7 **********\n",
      "Epoch:  449.4469954967499  fold:  8  kers:  64\n",
      "epoch:  8\n",
      "29817 466\n",
      "Loss:  0.07351132482290268\n",
      "Loss:  0.07498875260353088\n",
      "Loss:  0.08099747449159622\n",
      "8 **********\n",
      "Epoch:  493.61390256881714  fold:  8  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.2540120780467987\n",
      "Eval Loss:  1.6354217529296875\n",
      "Eval Loss:  0.0933561772108078\n",
      "[[1771  302]\n",
      " [ 494  507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82      2073\n",
      "           1       0.63      0.51      0.56      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.70      0.68      0.69      3074\n",
      "weighted avg       0.73      0.74      0.73      3074\n",
      "\n",
      "acc:  0.7410540013012362\n",
      "pre:  0.6266996291718171\n",
      "rec:  0.5064935064935064\n",
      "ma F1:  0.6883631482288093\n",
      "mi F1:  0.7410540013012362\n",
      "we F1:  0.7330503274168169\n",
      "Eval Loss:  0.261883944272995\n",
      "Eval Loss:  0.31043845415115356\n",
      "Eval Loss:  0.3711363673210144\n",
      "Eval Loss:  0.37647512555122375\n",
      "Eval Loss:  0.3405928909778595\n",
      "Eval Loss:  0.3966083228588104\n",
      "Eval Loss:  0.43943241238594055\n",
      "Eval Loss:  0.365985631942749\n",
      "Eval Loss:  0.3586355745792389\n",
      "Eval Loss:  0.29784369468688965\n",
      "Eval Loss:  0.25658249855041504\n",
      "Eval Loss:  0.2985520660877228\n",
      "Eval Loss:  0.3609846234321594\n",
      "Eval Loss:  0.3113323450088501\n",
      "Eval Loss:  0.3590300977230072\n",
      "Eval Loss:  0.36131036281585693\n",
      "Eval Loss:  0.31854304671287537\n",
      "Eval Loss:  0.33968353271484375\n",
      "Eval Loss:  0.2563401460647583\n",
      "Eval Loss:  0.31070151925086975\n",
      "Eval Loss:  0.501644492149353\n",
      "Eval Loss:  0.45955222845077515\n",
      "Eval Loss:  0.2941440939903259\n",
      "Eval Loss:  0.32556474208831787\n",
      "Eval Loss:  0.451993465423584\n",
      "Eval Loss:  0.34229984879493713\n",
      "Eval Loss:  0.4196772277355194\n",
      "Eval Loss:  0.34450939297676086\n",
      "Eval Loss:  0.32053083181381226\n",
      "[[17304   787]\n",
      " [ 3219  8507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     18091\n",
      "           1       0.92      0.73      0.81     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.88      0.84      0.85     29817\n",
      "weighted avg       0.87      0.87      0.86     29817\n",
      "\n",
      "acc:  0.8656471140624475\n",
      "pre:  0.9153217129330751\n",
      "rec:  0.7254818352379327\n",
      "ma F1:  0.8528374222962669\n",
      "mi F1:  0.8656471140624475\n",
      "we F1:  0.8621057737901557\n",
      "29817 466\n",
      "Loss:  0.08865466713905334\n",
      "Loss:  0.10972979664802551\n",
      "Loss:  0.10020799189805984\n",
      "9 **********\n",
      "Epoch:  578.6804513931274  fold:  8  kers:  64\n",
      "epoch:  10\n",
      "29817 466\n",
      "Loss:  0.08077191561460495\n",
      "Loss:  0.10959231108427048\n",
      "Loss:  0.08167729526758194\n",
      "10 **********\n",
      "Epoch:  622.8543391227722  fold:  8  kers:  64\n",
      "epoch:  11\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0760444924235344\n",
      "Loss:  0.070900559425354\n",
      "Loss:  0.09660707414150238\n",
      "11 **********\n",
      "Epoch:  667.0202486515045  fold:  8  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.17324818670749664\n",
      "Eval Loss:  1.8718178272247314\n",
      "Eval Loss:  0.08983691036701202\n",
      "[[1957  116]\n",
      " [ 629  372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      2073\n",
      "           1       0.76      0.37      0.50      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.76      0.66      0.67      3074\n",
      "weighted avg       0.76      0.76      0.73      3074\n",
      "\n",
      "acc:  0.7576447625243982\n",
      "pre:  0.7622950819672131\n",
      "rec:  0.37162837162837165\n",
      "ma F1:  0.6698793225155036\n",
      "mi F1:  0.7576447625243982\n",
      "we F1:  0.7292386611208884\n",
      "Eval Loss:  0.31932133436203003\n",
      "Eval Loss:  0.346249520778656\n",
      "Eval Loss:  0.42072877287864685\n",
      "Eval Loss:  0.4259393811225891\n",
      "Eval Loss:  0.43069154024124146\n",
      "Eval Loss:  0.4779238700866699\n",
      "Eval Loss:  0.5257004499435425\n",
      "Eval Loss:  0.4186995327472687\n",
      "Eval Loss:  0.41048479080200195\n",
      "Eval Loss:  0.35685259103775024\n",
      "Eval Loss:  0.3113511800765991\n",
      "Eval Loss:  0.287931352853775\n",
      "Eval Loss:  0.4081827998161316\n",
      "Eval Loss:  0.38489943742752075\n",
      "Eval Loss:  0.4000515043735504\n",
      "Eval Loss:  0.42727845907211304\n",
      "Eval Loss:  0.3700517416000366\n",
      "Eval Loss:  0.41174226999282837\n",
      "Eval Loss:  0.3259081244468689\n",
      "Eval Loss:  0.35400161147117615\n",
      "Eval Loss:  0.6468586325645447\n",
      "Eval Loss:  0.5408272743225098\n",
      "Eval Loss:  0.3855409026145935\n",
      "Eval Loss:  0.3502989709377289\n",
      "Eval Loss:  0.5390584468841553\n",
      "Eval Loss:  0.4769701361656189\n",
      "Eval Loss:  0.4874721169471741\n",
      "Eval Loss:  0.3947649300098419\n",
      "Eval Loss:  0.39251798391342163\n",
      "[[17726   365]\n",
      " [ 4401  7325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88     18091\n",
      "           1       0.95      0.62      0.75     11726\n",
      "\n",
      "    accuracy                           0.84     29817\n",
      "   macro avg       0.88      0.80      0.82     29817\n",
      "weighted avg       0.86      0.84      0.83     29817\n",
      "\n",
      "acc:  0.8401582989569708\n",
      "pre:  0.9525357607282184\n",
      "rec:  0.6246801978509295\n",
      "ma F1:  0.8180140960442965\n",
      "mi F1:  0.8401582989569708\n",
      "we F1:  0.8315654710600808\n",
      "29817 466\n",
      "Loss:  0.10519789904356003\n",
      "Loss:  0.0970790684223175\n",
      "Loss:  0.055344849824905396\n",
      "12 **********\n",
      "Epoch:  751.9511065483093  fold:  8  kers:  64\n",
      "epoch:  13\n",
      "29817 466\n",
      "Loss:  0.07971048355102539\n",
      "Loss:  0.03866977617144585\n",
      "Loss:  0.050667718052864075\n",
      "13 **********\n",
      "Epoch:  796.0561838150024  fold:  8  kers:  64\n",
      "epoch:  14\n",
      "29817 466\n",
      "Loss:  0.07087462395429611\n",
      "Loss:  0.06687018275260925\n",
      "Loss:  0.06246193125844002\n",
      "14 **********\n",
      "Epoch:  840.2709729671478  fold:  8  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.31317755579948425\n",
      "Eval Loss:  1.3255952596664429\n",
      "Eval Loss:  0.09658251702785492\n",
      "[[1737  336]\n",
      " [ 416  585]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      2073\n",
      "           1       0.64      0.58      0.61      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.72      0.71      0.72      3074\n",
      "weighted avg       0.75      0.76      0.75      3074\n",
      "\n",
      "acc:  0.7553675992192583\n",
      "pre:  0.6351791530944625\n",
      "rec:  0.5844155844155844\n",
      "ma F1:  0.7153974233142733\n",
      "mi F1:  0.7553675992192582\n",
      "we F1:  0.7525918925591899\n",
      "Eval Loss:  0.22403891384601593\n",
      "Eval Loss:  0.29152053594589233\n",
      "Eval Loss:  0.3022931218147278\n",
      "Eval Loss:  0.3377726078033447\n",
      "Eval Loss:  0.2806786298751831\n",
      "Eval Loss:  0.3189883530139923\n",
      "Eval Loss:  0.3761078119277954\n",
      "Eval Loss:  0.29076844453811646\n",
      "Eval Loss:  0.30448076128959656\n",
      "Eval Loss:  0.2531282305717468\n",
      "Eval Loss:  0.18794575333595276\n",
      "Eval Loss:  0.27492067217826843\n",
      "Eval Loss:  0.30738353729248047\n",
      "Eval Loss:  0.22656750679016113\n",
      "Eval Loss:  0.3193046450614929\n",
      "Eval Loss:  0.2775937616825104\n",
      "Eval Loss:  0.27023589611053467\n",
      "Eval Loss:  0.3016807436943054\n",
      "Eval Loss:  0.23215804994106293\n",
      "Eval Loss:  0.25952059030532837\n",
      "Eval Loss:  0.4166666269302368\n",
      "Eval Loss:  0.39059120416641235\n",
      "Eval Loss:  0.23435203731060028\n",
      "Eval Loss:  0.2802349925041199\n",
      "Eval Loss:  0.4188852310180664\n",
      "Eval Loss:  0.24785833060741425\n",
      "Eval Loss:  0.3305164575576782\n",
      "Eval Loss:  0.31637144088745117\n",
      "Eval Loss:  0.2499813288450241\n",
      "[[17168   923]\n",
      " [ 2555  9171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18091\n",
      "           1       0.91      0.78      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.87      0.87     29817\n",
      "weighted avg       0.89      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8833551329778314\n",
      "pre:  0.9085595403209827\n",
      "rec:  0.7821081357666724\n",
      "ma F1:  0.8743142164767417\n",
      "mi F1:  0.8833551329778314\n",
      "we F1:  0.8815100941220381\n",
      "29817 466\n",
      "Loss:  0.08313844352960587\n",
      "Loss:  0.07201723754405975\n",
      "Loss:  0.06688004732131958\n",
      "15 **********\n",
      "Epoch:  924.895530462265  fold:  8  kers:  64\n",
      "epoch:  16\n",
      "29817 466\n",
      "Loss:  0.041591331362724304\n",
      "Loss:  0.07105224579572678\n",
      "Loss:  0.05888909101486206\n",
      "16 **********\n",
      "Epoch:  968.8412907123566  fold:  8  kers:  64\n",
      "epoch:  17\n",
      "29817 466\n",
      "Loss:  0.05902357026934624\n",
      "Loss:  0.05166664347052574\n",
      "Loss:  0.05584738776087761\n",
      "17 **********\n",
      "Epoch:  1012.7468955516815  fold:  8  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.38142096996307373\n",
      "Eval Loss:  1.28694748878479\n",
      "Eval Loss:  0.09419785439968109\n",
      "[[1870  203]\n",
      " [ 450  551]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85      2073\n",
      "           1       0.73      0.55      0.63      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.77      0.73      0.74      3074\n",
      "weighted avg       0.78      0.79      0.78      3074\n",
      "\n",
      "acc:  0.7875731945348081\n",
      "pre:  0.7307692307692307\n",
      "rec:  0.5504495504495505\n",
      "ma F1:  0.7396373277092603\n",
      "mi F1:  0.7875731945348082\n",
      "we F1:  0.7785965765621694\n",
      "Eval Loss:  0.22566209733486176\n",
      "Eval Loss:  0.2810814380645752\n",
      "Eval Loss:  0.3085612952709198\n",
      "Eval Loss:  0.31759095191955566\n",
      "Eval Loss:  0.2936593294143677\n",
      "Eval Loss:  0.317802369594574\n",
      "Eval Loss:  0.38844433426856995\n",
      "Eval Loss:  0.2843620777130127\n",
      "Eval Loss:  0.30921807885169983\n",
      "Eval Loss:  0.2340201437473297\n",
      "Eval Loss:  0.19616061449050903\n",
      "Eval Loss:  0.22753094136714935\n",
      "Eval Loss:  0.3146209716796875\n",
      "Eval Loss:  0.2218123823404312\n",
      "Eval Loss:  0.31022363901138306\n",
      "Eval Loss:  0.2715900242328644\n",
      "Eval Loss:  0.26737067103385925\n",
      "Eval Loss:  0.3015894889831543\n",
      "Eval Loss:  0.22183239459991455\n",
      "Eval Loss:  0.25769299268722534\n",
      "Eval Loss:  0.4305332601070404\n",
      "Eval Loss:  0.377860426902771\n",
      "Eval Loss:  0.23365773260593414\n",
      "Eval Loss:  0.2685420513153076\n",
      "Eval Loss:  0.4167129397392273\n",
      "Eval Loss:  0.2740885317325592\n",
      "Eval Loss:  0.34110507369041443\n",
      "Eval Loss:  0.2997678518295288\n",
      "Eval Loss:  0.2502579092979431\n",
      "[[17371   720]\n",
      " [ 2748  8978]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18091\n",
      "           1       0.93      0.77      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.86      0.87     29817\n",
      "weighted avg       0.89      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8836905121239561\n",
      "pre:  0.9257578882243762\n",
      "rec:  0.7656489851611803\n",
      "ma F1:  0.8736819430141085\n",
      "mi F1:  0.8836905121239561\n",
      "we F1:  0.8812721422735129\n",
      "29817 466\n",
      "Loss:  0.07465839385986328\n",
      "Loss:  0.07429423928260803\n",
      "Loss:  0.0646379142999649\n",
      "18 **********\n",
      "Epoch:  1097.5733630657196  fold:  8  kers:  64\n",
      "epoch:  19\n",
      "29817 466\n",
      "Loss:  0.06055185943841934\n",
      "Loss:  0.045162033289670944\n",
      "Loss:  0.05602794885635376\n",
      "19 **********\n",
      "Epoch:  1141.8419976234436  fold:  8  kers:  64\n",
      "epoch:  20\n",
      "29817 466\n",
      "Loss:  0.06008915603160858\n",
      "Loss:  0.05808586627244949\n",
      "Loss:  0.04472658410668373\n",
      "20 **********\n",
      "Epoch:  1186.1405522823334  fold:  8  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.47638800740242004\n",
      "Eval Loss:  1.25472891330719\n",
      "Eval Loss:  0.09350231289863586\n",
      "[[1737  336]\n",
      " [ 439  562]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      2073\n",
      "           1       0.63      0.56      0.59      1001\n",
      "\n",
      "    accuracy                           0.75      3074\n",
      "   macro avg       0.71      0.70      0.70      3074\n",
      "weighted avg       0.74      0.75      0.74      3074\n",
      "\n",
      "acc:  0.7478854912166558\n",
      "pre:  0.6258351893095768\n",
      "rec:  0.5614385614385614\n",
      "ma F1:  0.7047473054094071\n",
      "mi F1:  0.7478854912166558\n",
      "we F1:  0.7441040162054673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22364845871925354\n",
      "Eval Loss:  0.2847341001033783\n",
      "Eval Loss:  0.28426891565322876\n",
      "Eval Loss:  0.30103206634521484\n",
      "Eval Loss:  0.261675626039505\n",
      "Eval Loss:  0.3119480311870575\n",
      "Eval Loss:  0.38631895184516907\n",
      "Eval Loss:  0.27049413323402405\n",
      "Eval Loss:  0.28736910223960876\n",
      "Eval Loss:  0.23791910707950592\n",
      "Eval Loss:  0.19429254531860352\n",
      "Eval Loss:  0.22003436088562012\n",
      "Eval Loss:  0.3155369162559509\n",
      "Eval Loss:  0.21207791566848755\n",
      "Eval Loss:  0.302561491727829\n",
      "Eval Loss:  0.2663593590259552\n",
      "Eval Loss:  0.24939027428627014\n",
      "Eval Loss:  0.2994096875190735\n",
      "Eval Loss:  0.21215848624706268\n",
      "Eval Loss:  0.24697330594062805\n",
      "Eval Loss:  0.4093221426010132\n",
      "Eval Loss:  0.33760058879852295\n",
      "Eval Loss:  0.25438788533210754\n",
      "Eval Loss:  0.2666023373603821\n",
      "Eval Loss:  0.3839925527572632\n",
      "Eval Loss:  0.3007858693599701\n",
      "Eval Loss:  0.3144912123680115\n",
      "Eval Loss:  0.28068944811820984\n",
      "Eval Loss:  0.23448792099952698\n",
      "[[17443   648]\n",
      " [ 2689  9037]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     18091\n",
      "           1       0.93      0.77      0.84     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.90      0.87      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8880839789381896\n",
      "pre:  0.9330924109447599\n",
      "rec:  0.7706805389732219\n",
      "ma F1:  0.878421038317899\n",
      "mi F1:  0.8880839789381896\n",
      "we F1:  0.8857377902865107\n",
      "29817 466\n",
      "Loss:  0.054191987961530685\n",
      "Loss:  0.11099342256784439\n",
      "Loss:  0.05567171797156334\n",
      "21 **********\n",
      "Epoch:  1271.113927602768  fold:  8  kers:  64\n",
      "epoch:  22\n",
      "29817 466\n",
      "Loss:  0.04251549765467644\n",
      "Loss:  0.06452318280935287\n",
      "Loss:  0.06713069975376129\n",
      "22 **********\n",
      "Epoch:  1315.2479214668274  fold:  8  kers:  64\n",
      "epoch:  23\n",
      "29817 466\n",
      "Loss:  0.07214021682739258\n",
      "Loss:  0.06418012827634811\n",
      "Loss:  0.0673457533121109\n",
      "23 **********\n",
      "Epoch:  1359.3599750995636  fold:  8  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.6294677257537842\n",
      "Eval Loss:  1.027776837348938\n",
      "Eval Loss:  0.10179819166660309\n",
      "[[1639  434]\n",
      " [ 249  752]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      2073\n",
      "           1       0.63      0.75      0.69      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.75      0.77      0.76      3074\n",
      "weighted avg       0.79      0.78      0.78      3074\n",
      "\n",
      "acc:  0.7778139232270657\n",
      "pre:  0.6340640809443507\n",
      "rec:  0.7512487512487512\n",
      "ma F1:  0.7576344207416921\n",
      "mi F1:  0.7778139232270656\n",
      "we F1:  0.7820227258874876\n",
      "Eval Loss:  0.2148602455854416\n",
      "Eval Loss:  0.261158287525177\n",
      "Eval Loss:  0.24816769361495972\n",
      "Eval Loss:  0.2702310085296631\n",
      "Eval Loss:  0.17898067831993103\n",
      "Eval Loss:  0.2610759437084198\n",
      "Eval Loss:  0.3360181748867035\n",
      "Eval Loss:  0.2241581380367279\n",
      "Eval Loss:  0.2709399163722992\n",
      "Eval Loss:  0.18950049579143524\n",
      "Eval Loss:  0.14810486137866974\n",
      "Eval Loss:  0.252748966217041\n",
      "Eval Loss:  0.2953941226005554\n",
      "Eval Loss:  0.19969548285007477\n",
      "Eval Loss:  0.2713322043418884\n",
      "Eval Loss:  0.21356163918972015\n",
      "Eval Loss:  0.22292226552963257\n",
      "Eval Loss:  0.26627111434936523\n",
      "Eval Loss:  0.19632810354232788\n",
      "Eval Loss:  0.20170000195503235\n",
      "Eval Loss:  0.324053019285202\n",
      "Eval Loss:  0.27195626497268677\n",
      "Eval Loss:  0.1862366646528244\n",
      "Eval Loss:  0.285432904958725\n",
      "Eval Loss:  0.32027286291122437\n",
      "Eval Loss:  0.18892377614974976\n",
      "Eval Loss:  0.26815471053123474\n",
      "Eval Loss:  0.25335660576820374\n",
      "Eval Loss:  0.18621769547462463\n",
      "[[16757  1334]\n",
      " [ 1520 10206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     18091\n",
      "           1       0.88      0.87      0.88     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.90      0.90     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.9042827916960123\n",
      "pre:  0.8844020797227037\n",
      "rec:  0.8703735289101143\n",
      "ma F1:  0.8994280728863899\n",
      "mi F1:  0.9042827916960123\n",
      "we F1:  0.9041449535493798\n",
      "29817 466\n",
      "Loss:  0.06321603059768677\n",
      "Loss:  0.05813692882657051\n",
      "Loss:  0.05578458309173584\n",
      "24 **********\n",
      "Epoch:  1447.3666632175446  fold:  8  kers:  64\n",
      "epoch:  25\n",
      "29817 466\n",
      "Loss:  0.060883525758981705\n",
      "Loss:  0.0671258270740509\n",
      "Loss:  0.06829597800970078\n",
      "25 **********\n",
      "Epoch:  1491.6013886928558  fold:  8  kers:  64\n",
      "epoch:  26\n",
      "29817 466\n",
      "Loss:  0.08255215734243393\n",
      "Loss:  0.0710819661617279\n",
      "Loss:  0.05033457279205322\n",
      "26 **********\n",
      "Epoch:  1534.3999540805817  fold:  8  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.5978776216506958\n",
      "Eval Loss:  1.04705810546875\n",
      "Eval Loss:  0.09822440147399902\n",
      "[[1744  329]\n",
      " [ 296  705]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      2073\n",
      "           1       0.68      0.70      0.69      1001\n",
      "\n",
      "    accuracy                           0.80      3074\n",
      "   macro avg       0.77      0.77      0.77      3074\n",
      "weighted avg       0.80      0.80      0.80      3074\n",
      "\n",
      "acc:  0.7966818477553675\n",
      "pre:  0.6818181818181818\n",
      "rec:  0.7042957042957043\n",
      "ma F1:  0.7704587420123525\n",
      "mi F1:  0.7966818477553675\n",
      "we F1:  0.7975147279185241\n",
      "Eval Loss:  0.1886066496372223\n",
      "Eval Loss:  0.26293665170669556\n",
      "Eval Loss:  0.2407175749540329\n",
      "Eval Loss:  0.26808345317840576\n",
      "Eval Loss:  0.1929607391357422\n",
      "Eval Loss:  0.2736150622367859\n",
      "Eval Loss:  0.34458160400390625\n",
      "Eval Loss:  0.23285186290740967\n",
      "Eval Loss:  0.25172531604766846\n",
      "Eval Loss:  0.18115220963954926\n",
      "Eval Loss:  0.15571962296962738\n",
      "Eval Loss:  0.21511046588420868\n",
      "Eval Loss:  0.29384589195251465\n",
      "Eval Loss:  0.17920202016830444\n",
      "Eval Loss:  0.27037176489830017\n",
      "Eval Loss:  0.2102581411600113\n",
      "Eval Loss:  0.22500570118427277\n",
      "Eval Loss:  0.2803294062614441\n",
      "Eval Loss:  0.1975516378879547\n",
      "Eval Loss:  0.22189947962760925\n",
      "Eval Loss:  0.34397581219673157\n",
      "Eval Loss:  0.2698013484477997\n",
      "Eval Loss:  0.2130698412656784\n",
      "Eval Loss:  0.25229427218437195\n",
      "Eval Loss:  0.32059523463249207\n",
      "Eval Loss:  0.2175687551498413\n",
      "Eval Loss:  0.27442824840545654\n",
      "Eval Loss:  0.2577577531337738\n",
      "Eval Loss:  0.19954806566238403\n",
      "[[17190   901]\n",
      " [ 1898  9828]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18091\n",
      "           1       0.92      0.84      0.88     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.89      0.90     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9061273769996981\n",
      "pre:  0.9160219964581974\n",
      "rec:  0.8381374722838137\n",
      "ma F1:  0.9000331333206233\n",
      "mi F1:  0.9061273769996981\n",
      "we F1:  0.9053020630974925\n",
      "29817 466\n",
      "Loss:  0.08599584549665451\n",
      "Loss:  0.07165582478046417\n",
      "Loss:  0.053448330610990524\n",
      "27 **********\n",
      "Epoch:  1616.5273616313934  fold:  8  kers:  64\n",
      "epoch:  28\n",
      "29817 466\n",
      "Loss:  0.07762344926595688\n",
      "Loss:  0.04719243198633194\n",
      "Loss:  0.02656860277056694\n",
      "28 **********\n",
      "Epoch:  1659.2261941432953  fold:  8  kers:  64\n",
      "epoch:  29\n",
      "29817 466\n",
      "Loss:  0.035050295293331146\n",
      "Loss:  0.09089430421590805\n",
      "Loss:  0.05703211948275566\n",
      "29 **********\n",
      "Epoch:  1701.9170472621918  fold:  8  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.42742910981178284\n",
      "Eval Loss:  1.0483436584472656\n",
      "Eval Loss:  0.0958223044872284\n",
      "[[1936  137]\n",
      " [ 333  668]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      2073\n",
      "           1       0.83      0.67      0.74      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.80      0.82      3074\n",
      "weighted avg       0.85      0.85      0.84      3074\n",
      "\n",
      "acc:  0.8471047495120364\n",
      "pre:  0.8298136645962733\n",
      "rec:  0.6673326673326674\n",
      "ma F1:  0.8157556596492679\n",
      "mi F1:  0.8471047495120364\n",
      "we F1:  0.8422589911420817\n",
      "update!  Acc:  0.8471047495120364\n",
      "Eval Loss:  0.18765214085578918\n",
      "Eval Loss:  0.25641587376594543\n",
      "Eval Loss:  0.24822047352790833\n",
      "Eval Loss:  0.27444154024124146\n",
      "Eval Loss:  0.19569896161556244\n",
      "Eval Loss:  0.27781108021736145\n",
      "Eval Loss:  0.34811586141586304\n",
      "Eval Loss:  0.21554410457611084\n",
      "Eval Loss:  0.2609671354293823\n",
      "Eval Loss:  0.1905646026134491\n",
      "Eval Loss:  0.15648497641086578\n",
      "Eval Loss:  0.1976507306098938\n",
      "Eval Loss:  0.2895510494709015\n",
      "Eval Loss:  0.17983675003051758\n",
      "Eval Loss:  0.2679688632488251\n",
      "Eval Loss:  0.2037915140390396\n",
      "Eval Loss:  0.22690646350383759\n",
      "Eval Loss:  0.2680252492427826\n",
      "Eval Loss:  0.2033626288175583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.22637256979942322\n",
      "Eval Loss:  0.3690928518772125\n",
      "Eval Loss:  0.289098858833313\n",
      "Eval Loss:  0.21823422610759735\n",
      "Eval Loss:  0.26083850860595703\n",
      "Eval Loss:  0.3299342393875122\n",
      "Eval Loss:  0.234502375125885\n",
      "Eval Loss:  0.27704817056655884\n",
      "Eval Loss:  0.2615375518798828\n",
      "Eval Loss:  0.19848507642745972\n",
      "[[17261   830]\n",
      " [ 2033  9693]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18091\n",
      "           1       0.92      0.83      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.91      0.89      0.90     29817\n",
      "weighted avg       0.91      0.90      0.90     29817\n",
      "\n",
      "acc:  0.9039809504645001\n",
      "pre:  0.9211251544236434\n",
      "rec:  0.8266245949172778\n",
      "ma F1:  0.897369271338723\n",
      "mi F1:  0.9039809504645001\n",
      "we F1:  0.902929966058011\n",
      "29817 466\n",
      "Loss:  0.07673262059688568\n",
      "Loss:  0.04527795687317848\n",
      "Loss:  0.044990237802267075\n",
      "30 **********\n",
      "Epoch:  1784.0639388561249  fold:  8  kers:  64\n",
      "epoch:  31\n",
      "29817 466\n",
      "Loss:  0.04279766604304314\n",
      "Loss:  0.08743032813072205\n",
      "Loss:  0.03178839012980461\n",
      "31 **********\n",
      "Epoch:  1826.8365740776062  fold:  8  kers:  64\n",
      "epoch:  32\n",
      "29817 466\n",
      "Loss:  0.06577175855636597\n",
      "Loss:  0.062147319316864014\n",
      "Loss:  0.11054952442646027\n",
      "32 **********\n",
      "Epoch:  1869.9413204193115  fold:  8  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.6102638840675354\n",
      "Eval Loss:  0.9454527497291565\n",
      "Eval Loss:  0.09418812394142151\n",
      "[[1815  258]\n",
      " [ 246  755]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      2073\n",
      "           1       0.75      0.75      0.75      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.81      0.81      0.81      3074\n",
      "weighted avg       0.84      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8360442420299284\n",
      "pre:  0.7453109575518263\n",
      "rec:  0.7542457542457542\n",
      "ma F1:  0.8139179589030632\n",
      "mi F1:  0.8360442420299284\n",
      "we F1:  0.8362947282540062\n",
      "Eval Loss:  0.2037360519170761\n",
      "Eval Loss:  0.2835524082183838\n",
      "Eval Loss:  0.233057901263237\n",
      "Eval Loss:  0.2779862880706787\n",
      "Eval Loss:  0.17819178104400635\n",
      "Eval Loss:  0.26386886835098267\n",
      "Eval Loss:  0.3125659227371216\n",
      "Eval Loss:  0.21592172980308533\n",
      "Eval Loss:  0.23640868067741394\n",
      "Eval Loss:  0.1805008053779602\n",
      "Eval Loss:  0.141825333237648\n",
      "Eval Loss:  0.22969743609428406\n",
      "Eval Loss:  0.29036152362823486\n",
      "Eval Loss:  0.17676587402820587\n",
      "Eval Loss:  0.2566564679145813\n",
      "Eval Loss:  0.19708746671676636\n",
      "Eval Loss:  0.2185794860124588\n",
      "Eval Loss:  0.26737263798713684\n",
      "Eval Loss:  0.22376863658428192\n",
      "Eval Loss:  0.22973589599132538\n",
      "Eval Loss:  0.2858339548110962\n",
      "Eval Loss:  0.26462817192077637\n",
      "Eval Loss:  0.20044776797294617\n",
      "Eval Loss:  0.28675878047943115\n",
      "Eval Loss:  0.28268149495124817\n",
      "Eval Loss:  0.2104368656873703\n",
      "Eval Loss:  0.24593044817447662\n",
      "Eval Loss:  0.24247783422470093\n",
      "Eval Loss:  0.20307713747024536\n",
      "[[16913  1178]\n",
      " [ 1534 10192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18091\n",
      "           1       0.90      0.87      0.88     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.90      0.90     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.909045175570983\n",
      "pre:  0.8963940193491645\n",
      "rec:  0.8691796008869179\n",
      "ma F1:  0.9041764870800936\n",
      "mi F1:  0.909045175570983\n",
      "we F1:  0.908787289378042\n",
      "29817 466\n",
      "Loss:  0.08084309101104736\n",
      "Loss:  0.057376254349946976\n",
      "Loss:  0.0607515424489975\n",
      "33 **********\n",
      "Epoch:  1952.569390296936  fold:  8  kers:  64\n",
      "epoch:  34\n",
      "29817 466\n",
      "Loss:  0.05284659564495087\n",
      "Loss:  0.04788094013929367\n",
      "Loss:  0.05698518827557564\n",
      "34 **********\n",
      "Epoch:  1995.7738699913025  fold:  8  kers:  64\n",
      "epoch:  35\n",
      "29817 466\n",
      "Loss:  0.07182687520980835\n",
      "Loss:  0.06875814497470856\n",
      "Loss:  0.0671762079000473\n",
      "35 **********\n",
      "Epoch:  2038.7260246276855  fold:  8  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.34410321712493896\n",
      "Eval Loss:  0.9730910658836365\n",
      "Eval Loss:  0.0980215072631836\n",
      "[[1897  176]\n",
      " [ 263  738]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      2073\n",
      "           1       0.81      0.74      0.77      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.84      0.83      0.83      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8571893298633702\n",
      "pre:  0.8074398249452954\n",
      "rec:  0.7372627372627373\n",
      "ma F1:  0.8335241133478778\n",
      "mi F1:  0.8571893298633702\n",
      "we F1:  0.8554129072258828\n",
      "update!  Acc:  0.8571893298633702\n",
      "Eval Loss:  0.1795615255832672\n",
      "Eval Loss:  0.23998410999774933\n",
      "Eval Loss:  0.21223723888397217\n",
      "Eval Loss:  0.25850552320480347\n",
      "Eval Loss:  0.16109037399291992\n",
      "Eval Loss:  0.25168517231941223\n",
      "Eval Loss:  0.3030843138694763\n",
      "Eval Loss:  0.20178024470806122\n",
      "Eval Loss:  0.2503975033760071\n",
      "Eval Loss:  0.16006414592266083\n",
      "Eval Loss:  0.14235571026802063\n",
      "Eval Loss:  0.19634927809238434\n",
      "Eval Loss:  0.28455549478530884\n",
      "Eval Loss:  0.18227490782737732\n",
      "Eval Loss:  0.26199623942375183\n",
      "Eval Loss:  0.20292986929416656\n",
      "Eval Loss:  0.2127985805273056\n",
      "Eval Loss:  0.2905862033367157\n",
      "Eval Loss:  0.22742082178592682\n",
      "Eval Loss:  0.20367474853992462\n",
      "Eval Loss:  0.291108101606369\n",
      "Eval Loss:  0.268545538187027\n",
      "Eval Loss:  0.17533327639102936\n",
      "Eval Loss:  0.26570925116539\n",
      "Eval Loss:  0.2769816815853119\n",
      "Eval Loss:  0.21346931159496307\n",
      "Eval Loss:  0.23922908306121826\n",
      "Eval Loss:  0.234102264046669\n",
      "Eval Loss:  0.1739434152841568\n",
      "[[17002  1089]\n",
      " [ 1511 10215]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18091\n",
      "           1       0.90      0.87      0.89     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9128014220075795\n",
      "pre:  0.9036624203821656\n",
      "rec:  0.8711410540678833\n",
      "ma F1:  0.90803664460504\n",
      "mi F1:  0.9128014220075795\n",
      "we F1:  0.9125051591427098\n",
      "29817 466\n",
      "Loss:  0.05246151238679886\n",
      "Loss:  0.05812244489789009\n",
      "Loss:  0.05187322944402695\n",
      "36 **********\n",
      "Epoch:  2120.8364775180817  fold:  8  kers:  64\n",
      "epoch:  37\n",
      "29817 466\n",
      "Loss:  0.074055515229702\n",
      "Loss:  0.0860530212521553\n",
      "Loss:  0.05794347822666168\n",
      "37 **********\n",
      "Epoch:  2163.4924240112305  fold:  8  kers:  64\n",
      "epoch:  38\n",
      "29817 466\n",
      "Loss:  0.07468929886817932\n",
      "Loss:  0.0616588331758976\n",
      "Loss:  0.05949723348021507\n",
      "38 **********\n",
      "Epoch:  2206.1822810173035  fold:  8  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.5001581907272339\n",
      "Eval Loss:  0.9929362535476685\n",
      "Eval Loss:  0.10399243980646133\n",
      "[[1869  204]\n",
      " [ 238  763]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      2073\n",
      "           1       0.79      0.76      0.78      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.84      0.83      0.83      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8562134027325959\n",
      "pre:  0.7890382626680456\n",
      "rec:  0.7622377622377622\n",
      "ma F1:  0.8348324386353911\n",
      "mi F1:  0.8562134027325959\n",
      "we F1:  0.8555561217386494\n",
      "Eval Loss:  0.19134628772735596\n",
      "Eval Loss:  0.23201781511306763\n",
      "Eval Loss:  0.21063226461410522\n",
      "Eval Loss:  0.2538924217224121\n",
      "Eval Loss:  0.1472613513469696\n",
      "Eval Loss:  0.23663471639156342\n",
      "Eval Loss:  0.3100930154323578\n",
      "Eval Loss:  0.20354019105434418\n",
      "Eval Loss:  0.251773476600647\n",
      "Eval Loss:  0.1607760637998581\n",
      "Eval Loss:  0.13227888941764832\n",
      "Eval Loss:  0.20365650951862335\n",
      "Eval Loss:  0.2733214497566223\n",
      "Eval Loss:  0.1823037564754486\n",
      "Eval Loss:  0.24173279106616974\n",
      "Eval Loss:  0.19348077476024628\n",
      "Eval Loss:  0.20373554527759552\n",
      "Eval Loss:  0.261420875787735\n",
      "Eval Loss:  0.21412919461727142\n",
      "Eval Loss:  0.20293442904949188\n",
      "Eval Loss:  0.26314640045166016\n",
      "Eval Loss:  0.2637213468551636\n",
      "Eval Loss:  0.16530293226242065\n",
      "Eval Loss:  0.2561495304107666\n",
      "Eval Loss:  0.257366806268692\n",
      "Eval Loss:  0.19581101834774017\n",
      "Eval Loss:  0.2345033437013626\n",
      "Eval Loss:  0.22338590025901794\n",
      "Eval Loss:  0.1856408268213272\n",
      "[[16901  1190]\n",
      " [ 1350 10376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18091\n",
      "           1       0.90      0.88      0.89     11726\n",
      "\n",
      "    accuracy                           0.91     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.91      0.91      0.91     29817\n",
      "\n",
      "acc:  0.9148136968843278\n",
      "pre:  0.8971122254885008\n",
      "rec:  0.884871226334641\n",
      "ma F1:  0.9105290484004908\n",
      "mi F1:  0.9148136968843278\n",
      "we F1:  0.9147086327069462\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05813371762633324\n",
      "Loss:  0.06819701939821243\n",
      "Loss:  0.0658591017127037\n",
      "39 **********\n",
      "Epoch:  2288.1371495723724  fold:  8  kers:  64\n",
      "epoch:  40\n",
      "29817 466\n",
      "Loss:  0.035736121237277985\n",
      "Loss:  0.08807644993066788\n",
      "Loss:  0.04224063828587532\n",
      "40 **********\n",
      "Epoch:  2330.8778698444366  fold:  8  kers:  64\n",
      "epoch:  41\n",
      "29817 466\n",
      "Loss:  0.07166460156440735\n",
      "Loss:  0.0716838389635086\n",
      "Loss:  0.042143747210502625\n",
      "41 **********\n",
      "Epoch:  2373.6594808101654  fold:  8  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.590151846408844\n",
      "Eval Loss:  1.0874782800674438\n",
      "Eval Loss:  0.09803299605846405\n",
      "[[1861  212]\n",
      " [ 228  773]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      2073\n",
      "           1       0.78      0.77      0.78      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.84      0.83      0.84      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8568640208197787\n",
      "pre:  0.7847715736040609\n",
      "rec:  0.7722277722277723\n",
      "ma F1:  0.8363653696974449\n",
      "mi F1:  0.8568640208197789\n",
      "we F1:  0.8565625700679798\n",
      "Eval Loss:  0.1906328946352005\n",
      "Eval Loss:  0.23805584013462067\n",
      "Eval Loss:  0.21807251870632172\n",
      "Eval Loss:  0.2543029487133026\n",
      "Eval Loss:  0.14504750072956085\n",
      "Eval Loss:  0.2472696304321289\n",
      "Eval Loss:  0.3202156722545624\n",
      "Eval Loss:  0.19413748383522034\n",
      "Eval Loss:  0.24725234508514404\n",
      "Eval Loss:  0.16188035905361176\n",
      "Eval Loss:  0.13996952772140503\n",
      "Eval Loss:  0.19506169855594635\n",
      "Eval Loss:  0.2652885615825653\n",
      "Eval Loss:  0.17647451162338257\n",
      "Eval Loss:  0.23855748772621155\n",
      "Eval Loss:  0.1932429075241089\n",
      "Eval Loss:  0.1911388784646988\n",
      "Eval Loss:  0.25803452730178833\n",
      "Eval Loss:  0.21018348634243011\n",
      "Eval Loss:  0.19328823685646057\n",
      "Eval Loss:  0.2855013906955719\n",
      "Eval Loss:  0.23484113812446594\n",
      "Eval Loss:  0.17267686128616333\n",
      "Eval Loss:  0.26164934039115906\n",
      "Eval Loss:  0.254154235124588\n",
      "Eval Loss:  0.20485267043113708\n",
      "Eval Loss:  0.24248099327087402\n",
      "Eval Loss:  0.23217782378196716\n",
      "Eval Loss:  0.171922504901886\n",
      "[[16893  1198]\n",
      " [ 1293 10433]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18091\n",
      "           1       0.90      0.89      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.91      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9164570547003388\n",
      "pre:  0.8969993981600894\n",
      "rec:  0.8897322190005117\n",
      "ma F1:  0.9123424663469304\n",
      "mi F1:  0.9164570547003388\n",
      "we F1:  0.9163965460480827\n",
      "29817 466\n",
      "Loss:  0.0469558946788311\n",
      "Loss:  0.09005720913410187\n",
      "Loss:  0.04786825552582741\n",
      "42 **********\n",
      "Epoch:  2455.637288570404  fold:  8  kers:  64\n",
      "epoch:  43\n",
      "29817 466\n",
      "Loss:  0.04850395396351814\n",
      "Loss:  0.051471810787916183\n",
      "Loss:  0.061821889132261276\n",
      "43 **********\n",
      "Epoch:  2498.345096349716  fold:  8  kers:  64\n",
      "epoch:  44\n",
      "29817 466\n",
      "Loss:  0.05809041112661362\n",
      "Loss:  0.041488103568553925\n",
      "Loss:  0.03433714434504509\n",
      "44 **********\n",
      "Epoch:  2541.0349526405334  fold:  8  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.467443585395813\n",
      "Eval Loss:  1.1658846139907837\n",
      "Eval Loss:  0.09909726679325104\n",
      "[[1916  157]\n",
      " [ 305  696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      2073\n",
      "           1       0.82      0.70      0.75      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.81      0.82      3074\n",
      "weighted avg       0.85      0.85      0.85      3074\n",
      "\n",
      "acc:  0.8497072218607677\n",
      "pre:  0.8159437280187574\n",
      "rec:  0.6953046953046953\n",
      "ma F1:  0.8216085363335308\n",
      "mi F1:  0.8497072218607677\n",
      "we F1:  0.8462985288623817\n",
      "Eval Loss:  0.18011511862277985\n",
      "Eval Loss:  0.22945529222488403\n",
      "Eval Loss:  0.20241579413414001\n",
      "Eval Loss:  0.24436534941196442\n",
      "Eval Loss:  0.15363949537277222\n",
      "Eval Loss:  0.24913150072097778\n",
      "Eval Loss:  0.3266928791999817\n",
      "Eval Loss:  0.17916810512542725\n",
      "Eval Loss:  0.21580849587917328\n",
      "Eval Loss:  0.16507722437381744\n",
      "Eval Loss:  0.14576317369937897\n",
      "Eval Loss:  0.17274776101112366\n",
      "Eval Loss:  0.25555089116096497\n",
      "Eval Loss:  0.1666146069765091\n",
      "Eval Loss:  0.2277146875858307\n",
      "Eval Loss:  0.19652000069618225\n",
      "Eval Loss:  0.18285152316093445\n",
      "Eval Loss:  0.254930317401886\n",
      "Eval Loss:  0.2276516705751419\n",
      "Eval Loss:  0.17657890915870667\n",
      "Eval Loss:  0.29549261927604675\n",
      "Eval Loss:  0.23518764972686768\n",
      "Eval Loss:  0.17931799590587616\n",
      "Eval Loss:  0.2360496073961258\n",
      "Eval Loss:  0.25655755400657654\n",
      "Eval Loss:  0.24722722172737122\n",
      "Eval Loss:  0.24969962239265442\n",
      "Eval Loss:  0.22764796018600464\n",
      "Eval Loss:  0.16878044605255127\n",
      "[[17266   825]\n",
      " [ 1625 10101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18091\n",
      "           1       0.92      0.86      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.91783210919945\n",
      "pre:  0.9244920373421197\n",
      "rec:  0.8614190687361419\n",
      "ma F1:  0.9127966673928631\n",
      "mi F1:  0.91783210919945\n",
      "we F1:  0.91726988261951\n",
      "29817 466\n",
      "Loss:  0.039874352514743805\n",
      "Loss:  0.027774116024374962\n",
      "Loss:  0.040707629173994064\n",
      "45 **********\n",
      "Epoch:  2623.247560977936  fold:  8  kers:  64\n",
      "epoch:  46\n",
      "29817 466\n",
      "Loss:  0.04930983483791351\n",
      "Loss:  0.1077074408531189\n",
      "Loss:  0.05962875112891197\n",
      "46 **********\n",
      "Epoch:  2665.980302333832  fold:  8  kers:  64\n",
      "epoch:  47\n",
      "29817 466\n",
      "Loss:  0.04275033250451088\n",
      "Loss:  0.0392286479473114\n",
      "Loss:  0.06669057905673981\n",
      "47 **********\n",
      "Epoch:  2708.704067468643  fold:  8  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.5112091302871704\n",
      "Eval Loss:  0.9561975002288818\n",
      "Eval Loss:  0.11021949350833893\n",
      "[[1844  229]\n",
      " [ 208  793]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      2073\n",
      "           1       0.78      0.79      0.78      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.84      0.84      0.84      3074\n",
      "weighted avg       0.86      0.86      0.86      3074\n",
      "\n",
      "acc:  0.8578399479505531\n",
      "pre:  0.7759295499021527\n",
      "rec:  0.7922077922077922\n",
      "ma F1:  0.8390223939843318\n",
      "mi F1:  0.857839947950553\n",
      "we F1:  0.8582159409413148\n",
      "update!  Acc:  0.8578399479505531\n",
      "Eval Loss:  0.19069136679172516\n",
      "Eval Loss:  0.22030022740364075\n",
      "Eval Loss:  0.18865230679512024\n",
      "Eval Loss:  0.2285226732492447\n",
      "Eval Loss:  0.12955138087272644\n",
      "Eval Loss:  0.2434106320142746\n",
      "Eval Loss:  0.2908177375793457\n",
      "Eval Loss:  0.17985543608665466\n",
      "Eval Loss:  0.24148151278495789\n",
      "Eval Loss:  0.16492614150047302\n",
      "Eval Loss:  0.13921521604061127\n",
      "Eval Loss:  0.19528748095035553\n",
      "Eval Loss:  0.26683807373046875\n",
      "Eval Loss:  0.17123109102249146\n",
      "Eval Loss:  0.23649471998214722\n",
      "Eval Loss:  0.20460624992847443\n",
      "Eval Loss:  0.20416894555091858\n",
      "Eval Loss:  0.2602306306362152\n",
      "Eval Loss:  0.19969308376312256\n",
      "Eval Loss:  0.18402262032032013\n",
      "Eval Loss:  0.250273734331131\n",
      "Eval Loss:  0.22647972404956818\n",
      "Eval Loss:  0.16124002635478973\n",
      "Eval Loss:  0.25107064843177795\n",
      "Eval Loss:  0.23590447008609772\n",
      "Eval Loss:  0.1981261670589447\n",
      "Eval Loss:  0.24326755106449127\n",
      "Eval Loss:  0.2135160118341446\n",
      "Eval Loss:  0.16870924830436707\n",
      "[[16804  1287]\n",
      " [ 1129 10597]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     18091\n",
      "           1       0.89      0.90      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.91      0.92      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.918972398296274\n",
      "pre:  0.891703130259172\n",
      "rec:  0.9037182329865256\n",
      "ma F1:  0.9153020392165494\n",
      "mi F1:  0.918972398296274\n",
      "we F1:  0.9190658277685789\n",
      "29817 466\n",
      "Loss:  0.05008779838681221\n",
      "Loss:  0.08100692182779312\n",
      "Loss:  0.04225453361868858\n",
      "48 **********\n",
      "Epoch:  2790.6310114860535  fold:  8  kers:  64\n",
      "epoch:  49\n",
      "29817 466\n",
      "Loss:  0.06107185408473015\n",
      "Loss:  0.034379079937934875\n",
      "Loss:  0.06290077418088913\n",
      "49 **********\n",
      "Epoch:  2833.5143501758575  fold:  8  kers:  64\n",
      "epoch:  50\n",
      "29817 466\n",
      "Loss:  0.03321308270096779\n",
      "Loss:  0.041176483035087585\n",
      "Loss:  0.04632924869656563\n",
      "50 **********\n",
      "Epoch:  2876.311918258667  fold:  8  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.4362010955810547\n",
      "Eval Loss:  1.1735981702804565\n",
      "Eval Loss:  0.09692789614200592\n",
      "[[1932  141]\n",
      " [ 299  702]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      2073\n",
      "           1       0.83      0.70      0.76      1001\n",
      "\n",
      "    accuracy                           0.86      3074\n",
      "   macro avg       0.85      0.82      0.83      3074\n",
      "weighted avg       0.86      0.86      0.85      3074\n",
      "\n",
      "acc:  0.8568640208197787\n",
      "pre:  0.8327402135231317\n",
      "rec:  0.7012987012987013\n",
      "ma F1:  0.8295789015313404\n",
      "mi F1:  0.8568640208197789\n",
      "we F1:  0.853359103057524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.17953930795192719\n",
      "Eval Loss:  0.19647245109081268\n",
      "Eval Loss:  0.19390209019184113\n",
      "Eval Loss:  0.2338121086359024\n",
      "Eval Loss:  0.14505380392074585\n",
      "Eval Loss:  0.24156956374645233\n",
      "Eval Loss:  0.3019551932811737\n",
      "Eval Loss:  0.1742546260356903\n",
      "Eval Loss:  0.23259033262729645\n",
      "Eval Loss:  0.1528976708650589\n",
      "Eval Loss:  0.14021487534046173\n",
      "Eval Loss:  0.19146043062210083\n",
      "Eval Loss:  0.25586915016174316\n",
      "Eval Loss:  0.17792262136936188\n",
      "Eval Loss:  0.21779537200927734\n",
      "Eval Loss:  0.19218701124191284\n",
      "Eval Loss:  0.18355317413806915\n",
      "Eval Loss:  0.25768351554870605\n",
      "Eval Loss:  0.2084498107433319\n",
      "Eval Loss:  0.18375547230243683\n",
      "Eval Loss:  0.2560573220252991\n",
      "Eval Loss:  0.2594585120677948\n",
      "Eval Loss:  0.15875472128391266\n",
      "Eval Loss:  0.23714226484298706\n",
      "Eval Loss:  0.23398657143115997\n",
      "Eval Loss:  0.2177732139825821\n",
      "Eval Loss:  0.2337655872106552\n",
      "Eval Loss:  0.22418707609176636\n",
      "Eval Loss:  0.19435207545757294\n",
      "[[17101   990]\n",
      " [ 1374 10352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     18091\n",
      "           1       0.91      0.88      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.92     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9207163698561224\n",
      "pre:  0.9127138070886969\n",
      "rec:  0.8828244925805901\n",
      "ma F1:  0.9164350765137838\n",
      "mi F1:  0.9207163698561224\n",
      "we F1:  0.920472775746853\n",
      "29817 466\n",
      "Loss:  0.06591612845659256\n",
      "Loss:  0.03914806246757507\n",
      "Loss:  0.03819352760910988\n",
      "51 **********\n",
      "Epoch:  2958.2468404769897  fold:  8  kers:  64\n",
      "epoch:  52\n",
      "29817 466\n",
      "Loss:  0.062238723039627075\n",
      "Loss:  0.06235732510685921\n",
      "Loss:  0.05876234546303749\n",
      "52 **********\n",
      "Epoch:  3000.9297153949738  fold:  8  kers:  64\n",
      "epoch:  53\n",
      "29817 466\n",
      "Loss:  0.06298869848251343\n",
      "Loss:  0.034027956426143646\n",
      "Loss:  0.04019281640648842\n",
      "53 **********\n",
      "Epoch:  3043.660462141037  fold:  8  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.605522871017456\n",
      "Eval Loss:  1.0403703451156616\n",
      "Eval Loss:  0.1264338493347168\n",
      "[[1786  287]\n",
      " [ 200  801]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88      2073\n",
      "           1       0.74      0.80      0.77      1001\n",
      "\n",
      "    accuracy                           0.84      3074\n",
      "   macro avg       0.82      0.83      0.82      3074\n",
      "weighted avg       0.85      0.84      0.84      3074\n",
      "\n",
      "acc:  0.8415744957709824\n",
      "pre:  0.7362132352941176\n",
      "rec:  0.8001998001998002\n",
      "ma F1:  0.8234469058646807\n",
      "mi F1:  0.8415744957709824\n",
      "we F1:  0.843175612849001\n",
      "Eval Loss:  0.1995512843132019\n",
      "Eval Loss:  0.24257127940654755\n",
      "Eval Loss:  0.19973011314868927\n",
      "Eval Loss:  0.22369033098220825\n",
      "Eval Loss:  0.13984982669353485\n",
      "Eval Loss:  0.2596046030521393\n",
      "Eval Loss:  0.30625611543655396\n",
      "Eval Loss:  0.19597528874874115\n",
      "Eval Loss:  0.25437453389167786\n",
      "Eval Loss:  0.16374559700489044\n",
      "Eval Loss:  0.14885012805461884\n",
      "Eval Loss:  0.22330978512763977\n",
      "Eval Loss:  0.27714645862579346\n",
      "Eval Loss:  0.1704174429178238\n",
      "Eval Loss:  0.26504194736480713\n",
      "Eval Loss:  0.20590753853321075\n",
      "Eval Loss:  0.20978094637393951\n",
      "Eval Loss:  0.24990758299827576\n",
      "Eval Loss:  0.2446729838848114\n",
      "Eval Loss:  0.16934505105018616\n",
      "Eval Loss:  0.26733362674713135\n",
      "Eval Loss:  0.27090984582901\n",
      "Eval Loss:  0.1479114145040512\n",
      "Eval Loss:  0.2537986636161804\n",
      "Eval Loss:  0.2411748170852661\n",
      "Eval Loss:  0.2078981250524521\n",
      "Eval Loss:  0.22116853296756744\n",
      "Eval Loss:  0.2158321887254715\n",
      "Eval Loss:  0.16854149103164673\n",
      "[[16496  1595]\n",
      " [  920 10806]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93     18091\n",
      "           1       0.87      0.92      0.90     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.91      0.92      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9156521447496395\n",
      "pre:  0.8713813402144989\n",
      "rec:  0.921541872761385\n",
      "ma F1:  0.9124644166370078\n",
      "mi F1:  0.9156521447496395\n",
      "we F1:  0.916030302302544\n",
      "29817 466\n",
      "Loss:  0.09010133147239685\n",
      "Loss:  0.049956027418375015\n",
      "Loss:  0.06533652544021606\n",
      "54 **********\n",
      "Epoch:  3125.672179698944  fold:  8  kers:  64\n",
      "epoch:  55\n",
      "29817 466\n",
      "Loss:  0.05907650664448738\n",
      "Loss:  0.07813148200511932\n",
      "Loss:  0.08996664732694626\n",
      "55 **********\n",
      "Epoch:  3168.420878171921  fold:  8  kers:  64\n",
      "epoch:  56\n",
      "29817 466\n",
      "Loss:  0.03233644366264343\n",
      "Loss:  0.04405698552727699\n",
      "Loss:  0.11558525264263153\n",
      "56 **********\n",
      "Epoch:  3211.296238422394  fold:  8  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.4238678812980652\n",
      "Eval Loss:  1.114073395729065\n",
      "Eval Loss:  0.10144336521625519\n",
      "[[1931  142]\n",
      " [ 325  676]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      2073\n",
      "           1       0.83      0.68      0.74      1001\n",
      "\n",
      "    accuracy                           0.85      3074\n",
      "   macro avg       0.84      0.80      0.82      3074\n",
      "weighted avg       0.85      0.85      0.84      3074\n",
      "\n",
      "acc:  0.8480806766428106\n",
      "pre:  0.8264058679706602\n",
      "rec:  0.6753246753246753\n",
      "ma F1:  0.8176942113170811\n",
      "mi F1:  0.8480806766428105\n",
      "we F1:  0.843649821539537\n",
      "Eval Loss:  0.1785345822572708\n",
      "Eval Loss:  0.24288028478622437\n",
      "Eval Loss:  0.21484142541885376\n",
      "Eval Loss:  0.2228439748287201\n",
      "Eval Loss:  0.1422606110572815\n",
      "Eval Loss:  0.2602119743824005\n",
      "Eval Loss:  0.3349578380584717\n",
      "Eval Loss:  0.17757348716259003\n",
      "Eval Loss:  0.24442051351070404\n",
      "Eval Loss:  0.16960015892982483\n",
      "Eval Loss:  0.12983910739421844\n",
      "Eval Loss:  0.1663437783718109\n",
      "Eval Loss:  0.2635593116283417\n",
      "Eval Loss:  0.16778570413589478\n",
      "Eval Loss:  0.20205442607402802\n",
      "Eval Loss:  0.1836523711681366\n",
      "Eval Loss:  0.18747171759605408\n",
      "Eval Loss:  0.26229187846183777\n",
      "Eval Loss:  0.2217114269733429\n",
      "Eval Loss:  0.17977818846702576\n",
      "Eval Loss:  0.2816462516784668\n",
      "Eval Loss:  0.2726516127586365\n",
      "Eval Loss:  0.15022224187850952\n",
      "Eval Loss:  0.22073395550251007\n",
      "Eval Loss:  0.2460278570652008\n",
      "Eval Loss:  0.23389378190040588\n",
      "Eval Loss:  0.2342815101146698\n",
      "Eval Loss:  0.21784795820713043\n",
      "Eval Loss:  0.22300565242767334\n",
      "[[17187   904]\n",
      " [ 1557 10169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18091\n",
      "           1       0.92      0.87      0.89     11726\n",
      "\n",
      "    accuracy                           0.92     29817\n",
      "   macro avg       0.92      0.91      0.91     29817\n",
      "weighted avg       0.92      0.92      0.92     29817\n",
      "\n",
      "acc:  0.9174631921387129\n",
      "pre:  0.9183599747132665\n",
      "rec:  0.8672181477059526\n",
      "ma F1:  0.9126226063284872\n",
      "mi F1:  0.9174631921387129\n",
      "we F1:  0.9170127928035635\n",
      "29817 466\n",
      "Loss:  0.038460779935121536\n",
      "Loss:  0.0409570075571537\n",
      "Loss:  0.047380752861499786\n",
      "57 **********\n",
      "Epoch:  3293.3129422664642  fold:  8  kers:  64\n",
      "epoch:  58\n",
      "29817 466\n",
      "Loss:  0.04496215283870697\n",
      "Loss:  0.06310174614191055\n",
      "Loss:  0.08424808830022812\n",
      "58 **********\n",
      "Epoch:  3336.092558145523  fold:  8  kers:  64\n",
      "epoch:  59\n",
      "29817 466\n",
      "Loss:  0.06833671778440475\n",
      "Loss:  0.05444379150867462\n",
      "Loss:  0.060424014925956726\n",
      "59 **********\n",
      "Epoch:  3378.7325472831726  fold:  8  kers:  64\n",
      "Eval Loss:  0.6200824975967407\n",
      "Eval Loss:  0.9059217572212219\n",
      "Eval Loss:  0.153413325548172\n",
      "[[1687  386]\n",
      " [ 149  852]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      2073\n",
      "           1       0.69      0.85      0.76      1001\n",
      "\n",
      "    accuracy                           0.83      3074\n",
      "   macro avg       0.80      0.83      0.81      3074\n",
      "weighted avg       0.84      0.83      0.83      3074\n",
      "\n",
      "acc:  0.8259596616785947\n",
      "pre:  0.6882067851373183\n",
      "rec:  0.8511488511488512\n",
      "ma F1:  0.8120951969956072\n",
      "mi F1:  0.8259596616785947\n",
      "we F1:  0.8298948450676581\n",
      "update!  Acc:  0.8578399479505531\n",
      "Epoch:  3382.3897688388824  fold:  8  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29483 3408\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29483 461\n",
      "Loss:  0.16792096197605133\n",
      "Loss:  0.15348957479000092\n",
      "Loss:  0.15342146158218384\n",
      "0 **********\n",
      "Epoch:  55.081340312957764  fold:  9  kers:  64\n",
      "epoch:  1\n",
      "29483 461\n",
      "Loss:  0.13399724662303925\n",
      "Loss:  0.12158320099115372\n",
      "Loss:  0.12857994437217712\n",
      "1 **********\n",
      "Epoch:  97.59966111183167  fold:  9  kers:  64\n",
      "epoch:  2\n",
      "29483 461\n",
      "Loss:  0.12717671692371368\n",
      "Loss:  0.12849728763103485\n",
      "Loss:  0.09826672822237015\n",
      "2 **********\n",
      "Epoch:  139.90582394599915  fold:  9  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.20430967211723328\n",
      "Eval Loss:  0.881584644317627\n",
      "Eval Loss:  0.36363232135772705\n",
      "[[1497  245]\n",
      " [ 376 1290]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      1742\n",
      "           1       0.84      0.77      0.81      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.82      0.82      0.82      3408\n",
      "weighted avg       0.82      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8177816901408451\n",
      "pre:  0.8403908794788274\n",
      "rec:  0.7743097238895558\n",
      "ma F1:  0.8171069466103045\n",
      "mi F1:  0.8177816901408451\n",
      "we F1:  0.8173546785345609\n",
      "update!  Acc:  0.8177816901408451\n",
      "Eval Loss:  0.4399642050266266\n",
      "Eval Loss:  0.41833075881004333\n",
      "Eval Loss:  0.37333086133003235\n",
      "Eval Loss:  0.3828830122947693\n",
      "Eval Loss:  0.42657849192619324\n",
      "Eval Loss:  0.4371492862701416\n",
      "Eval Loss:  0.35370349884033203\n",
      "Eval Loss:  0.517327070236206\n",
      "Eval Loss:  0.38582009077072144\n",
      "Eval Loss:  0.47206276655197144\n",
      "Eval Loss:  0.41178223490715027\n",
      "Eval Loss:  0.3553735613822937\n",
      "Eval Loss:  0.42768675088882446\n",
      "Eval Loss:  0.44825878739356995\n",
      "Eval Loss:  0.47859126329421997\n",
      "Eval Loss:  0.4229786694049835\n",
      "Eval Loss:  0.39697495102882385\n",
      "Eval Loss:  0.46867087483406067\n",
      "Eval Loss:  0.4291732609272003\n",
      "Eval Loss:  0.35872530937194824\n",
      "Eval Loss:  0.39512011408805847\n",
      "Eval Loss:  0.3538641333580017\n",
      "Eval Loss:  0.36254945397377014\n",
      "Eval Loss:  0.41899409890174866\n",
      "Eval Loss:  0.4154765009880066\n",
      "Eval Loss:  0.4662964344024658\n",
      "Eval Loss:  0.48295482993125916\n",
      "Eval Loss:  0.3843947649002075\n",
      "[[15941  2481]\n",
      " [ 3012  8049]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85     18422\n",
      "           1       0.76      0.73      0.75     11061\n",
      "\n",
      "    accuracy                           0.81     29483\n",
      "   macro avg       0.80      0.80      0.80     29483\n",
      "weighted avg       0.81      0.81      0.81     29483\n",
      "\n",
      "acc:  0.813689244649459\n",
      "pre:  0.7643874643874644\n",
      "rec:  0.7276918904258205\n",
      "ma F1:  0.7993092699810355\n",
      "mi F1:  0.813689244649459\n",
      "we F1:  0.8127217121419916\n",
      "29483 461\n",
      "Loss:  0.1591075360774994\n",
      "Loss:  0.09105919301509857\n",
      "Loss:  0.11433867365121841\n",
      "3 **********\n",
      "Epoch:  221.88163709640503  fold:  9  kers:  64\n",
      "epoch:  4\n",
      "29483 461\n",
      "Loss:  0.13164737820625305\n",
      "Loss:  0.10832391679286957\n",
      "Loss:  0.08010493218898773\n",
      "4 **********\n",
      "Epoch:  264.3401119709015  fold:  9  kers:  64\n",
      "epoch:  5\n",
      "29483 461\n",
      "Loss:  0.08105160295963287\n",
      "Loss:  0.07952535897493362\n",
      "Loss:  0.07253745198249817\n",
      "5 **********\n",
      "Epoch:  306.8853552341461  fold:  9  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.09349754452705383\n",
      "Eval Loss:  1.3009458780288696\n",
      "Eval Loss:  0.29278677701950073\n",
      "[[1628  114]\n",
      " [ 521 1145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84      1742\n",
      "           1       0.91      0.69      0.78      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.83      0.81      0.81      3408\n",
      "weighted avg       0.83      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8136737089201878\n",
      "pre:  0.90945194598888\n",
      "rec:  0.6872749099639855\n",
      "ma F1:  0.8098544306717013\n",
      "mi F1:  0.8136737089201878\n",
      "we F1:  0.8104553937087302\n",
      "Eval Loss:  0.3487863540649414\n",
      "Eval Loss:  0.34429869055747986\n",
      "Eval Loss:  0.3510322570800781\n",
      "Eval Loss:  0.3387249708175659\n",
      "Eval Loss:  0.38340502977371216\n",
      "Eval Loss:  0.27657589316368103\n",
      "Eval Loss:  0.36588430404663086\n",
      "Eval Loss:  0.48564958572387695\n",
      "Eval Loss:  0.28568023443222046\n",
      "Eval Loss:  0.398659348487854\n",
      "Eval Loss:  0.36134564876556396\n",
      "Eval Loss:  0.3857318162918091\n",
      "Eval Loss:  0.35783159732818604\n",
      "Eval Loss:  0.3797207176685333\n",
      "Eval Loss:  0.4148963689804077\n",
      "Eval Loss:  0.39212310314178467\n",
      "Eval Loss:  0.31379953026771545\n",
      "Eval Loss:  0.40873655676841736\n",
      "Eval Loss:  0.3767876923084259\n",
      "Eval Loss:  0.3609403371810913\n",
      "Eval Loss:  0.34238201379776\n",
      "Eval Loss:  0.2596534192562103\n",
      "Eval Loss:  0.24257488548755646\n",
      "Eval Loss:  0.3571297228336334\n",
      "Eval Loss:  0.38290008902549744\n",
      "Eval Loss:  0.43810635805130005\n",
      "Eval Loss:  0.32378408312797546\n",
      "Eval Loss:  0.29417645931243896\n",
      "[[17071  1351]\n",
      " [ 2771  8290]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89     18422\n",
      "           1       0.86      0.75      0.80     11061\n",
      "\n",
      "    accuracy                           0.86     29483\n",
      "   macro avg       0.86      0.84      0.85     29483\n",
      "weighted avg       0.86      0.86      0.86     29483\n",
      "\n",
      "acc:  0.860190618322423\n",
      "pre:  0.8598693081630536\n",
      "rec:  0.7494801555013109\n",
      "ma F1:  0.8465817629957062\n",
      "mi F1:  0.860190618322423\n",
      "we F1:  0.8579898923727659\n",
      "29483 461\n",
      "Loss:  0.06810552626848221\n",
      "Loss:  0.0760955736041069\n",
      "Loss:  0.10349052399396896\n",
      "6 **********\n",
      "Epoch:  388.7095732688904  fold:  9  kers:  64\n",
      "epoch:  7\n",
      "29483 461\n",
      "Loss:  0.10455355793237686\n",
      "Loss:  0.06909327208995819\n",
      "Loss:  0.06526557356119156\n",
      "7 **********\n",
      "Epoch:  431.266783952713  fold:  9  kers:  64\n",
      "epoch:  8\n",
      "29483 461\n",
      "Loss:  0.09166020154953003\n",
      "Loss:  0.08469469845294952\n",
      "Loss:  0.07923202216625214\n",
      "8 **********\n",
      "Epoch:  473.71628284454346  fold:  9  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.06392998993396759\n",
      "Eval Loss:  1.5526280403137207\n",
      "Eval Loss:  0.2658398151397705\n",
      "[[1646   96]\n",
      " [ 526 1140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      1742\n",
      "           1       0.92      0.68      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.84      0.81      0.81      3408\n",
      "weighted avg       0.84      0.82      0.81      3408\n",
      "\n",
      "acc:  0.8174882629107981\n",
      "pre:  0.9223300970873787\n",
      "rec:  0.6842737094837935\n",
      "ma F1:  0.8133741746657195\n",
      "mi F1:  0.8174882629107981\n",
      "we F1:  0.8139921009633994\n",
      "Eval Loss:  0.3502047657966614\n",
      "Eval Loss:  0.316607803106308\n",
      "Eval Loss:  0.3375108540058136\n",
      "Eval Loss:  0.3275189995765686\n",
      "Eval Loss:  0.3535199463367462\n",
      "Eval Loss:  0.2533862888813019\n",
      "Eval Loss:  0.3411520719528198\n",
      "Eval Loss:  0.43113577365875244\n",
      "Eval Loss:  0.2691832184791565\n",
      "Eval Loss:  0.3613894581794739\n",
      "Eval Loss:  0.3412173092365265\n",
      "Eval Loss:  0.3712879419326782\n",
      "Eval Loss:  0.32390788197517395\n",
      "Eval Loss:  0.36912140250205994\n",
      "Eval Loss:  0.40329688787460327\n",
      "Eval Loss:  0.37138083577156067\n",
      "Eval Loss:  0.24945195019245148\n",
      "Eval Loss:  0.3950016498565674\n",
      "Eval Loss:  0.3522374927997589\n",
      "Eval Loss:  0.3121741712093353\n",
      "Eval Loss:  0.330402135848999\n",
      "Eval Loss:  0.22868157923221588\n",
      "Eval Loss:  0.23345932364463806\n",
      "Eval Loss:  0.33966442942619324\n",
      "Eval Loss:  0.3453182876110077\n",
      "Eval Loss:  0.4136712849140167\n",
      "Eval Loss:  0.28064271807670593\n",
      "Eval Loss:  0.28124701976776123\n",
      "[[17389  1033]\n",
      " [ 2714  8347]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     18422\n",
      "           1       0.89      0.75      0.82     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.88      0.85      0.86     29483\n",
      "weighted avg       0.87      0.87      0.87     29483\n",
      "\n",
      "acc:  0.8729098124342841\n",
      "pre:  0.8898720682302772\n",
      "rec:  0.7546333966187506\n",
      "ma F1:  0.8597152120848846\n",
      "mi F1:  0.8729098124342841\n",
      "we F1:  0.8704568016858502\n",
      "29483 461\n",
      "Loss:  0.08712361007928848\n",
      "Loss:  0.11934629082679749\n",
      "Loss:  0.07995602488517761\n",
      "9 **********\n",
      "Epoch:  555.6791305541992  fold:  9  kers:  64\n",
      "epoch:  10\n",
      "29483 461\n",
      "Loss:  0.07337789237499237\n",
      "Loss:  0.05409178510308266\n",
      "Loss:  0.04907482489943504\n",
      "10 **********\n",
      "Epoch:  598.2413282394409  fold:  9  kers:  64\n",
      "epoch:  11\n",
      "29483 461\n",
      "Loss:  0.071273572742939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07622473686933517\n",
      "Loss:  0.09344494342803955\n",
      "11 **********\n",
      "Epoch:  640.7666244506836  fold:  9  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.038476377725601196\n",
      "Eval Loss:  1.9052586555480957\n",
      "Eval Loss:  0.2825358808040619\n",
      "[[1677   65]\n",
      " [ 639 1027]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.83      1742\n",
      "           1       0.94      0.62      0.74      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.83      0.79      0.79      3408\n",
      "weighted avg       0.83      0.79      0.79      3408\n",
      "\n",
      "acc:  0.7934272300469484\n",
      "pre:  0.9404761904761905\n",
      "rec:  0.6164465786314526\n",
      "ma F1:  0.7856290459833501\n",
      "mi F1:  0.7934272300469484\n",
      "we F1:  0.7865408336584785\n",
      "Eval Loss:  0.3480004370212555\n",
      "Eval Loss:  0.3285049796104431\n",
      "Eval Loss:  0.32981377840042114\n",
      "Eval Loss:  0.30605947971343994\n",
      "Eval Loss:  0.31381678581237793\n",
      "Eval Loss:  0.20951279997825623\n",
      "Eval Loss:  0.3403733968734741\n",
      "Eval Loss:  0.38897377252578735\n",
      "Eval Loss:  0.2808239758014679\n",
      "Eval Loss:  0.3332854211330414\n",
      "Eval Loss:  0.313405841588974\n",
      "Eval Loss:  0.341817706823349\n",
      "Eval Loss:  0.29502156376838684\n",
      "Eval Loss:  0.30739539861679077\n",
      "Eval Loss:  0.39486438035964966\n",
      "Eval Loss:  0.329931378364563\n",
      "Eval Loss:  0.2605412006378174\n",
      "Eval Loss:  0.3518538773059845\n",
      "Eval Loss:  0.32130128145217896\n",
      "Eval Loss:  0.29793545603752136\n",
      "Eval Loss:  0.34239113330841064\n",
      "Eval Loss:  0.2059081643819809\n",
      "Eval Loss:  0.246651753783226\n",
      "Eval Loss:  0.3047531843185425\n",
      "Eval Loss:  0.33057087659835815\n",
      "Eval Loss:  0.3830377757549286\n",
      "Eval Loss:  0.24408763647079468\n",
      "Eval Loss:  0.25797808170318604\n",
      "[[17510   912]\n",
      " [ 2562  8499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18422\n",
      "           1       0.90      0.77      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.89      0.86      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.882169385747719\n",
      "pre:  0.9030921262352566\n",
      "rec:  0.7683753729319229\n",
      "ma F1:  0.8700284878671429\n",
      "mi F1:  0.882169385747719\n",
      "we F1:  0.8799462716091162\n",
      "29483 461\n",
      "Loss:  0.05990114435553551\n",
      "Loss:  0.07321789860725403\n",
      "Loss:  0.10365492105484009\n",
      "12 **********\n",
      "Epoch:  722.8533098697662  fold:  9  kers:  64\n",
      "epoch:  13\n",
      "29483 461\n",
      "Loss:  0.06023530662059784\n",
      "Loss:  0.055177029222249985\n",
      "Loss:  0.06306805461645126\n",
      "13 **********\n",
      "Epoch:  765.5521421432495  fold:  9  kers:  64\n",
      "epoch:  14\n",
      "29483 461\n",
      "Loss:  0.0797979012131691\n",
      "Loss:  0.06679739058017731\n",
      "Loss:  0.050455182790756226\n",
      "14 **********\n",
      "Epoch:  808.0495126247406  fold:  9  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.037894777953624725\n",
      "Eval Loss:  1.570011854171753\n",
      "Eval Loss:  0.285379022359848\n",
      "[[1676   66]\n",
      " [ 662 1004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      1742\n",
      "           1       0.94      0.60      0.73      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.83      0.78      0.78      3408\n",
      "weighted avg       0.83      0.79      0.78      3408\n",
      "\n",
      "acc:  0.7863849765258216\n",
      "pre:  0.9383177570093458\n",
      "rec:  0.602641056422569\n",
      "ma F1:  0.7777433780529756\n",
      "mi F1:  0.7863849765258216\n",
      "we F1:  0.7787207016897855\n",
      "Eval Loss:  0.3176337778568268\n",
      "Eval Loss:  0.3150026798248291\n",
      "Eval Loss:  0.3173847496509552\n",
      "Eval Loss:  0.28243348002433777\n",
      "Eval Loss:  0.2934831380844116\n",
      "Eval Loss:  0.2032269537448883\n",
      "Eval Loss:  0.3197409510612488\n",
      "Eval Loss:  0.37101370096206665\n",
      "Eval Loss:  0.26113200187683105\n",
      "Eval Loss:  0.3125683069229126\n",
      "Eval Loss:  0.27669817209243774\n",
      "Eval Loss:  0.33501118421554565\n",
      "Eval Loss:  0.2707567811012268\n",
      "Eval Loss:  0.24837645888328552\n",
      "Eval Loss:  0.35189712047576904\n",
      "Eval Loss:  0.28276991844177246\n",
      "Eval Loss:  0.259115070104599\n",
      "Eval Loss:  0.3040957450866699\n",
      "Eval Loss:  0.3204197287559509\n",
      "Eval Loss:  0.29397013783454895\n",
      "Eval Loss:  0.32950249314308167\n",
      "Eval Loss:  0.18749329447746277\n",
      "Eval Loss:  0.22076742351055145\n",
      "Eval Loss:  0.28723379969596863\n",
      "Eval Loss:  0.29698529839515686\n",
      "Eval Loss:  0.3587300181388855\n",
      "Eval Loss:  0.2399934083223343\n",
      "Eval Loss:  0.2281971275806427\n",
      "[[17381  1041]\n",
      " [ 2250  8811]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     18422\n",
      "           1       0.89      0.80      0.84     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.89      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8883763524743072\n",
      "pre:  0.8943361753958587\n",
      "rec:  0.7965825874694874\n",
      "ma F1:  0.8780745643124728\n",
      "mi F1:  0.8883763524743072\n",
      "we F1:  0.8869230430358406\n",
      "29483 461\n",
      "Loss:  0.061737384647130966\n",
      "Loss:  0.0745609775185585\n",
      "Loss:  0.051139939576387405\n",
      "15 **********\n",
      "Epoch:  889.9654855728149  fold:  9  kers:  64\n",
      "epoch:  16\n",
      "29483 461\n",
      "Loss:  0.051833003759384155\n",
      "Loss:  0.06992807239294052\n",
      "Loss:  0.05639493465423584\n",
      "16 **********\n",
      "Epoch:  932.4073395729065  fold:  9  kers:  64\n",
      "epoch:  17\n",
      "29483 461\n",
      "Loss:  0.0624818354845047\n",
      "Loss:  0.0833335816860199\n",
      "Loss:  0.08397364616394043\n",
      "17 **********\n",
      "Epoch:  974.8594689369202  fold:  9  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.03153808042407036\n",
      "Eval Loss:  1.831480622291565\n",
      "Eval Loss:  0.289255827665329\n",
      "[[1708   34]\n",
      " [ 811  855]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80      1742\n",
      "           1       0.96      0.51      0.67      1666\n",
      "\n",
      "    accuracy                           0.75      3408\n",
      "   macro avg       0.82      0.75      0.74      3408\n",
      "weighted avg       0.82      0.75      0.74      3408\n",
      "\n",
      "acc:  0.7520539906103286\n",
      "pre:  0.9617547806524185\n",
      "rec:  0.5132052821128451\n",
      "ma F1:  0.7354828368707034\n",
      "mi F1:  0.7520539906103286\n",
      "we F1:  0.7369592819870122\n",
      "Eval Loss:  0.347564160823822\n",
      "Eval Loss:  0.2961761951446533\n",
      "Eval Loss:  0.2956719696521759\n",
      "Eval Loss:  0.29070842266082764\n",
      "Eval Loss:  0.2855221629142761\n",
      "Eval Loss:  0.2114897072315216\n",
      "Eval Loss:  0.30893760919570923\n",
      "Eval Loss:  0.34962236881256104\n",
      "Eval Loss:  0.2735896706581116\n",
      "Eval Loss:  0.2830565273761749\n",
      "Eval Loss:  0.27637892961502075\n",
      "Eval Loss:  0.29156485199928284\n",
      "Eval Loss:  0.2411605566740036\n",
      "Eval Loss:  0.2279331386089325\n",
      "Eval Loss:  0.3584217429161072\n",
      "Eval Loss:  0.26276347041130066\n",
      "Eval Loss:  0.23919826745986938\n",
      "Eval Loss:  0.30424588918685913\n",
      "Eval Loss:  0.3144710063934326\n",
      "Eval Loss:  0.2749057412147522\n",
      "Eval Loss:  0.3354197144508362\n",
      "Eval Loss:  0.19247710704803467\n",
      "Eval Loss:  0.23209434747695923\n",
      "Eval Loss:  0.27102214097976685\n",
      "Eval Loss:  0.2851034998893738\n",
      "Eval Loss:  0.3248651921749115\n",
      "Eval Loss:  0.22263583540916443\n",
      "Eval Loss:  0.2330324798822403\n",
      "[[17598   824]\n",
      " [ 2345  8716]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18422\n",
      "           1       0.91      0.79      0.85     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.90      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8925143302920326\n",
      "pre:  0.9136268343815513\n",
      "rec:  0.7879938522737546\n",
      "ma F1:  0.8817855932803258\n",
      "mi F1:  0.8925143302920326\n",
      "we F1:  0.8906770854153376\n",
      "29483 461\n",
      "Loss:  0.06954328715801239\n",
      "Loss:  0.07949286699295044\n",
      "Loss:  0.051889508962631226\n",
      "18 **********\n",
      "Epoch:  1056.9278876781464  fold:  9  kers:  64\n",
      "epoch:  19\n",
      "29483 461\n",
      "Loss:  0.08360426872968674\n",
      "Loss:  0.045025065541267395\n",
      "Loss:  0.06786991655826569\n",
      "19 **********\n",
      "Epoch:  1099.4262552261353  fold:  9  kers:  64\n",
      "epoch:  20\n",
      "29483 461\n",
      "Loss:  0.0864235907793045\n",
      "Loss:  0.06631672382354736\n",
      "Loss:  0.05301707983016968\n",
      "20 **********\n",
      "Epoch:  1141.9545426368713  fold:  9  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.029402725398540497\n",
      "Eval Loss:  1.4022828340530396\n",
      "Eval Loss:  0.3068511486053467\n",
      "[[1689   53]\n",
      " [ 768  898]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80      1742\n",
      "           1       0.94      0.54      0.69      1666\n",
      "\n",
      "    accuracy                           0.76      3408\n",
      "   macro avg       0.82      0.75      0.75      3408\n",
      "weighted avg       0.81      0.76      0.75      3408\n",
      "\n",
      "acc:  0.7590962441314554\n",
      "pre:  0.9442691903259727\n",
      "rec:  0.539015606242497\n",
      "ma F1:  0.745379629391171\n",
      "mi F1:  0.7590962441314553\n",
      "we F1:  0.7466975342208317\n",
      "Eval Loss:  0.3219946622848511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.28015750646591187\n",
      "Eval Loss:  0.2859055995941162\n",
      "Eval Loss:  0.26459434628486633\n",
      "Eval Loss:  0.23730072379112244\n",
      "Eval Loss:  0.1918538212776184\n",
      "Eval Loss:  0.30711817741394043\n",
      "Eval Loss:  0.34454411268234253\n",
      "Eval Loss:  0.26623719930648804\n",
      "Eval Loss:  0.2719302475452423\n",
      "Eval Loss:  0.2541506886482239\n",
      "Eval Loss:  0.3007906973361969\n",
      "Eval Loss:  0.22463679313659668\n",
      "Eval Loss:  0.22203028202056885\n",
      "Eval Loss:  0.34401825070381165\n",
      "Eval Loss:  0.2373894304037094\n",
      "Eval Loss:  0.2522040903568268\n",
      "Eval Loss:  0.2823171317577362\n",
      "Eval Loss:  0.2983989119529724\n",
      "Eval Loss:  0.2705555260181427\n",
      "Eval Loss:  0.3375576138496399\n",
      "Eval Loss:  0.17578043043613434\n",
      "Eval Loss:  0.2142634391784668\n",
      "Eval Loss:  0.24421989917755127\n",
      "Eval Loss:  0.24968332052230835\n",
      "Eval Loss:  0.29147079586982727\n",
      "Eval Loss:  0.218969464302063\n",
      "Eval Loss:  0.2099153697490692\n",
      "[[17493   929]\n",
      " [ 2065  8996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18422\n",
      "           1       0.91      0.81      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8984499542109012\n",
      "pre:  0.9063979848866499\n",
      "rec:  0.8133080191664407\n",
      "ma F1:  0.8892512483685431\n",
      "mi F1:  0.8984499542109012\n",
      "we F1:  0.8972201401780757\n",
      "29483 461\n",
      "Loss:  0.06303879618644714\n",
      "Loss:  0.0680481567978859\n",
      "Loss:  0.06660950928926468\n",
      "21 **********\n",
      "Epoch:  1223.7687878608704  fold:  9  kers:  64\n",
      "epoch:  22\n",
      "29483 461\n",
      "Loss:  0.05577287822961807\n",
      "Loss:  0.06936852633953094\n",
      "Loss:  0.05361860245466232\n",
      "22 **********\n",
      "Epoch:  1266.2661590576172  fold:  9  kers:  64\n",
      "epoch:  23\n",
      "29483 461\n",
      "Loss:  0.08794030547142029\n",
      "Loss:  0.05663777515292168\n",
      "Loss:  0.05241331830620766\n",
      "23 **********\n",
      "Epoch:  1308.720904827118  fold:  9  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.026560302823781967\n",
      "Eval Loss:  1.6500871181488037\n",
      "Eval Loss:  0.33350232243537903\n",
      "[[1693   49]\n",
      " [ 815  851]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80      1742\n",
      "           1       0.95      0.51      0.66      1666\n",
      "\n",
      "    accuracy                           0.75      3408\n",
      "   macro avg       0.81      0.74      0.73      3408\n",
      "weighted avg       0.81      0.75      0.73      3408\n",
      "\n",
      "acc:  0.7464788732394366\n",
      "pre:  0.9455555555555556\n",
      "rec:  0.5108043217286915\n",
      "ma F1:  0.7299975241850443\n",
      "mi F1:  0.7464788732394367\n",
      "we F1:  0.7314851518906663\n",
      "Eval Loss:  0.3653685450553894\n",
      "Eval Loss:  0.294349730014801\n",
      "Eval Loss:  0.30949151515960693\n",
      "Eval Loss:  0.2560330033302307\n",
      "Eval Loss:  0.26488691568374634\n",
      "Eval Loss:  0.20774178206920624\n",
      "Eval Loss:  0.2809978425502777\n",
      "Eval Loss:  0.32317817211151123\n",
      "Eval Loss:  0.27869269251823425\n",
      "Eval Loss:  0.2455689162015915\n",
      "Eval Loss:  0.26313817501068115\n",
      "Eval Loss:  0.2910878658294678\n",
      "Eval Loss:  0.21202129125595093\n",
      "Eval Loss:  0.23737964034080505\n",
      "Eval Loss:  0.3730705678462982\n",
      "Eval Loss:  0.2438511699438095\n",
      "Eval Loss:  0.2321522831916809\n",
      "Eval Loss:  0.28549131751060486\n",
      "Eval Loss:  0.29890933632850647\n",
      "Eval Loss:  0.26595643162727356\n",
      "Eval Loss:  0.33813127875328064\n",
      "Eval Loss:  0.1895212084054947\n",
      "Eval Loss:  0.21011897921562195\n",
      "Eval Loss:  0.25400736927986145\n",
      "Eval Loss:  0.26497215032577515\n",
      "Eval Loss:  0.302874892950058\n",
      "Eval Loss:  0.24435169994831085\n",
      "Eval Loss:  0.2064879834651947\n",
      "[[17715   707]\n",
      " [ 2307  8754]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18422\n",
      "           1       0.93      0.79      0.85     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8977715971916019\n",
      "pre:  0.9252721699608921\n",
      "rec:  0.7914293463520478\n",
      "ma F1:  0.8873667362983148\n",
      "mi F1:  0.8977715971916019\n",
      "we F1:  0.8959137936619445\n",
      "29483 461\n",
      "Loss:  0.0689530000090599\n",
      "Loss:  0.041539717465639114\n",
      "Loss:  0.10104352980852127\n",
      "24 **********\n",
      "Epoch:  1390.6650733947754  fold:  9  kers:  64\n",
      "epoch:  25\n",
      "29483 461\n",
      "Loss:  0.04737214371562004\n",
      "Loss:  0.049990683794021606\n",
      "Loss:  0.047385286539793015\n",
      "25 **********\n",
      "Epoch:  1433.228632926941  fold:  9  kers:  64\n",
      "epoch:  26\n",
      "29483 461\n",
      "Loss:  0.0496496818959713\n",
      "Loss:  0.062280163168907166\n",
      "Loss:  0.04896078258752823\n",
      "26 **********\n",
      "Epoch:  1475.7718811035156  fold:  9  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.025865893810987473\n",
      "Eval Loss:  1.6042875051498413\n",
      "Eval Loss:  0.2819647490978241\n",
      "[[1701   41]\n",
      " [ 800  866]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80      1742\n",
      "           1       0.95      0.52      0.67      1666\n",
      "\n",
      "    accuracy                           0.75      3408\n",
      "   macro avg       0.82      0.75      0.74      3408\n",
      "weighted avg       0.81      0.75      0.74      3408\n",
      "\n",
      "acc:  0.7532276995305164\n",
      "pre:  0.9547960308710033\n",
      "rec:  0.5198079231692677\n",
      "ma F1:  0.7374676875719218\n",
      "mi F1:  0.7532276995305164\n",
      "we F1:  0.7389021317741412\n",
      "Eval Loss:  0.35485154390335083\n",
      "Eval Loss:  0.3012547791004181\n",
      "Eval Loss:  0.2933139204978943\n",
      "Eval Loss:  0.2608222961425781\n",
      "Eval Loss:  0.24341559410095215\n",
      "Eval Loss:  0.22237160801887512\n",
      "Eval Loss:  0.2739213705062866\n",
      "Eval Loss:  0.30776116251945496\n",
      "Eval Loss:  0.26773756742477417\n",
      "Eval Loss:  0.26382479071617126\n",
      "Eval Loss:  0.2616642415523529\n",
      "Eval Loss:  0.2745814025402069\n",
      "Eval Loss:  0.19563902914524078\n",
      "Eval Loss:  0.23386035859584808\n",
      "Eval Loss:  0.3907127380371094\n",
      "Eval Loss:  0.24878667294979095\n",
      "Eval Loss:  0.24239276349544525\n",
      "Eval Loss:  0.30377358198165894\n",
      "Eval Loss:  0.28157728910446167\n",
      "Eval Loss:  0.24610620737075806\n",
      "Eval Loss:  0.3207170367240906\n",
      "Eval Loss:  0.2017960548400879\n",
      "Eval Loss:  0.20574449002742767\n",
      "Eval Loss:  0.2398117333650589\n",
      "Eval Loss:  0.2612754702568054\n",
      "Eval Loss:  0.296365350484848\n",
      "Eval Loss:  0.22306224703788757\n",
      "Eval Loss:  0.20021000504493713\n",
      "[[17702   720]\n",
      " [ 2282  8779]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18422\n",
      "           1       0.92      0.79      0.85     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8981786114031814\n",
      "pre:  0.9242025476365934\n",
      "rec:  0.793689539824609\n",
      "ma F1:  0.8879117283879323\n",
      "mi F1:  0.8981786114031814\n",
      "we F1:  0.8963813603362962\n",
      "29483 461\n",
      "Loss:  0.06455020606517792\n",
      "Loss:  0.06991217285394669\n",
      "Loss:  0.06502702087163925\n",
      "27 **********\n",
      "Epoch:  1557.5931079387665  fold:  9  kers:  64\n",
      "epoch:  28\n",
      "29483 461\n",
      "Loss:  0.10080075263977051\n",
      "Loss:  0.06922224164009094\n",
      "Loss:  0.06581677496433258\n",
      "28 **********\n",
      "Epoch:  1600.0226604938507  fold:  9  kers:  64\n",
      "epoch:  29\n",
      "29483 461\n",
      "Loss:  0.0890512466430664\n",
      "Loss:  0.05214175581932068\n",
      "Loss:  0.04662349820137024\n",
      "29 **********\n",
      "Epoch:  1642.6736204624176  fold:  9  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.027331195771694183\n",
      "Eval Loss:  1.4725490808486938\n",
      "Eval Loss:  0.330219030380249\n",
      "[[1698   44]\n",
      " [ 808  858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80      1742\n",
      "           1       0.95      0.52      0.67      1666\n",
      "\n",
      "    accuracy                           0.75      3408\n",
      "   macro avg       0.81      0.74      0.73      3408\n",
      "weighted avg       0.81      0.75      0.74      3408\n",
      "\n",
      "acc:  0.75\n",
      "pre:  0.9512195121951219\n",
      "rec:  0.5150060024009604\n",
      "ma F1:  0.7338296636570041\n",
      "mi F1:  0.75\n",
      "we F1:  0.7352926940880369\n",
      "Eval Loss:  0.31123074889183044\n",
      "Eval Loss:  0.26954156160354614\n",
      "Eval Loss:  0.29533660411834717\n",
      "Eval Loss:  0.23719827830791473\n",
      "Eval Loss:  0.2349616289138794\n",
      "Eval Loss:  0.1995389312505722\n",
      "Eval Loss:  0.24594296514987946\n",
      "Eval Loss:  0.31024420261383057\n",
      "Eval Loss:  0.2580327093601227\n",
      "Eval Loss:  0.25668826699256897\n",
      "Eval Loss:  0.23362693190574646\n",
      "Eval Loss:  0.27456775307655334\n",
      "Eval Loss:  0.17955811321735382\n",
      "Eval Loss:  0.20575912296772003\n",
      "Eval Loss:  0.34755298495292664\n",
      "Eval Loss:  0.24082660675048828\n",
      "Eval Loss:  0.2142460197210312\n",
      "Eval Loss:  0.2809349298477173\n",
      "Eval Loss:  0.28157395124435425\n",
      "Eval Loss:  0.22992292046546936\n",
      "Eval Loss:  0.3243892788887024\n",
      "Eval Loss:  0.1938066929578781\n",
      "Eval Loss:  0.18931664526462555\n",
      "Eval Loss:  0.22620517015457153\n",
      "Eval Loss:  0.24790596961975098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2760140299797058\n",
      "Eval Loss:  0.2130025178194046\n",
      "Eval Loss:  0.19273293018341064\n",
      "[[17733   689]\n",
      " [ 2116  8945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     18422\n",
      "           1       0.93      0.81      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.89      0.90     29483\n",
      "weighted avg       0.91      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9048604280432792\n",
      "pre:  0.9284824579613867\n",
      "rec:  0.8086972244824157\n",
      "ma F1:  0.8955834602543202\n",
      "mi F1:  0.9048604280432792\n",
      "we F1:  0.9033540291999879\n",
      "29483 461\n",
      "Loss:  0.062272150069475174\n",
      "Loss:  0.05181843787431717\n",
      "Loss:  0.07120970636606216\n",
      "30 **********\n",
      "Epoch:  1728.3980660438538  fold:  9  kers:  64\n",
      "epoch:  31\n",
      "29483 461\n",
      "Loss:  0.109364353120327\n",
      "Loss:  0.09562010318040848\n",
      "Loss:  0.06043791398406029\n",
      "31 **********\n",
      "Epoch:  1770.812658071518  fold:  9  kers:  64\n",
      "epoch:  32\n",
      "29483 461\n",
      "Loss:  0.07365070283412933\n",
      "Loss:  0.06670736521482468\n",
      "Loss:  0.11636252701282501\n",
      "32 **********\n",
      "Epoch:  1813.2761194705963  fold:  9  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.03188808634877205\n",
      "Eval Loss:  1.0533486604690552\n",
      "Eval Loss:  0.2590557932853699\n",
      "[[1668   74]\n",
      " [ 695  971]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.81      1742\n",
      "           1       0.93      0.58      0.72      1666\n",
      "\n",
      "    accuracy                           0.77      3408\n",
      "   macro avg       0.82      0.77      0.76      3408\n",
      "weighted avg       0.82      0.77      0.77      3408\n",
      "\n",
      "acc:  0.7743544600938967\n",
      "pre:  0.9291866028708134\n",
      "rec:  0.5828331332533013\n",
      "ma F1:  0.7645041561626271\n",
      "mi F1:  0.7743544600938967\n",
      "we F1:  0.7655782208667541\n",
      "Eval Loss:  0.27883094549179077\n",
      "Eval Loss:  0.250301718711853\n",
      "Eval Loss:  0.27618855237960815\n",
      "Eval Loss:  0.2352834790945053\n",
      "Eval Loss:  0.2049044370651245\n",
      "Eval Loss:  0.16972368955612183\n",
      "Eval Loss:  0.2268374115228653\n",
      "Eval Loss:  0.2652757167816162\n",
      "Eval Loss:  0.2391638606786728\n",
      "Eval Loss:  0.25209441781044006\n",
      "Eval Loss:  0.23621445894241333\n",
      "Eval Loss:  0.2639444172382355\n",
      "Eval Loss:  0.17908354103565216\n",
      "Eval Loss:  0.1873840093612671\n",
      "Eval Loss:  0.34442153573036194\n",
      "Eval Loss:  0.21326756477355957\n",
      "Eval Loss:  0.21217955648899078\n",
      "Eval Loss:  0.25577160716056824\n",
      "Eval Loss:  0.26676538586616516\n",
      "Eval Loss:  0.23256024718284607\n",
      "Eval Loss:  0.2872450351715088\n",
      "Eval Loss:  0.18006116151809692\n",
      "Eval Loss:  0.1713816523551941\n",
      "Eval Loss:  0.20217826962471008\n",
      "Eval Loss:  0.2216140627861023\n",
      "Eval Loss:  0.25459742546081543\n",
      "Eval Loss:  0.20431017875671387\n",
      "Eval Loss:  0.19141967594623566\n",
      "[[17479   943]\n",
      " [ 1661  9400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18422\n",
      "           1       0.91      0.85      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.90      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9116779160872367\n",
      "pre:  0.9088272261432853\n",
      "rec:  0.8498327456830305\n",
      "ma F1:  0.904507557534155\n",
      "mi F1:  0.9116779160872367\n",
      "we F1:  0.9110406692199126\n",
      "29483 461\n",
      "Loss:  0.06591453403234482\n",
      "Loss:  0.06224454194307327\n",
      "Loss:  0.04951946809887886\n",
      "33 **********\n",
      "Epoch:  1895.1232771873474  fold:  9  kers:  64\n",
      "epoch:  34\n",
      "29483 461\n",
      "Loss:  0.07394563406705856\n",
      "Loss:  0.060464031994342804\n",
      "Loss:  0.09525444358587265\n",
      "34 **********\n",
      "Epoch:  1937.5907275676727  fold:  9  kers:  64\n",
      "epoch:  35\n",
      "29483 461\n",
      "Loss:  0.04682088643312454\n",
      "Loss:  0.03855601325631142\n",
      "Loss:  0.09049651026725769\n",
      "35 **********\n",
      "Epoch:  1980.0641622543335  fold:  9  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.02528485655784607\n",
      "Eval Loss:  1.2510058879852295\n",
      "Eval Loss:  0.27882495522499084\n",
      "[[1675   67]\n",
      " [ 753  913]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80      1742\n",
      "           1       0.93      0.55      0.69      1666\n",
      "\n",
      "    accuracy                           0.76      3408\n",
      "   macro avg       0.81      0.75      0.75      3408\n",
      "weighted avg       0.81      0.76      0.75      3408\n",
      "\n",
      "acc:  0.7593896713615024\n",
      "pre:  0.9316326530612244\n",
      "rec:  0.5480192076830732\n",
      "ma F1:  0.7467277878377571\n",
      "mi F1:  0.7593896713615024\n",
      "we F1:  0.7479906528611228\n",
      "Eval Loss:  0.3041265904903412\n",
      "Eval Loss:  0.24681469798088074\n",
      "Eval Loss:  0.27956125140190125\n",
      "Eval Loss:  0.21781566739082336\n",
      "Eval Loss:  0.2432434856891632\n",
      "Eval Loss:  0.1846519112586975\n",
      "Eval Loss:  0.23922885954380035\n",
      "Eval Loss:  0.2610633969306946\n",
      "Eval Loss:  0.25061243772506714\n",
      "Eval Loss:  0.24200120568275452\n",
      "Eval Loss:  0.24769513309001923\n",
      "Eval Loss:  0.25659602880477905\n",
      "Eval Loss:  0.1767532080411911\n",
      "Eval Loss:  0.168707937002182\n",
      "Eval Loss:  0.34950512647628784\n",
      "Eval Loss:  0.22307050228118896\n",
      "Eval Loss:  0.2094721496105194\n",
      "Eval Loss:  0.2771082818508148\n",
      "Eval Loss:  0.24641522765159607\n",
      "Eval Loss:  0.2076287865638733\n",
      "Eval Loss:  0.292453795671463\n",
      "Eval Loss:  0.1937187910079956\n",
      "Eval Loss:  0.1820373833179474\n",
      "Eval Loss:  0.20536261796951294\n",
      "Eval Loss:  0.22521989047527313\n",
      "Eval Loss:  0.274480938911438\n",
      "Eval Loss:  0.19988463819026947\n",
      "Eval Loss:  0.19415301084518433\n",
      "[[17522   900]\n",
      " [ 1697  9364]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18422\n",
      "           1       0.91      0.85      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.90      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9119153410439914\n",
      "pre:  0.9123148869836322\n",
      "rec:  0.8465780670825422\n",
      "ma F1:  0.9046120688594628\n",
      "mi F1:  0.9119153410439914\n",
      "we F1:  0.9112018441169176\n",
      "29483 461\n",
      "Loss:  0.04796934500336647\n",
      "Loss:  0.06692498922348022\n",
      "Loss:  0.03783981874585152\n",
      "36 **********\n",
      "Epoch:  2061.998459815979  fold:  9  kers:  64\n",
      "epoch:  37\n",
      "29483 461\n",
      "Loss:  0.027041908353567123\n",
      "Loss:  0.05223153904080391\n",
      "Loss:  0.07901636511087418\n",
      "37 **********\n",
      "Epoch:  2104.575616836548  fold:  9  kers:  64\n",
      "epoch:  38\n",
      "29483 461\n",
      "Loss:  0.04415944218635559\n",
      "Loss:  0.04588088020682335\n",
      "Loss:  0.06112648546695709\n",
      "38 **********\n",
      "Epoch:  2147.1228544712067  fold:  9  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.027752572670578957\n",
      "Eval Loss:  1.3042628765106201\n",
      "Eval Loss:  0.2596745789051056\n",
      "[[1671   71]\n",
      " [ 661 1005]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      1742\n",
      "           1       0.93      0.60      0.73      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.83      0.78      0.78      3408\n",
      "weighted avg       0.82      0.79      0.78      3408\n",
      "\n",
      "acc:  0.7852112676056338\n",
      "pre:  0.9340148698884758\n",
      "rec:  0.6032412965186075\n",
      "ma F1:  0.7766827906916787\n",
      "mi F1:  0.7852112676056338\n",
      "we F1:  0.7776560102794574\n",
      "Eval Loss:  0.3050517141819\n",
      "Eval Loss:  0.2542245388031006\n",
      "Eval Loss:  0.2747618556022644\n",
      "Eval Loss:  0.21994225680828094\n",
      "Eval Loss:  0.201105535030365\n",
      "Eval Loss:  0.1608864665031433\n",
      "Eval Loss:  0.22607535123825073\n",
      "Eval Loss:  0.26347821950912476\n",
      "Eval Loss:  0.23164117336273193\n",
      "Eval Loss:  0.2246766984462738\n",
      "Eval Loss:  0.22803211212158203\n",
      "Eval Loss:  0.2382759153842926\n",
      "Eval Loss:  0.1747816801071167\n",
      "Eval Loss:  0.18496879935264587\n",
      "Eval Loss:  0.3612893223762512\n",
      "Eval Loss:  0.2041836529970169\n",
      "Eval Loss:  0.20098836719989777\n",
      "Eval Loss:  0.2320539504289627\n",
      "Eval Loss:  0.23787860572338104\n",
      "Eval Loss:  0.21479754149913788\n",
      "Eval Loss:  0.29324057698249817\n",
      "Eval Loss:  0.17142817378044128\n",
      "Eval Loss:  0.16026808321475983\n",
      "Eval Loss:  0.20835474133491516\n",
      "Eval Loss:  0.21298186480998993\n",
      "Eval Loss:  0.2577642500400543\n",
      "Eval Loss:  0.190130814909935\n",
      "Eval Loss:  0.18734320998191833\n",
      "[[17586   836]\n",
      " [ 1700  9361]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18422\n",
      "           1       0.92      0.85      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.90      0.91     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9139843299528542\n",
      "pre:  0.918015102481122\n",
      "rec:  0.8463068438658349\n",
      "ma F1:  0.9067250509415793\n",
      "mi F1:  0.9139843299528542\n",
      "we F1:  0.9132217746865027\n",
      "29483 461\n",
      "Loss:  0.04919205233454704\n",
      "Loss:  0.03325257822871208\n",
      "Loss:  0.05907979607582092\n",
      "39 **********\n",
      "Epoch:  2229.2223374843597  fold:  9  kers:  64\n",
      "epoch:  40\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.052869297564029694\n",
      "Loss:  0.04888242483139038\n",
      "Loss:  0.03256550431251526\n",
      "40 **********\n",
      "Epoch:  2271.7760581970215  fold:  9  kers:  64\n",
      "epoch:  41\n",
      "29483 461\n",
      "Loss:  0.060513801872730255\n",
      "Loss:  0.04667713865637779\n",
      "Loss:  0.07620388269424438\n",
      "41 **********\n",
      "Epoch:  2314.1906502246857  fold:  9  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.03232462704181671\n",
      "Eval Loss:  1.3161444664001465\n",
      "Eval Loss:  0.26954469084739685\n",
      "[[1655   87]\n",
      " [ 693  973]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81      1742\n",
      "           1       0.92      0.58      0.71      1666\n",
      "\n",
      "    accuracy                           0.77      3408\n",
      "   macro avg       0.81      0.77      0.76      3408\n",
      "weighted avg       0.81      0.77      0.76      3408\n",
      "\n",
      "acc:  0.7711267605633803\n",
      "pre:  0.9179245283018868\n",
      "rec:  0.5840336134453782\n",
      "ma F1:  0.7615787122825208\n",
      "mi F1:  0.7711267605633803\n",
      "we F1:  0.7626427176627926\n",
      "Eval Loss:  0.29838648438453674\n",
      "Eval Loss:  0.2512942850589752\n",
      "Eval Loss:  0.28365233540534973\n",
      "Eval Loss:  0.21331709623336792\n",
      "Eval Loss:  0.22122547030448914\n",
      "Eval Loss:  0.16185300052165985\n",
      "Eval Loss:  0.21564970910549164\n",
      "Eval Loss:  0.24957966804504395\n",
      "Eval Loss:  0.24133241176605225\n",
      "Eval Loss:  0.23582157492637634\n",
      "Eval Loss:  0.2290983349084854\n",
      "Eval Loss:  0.23220232129096985\n",
      "Eval Loss:  0.17542585730552673\n",
      "Eval Loss:  0.2043386846780777\n",
      "Eval Loss:  0.3502914011478424\n",
      "Eval Loss:  0.2208722084760666\n",
      "Eval Loss:  0.2236844003200531\n",
      "Eval Loss:  0.2525371015071869\n",
      "Eval Loss:  0.25043585896492004\n",
      "Eval Loss:  0.21583102643489838\n",
      "Eval Loss:  0.26132968068122864\n",
      "Eval Loss:  0.19241289794445038\n",
      "Eval Loss:  0.1736498475074768\n",
      "Eval Loss:  0.19352126121520996\n",
      "Eval Loss:  0.22717252373695374\n",
      "Eval Loss:  0.2842864394187927\n",
      "Eval Loss:  0.20301035046577454\n",
      "Eval Loss:  0.1940223127603531\n",
      "[[17442   980]\n",
      " [ 1587  9474]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18422\n",
      "           1       0.91      0.86      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.90      0.91     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9129328765729403\n",
      "pre:  0.906255978572795\n",
      "rec:  0.8565229183618118\n",
      "ma F1:  0.9060724980587074\n",
      "mi F1:  0.9129328765729403\n",
      "we F1:  0.9124102548663464\n",
      "29483 461\n",
      "Loss:  0.05414131283760071\n",
      "Loss:  0.04904725030064583\n",
      "Loss:  0.10556397587060928\n",
      "42 **********\n",
      "Epoch:  2396.1355459690094  fold:  9  kers:  64\n",
      "epoch:  43\n",
      "29483 461\n",
      "Loss:  0.10465049743652344\n",
      "Loss:  0.03201694041490555\n",
      "Loss:  0.03078313171863556\n",
      "43 **********\n",
      "Epoch:  2438.6029965877533  fold:  9  kers:  64\n",
      "epoch:  44\n",
      "29483 461\n",
      "Loss:  0.05313059687614441\n",
      "Loss:  0.06029902771115303\n",
      "Loss:  0.06707633286714554\n",
      "44 **********\n",
      "Epoch:  2481.188132762909  fold:  9  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.0283907949924469\n",
      "Eval Loss:  1.2898679971694946\n",
      "Eval Loss:  0.2422035038471222\n",
      "[[1615  127]\n",
      " [ 598 1068]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82      1742\n",
      "           1       0.89      0.64      0.75      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.81      0.78      0.78      3408\n",
      "weighted avg       0.81      0.79      0.78      3408\n",
      "\n",
      "acc:  0.7872652582159625\n",
      "pre:  0.8937238493723849\n",
      "rec:  0.6410564225690276\n",
      "ma F1:  0.7816399188529114\n",
      "mi F1:  0.7872652582159625\n",
      "we F1:  0.7824215016528965\n",
      "Eval Loss:  0.30921846628189087\n",
      "Eval Loss:  0.22527676820755005\n",
      "Eval Loss:  0.27220818400382996\n",
      "Eval Loss:  0.1925976723432541\n",
      "Eval Loss:  0.2193579226732254\n",
      "Eval Loss:  0.15366090834140778\n",
      "Eval Loss:  0.2252819985151291\n",
      "Eval Loss:  0.239446759223938\n",
      "Eval Loss:  0.235323965549469\n",
      "Eval Loss:  0.19085969030857086\n",
      "Eval Loss:  0.2198161631822586\n",
      "Eval Loss:  0.24662497639656067\n",
      "Eval Loss:  0.16507473587989807\n",
      "Eval Loss:  0.16296328604221344\n",
      "Eval Loss:  0.31840553879737854\n",
      "Eval Loss:  0.21494577825069427\n",
      "Eval Loss:  0.19391216337680817\n",
      "Eval Loss:  0.19826297461986542\n",
      "Eval Loss:  0.20945869386196136\n",
      "Eval Loss:  0.20049631595611572\n",
      "Eval Loss:  0.2640766501426697\n",
      "Eval Loss:  0.16941629350185394\n",
      "Eval Loss:  0.15039417147636414\n",
      "Eval Loss:  0.19076544046401978\n",
      "Eval Loss:  0.19912375509738922\n",
      "Eval Loss:  0.27101123332977295\n",
      "Eval Loss:  0.21149450540542603\n",
      "Eval Loss:  0.17286881804466248\n",
      "[[17398  1024]\n",
      " [ 1366  9695]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18422\n",
      "           1       0.90      0.88      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9189363361937387\n",
      "pre:  0.9044687004384737\n",
      "rec:  0.8765030286592532\n",
      "ma F1:  0.9129973996651582\n",
      "mi F1:  0.9189363361937387\n",
      "we F1:  0.9186726575889387\n",
      "29483 461\n",
      "Loss:  0.058933570981025696\n",
      "Loss:  0.06316859275102615\n",
      "Loss:  0.07053874433040619\n",
      "45 **********\n",
      "Epoch:  2563.203839302063  fold:  9  kers:  64\n",
      "epoch:  46\n",
      "29483 461\n",
      "Loss:  0.06257526576519012\n",
      "Loss:  0.06701164692640305\n",
      "Loss:  0.09249997138977051\n",
      "46 **********\n",
      "Epoch:  2605.652340888977  fold:  9  kers:  64\n",
      "epoch:  47\n",
      "29483 461\n",
      "Loss:  0.04213874787092209\n",
      "Loss:  0.05495192110538483\n",
      "Loss:  0.07211096584796906\n",
      "47 **********\n",
      "Epoch:  2648.00110912323  fold:  9  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.03158758580684662\n",
      "Eval Loss:  1.3755425214767456\n",
      "Eval Loss:  0.38693296909332275\n",
      "[[1680   62]\n",
      " [ 789  877]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.80      1742\n",
      "           1       0.93      0.53      0.67      1666\n",
      "\n",
      "    accuracy                           0.75      3408\n",
      "   macro avg       0.81      0.75      0.74      3408\n",
      "weighted avg       0.80      0.75      0.74      3408\n",
      "\n",
      "acc:  0.750293427230047\n",
      "pre:  0.933972310969116\n",
      "rec:  0.5264105642256903\n",
      "ma F1:  0.7356153862632873\n",
      "mi F1:  0.7502934272300471\n",
      "we F1:  0.7370045906387215\n",
      "Eval Loss:  0.3359202742576599\n",
      "Eval Loss:  0.28233572840690613\n",
      "Eval Loss:  0.3088809847831726\n",
      "Eval Loss:  0.21523557603359222\n",
      "Eval Loss:  0.2414322793483734\n",
      "Eval Loss:  0.19112098217010498\n",
      "Eval Loss:  0.23818135261535645\n",
      "Eval Loss:  0.26977044343948364\n",
      "Eval Loss:  0.24981531500816345\n",
      "Eval Loss:  0.1980712115764618\n",
      "Eval Loss:  0.21859601140022278\n",
      "Eval Loss:  0.24328044056892395\n",
      "Eval Loss:  0.19010566174983978\n",
      "Eval Loss:  0.21234872937202454\n",
      "Eval Loss:  0.3939007520675659\n",
      "Eval Loss:  0.2514030337333679\n",
      "Eval Loss:  0.20627543330192566\n",
      "Eval Loss:  0.2683820426464081\n",
      "Eval Loss:  0.2517412602901459\n",
      "Eval Loss:  0.19937726855278015\n",
      "Eval Loss:  0.27038073539733887\n",
      "Eval Loss:  0.20288242399692535\n",
      "Eval Loss:  0.17982885241508484\n",
      "Eval Loss:  0.2179751992225647\n",
      "Eval Loss:  0.25611573457717896\n",
      "Eval Loss:  0.29047080874443054\n",
      "Eval Loss:  0.20459376275539398\n",
      "Eval Loss:  0.17882093787193298\n",
      "[[17772   650]\n",
      " [ 2012  9049]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18422\n",
      "           1       0.93      0.82      0.87     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.92      0.89      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9097106807312688\n",
      "pre:  0.9329827817300753\n",
      "rec:  0.8180996293282705\n",
      "ma F1:  0.901048859761054\n",
      "mi F1:  0.9097106807312688\n",
      "we F1:  0.9083582331603148\n",
      "29483 461\n",
      "Loss:  0.047425176948308945\n",
      "Loss:  0.055924125015735626\n",
      "Loss:  0.07664748281240463\n",
      "48 **********\n",
      "Epoch:  2729.900127887726  fold:  9  kers:  64\n",
      "epoch:  49\n",
      "29483 461\n",
      "Loss:  0.027416594326496124\n",
      "Loss:  0.04731891304254532\n",
      "Loss:  0.06592060625553131\n",
      "49 **********\n",
      "Epoch:  2772.306740999222  fold:  9  kers:  64\n",
      "epoch:  50\n",
      "29483 461\n",
      "Loss:  0.04418301209807396\n",
      "Loss:  0.037520881742239\n",
      "Loss:  0.09959584474563599\n",
      "50 **********\n",
      "Epoch:  2814.8170766830444  fold:  9  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.03966071456670761\n",
      "Eval Loss:  0.9949328899383545\n",
      "Eval Loss:  0.15535788238048553\n",
      "[[1534  208]\n",
      " [ 448 1218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      1742\n",
      "           1       0.85      0.73      0.79      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.81      0.81      0.81      3408\n",
      "weighted avg       0.81      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8075117370892019\n",
      "pre:  0.8541374474053296\n",
      "rec:  0.7310924369747899\n",
      "ma F1:  0.8058424568165934\n",
      "mi F1:  0.8075117370892019\n",
      "we F1:  0.8062439292872208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2801763117313385\n",
      "Eval Loss:  0.258817195892334\n",
      "Eval Loss:  0.2752237319946289\n",
      "Eval Loss:  0.19850222766399384\n",
      "Eval Loss:  0.23311257362365723\n",
      "Eval Loss:  0.12571047246456146\n",
      "Eval Loss:  0.21590128540992737\n",
      "Eval Loss:  0.23508615791797638\n",
      "Eval Loss:  0.24220597743988037\n",
      "Eval Loss:  0.22390329837799072\n",
      "Eval Loss:  0.22523736953735352\n",
      "Eval Loss:  0.27258485555648804\n",
      "Eval Loss:  0.16966357827186584\n",
      "Eval Loss:  0.16661140322685242\n",
      "Eval Loss:  0.26003098487854004\n",
      "Eval Loss:  0.2284291833639145\n",
      "Eval Loss:  0.22793011367321014\n",
      "Eval Loss:  0.21097028255462646\n",
      "Eval Loss:  0.19457222521305084\n",
      "Eval Loss:  0.22392715513706207\n",
      "Eval Loss:  0.27650314569473267\n",
      "Eval Loss:  0.1549546718597412\n",
      "Eval Loss:  0.13528072834014893\n",
      "Eval Loss:  0.18429552018642426\n",
      "Eval Loss:  0.19080789387226105\n",
      "Eval Loss:  0.28091323375701904\n",
      "Eval Loss:  0.2196129411458969\n",
      "Eval Loss:  0.18256887793540955\n",
      "[[16731  1691]\n",
      " [  794 10267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93     18422\n",
      "           1       0.86      0.93      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.92      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9157141403520673\n",
      "pre:  0.8585883927078106\n",
      "rec:  0.9282162553114547\n",
      "ma F1:  0.9114580747684571\n",
      "mi F1:  0.9157141403520673\n",
      "we F1:  0.9163047484629118\n",
      "29483 461\n",
      "Loss:  0.05315149948000908\n",
      "Loss:  0.04853471368551254\n",
      "Loss:  0.050866492092609406\n",
      "51 **********\n",
      "Epoch:  2896.7160954475403  fold:  9  kers:  64\n",
      "epoch:  52\n",
      "29483 461\n",
      "Loss:  0.11935719847679138\n",
      "Loss:  0.06284456700086594\n",
      "Loss:  0.03946593031287193\n",
      "52 **********\n",
      "Epoch:  2939.1905274391174  fold:  9  kers:  64\n",
      "epoch:  53\n",
      "29483 461\n",
      "Loss:  0.06288409233093262\n",
      "Loss:  0.06754232197999954\n",
      "Loss:  0.10710803419351578\n",
      "53 **********\n",
      "Epoch:  2981.640026330948  fold:  9  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.03228814899921417\n",
      "Eval Loss:  1.3757396936416626\n",
      "Eval Loss:  0.26740482449531555\n",
      "[[1560  182]\n",
      " [ 618 1048]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80      1742\n",
      "           1       0.85      0.63      0.72      1666\n",
      "\n",
      "    accuracy                           0.77      3408\n",
      "   macro avg       0.78      0.76      0.76      3408\n",
      "weighted avg       0.78      0.77      0.76      3408\n",
      "\n",
      "acc:  0.7652582159624414\n",
      "pre:  0.8520325203252033\n",
      "rec:  0.6290516206482593\n",
      "ma F1:  0.7598376367121433\n",
      "mi F1:  0.7652582159624414\n",
      "we F1:  0.7606422539446094\n",
      "Eval Loss:  0.28032249212265015\n",
      "Eval Loss:  0.24348726868629456\n",
      "Eval Loss:  0.2848087549209595\n",
      "Eval Loss:  0.17788298428058624\n",
      "Eval Loss:  0.21531441807746887\n",
      "Eval Loss:  0.12557899951934814\n",
      "Eval Loss:  0.18815545737743378\n",
      "Eval Loss:  0.21572698652744293\n",
      "Eval Loss:  0.23382215201854706\n",
      "Eval Loss:  0.21927835047245026\n",
      "Eval Loss:  0.19632676243782043\n",
      "Eval Loss:  0.2309536635875702\n",
      "Eval Loss:  0.15504127740859985\n",
      "Eval Loss:  0.18447080254554749\n",
      "Eval Loss:  0.3027386963367462\n",
      "Eval Loss:  0.22600196301937103\n",
      "Eval Loss:  0.2101176679134369\n",
      "Eval Loss:  0.20789383351802826\n",
      "Eval Loss:  0.19577452540397644\n",
      "Eval Loss:  0.19901043176651\n",
      "Eval Loss:  0.2673223316669464\n",
      "Eval Loss:  0.16001632809638977\n",
      "Eval Loss:  0.14830125868320465\n",
      "Eval Loss:  0.1844295710325241\n",
      "Eval Loss:  0.19815181195735931\n",
      "Eval Loss:  0.261367529630661\n",
      "Eval Loss:  0.21017511188983917\n",
      "Eval Loss:  0.1770104467868805\n",
      "[[17212  1210]\n",
      " [ 1157  9904]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     18422\n",
      "           1       0.89      0.90      0.89     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.91      0.91      0.91     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9197164467659329\n",
      "pre:  0.8911283066402735\n",
      "rec:  0.8953982460898653\n",
      "ma F1:  0.9144608935013241\n",
      "mi F1:  0.9197164467659329\n",
      "we F1:  0.9197545617526631\n",
      "29483 461\n",
      "Loss:  0.05140487477183342\n",
      "Loss:  0.052073411643505096\n",
      "Loss:  0.06227003410458565\n",
      "54 **********\n",
      "Epoch:  3063.559988975525  fold:  9  kers:  64\n",
      "epoch:  55\n",
      "29483 461\n",
      "Loss:  0.04356885701417923\n",
      "Loss:  0.046189699321985245\n",
      "Loss:  0.03781919181346893\n",
      "55 **********\n",
      "Epoch:  3105.96959400177  fold:  9  kers:  64\n",
      "epoch:  56\n",
      "29483 461\n",
      "Loss:  0.07306097447872162\n",
      "Loss:  0.08394567668437958\n",
      "Loss:  0.07891827821731567\n",
      "56 **********\n",
      "Epoch:  3148.4250774383545  fold:  9  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.030399588868021965\n",
      "Eval Loss:  0.9675202369689941\n",
      "Eval Loss:  0.23636139929294586\n",
      "[[1615  127]\n",
      " [ 565 1101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82      1742\n",
      "           1       0.90      0.66      0.76      1666\n",
      "\n",
      "    accuracy                           0.80      3408\n",
      "   macro avg       0.82      0.79      0.79      3408\n",
      "weighted avg       0.82      0.80      0.79      3408\n",
      "\n",
      "acc:  0.7969483568075117\n",
      "pre:  0.8965798045602605\n",
      "rec:  0.6608643457382953\n",
      "ma F1:  0.7922219986347458\n",
      "mi F1:  0.7969483568075116\n",
      "we F1:  0.7929208375863611\n",
      "Eval Loss:  0.2622813880443573\n",
      "Eval Loss:  0.2290060967206955\n",
      "Eval Loss:  0.2704307436943054\n",
      "Eval Loss:  0.18215297162532806\n",
      "Eval Loss:  0.1962622106075287\n",
      "Eval Loss:  0.1156236082315445\n",
      "Eval Loss:  0.2046271711587906\n",
      "Eval Loss:  0.21255983412265778\n",
      "Eval Loss:  0.22105346620082855\n",
      "Eval Loss:  0.20730504393577576\n",
      "Eval Loss:  0.20189258456230164\n",
      "Eval Loss:  0.2508991062641144\n",
      "Eval Loss:  0.1640005260705948\n",
      "Eval Loss:  0.16325272619724274\n",
      "Eval Loss:  0.3128822147846222\n",
      "Eval Loss:  0.22006884217262268\n",
      "Eval Loss:  0.2146594375371933\n",
      "Eval Loss:  0.2126690149307251\n",
      "Eval Loss:  0.18385453522205353\n",
      "Eval Loss:  0.1889604926109314\n",
      "Eval Loss:  0.251058965921402\n",
      "Eval Loss:  0.1704278141260147\n",
      "Eval Loss:  0.13187678158283234\n",
      "Eval Loss:  0.165635347366333\n",
      "Eval Loss:  0.20558993518352509\n",
      "Eval Loss:  0.2506659924983978\n",
      "Eval Loss:  0.18688039481639862\n",
      "Eval Loss:  0.17428120970726013\n",
      "[[17299  1123]\n",
      " [ 1166  9895]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     18422\n",
      "           1       0.90      0.89      0.90     11061\n",
      "\n",
      "    accuracy                           0.92     29483\n",
      "   macro avg       0.92      0.92      0.92     29483\n",
      "weighted avg       0.92      0.92      0.92     29483\n",
      "\n",
      "acc:  0.9223620391412\n",
      "pre:  0.8980758758395353\n",
      "rec:  0.8945845764397432\n",
      "ma F1:  0.9171362220467073\n",
      "mi F1:  0.9223620391412\n",
      "we F1:  0.922331689312045\n",
      "29483 461\n",
      "Loss:  0.06933227926492691\n",
      "Loss:  0.06036624312400818\n",
      "Loss:  0.0890660211443901\n",
      "57 **********\n",
      "Epoch:  3230.359999895096  fold:  9  kers:  64\n",
      "epoch:  58\n",
      "29483 461\n",
      "Loss:  0.05182806774973869\n",
      "Loss:  0.06147203966975212\n",
      "Loss:  0.053395677357912064\n",
      "58 **********\n",
      "Epoch:  3272.712756872177  fold:  9  kers:  64\n",
      "epoch:  59\n",
      "29483 461\n",
      "Loss:  0.04412507638335228\n",
      "Loss:  0.0694233775138855\n",
      "Loss:  0.09216878563165665\n",
      "59 **********\n",
      "Epoch:  3315.1403148174286  fold:  9  kers:  64\n",
      "Eval Loss:  0.047449272125959396\n",
      "Eval Loss:  1.2906718254089355\n",
      "Eval Loss:  0.25653430819511414\n",
      "[[1594  148]\n",
      " [ 626 1040]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.80      1742\n",
      "           1       0.88      0.62      0.73      1666\n",
      "\n",
      "    accuracy                           0.77      3408\n",
      "   macro avg       0.80      0.77      0.77      3408\n",
      "weighted avg       0.79      0.77      0.77      3408\n",
      "\n",
      "acc:  0.772887323943662\n",
      "pre:  0.8754208754208754\n",
      "rec:  0.6242496998799519\n",
      "ma F1:  0.7667229004908932\n",
      "mi F1:  0.772887323943662\n",
      "we F1:  0.7675685614699734\n",
      "update!  Acc:  0.8177816901408451\n",
      "Epoch:  3319.215418815613  fold:  9  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29871 3020\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29871 467\n",
      "Loss:  0.16776318848133087\n",
      "Loss:  0.16900795698165894\n",
      "Loss:  0.16073457896709442\n",
      "0 **********\n",
      "Epoch:  55.53152012825012  fold:  10  kers:  64\n",
      "epoch:  1\n",
      "29871 467\n",
      "Loss:  0.12961120903491974\n",
      "Loss:  0.15182767808437347\n",
      "Loss:  0.1340007781982422\n",
      "1 **********\n",
      "Epoch:  98.80381917953491  fold:  10  kers:  64\n",
      "epoch:  2\n",
      "29871 467\n",
      "Loss:  0.10332539677619934\n",
      "Loss:  0.1042264997959137\n",
      "Loss:  0.12156767398118973\n",
      "2 **********\n",
      "Epoch:  142.1040427684784  fold:  10  kers:  64\n",
      "epoch:  3\n",
      "Eval Loss:  0.5702024698257446\n",
      "Eval Loss:  0.26620155572891235\n",
      "Eval Loss:  0.1123906597495079\n",
      "[[1533  218]\n",
      " [ 202 1067]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      1751\n",
      "           1       0.83      0.84      0.84      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.86      0.86      0.86      3020\n",
      "weighted avg       0.86      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8609271523178808\n",
      "pre:  0.8303501945525292\n",
      "rec:  0.8408195429472025\n",
      "ma F1:  0.8575350737326755\n",
      "mi F1:  0.8609271523178808\n",
      "we F1:  0.8610436185353987\n",
      "update!  Acc:  0.8609271523178808\n",
      "Eval Loss:  0.4247291684150696\n",
      "Eval Loss:  0.401816189289093\n",
      "Eval Loss:  0.4110777676105499\n",
      "Eval Loss:  0.4236506521701813\n",
      "Eval Loss:  0.46644508838653564\n",
      "Eval Loss:  0.4186653792858124\n",
      "Eval Loss:  0.41931816935539246\n",
      "Eval Loss:  0.43191176652908325\n",
      "Eval Loss:  0.4705047011375427\n",
      "Eval Loss:  0.4983971118927002\n",
      "Eval Loss:  0.43691739439964294\n",
      "Eval Loss:  0.4975094795227051\n",
      "Eval Loss:  0.356823205947876\n",
      "Eval Loss:  0.44943735003471375\n",
      "Eval Loss:  0.4856540262699127\n",
      "Eval Loss:  0.49922025203704834\n",
      "Eval Loss:  0.40547966957092285\n",
      "Eval Loss:  0.46571025252342224\n",
      "Eval Loss:  0.44970494508743286\n",
      "Eval Loss:  0.4985648989677429\n",
      "Eval Loss:  0.4220963716506958\n",
      "Eval Loss:  0.42702794075012207\n",
      "Eval Loss:  0.4860360324382782\n",
      "Eval Loss:  0.4899924099445343\n",
      "Eval Loss:  0.4087572693824768\n",
      "Eval Loss:  0.4141245484352112\n",
      "Eval Loss:  0.3591638207435608\n",
      "Eval Loss:  0.4591119587421417\n",
      "Eval Loss:  0.5322152972221375\n",
      "[[15854  2559]\n",
      " [ 3501  7957]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84     18413\n",
      "           1       0.76      0.69      0.72     11458\n",
      "\n",
      "    accuracy                           0.80     29871\n",
      "   macro avg       0.79      0.78      0.78     29871\n",
      "weighted avg       0.80      0.80      0.80     29871\n",
      "\n",
      "acc:  0.797127648890228\n",
      "pre:  0.7566565233929251\n",
      "rec:  0.6944492930703439\n",
      "ma F1:  0.7818831191903501\n",
      "mi F1:  0.797127648890228\n",
      "we F1:  0.7953091928971565\n",
      "29871 467\n",
      "Loss:  0.10419213771820068\n",
      "Loss:  0.11964112520217896\n",
      "Loss:  0.0962982252240181\n",
      "3 **********\n",
      "Epoch:  224.95651197433472  fold:  10  kers:  64\n",
      "epoch:  4\n",
      "29871 467\n",
      "Loss:  0.0998619794845581\n",
      "Loss:  0.07450562715530396\n",
      "Loss:  0.08381708711385727\n",
      "4 **********\n",
      "Epoch:  268.21926832199097  fold:  10  kers:  64\n",
      "epoch:  5\n",
      "29871 467\n",
      "Loss:  0.08541655540466309\n",
      "Loss:  0.10518625378608704\n",
      "Loss:  0.06124306097626686\n",
      "5 **********\n",
      "Epoch:  311.39482593536377  fold:  10  kers:  64\n",
      "epoch:  6\n",
      "Eval Loss:  0.48158395290374756\n",
      "Eval Loss:  0.16379870474338531\n",
      "Eval Loss:  0.12974004447460175\n",
      "[[1630  121]\n",
      " [ 212 1057]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      1751\n",
      "           1       0.90      0.83      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.88      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8897350993377483\n",
      "pre:  0.8972835314091681\n",
      "rec:  0.8329393223010244\n",
      "ma F1:  0.8856173932171385\n",
      "mi F1:  0.8897350993377484\n",
      "we F1:  0.8890811529904962\n",
      "update!  Acc:  0.8897350993377483\n",
      "Eval Loss:  0.38833510875701904\n",
      "Eval Loss:  0.2923010289669037\n",
      "Eval Loss:  0.32371318340301514\n",
      "Eval Loss:  0.3152628242969513\n",
      "Eval Loss:  0.42029139399528503\n",
      "Eval Loss:  0.33631569147109985\n",
      "Eval Loss:  0.36570218205451965\n",
      "Eval Loss:  0.3084969222545624\n",
      "Eval Loss:  0.411104679107666\n",
      "Eval Loss:  0.40367165207862854\n",
      "Eval Loss:  0.3371712863445282\n",
      "Eval Loss:  0.3950725495815277\n",
      "Eval Loss:  0.2900794744491577\n",
      "Eval Loss:  0.38005420565605164\n",
      "Eval Loss:  0.443168967962265\n",
      "Eval Loss:  0.4879229962825775\n",
      "Eval Loss:  0.32973650097846985\n",
      "Eval Loss:  0.3977668583393097\n",
      "Eval Loss:  0.3668690621852875\n",
      "Eval Loss:  0.37355467677116394\n",
      "Eval Loss:  0.346000611782074\n",
      "Eval Loss:  0.4044060707092285\n",
      "Eval Loss:  0.3866685628890991\n",
      "Eval Loss:  0.39441293478012085\n",
      "Eval Loss:  0.3344035744667053\n",
      "Eval Loss:  0.33666521310806274\n",
      "Eval Loss:  0.29231321811676025\n",
      "Eval Loss:  0.41287827491760254\n",
      "Eval Loss:  0.44135189056396484\n",
      "[[17192  1221]\n",
      " [ 3354  8104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88     18413\n",
      "           1       0.87      0.71      0.78     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.85      0.82      0.83     29871\n",
      "weighted avg       0.85      0.85      0.84     29871\n",
      "\n",
      "acc:  0.8468414180978207\n",
      "pre:  0.8690616621983914\n",
      "rec:  0.7072787572002095\n",
      "ma F1:  0.8312185079574234\n",
      "mi F1:  0.8468414180978207\n",
      "we F1:  0.8431746413230112\n",
      "29871 467\n",
      "Loss:  0.06775708496570587\n",
      "Loss:  0.07714682817459106\n",
      "Loss:  0.09295177459716797\n",
      "6 **********\n",
      "Epoch:  394.26824259757996  fold:  10  kers:  64\n",
      "epoch:  7\n",
      "29871 467\n",
      "Loss:  0.09097321331501007\n",
      "Loss:  0.07527859508991241\n",
      "Loss:  0.09928913414478302\n",
      "7 **********\n",
      "Epoch:  437.45177841186523  fold:  10  kers:  64\n",
      "epoch:  8\n",
      "29871 467\n",
      "Loss:  0.09644792973995209\n",
      "Loss:  0.06697123497724533\n",
      "Loss:  0.05373359099030495\n",
      "8 **********\n",
      "Epoch:  480.6223487854004  fold:  10  kers:  64\n",
      "epoch:  9\n",
      "Eval Loss:  0.6169261336326599\n",
      "Eval Loss:  0.10934021323919296\n",
      "Eval Loss:  0.08252429962158203\n",
      "[[1683   68]\n",
      " [ 299  970]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      1751\n",
      "           1       0.93      0.76      0.84      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.89      0.86      0.87      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.878476821192053\n",
      "pre:  0.9344894026974951\n",
      "rec:  0.764381402679275\n",
      "ma F1:  0.8713032965162342\n",
      "mi F1:  0.878476821192053\n",
      "we F1:  0.8761527199296207\n",
      "Eval Loss:  0.397984117269516\n",
      "Eval Loss:  0.31409355998039246\n",
      "Eval Loss:  0.38272130489349365\n",
      "Eval Loss:  0.28941383957862854\n",
      "Eval Loss:  0.42727553844451904\n",
      "Eval Loss:  0.3469651937484741\n",
      "Eval Loss:  0.4124077260494232\n",
      "Eval Loss:  0.35589686036109924\n",
      "Eval Loss:  0.41954305768013\n",
      "Eval Loss:  0.4840894341468811\n",
      "Eval Loss:  0.3663502335548401\n",
      "Eval Loss:  0.4703865349292755\n",
      "Eval Loss:  0.3016795814037323\n",
      "Eval Loss:  0.3548108637332916\n",
      "Eval Loss:  0.4793340265750885\n",
      "Eval Loss:  0.5426442623138428\n",
      "Eval Loss:  0.36317434906959534\n",
      "Eval Loss:  0.4521106779575348\n",
      "Eval Loss:  0.3871924579143524\n",
      "Eval Loss:  0.40297162532806396\n",
      "Eval Loss:  0.3557528257369995\n",
      "Eval Loss:  0.43137314915657043\n",
      "Eval Loss:  0.44162893295288086\n",
      "Eval Loss:  0.41362959146499634\n",
      "Eval Loss:  0.39169031381607056\n",
      "Eval Loss:  0.3723398745059967\n",
      "Eval Loss:  0.297823429107666\n",
      "Eval Loss:  0.41434043645858765\n",
      "Eval Loss:  0.47216472029685974\n",
      "[[17859   554]\n",
      " [ 4249  7209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88     18413\n",
      "           1       0.93      0.63      0.75     11458\n",
      "\n",
      "    accuracy                           0.84     29871\n",
      "   macro avg       0.87      0.80      0.82     29871\n",
      "weighted avg       0.85      0.84      0.83     29871\n",
      "\n",
      "acc:  0.8392085969669579\n",
      "pre:  0.9286358366610846\n",
      "rec:  0.6291673939605515\n",
      "ma F1:  0.815792963730291\n",
      "mi F1:  0.8392085969669579\n",
      "we F1:  0.831084581491889\n",
      "29871 467\n",
      "Loss:  0.10820933431386948\n",
      "Loss:  0.0943177193403244\n",
      "Loss:  0.07017068564891815\n",
      "9 **********\n",
      "Epoch:  563.3202319145203  fold:  10  kers:  64\n",
      "epoch:  10\n",
      "29871 467\n",
      "Loss:  0.07590886950492859\n",
      "Loss:  0.08910989761352539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.11070123314857483\n",
      "10 **********\n",
      "Epoch:  606.3830902576447  fold:  10  kers:  64\n",
      "epoch:  11\n",
      "29871 467\n",
      "Loss:  0.07760748267173767\n",
      "Loss:  0.07719200849533081\n",
      "Loss:  0.08042396605014801\n",
      "11 **********\n",
      "Epoch:  649.4489405155182  fold:  10  kers:  64\n",
      "epoch:  12\n",
      "Eval Loss:  0.7310223579406738\n",
      "Eval Loss:  0.09743665903806686\n",
      "Eval Loss:  0.06172218918800354\n",
      "[[1705   46]\n",
      " [ 362  907]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      1751\n",
      "           1       0.95      0.71      0.82      1269\n",
      "\n",
      "    accuracy                           0.86      3020\n",
      "   macro avg       0.89      0.84      0.85      3020\n",
      "weighted avg       0.88      0.86      0.86      3020\n",
      "\n",
      "acc:  0.8649006622516556\n",
      "pre:  0.9517313746065058\n",
      "rec:  0.7147360126083531\n",
      "ma F1:  0.8547597033144907\n",
      "mi F1:  0.8649006622516556\n",
      "we F1:  0.8608849441762871\n",
      "Eval Loss:  0.39551010727882385\n",
      "Eval Loss:  0.35135263204574585\n",
      "Eval Loss:  0.44048288464546204\n",
      "Eval Loss:  0.3035067617893219\n",
      "Eval Loss:  0.42641615867614746\n",
      "Eval Loss:  0.3719767928123474\n",
      "Eval Loss:  0.40988317131996155\n",
      "Eval Loss:  0.40820223093032837\n",
      "Eval Loss:  0.43576860427856445\n",
      "Eval Loss:  0.5216439366340637\n",
      "Eval Loss:  0.3805745542049408\n",
      "Eval Loss:  0.533793568611145\n",
      "Eval Loss:  0.2944851815700531\n",
      "Eval Loss:  0.3656647801399231\n",
      "Eval Loss:  0.5388467311859131\n",
      "Eval Loss:  0.5642440319061279\n",
      "Eval Loss:  0.3944723904132843\n",
      "Eval Loss:  0.4622478783130646\n",
      "Eval Loss:  0.41691410541534424\n",
      "Eval Loss:  0.43012428283691406\n",
      "Eval Loss:  0.34807953238487244\n",
      "Eval Loss:  0.44809484481811523\n",
      "Eval Loss:  0.4666477143764496\n",
      "Eval Loss:  0.465202659368515\n",
      "Eval Loss:  0.4449683129787445\n",
      "Eval Loss:  0.4194927513599396\n",
      "Eval Loss:  0.3215491473674774\n",
      "Eval Loss:  0.4284909665584564\n",
      "Eval Loss:  0.48795798420906067\n",
      "[[18085   328]\n",
      " [ 4967  6491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87     18413\n",
      "           1       0.95      0.57      0.71     11458\n",
      "\n",
      "    accuracy                           0.82     29871\n",
      "   macro avg       0.87      0.77      0.79     29871\n",
      "weighted avg       0.85      0.82      0.81     29871\n",
      "\n",
      "acc:  0.8227377724214121\n",
      "pre:  0.9518991054406805\n",
      "rec:  0.5665037528364462\n",
      "ma F1:  0.791296782374056\n",
      "mi F1:  0.8227377724214121\n",
      "we F1:  0.8101575798364815\n",
      "29871 467\n",
      "Loss:  0.09100303798913956\n",
      "Loss:  0.0771838054060936\n",
      "Loss:  0.04417417198419571\n",
      "12 **********\n",
      "Epoch:  732.0123543739319  fold:  10  kers:  64\n",
      "epoch:  13\n",
      "29871 467\n",
      "Loss:  0.06470415741205215\n",
      "Loss:  0.06910661607980728\n",
      "Loss:  0.0884893387556076\n",
      "13 **********\n",
      "Epoch:  775.2547326087952  fold:  10  kers:  64\n",
      "epoch:  14\n",
      "29871 467\n",
      "Loss:  0.06663480401039124\n",
      "Loss:  0.05941147729754448\n",
      "Loss:  0.057748790830373764\n",
      "14 **********\n",
      "Epoch:  818.3415274620056  fold:  10  kers:  64\n",
      "epoch:  15\n",
      "Eval Loss:  0.5642338991165161\n",
      "Eval Loss:  0.10555312782526016\n",
      "Eval Loss:  0.06520313024520874\n",
      "[[1696   55]\n",
      " [ 300  969]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91      1751\n",
      "           1       0.95      0.76      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.90      0.87      0.88      3020\n",
      "weighted avg       0.89      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8824503311258278\n",
      "pre:  0.9462890625\n",
      "rec:  0.7635933806146572\n",
      "ma F1:  0.8752192624865993\n",
      "mi F1:  0.8824503311258278\n",
      "we F1:  0.8800134510479586\n",
      "Eval Loss:  0.32485297322273254\n",
      "Eval Loss:  0.2787756323814392\n",
      "Eval Loss:  0.35325807332992554\n",
      "Eval Loss:  0.25739631056785583\n",
      "Eval Loss:  0.36707213521003723\n",
      "Eval Loss:  0.31080198287963867\n",
      "Eval Loss:  0.3261423707008362\n",
      "Eval Loss:  0.32604190707206726\n",
      "Eval Loss:  0.3613893985748291\n",
      "Eval Loss:  0.41478386521339417\n",
      "Eval Loss:  0.28525927662849426\n",
      "Eval Loss:  0.4435100257396698\n",
      "Eval Loss:  0.2479957938194275\n",
      "Eval Loss:  0.30678004026412964\n",
      "Eval Loss:  0.4571301341056824\n",
      "Eval Loss:  0.4660378694534302\n",
      "Eval Loss:  0.34376585483551025\n",
      "Eval Loss:  0.425150990486145\n",
      "Eval Loss:  0.35140421986579895\n",
      "Eval Loss:  0.331007719039917\n",
      "Eval Loss:  0.2740454375743866\n",
      "Eval Loss:  0.36272791028022766\n",
      "Eval Loss:  0.3875872790813446\n",
      "Eval Loss:  0.39140158891677856\n",
      "Eval Loss:  0.3415449857711792\n",
      "Eval Loss:  0.33987653255462646\n",
      "Eval Loss:  0.2587794065475464\n",
      "Eval Loss:  0.3414674997329712\n",
      "Eval Loss:  0.3739452362060547\n",
      "[[17919   494]\n",
      " [ 3840  7618]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     18413\n",
      "           1       0.94      0.66      0.78     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.88      0.82      0.84     29871\n",
      "weighted avg       0.87      0.85      0.85     29871\n",
      "\n",
      "acc:  0.8549094439422852\n",
      "pre:  0.9391025641025641\n",
      "rec:  0.6648629778320824\n",
      "ma F1:  0.8353262448222769\n",
      "mi F1:  0.8549094439422852\n",
      "we F1:  0.8485483737301166\n",
      "29871 467\n",
      "Loss:  0.06667671352624893\n",
      "Loss:  0.07185376435518265\n",
      "Loss:  0.06967205554246902\n",
      "15 **********\n",
      "Epoch:  900.7013144493103  fold:  10  kers:  64\n",
      "epoch:  16\n",
      "29871 467\n",
      "Loss:  0.06450003385543823\n",
      "Loss:  0.09029711782932281\n",
      "Loss:  0.061400219798088074\n",
      "16 **********\n",
      "Epoch:  943.7581889629364  fold:  10  kers:  64\n",
      "epoch:  17\n",
      "29871 467\n",
      "Loss:  0.07431122660636902\n",
      "Loss:  0.08165749907493591\n",
      "Loss:  0.06814263015985489\n",
      "17 **********\n",
      "Epoch:  986.8389992713928  fold:  10  kers:  64\n",
      "epoch:  18\n",
      "Eval Loss:  0.3626977503299713\n",
      "Eval Loss:  0.1026274561882019\n",
      "Eval Loss:  0.05782783031463623\n",
      "[[1686   65]\n",
      " [ 220 1049]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1751\n",
      "           1       0.94      0.83      0.88      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.89      0.90      3020\n",
      "weighted avg       0.91      0.91      0.90      3020\n",
      "\n",
      "acc:  0.9056291390728477\n",
      "pre:  0.9416517055655296\n",
      "rec:  0.8266351457840819\n",
      "ma F1:  0.9012350608993083\n",
      "mi F1:  0.9056291390728477\n",
      "we F1:  0.9045599363775594\n",
      "update!  Acc:  0.9056291390728477\n",
      "Eval Loss:  0.282262921333313\n",
      "Eval Loss:  0.2464703470468521\n",
      "Eval Loss:  0.299608051776886\n",
      "Eval Loss:  0.21092642843723297\n",
      "Eval Loss:  0.33940500020980835\n",
      "Eval Loss:  0.26364433765411377\n",
      "Eval Loss:  0.297268271446228\n",
      "Eval Loss:  0.28723615407943726\n",
      "Eval Loss:  0.3404386639595032\n",
      "Eval Loss:  0.35545584559440613\n",
      "Eval Loss:  0.2555786371231079\n",
      "Eval Loss:  0.418853759765625\n",
      "Eval Loss:  0.22234520316123962\n",
      "Eval Loss:  0.2576897144317627\n",
      "Eval Loss:  0.3831241726875305\n",
      "Eval Loss:  0.4148474633693695\n",
      "Eval Loss:  0.302698016166687\n",
      "Eval Loss:  0.38958072662353516\n",
      "Eval Loss:  0.28655630350112915\n",
      "Eval Loss:  0.28255876898765564\n",
      "Eval Loss:  0.24537383019924164\n",
      "Eval Loss:  0.3235315978527069\n",
      "Eval Loss:  0.32235634326934814\n",
      "Eval Loss:  0.3461681008338928\n",
      "Eval Loss:  0.29020363092422485\n",
      "Eval Loss:  0.28055429458618164\n",
      "Eval Loss:  0.25617700815200806\n",
      "Eval Loss:  0.3253633677959442\n",
      "Eval Loss:  0.3120848536491394\n",
      "[[17812   601]\n",
      " [ 3180  8278]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90     18413\n",
      "           1       0.93      0.72      0.81     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.89      0.84      0.86     29871\n",
      "weighted avg       0.88      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8734223829131934\n",
      "pre:  0.932312197319518\n",
      "rec:  0.7224646535171932\n",
      "ma F1:  0.8590652080393597\n",
      "mi F1:  0.8734223829131934\n",
      "we F1:  0.8695386872975425\n",
      "29871 467\n",
      "Loss:  0.07900591939687729\n",
      "Loss:  0.07239798456430435\n",
      "Loss:  0.07987433671951294\n",
      "18 **********\n",
      "Epoch:  1069.6745142936707  fold:  10  kers:  64\n",
      "epoch:  19\n",
      "29871 467\n",
      "Loss:  0.07123581320047379\n",
      "Loss:  0.08126822859048843\n",
      "Loss:  0.07333949953317642\n",
      "19 **********\n",
      "Epoch:  1112.7313890457153  fold:  10  kers:  64\n",
      "epoch:  20\n",
      "29871 467\n",
      "Loss:  0.0778801366686821\n",
      "Loss:  0.05217462405562401\n",
      "Loss:  0.06553032249212265\n",
      "20 **********\n",
      "Epoch:  1155.794507265091  fold:  10  kers:  64\n",
      "epoch:  21\n",
      "Eval Loss:  0.21069875359535217\n",
      "Eval Loss:  0.1447455734014511\n",
      "Eval Loss:  0.05336698144674301\n",
      "[[1674   77]\n",
      " [ 160 1109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      1751\n",
      "           1       0.94      0.87      0.90      1269\n",
      "\n",
      "    accuracy                           0.92      3020\n",
      "   macro avg       0.92      0.91      0.92      3020\n",
      "weighted avg       0.92      0.92      0.92      3020\n",
      "\n",
      "acc:  0.921523178807947\n",
      "pre:  0.9350758853288365\n",
      "rec:  0.8739164696611506\n",
      "ma F1:  0.9186767675906911\n",
      "mi F1:  0.921523178807947\n",
      "we F1:  0.9211050334432882\n",
      "update!  Acc:  0.921523178807947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2528230547904968\n",
      "Eval Loss:  0.22303752601146698\n",
      "Eval Loss:  0.27421167492866516\n",
      "Eval Loss:  0.2027658373117447\n",
      "Eval Loss:  0.3103684186935425\n",
      "Eval Loss:  0.20592546463012695\n",
      "Eval Loss:  0.2554878890514374\n",
      "Eval Loss:  0.24611885845661163\n",
      "Eval Loss:  0.2920393645763397\n",
      "Eval Loss:  0.28109386563301086\n",
      "Eval Loss:  0.2117430567741394\n",
      "Eval Loss:  0.36831966042518616\n",
      "Eval Loss:  0.17818103730678558\n",
      "Eval Loss:  0.23255975544452667\n",
      "Eval Loss:  0.3434772491455078\n",
      "Eval Loss:  0.33699220418930054\n",
      "Eval Loss:  0.2737869620323181\n",
      "Eval Loss:  0.3613404631614685\n",
      "Eval Loss:  0.23540404438972473\n",
      "Eval Loss:  0.23473477363586426\n",
      "Eval Loss:  0.19363875687122345\n",
      "Eval Loss:  0.2562406063079834\n",
      "Eval Loss:  0.24921287596225739\n",
      "Eval Loss:  0.305707722902298\n",
      "Eval Loss:  0.22189204394817352\n",
      "Eval Loss:  0.22874712944030762\n",
      "Eval Loss:  0.2418992519378662\n",
      "Eval Loss:  0.2927035689353943\n",
      "Eval Loss:  0.25892892479896545\n",
      "[[17520   893]\n",
      " [ 2342  9116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     18413\n",
      "           1       0.91      0.80      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.90      0.87      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8917009808844699\n",
      "pre:  0.9107802977320412\n",
      "rec:  0.795601326584046\n",
      "ma F1:  0.8823918303113277\n",
      "mi F1:  0.8917009808844699\n",
      "we F1:  0.8900959167268684\n",
      "29871 467\n",
      "Loss:  0.08091329038143158\n",
      "Loss:  0.06579650193452835\n",
      "Loss:  0.08725038170814514\n",
      "21 **********\n",
      "Epoch:  1238.175244808197  fold:  10  kers:  64\n",
      "epoch:  22\n",
      "29871 467\n",
      "Loss:  0.09559060633182526\n",
      "Loss:  0.0883701965212822\n",
      "Loss:  0.046442627906799316\n",
      "22 **********\n",
      "Epoch:  1281.162306547165  fold:  10  kers:  64\n",
      "epoch:  23\n",
      "29871 467\n",
      "Loss:  0.05150051414966583\n",
      "Loss:  0.05535563826560974\n",
      "Loss:  0.090064138174057\n",
      "23 **********\n",
      "Epoch:  1324.2580769062042  fold:  10  kers:  64\n",
      "epoch:  24\n",
      "Eval Loss:  0.32784146070480347\n",
      "Eval Loss:  0.10499981790781021\n",
      "Eval Loss:  0.01790744625031948\n",
      "[[1705   46]\n",
      " [ 216 1053]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      1751\n",
      "           1       0.96      0.83      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.92      0.90      0.91      3020\n",
      "weighted avg       0.92      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9132450331125828\n",
      "pre:  0.9581437670609645\n",
      "rec:  0.8297872340425532\n",
      "ma F1:  0.9090036727904375\n",
      "mi F1:  0.9132450331125828\n",
      "we F1:  0.9121391569549682\n",
      "Eval Loss:  0.26321977376937866\n",
      "Eval Loss:  0.2612362802028656\n",
      "Eval Loss:  0.3069714307785034\n",
      "Eval Loss:  0.20748114585876465\n",
      "Eval Loss:  0.33640623092651367\n",
      "Eval Loss:  0.2854408919811249\n",
      "Eval Loss:  0.27605217695236206\n",
      "Eval Loss:  0.29049697518348694\n",
      "Eval Loss:  0.31439095735549927\n",
      "Eval Loss:  0.3603248596191406\n",
      "Eval Loss:  0.2524295449256897\n",
      "Eval Loss:  0.44393059611320496\n",
      "Eval Loss:  0.2065805047750473\n",
      "Eval Loss:  0.24569445848464966\n",
      "Eval Loss:  0.38771551847457886\n",
      "Eval Loss:  0.38546836376190186\n",
      "Eval Loss:  0.30122947692871094\n",
      "Eval Loss:  0.39701002836227417\n",
      "Eval Loss:  0.2906534671783447\n",
      "Eval Loss:  0.28502708673477173\n",
      "Eval Loss:  0.22736386954784393\n",
      "Eval Loss:  0.31753578782081604\n",
      "Eval Loss:  0.30393901467323303\n",
      "Eval Loss:  0.3517453074455261\n",
      "Eval Loss:  0.30039188265800476\n",
      "Eval Loss:  0.2648827135562897\n",
      "Eval Loss:  0.24978390336036682\n",
      "Eval Loss:  0.3103470504283905\n",
      "Eval Loss:  0.32252225279808044\n",
      "[[17911   502]\n",
      " [ 3307  8151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     18413\n",
      "           1       0.94      0.71      0.81     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.89      0.84      0.86     29871\n",
      "weighted avg       0.88      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8724850189146663\n",
      "pre:  0.9419854385762163\n",
      "rec:  0.7113806947111189\n",
      "ma F1:  0.8572447668787877\n",
      "mi F1:  0.8724850189146663\n",
      "we F1:  0.8681050079555845\n",
      "29871 467\n",
      "Loss:  0.07794148474931717\n",
      "Loss:  0.047588229179382324\n",
      "Loss:  0.0890766978263855\n",
      "24 **********\n",
      "Epoch:  1406.5380766391754  fold:  10  kers:  64\n",
      "epoch:  25\n",
      "29871 467\n",
      "Loss:  0.07486165314912796\n",
      "Loss:  0.05574102699756622\n",
      "Loss:  0.04616294428706169\n",
      "25 **********\n",
      "Epoch:  1449.4503393173218  fold:  10  kers:  64\n",
      "epoch:  26\n",
      "29871 467\n",
      "Loss:  0.04258847236633301\n",
      "Loss:  0.08560054749250412\n",
      "Loss:  0.059329427778720856\n",
      "26 **********\n",
      "Epoch:  1492.3436505794525  fold:  10  kers:  64\n",
      "epoch:  27\n",
      "Eval Loss:  0.14098751544952393\n",
      "Eval Loss:  0.19053331017494202\n",
      "Eval Loss:  0.047108329832553864\n",
      "[[1660   91]\n",
      " [ 120 1149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1751\n",
      "           1       0.93      0.91      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9301324503311258\n",
      "pre:  0.9266129032258065\n",
      "rec:  0.9054373522458629\n",
      "ma F1:  0.9280731535828142\n",
      "mi F1:  0.9301324503311258\n",
      "we F1:  0.9300155822182079\n",
      "update!  Acc:  0.9301324503311258\n",
      "Eval Loss:  0.2564592659473419\n",
      "Eval Loss:  0.22664691507816315\n",
      "Eval Loss:  0.2439238429069519\n",
      "Eval Loss:  0.19340823590755463\n",
      "Eval Loss:  0.3080630898475647\n",
      "Eval Loss:  0.21778203547000885\n",
      "Eval Loss:  0.2297193855047226\n",
      "Eval Loss:  0.2407340705394745\n",
      "Eval Loss:  0.2702167332172394\n",
      "Eval Loss:  0.27724382281303406\n",
      "Eval Loss:  0.185733363032341\n",
      "Eval Loss:  0.3308018445968628\n",
      "Eval Loss:  0.16490978002548218\n",
      "Eval Loss:  0.21913856267929077\n",
      "Eval Loss:  0.3291480243206024\n",
      "Eval Loss:  0.28314220905303955\n",
      "Eval Loss:  0.2826355993747711\n",
      "Eval Loss:  0.3489612638950348\n",
      "Eval Loss:  0.2345554679632187\n",
      "Eval Loss:  0.2106379121541977\n",
      "Eval Loss:  0.19601459801197052\n",
      "Eval Loss:  0.2693602740764618\n",
      "Eval Loss:  0.23936249315738678\n",
      "Eval Loss:  0.2881070673465729\n",
      "Eval Loss:  0.2066376805305481\n",
      "Eval Loss:  0.20803314447402954\n",
      "Eval Loss:  0.25572484731674194\n",
      "Eval Loss:  0.27968230843544006\n",
      "Eval Loss:  0.2434694617986679\n",
      "[[17343  1070]\n",
      " [ 1878  9580]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18413\n",
      "           1       0.90      0.84      0.87     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9013089618693716\n",
      "pre:  0.8995305164319248\n",
      "rec:  0.8360970500960028\n",
      "ma F1:  0.894160591381135\n",
      "mi F1:  0.9013089618693716\n",
      "we F1:  0.9005649346434931\n",
      "29871 467\n",
      "Loss:  0.07237865775823593\n",
      "Loss:  0.056826673448085785\n",
      "Loss:  0.07654862105846405\n",
      "27 **********\n",
      "Epoch:  1574.8869466781616  fold:  10  kers:  64\n",
      "epoch:  28\n",
      "29871 467\n",
      "Loss:  0.0780029222369194\n",
      "Loss:  0.057656772434711456\n",
      "Loss:  0.05795838311314583\n",
      "28 **********\n",
      "Epoch:  1617.8740077018738  fold:  10  kers:  64\n",
      "epoch:  29\n",
      "29871 467\n",
      "Loss:  0.07009851187467575\n",
      "Loss:  0.07406572997570038\n",
      "Loss:  0.05867370590567589\n",
      "29 **********\n",
      "Epoch:  1660.8560819625854  fold:  10  kers:  64\n",
      "epoch:  30\n",
      "Eval Loss:  0.2609908878803253\n",
      "Eval Loss:  0.17345215380191803\n",
      "Eval Loss:  0.028855327516794205\n",
      "[[1682   69]\n",
      " [ 151 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1751\n",
      "           1       0.94      0.88      0.91      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.92      0.92      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9271523178807947\n",
      "pre:  0.9418702611625948\n",
      "rec:  0.8810086682427108\n",
      "ma F1:  0.9245197620986505\n",
      "mi F1:  0.9271523178807947\n",
      "we F1:  0.9267695704089227\n",
      "Eval Loss:  0.2661086320877075\n",
      "Eval Loss:  0.22309550642967224\n",
      "Eval Loss:  0.2587565779685974\n",
      "Eval Loss:  0.18947196006774902\n",
      "Eval Loss:  0.2988772690296173\n",
      "Eval Loss:  0.22507302463054657\n",
      "Eval Loss:  0.21947652101516724\n",
      "Eval Loss:  0.24133117496967316\n",
      "Eval Loss:  0.2648870646953583\n",
      "Eval Loss:  0.3455650210380554\n",
      "Eval Loss:  0.20637066662311554\n",
      "Eval Loss:  0.389620840549469\n",
      "Eval Loss:  0.17404532432556152\n",
      "Eval Loss:  0.21336853504180908\n",
      "Eval Loss:  0.3434290289878845\n",
      "Eval Loss:  0.3088735044002533\n",
      "Eval Loss:  0.2807632088661194\n",
      "Eval Loss:  0.34789279103279114\n",
      "Eval Loss:  0.27624237537384033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.224660724401474\n",
      "Eval Loss:  0.20923180878162384\n",
      "Eval Loss:  0.272315114736557\n",
      "Eval Loss:  0.24962420761585236\n",
      "Eval Loss:  0.3128686249256134\n",
      "Eval Loss:  0.23247231543064117\n",
      "Eval Loss:  0.22706200182437897\n",
      "Eval Loss:  0.2458311915397644\n",
      "Eval Loss:  0.2908652722835541\n",
      "Eval Loss:  0.2674475610256195\n",
      "[[17620   793]\n",
      " [ 2293  9165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18413\n",
      "           1       0.92      0.80      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.88      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.8966890964480599\n",
      "pre:  0.9203655352480418\n",
      "rec:  0.7998778146273346\n",
      "ma F1:  0.8876911888222523\n",
      "mi F1:  0.8966890964480599\n",
      "we F1:  0.895092779305693\n",
      "29871 467\n",
      "Loss:  0.07017200440168381\n",
      "Loss:  0.08407227694988251\n",
      "Loss:  0.06448041647672653\n",
      "30 **********\n",
      "Epoch:  1743.2061419487  fold:  10  kers:  64\n",
      "epoch:  31\n",
      "29871 467\n",
      "Loss:  0.054065361618995667\n",
      "Loss:  0.06232764571905136\n",
      "Loss:  0.07246090471744537\n",
      "31 **********\n",
      "Epoch:  1786.2134749889374  fold:  10  kers:  64\n",
      "epoch:  32\n",
      "29871 467\n",
      "Loss:  0.07970712333917618\n",
      "Loss:  0.0796375498175621\n",
      "Loss:  0.05199876427650452\n",
      "32 **********\n",
      "Epoch:  1829.1852185726166  fold:  10  kers:  64\n",
      "epoch:  33\n",
      "Eval Loss:  0.2776147723197937\n",
      "Eval Loss:  0.1585213840007782\n",
      "Eval Loss:  0.03538574278354645\n",
      "[[1692   59]\n",
      " [ 167 1102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      1751\n",
      "           1       0.95      0.87      0.91      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.92      0.92      3020\n",
      "weighted avg       0.93      0.93      0.92      3020\n",
      "\n",
      "acc:  0.9251655629139073\n",
      "pre:  0.9491817398794143\n",
      "rec:  0.8684003152088259\n",
      "ma F1:  0.9221960033286596\n",
      "mi F1:  0.9251655629139073\n",
      "we F1:  0.924621982515252\n",
      "Eval Loss:  0.27643704414367676\n",
      "Eval Loss:  0.22608888149261475\n",
      "Eval Loss:  0.2920491695404053\n",
      "Eval Loss:  0.19995109736919403\n",
      "Eval Loss:  0.3057636618614197\n",
      "Eval Loss:  0.24676576256752014\n",
      "Eval Loss:  0.2410770207643509\n",
      "Eval Loss:  0.25829488039016724\n",
      "Eval Loss:  0.25676101446151733\n",
      "Eval Loss:  0.3447778820991516\n",
      "Eval Loss:  0.20641499757766724\n",
      "Eval Loss:  0.41162553429603577\n",
      "Eval Loss:  0.17252345383167267\n",
      "Eval Loss:  0.22707098722457886\n",
      "Eval Loss:  0.3523339629173279\n",
      "Eval Loss:  0.31139183044433594\n",
      "Eval Loss:  0.2763735353946686\n",
      "Eval Loss:  0.35621896386146545\n",
      "Eval Loss:  0.30905190110206604\n",
      "Eval Loss:  0.21883247792720795\n",
      "Eval Loss:  0.21081331372261047\n",
      "Eval Loss:  0.2736128568649292\n",
      "Eval Loss:  0.2590319812297821\n",
      "Eval Loss:  0.3165862262248993\n",
      "Eval Loss:  0.2307123988866806\n",
      "Eval Loss:  0.23818111419677734\n",
      "Eval Loss:  0.23994971811771393\n",
      "Eval Loss:  0.2715788781642914\n",
      "Eval Loss:  0.279042512178421\n",
      "[[17694   719]\n",
      " [ 2496  8962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18413\n",
      "           1       0.93      0.78      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.90      0.87      0.88     29871\n",
      "weighted avg       0.90      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8923705265977034\n",
      "pre:  0.9257308129325483\n",
      "rec:  0.7821609355908535\n",
      "ma F1:  0.8823138803442526\n",
      "mi F1:  0.8923705265977034\n",
      "we F1:  0.8903239553205182\n",
      "29871 467\n",
      "Loss:  0.039299797266721725\n",
      "Loss:  0.07566146552562714\n",
      "Loss:  0.04554155096411705\n",
      "33 **********\n",
      "Epoch:  1911.5739388465881  fold:  10  kers:  64\n",
      "epoch:  34\n",
      "29871 467\n",
      "Loss:  0.04603147134184837\n",
      "Loss:  0.03610466793179512\n",
      "Loss:  0.06639780104160309\n",
      "34 **********\n",
      "Epoch:  1954.6736986637115  fold:  10  kers:  64\n",
      "epoch:  35\n",
      "29871 467\n",
      "Loss:  0.05711730569601059\n",
      "Loss:  0.057910699397325516\n",
      "Loss:  0.03958767652511597\n",
      "35 **********\n",
      "Epoch:  1997.6198687553406  fold:  10  kers:  64\n",
      "epoch:  36\n",
      "Eval Loss:  0.15106022357940674\n",
      "Eval Loss:  0.19913053512573242\n",
      "Eval Loss:  0.027664069086313248\n",
      "[[1685   66]\n",
      " [ 130 1139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      1751\n",
      "           1       0.95      0.90      0.92      1269\n",
      "\n",
      "    accuracy                           0.94      3020\n",
      "   macro avg       0.94      0.93      0.93      3020\n",
      "weighted avg       0.94      0.94      0.93      3020\n",
      "\n",
      "acc:  0.9350993377483444\n",
      "pre:  0.9452282157676348\n",
      "rec:  0.8975571315996848\n",
      "ma F1:  0.9329062632760405\n",
      "mi F1:  0.9350993377483444\n",
      "we F1:  0.9348422740739352\n",
      "update!  Acc:  0.9350993377483444\n",
      "Eval Loss:  0.20381991565227509\n",
      "Eval Loss:  0.22439442574977875\n",
      "Eval Loss:  0.2674577534198761\n",
      "Eval Loss:  0.18791057169437408\n",
      "Eval Loss:  0.3056541681289673\n",
      "Eval Loss:  0.21982669830322266\n",
      "Eval Loss:  0.20928353071212769\n",
      "Eval Loss:  0.19987794756889343\n",
      "Eval Loss:  0.2405514121055603\n",
      "Eval Loss:  0.25730177760124207\n",
      "Eval Loss:  0.17535458505153656\n",
      "Eval Loss:  0.3389991819858551\n",
      "Eval Loss:  0.13737142086029053\n",
      "Eval Loss:  0.2060738056898117\n",
      "Eval Loss:  0.31091177463531494\n",
      "Eval Loss:  0.28955620527267456\n",
      "Eval Loss:  0.2691699266433716\n",
      "Eval Loss:  0.31904885172843933\n",
      "Eval Loss:  0.2415374368429184\n",
      "Eval Loss:  0.1957988291978836\n",
      "Eval Loss:  0.18362872302532196\n",
      "Eval Loss:  0.27159178256988525\n",
      "Eval Loss:  0.22972920536994934\n",
      "Eval Loss:  0.28330129384994507\n",
      "Eval Loss:  0.20959873497486115\n",
      "Eval Loss:  0.1821403056383133\n",
      "Eval Loss:  0.24790264666080475\n",
      "Eval Loss:  0.2804960012435913\n",
      "Eval Loss:  0.2693639099597931\n",
      "[[17428   985]\n",
      " [ 1860  9598]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18413\n",
      "           1       0.91      0.84      0.87     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.91      0.89      0.90     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9047571222925245\n",
      "pre:  0.9069262024000756\n",
      "rec:  0.8376680048874149\n",
      "ma F1:  0.8977300913056744\n",
      "mi F1:  0.9047571222925245\n",
      "we F1:  0.9039718538233682\n",
      "29871 467\n",
      "Loss:  0.09280296415090561\n",
      "Loss:  0.054903384298086166\n",
      "Loss:  0.06051015108823776\n",
      "36 **********\n",
      "Epoch:  2080.1033248901367  fold:  10  kers:  64\n",
      "epoch:  37\n",
      "29871 467\n",
      "Loss:  0.03865077346563339\n",
      "Loss:  0.06746288388967514\n",
      "Loss:  0.07685357332229614\n",
      "37 **********\n",
      "Epoch:  2123.132274389267  fold:  10  kers:  64\n",
      "epoch:  38\n",
      "29871 467\n",
      "Loss:  0.03957848623394966\n",
      "Loss:  0.08278997987508774\n",
      "Loss:  0.07712098956108093\n",
      "38 **********\n",
      "Epoch:  2171.5577940940857  fold:  10  kers:  64\n",
      "epoch:  39\n",
      "Eval Loss:  0.1532527059316635\n",
      "Eval Loss:  0.22292445600032806\n",
      "Eval Loss:  0.03610539808869362\n",
      "[[1653   98]\n",
      " [ 119 1150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      1751\n",
      "           1       0.92      0.91      0.91      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9281456953642384\n",
      "pre:  0.9214743589743589\n",
      "rec:  0.9062253743104807\n",
      "ma F1:  0.926095511069716\n",
      "mi F1:  0.9281456953642384\n",
      "we F1:  0.9280601011889203\n",
      "Eval Loss:  0.20693887770175934\n",
      "Eval Loss:  0.21319231390953064\n",
      "Eval Loss:  0.24418000876903534\n",
      "Eval Loss:  0.18133805692195892\n",
      "Eval Loss:  0.2869180142879486\n",
      "Eval Loss:  0.21139468252658844\n",
      "Eval Loss:  0.21266235411167145\n",
      "Eval Loss:  0.20248620212078094\n",
      "Eval Loss:  0.22988587617874146\n",
      "Eval Loss:  0.24469196796417236\n",
      "Eval Loss:  0.16135986149311066\n",
      "Eval Loss:  0.31400489807128906\n",
      "Eval Loss:  0.12727193534374237\n",
      "Eval Loss:  0.22513338923454285\n",
      "Eval Loss:  0.3019150197505951\n",
      "Eval Loss:  0.28651049733161926\n",
      "Eval Loss:  0.26091906428337097\n",
      "Eval Loss:  0.31879541277885437\n",
      "Eval Loss:  0.24240179359912872\n",
      "Eval Loss:  0.1762789934873581\n",
      "Eval Loss:  0.18409527838230133\n",
      "Eval Loss:  0.2627035081386566\n",
      "Eval Loss:  0.2313331961631775\n",
      "Eval Loss:  0.2738274335861206\n",
      "Eval Loss:  0.1802522987127304\n",
      "Eval Loss:  0.18763668835163116\n",
      "Eval Loss:  0.24177107214927673\n",
      "Eval Loss:  0.250780314207077\n",
      "Eval Loss:  0.23901985585689545\n",
      "[[17322  1091]\n",
      " [ 1625  9833]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18413\n",
      "           1       0.90      0.86      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9090756921428811\n",
      "pre:  0.9001281581838154\n",
      "rec:  0.858177692441962\n",
      "ma F1:  0.9029772079008886\n",
      "mi F1:  0.9090756921428811\n",
      "we F1:  0.9086408422850597\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06893227249383926\n",
      "Loss:  0.05605100095272064\n",
      "Loss:  0.048691023141145706\n",
      "39 **********\n",
      "Epoch:  2254.125026702881  fold:  10  kers:  64\n",
      "epoch:  40\n",
      "29871 467\n",
      "Loss:  0.08230071514844894\n",
      "Loss:  0.05877736210823059\n",
      "Loss:  0.03856464475393295\n",
      "40 **********\n",
      "Epoch:  2297.3045732975006  fold:  10  kers:  64\n",
      "epoch:  41\n",
      "29871 467\n",
      "Loss:  0.03673318773508072\n",
      "Loss:  0.06747226417064667\n",
      "Loss:  0.08304627984762192\n",
      "41 **********\n",
      "Epoch:  2340.4172728061676  fold:  10  kers:  64\n",
      "epoch:  42\n",
      "Eval Loss:  0.13939805328845978\n",
      "Eval Loss:  0.24417538940906525\n",
      "Eval Loss:  0.014856982044875622\n",
      "[[1681   70]\n",
      " [ 121 1148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      1751\n",
      "           1       0.94      0.90      0.92      1269\n",
      "\n",
      "    accuracy                           0.94      3020\n",
      "   macro avg       0.94      0.93      0.93      3020\n",
      "weighted avg       0.94      0.94      0.94      3020\n",
      "\n",
      "acc:  0.9367549668874172\n",
      "pre:  0.9425287356321839\n",
      "rec:  0.904649330181245\n",
      "ma F1:  0.9347216276113415\n",
      "mi F1:  0.9367549668874172\n",
      "we F1:  0.9365604072193501\n",
      "update!  Acc:  0.9367549668874172\n",
      "Eval Loss:  0.22177754342556\n",
      "Eval Loss:  0.2193925529718399\n",
      "Eval Loss:  0.2625369429588318\n",
      "Eval Loss:  0.164758563041687\n",
      "Eval Loss:  0.2748947739601135\n",
      "Eval Loss:  0.22530436515808105\n",
      "Eval Loss:  0.21957561373710632\n",
      "Eval Loss:  0.21038755774497986\n",
      "Eval Loss:  0.22659403085708618\n",
      "Eval Loss:  0.2366447001695633\n",
      "Eval Loss:  0.17301566898822784\n",
      "Eval Loss:  0.31673353910446167\n",
      "Eval Loss:  0.13534903526306152\n",
      "Eval Loss:  0.2047155201435089\n",
      "Eval Loss:  0.2988032400608063\n",
      "Eval Loss:  0.2851387560367584\n",
      "Eval Loss:  0.26350706815719604\n",
      "Eval Loss:  0.3240465521812439\n",
      "Eval Loss:  0.2544454336166382\n",
      "Eval Loss:  0.17231954634189606\n",
      "Eval Loss:  0.19233937561511993\n",
      "Eval Loss:  0.2492581009864807\n",
      "Eval Loss:  0.2693900763988495\n",
      "Eval Loss:  0.2742840349674225\n",
      "Eval Loss:  0.16627538204193115\n",
      "Eval Loss:  0.20343443751335144\n",
      "Eval Loss:  0.22527801990509033\n",
      "Eval Loss:  0.2459598332643509\n",
      "Eval Loss:  0.23053357005119324\n",
      "[[17559   854]\n",
      " [ 1887  9571]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     18413\n",
      "           1       0.92      0.84      0.87     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.89      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9082387600013391\n",
      "pre:  0.9180815347721822\n",
      "rec:  0.8353115727002968\n",
      "ma F1:  0.901171364636693\n",
      "mi F1:  0.9082387600013391\n",
      "we F1:  0.9073248116523558\n",
      "29871 467\n",
      "Loss:  0.09249594807624817\n",
      "Loss:  0.08440978825092316\n",
      "Loss:  0.058942317962646484\n",
      "42 **********\n",
      "Epoch:  2423.04120016098  fold:  10  kers:  64\n",
      "epoch:  43\n",
      "29871 467\n",
      "Loss:  0.05285323038697243\n",
      "Loss:  0.0573451928794384\n",
      "Loss:  0.038468919694423676\n",
      "43 **********\n",
      "Epoch:  2465.9958477020264  fold:  10  kers:  64\n",
      "epoch:  44\n",
      "29871 467\n",
      "Loss:  0.04660677909851074\n",
      "Loss:  0.03348280116915703\n",
      "Loss:  0.04949130862951279\n",
      "44 **********\n",
      "Epoch:  2509.098562479019  fold:  10  kers:  64\n",
      "epoch:  45\n",
      "Eval Loss:  0.16595828533172607\n",
      "Eval Loss:  0.2293311357498169\n",
      "Eval Loss:  0.007994141429662704\n",
      "[[1681   70]\n",
      " [ 140 1129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1751\n",
      "           1       0.94      0.89      0.91      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.92      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9304635761589404\n",
      "pre:  0.9416180150125104\n",
      "rec:  0.8896769109535066\n",
      "ma F1:  0.9280601327450493\n",
      "mi F1:  0.9304635761589404\n",
      "we F1:  0.9301587916680485\n",
      "Eval Loss:  0.21661332249641418\n",
      "Eval Loss:  0.23019029200077057\n",
      "Eval Loss:  0.26218968629837036\n",
      "Eval Loss:  0.15824052691459656\n",
      "Eval Loss:  0.28037360310554504\n",
      "Eval Loss:  0.205951526761055\n",
      "Eval Loss:  0.22264191508293152\n",
      "Eval Loss:  0.20137369632720947\n",
      "Eval Loss:  0.23971600830554962\n",
      "Eval Loss:  0.25394439697265625\n",
      "Eval Loss:  0.18673133850097656\n",
      "Eval Loss:  0.31616050004959106\n",
      "Eval Loss:  0.14391404390335083\n",
      "Eval Loss:  0.19574646651744843\n",
      "Eval Loss:  0.3027218282222748\n",
      "Eval Loss:  0.2986162304878235\n",
      "Eval Loss:  0.26800060272216797\n",
      "Eval Loss:  0.32161468267440796\n",
      "Eval Loss:  0.2506886422634125\n",
      "Eval Loss:  0.18107958137989044\n",
      "Eval Loss:  0.17673556506633759\n",
      "Eval Loss:  0.26678016781806946\n",
      "Eval Loss:  0.2344885617494583\n",
      "Eval Loss:  0.2604246735572815\n",
      "Eval Loss:  0.18718576431274414\n",
      "Eval Loss:  0.1985316127538681\n",
      "Eval Loss:  0.23726116120815277\n",
      "Eval Loss:  0.2606337070465088\n",
      "Eval Loss:  0.23507238924503326\n",
      "[[17731   682]\n",
      " [ 2135  9323]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     18413\n",
      "           1       0.93      0.81      0.87     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.89      0.90     29871\n",
      "weighted avg       0.91      0.91      0.90     29871\n",
      "\n",
      "acc:  0.9056944862910515\n",
      "pre:  0.9318340829585208\n",
      "rec:  0.8136673066852854\n",
      "ma F1:  0.8975798047284077\n",
      "mi F1:  0.9056944862910515\n",
      "we F1:  0.9042921751218649\n",
      "29871 467\n",
      "Loss:  0.04194573685526848\n",
      "Loss:  0.05806078389286995\n",
      "Loss:  0.04002683609724045\n",
      "45 **********\n",
      "Epoch:  2591.6340072155  fold:  10  kers:  64\n",
      "epoch:  46\n",
      "29871 467\n",
      "Loss:  0.05399363115429878\n",
      "Loss:  0.07753468304872513\n",
      "Loss:  0.06247405707836151\n",
      "46 **********\n",
      "Epoch:  2634.687441110611  fold:  10  kers:  64\n",
      "epoch:  47\n",
      "29871 467\n",
      "Loss:  0.03075627237558365\n",
      "Loss:  0.07790627330541611\n",
      "Loss:  0.047157108783721924\n",
      "47 **********\n",
      "Epoch:  2677.615075826645  fold:  10  kers:  64\n",
      "epoch:  48\n",
      "Eval Loss:  0.1427111178636551\n",
      "Eval Loss:  0.2310837358236313\n",
      "Eval Loss:  0.026825889945030212\n",
      "[[1676   75]\n",
      " [ 120 1149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      1751\n",
      "           1       0.94      0.91      0.92      1269\n",
      "\n",
      "    accuracy                           0.94      3020\n",
      "   macro avg       0.94      0.93      0.93      3020\n",
      "weighted avg       0.94      0.94      0.94      3020\n",
      "\n",
      "acc:  0.9354304635761589\n",
      "pre:  0.9387254901960784\n",
      "rec:  0.9054373522458629\n",
      "ma F1:  0.9334024753380511\n",
      "mi F1:  0.9354304635761589\n",
      "we F1:  0.9352572957000398\n",
      "Eval Loss:  0.20412860810756683\n",
      "Eval Loss:  0.21039217710494995\n",
      "Eval Loss:  0.25084933638572693\n",
      "Eval Loss:  0.1669461578130722\n",
      "Eval Loss:  0.28401780128479004\n",
      "Eval Loss:  0.21697686612606049\n",
      "Eval Loss:  0.2237178534269333\n",
      "Eval Loss:  0.19270968437194824\n",
      "Eval Loss:  0.21491165459156036\n",
      "Eval Loss:  0.23265781998634338\n",
      "Eval Loss:  0.15847426652908325\n",
      "Eval Loss:  0.2927825152873993\n",
      "Eval Loss:  0.12079260498285294\n",
      "Eval Loss:  0.2035129964351654\n",
      "Eval Loss:  0.31001824140548706\n",
      "Eval Loss:  0.2632421851158142\n",
      "Eval Loss:  0.2637881338596344\n",
      "Eval Loss:  0.3217838406562805\n",
      "Eval Loss:  0.2501066029071808\n",
      "Eval Loss:  0.15284521877765656\n",
      "Eval Loss:  0.17913119494915009\n",
      "Eval Loss:  0.2579873204231262\n",
      "Eval Loss:  0.23846976459026337\n",
      "Eval Loss:  0.2661871016025543\n",
      "Eval Loss:  0.14146213233470917\n",
      "Eval Loss:  0.20258715748786926\n",
      "Eval Loss:  0.2063712328672409\n",
      "Eval Loss:  0.2431650608778\n",
      "Eval Loss:  0.2088107019662857\n",
      "[[17466   947]\n",
      " [ 1664  9794]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18413\n",
      "           1       0.91      0.85      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.91     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9125908071373573\n",
      "pre:  0.9118331626477981\n",
      "rec:  0.854773957060569\n",
      "ma F1:  0.9064175848755156\n",
      "mi F1:  0.9125908071373573\n",
      "we F1:  0.9120138779974015\n",
      "29871 467\n",
      "Loss:  0.04955187439918518\n",
      "Loss:  0.06811115890741348\n",
      "Loss:  0.0408356636762619\n",
      "48 **********\n",
      "Epoch:  2759.8073105812073  fold:  10  kers:  64\n",
      "epoch:  49\n",
      "29871 467\n",
      "Loss:  0.06227179989218712\n",
      "Loss:  0.06644032895565033\n",
      "Loss:  0.07572072744369507\n",
      "49 **********\n",
      "Epoch:  2802.7494781017303  fold:  10  kers:  64\n",
      "epoch:  50\n",
      "29871 467\n",
      "Loss:  0.06566263735294342\n",
      "Loss:  0.09015457332134247\n",
      "Loss:  0.08226154744625092\n",
      "50 **********\n",
      "Epoch:  2845.7185876369476  fold:  10  kers:  64\n",
      "epoch:  51\n",
      "Eval Loss:  0.18143001198768616\n",
      "Eval Loss:  0.23631471395492554\n",
      "Eval Loss:  0.018999001011252403\n",
      "[[1688   63]\n",
      " [ 128 1141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      1751\n",
      "           1       0.95      0.90      0.92      1269\n",
      "\n",
      "    accuracy                           0.94      3020\n",
      "   macro avg       0.94      0.93      0.93      3020\n",
      "weighted avg       0.94      0.94      0.94      3020\n",
      "\n",
      "acc:  0.9367549668874172\n",
      "pre:  0.9476744186046512\n",
      "rec:  0.8991331757289204\n",
      "ma F1:  0.9346097369391504\n",
      "mi F1:  0.9367549668874172\n",
      "we F1:  0.9365000492518829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.20426343381404877\n",
      "Eval Loss:  0.2056242674589157\n",
      "Eval Loss:  0.2457641065120697\n",
      "Eval Loss:  0.15749140083789825\n",
      "Eval Loss:  0.27092933654785156\n",
      "Eval Loss:  0.2399452030658722\n",
      "Eval Loss:  0.22655953466892242\n",
      "Eval Loss:  0.20583337545394897\n",
      "Eval Loss:  0.20309364795684814\n",
      "Eval Loss:  0.2609233260154724\n",
      "Eval Loss:  0.15986955165863037\n",
      "Eval Loss:  0.3109709918498993\n",
      "Eval Loss:  0.13220186531543732\n",
      "Eval Loss:  0.19055171310901642\n",
      "Eval Loss:  0.2883014976978302\n",
      "Eval Loss:  0.2791942358016968\n",
      "Eval Loss:  0.2681663930416107\n",
      "Eval Loss:  0.29429906606674194\n",
      "Eval Loss:  0.24383243918418884\n",
      "Eval Loss:  0.1384662687778473\n",
      "Eval Loss:  0.18946564197540283\n",
      "Eval Loss:  0.26791203022003174\n",
      "Eval Loss:  0.23563914000988007\n",
      "Eval Loss:  0.25017693638801575\n",
      "Eval Loss:  0.1663457155227661\n",
      "Eval Loss:  0.2121080458164215\n",
      "Eval Loss:  0.20347999036312103\n",
      "Eval Loss:  0.2453978806734085\n",
      "Eval Loss:  0.2215149700641632\n",
      "[[17586   827]\n",
      " [ 1841  9617]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18413\n",
      "           1       0.92      0.84      0.88     11458\n",
      "\n",
      "    accuracy                           0.91     29871\n",
      "   macro avg       0.91      0.90      0.90     29871\n",
      "weighted avg       0.91      0.91      0.91     29871\n",
      "\n",
      "acc:  0.9106826018546417\n",
      "pre:  0.9208157793948679\n",
      "rec:  0.8393262349450166\n",
      "ma F1:  0.9038386205474589\n",
      "mi F1:  0.9106826018546417\n",
      "we F1:  0.9098117526834177\n",
      "29871 467\n",
      "Loss:  0.08046925812959671\n",
      "Loss:  0.060020215809345245\n",
      "Loss:  0.06398620456457138\n",
      "51 **********\n",
      "Epoch:  2927.9007229804993  fold:  10  kers:  64\n",
      "epoch:  52\n",
      "29871 467\n",
      "Loss:  0.05115172639489174\n",
      "Loss:  0.03952861577272415\n",
      "Loss:  0.04184161126613617\n",
      "52 **********\n",
      "Epoch:  2970.9296720027924  fold:  10  kers:  64\n",
      "epoch:  53\n",
      "29871 467\n",
      "Loss:  0.08590862154960632\n",
      "Loss:  0.04657917097210884\n",
      "Loss:  0.07363855838775635\n",
      "53 **********\n",
      "Epoch:  3013.9067599773407  fold:  10  kers:  64\n",
      "epoch:  54\n",
      "Eval Loss:  0.14497804641723633\n",
      "Eval Loss:  0.26589420437812805\n",
      "Eval Loss:  0.017190633341670036\n",
      "[[1653   98]\n",
      " [ 100 1169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1751\n",
      "           1       0.92      0.92      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9344370860927153\n",
      "pre:  0.9226519337016574\n",
      "rec:  0.9211977935382191\n",
      "ma F1:  0.9327087204528759\n",
      "mi F1:  0.9344370860927153\n",
      "we F1:  0.934429944085939\n",
      "Eval Loss:  0.18064339458942413\n",
      "Eval Loss:  0.21222274005413055\n",
      "Eval Loss:  0.2447306215763092\n",
      "Eval Loss:  0.1672748476266861\n",
      "Eval Loss:  0.2515619993209839\n",
      "Eval Loss:  0.238067626953125\n",
      "Eval Loss:  0.21462708711624146\n",
      "Eval Loss:  0.19809095561504364\n",
      "Eval Loss:  0.20319832861423492\n",
      "Eval Loss:  0.23643912374973297\n",
      "Eval Loss:  0.1491502970457077\n",
      "Eval Loss:  0.3047473132610321\n",
      "Eval Loss:  0.1236531138420105\n",
      "Eval Loss:  0.19182881712913513\n",
      "Eval Loss:  0.2931244373321533\n",
      "Eval Loss:  0.2493574023246765\n",
      "Eval Loss:  0.2653202414512634\n",
      "Eval Loss:  0.29236292839050293\n",
      "Eval Loss:  0.23647794127464294\n",
      "Eval Loss:  0.14377357065677643\n",
      "Eval Loss:  0.1780654937028885\n",
      "Eval Loss:  0.2691853940486908\n",
      "Eval Loss:  0.23548434674739838\n",
      "Eval Loss:  0.2277945876121521\n",
      "Eval Loss:  0.14522644877433777\n",
      "Eval Loss:  0.19405700266361237\n",
      "Eval Loss:  0.19905459880828857\n",
      "Eval Loss:  0.2203749418258667\n",
      "Eval Loss:  0.2250738888978958\n",
      "[[17419   994]\n",
      " [ 1500  9958]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18413\n",
      "           1       0.91      0.87      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.91      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9165076495597737\n",
      "pre:  0.9092403214024836\n",
      "rec:  0.8690871007156572\n",
      "ma F1:  0.9109522198942561\n",
      "mi F1:  0.9165076495597738\n",
      "we F1:  0.9161308840577295\n",
      "29871 467\n",
      "Loss:  0.05686775594949722\n",
      "Loss:  0.047385696321725845\n",
      "Loss:  0.1349674016237259\n",
      "54 **********\n",
      "Epoch:  3096.332370519638  fold:  10  kers:  64\n",
      "epoch:  55\n",
      "29871 467\n",
      "Loss:  0.06613469868898392\n",
      "Loss:  0.07245860993862152\n",
      "Loss:  0.03817249834537506\n",
      "55 **********\n",
      "Epoch:  3139.414178609848  fold:  10  kers:  64\n",
      "epoch:  56\n",
      "29871 467\n",
      "Loss:  0.04666254296898842\n",
      "Loss:  0.05662589892745018\n",
      "Loss:  0.06248626112937927\n",
      "56 **********\n",
      "Epoch:  3182.4431278705597  fold:  10  kers:  64\n",
      "epoch:  57\n",
      "Eval Loss:  0.18489202857017517\n",
      "Eval Loss:  0.28952765464782715\n",
      "Eval Loss:  0.032469622790813446\n",
      "[[1655   96]\n",
      " [  97 1172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      1751\n",
      "           1       0.92      0.92      0.92      1269\n",
      "\n",
      "    accuracy                           0.94      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.94      0.94      0.94      3020\n",
      "\n",
      "acc:  0.936092715231788\n",
      "pre:  0.9242902208201893\n",
      "rec:  0.9235618597320725\n",
      "ma F1:  0.9344151322066305\n",
      "mi F1:  0.9360927152317882\n",
      "we F1:  0.9360892419750073\n",
      "Eval Loss:  0.17413154244422913\n",
      "Eval Loss:  0.19267037510871887\n",
      "Eval Loss:  0.23804721236228943\n",
      "Eval Loss:  0.17530857026576996\n",
      "Eval Loss:  0.2715212106704712\n",
      "Eval Loss:  0.22445832192897797\n",
      "Eval Loss:  0.226038858294487\n",
      "Eval Loss:  0.1726173311471939\n",
      "Eval Loss:  0.20375864207744598\n",
      "Eval Loss:  0.222945898771286\n",
      "Eval Loss:  0.12891343235969543\n",
      "Eval Loss:  0.2785705327987671\n",
      "Eval Loss:  0.10350355505943298\n",
      "Eval Loss:  0.2031082808971405\n",
      "Eval Loss:  0.2848074436187744\n",
      "Eval Loss:  0.25364914536476135\n",
      "Eval Loss:  0.25424090027809143\n",
      "Eval Loss:  0.3035467565059662\n",
      "Eval Loss:  0.2353442907333374\n",
      "Eval Loss:  0.13329945504665375\n",
      "Eval Loss:  0.17328202724456787\n",
      "Eval Loss:  0.2613033354282379\n",
      "Eval Loss:  0.2165570706129074\n",
      "Eval Loss:  0.21780814230442047\n",
      "Eval Loss:  0.14118561148643494\n",
      "Eval Loss:  0.18136799335479736\n",
      "Eval Loss:  0.19571179151535034\n",
      "Eval Loss:  0.21476837992668152\n",
      "Eval Loss:  0.22139698266983032\n",
      "[[17235  1178]\n",
      " [ 1229 10229]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18413\n",
      "           1       0.90      0.89      0.89     11458\n",
      "\n",
      "    accuracy                           0.92     29871\n",
      "   macro avg       0.92      0.91      0.91     29871\n",
      "weighted avg       0.92      0.92      0.92     29871\n",
      "\n",
      "acc:  0.9194201734123397\n",
      "pre:  0.896730078022267\n",
      "rec:  0.8927386978530285\n",
      "ma F1:  0.9147294502185537\n",
      "mi F1:  0.9194201734123397\n",
      "we F1:  0.9193860274113572\n",
      "29871 467\n",
      "Loss:  0.05288129299879074\n",
      "Loss:  0.061421096324920654\n",
      "Loss:  0.04870118945837021\n",
      "57 **********\n",
      "Epoch:  3264.84081363678  fold:  10  kers:  64\n",
      "epoch:  58\n",
      "29871 467\n",
      "Loss:  0.06413910537958145\n",
      "Loss:  0.06961368769407272\n",
      "Loss:  0.06590937823057175\n",
      "58 **********\n",
      "Epoch:  3307.8388454914093  fold:  10  kers:  64\n",
      "epoch:  59\n",
      "29871 467\n",
      "Loss:  0.057699814438819885\n",
      "Loss:  0.07725142687559128\n",
      "Loss:  0.04039318114519119\n",
      "59 **********\n",
      "Epoch:  3350.852834701538  fold:  10  kers:  64\n",
      "Eval Loss:  0.1237189769744873\n",
      "Eval Loss:  0.3500749468803406\n",
      "Eval Loss:  0.05500812456011772\n",
      "[[1641  110]\n",
      " [  93 1176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      1751\n",
      "           1       0.91      0.93      0.92      1269\n",
      "\n",
      "    accuracy                           0.93      3020\n",
      "   macro avg       0.93      0.93      0.93      3020\n",
      "weighted avg       0.93      0.93      0.93      3020\n",
      "\n",
      "acc:  0.9327814569536423\n",
      "pre:  0.9144634525660964\n",
      "rec:  0.9267139479905437\n",
      "ma F1:  0.9311491519427684\n",
      "mi F1:  0.9327814569536423\n",
      "we F1:  0.9328411326207064\n",
      "update!  Acc:  0.9367549668874172\n",
      "Epoch:  3354.4482209682465  fold:  10  kers:  64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2gUlEQVR4nO3dd3xUZdYH8N9JIwQSaigSMAEiiKgIoQvSVIqK6/oqoqvrqiyrKBZU1LWXdV1eV3llZVGxrYp9RUVAmnRIgFBDCSFAICGhJKGln/ePuZPczNyZuXfmTsmd8/18+DBz2zw3k5x55innIWaGEEII64oIdgGEEEL4lwR6IYSwOAn0QghhcRLohRDC4iTQCyGExUUFuwBaWrduzcnJycEuhhBCNBibNm06zsyJWvtCMtAnJycjIyMj2MUQQogGg4gOutonTTdCCGFxEuiFEMLiJNALIYTFSaAXQgiL0xXoiWg0Ee0homwimq6xvzsRrSOiciKa5rDvESLaSUQ7iOgLIoo1q/BCCCE88xjoiSgSwCwAYwD0AHAbEfVwOOwkgIcAzHA4t4OyPY2ZewKIBDDBhHILIYTQSU+Nvh+AbGbOYeYKAPMAjFcfwMyFzJwOoFLj/CgAjYkoCkAcgKM+llkIIYQBegJ9BwCHVc/zlG0eMfMR2Gr5hwDkAyhh5sVaxxLRJCLKIKKMoqIiPZf3u1NnK7Bge36wiyGEED7RE+hJY5uuJPZE1AK22n8KgAsANCGiO7SOZeY5zJzGzGmJiZqTuwLuz59uwv2fbUZhaVmwiyKEEF7TE+jzAHRUPU+C/uaXUQAOMHMRM1cC+A7AIGNF9E5haRmSp/+MH7d631J0pPg8AKCiusasYgkhRMDpCfTpAFKJKIWIYmDrTJ2v8/qHAAwgojgiIgAjAWR5V1RjdhecBgB8mX7Yw5FCCGFtHnPdMHMVEU0BsAi2UTNzmXknEU1W9s8monYAMgAkAKghoocB9GDmDUT0DYDNAKoAbAEwxz+3oo20Gp6EECKM6EpqxswLACxw2DZb9bgAtiYdrXOfB/C8D2X0iqyEK4QQNiGZvdIXq/cdR1KLxpBFz4UQwsZSgb7odDnu+GADAGDUxW0AAESEU2crsHxPIW7qrfmlQwghLM1Sgb7vq0tqHy/JKgRgGxs65YvNWJN9An0ubIELWzUJUumEECI4wiKp2bHScgBARZUMkxRChB/LB/rf9obGLFshhAgWywd6NemeFUKEI8sEenejbGQovRAinFkm0JPMjBJCCE2WCfTu5J2y5ayRofVCiHAUFoH+fGV1sIsghBBBExaBXgghwpmlAv2Gp0e63V8mNXshRBiyVKBvE9/I7f4vNh4KUEmEECJ0WCrQexp5U10jvbFCiPBjqUAvhBDCma5AT0SjiWgPEWUT0XSN/d2JaB0RlRPRNId9zYnoGyLaTURZRDTQrMJruX9YF5f7pD4vhAhHHrNXElEkgFkAroZt/dh0IprPzLtUh50E8BCAGzUu8TaAhcx8s7IUYZzPpXYjJkq+pAghhJqeqNgPQDYz5zBzBYB5AMarD2DmQmZOB1Cp3k5ECQCGAvhAOa6CmYvNKLgr7gL94p0F/nxpIYQISXoCfQcA6hW285RtenQGUATgQyLaQkTvE1HQEsKXllV5POZYaRlemL8TVdWS0lgIYQ16Ar3WUBa9zd1RAHoDeJeZrwBwFoBTGz8AENEkIsogooyiIu9TC5MXKcwW7yxA8vSf8a8V2Zj+7TZ8tDYXa/af8LoMQggRSvQE+jwAHVXPkwAc1Xn9PAB5zLxBef4NbIHfCTPPYeY0Zk5LTEzUeXlnN15xgeFznv5+OwDgjYV7UGXSEMwTZ8rDIhf+8TPl6PPyr9h5tCTYRRFCuKAn0KcDSCWiFKUzdQKA+XouzswFAA4TUTdl00gAu9yc4rP2zRr78/K63f7+Btw1d6Plm4BW7i3CibMVeH/VgWAXRQjhgsdRN8xcRURTACwCEAlgLjPvJKLJyv7ZRNQOQAaABAA1RPQwgB7MXArgQQCfKR8SOQDu9s+tGHOk+DzOlFWhW7t4v1x/X+EZv1xXCCGM0rU4ODMvALDAYdts1eMC2Jp0tM7NBJDmfRH9Y/DrywAAua+PC3JJhBDCvyw56Pyju/u63Kc3DYK7FauEEKIh0VWjb2iGdWvjcl+Xpxfgz0M7u9xvz5fz3qocn4J9qH5QMDNOnK1A66buE8AJIazDkjV6T/69MsflvpXKSJk12XXDK31ZpjDUljicszIHaa8swaET54JdFCFEgFg20D88KjWorx+a9Xlg+Z5CAEBesTmBPkS/uAghVCwb6Ptc2EL3scfPVPitHO7q89U1bJnx56H1vUUIoWbZQK93hmyljnHuetvbdx0txeNfb0VNDeuq6b6zLBvjZq7GtrxiXdcXQghvWDbQm8Fo+/qkTzPw9aY8HCk+r7qG6+O3H7HV5gtKygAANTWMV3/ehcMnA9B+bnKTi7TgCBG6LBvoQ6wPVJdd+aV4b9UBTPl8s99ew5tcQG6v1wB/zkKEG+sG+gC/nqtRLNvy9LfB25t7qk3o4dx1tDRkh3gKIQLLsoE+kJH+l+35GPqP5cg7dd5p3/hZawJXEMWSXccwduYqfLv5SMBfWwgReiwb6BNNnBDkaTatva3diLXZx5GVX+ptkdzaX2TLs7P32GmXx5hV15cvDUKEPssG+tS2vicrs3eqvrFoj8/XcjTx/Q31Om0DxV9t6tJUL0Tosmyg1+vlnzxnTc48VOz/ggghGrQth06FbL+YpQP95/f193jMJ+sOBqAkNsv3FCLvlKQeEMJqFu0swO/+tRbz0g97PjgILB3oB3Vpbcp1zPqUvvvDdFzzz5U6Xs+Ulwv6a4SjpVnHsLvAP30vInTZR93tD9F1KCwd6P2hoKQMucfPen3+uYpqp232mGt2+7nWB5TVxr1XVtfglZ924dRZ/6WxMOKejzMw+q1VwS6GEPXoCvRENJqI9hBRNhE5Le5NRN2JaB0RlRPRNI39kUS0hYh+MqPQwTTgb0sxbMaKettCrXJstWDuzi87CvD+6gN4+We/rlApGrBfdx1DfkngBz6EEo+BnogiAcwCMAZADwC3EVEPh8NOAngIwAwXl5kKIMuHcgZVqAVyUadGGfqqd0EZEX7u+yQDN7wT+PksoURPjb4fgGxmzmHmCgDzAIxXH8DMhcycDqDS8WQiSgIwDsD7JpQ3KMxuz163/0S953or4LuOlmL57kJTysDy8SXCSNHp8mAXIaj0BPoOANRdyXnKNr3eAvAEALdpIoloEhFlEFFGUVGRgcv7n9lB8bb31nt13tiZq3D3R+m1z5dmHUP3Z39Bl6cXuDmrPrNz3QghQp+eQK8VGXRFPiK6DkAhM2/ydCwzz2HmNGZOS0xM1HP5gDpafL62mUDtfEW1abVso+75OANllTXSbBEEZZXOnepChCo9gT4PQEfV8yQAR3VefzCAG4goF7YmnxFE9B9DJQwBx0rLMej1ZZj2zVanfc98vx27C1ynGgCAKh0579W8bSpiZmTknvT5OsK9LYdOofuzC7Fs97FgF0UIXfQE+nQAqUSUQkQxACYAmK/n4sz8FDMnMXOyct4yZr7D69IG2XeqJGGHT57DnoLTOHDCeahljUOE7frML34vGwD8uC0fN89eh283eU5mFs4fAhsPnET/15bgTHmVV+dvOngKALB63wmXx/x3iySUE6HDY6Bn5ioAUwAsgm3kzFfMvJOIJhPRZAAgonZElAfgUQB/JaI8IkrwZ8GDbcgby3HtW9qTnz7feMjn65dVVhtuHjiojO/PVT589mgkNTN9rL4X55RXVeta2cuovcdO49ddnmvZ/1i0G8dKy7HrqHcTm37c6vkL7cNfZnp1bdGwhWr9Sdc4emZewMwXMXMXZn5V2TabmWcrjwuUmnsCMzdXHpc6XGMFM19n/i2EnnPlvrffdn92Ifq+sgQAcKy0DGd11D4df8lW7TvufIyffhO/M1CD7fbXhRjt4kPSF9f8cyXu+yTD9Os62mpgjQF/ycovxdps5/dXmO/7LXnYeOCk22NCfe5KVLAL0NBp9YMaHaXj6ujTSnDv/9pSdE5sovt6en7p9P5ini2vwqaDpzD0InM7yPcXeT+7WC1ch4mOeds2+zb39XFBLon1PfKlrW+uIf+sJQWCj7YeLg7I6+ToCIz22nqNjlYRvTX7aV9vxZ1zN7pcxzZUKjLqcpyr8K7t3ap+21uExTsLgl0MEUQS6P0gWB2dv2bZ/pgr3LR/G/2Kma0kaTrvw3DCP32Ujq4GxvrbVdcwvt2Upzms1Z3C0vCeHOPorrkbMelTjyOchYVZPtDfOfDCYBfBMG8/J4wGuPMV1ZixaA/Kq4wF8eNnyrFyr/5Jbct2F6LKi7H+H6/NxWNfb8UX6b53bgsRKN9sygvKokLuWD7Qv3D9JQF/zfIq70aU+NKh86gXozze/W0/3lmejU8N5uRPe2UJ7py70e8TtU6ctX1whUpmSiE8KausxrSvt2LCnHXBLko9lg/0ERGBb0X+ZlOeoeMJtslO7yzL9vo1jYx6AWzfGuw1+cpq7wO2r6GemVFYWubjVRyuaeC1jTL67UeEF3vd5/jp0KqcWD7QNxQ/bcvHLzus32F219yN9Z5/uv4g+r22FHs8zC72RB2y564+UO/6jguB+JLv5/MN0ozkaNnuY0ie/rPpq6f9kHkEs5Z7X/kRdSTQh4gHv9hS+9jbpoqGMNDwN4e2/dXKWP8DXi7mYg/aP2TWTWL6dH1dU9Sz/91h6kIgFV42y4WS02WV+NuCLNPu5esM2zfYbSbPL5g6LxP/WLTH1Gv6X2j+FUqgD0EFqqYMV8MaA2HfsdNu2+GPFp/HJ+tyA1cgg86rVvPyx8/R3qdSWFqGkvNOGbp1yz1+FhPmrPM6JYNRby3Zh3+vzMHXm0JzfVNhPgn0AbL50CmvzjMyg9RIg4Sn9unswtO4+p8rkaPUtLWufdfcjabX4lyZt/EQjp8xNqpIvaqQL/0fnvR7bSkG/W2p1+f/Y/EerM85GbAsqPaavKfO9PKqaryzbJ8lvsWEOwn0AXLTv9a63HfITW3zrMYas0Y4Zs4k9dAeN3/nBSWeg+qpc751OOmdwn/45HlM/247/vIf57HgwZwZq/6s9PV9CkUfrD6AGYv34uO1ubqOD+dEeY5CbcZ2WAT65FZxwS6CW6/8bHyVxc5P/azruIM6miy8HdZ56pz3zRUAMPH9DU5/DsdKy5xmttoToJ04E1ojGazO3vTlabKc1u/PtrxivLtivz+KFeJCZa54fWER6Jc+NizYRTDVoRPnNHPseEurJhboGok9WPR/bSlu/bd3K3D5YufREl0ZNX39uZecqwzasnbfbsrDvR/7P+kbANzwzhr8feHugLyW8CwsAn1kEMbS+9OwGcu9PvdYia2jlwGXlY/3VubgtQXB+yPdfkS73d9ojCUPX1Xs1ztw/CzGzVyN1xZ4/mb1j0W+/Vx6v/Ir+r66xKdreOuxr7diSZZ5i6UwM/YXnTHtesJ/JHtlA+RLrdKeo95d2uNXdQQ8s52rqHK9EpeJn9P7jp3Gxtz6KWdnLLYN4dPTsexrjV6zA9RPX54yck/6tbP8vVW2CkGnlram0VBrlxZ1dNXoiWg0Ee0homwimq6xvzsRrSOiciKaptrekYiWE1EWEe0koqlmFl545qqDzDHevPjjTry1ZC+KXXSwvrYgC6VlvrXJu/PIl1v9uliHvXL/47b8etuPlZbhZ2WbNzNlzWR2TvObZ6/DSz/t8vk6rn4smw8WA4DpE6UakgXb83H5i4vdJhIMBR4DPRFFApgFYAyAHgBuI6IeDoedBPAQgBkO26sAPMbMFwMYAOABjXNFEMzPrL9K0odrcvHWkn3o9dKvmscv31OEfyw0f/KKOoj85BCEHR0/U276WHPHGva5iqrapQI9mbvmALLyvVulSvN6qw8gefrPLj9sA83bz51gf2C6s2SXbRbvaZMqLS/9uAsl5ytx0mGgQKj9CPTU6PsByGbmHGaugG2R7/HqA5i5kJnTAVQ6bM9n5s3K49OwLUXYwZSSCydGfreWZB0z3GSgp7OyrLIaf/nPJlMnKNlnv54uq8LI/11h4DxjGMDD8zLx+3fX6h6z/7jGgvHe2nyoGIBtMfpA8FcweiSEl1GcuWwfAH3rO3ij3Id03v6kJ9B3AKCeQpcHL4I1ESUDuALABhf7JxFRBhFlFBXpT4Er6ngKbPs01pAFjDUZHDrhPoAv312IX3YU4FUvhozqYXYQdLz3nco6smWV1Zj43np8v8V9grodR8yr0et1wuDEMUdmNRG5apP/b6b2mrrF5yrw94W7XffFeFBZXaNrSc1gsP9MjSYXDBQ9gV7r18JQXYCImgL4FsDDjmvJ1l6QeQ4zpzFzWmKiucvWCdsfydX/1J5l+/ov+keSjPrnb16X4UuNvPK+fs13d/qqfb5VGNbuP1G7jFwgeerUHD5jhU/X/8RgWmpP7KObPL2VL/64C++u2I8lWcdwtPi87sXZn/xmG8oqq3HH+xtwyfOLfC2uqRpKB7SeUTd5ADqqnicB0P7I1kBE0bAF+c+Y+TtjxRNGaHUIHTpp+4p623vOY9P/vTLH0PWZfUvq9eS32522LdUx7T+70LvMls/+sLP2sb3Gpa61OAYmV4HqxJlytGrayKsyALbyZ+SewoR+nTT3uwoWWw8Xo1njaCS3tq0XfP3/rUZWfmm9RVzOV1SjoroGzRpHGy6X3pr9+cpq7C4oRfd2CdrXUf5/8Ist6NCiseYxZ8qr8L1S262uAQa9vgxA/XVYs/JL0b1dvNOw2C8zDuOKTs2xwcMC3cHkaShvsOmp0acDSCWiFCKKATABwHw9Fyfb3X8AIIuZ3/S+mEKPYo2Zqn/6KAOj3vzNlEk6X2boT4JlZk1nq0lDBMsqq7HGIe2CnpTFN/5rjU+ve+1bqzD9O+cPOVfsHzjjZ63BMFXtffuREqeVuq59ayUuf3GxT+VzSQles3/bj9FvrXKZuE1dJlcrjz3t4f5X7zuOMW+vwmcu0kCHeBx1aX/RGfyQGfzmHI81emauIqIpABYBiAQwl5l3EtFkZf9sImoHIANAAoAaInoYthE6lwH4A4DtRJSpXPJpZja+gKhoENTpgpdmHcPHJjcTODISAF78cScy3IyoyTxcjLYJzjX3wyd9WxbO6EpcRlqz1HmSZi3PRk7RWUwdmYpOZqT9cCiIbdGVaFe7XVyCQUT1MrJqVQIOnLB988zKLwUzY/Zv9b9tuvoA8JZZ1RBXPwP75lFv/gZmYHyv4I5B0TVhSgnMCxy2zVY9LoCtScfRaoRq8gfhFwt32hZPKTlfiXt8nG6/dv8JM4pUy77QuTvuOnsDtQjGvsLTuLh9vOHz7Lnb/5t5BPtfG2v4/OV7CnH3h+nY8uzVaNEkxvD5WpiN18bX55x0Sp9g1sQvI/mSjPQfubrFUBlmGTYzY7u3i8duH1cxEvqtz/G9PXWLMtzQn1wFIa0210AtgjF1XqZPyzt6u5bvv3+zJSHLKijFoC6tPR6v9bNz6vfQOs9D3c+fE/OMLNqd8tQCjLq4ra5jQySeuxQWuW4A4Icpg4NdBGESZkaulytSBdLMpft0HadV69M7IsUXzLbl+sp0jv3+2WFC2zkdqZnteYtchXZfFmwx6qgqyH+dcVjXGhHe5gaqqKrRHGUWLGET6BtFRQa7CMIkX2/Kw7AZK7B2v+t89vO3Og4Mcw415yvNHZOdPL1+6ug3f91r6vXNtjH3JKbOy3ROk6B88Di2k7/4Y/3jVu3zvJ7AjbOcO7LVbfSXv7g4YDNp1R9on204hJv+tRa/bM9HTtEZVFXX1E4IXLijAAdP6KtI2Euu9UHmOMrspR93YUaQlkYMm6YbYR3b8ooBAPsLz6BprPav8EOqNXhdmf7tdvz04JVmFq1BKVVq0/aMpuomlRNnyr3K3+JNyP5k3UGfEultzyvB9e+sxg8PDMblHZsbKttfPtsMAEht0xT7Cs8g9/VxmPyfTYiJNFgH1tEPMXeNbdH6add2M3ZtE4RNjV40LO5qeWuybZ206nHyeji2DRcGKS98qFqXU9f57aqd/+4PN3p1bXcdss/P32lofobjzOClu48p/3u/FOM+h476UE9SZpQEemGatFe0E6KZ7YCqfd5fM1eXBWj91lDkrla+fI/x2caXv7i4Xue8u85YPd8I7CO7/OFAgPp+tueV4LkfdgSs2UoCvTDN8ZBe6s/FH5SLmLPe5KGdALDFwALxgZhab29jN/OVtDqgHTtc3d3brqOlHocklle6qG17OFFPTNWbXuLL9EPYX3TG6+GTE99bj0/WHcTpAOXuCatA//L4S4JdBBEkX2w87LTgCABU+TCM0ajfuVggPlTGWuu1Pa8Ei/1Uq848XIz5W93PJP2nQye3q28IHyhpn/3hyW+3Y9zMVR7L4EplTWCbhsKqM7Znh2bBLoLQSd1e7E/5JWWeDwoznj54rn9ntV9f39NEOb214Hkb/Tu8sayyBt6kQDp5tgJlyrcSZqCgpAw5RWcwqKvnuQveCqsafagnHhJ1njPY0eotf/9KfLre9xQQ5VXV6P+a/9aZDfRCIZ5qv1o5m/TwfBf+uE/j1zzvMG9h9NsrMfH9DX7NiRNegT7YBRC6HTJx4RJ3bnLRnGKWZ/+7Q3O7kVEmR4vL/LoYyfI9Rfhpm+6EtD4zu/9B74e13pXDvFFy3vv+KfsH29R5mSaVxll4BXqJ9A2GL+mQzbC7wL8zU6d97X600KmzdYFDz8pejowulTfl87p5B/7uCD5qIA2BEfYmnxV7CnGs1LlJTitNtlEl5yuRU+ScM+mLjfozu9YToC9TYdVGb7TDRISv/X5aas5u8S73nZnqVZr0pFL4wqE92nlmcOh4bYH+hW6M2HTwFBbvLMCkTzehXUIs4l1MpvPFjbPWBGwIppnCqkYvRCjyVIP2tGg6ADxlIN+9Jw1tFNBvqhz49nTIBRo1el99tuGgU5BvKD+rsAr00nQjvGXmYueB8Mz32n0DVuTPtnc1f/xMA7UUYVg13Qjhrd+/a26nbVllDW6ZvQ59U1qYel0zzEs/hP/p09HzgaLB0FWjJ6LRRLSHiLKJaLrG/u5EtI6IyolompFzA0lq9MJbJ86aP+t3Y+5JzFq+3/Tr+mrB9gLc/VF6sIvh1tr9x/Hd5jzkl9Tv2FX/iZ8JwKxTvfXxs6qyBCMMeazRE1EkgFkAroZtofB0IprPzOqcpScBPATgRi/OFSLkBXqsuXBv4nsbPB4TiMlwpTrz6T/2lfYoq0D9Wump0fcDkM3MOcxcAWAegPHqA5i5kJnTATjetcdzAylCqvTCS14u2qTL8t3GE4WJ0OC4WLsre49pr27nzdBZb+gJ9B0AqAeJ5inb9NB9LhFNIqIMIsooKvLPL77EeRGKrJYSV7j3jmrt4fdXHwjIa+oJ9FrhUW/9Rve5zDyHmdOYOS0xMVHn5YUQok56bmBG4BilDnqfb6ib8zBnZf1VvGr89NVRT6DPA6Dugk8CoHc2hi/nmk4mTAlhbaE6UUzvJCszciNp0RPo0wGkElEKEcUAmABgvs7r+3Ku6Vo3jQnWSwshhEfb8kr8cl2PgZ6ZqwBMAbAIQBaAr5h5JxFNJqLJAEBE7YgoD8CjAP5KRHlElODqXL/ciQ6tmjZC5nNXB+vlhRDCrW835/nluromTDHzAgALHLbNVj0ugK1ZRte5wdQ8Tmr1QojwElYpEIQQIhyFZaCfPqZ7sIsghBABE5aB/obLLwh2EYQQImDCMtALIUQ4CctA36SRJO0UQoSPsAz0zRpHY8mjQ7H75dHBLooQQvhd2FZtu7aJD3YRhBAiIMKyRi+EEOFEAr0QQlicBHohhLA4CfRCCGFxYR/oO7ZsHOwiCCGEX4V9oI+LDtuBR0KIMBH2gf6Rqy8KdhGEEMKvwj7Qj+7ZDu2bxQa7GEII4Te6Aj0RjSaiPUSUTUTTNfYTEc1U9m8jot6qfY8Q0U4i2kFEXxBRyEXVYd3aBLsIQgjhNx4DPRFFApgFYAyAHgBuI6IeDoeNAZCq/JsE4F3l3A4AHgKQxsw9AUTCtpygEEKIANFTo+8HIJuZc5i5AsA8AOMdjhkP4BO2WQ+gORG1V/ZFAWhMRFEA4hDExcFdIVkzXAhhYXoCfQcAh1XP85RtHo9h5iMAZgA4BCAfQAkzL9Z6ESKaREQZRJRRVFSkt/ymaBITGdDXE0KIQNIT6LXqu6znGCJqAVttPwXABQCaENEdWi/CzHOYOY2Z0xITE3UUyzwy8kYIYWV6An0egI6q50lwbn5xdcwoAAeYuYiZKwF8B2CQ98X1j7gYGUsvhLAuPYE+HUAqEaUQUQxsnanzHY6ZD+BOZfTNANiaaPJha7IZQERxREQARgLIMrH8QgghPPAY6Jm5CsAUAItgC9JfMfNOIppMRJOVwxYAyAGQDeA9APcr524A8A2AzQC2K683x+ybMMMX9w0IdhGEEMIvdLVZMPMC2IK5etts1WMG8ICLc58H8LwPZQyIgV1aBbsIQgjhF2E/M1Yt9/VxMktWCGE5EugdyJB6IYTVSKB30E5q9EIIi5FA7+CypObBLoIQQphKAr0QQlicBHohhLA4CfQOWsTFBLsIQghhKpn77+Avw7qgZZNoLMkqxG97A5tcTQgh/EFq9A5ioiLwh4HJkrpYCGEZEuhdiJBIL4SwCAn0LvxhwIVO2y5LahaEkgghhG8k0LvQqqlzp+xbt/YKfEGEEMJHEuhdkIlTQgirkEDvxojubYJdBCGE8JkEejfemXhFsIsghBA+0xXoiWg0Ee0homwimq6xn4hoprJ/GxH1Vu1rTkTfENFuIsoiooFm3oA/xcVEYdsL19Q+JxmJI4RogDwGeiKKBDALwBgAPQDcRkQ9HA4bAyBV+TcJwLuqfW8DWMjM3QFcjga2lGBCbHSwiyCEED7RU6PvByCbmXOYuQLAPADjHY4ZD+ATtlkPoDkRtSeiBABDAXwAAMxcwczF5hU/sOJiIoNdBCGEMExPoO8A4LDqeZ6yTc8xnQEUAfiQiLYQ0ftE1ETrRYhoEhFlEFFGUVFoph5omxCLPhe2CHYxhBDCED2BXqthmnUeEwWgN4B3mfkKAGcBOLXxAwAzz2HmNGZOS0xM1FGs4BjYWdaWFUI0LHqSmuUB6Kh6ngTgqM5jGEAeM29Qtn8DF4E+lE2+qguOFp93e8wFzWJxtKQsQCUSQgj99NTo0wGkElEKEcUAmABgvsMx8wHcqYy+GQCghJnzmbkAwGEi6qYcNxLALrMKHyjTx3THzNvcD7UccbGMuRdChCaPNXpmriKiKQAWAYgEMJeZdxLRZGX/bAALAIwFkA3gHIC7VZd4EMBnyodEjsO+BsfVCEt2bMwSQogQoSsfPTMvgC2Yq7fNVj1mAA+4ODcTQJr3RQwtsdG2kTe9OjZH5uHi4BZGCCF0kIVHDLp3SApqahidWsVh6rzMYBdHCCE8kkBvUKOoSDw4MhUl5yrRsWVjHD55Hj07JAS7WEII4ZIEei81i4vGqidG1D5/5vvtmsfdkpaErzLyAlUsIYRwIknN/OyNmy/H9ZdfoLlveLfQnS8ghLAOCfQmmdi/k9O2NvGNAADsYkhOyyaN/FomIYQAJNCb5pILmqFvcv30CPdcmeL2HMfj7W5JSzKtXEIIIYHej7wdWh8ZIW+LEMI8ElFMFBlRfzaVvcXmL8O61Dbj1Nuv/H9rWkd0aN7Yz6UTQoQrCfQmevOWXprbL7mgGTY+M6p2Vm2ExuzaJ0Z3q30s65sIIcwkgd5EF+islac/MwrrnhpRb9v4Xo6Zn4UQwhwS6P2IHVrpr+3RDgDQIi4G7Zs1rm3acazBx0Tqf1taNYkBALRvFut9QYUQliYTpgLo7dt64eTZCkQ4tN04BvpeHZvrvqa9X+CSCxKQL2mShRAapEbvR4617EZRkWjfrK55x7HGb6cO/J6GWn52b39MvqoLWjeVMflCCG0S6P3oRpPa3Ue5yXWf2jYe08d0d/pWoDUbNzba89stK2gJYT0S6P2ITBg+QyD01rVObd1r9erYHP+nsVDKfUM61z7ul9JS8yqNZQF0ISxHAn0Q1WVGcGyzr/98kipA69G6qa2D9qs/D8SjV1+keczHd/fDwoeHqM6xNf20iIsx9FpCiNCnK9AT0Wgi2kNE2UTktOarsoTgTGX/NiLq7bA/koi2ENFPZhXcShwr/uqncY0iEeViFM7Kx4e7vW6/lJZ4aGQqxl7azmlfTFQEurerS6+c2qap7vICQNNGUXjzlssNnSOECA6PgZ6IIgHMAjAGQA8AtxFRD4fDxgBIVf5NAvCuw/6pALJ8Lm0D8NODV+o+Vk+KhGnX2CZSzfify5EQaxsk1TbBVvvu1Cqu9jh3rURvT7gCmc9dratZxn6dpBbu5wSsfWoEbuotOXmEaAj0DK/sByCbmXMAgIjmARiP+ot8jwfwibKk4Hoiak5E7Zk5n4iSAIwD8CqAR80tfujp2aGZ7mPtaREcg6o92I69tB2aNLK9RTf3ScLonu1w8kwF2iQ0QnWN/kw60ZERaB4Xg3uuTMEbC/doHuM4AqhvckvknTqieWxCbBQSYqM19w3vlojle4p0l00I4X96mm46ADisep6nbNN7zFsAngBQ4+5FiGgSEWUQUUZRUXgEimt6tMUHd6Xhz0O71G67tEMzELSr500bRaFTqzjERkfWfgDYqc9w1c7eKCpSM/2CFgLw9NjuGHdZe6d9Sx69qvbx/tfGomWT+q/34d198cL1jl/69GnVRPoIhDCbnhq9VmhwrE5qHkNE1wEoZOZNRDTM3Ysw8xwAcwAgLS3N28SPIeHTe/rh0MlzHo8jIoy8uG3t86WPXYU28Y1wrqIaAHDHgAsNv/bF7RPwwg2XGD7PEQOYNLQLjp8px8/b8uvta5NQNz8gMsL5Y2l4tzZAN+CFH3fBUVKLxsg7dd7l67ZsEoMTZyt8Kbopft87Cd9ulpXBhDXoqdHnAeioep4E4KjOYwYDuIGIcgHMAzCCiP7jdWkbiCGpibi9v/Eg3SWxKeJjo9E2IRa5r4/DoC6tdZ9rb+6Z2K+jU21fjxrl+1akQ2N/qyYxmHaN9sgdO/WnsrshpTmvjUXfZO1hnXXnu90dEJdckID/lY5mYSF6An06gFQiSiGiGAATAMx3OGY+gDuV0TcDAJQwcz4zP8XMScycrJy3jJnvMPMGhG9WPzkc658aiZHKpKyUxCb19hMRpoxIRbKq49eRpwVW7CIiCK/c2NNwGcde2g53DjT+wektSRktrMZjoGfmKgBTACyCbeTMV8y8k4gmE9Fk5bAFAHIAZAN4D8D9fiqv8MBom1dSizi0axaLSUM7Y8eL1yJRGU/vqmK9fNowp20DOruvpas1aRSFVU+4Hhaq1T/RqWUTPHtdD83XFkJ4pus7PjMvgC2Yq7fNVj1mAA94uMYKACsMl1Do4qoDV/f5RGjqRZMPoJ74pW3spe0wpmddp27Hlq6/HTSP0x7NEx0ZgZTWTTT3+cvF7RPQP6UlPlqb6/a4Phe2wKaDpwJTKCG8IDNjLeKKTs0BAKlt4n26jq+94FofN/+6vY9m7h0t9rbxW9Pquny0kr9NH9O93nNXM4B98cvUIbo6tms8fdJpSH9mlDdFEsIrEugt4qbeSVj1xHAM7OKfpGT2IZRResdnAnjvzjS8+jtjbfJJLeLw2+PD8LKqLT9aYw3dyVfVDUk1Uia7hNgo3NhL34ePKxP7d9Lc/uOUK/HZvf1dnrfy8eFI1Fha0h2jxwuhJoHeQtw1iejlKmTO/kMfvPq7npqv0UI19l09aubqHm11jT5yXGv3wlZNEBMVUZu1s2PLus7Ray9pC0e/TB3itE2Pl2/sieZx0ZgyvCtmTeyN512M/W8Upf1ncltfW6C/Ja1jve2XJjXD4K6uR0zZZzQvefQq3DnwQux48Vrcrnxo3D+si+Y5z17n3bwEIQBZeETo1CY+1mXQ7pLYFN9MHoivMg7jsWu6aR7jyXf3D3Jq67d/i1Bvf/f2Pk4NOalt4/HbXuOT7OJjo5H53DW1zxfuKNA8bsPTI1F8rhLDZqyot/3SpGbIfX0cmBkfr83F7oLTGNFdO6X0ooeH4tq3Vtbb1rVNU7w0vv43nvbNYnFZUjNsyyupt91VSor+KS3x7HU9cN3/rdbcLwQgNfqw46kJwNs2+rTklnjj5svRNkHfkob/ur13vVTKvTu1QB+HdMxaHcwREeT0DQAA7hyYjCdHd3fa7sjepHL/8K66ygkAzeNi0KllHC5qq534jYjwt5suBQDcO0R7qGm3du77TuoSmRLmT3HOl9Sldd1rD0ltjReVvoMOLRobSrshwpME+jDzzeRB+N//uVwzWNbj54lLYy9tjzE9nbNqqkVH2QoRoWMWVUxUBP6iavZQp2mwp20GgMFdWyP39XH12vj1iIggLH6k7prtHD7QrujUAgf+NtbjJDdPQ1H1/NhbxMV4NSnODLmvj/P63Jt6d6hNyCcCSwJ9mOnYMg6/7xNaWSfZxaiVx6/tjj8NTsGNVxhfqaurKu1yxl+v9rpsjuzLQ6560nkugKeFZna9dC0+vUe7k9bIwB0i1OYscpzJ7M76p0Zi49MjNff1aJ+guV3tOo28R0Z0axuPDU+PcjmEVgBXuunb8YW00Yt64pRUxq6yU5rJU2Bs1jgaz7lJjvbFfQNQdKbc5f5P7+mHs+VVXpdPy38fGIys/FJEu1gjwJ24GNd/blNGdEVO0RnXw1AdflTXXXYBMg8X4+FR+oeVNo6JRLPG9d/Xbm3jsefYaXz55wEoPF2OzEPFqKiuwdCLEjH0jeW1WVL11uR3vHgtej6/qPZ5QmwUSsvqvweZz12D5Ok/1z6fNbE3Dhw/gxmL96JD88Y4Uuw6F5IRc/+Yhj99lGHKtRo6CfSintGXtMNz1/XAbf20hw6GEk9DSYekJnp1XXeV67YJsbr7Ibq3i8fugtO6ju3QvDG+/PNAXccCtqYqx45cu1+mDsGYt1d5vMasib0xpmc7MGwjn+Jjo9Else6bUIfmjTWT83VqGee0PTqSkPXSaKdFcjY8PQoXP7cQgOs8RjFREZh8VRe0aBKDW9M6ouszv3gsu5Z/3HwZHv9mGwBg5m1X4NIOzb26jl6f3dsft7+/wdRr+ivXkzTdiHoiIgh/ujIloGvHNo4OjXVqR3Rvg1vSkvCyiwBq1MKHh5pyHcAWSN1RL+rerW1dx+/iR4YiXlmwxv4Jpu70dtW5DbgOOvOnDMbiR4Zi1RPDcVmSrSN4zfQRmiuh6fk9YmZERUbg9v4XIioyot5wWsBWMx96kecP7f4pdT+D631sZtLD3RBab/XzkPTPW1KjF0ETGUF4ZuzFGNbNu5q32WKiIvDGzaGXtfKugRfWa/bRir8f/6kfKqprnNJYXNQ23un4tyf0wks/7nI5FNST5nExaK6sefD5fQOw40gJ2sTr+5ajx6DOrfHlybrlLUZ0b4voyAis1BhC2ya+EQpP25rv1M1SROS0ToI31N8SAuEBA6PBjJAavQiq+4Z2Rmpb39I2qCW1aOw0TLOha6EjYMVERXjMVWRPJZHUIg5z7kwz5Vtb00ZRGNDZfROa0ZE2T4zWPxdj4zOj8NdxF+Pze/vXjtKy0/qmYrTG3C/FnBp2J52TGSO8mOWt67p+uaoQQbL6yRH49i+Dgl2MWi+PvwSLvGjCUQ/fdJxP0Ndg8PHU6e0v9oB9/WW2Dma9ifdaNTX2wXDvkM4Y5KIZ5YXre2BIat2+rybr7wdx5yoXTUnPuZjBvNJNxtZAkEAvhB/9YWCyx8lSWn6YMhi9lUR1dp2V7J0TdXSUf3R3X7x/Z5rh11Xz9ePh/mHmNUNEKfmOrroo0WMWU3Wfzx8Hp+DTe/pj3KXt8cFdabXXMKpjy8Z4eqznCXnurH9qJDb91XUyO/V8D7NJoBciBLVNiHUaU/3DlMFY/eRwXTX0Yd3aYFQPW16gZ6/rgUZREQGbZPXTg1di9h293R6T+/o4TFHao93N1rb3I/RPaYlHRl2EN2+53OW6BPaJdY6duQAw6/betct2fvjHvvj77y+tzR90q0OuIi0EwqShnifZqedvfHZvf7z6u564QJl70a5ZLFo1bVQ7w3r7C9fUfvjYX8VfdL3zRDQawNsAIgG8z8yvO+wnZf9YAOcA/JGZNxNRRwCfAGgH2+Lgc5j5bRPLL4RlDbkoETOXZeNKpekhPjYa8V7Mb7i5TxJu9mKSXNc28cg94XntY0c9OzSrl5bB3knq+EHz8KhUDO+eiCs6Ofep/Oee/qisqbGtPwxb2/XUUaluXzc2OhL//kOf2pTdrkREEG7t2wkfrTmgnBeBW9M64suMw87HKh8erj4k42Iia9d4BoChFyXWrk9wcfsEDO7a2ilHlHqGtXrN6LGXup8p7guPgZ6IIgHMAnA1bGvDphPRfGZWr/w8BkCq8q8/gHeV/6sAPKYE/XgAm4joV4dzhRAa+ia39CnlgK/emtALH6054PNM6j9f1QXxsVG4tW/9mnNUZAT6XKjd33BlqndDF6+9RH+wtA/ZvKFXB+wvPKMZ6Du2jMMzYy/GOIfhmva5FiseH4YTZyrqzVv44r4BOFp8Xveon72vjMGGAycw2MAa0UbpqdH3A5DNzDkAQETzAIwHoA7W4wF8oqw0tZ6ImhNRe2bOB5APAMx8moiyAHRwOFcIEYKaNorClBHua9F6xERF4I+D9a0rHEidE5vWfpDmHj/r8rj7hnaufdyscTRKzlfWpu1oEx/rNLQ0JioCyQZWQ4uJivB6cp9eetroOwBQf9TlKdsMHUNEyQCuAKA5lYyIJhFRBhFlFBUZTzkrhDta7bZC2N3Q6wJdie5mqjKuqt0/rIuufEHBoifQa/UQOM4Sd3sMETUF8C2Ah5m5VOtFmHkOM6cxc1piYmhMoBHW8eOUK7H4EfNmqorgMzM5WnRkhNPylEY8Mbo7Fni5AE4g6Gm6yQOgblxLAnBU7zFEFA1bkP+Mmb/zvqhCeE89m1M0fCumDXNK0GaGX6YOQXxsFIbPWIGkFs6TnIIzI8F3egJ9OoBUIkoBcATABAATHY6ZD2CK0n7fH0AJM+cro3E+AJDFzG+aWG4hRBgz0gZuxMVK88vul8doBnX7+sQxXmQvDSaPgZ6Zq4hoCoBFsA2vnMvMO4losrJ/NoAFsA2tzIZteOXdyumDAfwBwHYiylS2Pc3MC0y9CyGEMJGrRG8DOrfClOFdcdeg5MAWyEfkatGHYEpLS+OMDMkjLYQQehHRJmbWnA7dsL5/CCGEMEwCvRBCWJwEeiGEsDgJ9EIIYXES6IUQwuIk0AshhMVJoBdCCIuTQC+EEBYXkhOmiKgIwEEvT28N4LiJxQkVcl8Nj1XvTe4rNF3IzJoZIUMy0PuCiDJczQ5ryOS+Gh6r3pvcV8MjTTdCCGFxEuiFEMLirBjo5wS7AH4i99XwWPXe5L4aGMu10QshhKjPijV6IYQQKhLohRDC4iwT6IloNBHtIaJsIpoe7PLoQUS5RLSdiDKJKEPZ1pKIfiWifcr/LVTHP6Xc3x4iula1vY9ynWwimqks4Rjoe5lLRIVEtEO1zbR7IaJGRPSlsn0DESUH8b5eIKIjyvuWSURjG+B9dSSi5USURUQ7iWiqsr1Bv2du7qvBv2c+YeYG/w+2JQ73A+gMIAbAVgA9gl0uHeXOBdDaYdsbAKYrj6cD+LvyuIdyX40ApCj3G6ns2whgIGxrF/8CYEwQ7mUogN4AdvjjXgDcD2C28ngCgC+DeF8vAJimcWxDuq/2AHorj+MB7FXK36DfMzf31eDfM1/+WaVG3w9ANjPnMHMFgHkAxge5TN4aD+Bj5fHHAG5UbZ/HzOXMfAC29Xn7EVF7AAnMvI5tv3mfqM4JGGZeCeCkw2Yz70V9rW8AjAzENxcX9+VKQ7qvfGberDw+DSALQAc08PfMzX250iDuy1dWCfQdABxWPc+D+zc3VDCAxUS0iYgmKdvaMnM+YPulBdBG2e7qHjsojx23hwIz76X2HGauAlACoJXfSu7ZFCLapjTt2Js3GuR9KU0PVwDYAAu9Zw73BVjoPTPKKoFe69O0IYwbHczMvQGMAfAAEQ11c6yre2yI9+7NvYTSfb4LoAuAXgDyAfyvsr3B3RcRNQXwLYCHmbnU3aEa20L23jTuyzLvmTesEujzAHRUPU8CcDRIZdGNmY8q/xcC+B62JqhjytdGKP8XKoe7usc85bHj9lBg5r3UnkNEUQCaQX+TiqmY+RgzVzNzDYD3YHvf6pVREdL3RUTRsAXDz5j5O2Vzg3/PtO7LKu+Zt6wS6NMBpBJRChHFwNZBMj/IZXKLiJoQUbz9MYBrAOyArdx3KYfdBeAH5fF8ABOUHv8UAKkANipfr08T0QClnfBO1TnBZua9qK91M4BlSttpwNkDoeJ3sL1vQAO6L6UcHwDIYuY3Vbsa9Hvm6r6s8J75JNi9wWb9AzAWth72/QCeCXZ5dJS3M2y9/VsB7LSXGba2vqUA9in/t1Sd84xyf3ugGlkDIA22X9z9AN6BMuM5wPfzBWxfiSthq/HcY+a9AIgF8DVsnWUbAXQO4n19CmA7gG2w/dG3b4D3dSVszQ3bAGQq/8Y29PfMzX01+PfMl3+SAkEIISzOKk03QgghXJBAL4QQFieBXgghLE4CvRBCWJwEeiGEsDgJ9EIIYXES6IUQwuL+H+AULth9w9JBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "  \n",
      "kernel: 32\n",
      "  \n",
      "*********\n",
      "29459 3432\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29459 461\n",
      "Loss:  0.16905121505260468\n",
      "Loss:  0.16023720800876617\n",
      "Loss:  0.15403352677822113\n",
      "0 **********\n",
      "Epoch:  52.03786063194275  fold:  1  kers:  32\n",
      "epoch:  1\n",
      "29459 461\n",
      "Loss:  0.1476772427558899\n",
      "Loss:  0.11922048032283783\n",
      "Loss:  0.16323991119861603\n",
      "1 **********\n",
      "Epoch:  91.77760481834412  fold:  1  kers:  32\n",
      "epoch:  2\n",
      "29459 461\n",
      "Loss:  0.0996454581618309\n",
      "Loss:  0.1056632474064827\n",
      "Loss:  0.11052271723747253\n",
      "2 **********\n",
      "Epoch:  131.4783899784088  fold:  1  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.3752261698246002\n",
      "Eval Loss:  0.5860748291015625\n",
      "Eval Loss:  0.2623479962348938\n",
      "[[ 841  198]\n",
      " [ 754 1639]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.81      0.64      1039\n",
      "           1       0.89      0.68      0.77      2393\n",
      "\n",
      "    accuracy                           0.72      3432\n",
      "   macro avg       0.71      0.75      0.71      3432\n",
      "weighted avg       0.78      0.72      0.73      3432\n",
      "\n",
      "acc:  0.7226107226107226\n",
      "pre:  0.8922155688622755\n",
      "rec:  0.6849143334726285\n",
      "ma F1:  0.7067567058164644\n",
      "mi F1:  0.7226107226107226\n",
      "we F1:  0.7336568796753937\n",
      "update!  Acc:  0.7226107226107226\n",
      "Eval Loss:  0.420186847448349\n",
      "Eval Loss:  0.39155852794647217\n",
      "Eval Loss:  0.31945690512657166\n",
      "Eval Loss:  0.43981292843818665\n",
      "Eval Loss:  0.3392401337623596\n",
      "Eval Loss:  0.43638068437576294\n",
      "Eval Loss:  0.4499736726284027\n",
      "Eval Loss:  0.3900963068008423\n",
      "Eval Loss:  0.42601656913757324\n",
      "Eval Loss:  0.47818681597709656\n",
      "Eval Loss:  0.3968605399131775\n",
      "Eval Loss:  0.4819532334804535\n",
      "Eval Loss:  0.4717312753200531\n",
      "Eval Loss:  0.4506997764110565\n",
      "Eval Loss:  0.3030514717102051\n",
      "Eval Loss:  0.500100314617157\n",
      "Eval Loss:  0.3906930685043335\n",
      "Eval Loss:  0.5191274285316467\n",
      "Eval Loss:  0.4824213683605194\n",
      "Eval Loss:  0.45658931136131287\n",
      "Eval Loss:  0.4320606589317322\n",
      "Eval Loss:  0.39209261536598206\n",
      "Eval Loss:  0.36994847655296326\n",
      "Eval Loss:  0.4704056680202484\n",
      "Eval Loss:  0.4519895017147064\n",
      "Eval Loss:  0.4401592016220093\n",
      "Eval Loss:  0.2947686016559601\n",
      "Eval Loss:  0.4740866422653198\n",
      "[[16954  2171]\n",
      " [ 3352  6982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86     19125\n",
      "           1       0.76      0.68      0.72     10334\n",
      "\n",
      "    accuracy                           0.81     29459\n",
      "   macro avg       0.80      0.78      0.79     29459\n",
      "weighted avg       0.81      0.81      0.81     29459\n",
      "\n",
      "acc:  0.8125190943344988\n",
      "pre:  0.7628100076477657\n",
      "rec:  0.675633830075479\n",
      "ma F1:  0.7882564123395487\n",
      "mi F1:  0.8125190943344988\n",
      "we F1:  0.8096456258792205\n",
      "29459 461\n",
      "Loss:  0.1171465590596199\n",
      "Loss:  0.1250913292169571\n",
      "Loss:  0.0789259821176529\n",
      "3 **********\n",
      "Epoch:  209.8049612045288  fold:  1  kers:  32\n",
      "epoch:  4\n",
      "29459 461\n",
      "Loss:  0.10346566140651703\n",
      "Loss:  0.08573075383901596\n",
      "Loss:  0.07891976833343506\n",
      "4 **********\n",
      "Epoch:  249.18666219711304  fold:  1  kers:  32\n",
      "epoch:  5\n",
      "29459 461\n",
      "Loss:  0.08125723153352737\n",
      "Loss:  0.07535990327596664\n",
      "Loss:  0.08046333491802216\n",
      "5 **********\n",
      "Epoch:  290.085307598114  fold:  1  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.5368342995643616\n",
      "Eval Loss:  0.5224247574806213\n",
      "Eval Loss:  0.1719065010547638\n",
      "[[ 822  217]\n",
      " [ 509 1884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69      1039\n",
      "           1       0.90      0.79      0.84      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.76      0.79      0.77      3432\n",
      "weighted avg       0.81      0.79      0.79      3432\n",
      "\n",
      "acc:  0.7884615384615384\n",
      "pre:  0.8967158495954307\n",
      "rec:  0.7872962808190556\n",
      "ma F1:  0.7660610772168799\n",
      "mi F1:  0.7884615384615384\n",
      "we F1:  0.7946206106681677\n",
      "update!  Acc:  0.7884615384615384\n",
      "Eval Loss:  0.40592160820961\n",
      "Eval Loss:  0.29700779914855957\n",
      "Eval Loss:  0.266420841217041\n",
      "Eval Loss:  0.43443822860717773\n",
      "Eval Loss:  0.27690747380256653\n",
      "Eval Loss:  0.3941793739795685\n",
      "Eval Loss:  0.36713722348213196\n",
      "Eval Loss:  0.3191365897655487\n",
      "Eval Loss:  0.3163764774799347\n",
      "Eval Loss:  0.3777276873588562\n",
      "Eval Loss:  0.3078691065311432\n",
      "Eval Loss:  0.3316876292228699\n",
      "Eval Loss:  0.38799622654914856\n",
      "Eval Loss:  0.3747633695602417\n",
      "Eval Loss:  0.23010846972465515\n",
      "Eval Loss:  0.4675106108188629\n",
      "Eval Loss:  0.33907461166381836\n",
      "Eval Loss:  0.3919055759906769\n",
      "Eval Loss:  0.4196555018424988\n",
      "Eval Loss:  0.32162120938301086\n",
      "Eval Loss:  0.36507847905158997\n",
      "Eval Loss:  0.3463822305202484\n",
      "Eval Loss:  0.30561283230781555\n",
      "Eval Loss:  0.3614535331726074\n",
      "Eval Loss:  0.35014453530311584\n",
      "Eval Loss:  0.38942813873291016\n",
      "Eval Loss:  0.2826184630393982\n",
      "Eval Loss:  0.3649892807006836\n",
      "[[17735  1390]\n",
      " [ 2919  7415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89     19125\n",
      "           1       0.84      0.72      0.77     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.85      0.82      0.83     29459\n",
      "weighted avg       0.85      0.85      0.85     29459\n",
      "\n",
      "acc:  0.8537289113683424\n",
      "pre:  0.8421351504826803\n",
      "rec:  0.7175343526224115\n",
      "ma F1:  0.8332670666490933\n",
      "mi F1:  0.8537289113683425\n",
      "we F1:  0.8506973066613918\n",
      "29459 461\n",
      "Loss:  0.06508160382509232\n",
      "Loss:  0.11734221875667572\n",
      "Loss:  0.08245394378900528\n",
      "6 **********\n",
      "Epoch:  369.1608271598816  fold:  1  kers:  32\n",
      "epoch:  7\n",
      "29459 461\n",
      "Loss:  0.08326508104801178\n",
      "Loss:  0.0863615944981575\n",
      "Loss:  0.0643015056848526\n",
      "7 **********\n",
      "Epoch:  408.60137152671814  fold:  1  kers:  32\n",
      "epoch:  8\n",
      "29459 461\n",
      "Loss:  0.07607955485582352\n",
      "Loss:  0.10463763773441315\n",
      "Loss:  0.09541800618171692\n",
      "8 **********\n",
      "Epoch:  450.7746088504791  fold:  1  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.48040762543678284\n",
      "Eval Loss:  0.8769922256469727\n",
      "Eval Loss:  0.1707044392824173\n",
      "[[ 910  129]\n",
      " [ 803 1590]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.88      0.66      1039\n",
      "           1       0.92      0.66      0.77      2393\n",
      "\n",
      "    accuracy                           0.73      3432\n",
      "   macro avg       0.73      0.77      0.72      3432\n",
      "weighted avg       0.81      0.73      0.74      3432\n",
      "\n",
      "acc:  0.7284382284382285\n",
      "pre:  0.924956369982548\n",
      "rec:  0.6644379440033431\n",
      "ma F1:  0.7173417564021356\n",
      "mi F1:  0.7284382284382286\n",
      "we F1:  0.739436790426944\n",
      "Eval Loss:  0.43986639380455017\n",
      "Eval Loss:  0.31727370619773865\n",
      "Eval Loss:  0.2984484136104584\n",
      "Eval Loss:  0.4247806966304779\n",
      "Eval Loss:  0.323083758354187\n",
      "Eval Loss:  0.4375580847263336\n",
      "Eval Loss:  0.3745952546596527\n",
      "Eval Loss:  0.34508514404296875\n",
      "Eval Loss:  0.3764748275279999\n",
      "Eval Loss:  0.4119144082069397\n",
      "Eval Loss:  0.33226922154426575\n",
      "Eval Loss:  0.37377190589904785\n",
      "Eval Loss:  0.4113204777240753\n",
      "Eval Loss:  0.4385589063167572\n",
      "Eval Loss:  0.2196834236383438\n",
      "Eval Loss:  0.4885328412055969\n",
      "Eval Loss:  0.34125351905822754\n",
      "Eval Loss:  0.4350828230381012\n",
      "Eval Loss:  0.4782029986381531\n",
      "Eval Loss:  0.38020607829093933\n",
      "Eval Loss:  0.38885948061943054\n",
      "Eval Loss:  0.3917727470397949\n",
      "Eval Loss:  0.323294997215271\n",
      "Eval Loss:  0.38426709175109863\n",
      "Eval Loss:  0.37687692046165466\n",
      "Eval Loss:  0.42537617683410645\n",
      "Eval Loss:  0.2913418412208557\n",
      "Eval Loss:  0.4011612832546234\n",
      "[[18426   699]\n",
      " [ 3864  6470]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     19125\n",
      "           1       0.90      0.63      0.74     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.86      0.79      0.81     29459\n",
      "weighted avg       0.85      0.85      0.84     29459\n",
      "\n",
      "acc:  0.8451067585457754\n",
      "pre:  0.9024968614869577\n",
      "rec:  0.6260886394426166\n",
      "ma F1:  0.8145621810204295\n",
      "mi F1:  0.8451067585457754\n",
      "we F1:  0.8370209783627945\n",
      "29459 461\n",
      "Loss:  0.11622750759124756\n",
      "Loss:  0.08101337403059006\n",
      "Loss:  0.07611984014511108\n",
      "9 **********\n",
      "Epoch:  543.5395743846893  fold:  1  kers:  32\n",
      "epoch:  10\n",
      "29459 461\n",
      "Loss:  0.07712431997060776\n",
      "Loss:  0.10104003548622131\n",
      "Loss:  0.09873219579458237\n",
      "10 **********\n",
      "Epoch:  585.7257766723633  fold:  1  kers:  32\n",
      "epoch:  11\n",
      "29459 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.07223112136125565\n",
      "Loss:  0.07467764616012573\n",
      "Loss:  0.10059429705142975\n",
      "11 **********\n",
      "Epoch:  626.8050389289856  fold:  1  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.6734354496002197\n",
      "Eval Loss:  0.5892624258995056\n",
      "Eval Loss:  0.14825062453746796\n",
      "[[ 840  199]\n",
      " [ 479 1914]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.71      1039\n",
      "           1       0.91      0.80      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.77      0.80      0.78      3432\n",
      "weighted avg       0.82      0.80      0.81      3432\n",
      "\n",
      "acc:  0.8024475524475524\n",
      "pre:  0.9058211074301941\n",
      "rec:  0.7998328458002507\n",
      "ma F1:  0.7810010740556274\n",
      "mi F1:  0.8024475524475524\n",
      "we F1:  0.8080388131083897\n",
      "update!  Acc:  0.8024475524475524\n",
      "Eval Loss:  0.395538866519928\n",
      "Eval Loss:  0.28683826327323914\n",
      "Eval Loss:  0.2529892325401306\n",
      "Eval Loss:  0.40555840730667114\n",
      "Eval Loss:  0.2647058665752411\n",
      "Eval Loss:  0.379855215549469\n",
      "Eval Loss:  0.30699101090431213\n",
      "Eval Loss:  0.27406013011932373\n",
      "Eval Loss:  0.27300557494163513\n",
      "Eval Loss:  0.32585078477859497\n",
      "Eval Loss:  0.262678325176239\n",
      "Eval Loss:  0.3052119016647339\n",
      "Eval Loss:  0.3514196276664734\n",
      "Eval Loss:  0.32254526019096375\n",
      "Eval Loss:  0.19856560230255127\n",
      "Eval Loss:  0.41131338477134705\n",
      "Eval Loss:  0.3194413185119629\n",
      "Eval Loss:  0.3395810127258301\n",
      "Eval Loss:  0.40498030185699463\n",
      "Eval Loss:  0.27669063210487366\n",
      "Eval Loss:  0.33543339371681213\n",
      "Eval Loss:  0.3382643461227417\n",
      "Eval Loss:  0.27207401394844055\n",
      "Eval Loss:  0.2824399471282959\n",
      "Eval Loss:  0.29040852189064026\n",
      "Eval Loss:  0.3793271481990814\n",
      "Eval Loss:  0.27867481112480164\n",
      "Eval Loss:  0.3355758488178253\n",
      "[[17800  1325]\n",
      " [ 2585  7749]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     19125\n",
      "           1       0.85      0.75      0.80     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.86      0.84      0.85     29459\n",
      "weighted avg       0.87      0.87      0.87     29459\n",
      "\n",
      "acc:  0.8672731593061543\n",
      "pre:  0.8539783998236721\n",
      "rec:  0.7498548480743178\n",
      "ma F1:  0.8497871989371866\n",
      "mi F1:  0.8672731593061543\n",
      "we F1:  0.8650811077625368\n",
      "29459 461\n",
      "Loss:  0.09815781563520432\n",
      "Loss:  0.06485284864902496\n",
      "Loss:  0.07030492275953293\n",
      "12 **********\n",
      "Epoch:  707.995786190033  fold:  1  kers:  32\n",
      "epoch:  13\n",
      "29459 461\n",
      "Loss:  0.08318430930376053\n",
      "Loss:  0.07333890348672867\n",
      "Loss:  0.06260646879673004\n",
      "13 **********\n",
      "Epoch:  751.5642926692963  fold:  1  kers:  32\n",
      "epoch:  14\n",
      "29459 461\n",
      "Loss:  0.0858294814825058\n",
      "Loss:  0.09806807339191437\n",
      "Loss:  0.09762074053287506\n",
      "14 **********\n",
      "Epoch:  793.0703139305115  fold:  1  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.6526457667350769\n",
      "Eval Loss:  0.6702713370323181\n",
      "Eval Loss:  0.13297489285469055\n",
      "[[ 860  179]\n",
      " [ 525 1868]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71      1039\n",
      "           1       0.91      0.78      0.84      2393\n",
      "\n",
      "    accuracy                           0.79      3432\n",
      "   macro avg       0.77      0.80      0.78      3432\n",
      "weighted avg       0.82      0.79      0.80      3432\n",
      "\n",
      "acc:  0.7948717948717948\n",
      "pre:  0.9125549584758182\n",
      "rec:  0.7806101128290849\n",
      "ma F1:  0.7755061992685757\n",
      "mi F1:  0.7948717948717948\n",
      "we F1:  0.8015191124102016\n",
      "Eval Loss:  0.40352076292037964\n",
      "Eval Loss:  0.2728959023952484\n",
      "Eval Loss:  0.25227025151252747\n",
      "Eval Loss:  0.39244726300239563\n",
      "Eval Loss:  0.27910593152046204\n",
      "Eval Loss:  0.36695846915245056\n",
      "Eval Loss:  0.29582953453063965\n",
      "Eval Loss:  0.2975503206253052\n",
      "Eval Loss:  0.28185027837753296\n",
      "Eval Loss:  0.3125891089439392\n",
      "Eval Loss:  0.25936654210090637\n",
      "Eval Loss:  0.3094143867492676\n",
      "Eval Loss:  0.35814639925956726\n",
      "Eval Loss:  0.3281497061252594\n",
      "Eval Loss:  0.19026780128479004\n",
      "Eval Loss:  0.41779759526252747\n",
      "Eval Loss:  0.3078574240207672\n",
      "Eval Loss:  0.34361955523490906\n",
      "Eval Loss:  0.41363900899887085\n",
      "Eval Loss:  0.2888793647289276\n",
      "Eval Loss:  0.3343307077884674\n",
      "Eval Loss:  0.3547794818878174\n",
      "Eval Loss:  0.2763274908065796\n",
      "Eval Loss:  0.26805442571640015\n",
      "Eval Loss:  0.27776744961738586\n",
      "Eval Loss:  0.3800254166126251\n",
      "Eval Loss:  0.3039452135562897\n",
      "Eval Loss:  0.3363933265209198\n",
      "[[18026  1099]\n",
      " [ 2795  7539]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     19125\n",
      "           1       0.87      0.73      0.79     10334\n",
      "\n",
      "    accuracy                           0.87     29459\n",
      "   macro avg       0.87      0.84      0.85     29459\n",
      "weighted avg       0.87      0.87      0.86     29459\n",
      "\n",
      "acc:  0.867816287043009\n",
      "pre:  0.8727714748784441\n",
      "rec:  0.7295335784788078\n",
      "ma F1:  0.8486342789837755\n",
      "mi F1:  0.867816287043009\n",
      "we F1:  0.8647140952180389\n",
      "29459 461\n",
      "Loss:  0.07011359184980392\n",
      "Loss:  0.09855498373508453\n",
      "Loss:  0.04420573264360428\n",
      "15 **********\n",
      "Epoch:  871.8734841346741  fold:  1  kers:  32\n",
      "epoch:  16\n",
      "29459 461\n",
      "Loss:  0.08782363682985306\n",
      "Loss:  0.0696566253900528\n",
      "Loss:  0.11091210693120956\n",
      "16 **********\n",
      "Epoch:  911.3459432125092  fold:  1  kers:  32\n",
      "epoch:  17\n",
      "29459 461\n",
      "Loss:  0.09161248058080673\n",
      "Loss:  0.07396367192268372\n",
      "Loss:  0.05739663541316986\n",
      "17 **********\n",
      "Epoch:  951.7091312408447  fold:  1  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.5560429692268372\n",
      "Eval Loss:  0.8667566180229187\n",
      "Eval Loss:  0.09742844849824905\n",
      "[[ 919  120]\n",
      " [ 784 1609]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.88      0.67      1039\n",
      "           1       0.93      0.67      0.78      2393\n",
      "\n",
      "    accuracy                           0.74      3432\n",
      "   macro avg       0.74      0.78      0.73      3432\n",
      "weighted avg       0.81      0.74      0.75      3432\n",
      "\n",
      "acc:  0.7365967365967366\n",
      "pre:  0.9305957200694043\n",
      "rec:  0.6723777684914334\n",
      "ma F1:  0.7255013128041135\n",
      "mi F1:  0.7365967365967366\n",
      "we F1:  0.7472740719565941\n",
      "Eval Loss:  0.42199817299842834\n",
      "Eval Loss:  0.31597766280174255\n",
      "Eval Loss:  0.2766057848930359\n",
      "Eval Loss:  0.3781258463859558\n",
      "Eval Loss:  0.3397939205169678\n",
      "Eval Loss:  0.4152360260486603\n",
      "Eval Loss:  0.324062317609787\n",
      "Eval Loss:  0.3271254897117615\n",
      "Eval Loss:  0.3172462284564972\n",
      "Eval Loss:  0.39490607380867004\n",
      "Eval Loss:  0.28578585386276245\n",
      "Eval Loss:  0.338373064994812\n",
      "Eval Loss:  0.42887288331985474\n",
      "Eval Loss:  0.38752609491348267\n",
      "Eval Loss:  0.18248245120048523\n",
      "Eval Loss:  0.4618607759475708\n",
      "Eval Loss:  0.33304399251937866\n",
      "Eval Loss:  0.4196438491344452\n",
      "Eval Loss:  0.46567243337631226\n",
      "Eval Loss:  0.37179693579673767\n",
      "Eval Loss:  0.37454697489738464\n",
      "Eval Loss:  0.39205774664878845\n",
      "Eval Loss:  0.30367594957351685\n",
      "Eval Loss:  0.34323546290397644\n",
      "Eval Loss:  0.3343123495578766\n",
      "Eval Loss:  0.39730387926101685\n",
      "Eval Loss:  0.30944210290908813\n",
      "Eval Loss:  0.3651633858680725\n",
      "[[18543   582]\n",
      " [ 3612  6722]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     19125\n",
      "           1       0.92      0.65      0.76     10334\n",
      "\n",
      "    accuracy                           0.86     29459\n",
      "   macro avg       0.88      0.81      0.83     29459\n",
      "weighted avg       0.87      0.86      0.85     29459\n",
      "\n",
      "acc:  0.857632641976985\n",
      "pre:  0.9203176341730559\n",
      "rec:  0.6504741629572286\n",
      "ma F1:  0.8303095506662412\n",
      "mi F1:  0.8576326419769851\n",
      "we F1:  0.8506290917975116\n",
      "29459 461\n",
      "Loss:  0.07624448835849762\n",
      "Loss:  0.07087253034114838\n",
      "Loss:  0.060598812997341156\n",
      "18 **********\n",
      "Epoch:  1033.7527632713318  fold:  1  kers:  32\n",
      "epoch:  19\n",
      "29459 461\n",
      "Loss:  0.0945221334695816\n",
      "Loss:  0.08791797608137131\n",
      "Loss:  0.07802712172269821\n",
      "19 **********\n",
      "Epoch:  1074.7082571983337  fold:  1  kers:  32\n",
      "epoch:  20\n",
      "29459 461\n",
      "Loss:  0.06411292403936386\n",
      "Loss:  0.07353496551513672\n",
      "Loss:  0.06524015218019485\n",
      "20 **********\n",
      "Epoch:  1114.8471684455872  fold:  1  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.5915893912315369\n",
      "Eval Loss:  0.8994793891906738\n",
      "Eval Loss:  0.1099836453795433\n",
      "[[ 934  105]\n",
      " [ 809 1584]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.90      0.67      1039\n",
      "           1       0.94      0.66      0.78      2393\n",
      "\n",
      "    accuracy                           0.73      3432\n",
      "   macro avg       0.74      0.78      0.72      3432\n",
      "weighted avg       0.82      0.73      0.74      3432\n",
      "\n",
      "acc:  0.7336829836829837\n",
      "pre:  0.9378330373001776\n",
      "rec:  0.661930631007104\n",
      "ma F1:  0.7237747668130429\n",
      "mi F1:  0.7336829836829837\n",
      "we F1:  0.744414344723658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.40838614106178284\n",
      "Eval Loss:  0.33850938081741333\n",
      "Eval Loss:  0.2828342616558075\n",
      "Eval Loss:  0.36112433671951294\n",
      "Eval Loss:  0.34932947158813477\n",
      "Eval Loss:  0.4135601222515106\n",
      "Eval Loss:  0.32022982835769653\n",
      "Eval Loss:  0.3109372556209564\n",
      "Eval Loss:  0.3345527648925781\n",
      "Eval Loss:  0.3897168040275574\n",
      "Eval Loss:  0.286663293838501\n",
      "Eval Loss:  0.3527791500091553\n",
      "Eval Loss:  0.4280363917350769\n",
      "Eval Loss:  0.37086424231529236\n",
      "Eval Loss:  0.18696507811546326\n",
      "Eval Loss:  0.4517827033996582\n",
      "Eval Loss:  0.34405893087387085\n",
      "Eval Loss:  0.41181862354278564\n",
      "Eval Loss:  0.46128934621810913\n",
      "Eval Loss:  0.37478744983673096\n",
      "Eval Loss:  0.37578558921813965\n",
      "Eval Loss:  0.3886120319366455\n",
      "Eval Loss:  0.30345749855041504\n",
      "Eval Loss:  0.31762439012527466\n",
      "Eval Loss:  0.36165788769721985\n",
      "Eval Loss:  0.39526280760765076\n",
      "Eval Loss:  0.2903172969818115\n",
      "Eval Loss:  0.374378502368927\n",
      "[[18617   508]\n",
      " [ 3776  6558]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     19125\n",
      "           1       0.93      0.63      0.75     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.88      0.80      0.83     29459\n",
      "weighted avg       0.87      0.85      0.85     29459\n",
      "\n",
      "acc:  0.8545775484571778\n",
      "pre:  0.9281064251344466\n",
      "rec:  0.6346042190826399\n",
      "ma F1:  0.8253044711807591\n",
      "mi F1:  0.8545775484571778\n",
      "we F1:  0.8466445178129007\n",
      "29459 461\n",
      "Loss:  0.07238437235355377\n",
      "Loss:  0.07704310864210129\n",
      "Loss:  0.11257299035787582\n",
      "21 **********\n",
      "Epoch:  1193.2236053943634  fold:  1  kers:  32\n",
      "epoch:  22\n",
      "29459 461\n",
      "Loss:  0.0631532371044159\n",
      "Loss:  0.08524695783853531\n",
      "Loss:  0.06239025667309761\n",
      "22 **********\n",
      "Epoch:  1233.2445976734161  fold:  1  kers:  32\n",
      "epoch:  23\n",
      "29459 461\n",
      "Loss:  0.10120342671871185\n",
      "Loss:  0.08300326764583588\n",
      "Loss:  0.07075164467096329\n",
      "23 **********\n",
      "Epoch:  1272.8487040996552  fold:  1  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.6102340817451477\n",
      "Eval Loss:  1.1642677783966064\n",
      "Eval Loss:  0.14080370962619781\n",
      "[[ 954   85]\n",
      " [ 934 1459]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.92      0.65      1039\n",
      "           1       0.94      0.61      0.74      2393\n",
      "\n",
      "    accuracy                           0.70      3432\n",
      "   macro avg       0.73      0.76      0.70      3432\n",
      "weighted avg       0.81      0.70      0.71      3432\n",
      "\n",
      "acc:  0.703088578088578\n",
      "pre:  0.9449481865284974\n",
      "rec:  0.6096949435854576\n",
      "ma F1:  0.696517728532553\n",
      "mi F1:  0.703088578088578\n",
      "we F1:  0.7141354122926676\n",
      "Eval Loss:  0.42209210991859436\n",
      "Eval Loss:  0.35322168469429016\n",
      "Eval Loss:  0.30423256754875183\n",
      "Eval Loss:  0.36236098408699036\n",
      "Eval Loss:  0.3798060417175293\n",
      "Eval Loss:  0.4649951457977295\n",
      "Eval Loss:  0.346772700548172\n",
      "Eval Loss:  0.3233998119831085\n",
      "Eval Loss:  0.372320294380188\n",
      "Eval Loss:  0.4310401380062103\n",
      "Eval Loss:  0.3240995705127716\n",
      "Eval Loss:  0.37924596667289734\n",
      "Eval Loss:  0.4672066569328308\n",
      "Eval Loss:  0.4080861210823059\n",
      "Eval Loss:  0.1950196474790573\n",
      "Eval Loss:  0.47238728404045105\n",
      "Eval Loss:  0.33072102069854736\n",
      "Eval Loss:  0.46769535541534424\n",
      "Eval Loss:  0.4793749749660492\n",
      "Eval Loss:  0.41472065448760986\n",
      "Eval Loss:  0.39006662368774414\n",
      "Eval Loss:  0.3940667510032654\n",
      "Eval Loss:  0.3177311420440674\n",
      "Eval Loss:  0.35612818598747253\n",
      "Eval Loss:  0.3778873682022095\n",
      "Eval Loss:  0.397142618894577\n",
      "Eval Loss:  0.2922459542751312\n",
      "Eval Loss:  0.37148573994636536\n",
      "[[18754   371]\n",
      " [ 4155  6179]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89     19125\n",
      "           1       0.94      0.60      0.73     10334\n",
      "\n",
      "    accuracy                           0.85     29459\n",
      "   macro avg       0.88      0.79      0.81     29459\n",
      "weighted avg       0.86      0.85      0.84     29459\n",
      "\n",
      "acc:  0.8463627414372518\n",
      "pre:  0.9433587786259542\n",
      "rec:  0.5979291658602671\n",
      "ma F1:  0.8121304103985857\n",
      "mi F1:  0.8463627414372518\n",
      "we F1:  0.836061736216551\n",
      "29459 461\n",
      "Loss:  0.06919895857572556\n",
      "Loss:  0.07270117849111557\n",
      "Loss:  0.04727507755160332\n",
      "24 **********\n",
      "Epoch:  1350.9768052101135  fold:  1  kers:  32\n",
      "epoch:  25\n",
      "29459 461\n",
      "Loss:  0.0691574215888977\n",
      "Loss:  0.07213712483644485\n",
      "Loss:  0.04838811978697777\n",
      "25 **********\n",
      "Epoch:  1390.3974027633667  fold:  1  kers:  32\n",
      "epoch:  26\n",
      "29459 461\n",
      "Loss:  0.06934148818254471\n",
      "Loss:  0.07871516048908234\n",
      "Loss:  0.04157688096165657\n",
      "26 **********\n",
      "Epoch:  1429.8558993339539  fold:  1  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.9484938383102417\n",
      "Eval Loss:  0.590324878692627\n",
      "Eval Loss:  0.09490104019641876\n",
      "[[ 835  204]\n",
      " [ 457 1936]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72      1039\n",
      "           1       0.90      0.81      0.85      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.81      0.79      3432\n",
      "weighted avg       0.83      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8074009324009324\n",
      "pre:  0.9046728971962616\n",
      "rec:  0.8090263267864605\n",
      "ma F1:  0.785305585437948\n",
      "mi F1:  0.8074009324009324\n",
      "we F1:  0.8124782464623629\n",
      "update!  Acc:  0.8074009324009324\n",
      "Eval Loss:  0.31749165058135986\n",
      "Eval Loss:  0.2799991965293884\n",
      "Eval Loss:  0.24159076809883118\n",
      "Eval Loss:  0.3385738134384155\n",
      "Eval Loss:  0.27318742871284485\n",
      "Eval Loss:  0.34482717514038086\n",
      "Eval Loss:  0.26496875286102295\n",
      "Eval Loss:  0.2464977204799652\n",
      "Eval Loss:  0.2624187171459198\n",
      "Eval Loss:  0.29446324706077576\n",
      "Eval Loss:  0.23829281330108643\n",
      "Eval Loss:  0.28728359937667847\n",
      "Eval Loss:  0.3506832718849182\n",
      "Eval Loss:  0.29872027039527893\n",
      "Eval Loss:  0.1649051010608673\n",
      "Eval Loss:  0.39912593364715576\n",
      "Eval Loss:  0.283507376909256\n",
      "Eval Loss:  0.31694144010543823\n",
      "Eval Loss:  0.3711469769477844\n",
      "Eval Loss:  0.26035407185554504\n",
      "Eval Loss:  0.31590962409973145\n",
      "Eval Loss:  0.3263329267501831\n",
      "Eval Loss:  0.25771400332450867\n",
      "Eval Loss:  0.246290385723114\n",
      "Eval Loss:  0.2689511179924011\n",
      "Eval Loss:  0.36150455474853516\n",
      "Eval Loss:  0.26630550622940063\n",
      "Eval Loss:  0.2992117702960968\n",
      "[[18059  1066]\n",
      " [ 2519  7815]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     19125\n",
      "           1       0.88      0.76      0.81     10334\n",
      "\n",
      "    accuracy                           0.88     29459\n",
      "   macro avg       0.88      0.85      0.86     29459\n",
      "weighted avg       0.88      0.88      0.88     29459\n",
      "\n",
      "acc:  0.8783054414610136\n",
      "pre:  0.8799684720189168\n",
      "rec:  0.7562415328043353\n",
      "ma F1:  0.8615657832395387\n",
      "mi F1:  0.8783054414610135\n",
      "we F1:  0.8759311029803611\n",
      "29459 461\n",
      "Loss:  0.07481907308101654\n",
      "Loss:  0.07991752028465271\n",
      "Loss:  0.08902143687009811\n",
      "27 **********\n",
      "Epoch:  1507.9171788692474  fold:  1  kers:  32\n",
      "epoch:  28\n",
      "29459 461\n",
      "Loss:  0.07572092115879059\n",
      "Loss:  0.08944223076105118\n",
      "Loss:  0.09035895764827728\n",
      "28 **********\n",
      "Epoch:  1547.393626689911  fold:  1  kers:  32\n",
      "epoch:  29\n",
      "29459 461\n",
      "Loss:  0.07596640288829803\n",
      "Loss:  0.07544532418251038\n",
      "Loss:  0.06951875239610672\n",
      "29 **********\n",
      "Epoch:  1586.8531200885773  fold:  1  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.8697636127471924\n",
      "Eval Loss:  0.5596883296966553\n",
      "Eval Loss:  0.08255571126937866\n",
      "[[ 837  202]\n",
      " [ 446 1947]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72      1039\n",
      "           1       0.91      0.81      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.81      0.79      3432\n",
      "weighted avg       0.83      0.81      0.82      3432\n",
      "\n",
      "acc:  0.8111888111888111\n",
      "pre:  0.9060027919962773\n",
      "rec:  0.8136230672795653\n",
      "ma F1:  0.7891309022764277\n",
      "mi F1:  0.8111888111888111\n",
      "we F1:  0.8160375767515333\n",
      "update!  Acc:  0.8111888111888111\n",
      "Eval Loss:  0.3149890601634979\n",
      "Eval Loss:  0.2605865001678467\n",
      "Eval Loss:  0.22876699268817902\n",
      "Eval Loss:  0.30819299817085266\n",
      "Eval Loss:  0.24658334255218506\n",
      "Eval Loss:  0.3393942713737488\n",
      "Eval Loss:  0.25462988018989563\n",
      "Eval Loss:  0.23295094072818756\n",
      "Eval Loss:  0.2373686134815216\n",
      "Eval Loss:  0.2750796675682068\n",
      "Eval Loss:  0.22926129400730133\n",
      "Eval Loss:  0.27466315031051636\n",
      "Eval Loss:  0.32269003987312317\n",
      "Eval Loss:  0.2711285650730133\n",
      "Eval Loss:  0.1590447872877121\n",
      "Eval Loss:  0.3797125518321991\n",
      "Eval Loss:  0.2587934732437134\n",
      "Eval Loss:  0.3001894950866699\n",
      "Eval Loss:  0.3472276031970978\n",
      "Eval Loss:  0.25277310609817505\n",
      "Eval Loss:  0.3053608536720276\n",
      "Eval Loss:  0.30547624826431274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.23890666663646698\n",
      "Eval Loss:  0.22962749004364014\n",
      "Eval Loss:  0.24510259926319122\n",
      "Eval Loss:  0.35582536458969116\n",
      "Eval Loss:  0.23792248964309692\n",
      "Eval Loss:  0.2736618220806122\n",
      "[[18097  1028]\n",
      " [ 2338  7996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.91     19125\n",
      "           1       0.89      0.77      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.89      0.86      0.87     29459\n",
      "weighted avg       0.89      0.89      0.88     29459\n",
      "\n",
      "acc:  0.8857395023592111\n",
      "pre:  0.8860815602836879\n",
      "rec:  0.7737565318366557\n",
      "ma F1:  0.8705162276309161\n",
      "mi F1:  0.8857395023592112\n",
      "we F1:  0.8837651938853901\n",
      "29459 461\n",
      "Loss:  0.05865882709622383\n",
      "Loss:  0.06813722103834152\n",
      "Loss:  0.09212396293878555\n",
      "30 **********\n",
      "Epoch:  1665.1138665676117  fold:  1  kers:  32\n",
      "epoch:  31\n",
      "29459 461\n",
      "Loss:  0.06538484245538712\n",
      "Loss:  0.09393419325351715\n",
      "Loss:  0.09283647686243057\n",
      "31 **********\n",
      "Epoch:  1704.5773496627808  fold:  1  kers:  32\n",
      "epoch:  32\n",
      "29459 461\n",
      "Loss:  0.07608185708522797\n",
      "Loss:  0.05410723760724068\n",
      "Loss:  0.03698365017771721\n",
      "32 **********\n",
      "Epoch:  1744.0198888778687  fold:  1  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  1.3072855472564697\n",
      "Eval Loss:  0.47832855582237244\n",
      "Eval Loss:  0.09137026965618134\n",
      "[[ 782  257]\n",
      " [ 351 2042]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72      1039\n",
      "           1       0.89      0.85      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.80      0.80      3432\n",
      "weighted avg       0.83      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8228438228438228\n",
      "pre:  0.8882122662026968\n",
      "rec:  0.8533221897200167\n",
      "ma F1:  0.7952456985676807\n",
      "mi F1:  0.8228438228438228\n",
      "we F1:  0.824902730527916\n",
      "update!  Acc:  0.8228438228438228\n",
      "Eval Loss:  0.2972542941570282\n",
      "Eval Loss:  0.26240453124046326\n",
      "Eval Loss:  0.2333688884973526\n",
      "Eval Loss:  0.30349308252334595\n",
      "Eval Loss:  0.23181840777397156\n",
      "Eval Loss:  0.3272397816181183\n",
      "Eval Loss:  0.2539925277233124\n",
      "Eval Loss:  0.23719514906406403\n",
      "Eval Loss:  0.22380484640598297\n",
      "Eval Loss:  0.26711505651474\n",
      "Eval Loss:  0.22915443778038025\n",
      "Eval Loss:  0.26716524362564087\n",
      "Eval Loss:  0.32822659611701965\n",
      "Eval Loss:  0.26246052980422974\n",
      "Eval Loss:  0.1604563444852829\n",
      "Eval Loss:  0.37970444560050964\n",
      "Eval Loss:  0.24339710175991058\n",
      "Eval Loss:  0.2884666323661804\n",
      "Eval Loss:  0.34224024415016174\n",
      "Eval Loss:  0.23382574319839478\n",
      "Eval Loss:  0.29040953516960144\n",
      "Eval Loss:  0.2932848632335663\n",
      "Eval Loss:  0.2394530326128006\n",
      "Eval Loss:  0.22603723406791687\n",
      "Eval Loss:  0.22985921800136566\n",
      "Eval Loss:  0.3518648147583008\n",
      "Eval Loss:  0.2553196847438812\n",
      "Eval Loss:  0.26543128490448\n",
      "[[17845  1280]\n",
      " [ 2055  8279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     19125\n",
      "           1       0.87      0.80      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.88      0.87      0.87     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8867918123493669\n",
      "pre:  0.8660947797886809\n",
      "rec:  0.8011418618153667\n",
      "ma F1:  0.8734475246540807\n",
      "mi F1:  0.886791812349367\n",
      "we F1:  0.8857107102205934\n",
      "29459 461\n",
      "Loss:  0.08534127473831177\n",
      "Loss:  0.062061842530965805\n",
      "Loss:  0.050583623349666595\n",
      "33 **********\n",
      "Epoch:  1822.1679360866547  fold:  1  kers:  32\n",
      "epoch:  34\n",
      "29459 461\n",
      "Loss:  0.06548984348773956\n",
      "Loss:  0.08617570996284485\n",
      "Loss:  0.08662097156047821\n",
      "34 **********\n",
      "Epoch:  1861.6912586688995  fold:  1  kers:  32\n",
      "epoch:  35\n",
      "29459 461\n",
      "Loss:  0.08587805181741714\n",
      "Loss:  0.07311151176691055\n",
      "Loss:  0.07616854459047318\n",
      "35 **********\n",
      "Epoch:  1901.1856586933136  fold:  1  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  1.1641823053359985\n",
      "Eval Loss:  0.4872107207775116\n",
      "Eval Loss:  0.055602483451366425\n",
      "[[ 797  242]\n",
      " [ 448 1945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.77      0.70      1039\n",
      "           1       0.89      0.81      0.85      2393\n",
      "\n",
      "    accuracy                           0.80      3432\n",
      "   macro avg       0.76      0.79      0.77      3432\n",
      "weighted avg       0.81      0.80      0.80      3432\n",
      "\n",
      "acc:  0.798951048951049\n",
      "pre:  0.8893461362597165\n",
      "rec:  0.812787296280819\n",
      "ma F1:  0.7736217009919012\n",
      "mi F1:  0.798951048951049\n",
      "we F1:  0.8034962106928473\n",
      "Eval Loss:  0.31836196780204773\n",
      "Eval Loss:  0.2600077986717224\n",
      "Eval Loss:  0.2279217690229416\n",
      "Eval Loss:  0.3013816773891449\n",
      "Eval Loss:  0.2351173460483551\n",
      "Eval Loss:  0.33049896359443665\n",
      "Eval Loss:  0.2622884511947632\n",
      "Eval Loss:  0.2421276718378067\n",
      "Eval Loss:  0.21631933748722076\n",
      "Eval Loss:  0.2894851565361023\n",
      "Eval Loss:  0.21330802142620087\n",
      "Eval Loss:  0.2810389995574951\n",
      "Eval Loss:  0.3611307740211487\n",
      "Eval Loss:  0.2919345796108246\n",
      "Eval Loss:  0.1516755372285843\n",
      "Eval Loss:  0.3965092897415161\n",
      "Eval Loss:  0.25797393918037415\n",
      "Eval Loss:  0.3161718547344208\n",
      "Eval Loss:  0.3705282509326935\n",
      "Eval Loss:  0.24386706948280334\n",
      "Eval Loss:  0.3304668366909027\n",
      "Eval Loss:  0.31366369128227234\n",
      "Eval Loss:  0.2709195911884308\n",
      "Eval Loss:  0.24300390481948853\n",
      "Eval Loss:  0.2645515501499176\n",
      "Eval Loss:  0.34719318151474\n",
      "Eval Loss:  0.2621191143989563\n",
      "Eval Loss:  0.2656151354312897\n",
      "[[18176   949]\n",
      " [ 2399  7935]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92     19125\n",
      "           1       0.89      0.77      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.89      0.86      0.87     29459\n",
      "weighted avg       0.89      0.89      0.88     29459\n",
      "\n",
      "acc:  0.8863505210631726\n",
      "pre:  0.8931787483115714\n",
      "rec:  0.7678536868589123\n",
      "ma F1:  0.8707279148719989\n",
      "mi F1:  0.8863505210631726\n",
      "we F1:  0.8841385516288202\n",
      "29459 461\n",
      "Loss:  0.07806470990180969\n",
      "Loss:  0.07029330730438232\n",
      "Loss:  0.05115405470132828\n",
      "36 **********\n",
      "Epoch:  1979.2968051433563  fold:  1  kers:  32\n",
      "epoch:  37\n",
      "29459 461\n",
      "Loss:  0.050521016120910645\n",
      "Loss:  0.0559362918138504\n",
      "Loss:  0.05156080052256584\n",
      "37 **********\n",
      "Epoch:  2018.7413392066956  fold:  1  kers:  32\n",
      "epoch:  38\n",
      "29459 461\n",
      "Loss:  0.05113403871655464\n",
      "Loss:  0.05655156821012497\n",
      "Loss:  0.08793165534734726\n",
      "38 **********\n",
      "Epoch:  2058.1978402137756  fold:  1  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  1.1344250440597534\n",
      "Eval Loss:  0.38486677408218384\n",
      "Eval Loss:  0.06980666518211365\n",
      "[[ 798  241]\n",
      " [ 371 2022]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72      1039\n",
      "           1       0.89      0.84      0.87      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.79      0.81      0.80      3432\n",
      "weighted avg       0.83      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8216783216783217\n",
      "pre:  0.8935041979673001\n",
      "rec:  0.8449644797325533\n",
      "ma F1:  0.7956913939937248\n",
      "mi F1:  0.8216783216783218\n",
      "we F1:  0.8244383711873067\n",
      "Eval Loss:  0.299071729183197\n",
      "Eval Loss:  0.2571718692779541\n",
      "Eval Loss:  0.22418643534183502\n",
      "Eval Loss:  0.28309762477874756\n",
      "Eval Loss:  0.2214997559785843\n",
      "Eval Loss:  0.3189273774623871\n",
      "Eval Loss:  0.25027671456336975\n",
      "Eval Loss:  0.226997971534729\n",
      "Eval Loss:  0.22478531301021576\n",
      "Eval Loss:  0.263282835483551\n",
      "Eval Loss:  0.2181997448205948\n",
      "Eval Loss:  0.27042073011398315\n",
      "Eval Loss:  0.3335857093334198\n",
      "Eval Loss:  0.27706921100616455\n",
      "Eval Loss:  0.1526508331298828\n",
      "Eval Loss:  0.3766016960144043\n",
      "Eval Loss:  0.23794671893119812\n",
      "Eval Loss:  0.2973792254924774\n",
      "Eval Loss:  0.33073532581329346\n",
      "Eval Loss:  0.2335527241230011\n",
      "Eval Loss:  0.2911645472049713\n",
      "Eval Loss:  0.30470481514930725\n",
      "Eval Loss:  0.24976931512355804\n",
      "Eval Loss:  0.23269696533679962\n",
      "Eval Loss:  0.23840254545211792\n",
      "Eval Loss:  0.34134340286254883\n",
      "Eval Loss:  0.24967330694198608\n",
      "Eval Loss:  0.2690257728099823\n",
      "[[18121  1004]\n",
      " [ 2218  8116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     19125\n",
      "           1       0.89      0.79      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.89      0.87      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8906276519909027\n",
      "pre:  0.8899122807017544\n",
      "rec:  0.7853686858912329\n",
      "ma F1:  0.8763672519877805\n",
      "mi F1:  0.8906276519909027\n",
      "we F1:  0.8888973046042169\n",
      "29459 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05915338546037674\n",
      "Loss:  0.06453579664230347\n",
      "Loss:  0.08740328252315521\n",
      "39 **********\n",
      "Epoch:  2136.377802848816  fold:  1  kers:  32\n",
      "epoch:  40\n",
      "29459 461\n",
      "Loss:  0.08099815249443054\n",
      "Loss:  0.09387007355690002\n",
      "Loss:  0.07542243599891663\n",
      "40 **********\n",
      "Epoch:  2175.8313121795654  fold:  1  kers:  32\n",
      "epoch:  41\n",
      "29459 461\n",
      "Loss:  0.06705798208713531\n",
      "Loss:  0.09361652284860611\n",
      "Loss:  0.04430137574672699\n",
      "41 **********\n",
      "Epoch:  2215.3636107444763  fold:  1  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  1.2472889423370361\n",
      "Eval Loss:  0.4849618375301361\n",
      "Eval Loss:  0.09149271249771118\n",
      "[[ 836  203]\n",
      " [ 452 1941]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72      1039\n",
      "           1       0.91      0.81      0.86      2393\n",
      "\n",
      "    accuracy                           0.81      3432\n",
      "   macro avg       0.78      0.81      0.79      3432\n",
      "weighted avg       0.83      0.81      0.81      3432\n",
      "\n",
      "acc:  0.8091491841491841\n",
      "pre:  0.9053171641791045\n",
      "rec:  0.8111157542833264\n",
      "ma F1:  0.7870765881522873\n",
      "mi F1:  0.8091491841491842\n",
      "we F1:  0.8141230089484849\n",
      "Eval Loss:  0.3202945291996002\n",
      "Eval Loss:  0.2911093831062317\n",
      "Eval Loss:  0.23664329946041107\n",
      "Eval Loss:  0.2850571870803833\n",
      "Eval Loss:  0.24097596108913422\n",
      "Eval Loss:  0.34005090594291687\n",
      "Eval Loss:  0.26017847657203674\n",
      "Eval Loss:  0.2267579883337021\n",
      "Eval Loss:  0.2420981526374817\n",
      "Eval Loss:  0.2783799171447754\n",
      "Eval Loss:  0.22544485330581665\n",
      "Eval Loss:  0.29653143882751465\n",
      "Eval Loss:  0.34608423709869385\n",
      "Eval Loss:  0.2940404713153839\n",
      "Eval Loss:  0.15327012538909912\n",
      "Eval Loss:  0.3893064856529236\n",
      "Eval Loss:  0.24170812964439392\n",
      "Eval Loss:  0.30377426743507385\n",
      "Eval Loss:  0.3437431752681732\n",
      "Eval Loss:  0.25059330463409424\n",
      "Eval Loss:  0.2881990075111389\n",
      "Eval Loss:  0.30992382764816284\n",
      "Eval Loss:  0.2510931193828583\n",
      "Eval Loss:  0.23121462762355804\n",
      "Eval Loss:  0.2590390145778656\n",
      "Eval Loss:  0.3315715789794922\n",
      "Eval Loss:  0.2377128154039383\n",
      "Eval Loss:  0.27642354369163513\n",
      "[[18347   778]\n",
      " [ 2510  7824]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     19125\n",
      "           1       0.91      0.76      0.83     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.89      0.86      0.87     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8883872500763773\n",
      "pre:  0.9095559172285514\n",
      "rec:  0.7571124443584285\n",
      "ma F1:  0.8720627387520835\n",
      "mi F1:  0.8883872500763773\n",
      "we F1:  0.8857003686154178\n",
      "29459 461\n",
      "Loss:  0.052730266004800797\n",
      "Loss:  0.07031156867742538\n",
      "Loss:  0.060210276395082474\n",
      "42 **********\n",
      "Epoch:  2293.8597280979156  fold:  1  kers:  32\n",
      "epoch:  43\n",
      "29459 461\n",
      "Loss:  0.07052286714315414\n",
      "Loss:  0.06834305077791214\n",
      "Loss:  0.08736660331487656\n",
      "43 **********\n",
      "Epoch:  2333.219488143921  fold:  1  kers:  32\n",
      "epoch:  44\n",
      "29459 461\n",
      "Loss:  0.0754747986793518\n",
      "Loss:  0.06948753446340561\n",
      "Loss:  0.05919308587908745\n",
      "44 **********\n",
      "Epoch:  2375.170320749283  fold:  1  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  1.24844229221344\n",
      "Eval Loss:  0.4341273605823517\n",
      "Eval Loss:  0.08842767775058746\n",
      "[[ 829  210]\n",
      " [ 423 1970]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.72      1039\n",
      "           1       0.90      0.82      0.86      2393\n",
      "\n",
      "    accuracy                           0.82      3432\n",
      "   macro avg       0.78      0.81      0.79      3432\n",
      "weighted avg       0.83      0.82      0.82      3432\n",
      "\n",
      "acc:  0.8155594405594405\n",
      "pre:  0.9036697247706422\n",
      "rec:  0.8232344337651484\n",
      "ma F1:  0.792640136347718\n",
      "mi F1:  0.8155594405594405\n",
      "we F1:  0.8198379785060638\n",
      "Eval Loss:  0.28752779960632324\n",
      "Eval Loss:  0.2674827575683594\n",
      "Eval Loss:  0.2354818880558014\n",
      "Eval Loss:  0.2757505178451538\n",
      "Eval Loss:  0.2190784066915512\n",
      "Eval Loss:  0.3051723837852478\n",
      "Eval Loss:  0.24631479382514954\n",
      "Eval Loss:  0.21725192666053772\n",
      "Eval Loss:  0.22139482200145721\n",
      "Eval Loss:  0.2656638026237488\n",
      "Eval Loss:  0.2176869660615921\n",
      "Eval Loss:  0.2803778052330017\n",
      "Eval Loss:  0.32446929812431335\n",
      "Eval Loss:  0.27463820576667786\n",
      "Eval Loss:  0.1493144929409027\n",
      "Eval Loss:  0.35060185194015503\n",
      "Eval Loss:  0.2340480089187622\n",
      "Eval Loss:  0.27819085121154785\n",
      "Eval Loss:  0.31849315762519836\n",
      "Eval Loss:  0.23386621475219727\n",
      "Eval Loss:  0.2456369698047638\n",
      "Eval Loss:  0.28017935156822205\n",
      "Eval Loss:  0.24269434809684753\n",
      "Eval Loss:  0.22667266428470612\n",
      "Eval Loss:  0.2306874692440033\n",
      "Eval Loss:  0.3192247748374939\n",
      "Eval Loss:  0.2349260002374649\n",
      "Eval Loss:  0.2612760663032532\n",
      "[[18167   958]\n",
      " [ 2194  8140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     19125\n",
      "           1       0.89      0.79      0.84     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.89      0.87      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8930038358396415\n",
      "pre:  0.8947021323367773\n",
      "rec:  0.7876911167021482\n",
      "ma F1:  0.878983784779747\n",
      "mi F1:  0.8930038358396415\n",
      "we F1:  0.8912756237014119\n",
      "29459 461\n",
      "Loss:  0.05997887998819351\n",
      "Loss:  0.08832602202892303\n",
      "Loss:  0.08478491753339767\n",
      "45 **********\n",
      "Epoch:  2453.2874512672424  fold:  1  kers:  32\n",
      "epoch:  46\n",
      "29459 461\n",
      "Loss:  0.09683458507061005\n",
      "Loss:  0.04921721667051315\n",
      "Loss:  0.059419337660074234\n",
      "46 **********\n",
      "Epoch:  2492.787834405899  fold:  1  kers:  32\n",
      "epoch:  47\n",
      "29459 461\n",
      "Loss:  0.06585422158241272\n",
      "Loss:  0.06951266527175903\n",
      "Loss:  0.06036851555109024\n",
      "47 **********\n",
      "Epoch:  2532.3261172771454  fold:  1  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  1.5012719631195068\n",
      "Eval Loss:  0.31920021772384644\n",
      "Eval Loss:  0.08947546780109406\n",
      "[[ 772  267]\n",
      " [ 314 2079]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73      1039\n",
      "           1       0.89      0.87      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.81      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8307109557109557\n",
      "pre:  0.8861892583120204\n",
      "rec:  0.8687839531968241\n",
      "ma F1:  0.8019942653575463\n",
      "mi F1:  0.8307109557109557\n",
      "we F1:  0.8317436140480713\n",
      "update!  Acc:  0.8307109557109557\n",
      "Eval Loss:  0.2885902225971222\n",
      "Eval Loss:  0.2716030180454254\n",
      "Eval Loss:  0.23934267461299896\n",
      "Eval Loss:  0.2906809151172638\n",
      "Eval Loss:  0.21779124438762665\n",
      "Eval Loss:  0.3034340441226959\n",
      "Eval Loss:  0.25334790349006653\n",
      "Eval Loss:  0.2214348018169403\n",
      "Eval Loss:  0.196227565407753\n",
      "Eval Loss:  0.2634938657283783\n",
      "Eval Loss:  0.21611802279949188\n",
      "Eval Loss:  0.27419260144233704\n",
      "Eval Loss:  0.319130539894104\n",
      "Eval Loss:  0.2635249197483063\n",
      "Eval Loss:  0.14748568832874298\n",
      "Eval Loss:  0.37518998980522156\n",
      "Eval Loss:  0.22025629878044128\n",
      "Eval Loss:  0.2838229835033417\n",
      "Eval Loss:  0.31448331475257874\n",
      "Eval Loss:  0.21861690282821655\n",
      "Eval Loss:  0.2446223497390747\n",
      "Eval Loss:  0.28165116906166077\n",
      "Eval Loss:  0.2460435926914215\n",
      "Eval Loss:  0.23283949494361877\n",
      "Eval Loss:  0.22487813234329224\n",
      "Eval Loss:  0.3232705891132355\n",
      "Eval Loss:  0.24695105850696564\n",
      "Eval Loss:  0.2557295560836792\n",
      "[[18026  1099]\n",
      " [ 1998  8336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     19125\n",
      "           1       0.88      0.81      0.84     10334\n",
      "\n",
      "    accuracy                           0.89     29459\n",
      "   macro avg       0.89      0.87      0.88     29459\n",
      "weighted avg       0.89      0.89      0.89     29459\n",
      "\n",
      "acc:  0.8948708374350792\n",
      "pre:  0.8835188129305777\n",
      "rec:  0.8066576349912908\n",
      "ma F1:  0.8821162802743912\n",
      "mi F1:  0.8948708374350792\n",
      "we F1:  0.8936875199028338\n",
      "29459 461\n",
      "Loss:  0.06414077430963516\n",
      "Loss:  0.05228555202484131\n",
      "Loss:  0.03258812427520752\n",
      "48 **********\n",
      "Epoch:  2610.640720129013  fold:  1  kers:  32\n",
      "epoch:  49\n",
      "29459 461\n",
      "Loss:  0.07541720569133759\n",
      "Loss:  0.0394401028752327\n",
      "Loss:  0.07831896841526031\n",
      "49 **********\n",
      "Epoch:  2650.047354698181  fold:  1  kers:  32\n",
      "epoch:  50\n",
      "29459 461\n",
      "Loss:  0.041246939450502396\n",
      "Loss:  0.08272136747837067\n",
      "Loss:  0.07136927545070648\n",
      "50 **********\n",
      "Epoch:  2689.912762403488  fold:  1  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  1.3863521814346313\n",
      "Eval Loss:  0.29441729187965393\n",
      "Eval Loss:  0.059894464910030365\n",
      "[[ 762  277]\n",
      " [ 318 2075]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      1039\n",
      "           1       0.88      0.87      0.87      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.79      0.80      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8266317016317016\n",
      "pre:  0.8822278911564626\n",
      "rec:  0.8671124111993314\n",
      "ma F1:  0.7969060102012451\n",
      "mi F1:  0.8266317016317016\n",
      "we F1:  0.8275599220038636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.27749377489089966\n",
      "Eval Loss:  0.2684538662433624\n",
      "Eval Loss:  0.22361093759536743\n",
      "Eval Loss:  0.2663585841655731\n",
      "Eval Loss:  0.19265981018543243\n",
      "Eval Loss:  0.30672457814216614\n",
      "Eval Loss:  0.24780188500881195\n",
      "Eval Loss:  0.20648972690105438\n",
      "Eval Loss:  0.19194699823856354\n",
      "Eval Loss:  0.2604232728481293\n",
      "Eval Loss:  0.20687395334243774\n",
      "Eval Loss:  0.2625592350959778\n",
      "Eval Loss:  0.3143754005432129\n",
      "Eval Loss:  0.253058522939682\n",
      "Eval Loss:  0.13212813436985016\n",
      "Eval Loss:  0.35503071546554565\n",
      "Eval Loss:  0.2179740071296692\n",
      "Eval Loss:  0.27753257751464844\n",
      "Eval Loss:  0.3156399130821228\n",
      "Eval Loss:  0.19908641278743744\n",
      "Eval Loss:  0.25587642192840576\n",
      "Eval Loss:  0.28321754932403564\n",
      "Eval Loss:  0.25174760818481445\n",
      "Eval Loss:  0.2139127254486084\n",
      "Eval Loss:  0.2294805645942688\n",
      "Eval Loss:  0.31982967257499695\n",
      "Eval Loss:  0.23202940821647644\n",
      "Eval Loss:  0.24383831024169922\n",
      "[[18024  1101]\n",
      " [ 1862  8472]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     19125\n",
      "           1       0.88      0.82      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.8994195322312366\n",
      "pre:  0.8849890316515199\n",
      "rec:  0.819818076253145\n",
      "ma F1:  0.8876024739050323\n",
      "mi F1:  0.8994195322312366\n",
      "we F1:  0.898478076893481\n",
      "29459 461\n",
      "Loss:  0.05226835235953331\n",
      "Loss:  0.06554688513278961\n",
      "Loss:  0.07454332709312439\n",
      "51 **********\n",
      "Epoch:  2768.025904417038  fold:  1  kers:  32\n",
      "epoch:  52\n",
      "29459 461\n",
      "Loss:  0.06318224966526031\n",
      "Loss:  0.04115649685263634\n",
      "Loss:  0.062119822949171066\n",
      "52 **********\n",
      "Epoch:  2807.427551984787  fold:  1  kers:  32\n",
      "epoch:  53\n",
      "29459 461\n",
      "Loss:  0.07240724563598633\n",
      "Loss:  0.08947297930717468\n",
      "Loss:  0.07610998302698135\n",
      "53 **********\n",
      "Epoch:  2846.9289338588715  fold:  1  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  1.5182392597198486\n",
      "Eval Loss:  0.30405381321907043\n",
      "Eval Loss:  0.08541058748960495\n",
      "[[ 756  283]\n",
      " [ 282 2111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      1039\n",
      "           1       0.88      0.88      0.88      2393\n",
      "\n",
      "    accuracy                           0.84      3432\n",
      "   macro avg       0.81      0.80      0.80      3432\n",
      "weighted avg       0.84      0.84      0.84      3432\n",
      "\n",
      "acc:  0.8353729603729604\n",
      "pre:  0.8817878028404345\n",
      "rec:  0.8821562891767656\n",
      "ma F1:  0.804972522777998\n",
      "mi F1:  0.8353729603729604\n",
      "we F1:  0.8353505246256578\n",
      "update!  Acc:  0.8353729603729604\n",
      "Eval Loss:  0.27490511536598206\n",
      "Eval Loss:  0.2706483006477356\n",
      "Eval Loss:  0.22758552432060242\n",
      "Eval Loss:  0.2730931341648102\n",
      "Eval Loss:  0.19193442165851593\n",
      "Eval Loss:  0.30024150013923645\n",
      "Eval Loss:  0.25972867012023926\n",
      "Eval Loss:  0.21394489705562592\n",
      "Eval Loss:  0.1965164691209793\n",
      "Eval Loss:  0.2495286762714386\n",
      "Eval Loss:  0.21693848073482513\n",
      "Eval Loss:  0.2768571376800537\n",
      "Eval Loss:  0.31182190775871277\n",
      "Eval Loss:  0.2539527714252472\n",
      "Eval Loss:  0.14094533026218414\n",
      "Eval Loss:  0.34702810645103455\n",
      "Eval Loss:  0.20925752818584442\n",
      "Eval Loss:  0.2592816650867462\n",
      "Eval Loss:  0.3058023750782013\n",
      "Eval Loss:  0.19811183214187622\n",
      "Eval Loss:  0.24416236579418182\n",
      "Eval Loss:  0.2794509530067444\n",
      "Eval Loss:  0.24775026738643646\n",
      "Eval Loss:  0.21866944432258606\n",
      "Eval Loss:  0.2360335886478424\n",
      "Eval Loss:  0.3056132197380066\n",
      "Eval Loss:  0.24667641520500183\n",
      "Eval Loss:  0.24219588935375214\n",
      "[[17973  1152]\n",
      " [ 1829  8505]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     19125\n",
      "           1       0.88      0.82      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.89      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.8988085135272752\n",
      "pre:  0.880708294501398\n",
      "rec:  0.8230114186181536\n",
      "ma F1:  0.8871518296214004\n",
      "mi F1:  0.8988085135272752\n",
      "we F1:  0.8979750138436802\n",
      "29459 461\n",
      "Loss:  0.07084982097148895\n",
      "Loss:  0.05301974341273308\n",
      "Loss:  0.07749326527118683\n",
      "54 **********\n",
      "Epoch:  2925.430276632309  fold:  1  kers:  32\n",
      "epoch:  55\n",
      "29459 461\n",
      "Loss:  0.07890976965427399\n",
      "Loss:  0.07219158858060837\n",
      "Loss:  0.07727877795696259\n",
      "55 **********\n",
      "Epoch:  2964.9276688098907  fold:  1  kers:  32\n",
      "epoch:  56\n",
      "29459 461\n",
      "Loss:  0.08149833977222443\n",
      "Loss:  0.06330964714288712\n",
      "Loss:  0.0698087066411972\n",
      "56 **********\n",
      "Epoch:  3004.331311225891  fold:  1  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  1.424987554550171\n",
      "Eval Loss:  0.31232717633247375\n",
      "Eval Loss:  0.12799467146396637\n",
      "[[ 780  259]\n",
      " [ 322 2071]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      1039\n",
      "           1       0.89      0.87      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.81      0.80      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8307109557109557\n",
      "pre:  0.8888412017167382\n",
      "rec:  0.8654408692018387\n",
      "ma F1:  0.8028082238992051\n",
      "mi F1:  0.8307109557109557\n",
      "we F1:  0.832072591732753\n",
      "Eval Loss:  0.2956027090549469\n",
      "Eval Loss:  0.2827918827533722\n",
      "Eval Loss:  0.21836677193641663\n",
      "Eval Loss:  0.25952017307281494\n",
      "Eval Loss:  0.19530156254768372\n",
      "Eval Loss:  0.2985110580921173\n",
      "Eval Loss:  0.25182440876960754\n",
      "Eval Loss:  0.19892553985118866\n",
      "Eval Loss:  0.2075222283601761\n",
      "Eval Loss:  0.2514168620109558\n",
      "Eval Loss:  0.21832191944122314\n",
      "Eval Loss:  0.2902129292488098\n",
      "Eval Loss:  0.33154594898223877\n",
      "Eval Loss:  0.2704470157623291\n",
      "Eval Loss:  0.1302356868982315\n",
      "Eval Loss:  0.3372538387775421\n",
      "Eval Loss:  0.2023220807313919\n",
      "Eval Loss:  0.2705215513706207\n",
      "Eval Loss:  0.30531734228134155\n",
      "Eval Loss:  0.2067895382642746\n",
      "Eval Loss:  0.22106124460697174\n",
      "Eval Loss:  0.2911931276321411\n",
      "Eval Loss:  0.2469707876443863\n",
      "Eval Loss:  0.22105446457862854\n",
      "Eval Loss:  0.2457040250301361\n",
      "Eval Loss:  0.3075694441795349\n",
      "Eval Loss:  0.239375039935112\n",
      "Eval Loss:  0.25108087062835693\n",
      "[[18074  1051]\n",
      " [ 1933  8401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     19125\n",
      "           1       0.89      0.81      0.85     10334\n",
      "\n",
      "    accuracy                           0.90     29459\n",
      "   macro avg       0.90      0.88      0.89     29459\n",
      "weighted avg       0.90      0.90      0.90     29459\n",
      "\n",
      "acc:  0.898706677076615\n",
      "pre:  0.8888066017774016\n",
      "rec:  0.8129475517708535\n",
      "ma F1:  0.886465782875025\n",
      "mi F1:  0.898706677076615\n",
      "we F1:  0.8975905322729549\n",
      "29459 461\n",
      "Loss:  0.059796880930662155\n",
      "Loss:  0.07185438275337219\n",
      "Loss:  0.07358188927173615\n",
      "57 **********\n",
      "Epoch:  3082.533215522766  fold:  1  kers:  32\n",
      "epoch:  58\n",
      "29459 461\n",
      "Loss:  0.07994016259908676\n",
      "Loss:  0.12468378245830536\n",
      "Loss:  0.0836886540055275\n",
      "58 **********\n",
      "Epoch:  3122.0744898319244  fold:  1  kers:  32\n",
      "epoch:  59\n",
      "29459 461\n",
      "Loss:  0.07757709175348282\n",
      "Loss:  0.06060602888464928\n",
      "Loss:  0.07182714343070984\n",
      "59 **********\n",
      "Epoch:  3161.555924654007  fold:  1  kers:  32\n",
      "Eval Loss:  1.4871548414230347\n",
      "Eval Loss:  0.27548423409461975\n",
      "Eval Loss:  0.14515262842178345\n",
      "[[ 696  343]\n",
      " [ 241 2152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70      1039\n",
      "           1       0.86      0.90      0.88      2393\n",
      "\n",
      "    accuracy                           0.83      3432\n",
      "   macro avg       0.80      0.78      0.79      3432\n",
      "weighted avg       0.83      0.83      0.83      3432\n",
      "\n",
      "acc:  0.8298368298368298\n",
      "pre:  0.8625250501002004\n",
      "rec:  0.8992895946510656\n",
      "ma F1:  0.7924885864415541\n",
      "mi F1:  0.8298368298368298\n",
      "we F1:  0.8272204006978752\n",
      "update!  Acc:  0.8353729603729604\n",
      "Epoch:  3165.5941274166107  fold:  1  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29797 3094\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29797 466\n",
      "Loss:  0.1672477126121521\n",
      "Loss:  0.16493839025497437\n",
      "Loss:  0.15999853610992432\n",
      "0 **********\n",
      "Epoch:  52.59537076950073  fold:  2  kers:  32\n",
      "epoch:  1\n",
      "29797 466\n",
      "Loss:  0.13577903807163239\n",
      "Loss:  0.14645549654960632\n",
      "Loss:  0.11564867198467255\n",
      "1 **********\n",
      "Epoch:  92.64528465270996  fold:  2  kers:  32\n",
      "epoch:  2\n",
      "29797 466\n",
      "Loss:  0.10835767537355423\n",
      "Loss:  0.09904933720827103\n",
      "Loss:  0.09812802076339722\n",
      "2 **********\n",
      "Epoch:  132.66926908493042  fold:  2  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.9498158693313599\n",
      "Eval Loss:  0.1696321964263916\n",
      "Eval Loss:  0.6065100431442261\n",
      "[[1180  250]\n",
      " [ 647 1017]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.83      0.72      1430\n",
      "           1       0.80      0.61      0.69      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.72      0.72      0.71      3094\n",
      "weighted avg       0.73      0.71      0.71      3094\n",
      "\n",
      "acc:  0.7100840336134454\n",
      "pre:  0.8026835043409629\n",
      "rec:  0.6111778846153846\n",
      "ma F1:  0.7092771446681725\n",
      "mi F1:  0.7100840336134453\n",
      "we F1:  0.7081187887590075\n",
      "update!  Acc:  0.7100840336134454\n",
      "Eval Loss:  0.4695141017436981\n",
      "Eval Loss:  0.47494301199913025\n",
      "Eval Loss:  0.34361788630485535\n",
      "Eval Loss:  0.3110212981700897\n",
      "Eval Loss:  0.41690704226493835\n",
      "Eval Loss:  0.4040079116821289\n",
      "Eval Loss:  0.4794442057609558\n",
      "Eval Loss:  0.44124096632003784\n",
      "Eval Loss:  0.4596550762653351\n",
      "Eval Loss:  0.35632815957069397\n",
      "Eval Loss:  0.38718241453170776\n",
      "Eval Loss:  0.4547470211982727\n",
      "Eval Loss:  0.40232014656066895\n",
      "Eval Loss:  0.4903186559677124\n",
      "Eval Loss:  0.37441790103912354\n",
      "Eval Loss:  0.4263494312763214\n",
      "Eval Loss:  0.4475504457950592\n",
      "Eval Loss:  0.44878265261650085\n",
      "Eval Loss:  0.3833799362182617\n",
      "Eval Loss:  0.34222665429115295\n",
      "Eval Loss:  0.41068390011787415\n",
      "Eval Loss:  0.37373456358909607\n",
      "Eval Loss:  0.4664595425128937\n",
      "Eval Loss:  0.42390507459640503\n",
      "Eval Loss:  0.4168640375137329\n",
      "Eval Loss:  0.4881258010864258\n",
      "Eval Loss:  0.4295556843280792\n",
      "Eval Loss:  0.4034782350063324\n",
      "Eval Loss:  0.4842313528060913\n",
      "[[16030  2704]\n",
      " [ 2770  8293]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85     18734\n",
      "           1       0.75      0.75      0.75     11063\n",
      "\n",
      "    accuracy                           0.82     29797\n",
      "   macro avg       0.80      0.80      0.80     29797\n",
      "weighted avg       0.82      0.82      0.82     29797\n",
      "\n",
      "acc:  0.8162902305601235\n",
      "pre:  0.7541147585705192\n",
      "rec:  0.7496158365723583\n",
      "ma F1:  0.8030087317387087\n",
      "mi F1:  0.8162902305601235\n",
      "we F1:  0.8161769335558308\n",
      "29797 466\n",
      "Loss:  0.10743632912635803\n",
      "Loss:  0.09797179698944092\n",
      "Loss:  0.0761999785900116\n",
      "3 **********\n",
      "Epoch:  211.54237842559814  fold:  2  kers:  32\n",
      "epoch:  4\n",
      "29797 466\n",
      "Loss:  0.11485832929611206\n",
      "Loss:  0.08289123326539993\n",
      "Loss:  0.10659483820199966\n",
      "4 **********\n",
      "Epoch:  251.5873064994812  fold:  2  kers:  32\n",
      "epoch:  5\n",
      "29797 466\n",
      "Loss:  0.06274376809597015\n",
      "Loss:  0.08320862054824829\n",
      "Loss:  0.0583459734916687\n",
      "5 **********\n",
      "Epoch:  291.6541769504547  fold:  2  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.9070019125938416\n",
      "Eval Loss:  0.08502247184515\n",
      "Eval Loss:  0.7347524166107178\n",
      "[[1292  138]\n",
      " [ 784  880]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.90      0.74      1430\n",
      "           1       0.86      0.53      0.66      1664\n",
      "\n",
      "    accuracy                           0.70      3094\n",
      "   macro avg       0.74      0.72      0.70      3094\n",
      "weighted avg       0.75      0.70      0.69      3094\n",
      "\n",
      "acc:  0.7020038784744667\n",
      "pre:  0.8644400785854617\n",
      "rec:  0.5288461538461539\n",
      "ma F1:  0.6966244720353688\n",
      "mi F1:  0.7020038784744667\n",
      "we F1:  0.6935691780869491\n",
      "Eval Loss:  0.3946143388748169\n",
      "Eval Loss:  0.44251278042793274\n",
      "Eval Loss:  0.30452537536621094\n",
      "Eval Loss:  0.27971506118774414\n",
      "Eval Loss:  0.3614750802516937\n",
      "Eval Loss:  0.40506380796432495\n",
      "Eval Loss:  0.4788312017917633\n",
      "Eval Loss:  0.4127061069011688\n",
      "Eval Loss:  0.3648518919944763\n",
      "Eval Loss:  0.2572619318962097\n",
      "Eval Loss:  0.29598256945610046\n",
      "Eval Loss:  0.354452908039093\n",
      "Eval Loss:  0.42214322090148926\n",
      "Eval Loss:  0.4562724530696869\n",
      "Eval Loss:  0.34805160760879517\n",
      "Eval Loss:  0.39531397819519043\n",
      "Eval Loss:  0.31507593393325806\n",
      "Eval Loss:  0.3829098641872406\n",
      "Eval Loss:  0.3924124538898468\n",
      "Eval Loss:  0.27002835273742676\n",
      "Eval Loss:  0.36535409092903137\n",
      "Eval Loss:  0.31857094168663025\n",
      "Eval Loss:  0.4960949718952179\n",
      "Eval Loss:  0.33851510286331177\n",
      "Eval Loss:  0.3533506393432617\n",
      "Eval Loss:  0.4854062497615814\n",
      "Eval Loss:  0.35687509179115295\n",
      "Eval Loss:  0.349295049905777\n",
      "Eval Loss:  0.4791674017906189\n",
      "[[17590  1144]\n",
      " [ 3226  7837]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     18734\n",
      "           1       0.87      0.71      0.78     11063\n",
      "\n",
      "    accuracy                           0.85     29797\n",
      "   macro avg       0.86      0.82      0.84     29797\n",
      "weighted avg       0.86      0.85      0.85     29797\n",
      "\n",
      "acc:  0.8533409403631238\n",
      "pre:  0.8726199755038414\n",
      "rec:  0.7083973605712736\n",
      "ma F1:  0.835743299002624\n",
      "mi F1:  0.8533409403631238\n",
      "we F1:  0.849584322982568\n",
      "29797 466\n",
      "Loss:  0.08849786967039108\n",
      "Loss:  0.07034274935722351\n",
      "Loss:  0.09163054078817368\n",
      "6 **********\n",
      "Epoch:  370.5083358287811  fold:  2  kers:  32\n",
      "epoch:  7\n",
      "29797 466\n",
      "Loss:  0.07272177934646606\n",
      "Loss:  0.1040879338979721\n",
      "Loss:  0.11889256536960602\n",
      "7 **********\n",
      "Epoch:  410.60113525390625  fold:  2  kers:  32\n",
      "epoch:  8\n",
      "29797 466\n",
      "Loss:  0.09059404581785202\n",
      "Loss:  0.07707613706588745\n",
      "Loss:  0.08554880321025848\n",
      "8 **********\n",
      "Epoch:  450.6021807193756  fold:  2  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.652065634727478\n",
      "Eval Loss:  0.24596087634563446\n",
      "Eval Loss:  0.4671960771083832\n",
      "[[1225  205]\n",
      " [ 606 1058]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75      1430\n",
      "           1       0.84      0.64      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.75      0.75      0.74      3094\n",
      "weighted avg       0.76      0.74      0.74      3094\n",
      "\n",
      "acc:  0.737879767291532\n",
      "pre:  0.8376880443388757\n",
      "rec:  0.6358173076923077\n",
      "ma F1:  0.7371138886365739\n",
      "mi F1:  0.737879767291532\n",
      "we F1:  0.7360407412996866\n",
      "update!  Acc:  0.737879767291532\n",
      "Eval Loss:  0.31092125177383423\n",
      "Eval Loss:  0.32969701290130615\n",
      "Eval Loss:  0.2693776786327362\n",
      "Eval Loss:  0.27989572286605835\n",
      "Eval Loss:  0.3592190146446228\n",
      "Eval Loss:  0.29505467414855957\n",
      "Eval Loss:  0.3525029420852661\n",
      "Eval Loss:  0.3079560697078705\n",
      "Eval Loss:  0.30985772609710693\n",
      "Eval Loss:  0.2340623140335083\n",
      "Eval Loss:  0.24099311232566833\n",
      "Eval Loss:  0.24985098838806152\n",
      "Eval Loss:  0.3532218337059021\n",
      "Eval Loss:  0.4333434998989105\n",
      "Eval Loss:  0.28803572058677673\n",
      "Eval Loss:  0.3444563150405884\n",
      "Eval Loss:  0.2783954441547394\n",
      "Eval Loss:  0.26190218329429626\n",
      "Eval Loss:  0.35526055097579956\n",
      "Eval Loss:  0.2579061985015869\n",
      "Eval Loss:  0.29696834087371826\n",
      "Eval Loss:  0.3386077284812927\n",
      "Eval Loss:  0.47197115421295166\n",
      "Eval Loss:  0.2409650981426239\n",
      "Eval Loss:  0.30666252970695496\n",
      "Eval Loss:  0.3288372755050659\n",
      "Eval Loss:  0.2890223264694214\n",
      "Eval Loss:  0.27628037333488464\n",
      "Eval Loss:  0.35304945707321167\n",
      "[[16944  1790]\n",
      " [ 2050  9013]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90     18734\n",
      "           1       0.83      0.81      0.82     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.86      0.86      0.86     29797\n",
      "weighted avg       0.87      0.87      0.87     29797\n",
      "\n",
      "acc:  0.8711279659026077\n",
      "pre:  0.8343052855688234\n",
      "rec:  0.8146976407845973\n",
      "ma F1:  0.8613018596498823\n",
      "mi F1:  0.8711279659026077\n",
      "we F1:  0.8708058391057714\n",
      "29797 466\n",
      "Loss:  0.10511571913957596\n",
      "Loss:  0.12584912776947021\n",
      "Loss:  0.06774941086769104\n",
      "9 **********\n",
      "Epoch:  528.9008259773254  fold:  2  kers:  32\n",
      "epoch:  10\n",
      "29797 466\n",
      "Loss:  0.07111448049545288\n",
      "Loss:  0.052654583007097244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0750994086265564\n",
      "10 **********\n",
      "Epoch:  568.7024049758911  fold:  2  kers:  32\n",
      "epoch:  11\n",
      "29797 466\n",
      "Loss:  0.06765063107013702\n",
      "Loss:  0.08398441225290298\n",
      "Loss:  0.08959276974201202\n",
      "11 **********\n",
      "Epoch:  608.6057114601135  fold:  2  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.818426251411438\n",
      "Eval Loss:  0.17735761404037476\n",
      "Eval Loss:  0.8368601202964783\n",
      "[[1319  111]\n",
      " [ 793  871]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74      1430\n",
      "           1       0.89      0.52      0.66      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.76      0.72      0.70      3094\n",
      "weighted avg       0.77      0.71      0.70      3094\n",
      "\n",
      "acc:  0.7078215901745314\n",
      "pre:  0.8869653767820774\n",
      "rec:  0.5234375\n",
      "ma F1:  0.7015645959745338\n",
      "mi F1:  0.7078215901745314\n",
      "we F1:  0.6982964338254278\n",
      "Eval Loss:  0.3449804484844208\n",
      "Eval Loss:  0.3979390561580658\n",
      "Eval Loss:  0.26743224263191223\n",
      "Eval Loss:  0.23906366527080536\n",
      "Eval Loss:  0.3472248315811157\n",
      "Eval Loss:  0.3452604115009308\n",
      "Eval Loss:  0.42969048023223877\n",
      "Eval Loss:  0.35342341661453247\n",
      "Eval Loss:  0.297713041305542\n",
      "Eval Loss:  0.20756836235523224\n",
      "Eval Loss:  0.23615267872810364\n",
      "Eval Loss:  0.28260764479637146\n",
      "Eval Loss:  0.3840203583240509\n",
      "Eval Loss:  0.4100821018218994\n",
      "Eval Loss:  0.2859266400337219\n",
      "Eval Loss:  0.36686480045318604\n",
      "Eval Loss:  0.2541408836841583\n",
      "Eval Loss:  0.32962051033973694\n",
      "Eval Loss:  0.3316856920719147\n",
      "Eval Loss:  0.23428304493427277\n",
      "Eval Loss:  0.3054905831813812\n",
      "Eval Loss:  0.3012053668498993\n",
      "Eval Loss:  0.48895037174224854\n",
      "Eval Loss:  0.2858527600765228\n",
      "Eval Loss:  0.29600948095321655\n",
      "Eval Loss:  0.3726310729980469\n",
      "Eval Loss:  0.3000308573246002\n",
      "Eval Loss:  0.30227285623550415\n",
      "Eval Loss:  0.4475783705711365\n",
      "[[17812   922]\n",
      " [ 2950  8113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18734\n",
      "           1       0.90      0.73      0.81     11063\n",
      "\n",
      "    accuracy                           0.87     29797\n",
      "   macro avg       0.88      0.84      0.85     29797\n",
      "weighted avg       0.87      0.87      0.87     29797\n",
      "\n",
      "acc:  0.8700540322851293\n",
      "pre:  0.8979524073049253\n",
      "rec:  0.7333453855192985\n",
      "ma F1:  0.8546543851272174\n",
      "mi F1:  0.8700540322851293\n",
      "we F1:  0.8668340627587612\n",
      "29797 466\n",
      "Loss:  0.0701746791601181\n",
      "Loss:  0.10376585274934769\n",
      "Loss:  0.08497213572263718\n",
      "12 **********\n",
      "Epoch:  687.1457116603851  fold:  2  kers:  32\n",
      "epoch:  13\n",
      "29797 466\n",
      "Loss:  0.11341653019189835\n",
      "Loss:  0.06666291505098343\n",
      "Loss:  0.057036347687244415\n",
      "13 **********\n",
      "Epoch:  726.9492852687836  fold:  2  kers:  32\n",
      "epoch:  14\n",
      "29797 466\n",
      "Loss:  0.06625967472791672\n",
      "Loss:  0.08051585406064987\n",
      "Loss:  0.12912459671497345\n",
      "14 **********\n",
      "Epoch:  766.8117008209229  fold:  2  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.5006260275840759\n",
      "Eval Loss:  0.2415565401315689\n",
      "Eval Loss:  0.565769374370575\n",
      "[[1292  138]\n",
      " [ 660 1004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      1430\n",
      "           1       0.88      0.60      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.77      0.75      0.74      3094\n",
      "weighted avg       0.78      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7420814479638009\n",
      "pre:  0.8791593695271454\n",
      "rec:  0.6033653846153846\n",
      "ma F1:  0.7398271761153867\n",
      "mi F1:  0.7420814479638009\n",
      "we F1:  0.7379955802385504\n",
      "update!  Acc:  0.7420814479638009\n",
      "Eval Loss:  0.29012835025787354\n",
      "Eval Loss:  0.3535565137863159\n",
      "Eval Loss:  0.23509474098682404\n",
      "Eval Loss:  0.23512274026870728\n",
      "Eval Loss:  0.33275556564331055\n",
      "Eval Loss:  0.2739117741584778\n",
      "Eval Loss:  0.37194645404815674\n",
      "Eval Loss:  0.30807921290397644\n",
      "Eval Loss:  0.260683536529541\n",
      "Eval Loss:  0.17577813565731049\n",
      "Eval Loss:  0.19702807068824768\n",
      "Eval Loss:  0.2357722371816635\n",
      "Eval Loss:  0.3448166251182556\n",
      "Eval Loss:  0.38844063878059387\n",
      "Eval Loss:  0.27079281210899353\n",
      "Eval Loss:  0.3279188871383667\n",
      "Eval Loss:  0.23993656039237976\n",
      "Eval Loss:  0.25889089703559875\n",
      "Eval Loss:  0.2860910892486572\n",
      "Eval Loss:  0.22930659353733063\n",
      "Eval Loss:  0.2557370066642761\n",
      "Eval Loss:  0.27300676703453064\n",
      "Eval Loss:  0.4397236704826355\n",
      "Eval Loss:  0.23246528208255768\n",
      "Eval Loss:  0.28957268595695496\n",
      "Eval Loss:  0.2805493474006653\n",
      "Eval Loss:  0.2587723731994629\n",
      "Eval Loss:  0.25355735421180725\n",
      "Eval Loss:  0.3722689151763916\n",
      "[[17608  1126]\n",
      " [ 2389  8674]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18734\n",
      "           1       0.89      0.78      0.83     11063\n",
      "\n",
      "    accuracy                           0.88     29797\n",
      "   macro avg       0.88      0.86      0.87     29797\n",
      "weighted avg       0.88      0.88      0.88     29797\n",
      "\n",
      "acc:  0.8820351042051213\n",
      "pre:  0.8851020408163265\n",
      "rec:  0.7840549579680014\n",
      "ma F1:  0.8703828696994373\n",
      "mi F1:  0.8820351042051213\n",
      "we F1:  0.8803878272652647\n",
      "29797 466\n",
      "Loss:  0.08862222731113434\n",
      "Loss:  0.079109326004982\n",
      "Loss:  0.06582124531269073\n",
      "15 **********\n",
      "Epoch:  845.5032958984375  fold:  2  kers:  32\n",
      "epoch:  16\n",
      "29797 466\n",
      "Loss:  0.06398380547761917\n",
      "Loss:  0.08967114984989166\n",
      "Loss:  0.07652833312749863\n",
      "16 **********\n",
      "Epoch:  885.3806717395782  fold:  2  kers:  32\n",
      "epoch:  17\n",
      "29797 466\n",
      "Loss:  0.09773551672697067\n",
      "Loss:  0.08585946261882782\n",
      "Loss:  0.08685383945703506\n",
      "17 **********\n",
      "Epoch:  925.2610392570496  fold:  2  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.40539002418518066\n",
      "Eval Loss:  0.35784727334976196\n",
      "Eval Loss:  0.3731178045272827\n",
      "[[1249  181]\n",
      " [ 559 1105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77      1430\n",
      "           1       0.86      0.66      0.75      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.78      0.77      0.76      3094\n",
      "weighted avg       0.78      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7608274078862314\n",
      "pre:  0.859253499222395\n",
      "rec:  0.6640625\n",
      "ma F1:  0.7603082044785963\n",
      "mi F1:  0.7608274078862314\n",
      "we F1:  0.7594644989411893\n",
      "update!  Acc:  0.7608274078862314\n",
      "Eval Loss:  0.27071526646614075\n",
      "Eval Loss:  0.32207217812538147\n",
      "Eval Loss:  0.23099669814109802\n",
      "Eval Loss:  0.24891988933086395\n",
      "Eval Loss:  0.3346323072910309\n",
      "Eval Loss:  0.23264160752296448\n",
      "Eval Loss:  0.3317209780216217\n",
      "Eval Loss:  0.26944610476493835\n",
      "Eval Loss:  0.2497982233762741\n",
      "Eval Loss:  0.1746256798505783\n",
      "Eval Loss:  0.17271704971790314\n",
      "Eval Loss:  0.22191250324249268\n",
      "Eval Loss:  0.32921019196510315\n",
      "Eval Loss:  0.3926190733909607\n",
      "Eval Loss:  0.27656257152557373\n",
      "Eval Loss:  0.30644017457962036\n",
      "Eval Loss:  0.2274063676595688\n",
      "Eval Loss:  0.21408313512802124\n",
      "Eval Loss:  0.267498254776001\n",
      "Eval Loss:  0.2182314693927765\n",
      "Eval Loss:  0.2404516637325287\n",
      "Eval Loss:  0.2736087143421173\n",
      "Eval Loss:  0.4156225323677063\n",
      "Eval Loss:  0.20622830092906952\n",
      "Eval Loss:  0.27316761016845703\n",
      "Eval Loss:  0.2537541687488556\n",
      "Eval Loss:  0.24661824107170105\n",
      "Eval Loss:  0.23596058785915375\n",
      "Eval Loss:  0.32439032196998596\n",
      "[[17319  1415]\n",
      " [ 1937  9126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     18734\n",
      "           1       0.87      0.82      0.84     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.88      0.87      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8875054535691512\n",
      "pre:  0.8657622616450052\n",
      "rec:  0.8249118683901293\n",
      "ma F1:  0.8783049008843233\n",
      "mi F1:  0.8875054535691512\n",
      "we F1:  0.886919259439836\n",
      "29797 466\n",
      "Loss:  0.07323740422725677\n",
      "Loss:  0.041764192283153534\n",
      "Loss:  0.06004594266414642\n",
      "18 **********\n",
      "Epoch:  1003.9486448764801  fold:  2  kers:  32\n",
      "epoch:  19\n",
      "29797 466\n",
      "Loss:  0.0778079628944397\n",
      "Loss:  0.0711590126156807\n",
      "Loss:  0.07564949989318848\n",
      "19 **********\n",
      "Epoch:  1043.870901107788  fold:  2  kers:  32\n",
      "epoch:  20\n",
      "29797 466\n",
      "Loss:  0.0496797189116478\n",
      "Loss:  0.07715357095003128\n",
      "Loss:  0.06832970678806305\n",
      "20 **********\n",
      "Epoch:  1083.7642340660095  fold:  2  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.5446426868438721\n",
      "Eval Loss:  0.25504016876220703\n",
      "Eval Loss:  0.7626004815101624\n",
      "[[1308  122]\n",
      " [ 737  927]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75      1430\n",
      "           1       0.88      0.56      0.68      1664\n",
      "\n",
      "    accuracy                           0.72      3094\n",
      "   macro avg       0.76      0.74      0.72      3094\n",
      "weighted avg       0.77      0.72      0.72      3094\n",
      "\n",
      "acc:  0.7223658694246929\n",
      "pre:  0.8836987607244995\n",
      "rec:  0.5570913461538461\n",
      "ma F1:  0.7180910457774583\n",
      "mi F1:  0.7223658694246929\n",
      "we F1:  0.7154655635374246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3142419457435608\n",
      "Eval Loss:  0.3639634847640991\n",
      "Eval Loss:  0.2606004774570465\n",
      "Eval Loss:  0.2064504325389862\n",
      "Eval Loss:  0.30991873145103455\n",
      "Eval Loss:  0.27011245489120483\n",
      "Eval Loss:  0.38752442598342896\n",
      "Eval Loss:  0.29574453830718994\n",
      "Eval Loss:  0.2683022618293762\n",
      "Eval Loss:  0.16620662808418274\n",
      "Eval Loss:  0.18771789968013763\n",
      "Eval Loss:  0.22758837044239044\n",
      "Eval Loss:  0.32727178931236267\n",
      "Eval Loss:  0.37727969884872437\n",
      "Eval Loss:  0.2652219533920288\n",
      "Eval Loss:  0.3128533959388733\n",
      "Eval Loss:  0.22758722305297852\n",
      "Eval Loss:  0.2738991677761078\n",
      "Eval Loss:  0.26467758417129517\n",
      "Eval Loss:  0.21825405955314636\n",
      "Eval Loss:  0.22709017992019653\n",
      "Eval Loss:  0.25748175382614136\n",
      "Eval Loss:  0.40087199211120605\n",
      "Eval Loss:  0.24064795672893524\n",
      "Eval Loss:  0.27684828639030457\n",
      "Eval Loss:  0.27603453397750854\n",
      "Eval Loss:  0.26441988348960876\n",
      "Eval Loss:  0.2605656087398529\n",
      "Eval Loss:  0.3959597647190094\n",
      "[[17848   886]\n",
      " [ 2537  8526]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18734\n",
      "           1       0.91      0.77      0.83     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.89      0.86      0.87     29797\n",
      "weighted avg       0.89      0.89      0.88     29797\n",
      "\n",
      "acc:  0.8851226633553714\n",
      "pre:  0.9058648533786655\n",
      "rec:  0.7706770315465967\n",
      "ma F1:  0.8726591380278848\n",
      "mi F1:  0.8851226633553714\n",
      "we F1:  0.8829152743491839\n",
      "29797 466\n",
      "Loss:  0.08810998499393463\n",
      "Loss:  0.07932842522859573\n",
      "Loss:  0.03775415197014809\n",
      "21 **********\n",
      "Epoch:  1162.3122129440308  fold:  2  kers:  32\n",
      "epoch:  22\n",
      "29797 466\n",
      "Loss:  0.07923606038093567\n",
      "Loss:  0.10325537621974945\n",
      "Loss:  0.07207195460796356\n",
      "22 **********\n",
      "Epoch:  1202.171637058258  fold:  2  kers:  32\n",
      "epoch:  23\n",
      "29797 466\n",
      "Loss:  0.043487582355737686\n",
      "Loss:  0.054464660584926605\n",
      "Loss:  0.06613633036613464\n",
      "23 **********\n",
      "Epoch:  1241.9442932605743  fold:  2  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.6484977602958679\n",
      "Eval Loss:  0.25295063853263855\n",
      "Eval Loss:  0.8711947798728943\n",
      "[[1326  104]\n",
      " [ 778  886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.93      0.75      1430\n",
      "           1       0.89      0.53      0.67      1664\n",
      "\n",
      "    accuracy                           0.71      3094\n",
      "   macro avg       0.76      0.73      0.71      3094\n",
      "weighted avg       0.77      0.71      0.71      3094\n",
      "\n",
      "acc:  0.7149321266968326\n",
      "pre:  0.8949494949494949\n",
      "rec:  0.5324519230769231\n",
      "ma F1:  0.7090479437770838\n",
      "mi F1:  0.7149321266968327\n",
      "we F1:  0.7059186283152172\n",
      "Eval Loss:  0.3119274377822876\n",
      "Eval Loss:  0.34148287773132324\n",
      "Eval Loss:  0.2493230253458023\n",
      "Eval Loss:  0.19529250264167786\n",
      "Eval Loss:  0.2984217703342438\n",
      "Eval Loss:  0.2620634436607361\n",
      "Eval Loss:  0.37267252802848816\n",
      "Eval Loss:  0.28003907203674316\n",
      "Eval Loss:  0.23616968095302582\n",
      "Eval Loss:  0.16874946653842926\n",
      "Eval Loss:  0.18322817981243134\n",
      "Eval Loss:  0.22362589836120605\n",
      "Eval Loss:  0.3367930054664612\n",
      "Eval Loss:  0.3522801995277405\n",
      "Eval Loss:  0.2654721438884735\n",
      "Eval Loss:  0.3062407672405243\n",
      "Eval Loss:  0.20469142496585846\n",
      "Eval Loss:  0.2605689764022827\n",
      "Eval Loss:  0.2753826975822449\n",
      "Eval Loss:  0.2094201296567917\n",
      "Eval Loss:  0.22336958348751068\n",
      "Eval Loss:  0.24374112486839294\n",
      "Eval Loss:  0.4062464237213135\n",
      "Eval Loss:  0.24683961272239685\n",
      "Eval Loss:  0.2622711658477783\n",
      "Eval Loss:  0.282964825630188\n",
      "Eval Loss:  0.2457839846611023\n",
      "Eval Loss:  0.2548823952674866\n",
      "Eval Loss:  0.38652995228767395\n",
      "[[17905   829]\n",
      " [ 2503  8560]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91     18734\n",
      "           1       0.91      0.77      0.84     11063\n",
      "\n",
      "    accuracy                           0.89     29797\n",
      "   macro avg       0.89      0.86      0.88     29797\n",
      "weighted avg       0.89      0.89      0.89     29797\n",
      "\n",
      "acc:  0.8881766620800752\n",
      "pre:  0.9117051869208649\n",
      "rec:  0.7737503389677303\n",
      "ma F1:  0.8759779981562865\n",
      "mi F1:  0.8881766620800752\n",
      "we F1:  0.8859914760545617\n",
      "29797 466\n",
      "Loss:  0.08466097712516785\n",
      "Loss:  0.07065532356500626\n",
      "Loss:  0.05890201777219772\n",
      "24 **********\n",
      "Epoch:  1320.247925043106  fold:  2  kers:  32\n",
      "epoch:  25\n",
      "29797 466\n",
      "Loss:  0.06989170610904694\n",
      "Loss:  0.08783841133117676\n",
      "Loss:  0.057419147342443466\n",
      "25 **********\n",
      "Epoch:  1360.041524887085  fold:  2  kers:  32\n",
      "epoch:  26\n",
      "29797 466\n",
      "Loss:  0.07244925200939178\n",
      "Loss:  0.07546547800302505\n",
      "Loss:  0.05123792216181755\n",
      "26 **********\n",
      "Epoch:  1399.8989543914795  fold:  2  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.42304298281669617\n",
      "Eval Loss:  0.2856169641017914\n",
      "Eval Loss:  0.43877866864204407\n",
      "[[1283  147]\n",
      " [ 620 1044]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      1430\n",
      "           1       0.88      0.63      0.73      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.78      0.76      0.75      3094\n",
      "weighted avg       0.78      0.75      0.75      3094\n",
      "\n",
      "acc:  0.7521008403361344\n",
      "pre:  0.8765743073047859\n",
      "rec:  0.6274038461538461\n",
      "ma F1:  0.7506127495411539\n",
      "mi F1:  0.7521008403361344\n",
      "we F1:  0.7491557903527627\n",
      "Eval Loss:  0.28944334387779236\n",
      "Eval Loss:  0.3231249153614044\n",
      "Eval Loss:  0.23065394163131714\n",
      "Eval Loss:  0.21446716785430908\n",
      "Eval Loss:  0.30095112323760986\n",
      "Eval Loss:  0.21203643083572388\n",
      "Eval Loss:  0.320545494556427\n",
      "Eval Loss:  0.24560114741325378\n",
      "Eval Loss:  0.21444588899612427\n",
      "Eval Loss:  0.1566033959388733\n",
      "Eval Loss:  0.15704672038555145\n",
      "Eval Loss:  0.20829300582408905\n",
      "Eval Loss:  0.31857162714004517\n",
      "Eval Loss:  0.35802584886550903\n",
      "Eval Loss:  0.2535684108734131\n",
      "Eval Loss:  0.2712995409965515\n",
      "Eval Loss:  0.1978769302368164\n",
      "Eval Loss:  0.2137654572725296\n",
      "Eval Loss:  0.2325218915939331\n",
      "Eval Loss:  0.19235874712467194\n",
      "Eval Loss:  0.20741517841815948\n",
      "Eval Loss:  0.23971477150917053\n",
      "Eval Loss:  0.3729854226112366\n",
      "Eval Loss:  0.2200102061033249\n",
      "Eval Loss:  0.2521381378173828\n",
      "Eval Loss:  0.22897620499134064\n",
      "Eval Loss:  0.22210004925727844\n",
      "Eval Loss:  0.22038283944129944\n",
      "Eval Loss:  0.32286199927330017\n",
      "[[17678  1056]\n",
      " [ 2029  9034]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18734\n",
      "           1       0.90      0.82      0.85     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.88      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.8964660871899855\n",
      "pre:  0.8953419226957383\n",
      "rec:  0.816595860074121\n",
      "ma F1:  0.8869524738255801\n",
      "mi F1:  0.8964660871899855\n",
      "we F1:  0.8953952003547743\n",
      "29797 466\n",
      "Loss:  0.048353761434555054\n",
      "Loss:  0.06764306873083115\n",
      "Loss:  0.05730893835425377\n",
      "27 **********\n",
      "Epoch:  1478.2793810367584  fold:  2  kers:  32\n",
      "epoch:  28\n",
      "29797 466\n",
      "Loss:  0.10219034552574158\n",
      "Loss:  0.06242723390460014\n",
      "Loss:  0.11052769422531128\n",
      "28 **********\n",
      "Epoch:  1518.2305598258972  fold:  2  kers:  32\n",
      "epoch:  29\n",
      "29797 466\n",
      "Loss:  0.08379258215427399\n",
      "Loss:  0.05944827198982239\n",
      "Loss:  0.06998932361602783\n",
      "29 **********\n",
      "Epoch:  1558.2116584777832  fold:  2  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.39370521903038025\n",
      "Eval Loss:  0.48001718521118164\n",
      "Eval Loss:  0.44178590178489685\n",
      "[[1242  188]\n",
      " [ 551 1113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77      1430\n",
      "           1       0.86      0.67      0.75      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.77      0.77      0.76      3094\n",
      "weighted avg       0.78      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7611506140917905\n",
      "pre:  0.8554957724827056\n",
      "rec:  0.6688701923076923\n",
      "ma F1:  0.7607346857195777\n",
      "mi F1:  0.7611506140917905\n",
      "we F1:  0.7599802109978893\n",
      "update!  Acc:  0.7611506140917905\n",
      "Eval Loss:  0.28981274366378784\n",
      "Eval Loss:  0.31137028336524963\n",
      "Eval Loss:  0.24465350806713104\n",
      "Eval Loss:  0.21902592480182648\n",
      "Eval Loss:  0.29624974727630615\n",
      "Eval Loss:  0.19906459748744965\n",
      "Eval Loss:  0.29267391562461853\n",
      "Eval Loss:  0.22852490842342377\n",
      "Eval Loss:  0.22414849698543549\n",
      "Eval Loss:  0.1523774415254593\n",
      "Eval Loss:  0.13458335399627686\n",
      "Eval Loss:  0.2021515965461731\n",
      "Eval Loss:  0.3056016266345978\n",
      "Eval Loss:  0.3333071172237396\n",
      "Eval Loss:  0.25493085384368896\n",
      "Eval Loss:  0.2601829469203949\n",
      "Eval Loss:  0.18345551192760468\n",
      "Eval Loss:  0.1905890852212906\n",
      "Eval Loss:  0.23024620115756989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18837694823741913\n",
      "Eval Loss:  0.18976432085037231\n",
      "Eval Loss:  0.24422195553779602\n",
      "Eval Loss:  0.3579854667186737\n",
      "Eval Loss:  0.19256484508514404\n",
      "Eval Loss:  0.24903160333633423\n",
      "Eval Loss:  0.2079666554927826\n",
      "Eval Loss:  0.22414517402648926\n",
      "Eval Loss:  0.21124491095542908\n",
      "Eval Loss:  0.2935003340244293\n",
      "[[17526  1208]\n",
      " [ 1745  9318]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     18734\n",
      "           1       0.89      0.84      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.89      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9008960633620834\n",
      "pre:  0.8852365570967129\n",
      "rec:  0.8422670161800596\n",
      "ma F1:  0.8927585383145676\n",
      "mi F1:  0.9008960633620833\n",
      "we F1:  0.9003636741137262\n",
      "29797 466\n",
      "Loss:  0.09975837916135788\n",
      "Loss:  0.065535768866539\n",
      "Loss:  0.06498269736766815\n",
      "30 **********\n",
      "Epoch:  1636.589093208313  fold:  2  kers:  32\n",
      "epoch:  31\n",
      "29797 466\n",
      "Loss:  0.06568886339664459\n",
      "Loss:  0.07042491436004639\n",
      "Loss:  0.04988246411085129\n",
      "31 **********\n",
      "Epoch:  1676.459487915039  fold:  2  kers:  32\n",
      "epoch:  32\n",
      "29797 466\n",
      "Loss:  0.06751561909914017\n",
      "Loss:  0.06623850017786026\n",
      "Loss:  0.08038344234228134\n",
      "32 **********\n",
      "Epoch:  1716.3199093341827  fold:  2  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.5221518278121948\n",
      "Eval Loss:  0.4142957627773285\n",
      "Eval Loss:  0.5736913681030273\n",
      "[[1280  150]\n",
      " [ 650 1014]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      1430\n",
      "           1       0.87      0.61      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.77      0.75      0.74      3094\n",
      "weighted avg       0.78      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7414350355526826\n",
      "pre:  0.8711340206185567\n",
      "rec:  0.609375\n",
      "ma F1:  0.7395096652522395\n",
      "mi F1:  0.7414350355526826\n",
      "we F1:  0.7378159184465866\n",
      "Eval Loss:  0.29588204622268677\n",
      "Eval Loss:  0.30159711837768555\n",
      "Eval Loss:  0.23218899965286255\n",
      "Eval Loss:  0.188935786485672\n",
      "Eval Loss:  0.26823529601097107\n",
      "Eval Loss:  0.20788271725177765\n",
      "Eval Loss:  0.3016984760761261\n",
      "Eval Loss:  0.23195898532867432\n",
      "Eval Loss:  0.21769343316555023\n",
      "Eval Loss:  0.14926934242248535\n",
      "Eval Loss:  0.13545149564743042\n",
      "Eval Loss:  0.20535114407539368\n",
      "Eval Loss:  0.29767775535583496\n",
      "Eval Loss:  0.33099430799484253\n",
      "Eval Loss:  0.241387277841568\n",
      "Eval Loss:  0.2570507228374481\n",
      "Eval Loss:  0.17893213033676147\n",
      "Eval Loss:  0.19372160732746124\n",
      "Eval Loss:  0.22010517120361328\n",
      "Eval Loss:  0.18089072406291962\n",
      "Eval Loss:  0.18400554358959198\n",
      "Eval Loss:  0.2411564290523529\n",
      "Eval Loss:  0.3522288203239441\n",
      "Eval Loss:  0.2098725140094757\n",
      "Eval Loss:  0.22609251737594604\n",
      "Eval Loss:  0.212962806224823\n",
      "Eval Loss:  0.21631692349910736\n",
      "Eval Loss:  0.20989741384983063\n",
      "Eval Loss:  0.30569398403167725\n",
      "[[17712  1022]\n",
      " [ 1902  9161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18734\n",
      "           1       0.90      0.83      0.86     11063\n",
      "\n",
      "    accuracy                           0.90     29797\n",
      "   macro avg       0.90      0.89      0.89     29797\n",
      "weighted avg       0.90      0.90      0.90     29797\n",
      "\n",
      "acc:  0.9018693157029231\n",
      "pre:  0.89963664931749\n",
      "rec:  0.828075567206002\n",
      "ma F1:  0.8930625033206847\n",
      "mi F1:  0.9018693157029231\n",
      "we F1:  0.9009629895543593\n",
      "29797 466\n",
      "Loss:  0.0631333515048027\n",
      "Loss:  0.05824333429336548\n",
      "Loss:  0.06319177150726318\n",
      "33 **********\n",
      "Epoch:  1794.6913590431213  fold:  2  kers:  32\n",
      "epoch:  34\n",
      "29797 466\n",
      "Loss:  0.0669855922460556\n",
      "Loss:  0.04903935641050339\n",
      "Loss:  0.043488532304763794\n",
      "34 **********\n",
      "Epoch:  1834.4610233306885  fold:  2  kers:  32\n",
      "epoch:  35\n",
      "29797 466\n",
      "Loss:  0.0667034462094307\n",
      "Loss:  0.09539711475372314\n",
      "Loss:  0.04519963636994362\n",
      "35 **********\n",
      "Epoch:  1874.267588853836  fold:  2  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.38975802063941956\n",
      "Eval Loss:  0.37035003304481506\n",
      "Eval Loss:  0.39882373809814453\n",
      "[[1269  161]\n",
      " [ 557 1107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78      1430\n",
      "           1       0.87      0.67      0.76      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.78      0.78      0.77      3094\n",
      "weighted avg       0.79      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7679379444085327\n",
      "pre:  0.8730283911671924\n",
      "rec:  0.6652644230769231\n",
      "ma F1:  0.7672999956424241\n",
      "mi F1:  0.7679379444085327\n",
      "we F1:  0.7663785140913784\n",
      "update!  Acc:  0.7679379444085327\n",
      "Eval Loss:  0.2795107364654541\n",
      "Eval Loss:  0.2819584608078003\n",
      "Eval Loss:  0.21936985850334167\n",
      "Eval Loss:  0.2062220573425293\n",
      "Eval Loss:  0.2723642587661743\n",
      "Eval Loss:  0.19564928114414215\n",
      "Eval Loss:  0.2776326835155487\n",
      "Eval Loss:  0.22100326418876648\n",
      "Eval Loss:  0.19983401894569397\n",
      "Eval Loss:  0.15780898928642273\n",
      "Eval Loss:  0.1351069211959839\n",
      "Eval Loss:  0.2080584615468979\n",
      "Eval Loss:  0.29433631896972656\n",
      "Eval Loss:  0.3157556354999542\n",
      "Eval Loss:  0.24442583322525024\n",
      "Eval Loss:  0.2585771083831787\n",
      "Eval Loss:  0.17213650047779083\n",
      "Eval Loss:  0.19758500158786774\n",
      "Eval Loss:  0.21674461662769318\n",
      "Eval Loss:  0.17792342603206635\n",
      "Eval Loss:  0.19139711558818817\n",
      "Eval Loss:  0.24008779227733612\n",
      "Eval Loss:  0.3459511995315552\n",
      "Eval Loss:  0.2050960659980774\n",
      "Eval Loss:  0.2163293957710266\n",
      "Eval Loss:  0.1997014731168747\n",
      "Eval Loss:  0.21087394654750824\n",
      "Eval Loss:  0.20600132644176483\n",
      "Eval Loss:  0.2645311653614044\n",
      "[[17602  1132]\n",
      " [ 1692  9371]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18734\n",
      "           1       0.89      0.85      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.90      0.89      0.90     29797\n",
      "weighted avg       0.90      0.91      0.90     29797\n",
      "\n",
      "acc:  0.9052253582575427\n",
      "pre:  0.892221270113301\n",
      "rec:  0.8470577601012383\n",
      "ma F1:  0.8973960342053247\n",
      "mi F1:  0.9052253582575427\n",
      "we F1:  0.9046926864717034\n",
      "29797 466\n",
      "Loss:  0.0345471128821373\n",
      "Loss:  0.11195708066225052\n",
      "Loss:  0.04797983914613724\n",
      "36 **********\n",
      "Epoch:  1952.7557275295258  fold:  2  kers:  32\n",
      "epoch:  37\n",
      "29797 466\n",
      "Loss:  0.04708116501569748\n",
      "Loss:  0.05201900005340576\n",
      "Loss:  0.07180238515138626\n",
      "37 **********\n",
      "Epoch:  1992.6879568099976  fold:  2  kers:  32\n",
      "epoch:  38\n",
      "29797 466\n",
      "Loss:  0.10069553554058075\n",
      "Loss:  0.08143860101699829\n",
      "Loss:  0.06640329211950302\n",
      "38 **********\n",
      "Epoch:  2032.6161971092224  fold:  2  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.39892587065696716\n",
      "Eval Loss:  0.45644208788871765\n",
      "Eval Loss:  0.36503803730010986\n",
      "[[1209  221]\n",
      " [ 481 1183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78      1430\n",
      "           1       0.84      0.71      0.77      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.78      0.78      0.77      3094\n",
      "weighted avg       0.78      0.77      0.77      3094\n",
      "\n",
      "acc:  0.773109243697479\n",
      "pre:  0.8425925925925926\n",
      "rec:  0.7109375\n",
      "ma F1:  0.7730932203389831\n",
      "mi F1:  0.7731092436974791\n",
      "we F1:  0.7729490101125195\n",
      "update!  Acc:  0.773109243697479\n",
      "Eval Loss:  0.2879418730735779\n",
      "Eval Loss:  0.2894538342952728\n",
      "Eval Loss:  0.24172665178775787\n",
      "Eval Loss:  0.2101597785949707\n",
      "Eval Loss:  0.27513885498046875\n",
      "Eval Loss:  0.19181479513645172\n",
      "Eval Loss:  0.2717818021774292\n",
      "Eval Loss:  0.21034644544124603\n",
      "Eval Loss:  0.2113136351108551\n",
      "Eval Loss:  0.16471266746520996\n",
      "Eval Loss:  0.12657570838928223\n",
      "Eval Loss:  0.20199936628341675\n",
      "Eval Loss:  0.30073297023773193\n",
      "Eval Loss:  0.32950732111930847\n",
      "Eval Loss:  0.23612530529499054\n",
      "Eval Loss:  0.25246942043304443\n",
      "Eval Loss:  0.17478960752487183\n",
      "Eval Loss:  0.18493151664733887\n",
      "Eval Loss:  0.21896734833717346\n",
      "Eval Loss:  0.1796637326478958\n",
      "Eval Loss:  0.1759120374917984\n",
      "Eval Loss:  0.24102699756622314\n",
      "Eval Loss:  0.3343253433704376\n",
      "Eval Loss:  0.19435825943946838\n",
      "Eval Loss:  0.22766411304473877\n",
      "Eval Loss:  0.18411965668201447\n",
      "Eval Loss:  0.1995311975479126\n",
      "Eval Loss:  0.19680042564868927\n",
      "Eval Loss:  0.2799982726573944\n",
      "[[17456  1278]\n",
      " [ 1529  9534]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18734\n",
      "           1       0.88      0.86      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.90      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.905795885491828\n",
      "pre:  0.8817980022197558\n",
      "rec:  0.8617915574437314\n",
      "ma F1:  0.8986306360189825\n",
      "mi F1:  0.905795885491828\n",
      "we F1:  0.9055688623136301\n",
      "29797 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.05759352818131447\n",
      "Loss:  0.08191176503896713\n",
      "Loss:  0.08800855278968811\n",
      "39 **********\n",
      "Epoch:  2111.2718873023987  fold:  2  kers:  32\n",
      "epoch:  40\n",
      "29797 466\n",
      "Loss:  0.045314397662878036\n",
      "Loss:  0.10341235250234604\n",
      "Loss:  0.08703925460577011\n",
      "40 **********\n",
      "Epoch:  2151.206111907959  fold:  2  kers:  32\n",
      "epoch:  41\n",
      "29797 466\n",
      "Loss:  0.06426307559013367\n",
      "Loss:  0.08176031708717346\n",
      "Loss:  0.06592239439487457\n",
      "41 **********\n",
      "Epoch:  2191.09645318985  fold:  2  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.35765838623046875\n",
      "Eval Loss:  0.5228518843650818\n",
      "Eval Loss:  0.5855181813240051\n",
      "[[1207  223]\n",
      " [ 483 1181]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      1430\n",
      "           1       0.84      0.71      0.77      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.78      0.78      0.77      3094\n",
      "weighted avg       0.78      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7718164188752424\n",
      "pre:  0.8411680911680912\n",
      "rec:  0.7097355769230769\n",
      "ma F1:  0.7718003042155586\n",
      "mi F1:  0.7718164188752425\n",
      "we F1:  0.7716552722784028\n",
      "Eval Loss:  0.2776249349117279\n",
      "Eval Loss:  0.2757105529308319\n",
      "Eval Loss:  0.24850763380527496\n",
      "Eval Loss:  0.22040416300296783\n",
      "Eval Loss:  0.26930543780326843\n",
      "Eval Loss:  0.19819776713848114\n",
      "Eval Loss:  0.27500906586647034\n",
      "Eval Loss:  0.2066212147474289\n",
      "Eval Loss:  0.21694807708263397\n",
      "Eval Loss:  0.17217552661895752\n",
      "Eval Loss:  0.12005922943353653\n",
      "Eval Loss:  0.19214223325252533\n",
      "Eval Loss:  0.29830390214920044\n",
      "Eval Loss:  0.3519071936607361\n",
      "Eval Loss:  0.24250450730323792\n",
      "Eval Loss:  0.2600427269935608\n",
      "Eval Loss:  0.17980879545211792\n",
      "Eval Loss:  0.16071869432926178\n",
      "Eval Loss:  0.2113061100244522\n",
      "Eval Loss:  0.16890156269073486\n",
      "Eval Loss:  0.17313221096992493\n",
      "Eval Loss:  0.25983667373657227\n",
      "Eval Loss:  0.3416920602321625\n",
      "Eval Loss:  0.1861838698387146\n",
      "Eval Loss:  0.23305797576904297\n",
      "Eval Loss:  0.18998262286186218\n",
      "Eval Loss:  0.21260535717010498\n",
      "Eval Loss:  0.1924303025007248\n",
      "Eval Loss:  0.2800564765930176\n",
      "[[17373  1361]\n",
      " [ 1434  9629]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18734\n",
      "           1       0.88      0.87      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.90      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9061986105983824\n",
      "pre:  0.8761601455868971\n",
      "rec:  0.8703787399439573\n",
      "ma F1:  0.8994039706931561\n",
      "mi F1:  0.9061986105983824\n",
      "we F1:  0.906134559886466\n",
      "29797 466\n",
      "Loss:  0.05576818436384201\n",
      "Loss:  0.0618639774620533\n",
      "Loss:  0.058224014937877655\n",
      "42 **********\n",
      "Epoch:  2269.6773431301117  fold:  2  kers:  32\n",
      "epoch:  43\n",
      "29797 466\n",
      "Loss:  0.08026756346225739\n",
      "Loss:  0.07404988259077072\n",
      "Loss:  0.0542287714779377\n",
      "43 **********\n",
      "Epoch:  2309.5796530246735  fold:  2  kers:  32\n",
      "epoch:  44\n",
      "29797 466\n",
      "Loss:  0.06568533927202225\n",
      "Loss:  0.0644480288028717\n",
      "Loss:  0.08149033784866333\n",
      "44 **********\n",
      "Epoch:  2349.4281063079834  fold:  2  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.3795970678329468\n",
      "Eval Loss:  0.28890153765678406\n",
      "Eval Loss:  0.8792935013771057\n",
      "[[1290  140]\n",
      " [ 655 1009]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      1430\n",
      "           1       0.88      0.61      0.72      1664\n",
      "\n",
      "    accuracy                           0.74      3094\n",
      "   macro avg       0.77      0.75      0.74      3094\n",
      "weighted avg       0.78      0.74      0.74      3094\n",
      "\n",
      "acc:  0.7430510665804784\n",
      "pre:  0.8781549173194082\n",
      "rec:  0.6063701923076923\n",
      "ma F1:  0.7409140103487775\n",
      "mi F1:  0.7430510665804783\n",
      "we F1:  0.7391343976860799\n",
      "Eval Loss:  0.31116431951522827\n",
      "Eval Loss:  0.2615281045436859\n",
      "Eval Loss:  0.2380865514278412\n",
      "Eval Loss:  0.18464359641075134\n",
      "Eval Loss:  0.253797322511673\n",
      "Eval Loss:  0.22204697132110596\n",
      "Eval Loss:  0.30223673582077026\n",
      "Eval Loss:  0.22842217981815338\n",
      "Eval Loss:  0.20858293771743774\n",
      "Eval Loss:  0.14767256379127502\n",
      "Eval Loss:  0.141439288854599\n",
      "Eval Loss:  0.18528388440608978\n",
      "Eval Loss:  0.2881532609462738\n",
      "Eval Loss:  0.30411288142204285\n",
      "Eval Loss:  0.21508517861366272\n",
      "Eval Loss:  0.2634391188621521\n",
      "Eval Loss:  0.1546463668346405\n",
      "Eval Loss:  0.20850974321365356\n",
      "Eval Loss:  0.21765613555908203\n",
      "Eval Loss:  0.16105081140995026\n",
      "Eval Loss:  0.16929224133491516\n",
      "Eval Loss:  0.2313779592514038\n",
      "Eval Loss:  0.3450641632080078\n",
      "Eval Loss:  0.19004884362220764\n",
      "Eval Loss:  0.2105572521686554\n",
      "Eval Loss:  0.20069606602191925\n",
      "Eval Loss:  0.1926870495080948\n",
      "Eval Loss:  0.21692998707294464\n",
      "Eval Loss:  0.32124754786491394\n",
      "[[17894   840]\n",
      " [ 1948  9115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18734\n",
      "           1       0.92      0.82      0.87     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.89      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9064335335772058\n",
      "pre:  0.9156202913108991\n",
      "rec:  0.8239175630479978\n",
      "ma F1:  0.897539438949033\n",
      "mi F1:  0.9064335335772058\n",
      "we F1:  0.9053110074525883\n",
      "29797 466\n",
      "Loss:  0.028979111462831497\n",
      "Loss:  0.06013510003685951\n",
      "Loss:  0.05523126944899559\n",
      "45 **********\n",
      "Epoch:  2427.9780797958374  fold:  2  kers:  32\n",
      "epoch:  46\n",
      "29797 466\n",
      "Loss:  0.04630289226770401\n",
      "Loss:  0.06189848482608795\n",
      "Loss:  0.059090737253427505\n",
      "46 **********\n",
      "Epoch:  2467.996079683304  fold:  2  kers:  32\n",
      "epoch:  47\n",
      "29797 466\n",
      "Loss:  0.12378628551959991\n",
      "Loss:  0.04714184254407883\n",
      "Loss:  0.04021017253398895\n",
      "47 **********\n",
      "Epoch:  2507.897391319275  fold:  2  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.3961699604988098\n",
      "Eval Loss:  0.36125367879867554\n",
      "Eval Loss:  0.5746596455574036\n",
      "[[1274  156]\n",
      " [ 586 1078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      1430\n",
      "           1       0.87      0.65      0.74      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.78      0.77      0.76      3094\n",
      "weighted avg       0.79      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7601809954751131\n",
      "pre:  0.873581847649919\n",
      "rec:  0.6478365384615384\n",
      "ma F1:  0.759214718881694\n",
      "mi F1:  0.7601809954751131\n",
      "we F1:  0.7580611029487343\n",
      "Eval Loss:  0.2761406898498535\n",
      "Eval Loss:  0.25633567571640015\n",
      "Eval Loss:  0.21221259236335754\n",
      "Eval Loss:  0.18233497440814972\n",
      "Eval Loss:  0.2446344792842865\n",
      "Eval Loss:  0.19290633499622345\n",
      "Eval Loss:  0.28798404335975647\n",
      "Eval Loss:  0.20929452776908875\n",
      "Eval Loss:  0.1925310343503952\n",
      "Eval Loss:  0.14703048765659332\n",
      "Eval Loss:  0.1346006542444229\n",
      "Eval Loss:  0.1952170878648758\n",
      "Eval Loss:  0.2683364450931549\n",
      "Eval Loss:  0.28525686264038086\n",
      "Eval Loss:  0.22200652956962585\n",
      "Eval Loss:  0.23882551491260529\n",
      "Eval Loss:  0.1519402116537094\n",
      "Eval Loss:  0.18946924805641174\n",
      "Eval Loss:  0.19979722797870636\n",
      "Eval Loss:  0.15148568153381348\n",
      "Eval Loss:  0.16672064363956451\n",
      "Eval Loss:  0.23527109622955322\n",
      "Eval Loss:  0.32365110516548157\n",
      "Eval Loss:  0.19268731772899628\n",
      "Eval Loss:  0.19188430905342102\n",
      "Eval Loss:  0.18018899857997894\n",
      "Eval Loss:  0.19002220034599304\n",
      "Eval Loss:  0.1855531632900238\n",
      "Eval Loss:  0.2731214463710785\n",
      "[[17749   985]\n",
      " [ 1679  9384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18734\n",
      "           1       0.91      0.85      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.910595026344934\n",
      "pre:  0.9050053042723503\n",
      "rec:  0.8482328482328483\n",
      "ma F1:  0.9029461129728493\n",
      "mi F1:  0.910595026344934\n",
      "we F1:  0.9099604362815478\n",
      "29797 466\n",
      "Loss:  0.03766898065805435\n",
      "Loss:  0.07336477935314178\n",
      "Loss:  0.035690389573574066\n",
      "48 **********\n",
      "Epoch:  2586.2638556957245  fold:  2  kers:  32\n",
      "epoch:  49\n",
      "29797 466\n",
      "Loss:  0.07947170734405518\n",
      "Loss:  0.03551959991455078\n",
      "Loss:  0.0603485181927681\n",
      "49 **********\n",
      "Epoch:  2626.136245250702  fold:  2  kers:  32\n",
      "epoch:  50\n",
      "29797 466\n",
      "Loss:  0.06492636352777481\n",
      "Loss:  0.07280383259057999\n",
      "Loss:  0.036618076264858246\n",
      "50 **********\n",
      "Epoch:  2667.512613296509  fold:  2  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.41308677196502686\n",
      "Eval Loss:  0.3390708565711975\n",
      "Eval Loss:  0.49769049882888794\n",
      "[[1275  155]\n",
      " [ 589 1075]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      1430\n",
      "           1       0.87      0.65      0.74      1664\n",
      "\n",
      "    accuracy                           0.76      3094\n",
      "   macro avg       0.78      0.77      0.76      3094\n",
      "weighted avg       0.79      0.76      0.76      3094\n",
      "\n",
      "acc:  0.7595345830639948\n",
      "pre:  0.8739837398373984\n",
      "rec:  0.6460336538461539\n",
      "ma F1:  0.7585255846214075\n",
      "mi F1:  0.7595345830639948\n",
      "we F1:  0.7573450564435804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2852489948272705\n",
      "Eval Loss:  0.2555358409881592\n",
      "Eval Loss:  0.194553405046463\n",
      "Eval Loss:  0.18658174574375153\n",
      "Eval Loss:  0.24815396964550018\n",
      "Eval Loss:  0.180317223072052\n",
      "Eval Loss:  0.2831169366836548\n",
      "Eval Loss:  0.21784508228302002\n",
      "Eval Loss:  0.1848623901605606\n",
      "Eval Loss:  0.15364272892475128\n",
      "Eval Loss:  0.14804449677467346\n",
      "Eval Loss:  0.2012699395418167\n",
      "Eval Loss:  0.28630632162094116\n",
      "Eval Loss:  0.27860787510871887\n",
      "Eval Loss:  0.23572103679180145\n",
      "Eval Loss:  0.2594199478626251\n",
      "Eval Loss:  0.16146308183670044\n",
      "Eval Loss:  0.19149939715862274\n",
      "Eval Loss:  0.20210076868534088\n",
      "Eval Loss:  0.154274120926857\n",
      "Eval Loss:  0.1738673746585846\n",
      "Eval Loss:  0.24254286289215088\n",
      "Eval Loss:  0.3359665274620056\n",
      "Eval Loss:  0.2050899863243103\n",
      "Eval Loss:  0.18259453773498535\n",
      "Eval Loss:  0.19353747367858887\n",
      "Eval Loss:  0.1906016319990158\n",
      "Eval Loss:  0.18661808967590332\n",
      "Eval Loss:  0.27010518312454224\n",
      "[[17724  1010]\n",
      " [ 1634  9429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18734\n",
      "           1       0.90      0.85      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.911266234855858\n",
      "pre:  0.9032474374940128\n",
      "rec:  0.8523004609961131\n",
      "ma F1:  0.9038118972602672\n",
      "mi F1:  0.911266234855858\n",
      "we F1:  0.9107054745593361\n",
      "29797 466\n",
      "Loss:  0.047907691448926926\n",
      "Loss:  0.05421868711709976\n",
      "Loss:  0.06083939969539642\n",
      "51 **********\n",
      "Epoch:  2745.8312046527863  fold:  2  kers:  32\n",
      "epoch:  52\n",
      "29797 466\n",
      "Loss:  0.07545748353004456\n",
      "Loss:  0.03724641352891922\n",
      "Loss:  0.03910960257053375\n",
      "52 **********\n",
      "Epoch:  2785.598874568939  fold:  2  kers:  32\n",
      "epoch:  53\n",
      "29797 466\n",
      "Loss:  0.05637527257204056\n",
      "Loss:  0.060538679361343384\n",
      "Loss:  0.07494732737541199\n",
      "53 **********\n",
      "Epoch:  2825.4333646297455  fold:  2  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.3362448215484619\n",
      "Eval Loss:  0.2030019313097\n",
      "Eval Loss:  0.4724397361278534\n",
      "[[1286  144]\n",
      " [ 575 1089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78      1430\n",
      "           1       0.88      0.65      0.75      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.79      0.78      0.77      3094\n",
      "weighted avg       0.79      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7676147382029735\n",
      "pre:  0.8832116788321168\n",
      "rec:  0.6544471153846154\n",
      "ma F1:  0.7666687958823695\n",
      "mi F1:  0.7676147382029735\n",
      "we F1:  0.765545189268048\n",
      "Eval Loss:  0.2844219505786896\n",
      "Eval Loss:  0.25566330552101135\n",
      "Eval Loss:  0.21099671721458435\n",
      "Eval Loss:  0.17156557738780975\n",
      "Eval Loss:  0.24698719382286072\n",
      "Eval Loss:  0.18403290212154388\n",
      "Eval Loss:  0.2914535701274872\n",
      "Eval Loss:  0.22007212042808533\n",
      "Eval Loss:  0.19833676517009735\n",
      "Eval Loss:  0.14304524660110474\n",
      "Eval Loss:  0.14515283703804016\n",
      "Eval Loss:  0.18561452627182007\n",
      "Eval Loss:  0.2780914008617401\n",
      "Eval Loss:  0.26548585295677185\n",
      "Eval Loss:  0.22316953539848328\n",
      "Eval Loss:  0.2449643909931183\n",
      "Eval Loss:  0.14765451848506927\n",
      "Eval Loss:  0.2148067057132721\n",
      "Eval Loss:  0.19782541692256927\n",
      "Eval Loss:  0.16416208446025848\n",
      "Eval Loss:  0.16185109317302704\n",
      "Eval Loss:  0.23465365171432495\n",
      "Eval Loss:  0.31430783867836\n",
      "Eval Loss:  0.21255476772785187\n",
      "Eval Loss:  0.19318421185016632\n",
      "Eval Loss:  0.18917641043663025\n",
      "Eval Loss:  0.1747712343931198\n",
      "Eval Loss:  0.17776545882225037\n",
      "Eval Loss:  0.29113030433654785\n",
      "[[17910   824]\n",
      " [ 1784  9279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     18734\n",
      "           1       0.92      0.84      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.912474410175521\n",
      "pre:  0.9184400673067405\n",
      "rec:  0.83874175178523\n",
      "ma F1:  0.9044581702798463\n",
      "mi F1:  0.912474410175521\n",
      "we F1:  0.9115827880807639\n",
      "29797 466\n",
      "Loss:  0.06300292909145355\n",
      "Loss:  0.05053864046931267\n",
      "Loss:  0.048397861421108246\n",
      "54 **********\n",
      "Epoch:  2903.7509591579437  fold:  2  kers:  32\n",
      "epoch:  55\n",
      "29797 466\n",
      "Loss:  0.06029895320534706\n",
      "Loss:  0.046956971287727356\n",
      "Loss:  0.06375249475240707\n",
      "55 **********\n",
      "Epoch:  2944.8151621818542  fold:  2  kers:  32\n",
      "epoch:  56\n",
      "29797 466\n",
      "Loss:  0.07985260337591171\n",
      "Loss:  0.04491327702999115\n",
      "Loss:  0.07422942668199539\n",
      "56 **********\n",
      "Epoch:  2984.576847553253  fold:  2  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.3432052731513977\n",
      "Eval Loss:  0.26299065351486206\n",
      "Eval Loss:  0.6459736227989197\n",
      "[[1271  159]\n",
      " [ 554 1110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.78      1430\n",
      "           1       0.87      0.67      0.76      1664\n",
      "\n",
      "    accuracy                           0.77      3094\n",
      "   macro avg       0.79      0.78      0.77      3094\n",
      "weighted avg       0.79      0.77      0.77      3094\n",
      "\n",
      "acc:  0.7695539754363284\n",
      "pre:  0.8747044917257684\n",
      "rec:  0.6670673076923077\n",
      "ma F1:  0.7689282873053757\n",
      "mi F1:  0.7695539754363284\n",
      "we F1:  0.7680189020715685\n",
      "Eval Loss:  0.29556211829185486\n",
      "Eval Loss:  0.2606803774833679\n",
      "Eval Loss:  0.21663431823253632\n",
      "Eval Loss:  0.17018793523311615\n",
      "Eval Loss:  0.24892114102840424\n",
      "Eval Loss:  0.17839552462100983\n",
      "Eval Loss:  0.2783331274986267\n",
      "Eval Loss:  0.21435436606407166\n",
      "Eval Loss:  0.20187491178512573\n",
      "Eval Loss:  0.139051616191864\n",
      "Eval Loss:  0.13680219650268555\n",
      "Eval Loss:  0.18229614198207855\n",
      "Eval Loss:  0.28772085905075073\n",
      "Eval Loss:  0.2722035050392151\n",
      "Eval Loss:  0.21830284595489502\n",
      "Eval Loss:  0.2525012493133545\n",
      "Eval Loss:  0.1491161584854126\n",
      "Eval Loss:  0.20875698328018188\n",
      "Eval Loss:  0.19460295140743256\n",
      "Eval Loss:  0.15959423780441284\n",
      "Eval Loss:  0.1597997546195984\n",
      "Eval Loss:  0.22940348088741302\n",
      "Eval Loss:  0.31413358449935913\n",
      "Eval Loss:  0.19992630183696747\n",
      "Eval Loss:  0.18785643577575684\n",
      "Eval Loss:  0.1947522908449173\n",
      "Eval Loss:  0.1765819936990738\n",
      "Eval Loss:  0.19291335344314575\n",
      "Eval Loss:  0.28602486848831177\n",
      "[[17868   866]\n",
      " [ 1753  9310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18734\n",
      "           1       0.91      0.84      0.88     11063\n",
      "\n",
      "    accuracy                           0.91     29797\n",
      "   macro avg       0.91      0.90      0.90     29797\n",
      "weighted avg       0.91      0.91      0.91     29797\n",
      "\n",
      "acc:  0.9121052454945129\n",
      "pre:  0.9148977987421384\n",
      "rec:  0.8415438850221459\n",
      "ma F1:  0.9042029826735127\n",
      "mi F1:  0.9121052454945129\n",
      "we F1:  0.9112862098410627\n",
      "29797 466\n",
      "Loss:  0.07140006870031357\n",
      "Loss:  0.07068643718957901\n",
      "Loss:  0.09801289439201355\n",
      "57 **********\n",
      "Epoch:  3063.2863945961  fold:  2  kers:  32\n",
      "epoch:  58\n",
      "29797 466\n",
      "Loss:  0.06445761770009995\n",
      "Loss:  0.04778686538338661\n",
      "Loss:  0.06892774999141693\n",
      "58 **********\n",
      "Epoch:  3103.178730726242  fold:  2  kers:  32\n",
      "epoch:  59\n",
      "29797 466\n",
      "Loss:  0.06148214265704155\n",
      "Loss:  0.06460869312286377\n",
      "Loss:  0.07359395176172256\n",
      "59 **********\n",
      "Epoch:  3143.0840318202972  fold:  2  kers:  32\n",
      "Eval Loss:  0.38361260294914246\n",
      "Eval Loss:  0.38094261288642883\n",
      "Eval Loss:  0.9788997769355774\n",
      "[[1242  188]\n",
      " [ 589 1075]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.76      1430\n",
      "           1       0.85      0.65      0.73      1664\n",
      "\n",
      "    accuracy                           0.75      3094\n",
      "   macro avg       0.76      0.76      0.75      3094\n",
      "weighted avg       0.77      0.75      0.75      3094\n",
      "\n",
      "acc:  0.748868778280543\n",
      "pre:  0.8511480601741884\n",
      "rec:  0.6460336538461539\n",
      "ma F1:  0.7481350079785671\n",
      "mi F1:  0.748868778280543\n",
      "we F1:  0.7471068507889721\n",
      "update!  Acc:  0.773109243697479\n",
      "Epoch:  3146.712330341339  fold:  2  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.17039696872234344\n",
      "Loss:  0.16804258525371552\n",
      "Loss:  0.16441810131072998\n",
      "0 **********\n",
      "Epoch:  51.99896478652954  fold:  3  kers:  32\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.1446966975927353\n",
      "Loss:  0.13954763114452362\n",
      "Loss:  0.11688563227653503\n",
      "1 **********\n",
      "Epoch:  91.60207486152649  fold:  3  kers:  32\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.11653286963701248\n",
      "Loss:  0.11765041947364807\n",
      "Loss:  0.09601900726556778\n",
      "2 **********\n",
      "Epoch:  131.0366349220276  fold:  3  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.7299755215644836\n",
      "Eval Loss:  0.6134582161903381\n",
      "Eval Loss:  0.3783038556575775\n",
      "[[1226  310]\n",
      " [ 435 1460]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      1536\n",
      "           1       0.82      0.77      0.80      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.78      0.78      3431\n",
      "weighted avg       0.79      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7828621393179831\n",
      "pre:  0.8248587570621468\n",
      "rec:  0.7704485488126649\n",
      "ma F1:  0.7818474089581766\n",
      "mi F1:  0.7828621393179832\n",
      "we F1:  0.783404196134119\n",
      "update!  Acc:  0.7828621393179831\n",
      "Eval Loss:  0.3590250611305237\n",
      "Eval Loss:  0.46152135729789734\n",
      "Eval Loss:  0.35176408290863037\n",
      "Eval Loss:  0.4738291800022125\n",
      "Eval Loss:  0.3782016932964325\n",
      "Eval Loss:  0.4963092505931854\n",
      "Eval Loss:  0.3020024299621582\n",
      "Eval Loss:  0.49990442395210266\n",
      "Eval Loss:  0.3242354989051819\n",
      "Eval Loss:  0.4748302102088928\n",
      "Eval Loss:  0.3166244328022003\n",
      "Eval Loss:  0.3654089570045471\n",
      "Eval Loss:  0.3886125087738037\n",
      "Eval Loss:  0.41146183013916016\n",
      "Eval Loss:  0.41654080152511597\n",
      "Eval Loss:  0.424407422542572\n",
      "Eval Loss:  0.34331175684928894\n",
      "Eval Loss:  0.4245074391365051\n",
      "Eval Loss:  0.45241957902908325\n",
      "Eval Loss:  0.42258700728416443\n",
      "Eval Loss:  0.4643475115299225\n",
      "Eval Loss:  0.3830147087574005\n",
      "Eval Loss:  0.3949402868747711\n",
      "Eval Loss:  0.35376495122909546\n",
      "Eval Loss:  0.3718762695789337\n",
      "Eval Loss:  0.365301251411438\n",
      "Eval Loss:  0.4242086708545685\n",
      "Eval Loss:  0.43608933687210083\n",
      "[[15727  2901]\n",
      " [ 2468  8364]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85     18628\n",
      "           1       0.74      0.77      0.76     10832\n",
      "\n",
      "    accuracy                           0.82     29460\n",
      "   macro avg       0.80      0.81      0.81     29460\n",
      "weighted avg       0.82      0.82      0.82     29460\n",
      "\n",
      "acc:  0.8177528852681603\n",
      "pre:  0.7424766977363515\n",
      "rec:  0.7721565731166913\n",
      "ma F1:  0.8056101149940265\n",
      "mi F1:  0.8177528852681603\n",
      "we F1:  0.8184669718536145\n",
      "29460 461\n",
      "Loss:  0.09664741158485413\n",
      "Loss:  0.09756030887365341\n",
      "Loss:  0.08483444899320602\n",
      "3 **********\n",
      "Epoch:  209.45994687080383  fold:  3  kers:  32\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.10730770230293274\n",
      "Loss:  0.09760194271802902\n",
      "Loss:  0.07673267275094986\n",
      "4 **********\n",
      "Epoch:  248.96830892562866  fold:  3  kers:  32\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.09408538788557053\n",
      "Loss:  0.0858287513256073\n",
      "Loss:  0.08719250559806824\n",
      "5 **********\n",
      "Epoch:  288.8845818042755  fold:  3  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.8878561854362488\n",
      "Eval Loss:  0.5727425217628479\n",
      "Eval Loss:  0.5400398969650269\n",
      "[[1376  160]\n",
      " [ 631 1264]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78      1536\n",
      "           1       0.89      0.67      0.76      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.78      0.77      3431\n",
      "weighted avg       0.80      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7694549693966773\n",
      "pre:  0.8876404494382022\n",
      "rec:  0.6670184696569921\n",
      "ma F1:  0.7692090383228747\n",
      "mi F1:  0.7694549693966773\n",
      "we F1:  0.768420741398811\n",
      "Eval Loss:  0.31204476952552795\n",
      "Eval Loss:  0.38143834471702576\n",
      "Eval Loss:  0.3490995168685913\n",
      "Eval Loss:  0.4189359247684479\n",
      "Eval Loss:  0.37189435958862305\n",
      "Eval Loss:  0.4381847381591797\n",
      "Eval Loss:  0.23234909772872925\n",
      "Eval Loss:  0.4586242735385895\n",
      "Eval Loss:  0.2983034551143646\n",
      "Eval Loss:  0.5150885581970215\n",
      "Eval Loss:  0.26090526580810547\n",
      "Eval Loss:  0.34834250807762146\n",
      "Eval Loss:  0.37839600443840027\n",
      "Eval Loss:  0.33698493242263794\n",
      "Eval Loss:  0.3867855668067932\n",
      "Eval Loss:  0.3549945652484894\n",
      "Eval Loss:  0.33859091997146606\n",
      "Eval Loss:  0.35993897914886475\n",
      "Eval Loss:  0.4195234775543213\n",
      "Eval Loss:  0.389591783285141\n",
      "Eval Loss:  0.4364611506462097\n",
      "Eval Loss:  0.34305083751678467\n",
      "Eval Loss:  0.3835484981536865\n",
      "Eval Loss:  0.31815260648727417\n",
      "Eval Loss:  0.37650904059410095\n",
      "Eval Loss:  0.3202199637889862\n",
      "Eval Loss:  0.3890387713909149\n",
      "Eval Loss:  0.4832935929298401\n",
      "[[17596  1032]\n",
      " [ 3462  7370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     18628\n",
      "           1       0.88      0.68      0.77     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.86      0.81      0.83     29460\n",
      "weighted avg       0.85      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8474541751527495\n",
      "pre:  0.8771721018805047\n",
      "rec:  0.6803914327917282\n",
      "ma F1:  0.8265561637119037\n",
      "mi F1:  0.8474541751527495\n",
      "we F1:  0.842488189645097\n",
      "29460 461\n",
      "Loss:  0.09743715077638626\n",
      "Loss:  0.12053292989730835\n",
      "Loss:  0.09301016479730606\n",
      "6 **********\n",
      "Epoch:  367.0276427268982  fold:  3  kers:  32\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.10553690046072006\n",
      "Loss:  0.10284044593572617\n",
      "Loss:  0.07899343967437744\n",
      "7 **********\n",
      "Epoch:  406.450234413147  fold:  3  kers:  32\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.05597848445177078\n",
      "Loss:  0.10218443721532822\n",
      "Loss:  0.06898343563079834\n",
      "8 **********\n",
      "Epoch:  445.8538773059845  fold:  3  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  1.0072349309921265\n",
      "Eval Loss:  0.49038073420524597\n",
      "Eval Loss:  0.59898841381073\n",
      "[[1415  121]\n",
      " [ 705 1190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.77      1536\n",
      "           1       0.91      0.63      0.74      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.79      0.77      0.76      3431\n",
      "weighted avg       0.80      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7592538618478578\n",
      "pre:  0.9077040427154843\n",
      "rec:  0.6279683377308707\n",
      "ma F1:  0.7582140502422292\n",
      "mi F1:  0.7592538618478578\n",
      "we F1:  0.7565549730581371\n",
      "Eval Loss:  0.31904852390289307\n",
      "Eval Loss:  0.3739384710788727\n",
      "Eval Loss:  0.34724634885787964\n",
      "Eval Loss:  0.41054654121398926\n",
      "Eval Loss:  0.383293092250824\n",
      "Eval Loss:  0.40907976031303406\n",
      "Eval Loss:  0.20877769589424133\n",
      "Eval Loss:  0.4590383470058441\n",
      "Eval Loss:  0.32685527205467224\n",
      "Eval Loss:  0.5254114866256714\n",
      "Eval Loss:  0.2723255157470703\n",
      "Eval Loss:  0.37389668822288513\n",
      "Eval Loss:  0.412788450717926\n",
      "Eval Loss:  0.33714303374290466\n",
      "Eval Loss:  0.4205726385116577\n",
      "Eval Loss:  0.3427664637565613\n",
      "Eval Loss:  0.35086172819137573\n",
      "Eval Loss:  0.3297780156135559\n",
      "Eval Loss:  0.47402048110961914\n",
      "Eval Loss:  0.381182461977005\n",
      "Eval Loss:  0.4043208658695221\n",
      "Eval Loss:  0.34417474269866943\n",
      "Eval Loss:  0.423405259847641\n",
      "Eval Loss:  0.3040883541107178\n",
      "Eval Loss:  0.38674724102020264\n",
      "Eval Loss:  0.2989489436149597\n",
      "Eval Loss:  0.39203184843063354\n",
      "Eval Loss:  0.4932706654071808\n",
      "[[17982   646]\n",
      " [ 3734  7098]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89     18628\n",
      "           1       0.92      0.66      0.76     10832\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.87      0.81      0.83     29460\n",
      "weighted avg       0.86      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8513238289205702\n",
      "pre:  0.9165805785123967\n",
      "rec:  0.6552806499261448\n",
      "ma F1:  0.8278227783695875\n",
      "mi F1:  0.8513238289205702\n",
      "we F1:  0.844656129168509\n",
      "29460 461\n",
      "Loss:  0.08750168234109879\n",
      "Loss:  0.07634978741407394\n",
      "Loss:  0.08686263114213943\n",
      "9 **********\n",
      "Epoch:  524.1814453601837  fold:  3  kers:  32\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.09264092147350311\n",
      "Loss:  0.08659019321203232\n",
      "Loss:  0.09745613485574722\n",
      "10 **********\n",
      "Epoch:  563.6379477977753  fold:  3  kers:  32\n",
      "epoch:  11\n",
      "29460 461\n",
      "Loss:  0.08972211927175522\n",
      "Loss:  0.06719937175512314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.12167184799909592\n",
      "11 **********\n",
      "Epoch:  603.085471868515  fold:  3  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.7543255090713501\n",
      "Eval Loss:  0.25799819827079773\n",
      "Eval Loss:  0.5671979188919067\n",
      "[[1318  218]\n",
      " [ 551 1344]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.77      1536\n",
      "           1       0.86      0.71      0.78      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.78      0.78      3431\n",
      "weighted avg       0.79      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7758670941416497\n",
      "pre:  0.8604353393085787\n",
      "rec:  0.7092348284960422\n",
      "ma F1:  0.7758542224442352\n",
      "mi F1:  0.7758670941416497\n",
      "we F1:  0.7760319508816121\n",
      "Eval Loss:  0.261760950088501\n",
      "Eval Loss:  0.2758231461048126\n",
      "Eval Loss:  0.305097758769989\n",
      "Eval Loss:  0.3165473937988281\n",
      "Eval Loss:  0.3352965712547302\n",
      "Eval Loss:  0.33586037158966064\n",
      "Eval Loss:  0.17833445966243744\n",
      "Eval Loss:  0.3803712725639343\n",
      "Eval Loss:  0.273124635219574\n",
      "Eval Loss:  0.4182369112968445\n",
      "Eval Loss:  0.23806670308113098\n",
      "Eval Loss:  0.31214651465415955\n",
      "Eval Loss:  0.3040587902069092\n",
      "Eval Loss:  0.2844253182411194\n",
      "Eval Loss:  0.32884952425956726\n",
      "Eval Loss:  0.27094170451164246\n",
      "Eval Loss:  0.3052763044834137\n",
      "Eval Loss:  0.2746002674102783\n",
      "Eval Loss:  0.39426857233047485\n",
      "Eval Loss:  0.34557756781578064\n",
      "Eval Loss:  0.29801955819129944\n",
      "Eval Loss:  0.28111475706100464\n",
      "Eval Loss:  0.3608980178833008\n",
      "Eval Loss:  0.23886778950691223\n",
      "Eval Loss:  0.30268481373786926\n",
      "Eval Loss:  0.20201212167739868\n",
      "Eval Loss:  0.31506550312042236\n",
      "Eval Loss:  0.4410466253757477\n",
      "[[17617  1011]\n",
      " [ 2693  8139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.90     18628\n",
      "           1       0.89      0.75      0.81     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.85      0.86     29460\n",
      "weighted avg       0.88      0.87      0.87     29460\n",
      "\n",
      "acc:  0.8742701968771215\n",
      "pre:  0.8895081967213114\n",
      "rec:  0.7513847858197932\n",
      "ma F1:  0.8597537927953536\n",
      "mi F1:  0.8742701968771215\n",
      "we F1:  0.8716940635509416\n",
      "29460 461\n",
      "Loss:  0.0838533565402031\n",
      "Loss:  0.05448024719953537\n",
      "Loss:  0.09031733870506287\n",
      "12 **********\n",
      "Epoch:  681.4948225021362  fold:  3  kers:  32\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.0661638155579567\n",
      "Loss:  0.08179572224617004\n",
      "Loss:  0.10153310000896454\n",
      "13 **********\n",
      "Epoch:  720.9782502651215  fold:  3  kers:  32\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.07192341983318329\n",
      "Loss:  0.12082324922084808\n",
      "Loss:  0.07691653072834015\n",
      "14 **********\n",
      "Epoch:  760.4836213588715  fold:  3  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.7725686430931091\n",
      "Eval Loss:  0.26089680194854736\n",
      "Eval Loss:  0.5754854083061218\n",
      "[[1329  207]\n",
      " [ 562 1333]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      1536\n",
      "           1       0.87      0.70      0.78      1895\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.78      0.78      0.78      3431\n",
      "weighted avg       0.79      0.78      0.78      3431\n",
      "\n",
      "acc:  0.7758670941416497\n",
      "pre:  0.8655844155844156\n",
      "rec:  0.7034300791556728\n",
      "ma F1:  0.7758667895031706\n",
      "mi F1:  0.7758670941416497\n",
      "we F1:  0.7758941308066741\n",
      "Eval Loss:  0.2634720504283905\n",
      "Eval Loss:  0.2562400996685028\n",
      "Eval Loss:  0.2890842854976654\n",
      "Eval Loss:  0.3151991069316864\n",
      "Eval Loss:  0.3283001184463501\n",
      "Eval Loss:  0.310165137052536\n",
      "Eval Loss:  0.1814415007829666\n",
      "Eval Loss:  0.37833601236343384\n",
      "Eval Loss:  0.2778960168361664\n",
      "Eval Loss:  0.40950003266334534\n",
      "Eval Loss:  0.21839268505573273\n",
      "Eval Loss:  0.30009326338768005\n",
      "Eval Loss:  0.30510053038597107\n",
      "Eval Loss:  0.29688209295272827\n",
      "Eval Loss:  0.3225044012069702\n",
      "Eval Loss:  0.2604295313358307\n",
      "Eval Loss:  0.314274400472641\n",
      "Eval Loss:  0.2625056803226471\n",
      "Eval Loss:  0.4033517837524414\n",
      "Eval Loss:  0.3380752205848694\n",
      "Eval Loss:  0.279157817363739\n",
      "Eval Loss:  0.2632654011249542\n",
      "Eval Loss:  0.3462926745414734\n",
      "Eval Loss:  0.23453611135482788\n",
      "Eval Loss:  0.30510321259498596\n",
      "Eval Loss:  0.18179158866405487\n",
      "Eval Loss:  0.31929245591163635\n",
      "Eval Loss:  0.4545060098171234\n",
      "[[17680   948]\n",
      " [ 2600  8232]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18628\n",
      "           1       0.90      0.76      0.82     10832\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.88      0.85      0.87     29460\n",
      "weighted avg       0.88      0.88      0.88     29460\n",
      "\n",
      "acc:  0.8795655125594026\n",
      "pre:  0.8967320261437909\n",
      "rec:  0.759970457902511\n",
      "ma F1:  0.8657584517861299\n",
      "mi F1:  0.8795655125594025\n",
      "we F1:  0.8771513228475645\n",
      "29460 461\n",
      "Loss:  0.06966138631105423\n",
      "Loss:  0.07728008925914764\n",
      "Loss:  0.0656564012169838\n",
      "15 **********\n",
      "Epoch:  838.7443680763245  fold:  3  kers:  32\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.06571532040834427\n",
      "Loss:  0.07599350810050964\n",
      "Loss:  0.0916464701294899\n",
      "16 **********\n",
      "Epoch:  878.2646989822388  fold:  3  kers:  32\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.05469713360071182\n",
      "Loss:  0.07499416172504425\n",
      "Loss:  0.05563972890377045\n",
      "17 **********\n",
      "Epoch:  917.7291784286499  fold:  3  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.9886541962623596\n",
      "Eval Loss:  0.30295997858047485\n",
      "Eval Loss:  0.648727536201477\n",
      "[[1377  159]\n",
      " [ 628 1267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78      1536\n",
      "           1       0.89      0.67      0.76      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.79      0.78      0.77      3431\n",
      "weighted avg       0.80      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7706208102593995\n",
      "pre:  0.8884992987377279\n",
      "rec:  0.6686015831134564\n",
      "ma F1:  0.7703847925548194\n",
      "mi F1:  0.7706208102593995\n",
      "we F1:  0.7696145165916894\n",
      "Eval Loss:  0.30839088559150696\n",
      "Eval Loss:  0.2837792932987213\n",
      "Eval Loss:  0.31307530403137207\n",
      "Eval Loss:  0.3682810962200165\n",
      "Eval Loss:  0.34684333205223083\n",
      "Eval Loss:  0.3257715106010437\n",
      "Eval Loss:  0.17936982214450836\n",
      "Eval Loss:  0.42837023735046387\n",
      "Eval Loss:  0.296670138835907\n",
      "Eval Loss:  0.41922080516815186\n",
      "Eval Loss:  0.2223527878522873\n",
      "Eval Loss:  0.3407141864299774\n",
      "Eval Loss:  0.3433229625225067\n",
      "Eval Loss:  0.2923370897769928\n",
      "Eval Loss:  0.3280945122241974\n",
      "Eval Loss:  0.32356083393096924\n",
      "Eval Loss:  0.32550323009490967\n",
      "Eval Loss:  0.28384119272232056\n",
      "Eval Loss:  0.45206260681152344\n",
      "Eval Loss:  0.35274621844291687\n",
      "Eval Loss:  0.3408944606781006\n",
      "Eval Loss:  0.277908056974411\n",
      "Eval Loss:  0.3813089430332184\n",
      "Eval Loss:  0.2603278160095215\n",
      "Eval Loss:  0.359714150428772\n",
      "Eval Loss:  0.21393826603889465\n",
      "Eval Loss:  0.37220606207847595\n",
      "Eval Loss:  0.46995779871940613\n",
      "[[18075   553]\n",
      " [ 3303  7529]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90     18628\n",
      "           1       0.93      0.70      0.80     10832\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.89      0.83      0.85     29460\n",
      "weighted avg       0.88      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8691106585200271\n",
      "pre:  0.9315763424894828\n",
      "rec:  0.6950701624815362\n",
      "ma F1:  0.8498721543677087\n",
      "mi F1:  0.8691106585200271\n",
      "we F1:  0.8640939804981349\n",
      "29460 461\n",
      "Loss:  0.09734946489334106\n",
      "Loss:  0.06954076141119003\n",
      "Loss:  0.06837793439626694\n",
      "18 **********\n",
      "Epoch:  996.1584746837616  fold:  3  kers:  32\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.10591716319322586\n",
      "Loss:  0.07513301074504852\n",
      "Loss:  0.07703405618667603\n",
      "19 **********\n",
      "Epoch:  1035.640906572342  fold:  3  kers:  32\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.07575944811105728\n",
      "Loss:  0.06421525031328201\n",
      "Loss:  0.09229567646980286\n",
      "20 **********\n",
      "Epoch:  1075.0794558525085  fold:  3  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.3833370804786682\n",
      "Eval Loss:  0.18325740098953247\n",
      "Eval Loss:  0.5904116630554199\n",
      "[[1173  363]\n",
      " [ 426 1469]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75      1536\n",
      "           1       0.80      0.78      0.79      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7700378898280384\n",
      "pre:  0.8018558951965066\n",
      "rec:  0.775197889182058\n",
      "ma F1:  0.7683134709471682\n",
      "mi F1:  0.7700378898280384\n",
      "we F1:  0.7704049114141697\n",
      "Eval Loss:  0.2035919427871704\n",
      "Eval Loss:  0.21481916308403015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2850475609302521\n",
      "Eval Loss:  0.27049508690834045\n",
      "Eval Loss:  0.30367228388786316\n",
      "Eval Loss:  0.2764914333820343\n",
      "Eval Loss:  0.17152856290340424\n",
      "Eval Loss:  0.3332083523273468\n",
      "Eval Loss:  0.1993357241153717\n",
      "Eval Loss:  0.30883872509002686\n",
      "Eval Loss:  0.23772136867046356\n",
      "Eval Loss:  0.2229221910238266\n",
      "Eval Loss:  0.2342519462108612\n",
      "Eval Loss:  0.2580937445163727\n",
      "Eval Loss:  0.27007076144218445\n",
      "Eval Loss:  0.21729737520217896\n",
      "Eval Loss:  0.29312968254089355\n",
      "Eval Loss:  0.24268920719623566\n",
      "Eval Loss:  0.3343413770198822\n",
      "Eval Loss:  0.30681291222572327\n",
      "Eval Loss:  0.2164311707019806\n",
      "Eval Loss:  0.25535935163497925\n",
      "Eval Loss:  0.2722706198692322\n",
      "Eval Loss:  0.23538623750209808\n",
      "Eval Loss:  0.25159338116645813\n",
      "Eval Loss:  0.1685238778591156\n",
      "Eval Loss:  0.26302260160446167\n",
      "Eval Loss:  0.39474940299987793\n",
      "[[17003  1625]\n",
      " [ 1522  9310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92     18628\n",
      "           1       0.85      0.86      0.86     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.88      0.89      0.89     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8931771894093686\n",
      "pre:  0.8513946044810242\n",
      "rec:  0.8594903988183161\n",
      "ma F1:  0.8853597774214435\n",
      "mi F1:  0.8931771894093686\n",
      "we F1:  0.8932818551359715\n",
      "29460 461\n",
      "Loss:  0.07542693614959717\n",
      "Loss:  0.07861021906137466\n",
      "Loss:  0.05663832649588585\n",
      "21 **********\n",
      "Epoch:  1153.332224369049  fold:  3  kers:  32\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.06801431626081467\n",
      "Loss:  0.07279405742883682\n",
      "Loss:  0.058346353471279144\n",
      "22 **********\n",
      "Epoch:  1192.7677817344666  fold:  3  kers:  32\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.05086063593626022\n",
      "Loss:  0.0434526726603508\n",
      "Loss:  0.08646681159734726\n",
      "23 **********\n",
      "Epoch:  1232.3788692951202  fold:  3  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.7713385224342346\n",
      "Eval Loss:  0.19918696582317352\n",
      "Eval Loss:  0.6881963014602661\n",
      "[[1315  221]\n",
      " [ 565 1330]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77      1536\n",
      "           1       0.86      0.70      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.78      0.78      0.77      3431\n",
      "weighted avg       0.79      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7709122704750802\n",
      "pre:  0.8575112830431979\n",
      "rec:  0.7018469656992085\n",
      "ma F1:  0.7709078917143863\n",
      "mi F1:  0.77091227047508\n",
      "we F1:  0.7710126900536592\n",
      "Eval Loss:  0.23058292269706726\n",
      "Eval Loss:  0.21617397665977478\n",
      "Eval Loss:  0.2863462567329407\n",
      "Eval Loss:  0.30103394389152527\n",
      "Eval Loss:  0.30628129839897156\n",
      "Eval Loss:  0.27713626623153687\n",
      "Eval Loss:  0.16819342970848083\n",
      "Eval Loss:  0.3620735704898834\n",
      "Eval Loss:  0.24141912162303925\n",
      "Eval Loss:  0.32675158977508545\n",
      "Eval Loss:  0.2029470056295395\n",
      "Eval Loss:  0.2713003158569336\n",
      "Eval Loss:  0.2780487537384033\n",
      "Eval Loss:  0.23794406652450562\n",
      "Eval Loss:  0.2602204382419586\n",
      "Eval Loss:  0.25546759366989136\n",
      "Eval Loss:  0.2879502475261688\n",
      "Eval Loss:  0.2276536524295807\n",
      "Eval Loss:  0.3509387969970703\n",
      "Eval Loss:  0.30578064918518066\n",
      "Eval Loss:  0.23515324294567108\n",
      "Eval Loss:  0.24435845017433167\n",
      "Eval Loss:  0.3008510172367096\n",
      "Eval Loss:  0.2316075712442398\n",
      "Eval Loss:  0.28617215156555176\n",
      "Eval Loss:  0.1537957787513733\n",
      "Eval Loss:  0.2916671335697174\n",
      "Eval Loss:  0.41520681977272034\n",
      "[[17853   775]\n",
      " [ 2437  8395]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18628\n",
      "           1       0.92      0.78      0.84     10832\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8909708078750849\n",
      "pre:  0.9154852780806979\n",
      "rec:  0.7750184638109305\n",
      "ma F1:  0.8784417770772386\n",
      "mi F1:  0.8909708078750849\n",
      "we F1:  0.8887691532772819\n",
      "29460 461\n",
      "Loss:  0.06720522791147232\n",
      "Loss:  0.04797373712062836\n",
      "Loss:  0.035218872129917145\n",
      "24 **********\n",
      "Epoch:  1310.6196694374084  fold:  3  kers:  32\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.09282144904136658\n",
      "Loss:  0.07745616883039474\n",
      "Loss:  0.04358046501874924\n",
      "25 **********\n",
      "Epoch:  1350.1439895629883  fold:  3  kers:  32\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.07535505294799805\n",
      "Loss:  0.08059993386268616\n",
      "Loss:  0.06147591769695282\n",
      "26 **********\n",
      "Epoch:  1389.5855309963226  fold:  3  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.6310312747955322\n",
      "Eval Loss:  0.15461234748363495\n",
      "Eval Loss:  0.6583517789840698\n",
      "[[1259  277]\n",
      " [ 509 1386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      1536\n",
      "           1       0.83      0.73      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.78      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7709122704750802\n",
      "pre:  0.8334335538184005\n",
      "rec:  0.7313984168865435\n",
      "ma F1:  0.7705979567921146\n",
      "mi F1:  0.77091227047508\n",
      "we F1:  0.7714864498014424\n",
      "Eval Loss:  0.21012061834335327\n",
      "Eval Loss:  0.2082010805606842\n",
      "Eval Loss:  0.24228467047214508\n",
      "Eval Loss:  0.26589474081993103\n",
      "Eval Loss:  0.2965335547924042\n",
      "Eval Loss:  0.25004875659942627\n",
      "Eval Loss:  0.15530133247375488\n",
      "Eval Loss:  0.3492205739021301\n",
      "Eval Loss:  0.22034992277622223\n",
      "Eval Loss:  0.2836410105228424\n",
      "Eval Loss:  0.19269227981567383\n",
      "Eval Loss:  0.23274178802967072\n",
      "Eval Loss:  0.24815663695335388\n",
      "Eval Loss:  0.2218555510044098\n",
      "Eval Loss:  0.24245579540729523\n",
      "Eval Loss:  0.24079298973083496\n",
      "Eval Loss:  0.27951952815055847\n",
      "Eval Loss:  0.20106098055839539\n",
      "Eval Loss:  0.32463538646698\n",
      "Eval Loss:  0.3002578914165497\n",
      "Eval Loss:  0.20948241651058197\n",
      "Eval Loss:  0.2412521243095398\n",
      "Eval Loss:  0.25600385665893555\n",
      "Eval Loss:  0.2269367128610611\n",
      "Eval Loss:  0.2503238320350647\n",
      "Eval Loss:  0.14222656190395355\n",
      "Eval Loss:  0.268094003200531\n",
      "Eval Loss:  0.37498852610588074\n",
      "[[17627  1001]\n",
      " [ 1956  8876]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18628\n",
      "           1       0.90      0.82      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.8996266123557366\n",
      "pre:  0.8986534372785259\n",
      "rec:  0.819423929098966\n",
      "ma F1:  0.8899128736264107\n",
      "mi F1:  0.8996266123557366\n",
      "we F1:  0.8985665483074556\n",
      "29460 461\n",
      "Loss:  0.06357631087303162\n",
      "Loss:  0.03145553544163704\n",
      "Loss:  0.06344664096832275\n",
      "27 **********\n",
      "Epoch:  1467.8113708496094  fold:  3  kers:  32\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.06563495099544525\n",
      "Loss:  0.043849602341651917\n",
      "Loss:  0.05660655349493027\n",
      "28 **********\n",
      "Epoch:  1507.2020478248596  fold:  3  kers:  32\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.06044872850179672\n",
      "Loss:  0.07362561672925949\n",
      "Loss:  0.044902633875608444\n",
      "29 **********\n",
      "Epoch:  1546.7552909851074  fold:  3  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.6848694682121277\n",
      "Eval Loss:  0.1642092615365982\n",
      "Eval Loss:  0.7472171187400818\n",
      "[[1293  243]\n",
      " [ 552 1343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1536\n",
      "           1       0.85      0.71      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.78      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7682891285339551\n",
      "pre:  0.8467843631778058\n",
      "rec:  0.7087071240105541\n",
      "ma F1:  0.768239909030822\n",
      "mi F1:  0.7682891285339551\n",
      "we F1:  0.7685933050633185\n",
      "Eval Loss:  0.2239345759153366\n",
      "Eval Loss:  0.20426298677921295\n",
      "Eval Loss:  0.2781403660774231\n",
      "Eval Loss:  0.27451831102371216\n",
      "Eval Loss:  0.3100409507751465\n",
      "Eval Loss:  0.2518267035484314\n",
      "Eval Loss:  0.18857377767562866\n",
      "Eval Loss:  0.3737375736236572\n",
      "Eval Loss:  0.22921855747699738\n",
      "Eval Loss:  0.2855657935142517\n",
      "Eval Loss:  0.20421268045902252\n",
      "Eval Loss:  0.2587440609931946\n",
      "Eval Loss:  0.27533912658691406\n",
      "Eval Loss:  0.24174965918064117\n",
      "Eval Loss:  0.23680831491947174\n",
      "Eval Loss:  0.2524856626987457\n",
      "Eval Loss:  0.284552663564682\n",
      "Eval Loss:  0.20946945250034332\n",
      "Eval Loss:  0.3411521017551422\n",
      "Eval Loss:  0.3167409300804138\n",
      "Eval Loss:  0.21658404171466827\n",
      "Eval Loss:  0.22853131592273712\n",
      "Eval Loss:  0.26462772488594055\n",
      "Eval Loss:  0.24031944572925568\n",
      "Eval Loss:  0.2858204245567322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.1564932018518448\n",
      "Eval Loss:  0.30090567469596863\n",
      "Eval Loss:  0.38538867235183716\n",
      "[[17874   754]\n",
      " [ 2317  8515]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18628\n",
      "           1       0.92      0.79      0.85     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.87      0.88     29460\n",
      "weighted avg       0.90      0.90      0.89     29460\n",
      "\n",
      "acc:  0.8957569585879158\n",
      "pre:  0.9186535764375876\n",
      "rec:  0.7860967503692762\n",
      "ma F1:  0.8840553932643499\n",
      "mi F1:  0.8957569585879158\n",
      "we F1:  0.8938027384147421\n",
      "29460 461\n",
      "Loss:  0.055291078984737396\n",
      "Loss:  0.04352204501628876\n",
      "Loss:  0.07019388675689697\n",
      "30 **********\n",
      "Epoch:  1625.015040397644  fold:  3  kers:  32\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.04718278348445892\n",
      "Loss:  0.05988747626543045\n",
      "Loss:  0.05886327102780342\n",
      "31 **********\n",
      "Epoch:  1664.3977391719818  fold:  3  kers:  32\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.09110234677791595\n",
      "Loss:  0.06598089635372162\n",
      "Loss:  0.0722740963101387\n",
      "32 **********\n",
      "Epoch:  1703.8243200778961  fold:  3  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.5921732783317566\n",
      "Eval Loss:  0.18220186233520508\n",
      "Eval Loss:  0.8514028191566467\n",
      "[[1296  240]\n",
      " [ 558 1337]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1536\n",
      "           1       0.85      0.71      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7674147478869134\n",
      "pre:  0.8478123018389346\n",
      "rec:  0.7055408970976254\n",
      "ma F1:  0.7673815301170425\n",
      "mi F1:  0.7674147478869136\n",
      "we F1:  0.7676723881507902\n",
      "Eval Loss:  0.22034852206707\n",
      "Eval Loss:  0.19378268718719482\n",
      "Eval Loss:  0.2651917338371277\n",
      "Eval Loss:  0.2629995048046112\n",
      "Eval Loss:  0.28255340456962585\n",
      "Eval Loss:  0.23172076046466827\n",
      "Eval Loss:  0.15414808690547943\n",
      "Eval Loss:  0.35767197608947754\n",
      "Eval Loss:  0.19627176225185394\n",
      "Eval Loss:  0.24262535572052002\n",
      "Eval Loss:  0.1951090395450592\n",
      "Eval Loss:  0.22925549745559692\n",
      "Eval Loss:  0.2542232871055603\n",
      "Eval Loss:  0.21826279163360596\n",
      "Eval Loss:  0.2048877328634262\n",
      "Eval Loss:  0.25593301653862\n",
      "Eval Loss:  0.2625992000102997\n",
      "Eval Loss:  0.19237156212329865\n",
      "Eval Loss:  0.31331852078437805\n",
      "Eval Loss:  0.2860139310359955\n",
      "Eval Loss:  0.21832653880119324\n",
      "Eval Loss:  0.20682060718536377\n",
      "Eval Loss:  0.2578155994415283\n",
      "Eval Loss:  0.2415679693222046\n",
      "Eval Loss:  0.2636205554008484\n",
      "Eval Loss:  0.16095325350761414\n",
      "Eval Loss:  0.2771742045879364\n",
      "Eval Loss:  0.34641802310943604\n",
      "[[17847   781]\n",
      " [ 2133  8699]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18628\n",
      "           1       0.92      0.80      0.86     10832\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.91      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9010862186014935\n",
      "pre:  0.9176160337552742\n",
      "rec:  0.8030834564254062\n",
      "ma F1:  0.8905307109628544\n",
      "mi F1:  0.9010862186014935\n",
      "we F1:  0.8995262004196571\n",
      "29460 461\n",
      "Loss:  0.046041958034038544\n",
      "Loss:  0.05791151151061058\n",
      "Loss:  0.06966368108987808\n",
      "33 **********\n",
      "Epoch:  1781.8716373443604  fold:  3  kers:  32\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.0696348324418068\n",
      "Loss:  0.07996408641338348\n",
      "Loss:  0.058347295969724655\n",
      "34 **********\n",
      "Epoch:  1821.3181657791138  fold:  3  kers:  32\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.08792196959257126\n",
      "Loss:  0.05644530430436134\n",
      "Loss:  0.05968965217471123\n",
      "35 **********\n",
      "Epoch:  1860.7646932601929  fold:  3  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.5031542778015137\n",
      "Eval Loss:  0.1403462290763855\n",
      "Eval Loss:  0.8110332489013672\n",
      "[[1237  299]\n",
      " [ 503 1392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1536\n",
      "           1       0.82      0.73      0.78      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.77      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7662489070241912\n",
      "pre:  0.8231815493790656\n",
      "rec:  0.7345646437994723\n",
      "ma F1:  0.7657708685316047\n",
      "mi F1:  0.7662489070241914\n",
      "we F1:  0.766878067362821\n",
      "Eval Loss:  0.1857660561800003\n",
      "Eval Loss:  0.1688925325870514\n",
      "Eval Loss:  0.2522847056388855\n",
      "Eval Loss:  0.22692477703094482\n",
      "Eval Loss:  0.27298086881637573\n",
      "Eval Loss:  0.24376487731933594\n",
      "Eval Loss:  0.14071281254291534\n",
      "Eval Loss:  0.32304975390434265\n",
      "Eval Loss:  0.16932502388954163\n",
      "Eval Loss:  0.2381923645734787\n",
      "Eval Loss:  0.20629577338695526\n",
      "Eval Loss:  0.19999302923679352\n",
      "Eval Loss:  0.2319713979959488\n",
      "Eval Loss:  0.20266027748584747\n",
      "Eval Loss:  0.205143541097641\n",
      "Eval Loss:  0.20372097194194794\n",
      "Eval Loss:  0.25865140557289124\n",
      "Eval Loss:  0.17550531029701233\n",
      "Eval Loss:  0.2666097581386566\n",
      "Eval Loss:  0.27717408537864685\n",
      "Eval Loss:  0.20604264736175537\n",
      "Eval Loss:  0.23568829894065857\n",
      "Eval Loss:  0.2480390965938568\n",
      "Eval Loss:  0.2317984700202942\n",
      "Eval Loss:  0.23868359625339508\n",
      "Eval Loss:  0.14243900775909424\n",
      "Eval Loss:  0.24980147182941437\n",
      "Eval Loss:  0.32884451746940613\n",
      "[[17574  1054]\n",
      " [ 1670  9162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18628\n",
      "           1       0.90      0.85      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9075356415478615\n",
      "pre:  0.8968285043069695\n",
      "rec:  0.8458271787296898\n",
      "ma F1:  0.8993275193546382\n",
      "mi F1:  0.9075356415478615\n",
      "we F1:  0.9069345712588665\n",
      "29460 461\n",
      "Loss:  0.02307777851819992\n",
      "Loss:  0.052098348736763\n",
      "Loss:  0.09408874809741974\n",
      "36 **********\n",
      "Epoch:  1939.023445367813  fold:  3  kers:  32\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.053278565406799316\n",
      "Loss:  0.06971558183431625\n",
      "Loss:  0.0692681148648262\n",
      "37 **********\n",
      "Epoch:  1978.4580054283142  fold:  3  kers:  32\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.08073998242616653\n",
      "Loss:  0.05017447844147682\n",
      "Loss:  0.10607849061489105\n",
      "38 **********\n",
      "Epoch:  2017.8975520133972  fold:  3  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.3518829345703125\n",
      "Eval Loss:  0.1356317400932312\n",
      "Eval Loss:  0.8260498642921448\n",
      "[[1208  328]\n",
      " [ 444 1451]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1536\n",
      "           1       0.82      0.77      0.79      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.78      0.77      3431\n",
      "weighted avg       0.78      0.77      0.78      3431\n",
      "\n",
      "acc:  0.774992713494608\n",
      "pre:  0.8156267566048342\n",
      "rec:  0.7656992084432718\n",
      "ma F1:  0.7738583515073196\n",
      "mi F1:  0.774992713494608\n",
      "we F1:  0.7755342196284576\n",
      "Eval Loss:  0.19532249867916107\n",
      "Eval Loss:  0.17508354783058167\n",
      "Eval Loss:  0.25329962372779846\n",
      "Eval Loss:  0.22326725721359253\n",
      "Eval Loss:  0.28359559178352356\n",
      "Eval Loss:  0.2201141119003296\n",
      "Eval Loss:  0.15251553058624268\n",
      "Eval Loss:  0.31960079073905945\n",
      "Eval Loss:  0.14795184135437012\n",
      "Eval Loss:  0.23080773651599884\n",
      "Eval Loss:  0.21178767085075378\n",
      "Eval Loss:  0.17501391470432281\n",
      "Eval Loss:  0.20569954812526703\n",
      "Eval Loss:  0.2132759541273117\n",
      "Eval Loss:  0.18616236746311188\n",
      "Eval Loss:  0.2228303700685501\n",
      "Eval Loss:  0.2493652105331421\n",
      "Eval Loss:  0.17016857862472534\n",
      "Eval Loss:  0.2767200469970703\n",
      "Eval Loss:  0.2598899304866791\n",
      "Eval Loss:  0.19622865319252014\n",
      "Eval Loss:  0.22550755739212036\n",
      "Eval Loss:  0.23151792585849762\n",
      "Eval Loss:  0.24539577960968018\n",
      "Eval Loss:  0.21931065618991852\n",
      "Eval Loss:  0.1506171077489853\n",
      "Eval Loss:  0.22551865875720978\n",
      "Eval Loss:  0.3078274726867676\n",
      "[[17320  1308]\n",
      " [ 1366  9466]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     18628\n",
      "           1       0.88      0.87      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9092328581126952\n",
      "pre:  0.8785966214961946\n",
      "rec:  0.8738921713441654\n",
      "ma F1:  0.9022879856391692\n",
      "mi F1:  0.9092328581126952\n",
      "we F1:  0.9091815718122795\n",
      "29460 461\n",
      "Loss:  0.07793185859918594\n",
      "Loss:  0.05764839053153992\n",
      "Loss:  0.05439450591802597\n",
      "39 **********\n",
      "Epoch:  2097.1426663398743  fold:  3  kers:  32\n",
      "epoch:  40\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.053155411034822464\n",
      "Loss:  0.043701764196157455\n",
      "Loss:  0.0820370763540268\n",
      "40 **********\n",
      "Epoch:  2139.6190938949585  fold:  3  kers:  32\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.06053447350859642\n",
      "Loss:  0.04872416332364082\n",
      "Loss:  0.05459003150463104\n",
      "41 **********\n",
      "Epoch:  2181.952901363373  fold:  3  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.5070400834083557\n",
      "Eval Loss:  0.15008151531219482\n",
      "Eval Loss:  1.0261870622634888\n",
      "[[1294  242]\n",
      " [ 560 1335]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1536\n",
      "           1       0.85      0.70      0.77      1895\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.77      0.77      3431\n",
      "weighted avg       0.78      0.77      0.77      3431\n",
      "\n",
      "acc:  0.7662489070241912\n",
      "pre:  0.8465440710209258\n",
      "rec:  0.7044854881266491\n",
      "ma F1:  0.7662155227492082\n",
      "mi F1:  0.7662489070241914\n",
      "we F1:  0.7665078387179621\n",
      "Eval Loss:  0.1934324949979782\n",
      "Eval Loss:  0.16506926715373993\n",
      "Eval Loss:  0.28058922290802\n",
      "Eval Loss:  0.23203900456428528\n",
      "Eval Loss:  0.28104081749916077\n",
      "Eval Loss:  0.22193175554275513\n",
      "Eval Loss:  0.14113962650299072\n",
      "Eval Loss:  0.3182451128959656\n",
      "Eval Loss:  0.14622174203395844\n",
      "Eval Loss:  0.21322989463806152\n",
      "Eval Loss:  0.21197041869163513\n",
      "Eval Loss:  0.19668328762054443\n",
      "Eval Loss:  0.21039731800556183\n",
      "Eval Loss:  0.1973394900560379\n",
      "Eval Loss:  0.17074553668498993\n",
      "Eval Loss:  0.24293744564056396\n",
      "Eval Loss:  0.23984141647815704\n",
      "Eval Loss:  0.1605643928050995\n",
      "Eval Loss:  0.2745462954044342\n",
      "Eval Loss:  0.2570939362049103\n",
      "Eval Loss:  0.20897312462329865\n",
      "Eval Loss:  0.21220819652080536\n",
      "Eval Loss:  0.24396038055419922\n",
      "Eval Loss:  0.23047621548175812\n",
      "Eval Loss:  0.21604780852794647\n",
      "Eval Loss:  0.14362971484661102\n",
      "Eval Loss:  0.252558171749115\n",
      "Eval Loss:  0.32216909527778625\n",
      "[[17757   871]\n",
      " [ 1781  9051]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     18628\n",
      "           1       0.91      0.84      0.87     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.909979633401222\n",
      "pre:  0.9122152791775852\n",
      "rec:  0.8355797636632201\n",
      "ma F1:  0.901365736994357\n",
      "mi F1:  0.909979633401222\n",
      "we F1:  0.9090792605858938\n",
      "29460 461\n",
      "Loss:  0.0556122325360775\n",
      "Loss:  0.04586641117930412\n",
      "Loss:  0.10363753139972687\n",
      "42 **********\n",
      "Epoch:  2260.907791852951  fold:  3  kers:  32\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.055345918983221054\n",
      "Loss:  0.03869108483195305\n",
      "Loss:  0.07583566009998322\n",
      "43 **********\n",
      "Epoch:  2300.3303837776184  fold:  3  kers:  32\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.04431864619255066\n",
      "Loss:  0.06450975686311722\n",
      "Loss:  0.06546974182128906\n",
      "44 **********\n",
      "Epoch:  2339.7569653987885  fold:  3  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.37698429822921753\n",
      "Eval Loss:  0.12768737971782684\n",
      "Eval Loss:  1.009556531906128\n",
      "[[1210  326]\n",
      " [ 485 1410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75      1536\n",
      "           1       0.81      0.74      0.78      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7636257650830661\n",
      "pre:  0.8122119815668203\n",
      "rec:  0.7440633245382586\n",
      "ma F1:  0.7628198358285683\n",
      "mi F1:  0.7636257650830661\n",
      "we F1:  0.7642664788403921\n",
      "Eval Loss:  0.1854538768529892\n",
      "Eval Loss:  0.16444948315620422\n",
      "Eval Loss:  0.27529647946357727\n",
      "Eval Loss:  0.21002960205078125\n",
      "Eval Loss:  0.276800274848938\n",
      "Eval Loss:  0.20773661136627197\n",
      "Eval Loss:  0.14378957450389862\n",
      "Eval Loss:  0.3189530372619629\n",
      "Eval Loss:  0.14862008392810822\n",
      "Eval Loss:  0.20750832557678223\n",
      "Eval Loss:  0.21116825938224792\n",
      "Eval Loss:  0.1798689365386963\n",
      "Eval Loss:  0.2062545269727707\n",
      "Eval Loss:  0.2026471644639969\n",
      "Eval Loss:  0.1694784313440323\n",
      "Eval Loss:  0.21391178667545319\n",
      "Eval Loss:  0.23818224668502808\n",
      "Eval Loss:  0.16041994094848633\n",
      "Eval Loss:  0.26679614186286926\n",
      "Eval Loss:  0.25778740644454956\n",
      "Eval Loss:  0.1824750006198883\n",
      "Eval Loss:  0.22819963097572327\n",
      "Eval Loss:  0.23956312239170074\n",
      "Eval Loss:  0.23906370997428894\n",
      "Eval Loss:  0.2142653614282608\n",
      "Eval Loss:  0.1433233916759491\n",
      "Eval Loss:  0.22758983075618744\n",
      "Eval Loss:  0.31626763939857483\n",
      "[[17582  1046]\n",
      " [ 1514  9318]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18628\n",
      "           1       0.90      0.86      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9131025118805159\n",
      "pre:  0.8990737167116943\n",
      "rec:  0.8602289512555391\n",
      "ma F1:  0.905680593179744\n",
      "mi F1:  0.9131025118805159\n",
      "we F1:  0.9126821999308594\n",
      "29460 461\n",
      "Loss:  0.06667912751436234\n",
      "Loss:  0.06541310250759125\n",
      "Loss:  0.06621436774730682\n",
      "45 **********\n",
      "Epoch:  2417.6885919570923  fold:  3  kers:  32\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.056568246334791183\n",
      "Loss:  0.06116577237844467\n",
      "Loss:  0.07512747496366501\n",
      "46 **********\n",
      "Epoch:  2457.1351199150085  fold:  3  kers:  32\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.07198528945446014\n",
      "Loss:  0.06293436884880066\n",
      "Loss:  0.05005040019750595\n",
      "47 **********\n",
      "Epoch:  2496.529786348343  fold:  3  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.43355628848075867\n",
      "Eval Loss:  0.1380632221698761\n",
      "Eval Loss:  0.9888862371444702\n",
      "[[1236  300]\n",
      " [ 507 1388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75      1536\n",
      "           1       0.82      0.73      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.77      3431\n",
      "\n",
      "acc:  0.7647916059457884\n",
      "pre:  0.8222748815165877\n",
      "rec:  0.7324538258575198\n",
      "ma F1:  0.7643290633133641\n",
      "mi F1:  0.7647916059457883\n",
      "we F1:  0.7654215159781028\n",
      "Eval Loss:  0.1665717363357544\n",
      "Eval Loss:  0.15777705609798431\n",
      "Eval Loss:  0.24959035217761993\n",
      "Eval Loss:  0.2161385416984558\n",
      "Eval Loss:  0.2745063006877899\n",
      "Eval Loss:  0.2008955478668213\n",
      "Eval Loss:  0.141210675239563\n",
      "Eval Loss:  0.31814050674438477\n",
      "Eval Loss:  0.14381060004234314\n",
      "Eval Loss:  0.21164631843566895\n",
      "Eval Loss:  0.20584999024868011\n",
      "Eval Loss:  0.18453723192214966\n",
      "Eval Loss:  0.20675526559352875\n",
      "Eval Loss:  0.20972557365894318\n",
      "Eval Loss:  0.15568459033966064\n",
      "Eval Loss:  0.2088218629360199\n",
      "Eval Loss:  0.22504569590091705\n",
      "Eval Loss:  0.15219277143478394\n",
      "Eval Loss:  0.25893500447273254\n",
      "Eval Loss:  0.25720253586769104\n",
      "Eval Loss:  0.1882268190383911\n",
      "Eval Loss:  0.22189374268054962\n",
      "Eval Loss:  0.2272949516773224\n",
      "Eval Loss:  0.241220623254776\n",
      "Eval Loss:  0.21604189276695251\n",
      "Eval Loss:  0.14662572741508484\n",
      "Eval Loss:  0.22943653166294098\n",
      "Eval Loss:  0.30667364597320557\n",
      "[[17650   978]\n",
      " [ 1525  9307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18628\n",
      "           1       0.90      0.86      0.88     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.90      0.91     29460\n",
      "weighted avg       0.91      0.92      0.91     29460\n",
      "\n",
      "acc:  0.9150373387644264\n",
      "pre:  0.9049100631988333\n",
      "rec:  0.8592134416543574\n",
      "ma F1:  0.9076291147205722\n",
      "mi F1:  0.9150373387644264\n",
      "we F1:  0.9145516263645717\n",
      "29460 461\n",
      "Loss:  0.03958817943930626\n",
      "Loss:  0.06646903604269028\n",
      "Loss:  0.04162622615695\n",
      "48 **********\n",
      "Epoch:  2574.556159734726  fold:  3  kers:  32\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.06244195997714996\n",
      "Loss:  0.05379088222980499\n",
      "Loss:  0.07563361525535583\n",
      "49 **********\n",
      "Epoch:  2613.9877276420593  fold:  3  kers:  32\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.056842681020498276\n",
      "Loss:  0.06570795178413391\n",
      "Loss:  0.031009603291749954\n",
      "50 **********\n",
      "Epoch:  2653.404335975647  fold:  3  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.40843144059181213\n",
      "Eval Loss:  0.16515842080116272\n",
      "Eval Loss:  1.0243457555770874\n",
      "[[1220  316]\n",
      " [ 508 1387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75      1536\n",
      "           1       0.81      0.73      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.76      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7598367822792189\n",
      "pre:  0.8144450968878449\n",
      "rec:  0.7319261213720316\n",
      "ma F1:  0.7592664497705697\n",
      "mi F1:  0.7598367822792189\n",
      "we F1:  0.7604924939059293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.18168610334396362\n",
      "Eval Loss:  0.14822229743003845\n",
      "Eval Loss:  0.26362550258636475\n",
      "Eval Loss:  0.20970216393470764\n",
      "Eval Loss:  0.2890499234199524\n",
      "Eval Loss:  0.19293494522571564\n",
      "Eval Loss:  0.1372591108083725\n",
      "Eval Loss:  0.3127385377883911\n",
      "Eval Loss:  0.12809598445892334\n",
      "Eval Loss:  0.20373426377773285\n",
      "Eval Loss:  0.21432015299797058\n",
      "Eval Loss:  0.17353394627571106\n",
      "Eval Loss:  0.1999383121728897\n",
      "Eval Loss:  0.21186292171478271\n",
      "Eval Loss:  0.1624782830476761\n",
      "Eval Loss:  0.21616654098033905\n",
      "Eval Loss:  0.23462986946105957\n",
      "Eval Loss:  0.1465379148721695\n",
      "Eval Loss:  0.26549071073532104\n",
      "Eval Loss:  0.24759571254253387\n",
      "Eval Loss:  0.1985217034816742\n",
      "Eval Loss:  0.21698233485221863\n",
      "Eval Loss:  0.23427334427833557\n",
      "Eval Loss:  0.23453205823898315\n",
      "Eval Loss:  0.20643137395381927\n",
      "Eval Loss:  0.1420568823814392\n",
      "Eval Loss:  0.23690399527549744\n",
      "Eval Loss:  0.3077504336833954\n",
      "[[17663   965]\n",
      " [ 1551  9281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     18628\n",
      "           1       0.91      0.86      0.88     10832\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.91     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9145960624575696\n",
      "pre:  0.9058169041577201\n",
      "rec:  0.8568131462333826\n",
      "ma F1:  0.9070734320399982\n",
      "mi F1:  0.9145960624575697\n",
      "we F1:  0.9140701424593953\n",
      "29460 461\n",
      "Loss:  0.06400029361248016\n",
      "Loss:  0.04189961031079292\n",
      "Loss:  0.07576597481966019\n",
      "51 **********\n",
      "Epoch:  2731.6072375774384  fold:  3  kers:  32\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.02561449259519577\n",
      "Loss:  0.09890220314264297\n",
      "Loss:  0.09032846987247467\n",
      "52 **********\n",
      "Epoch:  2771.0976481437683  fold:  3  kers:  32\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.06499701738357544\n",
      "Loss:  0.07145226001739502\n",
      "Loss:  0.05445532500743866\n",
      "53 **********\n",
      "Epoch:  2810.5730991363525  fold:  3  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.4046540856361389\n",
      "Eval Loss:  0.14253807067871094\n",
      "Eval Loss:  0.93055260181427\n",
      "[[1225  311]\n",
      " [ 501 1394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75      1536\n",
      "           1       0.82      0.74      0.77      1895\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.77      0.76      3431\n",
      "weighted avg       0.77      0.76      0.76      3431\n",
      "\n",
      "acc:  0.7633343048673856\n",
      "pre:  0.8175953079178886\n",
      "rec:  0.7356200527704485\n",
      "ma F1:  0.7627587029089175\n",
      "mi F1:  0.7633343048673855\n",
      "we F1:  0.7639814313295685\n",
      "Eval Loss:  0.17636093497276306\n",
      "Eval Loss:  0.16492532193660736\n",
      "Eval Loss:  0.24479052424430847\n",
      "Eval Loss:  0.2012048363685608\n",
      "Eval Loss:  0.2867332696914673\n",
      "Eval Loss:  0.1870012730360031\n",
      "Eval Loss:  0.13113544881343842\n",
      "Eval Loss:  0.29128554463386536\n",
      "Eval Loss:  0.12610755860805511\n",
      "Eval Loss:  0.19057562947273254\n",
      "Eval Loss:  0.20170490443706512\n",
      "Eval Loss:  0.16008275747299194\n",
      "Eval Loss:  0.19862580299377441\n",
      "Eval Loss:  0.20218870043754578\n",
      "Eval Loss:  0.16520261764526367\n",
      "Eval Loss:  0.226726695895195\n",
      "Eval Loss:  0.2236911505460739\n",
      "Eval Loss:  0.14852462708950043\n",
      "Eval Loss:  0.2635791003704071\n",
      "Eval Loss:  0.24232807755470276\n",
      "Eval Loss:  0.1862206608057022\n",
      "Eval Loss:  0.2239280343055725\n",
      "Eval Loss:  0.21786098182201385\n",
      "Eval Loss:  0.23507772386074066\n",
      "Eval Loss:  0.19452142715454102\n",
      "Eval Loss:  0.14600872993469238\n",
      "Eval Loss:  0.2253054827451706\n",
      "Eval Loss:  0.30170729756355286\n",
      "[[17643   985]\n",
      " [ 1451  9381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     18628\n",
      "           1       0.90      0.87      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9173116089613035\n",
      "pre:  0.9049778120779471\n",
      "rec:  0.8660450516986706\n",
      "ma F1:  0.9102528992136718\n",
      "mi F1:  0.9173116089613035\n",
      "we F1:  0.9169134779104204\n",
      "29460 461\n",
      "Loss:  0.028677169233560562\n",
      "Loss:  0.04946637526154518\n",
      "Loss:  0.03935603052377701\n",
      "54 **********\n",
      "Epoch:  2888.68923163414  fold:  3  kers:  32\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.04643396660685539\n",
      "Loss:  0.057596106082201004\n",
      "Loss:  0.04676922410726547\n",
      "55 **********\n",
      "Epoch:  2928.096863746643  fold:  3  kers:  32\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.055228427052497864\n",
      "Loss:  0.11305665224790573\n",
      "Loss:  0.03744719550013542\n",
      "56 **********\n",
      "Epoch:  2967.498512029648  fold:  3  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.4133351743221283\n",
      "Eval Loss:  0.11518201231956482\n",
      "Eval Loss:  0.924923300743103\n",
      "[[1173  363]\n",
      " [ 488 1407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      1536\n",
      "           1       0.79      0.74      0.77      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.76      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7519673564558438\n",
      "pre:  0.7949152542372881\n",
      "rec:  0.7424802110817942\n",
      "ma F1:  0.7508082483535682\n",
      "mi F1:  0.7519673564558438\n",
      "we F1:  0.7525865381344099\n",
      "Eval Loss:  0.16967181861400604\n",
      "Eval Loss:  0.18154363334178925\n",
      "Eval Loss:  0.22707228362560272\n",
      "Eval Loss:  0.192843958735466\n",
      "Eval Loss:  0.2819037437438965\n",
      "Eval Loss:  0.1875075101852417\n",
      "Eval Loss:  0.13006682693958282\n",
      "Eval Loss:  0.28688156604766846\n",
      "Eval Loss:  0.13633589446544647\n",
      "Eval Loss:  0.19777512550354004\n",
      "Eval Loss:  0.2129237949848175\n",
      "Eval Loss:  0.16690859198570251\n",
      "Eval Loss:  0.1841389536857605\n",
      "Eval Loss:  0.2041107714176178\n",
      "Eval Loss:  0.17156173288822174\n",
      "Eval Loss:  0.20993173122406006\n",
      "Eval Loss:  0.2340836375951767\n",
      "Eval Loss:  0.1420217901468277\n",
      "Eval Loss:  0.2511920630931854\n",
      "Eval Loss:  0.2375243604183197\n",
      "Eval Loss:  0.1691470742225647\n",
      "Eval Loss:  0.24633058905601501\n",
      "Eval Loss:  0.2118409126996994\n",
      "Eval Loss:  0.2333526313304901\n",
      "Eval Loss:  0.19238796830177307\n",
      "Eval Loss:  0.14699551463127136\n",
      "Eval Loss:  0.20279701054096222\n",
      "Eval Loss:  0.3007305860519409\n",
      "[[17452  1176]\n",
      " [ 1219  9613]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     18628\n",
      "           1       0.89      0.89      0.89     10832\n",
      "\n",
      "    accuracy                           0.92     29460\n",
      "   macro avg       0.91      0.91      0.91     29460\n",
      "weighted avg       0.92      0.92      0.92     29460\n",
      "\n",
      "acc:  0.9187033265444671\n",
      "pre:  0.891000092686996\n",
      "rec:  0.8874630723781388\n",
      "ma F1:  0.9125086142776111\n",
      "mi F1:  0.9187033265444671\n",
      "we F1:  0.9186693461097848\n",
      "29460 461\n",
      "Loss:  0.07131040841341019\n",
      "Loss:  0.046308357268571854\n",
      "Loss:  0.06864194571971893\n",
      "57 **********\n",
      "Epoch:  3045.5248856544495  fold:  3  kers:  32\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.06709793955087662\n",
      "Loss:  0.05799282342195511\n",
      "Loss:  0.06070511415600777\n",
      "58 **********\n",
      "Epoch:  3084.9225442409515  fold:  3  kers:  32\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.0450984388589859\n",
      "Loss:  0.0704629048705101\n",
      "Loss:  0.0715363472700119\n",
      "59 **********\n",
      "Epoch:  3127.6173870563507  fold:  3  kers:  32\n",
      "Eval Loss:  0.3619728982448578\n",
      "Eval Loss:  0.11389490962028503\n",
      "Eval Loss:  0.9542679786682129\n",
      "[[1160  376]\n",
      " [ 488 1407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      1536\n",
      "           1       0.79      0.74      0.77      1895\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.75      0.75      3431\n",
      "weighted avg       0.75      0.75      0.75      3431\n",
      "\n",
      "acc:  0.7481783736519965\n",
      "pre:  0.7891194615816041\n",
      "rec:  0.7424802110817942\n",
      "ma F1:  0.7468664693778846\n",
      "mi F1:  0.7481783736519965\n",
      "we F1:  0.748773245225683\n",
      "update!  Acc:  0.7828621393179831\n",
      "Epoch:  3131.6695518493652  fold:  3  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29520 3371\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29520 462\n",
      "Loss:  0.1720971167087555\n",
      "Loss:  0.17019689083099365\n",
      "Loss:  0.16298234462738037\n",
      "0 **********\n",
      "Epoch:  52.13360595703125  fold:  4  kers:  32\n",
      "epoch:  1\n",
      "29520 462\n",
      "Loss:  0.15267115831375122\n",
      "Loss:  0.14776624739170074\n",
      "Loss:  0.1402611881494522\n",
      "1 **********\n",
      "Epoch:  91.79256534576416  fold:  4  kers:  32\n",
      "epoch:  2\n",
      "29520 462\n",
      "Loss:  0.12331906706094742\n",
      "Loss:  0.14052338898181915\n",
      "Loss:  0.10662020742893219\n",
      "2 **********\n",
      "Epoch:  131.42659258842468  fold:  4  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.26893994212150574\n",
      "Eval Loss:  0.3767274022102356\n",
      "Eval Loss:  0.09401810169219971\n",
      "[[2788  349]\n",
      " [ 164   70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92      3137\n",
      "           1       0.17      0.30      0.21       234\n",
      "\n",
      "    accuracy                           0.85      3371\n",
      "   macro avg       0.56      0.59      0.57      3371\n",
      "weighted avg       0.89      0.85      0.87      3371\n",
      "\n",
      "acc:  0.8478196380895877\n",
      "pre:  0.16706443914081145\n",
      "rec:  0.29914529914529914\n",
      "ma F1:  0.5650724060685337\n",
      "mi F1:  0.8478196380895877\n",
      "we F1:  0.8670647587385555\n",
      "update!  Acc:  0.8478196380895877\n",
      "Eval Loss:  0.42162904143333435\n",
      "Eval Loss:  0.4483136534690857\n",
      "Eval Loss:  0.4073827266693115\n",
      "Eval Loss:  0.4744127690792084\n",
      "Eval Loss:  0.4808081090450287\n",
      "Eval Loss:  0.4030930697917938\n",
      "Eval Loss:  0.38477614521980286\n",
      "Eval Loss:  0.4986776113510132\n",
      "Eval Loss:  0.3897952139377594\n",
      "Eval Loss:  0.36939048767089844\n",
      "Eval Loss:  0.49122461676597595\n",
      "Eval Loss:  0.4273098409175873\n",
      "Eval Loss:  0.44430893659591675\n",
      "Eval Loss:  0.388833612203598\n",
      "Eval Loss:  0.3558097183704376\n",
      "Eval Loss:  0.3990288972854614\n",
      "Eval Loss:  0.4688946604728699\n",
      "Eval Loss:  0.4729863405227661\n",
      "Eval Loss:  0.38624101877212524\n",
      "Eval Loss:  0.41388043761253357\n",
      "Eval Loss:  0.49787455797195435\n",
      "Eval Loss:  0.48462167382240295\n",
      "Eval Loss:  0.4845627248287201\n",
      "Eval Loss:  0.4045218825340271\n",
      "Eval Loss:  0.37774860858917236\n",
      "Eval Loss:  0.38708725571632385\n",
      "Eval Loss:  0.4432614743709564\n",
      "Eval Loss:  0.4644668400287628\n",
      "[[14321  2706]\n",
      " [ 2847  9646]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84     17027\n",
      "           1       0.78      0.77      0.78     12493\n",
      "\n",
      "    accuracy                           0.81     29520\n",
      "   macro avg       0.81      0.81      0.81     29520\n",
      "weighted avg       0.81      0.81      0.81     29520\n",
      "\n",
      "acc:  0.811890243902439\n",
      "pre:  0.7809261658031088\n",
      "rec:  0.7721123829344433\n",
      "ma F1:  0.8070510509213271\n",
      "mi F1:  0.811890243902439\n",
      "we F1:  0.8117442917718857\n",
      "29520 462\n",
      "Loss:  0.10075729340314865\n",
      "Loss:  0.12299082428216934\n",
      "Loss:  0.09421328455209732\n",
      "3 **********\n",
      "Epoch:  209.944650888443  fold:  4  kers:  32\n",
      "epoch:  4\n",
      "29520 462\n",
      "Loss:  0.08699867129325867\n",
      "Loss:  0.09523157775402069\n",
      "Loss:  0.100485660135746\n",
      "4 **********\n",
      "Epoch:  249.64450407028198  fold:  4  kers:  32\n",
      "epoch:  5\n",
      "29520 462\n",
      "Loss:  0.12015329301357269\n",
      "Loss:  0.0965472087264061\n",
      "Loss:  0.10826323181390762\n",
      "5 **********\n",
      "Epoch:  289.29348850250244  fold:  4  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.08101856708526611\n",
      "Eval Loss:  0.13651920855045319\n",
      "Eval Loss:  0.04245447367429733\n",
      "[[3076   61]\n",
      " [ 220   14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3137\n",
      "           1       0.19      0.06      0.09       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.56      0.52      0.52      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.916641946010086\n",
      "pre:  0.18666666666666668\n",
      "rec:  0.05982905982905983\n",
      "ma F1:  0.5234669334947181\n",
      "mi F1:  0.916641946010086\n",
      "we F1:  0.8962256079990006\n",
      "update!  Acc:  0.916641946010086\n",
      "Eval Loss:  0.4091673195362091\n",
      "Eval Loss:  0.44802626967430115\n",
      "Eval Loss:  0.4643006920814514\n",
      "Eval Loss:  0.4902154207229614\n",
      "Eval Loss:  0.5266406536102295\n",
      "Eval Loss:  0.42856669425964355\n",
      "Eval Loss:  0.3987964391708374\n",
      "Eval Loss:  0.5391544699668884\n",
      "Eval Loss:  0.4695889949798584\n",
      "Eval Loss:  0.37674444913864136\n",
      "Eval Loss:  0.5412869453430176\n",
      "Eval Loss:  0.44527721405029297\n",
      "Eval Loss:  0.4974844753742218\n",
      "Eval Loss:  0.4035181701183319\n",
      "Eval Loss:  0.3835334777832031\n",
      "Eval Loss:  0.4096038043498993\n",
      "Eval Loss:  0.4231448769569397\n",
      "Eval Loss:  0.5261667966842651\n",
      "Eval Loss:  0.4100634753704071\n",
      "Eval Loss:  0.442414790391922\n",
      "Eval Loss:  0.5699633359909058\n",
      "Eval Loss:  0.5587302446365356\n",
      "Eval Loss:  0.5292105674743652\n",
      "Eval Loss:  0.4589079022407532\n",
      "Eval Loss:  0.3905057907104492\n",
      "Eval Loss:  0.4205811619758606\n",
      "Eval Loss:  0.46909376978874207\n",
      "Eval Loss:  0.5160506367683411\n",
      "[[16145   882]\n",
      " [ 4593  7900]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86     17027\n",
      "           1       0.90      0.63      0.74     12493\n",
      "\n",
      "    accuracy                           0.81     29520\n",
      "   macro avg       0.84      0.79      0.80     29520\n",
      "weighted avg       0.83      0.81      0.81     29520\n",
      "\n",
      "acc:  0.8145325203252033\n",
      "pre:  0.8995672967433387\n",
      "rec:  0.6323541183062515\n",
      "ma F1:  0.7988400963780744\n",
      "mi F1:  0.8145325203252033\n",
      "we F1:  0.8074695020998793\n",
      "29520 462\n",
      "Loss:  0.11266253143548965\n",
      "Loss:  0.08052293211221695\n",
      "Loss:  0.11216086894273758\n",
      "6 **********\n",
      "Epoch:  367.94917917251587  fold:  4  kers:  32\n",
      "epoch:  7\n",
      "29520 462\n",
      "Loss:  0.13721734285354614\n",
      "Loss:  0.07484693825244904\n",
      "Loss:  0.09589561074972153\n",
      "7 **********\n",
      "Epoch:  407.7776861190796  fold:  4  kers:  32\n",
      "epoch:  8\n",
      "29520 462\n",
      "Loss:  0.10615184158086777\n",
      "Loss:  0.0864534005522728\n",
      "Loss:  0.06102105975151062\n",
      "8 **********\n",
      "Epoch:  447.45359992980957  fold:  4  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.08245658129453659\n",
      "Eval Loss:  0.10598260164260864\n",
      "Eval Loss:  0.029815787449479103\n",
      "[[3108   29]\n",
      " [ 228    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.17      0.03      0.04       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.55      0.51      0.50      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.92376149510531\n",
      "pre:  0.17142857142857143\n",
      "rec:  0.02564102564102564\n",
      "ma F1:  0.5024531410715486\n",
      "mi F1:  0.92376149510531\n",
      "we F1:  0.8967336542114615\n",
      "update!  Acc:  0.92376149510531\n",
      "Eval Loss:  0.41260579228401184\n",
      "Eval Loss:  0.4405175745487213\n",
      "Eval Loss:  0.4698781371116638\n",
      "Eval Loss:  0.4675147235393524\n",
      "Eval Loss:  0.5129649043083191\n",
      "Eval Loss:  0.4084811210632324\n",
      "Eval Loss:  0.3797414004802704\n",
      "Eval Loss:  0.5229610800743103\n",
      "Eval Loss:  0.4887272119522095\n",
      "Eval Loss:  0.3687622547149658\n",
      "Eval Loss:  0.5226815938949585\n",
      "Eval Loss:  0.4321213662624359\n",
      "Eval Loss:  0.4874621033668518\n",
      "Eval Loss:  0.39638248085975647\n",
      "Eval Loss:  0.39247602224349976\n",
      "Eval Loss:  0.39715462923049927\n",
      "Eval Loss:  0.403516948223114\n",
      "Eval Loss:  0.5018174052238464\n",
      "Eval Loss:  0.4237003028392792\n",
      "Eval Loss:  0.423332154750824\n",
      "Eval Loss:  0.5628229379653931\n",
      "Eval Loss:  0.5317301154136658\n",
      "Eval Loss:  0.5206764936447144\n",
      "Eval Loss:  0.4645477533340454\n",
      "Eval Loss:  0.4337165355682373\n",
      "Eval Loss:  0.44458094239234924\n",
      "Eval Loss:  0.4427441954612732\n",
      "Eval Loss:  0.4968617260456085\n",
      "[[16440   587]\n",
      " [ 4866  7627]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86     17027\n",
      "           1       0.93      0.61      0.74     12493\n",
      "\n",
      "    accuracy                           0.82     29520\n",
      "   macro avg       0.85      0.79      0.80     29520\n",
      "weighted avg       0.84      0.82      0.81     29520\n",
      "\n",
      "acc:  0.8152777777777778\n",
      "pre:  0.928536644752861\n",
      "rec:  0.6105018810533899\n",
      "ma F1:  0.7972028449439741\n",
      "mi F1:  0.8152777777777778\n",
      "we F1:  0.8065018061908215\n",
      "29520 462\n",
      "Loss:  0.054115477949380875\n",
      "Loss:  0.08637585490942001\n",
      "Loss:  0.09199918061494827\n",
      "9 **********\n",
      "Epoch:  525.7692005634308  fold:  4  kers:  32\n",
      "epoch:  10\n",
      "29520 462\n",
      "Loss:  0.06934066861867905\n",
      "Loss:  0.092869333922863\n",
      "Loss:  0.08384048938751221\n",
      "10 **********\n",
      "Epoch:  565.2825496196747  fold:  4  kers:  32\n",
      "epoch:  11\n",
      "29520 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.1146848052740097\n",
      "Loss:  0.10615004599094391\n",
      "Loss:  0.07873478531837463\n",
      "11 **********\n",
      "Epoch:  604.8507521152496  fold:  4  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.08572757989168167\n",
      "Eval Loss:  0.1271970421075821\n",
      "Eval Loss:  0.04590240865945816\n",
      "[[3043   94]\n",
      " [ 200   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.27      0.15      0.19       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.60      0.56      0.57      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9127855235835064\n",
      "pre:  0.265625\n",
      "rec:  0.1452991452991453\n",
      "ma F1:  0.5708818995826045\n",
      "mi F1:  0.9127855235835064\n",
      "we F1:  0.9007410622528\n",
      "Eval Loss:  0.3289356827735901\n",
      "Eval Loss:  0.37971895933151245\n",
      "Eval Loss:  0.3176229000091553\n",
      "Eval Loss:  0.3714480400085449\n",
      "Eval Loss:  0.37288010120391846\n",
      "Eval Loss:  0.2994799315929413\n",
      "Eval Loss:  0.3185644745826721\n",
      "Eval Loss:  0.32903003692626953\n",
      "Eval Loss:  0.36537206172943115\n",
      "Eval Loss:  0.28494715690612793\n",
      "Eval Loss:  0.4168001413345337\n",
      "Eval Loss:  0.35873258113861084\n",
      "Eval Loss:  0.3087695837020874\n",
      "Eval Loss:  0.27040600776672363\n",
      "Eval Loss:  0.2916066646575928\n",
      "Eval Loss:  0.3490392565727234\n",
      "Eval Loss:  0.2911921739578247\n",
      "Eval Loss:  0.3763941526412964\n",
      "Eval Loss:  0.30257856845855713\n",
      "Eval Loss:  0.282789021730423\n",
      "Eval Loss:  0.407364159822464\n",
      "Eval Loss:  0.3856750726699829\n",
      "Eval Loss:  0.4167144298553467\n",
      "Eval Loss:  0.36110368371009827\n",
      "Eval Loss:  0.38654598593711853\n",
      "Eval Loss:  0.3228728771209717\n",
      "Eval Loss:  0.34080269932746887\n",
      "Eval Loss:  0.3583471179008484\n",
      "[[15903  1124]\n",
      " [ 3039  9454]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88     17027\n",
      "           1       0.89      0.76      0.82     12493\n",
      "\n",
      "    accuracy                           0.86     29520\n",
      "   macro avg       0.87      0.85      0.85     29520\n",
      "weighted avg       0.86      0.86      0.86     29520\n",
      "\n",
      "acc:  0.8589769647696477\n",
      "pre:  0.8937417281149556\n",
      "rec:  0.7567437765148484\n",
      "ma F1:  0.8519092334962433\n",
      "mi F1:  0.8589769647696477\n",
      "we F1:  0.8568782354490446\n",
      "29520 462\n",
      "Loss:  0.08524183183908463\n",
      "Loss:  0.07584603875875473\n",
      "Loss:  0.08608533442020416\n",
      "12 **********\n",
      "Epoch:  682.9040539264679  fold:  4  kers:  32\n",
      "epoch:  13\n",
      "29520 462\n",
      "Loss:  0.08445708453655243\n",
      "Loss:  0.05494066700339317\n",
      "Loss:  0.07303831726312637\n",
      "13 **********\n",
      "Epoch:  722.2777764797211  fold:  4  kers:  32\n",
      "epoch:  14\n",
      "29520 462\n",
      "Loss:  0.07946252822875977\n",
      "Loss:  0.059572409838438034\n",
      "Loss:  0.08682439476251602\n",
      "14 **********\n",
      "Epoch:  761.7701830863953  fold:  4  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.07516919076442719\n",
      "Eval Loss:  0.10322730243206024\n",
      "Eval Loss:  0.02493509277701378\n",
      "[[3102   35]\n",
      " [ 222   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.26      0.05      0.09       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.59      0.52      0.52      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.92376149510531\n",
      "pre:  0.2553191489361702\n",
      "rec:  0.05128205128205128\n",
      "ma F1:  0.5228160641924363\n",
      "mi F1:  0.92376149510531\n",
      "we F1:  0.8994971599659225\n",
      "Eval Loss:  0.35966646671295166\n",
      "Eval Loss:  0.41193246841430664\n",
      "Eval Loss:  0.4000667929649353\n",
      "Eval Loss:  0.4104413390159607\n",
      "Eval Loss:  0.41903725266456604\n",
      "Eval Loss:  0.3476468324661255\n",
      "Eval Loss:  0.36553052067756653\n",
      "Eval Loss:  0.4014776051044464\n",
      "Eval Loss:  0.4110385775566101\n",
      "Eval Loss:  0.30779391527175903\n",
      "Eval Loss:  0.4778045117855072\n",
      "Eval Loss:  0.3957916796207428\n",
      "Eval Loss:  0.38228535652160645\n",
      "Eval Loss:  0.3214145004749298\n",
      "Eval Loss:  0.33369746804237366\n",
      "Eval Loss:  0.3675585389137268\n",
      "Eval Loss:  0.31815770268440247\n",
      "Eval Loss:  0.4398330748081207\n",
      "Eval Loss:  0.3431583344936371\n",
      "Eval Loss:  0.30613037943840027\n",
      "Eval Loss:  0.47255247831344604\n",
      "Eval Loss:  0.44571495056152344\n",
      "Eval Loss:  0.4464386999607086\n",
      "Eval Loss:  0.4393399953842163\n",
      "Eval Loss:  0.41280072927474976\n",
      "Eval Loss:  0.38710784912109375\n",
      "Eval Loss:  0.38096851110458374\n",
      "Eval Loss:  0.43381357192993164\n",
      "[[16417   610]\n",
      " [ 4102  8391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87     17027\n",
      "           1       0.93      0.67      0.78     12493\n",
      "\n",
      "    accuracy                           0.84     29520\n",
      "   macro avg       0.87      0.82      0.83     29520\n",
      "weighted avg       0.86      0.84      0.83     29520\n",
      "\n",
      "acc:  0.840379403794038\n",
      "pre:  0.93222975224975\n",
      "rec:  0.6716561274313616\n",
      "ma F1:  0.8276383215510223\n",
      "mi F1:  0.840379403794038\n",
      "we F1:  0.8348359376598976\n",
      "29520 462\n",
      "Loss:  0.09219645708799362\n",
      "Loss:  0.09048201888799667\n",
      "Loss:  0.08150728791952133\n",
      "15 **********\n",
      "Epoch:  840.0748112201691  fold:  4  kers:  32\n",
      "epoch:  16\n",
      "29520 462\n",
      "Loss:  0.08009186387062073\n",
      "Loss:  0.1246006041765213\n",
      "Loss:  0.06342673301696777\n",
      "16 **********\n",
      "Epoch:  879.6430134773254  fold:  4  kers:  32\n",
      "epoch:  17\n",
      "29520 462\n",
      "Loss:  0.07762029021978378\n",
      "Loss:  0.07376929372549057\n",
      "Loss:  0.10256888717412949\n",
      "17 **********\n",
      "Epoch:  919.1733174324036  fold:  4  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.09398652613162994\n",
      "Eval Loss:  0.1598590612411499\n",
      "Eval Loss:  0.042915984988212585\n",
      "[[3009  128]\n",
      " [ 199   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.21      0.15      0.18       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.58      0.55      0.56      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9029961435775734\n",
      "pre:  0.2147239263803681\n",
      "rec:  0.14957264957264957\n",
      "ma F1:  0.5623928875550077\n",
      "mi F1:  0.9029961435775734\n",
      "we F1:  0.8948647275797247\n",
      "Eval Loss:  0.2985309064388275\n",
      "Eval Loss:  0.3550296127796173\n",
      "Eval Loss:  0.306135892868042\n",
      "Eval Loss:  0.3504263460636139\n",
      "Eval Loss:  0.35918736457824707\n",
      "Eval Loss:  0.3007209599018097\n",
      "Eval Loss:  0.31085434556007385\n",
      "Eval Loss:  0.3061312437057495\n",
      "Eval Loss:  0.36011984944343567\n",
      "Eval Loss:  0.2716907858848572\n",
      "Eval Loss:  0.4047330617904663\n",
      "Eval Loss:  0.3436047434806824\n",
      "Eval Loss:  0.28775840997695923\n",
      "Eval Loss:  0.2637224793434143\n",
      "Eval Loss:  0.2804960310459137\n",
      "Eval Loss:  0.33192718029022217\n",
      "Eval Loss:  0.2842354476451874\n",
      "Eval Loss:  0.33240580558776855\n",
      "Eval Loss:  0.28048786520957947\n",
      "Eval Loss:  0.24525520205497742\n",
      "Eval Loss:  0.3713759481906891\n",
      "Eval Loss:  0.36395829916000366\n",
      "Eval Loss:  0.3958371579647064\n",
      "Eval Loss:  0.35350826382637024\n",
      "Eval Loss:  0.37731701135635376\n",
      "Eval Loss:  0.3094383776187897\n",
      "Eval Loss:  0.33504754304885864\n",
      "Eval Loss:  0.34053367376327515\n",
      "[[15919  1108]\n",
      " [ 2853  9640]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     17027\n",
      "           1       0.90      0.77      0.83     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.87      0.85      0.86     29520\n",
      "weighted avg       0.87      0.87      0.86     29520\n",
      "\n",
      "acc:  0.8658197831978319\n",
      "pre:  0.8969110532192036\n",
      "rec:  0.7716321139838309\n",
      "ma F1:  0.8594614431674046\n",
      "mi F1:  0.8658197831978319\n",
      "we F1:  0.8640527337706786\n",
      "29520 462\n",
      "Loss:  0.06976072490215302\n",
      "Loss:  0.08363016694784164\n",
      "Loss:  0.08518272638320923\n",
      "18 **********\n",
      "Epoch:  997.388186454773  fold:  4  kers:  32\n",
      "epoch:  19\n",
      "29520 462\n",
      "Loss:  0.06723377108573914\n",
      "Loss:  0.10260076820850372\n",
      "Loss:  0.062355928122997284\n",
      "19 **********\n",
      "Epoch:  1036.8397026062012  fold:  4  kers:  32\n",
      "epoch:  20\n",
      "29520 462\n",
      "Loss:  0.0905180275440216\n",
      "Loss:  0.059111595153808594\n",
      "Loss:  0.07370255142450333\n",
      "20 **********\n",
      "Epoch:  1076.2852323055267  fold:  4  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.08849397301673889\n",
      "Eval Loss:  0.12875014543533325\n",
      "Eval Loss:  0.026634037494659424\n",
      "[[3090   47]\n",
      " [ 215   19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.29      0.08      0.13       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.61      0.53      0.54      3371\n",
      "weighted avg       0.89      0.92      0.90      3371\n",
      "\n",
      "acc:  0.9222782557104716\n",
      "pre:  0.2878787878787879\n",
      "rec:  0.0811965811965812\n",
      "ma F1:  0.5429980337369347\n",
      "mi F1:  0.9222782557104716\n",
      "we F1:  0.9015296144563023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.32179969549179077\n",
      "Eval Loss:  0.38129723072052\n",
      "Eval Loss:  0.35900646448135376\n",
      "Eval Loss:  0.37480854988098145\n",
      "Eval Loss:  0.39729052782058716\n",
      "Eval Loss:  0.31510844826698303\n",
      "Eval Loss:  0.3327397406101227\n",
      "Eval Loss:  0.3670545220375061\n",
      "Eval Loss:  0.38319188356399536\n",
      "Eval Loss:  0.28051507472991943\n",
      "Eval Loss:  0.44903427362442017\n",
      "Eval Loss:  0.374120831489563\n",
      "Eval Loss:  0.3583630919456482\n",
      "Eval Loss:  0.3056710660457611\n",
      "Eval Loss:  0.3130699694156647\n",
      "Eval Loss:  0.3422510325908661\n",
      "Eval Loss:  0.29969120025634766\n",
      "Eval Loss:  0.3762325942516327\n",
      "Eval Loss:  0.30240774154663086\n",
      "Eval Loss:  0.28742873668670654\n",
      "Eval Loss:  0.42659318447113037\n",
      "Eval Loss:  0.41386425495147705\n",
      "Eval Loss:  0.39882707595825195\n",
      "Eval Loss:  0.393785685300827\n",
      "Eval Loss:  0.3935009837150574\n",
      "Eval Loss:  0.34382084012031555\n",
      "Eval Loss:  0.3543007969856262\n",
      "Eval Loss:  0.38235509395599365\n",
      "[[16368   659]\n",
      " [ 3748  8745]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88     17027\n",
      "           1       0.93      0.70      0.80     12493\n",
      "\n",
      "    accuracy                           0.85     29520\n",
      "   macro avg       0.87      0.83      0.84     29520\n",
      "weighted avg       0.86      0.85      0.85     29520\n",
      "\n",
      "acc:  0.8507113821138211\n",
      "pre:  0.9299234368353892\n",
      "rec:  0.6999919955174898\n",
      "ma F1:  0.8400450048539365\n",
      "mi F1:  0.8507113821138211\n",
      "we F1:  0.8463891416106356\n",
      "29520 462\n",
      "Loss:  0.06899097561836243\n",
      "Loss:  0.07711877673864365\n",
      "Loss:  0.09493093937635422\n",
      "21 **********\n",
      "Epoch:  1154.713530778885  fold:  4  kers:  32\n",
      "epoch:  22\n",
      "29520 462\n",
      "Loss:  0.08098272979259491\n",
      "Loss:  0.0916367620229721\n",
      "Loss:  0.04155515134334564\n",
      "22 **********\n",
      "Epoch:  1194.2956964969635  fold:  4  kers:  32\n",
      "epoch:  23\n",
      "29520 462\n",
      "Loss:  0.07386698573827744\n",
      "Loss:  0.04764436185359955\n",
      "Loss:  0.0869707316160202\n",
      "23 **********\n",
      "Epoch:  1233.9227418899536  fold:  4  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.09711728990077972\n",
      "Eval Loss:  0.1385468691587448\n",
      "Eval Loss:  0.026988161727786064\n",
      "[[3058   79]\n",
      " [ 212   22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.22      0.09      0.13       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.58      0.53      0.54      3371\n",
      "weighted avg       0.89      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9136754672204094\n",
      "pre:  0.21782178217821782\n",
      "rec:  0.09401709401709402\n",
      "ma F1:  0.5429621053465309\n",
      "mi F1:  0.9136754672204094\n",
      "we F1:  0.8974353891146036\n",
      "Eval Loss:  0.30082497000694275\n",
      "Eval Loss:  0.3701256513595581\n",
      "Eval Loss:  0.3366939425468445\n",
      "Eval Loss:  0.36492687463760376\n",
      "Eval Loss:  0.36799365282058716\n",
      "Eval Loss:  0.302565336227417\n",
      "Eval Loss:  0.3230219781398773\n",
      "Eval Loss:  0.34387850761413574\n",
      "Eval Loss:  0.36385565996170044\n",
      "Eval Loss:  0.26211249828338623\n",
      "Eval Loss:  0.426061749458313\n",
      "Eval Loss:  0.35484614968299866\n",
      "Eval Loss:  0.33141574263572693\n",
      "Eval Loss:  0.27884939312934875\n",
      "Eval Loss:  0.2928200662136078\n",
      "Eval Loss:  0.33198437094688416\n",
      "Eval Loss:  0.2785489559173584\n",
      "Eval Loss:  0.3552224040031433\n",
      "Eval Loss:  0.2797762453556061\n",
      "Eval Loss:  0.2619923949241638\n",
      "Eval Loss:  0.38841238617897034\n",
      "Eval Loss:  0.386541485786438\n",
      "Eval Loss:  0.3865862488746643\n",
      "Eval Loss:  0.38358601927757263\n",
      "Eval Loss:  0.3799586892127991\n",
      "Eval Loss:  0.32465410232543945\n",
      "Eval Loss:  0.3445075452327728\n",
      "Eval Loss:  0.3679181635379791\n",
      "[[16294   733]\n",
      " [ 3447  9046]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     17027\n",
      "           1       0.93      0.72      0.81     12493\n",
      "\n",
      "    accuracy                           0.86     29520\n",
      "   macro avg       0.88      0.84      0.85     29520\n",
      "weighted avg       0.87      0.86      0.85     29520\n",
      "\n",
      "acc:  0.8584010840108401\n",
      "pre:  0.9250434604765313\n",
      "rec:  0.724085487873209\n",
      "ma F1:  0.8493172942738814\n",
      "mi F1:  0.8584010840108401\n",
      "we F1:  0.8549996759884745\n",
      "29520 462\n",
      "Loss:  0.09635544568300247\n",
      "Loss:  0.07645577937364578\n",
      "Loss:  0.08563895523548126\n",
      "24 **********\n",
      "Epoch:  1312.0987153053284  fold:  4  kers:  32\n",
      "epoch:  25\n",
      "29520 462\n",
      "Loss:  0.09021361172199249\n",
      "Loss:  0.10732126981019974\n",
      "Loss:  0.06539336591959\n",
      "25 **********\n",
      "Epoch:  1351.5452439785004  fold:  4  kers:  32\n",
      "epoch:  26\n",
      "29520 462\n",
      "Loss:  0.06619444489479065\n",
      "Loss:  0.06680892407894135\n",
      "Loss:  0.08219601213932037\n",
      "26 **********\n",
      "Epoch:  1390.959856748581  fold:  4  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.07715858519077301\n",
      "Eval Loss:  0.1197214126586914\n",
      "Eval Loss:  0.01840272918343544\n",
      "[[3101   36]\n",
      " [ 224   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3137\n",
      "           1       0.22      0.04      0.07       234\n",
      "\n",
      "    accuracy                           0.92      3371\n",
      "   macro avg       0.58      0.52      0.52      3371\n",
      "weighted avg       0.88      0.92      0.90      3371\n",
      "\n",
      "acc:  0.922871551468407\n",
      "pre:  0.21739130434782608\n",
      "rec:  0.042735042735042736\n",
      "ma F1:  0.5155966750674271\n",
      "mi F1:  0.922871551468407\n",
      "we F1:  0.8981003846086902\n",
      "Eval Loss:  0.3374367952346802\n",
      "Eval Loss:  0.39792001247406006\n",
      "Eval Loss:  0.3869115710258484\n",
      "Eval Loss:  0.39841675758361816\n",
      "Eval Loss:  0.40459948778152466\n",
      "Eval Loss:  0.3383888304233551\n",
      "Eval Loss:  0.36366817355155945\n",
      "Eval Loss:  0.40056437253952026\n",
      "Eval Loss:  0.3913465440273285\n",
      "Eval Loss:  0.2740319073200226\n",
      "Eval Loss:  0.4615088999271393\n",
      "Eval Loss:  0.3917209804058075\n",
      "Eval Loss:  0.37583228945732117\n",
      "Eval Loss:  0.3275172710418701\n",
      "Eval Loss:  0.3201662302017212\n",
      "Eval Loss:  0.3498300313949585\n",
      "Eval Loss:  0.2920035421848297\n",
      "Eval Loss:  0.4024672210216522\n",
      "Eval Loss:  0.30743443965911865\n",
      "Eval Loss:  0.3090793192386627\n",
      "Eval Loss:  0.4375324249267578\n",
      "Eval Loss:  0.43115943670272827\n",
      "Eval Loss:  0.40181827545166016\n",
      "Eval Loss:  0.4206996560096741\n",
      "Eval Loss:  0.40192532539367676\n",
      "Eval Loss:  0.3564201295375824\n",
      "Eval Loss:  0.3774217963218689\n",
      "Eval Loss:  0.3973219394683838\n",
      "[[16527   500]\n",
      " [ 4046  8447]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88     17027\n",
      "           1       0.94      0.68      0.79     12493\n",
      "\n",
      "    accuracy                           0.85     29520\n",
      "   macro avg       0.87      0.82      0.83     29520\n",
      "weighted avg       0.86      0.85      0.84     29520\n",
      "\n",
      "acc:  0.8460027100271003\n",
      "pre:  0.9441153459260088\n",
      "rec:  0.6761386376370767\n",
      "ma F1:  0.8335310812956493\n",
      "mi F1:  0.8460027100271004\n",
      "we F1:  0.8405293937546096\n",
      "29520 462\n",
      "Loss:  0.07986821234226227\n",
      "Loss:  0.08118331432342529\n",
      "Loss:  0.06123852729797363\n",
      "27 **********\n",
      "Epoch:  1469.2146184444427  fold:  4  kers:  32\n",
      "epoch:  28\n",
      "29520 462\n",
      "Loss:  0.06551551818847656\n",
      "Loss:  0.06454165279865265\n",
      "Loss:  0.05695613473653793\n",
      "28 **********\n",
      "Epoch:  1508.8047654628754  fold:  4  kers:  32\n",
      "epoch:  29\n",
      "29520 462\n",
      "Loss:  0.08584734052419662\n",
      "Loss:  0.06900975108146667\n",
      "Loss:  0.06679592281579971\n",
      "29 **********\n",
      "Epoch:  1548.3240966796875  fold:  4  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.08271697163581848\n",
      "Eval Loss:  0.2159252017736435\n",
      "Eval Loss:  0.023566003888845444\n",
      "[[3022  115]\n",
      " [ 214   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      3137\n",
      "           1       0.15      0.09      0.11       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.54      0.52      0.53      3371\n",
      "weighted avg       0.88      0.90      0.89      3371\n",
      "\n",
      "acc:  0.9024028478196381\n",
      "pre:  0.14814814814814814\n",
      "rec:  0.08547008547008547\n",
      "ma F1:  0.5283885225483355\n",
      "mi F1:  0.9024028478196381\n",
      "we F1:  0.8900685979189522\n",
      "Eval Loss:  0.29401692748069763\n",
      "Eval Loss:  0.3458189070224762\n",
      "Eval Loss:  0.29820066690444946\n",
      "Eval Loss:  0.34253990650177\n",
      "Eval Loss:  0.33754926919937134\n",
      "Eval Loss:  0.2890123128890991\n",
      "Eval Loss:  0.31427207589149475\n",
      "Eval Loss:  0.30087196826934814\n",
      "Eval Loss:  0.34531205892562866\n",
      "Eval Loss:  0.23437944054603577\n",
      "Eval Loss:  0.37911301851272583\n",
      "Eval Loss:  0.33365973830223083\n",
      "Eval Loss:  0.28842684626579285\n",
      "Eval Loss:  0.2597757577896118\n",
      "Eval Loss:  0.2618567943572998\n",
      "Eval Loss:  0.3190034329891205\n",
      "Eval Loss:  0.2586069107055664\n",
      "Eval Loss:  0.3056623637676239\n",
      "Eval Loss:  0.261046826839447\n",
      "Eval Loss:  0.23617322742938995\n",
      "Eval Loss:  0.34651219844818115\n",
      "Eval Loss:  0.34697458148002625\n",
      "Eval Loss:  0.3505379855632782\n",
      "Eval Loss:  0.3238064646720886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.37339508533477783\n",
      "Eval Loss:  0.29958969354629517\n",
      "Eval Loss:  0.3213297724723816\n",
      "Eval Loss:  0.29796940088272095\n",
      "[[16083   944]\n",
      " [ 2837  9656]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     17027\n",
      "           1       0.91      0.77      0.84     12493\n",
      "\n",
      "    accuracy                           0.87     29520\n",
      "   macro avg       0.88      0.86      0.87     29520\n",
      "weighted avg       0.88      0.87      0.87     29520\n",
      "\n",
      "acc:  0.8719173441734417\n",
      "pre:  0.9109433962264151\n",
      "rec:  0.7729128311854638\n",
      "ma F1:  0.865544050703717\n",
      "mi F1:  0.8719173441734417\n",
      "we F1:  0.8700401628231712\n",
      "29520 462\n",
      "Loss:  0.09596004337072372\n",
      "Loss:  0.05951796844601631\n",
      "Loss:  0.08149358630180359\n",
      "30 **********\n",
      "Epoch:  1626.3793923854828  fold:  4  kers:  32\n",
      "epoch:  31\n",
      "29520 462\n",
      "Loss:  0.06394180655479431\n",
      "Loss:  0.08727667480707169\n",
      "Loss:  0.06928202509880066\n",
      "31 **********\n",
      "Epoch:  1665.7531151771545  fold:  4  kers:  32\n",
      "epoch:  32\n",
      "29520 462\n",
      "Loss:  0.06530051678419113\n",
      "Loss:  0.07925374060869217\n",
      "Loss:  0.08621678501367569\n",
      "32 **********\n",
      "Epoch:  1705.2086191177368  fold:  4  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.08917556703090668\n",
      "Eval Loss:  0.17494381964206696\n",
      "Eval Loss:  0.02168070524930954\n",
      "[[3044   93]\n",
      " [ 210   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3137\n",
      "           1       0.21      0.10      0.14       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.57      0.54      0.54      3371\n",
      "weighted avg       0.88      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9101156926727973\n",
      "pre:  0.20512820512820512\n",
      "rec:  0.10256410256410256\n",
      "ma F1:  0.54467085792387\n",
      "mi F1:  0.9101156926727973\n",
      "we F1:  0.8959577305318622\n",
      "Eval Loss:  0.26754656434059143\n",
      "Eval Loss:  0.3253968358039856\n",
      "Eval Loss:  0.28963935375213623\n",
      "Eval Loss:  0.32246407866477966\n",
      "Eval Loss:  0.3401908874511719\n",
      "Eval Loss:  0.2792838215827942\n",
      "Eval Loss:  0.29812315106391907\n",
      "Eval Loss:  0.3196800649166107\n",
      "Eval Loss:  0.3225254714488983\n",
      "Eval Loss:  0.23536375164985657\n",
      "Eval Loss:  0.36432260274887085\n",
      "Eval Loss:  0.3166373670101166\n",
      "Eval Loss:  0.280771940946579\n",
      "Eval Loss:  0.2726142704486847\n",
      "Eval Loss:  0.24912527203559875\n",
      "Eval Loss:  0.29929912090301514\n",
      "Eval Loss:  0.26342466473579407\n",
      "Eval Loss:  0.2925185561180115\n",
      "Eval Loss:  0.24333520233631134\n",
      "Eval Loss:  0.23856480419635773\n",
      "Eval Loss:  0.3246937096118927\n",
      "Eval Loss:  0.3440394699573517\n",
      "Eval Loss:  0.34402701258659363\n",
      "Eval Loss:  0.3193650543689728\n",
      "Eval Loss:  0.36301523447036743\n",
      "Eval Loss:  0.2964392304420471\n",
      "Eval Loss:  0.31168392300605774\n",
      "Eval Loss:  0.2977764308452606\n",
      "[[16159   868]\n",
      " [ 2798  9695]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     17027\n",
      "           1       0.92      0.78      0.84     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.89      0.86      0.87     29520\n",
      "weighted avg       0.88      0.88      0.87     29520\n",
      "\n",
      "acc:  0.8758130081300813\n",
      "pre:  0.9178263750828363\n",
      "rec:  0.7760345793644441\n",
      "ma F1:  0.8695586117540404\n",
      "mi F1:  0.8758130081300813\n",
      "we F1:  0.8739455908952795\n",
      "29520 462\n",
      "Loss:  0.07158979028463364\n",
      "Loss:  0.06837478280067444\n",
      "Loss:  0.09854615479707718\n",
      "33 **********\n",
      "Epoch:  1783.4145121574402  fold:  4  kers:  32\n",
      "epoch:  34\n",
      "29520 462\n",
      "Loss:  0.08362676203250885\n",
      "Loss:  0.08355565369129181\n",
      "Loss:  0.0801423192024231\n",
      "34 **********\n",
      "Epoch:  1822.9468109607697  fold:  4  kers:  32\n",
      "epoch:  35\n",
      "29520 462\n",
      "Loss:  0.04486854746937752\n",
      "Loss:  0.051041364669799805\n",
      "Loss:  0.08178817480802536\n",
      "35 **********\n",
      "Epoch:  1862.4541766643524  fold:  4  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.10213198512792587\n",
      "Eval Loss:  0.216142937541008\n",
      "Eval Loss:  0.033874016255140305\n",
      "[[2993  144]\n",
      " [ 191   43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      3137\n",
      "           1       0.23      0.18      0.20       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.58      0.57      0.58      3371\n",
      "weighted avg       0.89      0.90      0.90      3371\n",
      "\n",
      "acc:  0.9006229605458321\n",
      "pre:  0.22994652406417113\n",
      "rec:  0.18376068376068377\n",
      "ma F1:  0.5756387955392066\n",
      "mi F1:  0.9006229605458321\n",
      "we F1:  0.8954452467304721\n",
      "Eval Loss:  0.26292797923088074\n",
      "Eval Loss:  0.3125613331794739\n",
      "Eval Loss:  0.24644693732261658\n",
      "Eval Loss:  0.29038625955581665\n",
      "Eval Loss:  0.3192019462585449\n",
      "Eval Loss:  0.260669469833374\n",
      "Eval Loss:  0.28313595056533813\n",
      "Eval Loss:  0.2788003087043762\n",
      "Eval Loss:  0.2901231050491333\n",
      "Eval Loss:  0.22271110117435455\n",
      "Eval Loss:  0.3429710268974304\n",
      "Eval Loss:  0.2830408215522766\n",
      "Eval Loss:  0.24107544124126434\n",
      "Eval Loss:  0.24902765452861786\n",
      "Eval Loss:  0.22762814164161682\n",
      "Eval Loss:  0.29769837856292725\n",
      "Eval Loss:  0.26939862966537476\n",
      "Eval Loss:  0.2548299729824066\n",
      "Eval Loss:  0.21864594519138336\n",
      "Eval Loss:  0.21852022409439087\n",
      "Eval Loss:  0.2988383173942566\n",
      "Eval Loss:  0.30491310358047485\n",
      "Eval Loss:  0.3304135799407959\n",
      "Eval Loss:  0.27436763048171997\n",
      "Eval Loss:  0.3591132164001465\n",
      "Eval Loss:  0.2780817747116089\n",
      "Eval Loss:  0.3040541708469391\n",
      "Eval Loss:  0.2527935206890106\n",
      "[[15865  1162]\n",
      " [ 2178 10315]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     17027\n",
      "           1       0.90      0.83      0.86     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.88      0.88     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8868563685636857\n",
      "pre:  0.8987540297987279\n",
      "rec:  0.8256623709277195\n",
      "ma F1:  0.8827105310209191\n",
      "mi F1:  0.8868563685636857\n",
      "we F1:  0.8860974188441451\n",
      "29520 462\n",
      "Loss:  0.06867372989654541\n",
      "Loss:  0.07852203398942947\n",
      "Loss:  0.07704047858715057\n",
      "36 **********\n",
      "Epoch:  1940.6231689453125  fold:  4  kers:  32\n",
      "epoch:  37\n",
      "29520 462\n",
      "Loss:  0.06698955595493317\n",
      "Loss:  0.05648072063922882\n",
      "Loss:  0.09468693286180496\n",
      "37 **********\n",
      "Epoch:  1979.9938988685608  fold:  4  kers:  32\n",
      "epoch:  38\n",
      "29520 462\n",
      "Loss:  0.08098023384809494\n",
      "Loss:  0.05086334049701691\n",
      "Loss:  0.09297513216733932\n",
      "38 **********\n",
      "Epoch:  2019.4484059810638  fold:  4  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.09257302433252335\n",
      "Eval Loss:  0.48056092858314514\n",
      "Eval Loss:  0.02333865687251091\n",
      "[[2892  245]\n",
      " [ 204   30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      3137\n",
      "           1       0.11      0.13      0.12       234\n",
      "\n",
      "    accuracy                           0.87      3371\n",
      "   macro avg       0.52      0.53      0.52      3371\n",
      "weighted avg       0.88      0.87      0.87      3371\n",
      "\n",
      "acc:  0.8668051023435183\n",
      "pre:  0.10909090909090909\n",
      "rec:  0.1282051282051282\n",
      "ma F1:  0.5229211273918497\n",
      "mi F1:  0.8668051023435183\n",
      "we F1:  0.8717314625716868\n",
      "Eval Loss:  0.29324910044670105\n",
      "Eval Loss:  0.30445772409439087\n",
      "Eval Loss:  0.25391003489494324\n",
      "Eval Loss:  0.293892502784729\n",
      "Eval Loss:  0.32613563537597656\n",
      "Eval Loss:  0.2560539245605469\n",
      "Eval Loss:  0.29084938764572144\n",
      "Eval Loss:  0.2729546129703522\n",
      "Eval Loss:  0.3203583061695099\n",
      "Eval Loss:  0.23584267497062683\n",
      "Eval Loss:  0.33216264843940735\n",
      "Eval Loss:  0.2953105568885803\n",
      "Eval Loss:  0.2245209664106369\n",
      "Eval Loss:  0.2403063327074051\n",
      "Eval Loss:  0.22328630089759827\n",
      "Eval Loss:  0.30559003353118896\n",
      "Eval Loss:  0.2677322030067444\n",
      "Eval Loss:  0.2530357241630554\n",
      "Eval Loss:  0.2488306164741516\n",
      "Eval Loss:  0.2248774766921997\n",
      "Eval Loss:  0.3036264181137085\n",
      "Eval Loss:  0.2931000888347626\n",
      "Eval Loss:  0.3508153557777405\n",
      "Eval Loss:  0.24677149951457977\n",
      "Eval Loss:  0.35605505108833313\n",
      "Eval Loss:  0.2850840389728546\n",
      "Eval Loss:  0.30729642510414124\n",
      "Eval Loss:  0.2570359706878662\n",
      "[[15635  1392]\n",
      " [ 1995 10498]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90     17027\n",
      "           1       0.88      0.84      0.86     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.88      0.88      0.88     29520\n",
      "weighted avg       0.89      0.89      0.88     29520\n",
      "\n",
      "acc:  0.8852642276422764\n",
      "pre:  0.8829268292682927\n",
      "rec:  0.840310573921396\n",
      "ma F1:  0.881681284883348\n",
      "mi F1:  0.8852642276422764\n",
      "we F1:  0.8848436486110066\n",
      "29520 462\n",
      "Loss:  0.08381438255310059\n",
      "Loss:  0.08993364870548248\n",
      "Loss:  0.07114127278327942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 **********\n",
      "Epoch:  2097.7261068820953  fold:  4  kers:  32\n",
      "epoch:  40\n",
      "29520 462\n",
      "Loss:  0.08352863788604736\n",
      "Loss:  0.05514609441161156\n",
      "Loss:  0.06624153256416321\n",
      "40 **********\n",
      "Epoch:  2137.2673819065094  fold:  4  kers:  32\n",
      "epoch:  41\n",
      "29520 462\n",
      "Loss:  0.04943306744098663\n",
      "Loss:  0.054346438497304916\n",
      "Loss:  0.07276131212711334\n",
      "41 **********\n",
      "Epoch:  2176.951274871826  fold:  4  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.08830081671476364\n",
      "Eval Loss:  0.2575550973415375\n",
      "Eval Loss:  0.02347809076309204\n",
      "[[2975  162]\n",
      " [ 187   47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      3137\n",
      "           1       0.22      0.20      0.21       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.58      0.57      0.58      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.8964698902402848\n",
      "pre:  0.22488038277511962\n",
      "rec:  0.20085470085470086\n",
      "ma F1:  0.5783919981565744\n",
      "mi F1:  0.8964698902402848\n",
      "we F1:  0.8937540612436685\n",
      "Eval Loss:  0.2887859046459198\n",
      "Eval Loss:  0.3098340630531311\n",
      "Eval Loss:  0.2367437183856964\n",
      "Eval Loss:  0.28337886929512024\n",
      "Eval Loss:  0.3324461579322815\n",
      "Eval Loss:  0.2476358264684677\n",
      "Eval Loss:  0.2814735770225525\n",
      "Eval Loss:  0.28066861629486084\n",
      "Eval Loss:  0.3012959063053131\n",
      "Eval Loss:  0.2315315306186676\n",
      "Eval Loss:  0.3155862092971802\n",
      "Eval Loss:  0.2775190472602844\n",
      "Eval Loss:  0.2174334079027176\n",
      "Eval Loss:  0.23513637483119965\n",
      "Eval Loss:  0.22825486958026886\n",
      "Eval Loss:  0.30962124466896057\n",
      "Eval Loss:  0.28379637002944946\n",
      "Eval Loss:  0.2391006499528885\n",
      "Eval Loss:  0.22711484134197235\n",
      "Eval Loss:  0.22834399342536926\n",
      "Eval Loss:  0.28123563528060913\n",
      "Eval Loss:  0.2765231132507324\n",
      "Eval Loss:  0.3428504467010498\n",
      "Eval Loss:  0.22783133387565613\n",
      "Eval Loss:  0.3673246204853058\n",
      "Eval Loss:  0.2783207595348358\n",
      "Eval Loss:  0.3081374168395996\n",
      "Eval Loss:  0.240168958902359\n",
      "[[15451  1576]\n",
      " [ 1674 10819]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90     17027\n",
      "           1       0.87      0.87      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8899051490514905\n",
      "pre:  0.872851956434046\n",
      "rec:  0.8660049627791563\n",
      "ma F1:  0.8871260887567589\n",
      "mi F1:  0.8899051490514905\n",
      "we F1:  0.8898463520072583\n",
      "29520 462\n",
      "Loss:  0.06671515107154846\n",
      "Loss:  0.09305042773485184\n",
      "Loss:  0.11524868756532669\n",
      "42 **********\n",
      "Epoch:  2255.1392164230347  fold:  4  kers:  32\n",
      "epoch:  43\n",
      "29520 462\n",
      "Loss:  0.08671578764915466\n",
      "Loss:  0.06304417550563812\n",
      "Loss:  0.05283480882644653\n",
      "43 **********\n",
      "Epoch:  2294.5598146915436  fold:  4  kers:  32\n",
      "epoch:  44\n",
      "29520 462\n",
      "Loss:  0.07606031000614166\n",
      "Loss:  0.10531145334243774\n",
      "Loss:  0.06826528161764145\n",
      "44 **********\n",
      "Epoch:  2334.015317440033  fold:  4  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.09187765419483185\n",
      "Eval Loss:  0.3318301737308502\n",
      "Eval Loss:  0.04037771373987198\n",
      "[[2868  269]\n",
      " [ 164   70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      3137\n",
      "           1       0.21      0.30      0.24       234\n",
      "\n",
      "    accuracy                           0.87      3371\n",
      "   macro avg       0.58      0.61      0.59      3371\n",
      "weighted avg       0.89      0.87      0.88      3371\n",
      "\n",
      "acc:  0.8715514684070009\n",
      "pre:  0.20648967551622419\n",
      "rec:  0.29914529914529914\n",
      "ma F1:  0.5870692198819918\n",
      "mi F1:  0.8715514684070009\n",
      "we F1:  0.8822271782337078\n",
      "Eval Loss:  0.32169708609580994\n",
      "Eval Loss:  0.32961907982826233\n",
      "Eval Loss:  0.236413836479187\n",
      "Eval Loss:  0.27505064010620117\n",
      "Eval Loss:  0.3545978367328644\n",
      "Eval Loss:  0.26827937364578247\n",
      "Eval Loss:  0.296082079410553\n",
      "Eval Loss:  0.2714568078517914\n",
      "Eval Loss:  0.3104690611362457\n",
      "Eval Loss:  0.24453896284103394\n",
      "Eval Loss:  0.3270431160926819\n",
      "Eval Loss:  0.2700854539871216\n",
      "Eval Loss:  0.21779173612594604\n",
      "Eval Loss:  0.24346786737442017\n",
      "Eval Loss:  0.2505720853805542\n",
      "Eval Loss:  0.35732361674308777\n",
      "Eval Loss:  0.3066158592700958\n",
      "Eval Loss:  0.24247430264949799\n",
      "Eval Loss:  0.24940666556358337\n",
      "Eval Loss:  0.2676900327205658\n",
      "Eval Loss:  0.2894488573074341\n",
      "Eval Loss:  0.275051087141037\n",
      "Eval Loss:  0.3722361922264099\n",
      "Eval Loss:  0.22656439244747162\n",
      "Eval Loss:  0.40706124901771545\n",
      "Eval Loss:  0.28636953234672546\n",
      "Eval Loss:  0.3417026698589325\n",
      "Eval Loss:  0.251651406288147\n",
      "[[14780  2247]\n",
      " [ 1282 11211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89     17027\n",
      "           1       0.83      0.90      0.86     12493\n",
      "\n",
      "    accuracy                           0.88     29520\n",
      "   macro avg       0.88      0.88      0.88     29520\n",
      "weighted avg       0.88      0.88      0.88     29520\n",
      "\n",
      "acc:  0.8804539295392954\n",
      "pre:  0.8330361123495319\n",
      "rec:  0.8973825342191627\n",
      "ma F1:  0.878680595048166\n",
      "mi F1:  0.8804539295392954\n",
      "we F1:  0.8809334105658967\n",
      "29520 462\n",
      "Loss:  0.08404874801635742\n",
      "Loss:  0.05414154380559921\n",
      "Loss:  0.07784459739923477\n",
      "45 **********\n",
      "Epoch:  2412.3454463481903  fold:  4  kers:  32\n",
      "epoch:  46\n",
      "29520 462\n",
      "Loss:  0.10680381953716278\n",
      "Loss:  0.05963829904794693\n",
      "Loss:  0.0961892232298851\n",
      "46 **********\n",
      "Epoch:  2451.8248858451843  fold:  4  kers:  32\n",
      "epoch:  47\n",
      "29520 462\n",
      "Loss:  0.055700406432151794\n",
      "Loss:  0.07995657622814178\n",
      "Loss:  0.0740838572382927\n",
      "47 **********\n",
      "Epoch:  2491.2813873291016  fold:  4  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.06707773357629776\n",
      "Eval Loss:  0.43675267696380615\n",
      "Eval Loss:  0.023944266140460968\n",
      "[[2878  259]\n",
      " [ 187   47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3137\n",
      "           1       0.15      0.20      0.17       234\n",
      "\n",
      "    accuracy                           0.87      3371\n",
      "   macro avg       0.55      0.56      0.55      3371\n",
      "weighted avg       0.88      0.87      0.88      3371\n",
      "\n",
      "acc:  0.8676950459804212\n",
      "pre:  0.15359477124183007\n",
      "rec:  0.20085470085470086\n",
      "ma F1:  0.5510808938574175\n",
      "mi F1:  0.8676950459804212\n",
      "we F1:  0.8757474016684664\n",
      "Eval Loss:  0.2981233298778534\n",
      "Eval Loss:  0.3015052378177643\n",
      "Eval Loss:  0.23934213817119598\n",
      "Eval Loss:  0.26895415782928467\n",
      "Eval Loss:  0.31654635071754456\n",
      "Eval Loss:  0.23961259424686432\n",
      "Eval Loss:  0.2844780683517456\n",
      "Eval Loss:  0.26980841159820557\n",
      "Eval Loss:  0.29391083121299744\n",
      "Eval Loss:  0.22607752680778503\n",
      "Eval Loss:  0.32133448123931885\n",
      "Eval Loss:  0.25908511877059937\n",
      "Eval Loss:  0.20045672357082367\n",
      "Eval Loss:  0.23463678359985352\n",
      "Eval Loss:  0.22618988156318665\n",
      "Eval Loss:  0.3160652220249176\n",
      "Eval Loss:  0.28221595287323\n",
      "Eval Loss:  0.23532187938690186\n",
      "Eval Loss:  0.22545064985752106\n",
      "Eval Loss:  0.23512186110019684\n",
      "Eval Loss:  0.29353639483451843\n",
      "Eval Loss:  0.2731558382511139\n",
      "Eval Loss:  0.33784061670303345\n",
      "Eval Loss:  0.22029000520706177\n",
      "Eval Loss:  0.37632331252098083\n",
      "Eval Loss:  0.2665683627128601\n",
      "Eval Loss:  0.31924906373023987\n",
      "Eval Loss:  0.23235556483268738\n",
      "[[15382  1645]\n",
      " [ 1563 10930]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91     17027\n",
      "           1       0.87      0.87      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8913279132791327\n",
      "pre:  0.8691848906560636\n",
      "rec:  0.8748899383654847\n",
      "ma F1:  0.8887986879854934\n",
      "mi F1:  0.8913279132791327\n",
      "we F1:  0.8913744982912798\n",
      "29520 462\n",
      "Loss:  0.07322931289672852\n",
      "Loss:  0.0689738318324089\n",
      "Loss:  0.08284933120012283\n",
      "48 **********\n",
      "Epoch:  2569.2439317703247  fold:  4  kers:  32\n",
      "epoch:  49\n",
      "29520 462\n",
      "Loss:  0.05697981268167496\n",
      "Loss:  0.07983092963695526\n",
      "Loss:  0.04491191357374191\n",
      "49 **********\n",
      "Epoch:  2608.2027633190155  fold:  4  kers:  32\n",
      "epoch:  50\n",
      "29520 462\n",
      "Loss:  0.07174573838710785\n",
      "Loss:  0.07340650260448456\n",
      "Loss:  0.09313848614692688\n",
      "50 **********\n",
      "Epoch:  2647.120704650879  fold:  4  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.060837045311927795\n",
      "Eval Loss:  0.2249835878610611\n",
      "Eval Loss:  0.01691993698477745\n",
      "[[2976  161]\n",
      " [ 189   45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      3137\n",
      "           1       0.22      0.19      0.20       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.58      0.57      0.57      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.8961732423613171\n",
      "pre:  0.21844660194174756\n",
      "rec:  0.19230769230769232\n",
      "ma F1:  0.574503765038516\n",
      "mi F1:  0.8961732423613171\n",
      "we F1:  0.8931003166141189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.30302610993385315\n",
      "Eval Loss:  0.2882487177848816\n",
      "Eval Loss:  0.25374990701675415\n",
      "Eval Loss:  0.27391427755355835\n",
      "Eval Loss:  0.3043733239173889\n",
      "Eval Loss:  0.2338688224554062\n",
      "Eval Loss:  0.2677023410797119\n",
      "Eval Loss:  0.27894026041030884\n",
      "Eval Loss:  0.2831266522407532\n",
      "Eval Loss:  0.21879400312900543\n",
      "Eval Loss:  0.3103434145450592\n",
      "Eval Loss:  0.24481087923049927\n",
      "Eval Loss:  0.1907118260860443\n",
      "Eval Loss:  0.2396334558725357\n",
      "Eval Loss:  0.20474356412887573\n",
      "Eval Loss:  0.3079630732536316\n",
      "Eval Loss:  0.26814335584640503\n",
      "Eval Loss:  0.23089911043643951\n",
      "Eval Loss:  0.21815550327301025\n",
      "Eval Loss:  0.2368314564228058\n",
      "Eval Loss:  0.2990269362926483\n",
      "Eval Loss:  0.2687201201915741\n",
      "Eval Loss:  0.34299665689468384\n",
      "Eval Loss:  0.21365654468536377\n",
      "Eval Loss:  0.3592744767665863\n",
      "Eval Loss:  0.2614425718784332\n",
      "Eval Loss:  0.2937797009944916\n",
      "Eval Loss:  0.23371466994285583\n",
      "[[15605  1422]\n",
      " [ 1753 10740]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     17027\n",
      "           1       0.88      0.86      0.87     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8924457994579946\n",
      "pre:  0.8830784410458806\n",
      "rec:  0.8596814215960938\n",
      "ma F1:  0.8894430504640054\n",
      "mi F1:  0.8924457994579946\n",
      "we F1:  0.8922415014277766\n",
      "29520 462\n",
      "Loss:  0.0773141011595726\n",
      "Loss:  0.11625407636165619\n",
      "Loss:  0.05861259624361992\n",
      "51 **********\n",
      "Epoch:  2725.0224113464355  fold:  4  kers:  32\n",
      "epoch:  52\n",
      "29520 462\n",
      "Loss:  0.07230699062347412\n",
      "Loss:  0.06936784833669662\n",
      "Loss:  0.09051847457885742\n",
      "52 **********\n",
      "Epoch:  2764.422064781189  fold:  4  kers:  32\n",
      "epoch:  53\n",
      "29520 462\n",
      "Loss:  0.06691986322402954\n",
      "Loss:  0.09336797147989273\n",
      "Loss:  0.09786916524171829\n",
      "53 **********\n",
      "Epoch:  2803.829696893692  fold:  4  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.10947412997484207\n",
      "Eval Loss:  0.26269376277923584\n",
      "Eval Loss:  0.015003872103989124\n",
      "[[3019  118]\n",
      " [ 185   49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3137\n",
      "           1       0.29      0.21      0.24       234\n",
      "\n",
      "    accuracy                           0.91      3371\n",
      "   macro avg       0.62      0.59      0.60      3371\n",
      "weighted avg       0.90      0.91      0.90      3371\n",
      "\n",
      "acc:  0.9101156926727973\n",
      "pre:  0.2934131736526946\n",
      "rec:  0.2094017094017094\n",
      "ma F1:  0.5983023831369376\n",
      "mi F1:  0.9101156926727973\n",
      "we F1:  0.9030815203701367\n",
      "Eval Loss:  0.2744406759738922\n",
      "Eval Loss:  0.2745377719402313\n",
      "Eval Loss:  0.26622891426086426\n",
      "Eval Loss:  0.25652873516082764\n",
      "Eval Loss:  0.28022390604019165\n",
      "Eval Loss:  0.22928953170776367\n",
      "Eval Loss:  0.2640736401081085\n",
      "Eval Loss:  0.2672649323940277\n",
      "Eval Loss:  0.2729697823524475\n",
      "Eval Loss:  0.19717614352703094\n",
      "Eval Loss:  0.32550501823425293\n",
      "Eval Loss:  0.23435546457767487\n",
      "Eval Loss:  0.20952072739601135\n",
      "Eval Loss:  0.23631976544857025\n",
      "Eval Loss:  0.19322402775287628\n",
      "Eval Loss:  0.29501602053642273\n",
      "Eval Loss:  0.25297045707702637\n",
      "Eval Loss:  0.2275262475013733\n",
      "Eval Loss:  0.2064930945634842\n",
      "Eval Loss:  0.2246435284614563\n",
      "Eval Loss:  0.2814101278781891\n",
      "Eval Loss:  0.27145135402679443\n",
      "Eval Loss:  0.31843820214271545\n",
      "Eval Loss:  0.22428563237190247\n",
      "Eval Loss:  0.3395395278930664\n",
      "Eval Loss:  0.23820994794368744\n",
      "Eval Loss:  0.2943591773509979\n",
      "Eval Loss:  0.2280767410993576\n",
      "[[15905  1122]\n",
      " [ 1954 10539]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     17027\n",
      "           1       0.90      0.84      0.87     12493\n",
      "\n",
      "    accuracy                           0.90     29520\n",
      "   macro avg       0.90      0.89      0.89     29520\n",
      "weighted avg       0.90      0.90      0.90     29520\n",
      "\n",
      "acc:  0.8957994579945799\n",
      "pre:  0.9037818368922048\n",
      "rec:  0.8435924117505803\n",
      "ma F1:  0.8922387933176077\n",
      "mi F1:  0.8957994579945799\n",
      "we F1:  0.8952473758083629\n",
      "29520 462\n",
      "Loss:  0.07934986054897308\n",
      "Loss:  0.08801641315221786\n",
      "Loss:  0.07409939169883728\n",
      "54 **********\n",
      "Epoch:  2881.474091529846  fold:  4  kers:  32\n",
      "epoch:  55\n",
      "29520 462\n",
      "Loss:  0.04615377262234688\n",
      "Loss:  0.04685123637318611\n",
      "Loss:  0.06402600556612015\n",
      "55 **********\n",
      "Epoch:  2920.828864336014  fold:  4  kers:  32\n",
      "epoch:  56\n",
      "29520 462\n",
      "Loss:  0.06084543839097023\n",
      "Loss:  0.07765433937311172\n",
      "Loss:  0.061262346804142\n",
      "56 **********\n",
      "Epoch:  2960.0460062026978  fold:  4  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.11976821720600128\n",
      "Eval Loss:  0.29954957962036133\n",
      "Eval Loss:  0.018103858456015587\n",
      "[[2976  161]\n",
      " [ 188   46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      3137\n",
      "           1       0.22      0.20      0.21       234\n",
      "\n",
      "    accuracy                           0.90      3371\n",
      "   macro avg       0.58      0.57      0.58      3371\n",
      "weighted avg       0.89      0.90      0.89      3371\n",
      "\n",
      "acc:  0.8964698902402848\n",
      "pre:  0.2222222222222222\n",
      "rec:  0.19658119658119658\n",
      "ma F1:  0.5766143731999492\n",
      "mi F1:  0.8964698902402848\n",
      "we F1:  0.8935224161924727\n",
      "Eval Loss:  0.32009926438331604\n",
      "Eval Loss:  0.28118377923965454\n",
      "Eval Loss:  0.24780631065368652\n",
      "Eval Loss:  0.25293537974357605\n",
      "Eval Loss:  0.313936710357666\n",
      "Eval Loss:  0.23122252523899078\n",
      "Eval Loss:  0.2609577178955078\n",
      "Eval Loss:  0.24813911318778992\n",
      "Eval Loss:  0.28990066051483154\n",
      "Eval Loss:  0.2111077904701233\n",
      "Eval Loss:  0.3178626596927643\n",
      "Eval Loss:  0.23930871486663818\n",
      "Eval Loss:  0.1998913735151291\n",
      "Eval Loss:  0.22906416654586792\n",
      "Eval Loss:  0.20872566103935242\n",
      "Eval Loss:  0.3179953992366791\n",
      "Eval Loss:  0.2813999652862549\n",
      "Eval Loss:  0.21405398845672607\n",
      "Eval Loss:  0.22632090747356415\n",
      "Eval Loss:  0.2583591341972351\n",
      "Eval Loss:  0.26610270142555237\n",
      "Eval Loss:  0.2580406963825226\n",
      "Eval Loss:  0.3544957637786865\n",
      "Eval Loss:  0.19197136163711548\n",
      "Eval Loss:  0.3653092384338379\n",
      "Eval Loss:  0.2594403326511383\n",
      "Eval Loss:  0.3047659695148468\n",
      "Eval Loss:  0.228401780128479\n",
      "[[15151  1876]\n",
      " [ 1307 11186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90     17027\n",
      "           1       0.86      0.90      0.88     12493\n",
      "\n",
      "    accuracy                           0.89     29520\n",
      "   macro avg       0.89      0.89      0.89     29520\n",
      "weighted avg       0.89      0.89      0.89     29520\n",
      "\n",
      "acc:  0.8921747967479675\n",
      "pre:  0.8563772775991425\n",
      "rec:  0.8953814135916113\n",
      "ma F1:  0.8901938149722421\n",
      "mi F1:  0.8921747967479675\n",
      "we F1:  0.8924590788741686\n",
      "29520 462\n",
      "Loss:  0.0511833019554615\n",
      "Loss:  0.05345416069030762\n",
      "Loss:  0.08582596480846405\n",
      "57 **********\n",
      "Epoch:  3037.931755065918  fold:  4  kers:  32\n",
      "epoch:  58\n",
      "29520 462\n",
      "Loss:  0.08331204950809479\n",
      "Loss:  0.08060742914676666\n",
      "Loss:  0.08747871965169907\n",
      "58 **********\n",
      "Epoch:  3077.3244273662567  fold:  4  kers:  32\n",
      "epoch:  59\n",
      "29520 462\n",
      "Loss:  0.0922689437866211\n",
      "Loss:  0.04822546988725662\n",
      "Loss:  0.0573233924806118\n",
      "59 **********\n",
      "Epoch:  3116.7918994426727  fold:  4  kers:  32\n",
      "Eval Loss:  0.09060579538345337\n",
      "Eval Loss:  0.3600451648235321\n",
      "Eval Loss:  0.017247958108782768\n",
      "[[2945  192]\n",
      " [ 195   39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3137\n",
      "           1       0.17      0.17      0.17       234\n",
      "\n",
      "    accuracy                           0.89      3371\n",
      "   macro avg       0.55      0.55      0.55      3371\n",
      "weighted avg       0.88      0.89      0.88      3371\n",
      "\n",
      "acc:  0.8851972708395135\n",
      "pre:  0.16883116883116883\n",
      "rec:  0.16666666666666666\n",
      "ma F1:  0.5530441396393387\n",
      "mi F1:  0.8851972708395135\n",
      "we F1:  0.8848543735946406\n",
      "update!  Acc:  0.92376149510531\n",
      "Epoch:  3120.7443313598633  fold:  4  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29673 3218\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29673 464\n",
      "Loss:  0.1694105714559555\n",
      "Loss:  0.16417965292930603\n",
      "Loss:  0.15603557229042053\n",
      "0 **********\n",
      "Epoch:  52.13759398460388  fold:  5  kers:  32\n",
      "epoch:  1\n",
      "29673 464\n",
      "Loss:  0.16762807965278625\n",
      "Loss:  0.14318615198135376\n",
      "Loss:  0.13071300089359283\n",
      "1 **********\n",
      "Epoch:  91.94914627075195  fold:  5  kers:  32\n",
      "epoch:  2\n",
      "29673 464\n",
      "Loss:  0.12390215694904327\n",
      "Loss:  0.10888584703207016\n",
      "Loss:  0.12453432381153107\n",
      "2 **********\n",
      "Epoch:  131.71881008148193  fold:  5  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.17071951925754547\n",
      "Eval Loss:  0.32106927037239075\n",
      "Eval Loss:  0.33403459191322327\n",
      "[[2758  339]\n",
      " [  49   72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      3097\n",
      "           1       0.18      0.60      0.27       121\n",
      "\n",
      "    accuracy                           0.88      3218\n",
      "   macro avg       0.58      0.74      0.60      3218\n",
      "weighted avg       0.95      0.88      0.91      3218\n",
      "\n",
      "acc:  0.8794282162834058\n",
      "pre:  0.17518248175182483\n",
      "rec:  0.5950413223140496\n",
      "ma F1:  0.6024792672738757\n",
      "mi F1:  0.879428216283406\n",
      "we F1:  0.9093296292442262\n",
      "update!  Acc:  0.8794282162834058\n",
      "Eval Loss:  0.5426914095878601\n",
      "Eval Loss:  0.3941563367843628\n",
      "Eval Loss:  0.5134089589118958\n",
      "Eval Loss:  0.44344139099121094\n",
      "Eval Loss:  0.4644440710544586\n",
      "Eval Loss:  0.40205150842666626\n",
      "Eval Loss:  0.4801042377948761\n",
      "Eval Loss:  0.37347349524497986\n",
      "Eval Loss:  0.43357381224632263\n",
      "Eval Loss:  0.4904300570487976\n",
      "Eval Loss:  0.4793696403503418\n",
      "Eval Loss:  0.42403456568717957\n",
      "Eval Loss:  0.3943890929222107\n",
      "Eval Loss:  0.42799657583236694\n",
      "Eval Loss:  0.44738879799842834\n",
      "Eval Loss:  0.49302542209625244\n",
      "Eval Loss:  0.44401177763938904\n",
      "Eval Loss:  0.5320389270782471\n",
      "Eval Loss:  0.5218966007232666\n",
      "Eval Loss:  0.4456982910633087\n",
      "Eval Loss:  0.4707185924053192\n",
      "Eval Loss:  0.5315547585487366\n",
      "Eval Loss:  0.5074937343597412\n",
      "Eval Loss:  0.4885800778865814\n",
      "Eval Loss:  0.5141993165016174\n",
      "Eval Loss:  0.39321213960647583\n",
      "Eval Loss:  0.5267015099525452\n",
      "Eval Loss:  0.5088674426078796\n",
      "Eval Loss:  0.3650151491165161\n",
      "[[14524  2543]\n",
      " [ 3543  9063]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83     17067\n",
      "           1       0.78      0.72      0.75     12606\n",
      "\n",
      "    accuracy                           0.79     29673\n",
      "   macro avg       0.79      0.78      0.79     29673\n",
      "weighted avg       0.79      0.79      0.79     29673\n",
      "\n",
      "acc:  0.7948977184645974\n",
      "pre:  0.7808891952438394\n",
      "rec:  0.7189433603046168\n",
      "ma F1:  0.7877072599938847\n",
      "mi F1:  0.7948977184645974\n",
      "we F1:  0.7935810258312496\n",
      "29673 464\n",
      "Loss:  0.08505275100469589\n",
      "Loss:  0.11245173960924149\n",
      "Loss:  0.09361987560987473\n",
      "3 **********\n",
      "Epoch:  210.4921863079071  fold:  5  kers:  32\n",
      "epoch:  4\n",
      "29673 464\n",
      "Loss:  0.1298830807209015\n",
      "Loss:  0.11141595244407654\n",
      "Loss:  0.09276186674833298\n",
      "4 **********\n",
      "Epoch:  250.4712905883789  fold:  5  kers:  32\n",
      "epoch:  5\n",
      "29673 464\n",
      "Loss:  0.09145741909742355\n",
      "Loss:  0.10591455549001694\n",
      "Loss:  0.08662690222263336\n",
      "5 **********\n",
      "Epoch:  290.3386924266815  fold:  5  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.12135525047779083\n",
      "Eval Loss:  0.30701780319213867\n",
      "Eval Loss:  0.16524386405944824\n",
      "[[2963  134]\n",
      " [  55   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      3097\n",
      "           1       0.33      0.55      0.41       121\n",
      "\n",
      "    accuracy                           0.94      3218\n",
      "   macro avg       0.66      0.75      0.69      3218\n",
      "weighted avg       0.96      0.94      0.95      3218\n",
      "\n",
      "acc:  0.9412678682411436\n",
      "pre:  0.33\n",
      "rec:  0.5454545454545454\n",
      "ma F1:  0.6901536745095942\n",
      "mi F1:  0.9412678682411436\n",
      "we F1:  0.9481156491540855\n",
      "update!  Acc:  0.9412678682411436\n",
      "Eval Loss:  0.5414596199989319\n",
      "Eval Loss:  0.3590664863586426\n",
      "Eval Loss:  0.44204917550086975\n",
      "Eval Loss:  0.4304332435131073\n",
      "Eval Loss:  0.4616164565086365\n",
      "Eval Loss:  0.34916168451309204\n",
      "Eval Loss:  0.45694005489349365\n",
      "Eval Loss:  0.34888195991516113\n",
      "Eval Loss:  0.4457801580429077\n",
      "Eval Loss:  0.4279141128063202\n",
      "Eval Loss:  0.42939117550849915\n",
      "Eval Loss:  0.34470558166503906\n",
      "Eval Loss:  0.3513658344745636\n",
      "Eval Loss:  0.4336639940738678\n",
      "Eval Loss:  0.4609525501728058\n",
      "Eval Loss:  0.5023199915885925\n",
      "Eval Loss:  0.47502025961875916\n",
      "Eval Loss:  0.5890275239944458\n",
      "Eval Loss:  0.5016446113586426\n",
      "Eval Loss:  0.421770840883255\n",
      "Eval Loss:  0.454681396484375\n",
      "Eval Loss:  0.5376786589622498\n",
      "Eval Loss:  0.48944294452667236\n",
      "Eval Loss:  0.5206615924835205\n",
      "Eval Loss:  0.5419495701789856\n",
      "Eval Loss:  0.3613531291484833\n",
      "Eval Loss:  0.4818059802055359\n",
      "Eval Loss:  0.48140987753868103\n",
      "Eval Loss:  0.3229965567588806\n",
      "[[15981  1086]\n",
      " [ 4325  8281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86     17067\n",
      "           1       0.88      0.66      0.75     12606\n",
      "\n",
      "    accuracy                           0.82     29673\n",
      "   macro avg       0.84      0.80      0.80     29673\n",
      "weighted avg       0.83      0.82      0.81     29673\n",
      "\n",
      "acc:  0.8176456711488559\n",
      "pre:  0.884061065442511\n",
      "rec:  0.6569094082183088\n",
      "ma F1:  0.8044797814873466\n",
      "mi F1:  0.8176456711488559\n",
      "we F1:  0.812107448212021\n",
      "29673 464\n",
      "Loss:  0.09203965961933136\n",
      "Loss:  0.11661037057638168\n",
      "Loss:  0.06952602416276932\n",
      "6 **********\n",
      "Epoch:  368.9724428653717  fold:  5  kers:  32\n",
      "epoch:  7\n",
      "29673 464\n",
      "Loss:  0.10632297396659851\n",
      "Loss:  0.07752472162246704\n",
      "Loss:  0.08582167327404022\n",
      "7 **********\n",
      "Epoch:  408.8538074493408  fold:  5  kers:  32\n",
      "epoch:  8\n",
      "29673 464\n",
      "Loss:  0.11872515082359314\n",
      "Loss:  0.08884307742118835\n",
      "Loss:  0.06573432683944702\n",
      "8 **********\n",
      "Epoch:  448.90471959114075  fold:  5  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.12636925280094147\n",
      "Eval Loss:  0.3133239150047302\n",
      "Eval Loss:  0.12025951594114304\n",
      "[[2983  114]\n",
      " [  33   88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      3097\n",
      "           1       0.44      0.73      0.54       121\n",
      "\n",
      "    accuracy                           0.95      3218\n",
      "   macro avg       0.71      0.85      0.76      3218\n",
      "weighted avg       0.97      0.95      0.96      3218\n",
      "\n",
      "acc:  0.954319453076445\n",
      "pre:  0.43564356435643564\n",
      "rec:  0.7272727272727273\n",
      "ma F1:  0.7604222640781282\n",
      "mi F1:  0.954319453076445\n",
      "we F1:  0.9597445557738071\n",
      "update!  Acc:  0.954319453076445\n",
      "Eval Loss:  0.45575276017189026\n",
      "Eval Loss:  0.3295871615409851\n",
      "Eval Loss:  0.38356688618659973\n",
      "Eval Loss:  0.38534754514694214\n",
      "Eval Loss:  0.39664238691329956\n",
      "Eval Loss:  0.3053363263607025\n",
      "Eval Loss:  0.31774675846099854\n",
      "Eval Loss:  0.3001115322113037\n",
      "Eval Loss:  0.3525688052177429\n",
      "Eval Loss:  0.3493475615978241\n",
      "Eval Loss:  0.35305055975914\n",
      "Eval Loss:  0.3182334005832672\n",
      "Eval Loss:  0.3125793933868408\n",
      "Eval Loss:  0.36754110455513\n",
      "Eval Loss:  0.3488425612449646\n",
      "Eval Loss:  0.39379018545150757\n",
      "Eval Loss:  0.4140656590461731\n",
      "Eval Loss:  0.49204736948013306\n",
      "Eval Loss:  0.4251541197299957\n",
      "Eval Loss:  0.35178422927856445\n",
      "Eval Loss:  0.3875386118888855\n",
      "Eval Loss:  0.4699084758758545\n",
      "Eval Loss:  0.3907063901424408\n",
      "Eval Loss:  0.4152229428291321\n",
      "Eval Loss:  0.4431619346141815\n",
      "Eval Loss:  0.3377821743488312\n",
      "Eval Loss:  0.3343661427497864\n",
      "Eval Loss:  0.3718022406101227\n",
      "Eval Loss:  0.26321324706077576\n",
      "[[15813  1254]\n",
      " [ 3367  9239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87     17067\n",
      "           1       0.88      0.73      0.80     12606\n",
      "\n",
      "    accuracy                           0.84     29673\n",
      "   macro avg       0.85      0.83      0.84     29673\n",
      "weighted avg       0.85      0.84      0.84     29673\n",
      "\n",
      "acc:  0.844269200957099\n",
      "pre:  0.8804917564090345\n",
      "rec:  0.7329049658892591\n",
      "ma F1:  0.8362308185152433\n",
      "mi F1:  0.844269200957099\n",
      "we F1:  0.8416855225117628\n",
      "29673 464\n",
      "Loss:  0.09682117402553558\n",
      "Loss:  0.11680638045072556\n",
      "Loss:  0.12442385405302048\n",
      "9 **********\n",
      "Epoch:  531.2864472866058  fold:  5  kers:  32\n",
      "epoch:  10\n",
      "29673 464\n",
      "Loss:  0.08622074127197266\n",
      "Loss:  0.08722301572561264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06931731849908829\n",
      "10 **********\n",
      "Epoch:  570.4218072891235  fold:  5  kers:  32\n",
      "epoch:  11\n",
      "29673 464\n",
      "Loss:  0.10824084281921387\n",
      "Loss:  0.1002480611205101\n",
      "Loss:  0.10656630992889404\n",
      "11 **********\n",
      "Epoch:  609.5591623783112  fold:  5  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.10478478670120239\n",
      "Eval Loss:  0.2525576651096344\n",
      "Eval Loss:  0.09840336441993713\n",
      "[[3012   85]\n",
      " [  40   81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.49      0.67      0.56       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.74      0.82      0.77      3218\n",
      "weighted avg       0.97      0.96      0.96      3218\n",
      "\n",
      "acc:  0.9611559975139838\n",
      "pre:  0.4879518072289157\n",
      "rec:  0.6694214876033058\n",
      "ma F1:  0.7720657108064936\n",
      "mi F1:  0.961155997513984\n",
      "we F1:  0.9640591237172718\n",
      "update!  Acc:  0.9611559975139838\n",
      "Eval Loss:  0.4363464415073395\n",
      "Eval Loss:  0.32321396470069885\n",
      "Eval Loss:  0.3810362219810486\n",
      "Eval Loss:  0.37968873977661133\n",
      "Eval Loss:  0.4173182249069214\n",
      "Eval Loss:  0.30534863471984863\n",
      "Eval Loss:  0.3544282615184784\n",
      "Eval Loss:  0.303630530834198\n",
      "Eval Loss:  0.3496224582195282\n",
      "Eval Loss:  0.35237178206443787\n",
      "Eval Loss:  0.35241949558258057\n",
      "Eval Loss:  0.3237200379371643\n",
      "Eval Loss:  0.2961229681968689\n",
      "Eval Loss:  0.35903510451316833\n",
      "Eval Loss:  0.3739127516746521\n",
      "Eval Loss:  0.4208619296550751\n",
      "Eval Loss:  0.4165951907634735\n",
      "Eval Loss:  0.5353922843933105\n",
      "Eval Loss:  0.41328760981559753\n",
      "Eval Loss:  0.3526000380516052\n",
      "Eval Loss:  0.37147703766822815\n",
      "Eval Loss:  0.45315447449684143\n",
      "Eval Loss:  0.41218018531799316\n",
      "Eval Loss:  0.4287145137786865\n",
      "Eval Loss:  0.44763392210006714\n",
      "Eval Loss:  0.3437681794166565\n",
      "Eval Loss:  0.37432757019996643\n",
      "Eval Loss:  0.382474809885025\n",
      "Eval Loss:  0.2735649645328522\n",
      "[[16220   847]\n",
      " [ 3841  8765]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87     17067\n",
      "           1       0.91      0.70      0.79     12606\n",
      "\n",
      "    accuracy                           0.84     29673\n",
      "   macro avg       0.86      0.82      0.83     29673\n",
      "weighted avg       0.85      0.84      0.84     29673\n",
      "\n",
      "acc:  0.8420112560239948\n",
      "pre:  0.9118809821057012\n",
      "rec:  0.6953038235760749\n",
      "ma F1:  0.8313670095055616\n",
      "mi F1:  0.8420112560239948\n",
      "we F1:  0.8377364238206161\n",
      "29673 464\n",
      "Loss:  0.080929234623909\n",
      "Loss:  0.07923676818609238\n",
      "Loss:  0.06117221713066101\n",
      "12 **********\n",
      "Epoch:  687.7840046882629  fold:  5  kers:  32\n",
      "epoch:  13\n",
      "29673 464\n",
      "Loss:  0.09612631052732468\n",
      "Loss:  0.09110749512910843\n",
      "Loss:  0.10898741334676743\n",
      "13 **********\n",
      "Epoch:  727.0779407024384  fold:  5  kers:  32\n",
      "epoch:  14\n",
      "29673 464\n",
      "Loss:  0.09440875053405762\n",
      "Loss:  0.08937591314315796\n",
      "Loss:  0.09788435697555542\n",
      "14 **********\n",
      "Epoch:  766.3519303798676  fold:  5  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.10315116494894028\n",
      "Eval Loss:  0.24295605719089508\n",
      "Eval Loss:  0.07287931442260742\n",
      "[[3009   88]\n",
      " [  34   87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.50      0.72      0.59       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.74      0.85      0.78      3218\n",
      "weighted avg       0.97      0.96      0.97      3218\n",
      "\n",
      "acc:  0.9620882535736482\n",
      "pre:  0.49714285714285716\n",
      "rec:  0.71900826446281\n",
      "ma F1:  0.7839840654987236\n",
      "mi F1:  0.9620882535736482\n",
      "we F1:  0.9653797067413574\n",
      "update!  Acc:  0.9620882535736482\n",
      "Eval Loss:  0.37915509939193726\n",
      "Eval Loss:  0.315165251493454\n",
      "Eval Loss:  0.3513127267360687\n",
      "Eval Loss:  0.3705233335494995\n",
      "Eval Loss:  0.3904708921909332\n",
      "Eval Loss:  0.30062341690063477\n",
      "Eval Loss:  0.3000318109989166\n",
      "Eval Loss:  0.28643423318862915\n",
      "Eval Loss:  0.29773175716400146\n",
      "Eval Loss:  0.3232353925704956\n",
      "Eval Loss:  0.32088208198547363\n",
      "Eval Loss:  0.3023620545864105\n",
      "Eval Loss:  0.2918621599674225\n",
      "Eval Loss:  0.3312402367591858\n",
      "Eval Loss:  0.3077935576438904\n",
      "Eval Loss:  0.3768317699432373\n",
      "Eval Loss:  0.3926033079624176\n",
      "Eval Loss:  0.46981188654899597\n",
      "Eval Loss:  0.40027672052383423\n",
      "Eval Loss:  0.32037049531936646\n",
      "Eval Loss:  0.3349725008010864\n",
      "Eval Loss:  0.3999638557434082\n",
      "Eval Loss:  0.3509122133255005\n",
      "Eval Loss:  0.3949539065361023\n",
      "Eval Loss:  0.40553972125053406\n",
      "Eval Loss:  0.3265972137451172\n",
      "Eval Loss:  0.31684914231300354\n",
      "Eval Loss:  0.33661141991615295\n",
      "Eval Loss:  0.24800801277160645\n",
      "[[16019  1048]\n",
      " [ 3233  9373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88     17067\n",
      "           1       0.90      0.74      0.81     12606\n",
      "\n",
      "    accuracy                           0.86     29673\n",
      "   macro avg       0.87      0.84      0.85     29673\n",
      "weighted avg       0.86      0.86      0.85     29673\n",
      "\n",
      "acc:  0.8557274289758366\n",
      "pre:  0.8994338355244218\n",
      "rec:  0.7435348246866571\n",
      "ma F1:  0.8481078109256561\n",
      "mi F1:  0.8557274289758365\n",
      "we F1:  0.8532223333634916\n",
      "29673 464\n",
      "Loss:  0.09472642838954926\n",
      "Loss:  0.10428588092327118\n",
      "Loss:  0.07686267793178558\n",
      "15 **********\n",
      "Epoch:  843.7759146690369  fold:  5  kers:  32\n",
      "epoch:  16\n",
      "29673 464\n",
      "Loss:  0.08010556548833847\n",
      "Loss:  0.07568206638097763\n",
      "Loss:  0.08155801147222519\n",
      "16 **********\n",
      "Epoch:  883.0389325618744  fold:  5  kers:  32\n",
      "epoch:  17\n",
      "29673 464\n",
      "Loss:  0.08853956311941147\n",
      "Loss:  0.07443408668041229\n",
      "Loss:  0.08811912685632706\n",
      "17 **********\n",
      "Epoch:  922.3258872032166  fold:  5  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.08887284994125366\n",
      "Eval Loss:  0.17164941132068634\n",
      "Eval Loss:  0.08255242556333542\n",
      "[[3024   73]\n",
      " [  70   51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3097\n",
      "           1       0.41      0.42      0.42       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.69      0.70      0.70      3218\n",
      "weighted avg       0.96      0.96      0.96      3218\n",
      "\n",
      "acc:  0.9555624611559975\n",
      "pre:  0.4112903225806452\n",
      "rec:  0.4214876033057851\n",
      "ma F1:  0.6966142425311266\n",
      "mi F1:  0.9555624611559975\n",
      "we F1:  0.9558237610738834\n",
      "Eval Loss:  0.422711580991745\n",
      "Eval Loss:  0.3295578062534332\n",
      "Eval Loss:  0.3870971202850342\n",
      "Eval Loss:  0.4064125120639801\n",
      "Eval Loss:  0.44764095544815063\n",
      "Eval Loss:  0.33896908164024353\n",
      "Eval Loss:  0.4072427451610565\n",
      "Eval Loss:  0.34217143058776855\n",
      "Eval Loss:  0.3513661026954651\n",
      "Eval Loss:  0.38239583373069763\n",
      "Eval Loss:  0.34696441888809204\n",
      "Eval Loss:  0.3349371552467346\n",
      "Eval Loss:  0.3125438094139099\n",
      "Eval Loss:  0.3842913806438446\n",
      "Eval Loss:  0.4106729030609131\n",
      "Eval Loss:  0.43133580684661865\n",
      "Eval Loss:  0.44302883744239807\n",
      "Eval Loss:  0.5545034408569336\n",
      "Eval Loss:  0.42083585262298584\n",
      "Eval Loss:  0.3669078052043915\n",
      "Eval Loss:  0.3742818236351013\n",
      "Eval Loss:  0.43479958176612854\n",
      "Eval Loss:  0.455135703086853\n",
      "Eval Loss:  0.43569159507751465\n",
      "Eval Loss:  0.46199578046798706\n",
      "Eval Loss:  0.3653497099876404\n",
      "Eval Loss:  0.41416025161743164\n",
      "Eval Loss:  0.4004567861557007\n",
      "Eval Loss:  0.29485023021698\n",
      "[[16467   600]\n",
      " [ 4302  8304]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87     17067\n",
      "           1       0.93      0.66      0.77     12606\n",
      "\n",
      "    accuracy                           0.83     29673\n",
      "   macro avg       0.86      0.81      0.82     29673\n",
      "weighted avg       0.85      0.83      0.83     29673\n",
      "\n",
      "acc:  0.8347993125063189\n",
      "pre:  0.9326145552560647\n",
      "rec:  0.6587339362208472\n",
      "ma F1:  0.8212734235973709\n",
      "mi F1:  0.8347993125063189\n",
      "we F1:  0.8286651901565791\n",
      "29673 464\n",
      "Loss:  0.11769034713506699\n",
      "Loss:  0.10412973910570145\n",
      "Loss:  0.06535201519727707\n",
      "18 **********\n",
      "Epoch:  999.9054555892944  fold:  5  kers:  32\n",
      "epoch:  19\n",
      "29673 464\n",
      "Loss:  0.07061997056007385\n",
      "Loss:  0.09674572944641113\n",
      "Loss:  0.10235170274972916\n",
      "19 **********\n",
      "Epoch:  1039.1973962783813  fold:  5  kers:  32\n",
      "epoch:  20\n",
      "29673 464\n",
      "Loss:  0.08203674852848053\n",
      "Loss:  0.08241046220064163\n",
      "Loss:  0.07631276547908783\n",
      "20 **********\n",
      "Epoch:  1078.5013060569763  fold:  5  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.09612254798412323\n",
      "Eval Loss:  0.2480771243572235\n",
      "Eval Loss:  0.07828371971845627\n",
      "[[3011   86]\n",
      " [  49   72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      3097\n",
      "           1       0.46      0.60      0.52       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.72      0.78      0.75      3218\n",
      "weighted avg       0.96      0.96      0.96      3218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc:  0.9580484773151026\n",
      "pre:  0.45569620253164556\n",
      "rec:  0.5950413223140496\n",
      "ma F1:  0.7471013847338723\n",
      "mi F1:  0.9580484773151025\n",
      "we F1:  0.960704156942699\n",
      "Eval Loss:  0.34493911266326904\n",
      "Eval Loss:  0.2896522283554077\n",
      "Eval Loss:  0.33661550283432007\n",
      "Eval Loss:  0.34754788875579834\n",
      "Eval Loss:  0.3688262104988098\n",
      "Eval Loss:  0.3033488690853119\n",
      "Eval Loss:  0.3080713152885437\n",
      "Eval Loss:  0.27117669582366943\n",
      "Eval Loss:  0.2763662338256836\n",
      "Eval Loss:  0.3000776469707489\n",
      "Eval Loss:  0.28643903136253357\n",
      "Eval Loss:  0.2922128140926361\n",
      "Eval Loss:  0.25245851278305054\n",
      "Eval Loss:  0.29014796018600464\n",
      "Eval Loss:  0.27129286527633667\n",
      "Eval Loss:  0.3405294716358185\n",
      "Eval Loss:  0.3725140690803528\n",
      "Eval Loss:  0.44428202509880066\n",
      "Eval Loss:  0.40820828080177307\n",
      "Eval Loss:  0.2956852912902832\n",
      "Eval Loss:  0.31298398971557617\n",
      "Eval Loss:  0.351077139377594\n",
      "Eval Loss:  0.33475741744041443\n",
      "Eval Loss:  0.3849359452724457\n",
      "Eval Loss:  0.39380061626434326\n",
      "Eval Loss:  0.299578994512558\n",
      "Eval Loss:  0.30163222551345825\n",
      "Eval Loss:  0.31373146176338196\n",
      "Eval Loss:  0.22753199934959412\n",
      "[[16042  1025]\n",
      " [ 2971  9635]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     17067\n",
      "           1       0.90      0.76      0.83     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.87      0.85      0.86     29673\n",
      "weighted avg       0.87      0.87      0.86     29673\n",
      "\n",
      "acc:  0.8653321201091901\n",
      "pre:  0.9038461538461539\n",
      "rec:  0.7643185784547041\n",
      "ma F1:  0.8587466737240929\n",
      "mi F1:  0.8653321201091901\n",
      "we F1:  0.8633319205360047\n",
      "29673 464\n",
      "Loss:  0.06875237077474594\n",
      "Loss:  0.0709039494395256\n",
      "Loss:  0.07939691096544266\n",
      "21 **********\n",
      "Epoch:  1156.0579352378845  fold:  5  kers:  32\n",
      "epoch:  22\n",
      "29673 464\n",
      "Loss:  0.07913617789745331\n",
      "Loss:  0.10323251038789749\n",
      "Loss:  0.09562916308641434\n",
      "22 **********\n",
      "Epoch:  1195.3349170684814  fold:  5  kers:  32\n",
      "epoch:  23\n",
      "29673 464\n",
      "Loss:  0.08360444009304047\n",
      "Loss:  0.04694374278187752\n",
      "Loss:  0.07518450915813446\n",
      "23 **********\n",
      "Epoch:  1234.6617648601532  fold:  5  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.09574208408594131\n",
      "Eval Loss:  0.24583715200424194\n",
      "Eval Loss:  0.06836714595556259\n",
      "[[2997  100]\n",
      " [  34   87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.47      0.72      0.56       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.73      0.84      0.77      3218\n",
      "weighted avg       0.97      0.96      0.96      3218\n",
      "\n",
      "acc:  0.9583592293349906\n",
      "pre:  0.46524064171123\n",
      "rec:  0.71900826446281\n",
      "ma F1:  0.7715341121019972\n",
      "mi F1:  0.9583592293349906\n",
      "we F1:  0.9625965000351203\n",
      "Eval Loss:  0.3278740346431732\n",
      "Eval Loss:  0.29583385586738586\n",
      "Eval Loss:  0.29467833042144775\n",
      "Eval Loss:  0.3353164792060852\n",
      "Eval Loss:  0.32439252734184265\n",
      "Eval Loss:  0.30184829235076904\n",
      "Eval Loss:  0.2685541808605194\n",
      "Eval Loss:  0.2680402994155884\n",
      "Eval Loss:  0.25864437222480774\n",
      "Eval Loss:  0.2964719235897064\n",
      "Eval Loss:  0.2842913568019867\n",
      "Eval Loss:  0.265381783246994\n",
      "Eval Loss:  0.24450862407684326\n",
      "Eval Loss:  0.278619647026062\n",
      "Eval Loss:  0.23242488503456116\n",
      "Eval Loss:  0.2985294759273529\n",
      "Eval Loss:  0.3333793580532074\n",
      "Eval Loss:  0.40064895153045654\n",
      "Eval Loss:  0.3691072463989258\n",
      "Eval Loss:  0.24884578585624695\n",
      "Eval Loss:  0.2920719385147095\n",
      "Eval Loss:  0.34527966380119324\n",
      "Eval Loss:  0.3097018599510193\n",
      "Eval Loss:  0.31806686520576477\n",
      "Eval Loss:  0.3675743043422699\n",
      "Eval Loss:  0.29690492153167725\n",
      "Eval Loss:  0.26805150508880615\n",
      "Eval Loss:  0.2951717972755432\n",
      "Eval Loss:  0.21290041506290436\n",
      "[[15808  1259]\n",
      " [ 2463 10143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.89     17067\n",
      "           1       0.89      0.80      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.87      0.87     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.874566103865467\n",
      "pre:  0.8895807753025785\n",
      "rec:  0.804616849119467\n",
      "ma F1:  0.8698213160934583\n",
      "mi F1:  0.874566103865467\n",
      "we F1:  0.8735576794210717\n",
      "29673 464\n",
      "Loss:  0.07763015478849411\n",
      "Loss:  0.10240932554006577\n",
      "Loss:  0.09278863668441772\n",
      "24 **********\n",
      "Epoch:  1312.3530344963074  fold:  5  kers:  32\n",
      "epoch:  25\n",
      "29673 464\n",
      "Loss:  0.10535570979118347\n",
      "Loss:  0.07036137580871582\n",
      "Loss:  0.10294289141893387\n",
      "25 **********\n",
      "Epoch:  1351.6868631839752  fold:  5  kers:  32\n",
      "epoch:  26\n",
      "29673 464\n",
      "Loss:  0.0924149677157402\n",
      "Loss:  0.09963925927877426\n",
      "Loss:  0.09536691755056381\n",
      "26 **********\n",
      "Epoch:  1390.9807991981506  fold:  5  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.08717761933803558\n",
      "Eval Loss:  0.1879459172487259\n",
      "Eval Loss:  0.07112491130828857\n",
      "[[3016   81]\n",
      " [  41   80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.50      0.66      0.57       121\n",
      "\n",
      "    accuracy                           0.96      3218\n",
      "   macro avg       0.74      0.82      0.77      3218\n",
      "weighted avg       0.97      0.96      0.96      3218\n",
      "\n",
      "acc:  0.9620882535736482\n",
      "pre:  0.4968944099378882\n",
      "rec:  0.6611570247933884\n",
      "ma F1:  0.7737756910687161\n",
      "mi F1:  0.9620882535736482\n",
      "we F1:  0.9646538198203095\n",
      "Eval Loss:  0.3098258972167969\n",
      "Eval Loss:  0.28180158138275146\n",
      "Eval Loss:  0.3021869957447052\n",
      "Eval Loss:  0.34350329637527466\n",
      "Eval Loss:  0.32018521428108215\n",
      "Eval Loss:  0.30066028237342834\n",
      "Eval Loss:  0.2827427387237549\n",
      "Eval Loss:  0.2686717212200165\n",
      "Eval Loss:  0.256130576133728\n",
      "Eval Loss:  0.2951662540435791\n",
      "Eval Loss:  0.2615785300731659\n",
      "Eval Loss:  0.2650449275970459\n",
      "Eval Loss:  0.24400457739830017\n",
      "Eval Loss:  0.27406829595565796\n",
      "Eval Loss:  0.24539069831371307\n",
      "Eval Loss:  0.298427015542984\n",
      "Eval Loss:  0.3307190239429474\n",
      "Eval Loss:  0.4084490239620209\n",
      "Eval Loss:  0.360689640045166\n",
      "Eval Loss:  0.2533900737762451\n",
      "Eval Loss:  0.2882672846317291\n",
      "Eval Loss:  0.3312199115753174\n",
      "Eval Loss:  0.3158024251461029\n",
      "Eval Loss:  0.3161795139312744\n",
      "Eval Loss:  0.37240245938301086\n",
      "Eval Loss:  0.28793370723724365\n",
      "Eval Loss:  0.29188910126686096\n",
      "Eval Loss:  0.28725624084472656\n",
      "Eval Loss:  0.2203298956155777\n",
      "[[16037  1030]\n",
      " [ 2705  9901]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     17067\n",
      "           1       0.91      0.79      0.84     12606\n",
      "\n",
      "    accuracy                           0.87     29673\n",
      "   macro avg       0.88      0.86      0.87     29673\n",
      "weighted avg       0.88      0.87      0.87     29673\n",
      "\n",
      "acc:  0.8741279951471034\n",
      "pre:  0.9057725734150581\n",
      "rec:  0.7854196414405838\n",
      "ma F1:  0.8685051444614047\n",
      "mi F1:  0.8741279951471034\n",
      "we F1:  0.8725930742053587\n",
      "29673 464\n",
      "Loss:  0.0898500308394432\n",
      "Loss:  0.08544114232063293\n",
      "Loss:  0.061765868216753006\n",
      "27 **********\n",
      "Epoch:  1469.1717326641083  fold:  5  kers:  32\n",
      "epoch:  28\n",
      "29673 464\n",
      "Loss:  0.08476301282644272\n",
      "Loss:  0.08993852883577347\n",
      "Loss:  0.05973745509982109\n",
      "28 **********\n",
      "Epoch:  1508.4457223415375  fold:  5  kers:  32\n",
      "epoch:  29\n",
      "29673 464\n",
      "Loss:  0.07302507013082504\n",
      "Loss:  0.05955296382308006\n",
      "Loss:  0.055751148611307144\n",
      "29 **********\n",
      "Epoch:  1547.7097382545471  fold:  5  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.08410434424877167\n",
      "Eval Loss:  0.1705837845802307\n",
      "Eval Loss:  0.054278451949357986\n",
      "[[3026   71]\n",
      " [  39   82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.54      0.68      0.60       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.76      0.83      0.79      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9658172778123058\n",
      "pre:  0.5359477124183006\n",
      "rec:  0.6776859504132231\n",
      "ma F1:  0.7903443995100652\n",
      "mi F1:  0.9658172778123058\n",
      "we F1:  0.9677245917068954\n",
      "update!  Acc:  0.9658172778123058\n",
      "Eval Loss:  0.2948625385761261\n",
      "Eval Loss:  0.2694416046142578\n",
      "Eval Loss:  0.3124198019504547\n",
      "Eval Loss:  0.3133440315723419\n",
      "Eval Loss:  0.3053251802921295\n",
      "Eval Loss:  0.3086589574813843\n",
      "Eval Loss:  0.27998921275138855\n",
      "Eval Loss:  0.26682138442993164\n",
      "Eval Loss:  0.2472461760044098\n",
      "Eval Loss:  0.2840191125869751\n",
      "Eval Loss:  0.25377190113067627\n",
      "Eval Loss:  0.24881212413311005\n",
      "Eval Loss:  0.22563575208187103\n",
      "Eval Loss:  0.2575565576553345\n",
      "Eval Loss:  0.22556926310062408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.28304579854011536\n",
      "Eval Loss:  0.3143063485622406\n",
      "Eval Loss:  0.3652321994304657\n",
      "Eval Loss:  0.35986292362213135\n",
      "Eval Loss:  0.2286471277475357\n",
      "Eval Loss:  0.2689955234527588\n",
      "Eval Loss:  0.3196524977684021\n",
      "Eval Loss:  0.30011650919914246\n",
      "Eval Loss:  0.3053399920463562\n",
      "Eval Loss:  0.3751458525657654\n",
      "Eval Loss:  0.28725361824035645\n",
      "Eval Loss:  0.2775445580482483\n",
      "Eval Loss:  0.28859734535217285\n",
      "Eval Loss:  0.20646324753761292\n",
      "[[15975  1092]\n",
      " [ 2483 10123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     17067\n",
      "           1       0.90      0.80      0.85     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.88      0.87      0.87     29673\n",
      "weighted avg       0.88      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8795201024500388\n",
      "pre:  0.9026304057066429\n",
      "rec:  0.803030303030303\n",
      "ma F1:  0.8746444903211824\n",
      "mi F1:  0.8795201024500388\n",
      "we F1:  0.8783611864433335\n",
      "29673 464\n",
      "Loss:  0.057309672236442566\n",
      "Loss:  0.08942243456840515\n",
      "Loss:  0.06895309686660767\n",
      "30 **********\n",
      "Epoch:  1625.4628422260284  fold:  5  kers:  32\n",
      "epoch:  31\n",
      "29673 464\n",
      "Loss:  0.06975924223661423\n",
      "Loss:  0.07949574291706085\n",
      "Loss:  0.08916255831718445\n",
      "31 **********\n",
      "Epoch:  1664.7109005451202  fold:  5  kers:  32\n",
      "epoch:  32\n",
      "29673 464\n",
      "Loss:  0.07829277217388153\n",
      "Loss:  0.06339333951473236\n",
      "Loss:  0.10903569310903549\n",
      "32 **********\n",
      "Epoch:  1703.9848899841309  fold:  5  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.08291277289390564\n",
      "Eval Loss:  0.1530265510082245\n",
      "Eval Loss:  0.04696739464998245\n",
      "[[3031   66]\n",
      " [  41   80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.55      0.66      0.60       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.82      0.79      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9667495338719702\n",
      "pre:  0.547945205479452\n",
      "rec:  0.6611570247933884\n",
      "ma F1:  0.7909530739355835\n",
      "mi F1:  0.96674953387197\n",
      "we F1:  0.9682388295339185\n",
      "update!  Acc:  0.9667495338719702\n",
      "Eval Loss:  0.2887042760848999\n",
      "Eval Loss:  0.26257288455963135\n",
      "Eval Loss:  0.3081035017967224\n",
      "Eval Loss:  0.2912358045578003\n",
      "Eval Loss:  0.3017190396785736\n",
      "Eval Loss:  0.3180454969406128\n",
      "Eval Loss:  0.2792099714279175\n",
      "Eval Loss:  0.27323949337005615\n",
      "Eval Loss:  0.25128456950187683\n",
      "Eval Loss:  0.28587213158607483\n",
      "Eval Loss:  0.2488912045955658\n",
      "Eval Loss:  0.2365252524614334\n",
      "Eval Loss:  0.21302500367164612\n",
      "Eval Loss:  0.25589197874069214\n",
      "Eval Loss:  0.21805399656295776\n",
      "Eval Loss:  0.27955225110054016\n",
      "Eval Loss:  0.29804307222366333\n",
      "Eval Loss:  0.3381548225879669\n",
      "Eval Loss:  0.3736360967159271\n",
      "Eval Loss:  0.22139452397823334\n",
      "Eval Loss:  0.25369375944137573\n",
      "Eval Loss:  0.31120020151138306\n",
      "Eval Loss:  0.29697057604789734\n",
      "Eval Loss:  0.2858124375343323\n",
      "Eval Loss:  0.36724117398262024\n",
      "Eval Loss:  0.28225794434547424\n",
      "Eval Loss:  0.2652698755264282\n",
      "Eval Loss:  0.28276723623275757\n",
      "Eval Loss:  0.19407892227172852\n",
      "[[15903  1164]\n",
      " [ 2271 10335]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     17067\n",
      "           1       0.90      0.82      0.86     12606\n",
      "\n",
      "    accuracy                           0.88     29673\n",
      "   macro avg       0.89      0.88      0.88     29673\n",
      "weighted avg       0.89      0.88      0.88     29673\n",
      "\n",
      "acc:  0.8842381963401071\n",
      "pre:  0.8987738064179494\n",
      "rec:  0.8198476915754402\n",
      "ma F1:  0.8800133747026674\n",
      "mi F1:  0.8842381963401071\n",
      "we F1:  0.8833982398830947\n",
      "29673 464\n",
      "Loss:  0.06195848435163498\n",
      "Loss:  0.06841941177845001\n",
      "Loss:  0.05980076640844345\n",
      "33 **********\n",
      "Epoch:  1781.7010927200317  fold:  5  kers:  32\n",
      "epoch:  34\n",
      "29673 464\n",
      "Loss:  0.06693191081285477\n",
      "Loss:  0.12368367612361908\n",
      "Loss:  0.12415372580289841\n",
      "34 **********\n",
      "Epoch:  1821.059855222702  fold:  5  kers:  32\n",
      "epoch:  35\n",
      "29673 464\n",
      "Loss:  0.07596457004547119\n",
      "Loss:  0.053685836493968964\n",
      "Loss:  0.07554329931735992\n",
      "35 **********\n",
      "Epoch:  1860.3298554420471  fold:  5  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.08043023198843002\n",
      "Eval Loss:  0.16016755998134613\n",
      "Eval Loss:  0.0467042550444603\n",
      "[[3033   64]\n",
      " [  28   93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.59      0.77      0.67       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.79      0.87      0.83      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9714108141702921\n",
      "pre:  0.5923566878980892\n",
      "rec:  0.768595041322314\n",
      "ma F1:  0.8270624163222199\n",
      "mi F1:  0.9714108141702921\n",
      "we F1:  0.9731783455725133\n",
      "update!  Acc:  0.9714108141702921\n",
      "Eval Loss:  0.2677266001701355\n",
      "Eval Loss:  0.2828953266143799\n",
      "Eval Loss:  0.29048025608062744\n",
      "Eval Loss:  0.2969933748245239\n",
      "Eval Loss:  0.2893856465816498\n",
      "Eval Loss:  0.3331453502178192\n",
      "Eval Loss:  0.25706037878990173\n",
      "Eval Loss:  0.25198066234588623\n",
      "Eval Loss:  0.229400634765625\n",
      "Eval Loss:  0.26851698756217957\n",
      "Eval Loss:  0.2593704164028168\n",
      "Eval Loss:  0.235289067029953\n",
      "Eval Loss:  0.21742384135723114\n",
      "Eval Loss:  0.2493346929550171\n",
      "Eval Loss:  0.19161544740200043\n",
      "Eval Loss:  0.2672942578792572\n",
      "Eval Loss:  0.29321911931037903\n",
      "Eval Loss:  0.33893266320228577\n",
      "Eval Loss:  0.35641348361968994\n",
      "Eval Loss:  0.21152076125144958\n",
      "Eval Loss:  0.2426866739988327\n",
      "Eval Loss:  0.30293601751327515\n",
      "Eval Loss:  0.2859502136707306\n",
      "Eval Loss:  0.27643245458602905\n",
      "Eval Loss:  0.3793680965900421\n",
      "Eval Loss:  0.27975788712501526\n",
      "Eval Loss:  0.252257764339447\n",
      "Eval Loss:  0.276114821434021\n",
      "Eval Loss:  0.19029518961906433\n",
      "[[15762  1305]\n",
      " [ 2067 10539]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     17067\n",
      "           1       0.89      0.84      0.86     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.88      0.88     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8863613385906379\n",
      "pre:  0.8898176291793313\n",
      "rec:  0.8360304616849119\n",
      "ma F1:  0.8827279516628551\n",
      "mi F1:  0.8863613385906379\n",
      "we F1:  0.885831252272627\n",
      "29673 464\n",
      "Loss:  0.08029768615961075\n",
      "Loss:  0.07465650141239166\n",
      "Loss:  0.06745293736457825\n",
      "36 **********\n",
      "Epoch:  1938.1517753601074  fold:  5  kers:  32\n",
      "epoch:  37\n",
      "29673 464\n",
      "Loss:  0.05899946764111519\n",
      "Loss:  0.07691136002540588\n",
      "Loss:  0.056876447051763535\n",
      "37 **********\n",
      "Epoch:  1977.4467089176178  fold:  5  kers:  32\n",
      "epoch:  38\n",
      "29673 464\n",
      "Loss:  0.08105362206697464\n",
      "Loss:  0.08206441253423691\n",
      "Loss:  0.04768935590982437\n",
      "38 **********\n",
      "Epoch:  2016.6818017959595  fold:  5  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.08350919932126999\n",
      "Eval Loss:  0.18835288286209106\n",
      "Eval Loss:  0.05974796414375305\n",
      "[[3015   82]\n",
      " [  29   92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3097\n",
      "           1       0.53      0.76      0.62       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.76      0.87      0.80      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9655065257924177\n",
      "pre:  0.5287356321839081\n",
      "rec:  0.7603305785123967\n",
      "ma F1:  0.802826790756212\n",
      "mi F1:  0.9655065257924177\n",
      "we F1:  0.9684562438755236\n",
      "Eval Loss:  0.2760307192802429\n",
      "Eval Loss:  0.27187368273735046\n",
      "Eval Loss:  0.27621224522590637\n",
      "Eval Loss:  0.29063135385513306\n",
      "Eval Loss:  0.2578383982181549\n",
      "Eval Loss:  0.3482191264629364\n",
      "Eval Loss:  0.24417974054813385\n",
      "Eval Loss:  0.24209542572498322\n",
      "Eval Loss:  0.22636540234088898\n",
      "Eval Loss:  0.27032968401908875\n",
      "Eval Loss:  0.251390665769577\n",
      "Eval Loss:  0.21479101479053497\n",
      "Eval Loss:  0.20901282131671906\n",
      "Eval Loss:  0.21991321444511414\n",
      "Eval Loss:  0.1843106746673584\n",
      "Eval Loss:  0.2602105736732483\n",
      "Eval Loss:  0.2742021381855011\n",
      "Eval Loss:  0.3035777509212494\n",
      "Eval Loss:  0.3641369342803955\n",
      "Eval Loss:  0.21965931355953217\n",
      "Eval Loss:  0.2468697428703308\n",
      "Eval Loss:  0.30051809549331665\n",
      "Eval Loss:  0.2671950161457062\n",
      "Eval Loss:  0.25651124119758606\n",
      "Eval Loss:  0.35417571663856506\n",
      "Eval Loss:  0.2533324956893921\n",
      "Eval Loss:  0.23923993110656738\n",
      "Eval Loss:  0.2591125965118408\n",
      "Eval Loss:  0.18399958312511444\n",
      "[[15488  1579]\n",
      " [ 1663 10943]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91     17067\n",
      "           1       0.87      0.87      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8907424257742729\n",
      "pre:  0.8739019325986264\n",
      "rec:  0.8680786926860226\n",
      "ma F1:  0.888117561912571\n",
      "mi F1:  0.890742425774273\n",
      "we F1:  0.8906939134388752\n",
      "29673 464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.060215938836336136\n",
      "Loss:  0.10862819105386734\n",
      "Loss:  0.05389530211687088\n",
      "39 **********\n",
      "Epoch:  2094.4408905506134  fold:  5  kers:  32\n",
      "epoch:  40\n",
      "29673 464\n",
      "Loss:  0.07280439883470535\n",
      "Loss:  0.09705989062786102\n",
      "Loss:  0.10543610900640488\n",
      "40 **********\n",
      "Epoch:  2133.7368206977844  fold:  5  kers:  32\n",
      "epoch:  41\n",
      "29673 464\n",
      "Loss:  0.049732740968465805\n",
      "Loss:  0.07347477972507477\n",
      "Loss:  0.09020958095788956\n",
      "41 **********\n",
      "Epoch:  2173.0876047611237  fold:  5  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.06751997768878937\n",
      "Eval Loss:  0.14107094705104828\n",
      "Eval Loss:  0.04013582319021225\n",
      "[[3049   48]\n",
      " [  38   83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.63      0.69      0.66       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.81      0.84      0.82      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9732753262896209\n",
      "pre:  0.6335877862595419\n",
      "rec:  0.6859504132231405\n",
      "ma F1:  0.8224116511632682\n",
      "mi F1:  0.9732753262896209\n",
      "we F1:  0.9737839698335399\n",
      "update!  Acc:  0.9732753262896209\n",
      "Eval Loss:  0.28351256251335144\n",
      "Eval Loss:  0.2513515055179596\n",
      "Eval Loss:  0.297398179769516\n",
      "Eval Loss:  0.2802255153656006\n",
      "Eval Loss:  0.28386858105659485\n",
      "Eval Loss:  0.3390832841396332\n",
      "Eval Loss:  0.28069359064102173\n",
      "Eval Loss:  0.25645771622657776\n",
      "Eval Loss:  0.23982098698616028\n",
      "Eval Loss:  0.26246345043182373\n",
      "Eval Loss:  0.24033035337924957\n",
      "Eval Loss:  0.21453143656253815\n",
      "Eval Loss:  0.19034643471240997\n",
      "Eval Loss:  0.22381357848644257\n",
      "Eval Loss:  0.20338307321071625\n",
      "Eval Loss:  0.2830672562122345\n",
      "Eval Loss:  0.27871060371398926\n",
      "Eval Loss:  0.3128211200237274\n",
      "Eval Loss:  0.3567212224006653\n",
      "Eval Loss:  0.21334107220172882\n",
      "Eval Loss:  0.23928871750831604\n",
      "Eval Loss:  0.28729721903800964\n",
      "Eval Loss:  0.2790173292160034\n",
      "Eval Loss:  0.2652764618396759\n",
      "Eval Loss:  0.3620026707649231\n",
      "Eval Loss:  0.25529271364212036\n",
      "Eval Loss:  0.26166924834251404\n",
      "Eval Loss:  0.26044803857803345\n",
      "Eval Loss:  0.17647160589694977\n",
      "[[15875  1192]\n",
      " [ 2018 10588]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     17067\n",
      "           1       0.90      0.84      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.89182084723486\n",
      "pre:  0.8988115449915111\n",
      "rec:  0.8399174996033635\n",
      "ma F1:  0.8882739369533594\n",
      "mi F1:  0.89182084723486\n",
      "we F1:  0.8912667053978032\n",
      "29673 464\n",
      "Loss:  0.06724970787763596\n",
      "Loss:  0.09891334176063538\n",
      "Loss:  0.0509813167154789\n",
      "42 **********\n",
      "Epoch:  2250.715044736862  fold:  5  kers:  32\n",
      "epoch:  43\n",
      "29673 464\n",
      "Loss:  0.053219329565763474\n",
      "Loss:  0.08181452751159668\n",
      "Loss:  0.07939767092466354\n",
      "43 **********\n",
      "Epoch:  2290.0428895950317  fold:  5  kers:  32\n",
      "epoch:  44\n",
      "29673 464\n",
      "Loss:  0.06021435558795929\n",
      "Loss:  0.06873561441898346\n",
      "Loss:  0.05279695615172386\n",
      "44 **********\n",
      "Epoch:  2329.2600314617157  fold:  5  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.06816023588180542\n",
      "Eval Loss:  0.11740989983081818\n",
      "Eval Loss:  0.03778880834579468\n",
      "[[3051   46]\n",
      " [  40   81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3097\n",
      "           1       0.64      0.67      0.65       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.81      0.83      0.82      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9732753262896209\n",
      "pre:  0.6377952755905512\n",
      "rec:  0.6694214876033058\n",
      "ma F1:  0.8196639698062846\n",
      "mi F1:  0.9732753262896209\n",
      "we F1:  0.9735856522623144\n",
      "Eval Loss:  0.27327364683151245\n",
      "Eval Loss:  0.2546527087688446\n",
      "Eval Loss:  0.2690238654613495\n",
      "Eval Loss:  0.29130780696868896\n",
      "Eval Loss:  0.26369062066078186\n",
      "Eval Loss:  0.3171582520008087\n",
      "Eval Loss:  0.2638692259788513\n",
      "Eval Loss:  0.27148839831352234\n",
      "Eval Loss:  0.23632091283798218\n",
      "Eval Loss:  0.2775627374649048\n",
      "Eval Loss:  0.2357013076543808\n",
      "Eval Loss:  0.21779115498065948\n",
      "Eval Loss:  0.18437379598617554\n",
      "Eval Loss:  0.2358909398317337\n",
      "Eval Loss:  0.2006240338087082\n",
      "Eval Loss:  0.26346972584724426\n",
      "Eval Loss:  0.26096874475479126\n",
      "Eval Loss:  0.3270067870616913\n",
      "Eval Loss:  0.34726443886756897\n",
      "Eval Loss:  0.19947369396686554\n",
      "Eval Loss:  0.23067936301231384\n",
      "Eval Loss:  0.29355886578559875\n",
      "Eval Loss:  0.28272703289985657\n",
      "Eval Loss:  0.2479488104581833\n",
      "Eval Loss:  0.3503331243991852\n",
      "Eval Loss:  0.24979707598686218\n",
      "Eval Loss:  0.2570003569126129\n",
      "Eval Loss:  0.2614886462688446\n",
      "Eval Loss:  0.18252980709075928\n",
      "[[15942  1125]\n",
      " [ 2023 10583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     17067\n",
      "           1       0.90      0.84      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.90      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8939102888147474\n",
      "pre:  0.9039118551417834\n",
      "rec:  0.8395208630810725\n",
      "ma F1:  0.890333284725421\n",
      "mi F1:  0.8939102888147474\n",
      "we F1:  0.8933108953323412\n",
      "29673 464\n",
      "Loss:  0.07268049567937851\n",
      "Loss:  0.07558263838291168\n",
      "Loss:  0.06523651629686356\n",
      "45 **********\n",
      "Epoch:  2406.961274623871  fold:  5  kers:  32\n",
      "epoch:  46\n",
      "29673 464\n",
      "Loss:  0.06179768592119217\n",
      "Loss:  0.0936683937907219\n",
      "Loss:  0.05203654244542122\n",
      "46 **********\n",
      "Epoch:  2446.183402299881  fold:  5  kers:  32\n",
      "epoch:  47\n",
      "29673 464\n",
      "Loss:  0.05915284901857376\n",
      "Loss:  0.07955332845449448\n",
      "Loss:  0.044716328382492065\n",
      "47 **********\n",
      "Epoch:  2485.434452533722  fold:  5  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.07700978964567184\n",
      "Eval Loss:  0.17079809308052063\n",
      "Eval Loss:  0.05041593313217163\n",
      "[[3031   66]\n",
      " [  31   90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.58      0.74      0.65       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.78      0.86      0.82      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9698570540708514\n",
      "pre:  0.5769230769230769\n",
      "rec:  0.743801652892562\n",
      "ma F1:  0.8170350923159615\n",
      "mi F1:  0.9698570540708514\n",
      "we F1:  0.9716757445371627\n",
      "Eval Loss:  0.2687840759754181\n",
      "Eval Loss:  0.2617017328739166\n",
      "Eval Loss:  0.2682146728038788\n",
      "Eval Loss:  0.27814993262290955\n",
      "Eval Loss:  0.232130765914917\n",
      "Eval Loss:  0.3358158767223358\n",
      "Eval Loss:  0.2436286360025406\n",
      "Eval Loss:  0.23685871064662933\n",
      "Eval Loss:  0.2257341742515564\n",
      "Eval Loss:  0.25292590260505676\n",
      "Eval Loss:  0.23422369360923767\n",
      "Eval Loss:  0.20820775628089905\n",
      "Eval Loss:  0.2042781263589859\n",
      "Eval Loss:  0.20299556851387024\n",
      "Eval Loss:  0.17717185616493225\n",
      "Eval Loss:  0.26390036940574646\n",
      "Eval Loss:  0.2669435441493988\n",
      "Eval Loss:  0.29481253027915955\n",
      "Eval Loss:  0.36683040857315063\n",
      "Eval Loss:  0.21632185578346252\n",
      "Eval Loss:  0.22780030965805054\n",
      "Eval Loss:  0.2767203748226166\n",
      "Eval Loss:  0.2624748945236206\n",
      "Eval Loss:  0.2502064108848572\n",
      "Eval Loss:  0.34697437286376953\n",
      "Eval Loss:  0.25249725580215454\n",
      "Eval Loss:  0.22026947140693665\n",
      "Eval Loss:  0.24623355269432068\n",
      "Eval Loss:  0.16146130859851837\n",
      "[[15480  1587]\n",
      " [ 1508 11098]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     17067\n",
      "           1       0.87      0.88      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.8956964243588448\n",
      "pre:  0.8748916042569964\n",
      "rec:  0.8803744248770426\n",
      "ma F1:  0.8933710276309756\n",
      "mi F1:  0.8956964243588448\n",
      "we F1:  0.8957383473030488\n",
      "29673 464\n",
      "Loss:  0.07555872201919556\n",
      "Loss:  0.06163392588496208\n",
      "Loss:  0.06719604134559631\n",
      "48 **********\n",
      "Epoch:  2563.160628557205  fold:  5  kers:  32\n",
      "epoch:  49\n",
      "29673 464\n",
      "Loss:  0.06058523803949356\n",
      "Loss:  0.04749298468232155\n",
      "Loss:  0.08677877485752106\n",
      "49 **********\n",
      "Epoch:  2602.4066922664642  fold:  5  kers:  32\n",
      "epoch:  50\n",
      "29673 464\n",
      "Loss:  0.0679667517542839\n",
      "Loss:  0.06546583026647568\n",
      "Loss:  0.06540630012750626\n",
      "50 **********\n",
      "Epoch:  2641.6846714019775  fold:  5  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.07142424583435059\n",
      "Eval Loss:  0.16219522058963776\n",
      "Eval Loss:  0.039546892046928406\n",
      "[[3035   62]\n",
      " [  27   94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.60      0.78      0.68       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.80      0.88      0.83      3218\n",
      "weighted avg       0.98      0.97      0.97      3218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc:  0.9723430702299565\n",
      "pre:  0.6025641025641025\n",
      "rec:  0.7768595041322314\n",
      "ma F1:  0.8321249816094904\n",
      "mi F1:  0.9723430702299565\n",
      "we F1:  0.9740117656062627\n",
      "Eval Loss:  0.28518491983413696\n",
      "Eval Loss:  0.27179521322250366\n",
      "Eval Loss:  0.26927679777145386\n",
      "Eval Loss:  0.27511492371559143\n",
      "Eval Loss:  0.22151601314544678\n",
      "Eval Loss:  0.32626429200172424\n",
      "Eval Loss:  0.24643199145793915\n",
      "Eval Loss:  0.2369767129421234\n",
      "Eval Loss:  0.23257777094841003\n",
      "Eval Loss:  0.29029709100723267\n",
      "Eval Loss:  0.2707040309906006\n",
      "Eval Loss:  0.20552274584770203\n",
      "Eval Loss:  0.21809838712215424\n",
      "Eval Loss:  0.2090311199426651\n",
      "Eval Loss:  0.17557339370250702\n",
      "Eval Loss:  0.26700887084007263\n",
      "Eval Loss:  0.2602114975452423\n",
      "Eval Loss:  0.291672945022583\n",
      "Eval Loss:  0.3571931719779968\n",
      "Eval Loss:  0.1944354623556137\n",
      "Eval Loss:  0.2415824681520462\n",
      "Eval Loss:  0.28215324878692627\n",
      "Eval Loss:  0.2692578434944153\n",
      "Eval Loss:  0.24874725937843323\n",
      "Eval Loss:  0.37983232736587524\n",
      "Eval Loss:  0.2748733162879944\n",
      "Eval Loss:  0.22805668413639069\n",
      "Eval Loss:  0.2561095952987671\n",
      "Eval Loss:  0.18880316615104675\n",
      "[[15260  1807]\n",
      " [ 1402 11204]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90     17067\n",
      "           1       0.86      0.89      0.87     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8918545479055033\n",
      "pre:  0.861117515948044\n",
      "rec:  0.8887831191496113\n",
      "ma F1:  0.8897954717021775\n",
      "mi F1:  0.8918545479055033\n",
      "we F1:  0.8920601509287645\n",
      "29673 464\n",
      "Loss:  0.07453315705060959\n",
      "Loss:  0.07343094050884247\n",
      "Loss:  0.06808685511350632\n",
      "51 **********\n",
      "Epoch:  2719.351007461548  fold:  5  kers:  32\n",
      "epoch:  52\n",
      "29673 464\n",
      "Loss:  0.04684346914291382\n",
      "Loss:  0.05378435179591179\n",
      "Loss:  0.05967141315340996\n",
      "52 **********\n",
      "Epoch:  2758.542218208313  fold:  5  kers:  32\n",
      "epoch:  53\n",
      "29673 464\n",
      "Loss:  0.04760602116584778\n",
      "Loss:  0.07799698412418365\n",
      "Loss:  0.04782671108841896\n",
      "53 **********\n",
      "Epoch:  2797.9558339118958  fold:  5  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.0679820328950882\n",
      "Eval Loss:  0.15669050812721252\n",
      "Eval Loss:  0.04732765629887581\n",
      "[[3023   74]\n",
      " [  31   90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3097\n",
      "           1       0.55      0.74      0.63       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.77      0.86      0.81      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9673710379117464\n",
      "pre:  0.5487804878048781\n",
      "rec:  0.743801652892562\n",
      "ma F1:  0.8072542761553534\n",
      "mi F1:  0.9673710379117464\n",
      "we F1:  0.9697184708321436\n",
      "Eval Loss:  0.2793619632720947\n",
      "Eval Loss:  0.2781546711921692\n",
      "Eval Loss:  0.2716844379901886\n",
      "Eval Loss:  0.2774985432624817\n",
      "Eval Loss:  0.1990233212709427\n",
      "Eval Loss:  0.34785720705986023\n",
      "Eval Loss:  0.22658368945121765\n",
      "Eval Loss:  0.23039627075195312\n",
      "Eval Loss:  0.22753623127937317\n",
      "Eval Loss:  0.2767897844314575\n",
      "Eval Loss:  0.23741504549980164\n",
      "Eval Loss:  0.21190579235553741\n",
      "Eval Loss:  0.20528391003608704\n",
      "Eval Loss:  0.19624942541122437\n",
      "Eval Loss:  0.189487025141716\n",
      "Eval Loss:  0.2901786267757416\n",
      "Eval Loss:  0.2519073188304901\n",
      "Eval Loss:  0.29273056983947754\n",
      "Eval Loss:  0.34855058789253235\n",
      "Eval Loss:  0.21634796261787415\n",
      "Eval Loss:  0.23496925830841064\n",
      "Eval Loss:  0.2773664891719818\n",
      "Eval Loss:  0.2563338577747345\n",
      "Eval Loss:  0.24538545310497284\n",
      "Eval Loss:  0.34121906757354736\n",
      "Eval Loss:  0.2527463138103485\n",
      "Eval Loss:  0.21841886639595032\n",
      "Eval Loss:  0.2347557097673416\n",
      "Eval Loss:  0.18179422616958618\n",
      "[[15239  1828]\n",
      " [ 1328 11278]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91     17067\n",
      "           1       0.86      0.89      0.88     12606\n",
      "\n",
      "    accuracy                           0.89     29673\n",
      "   macro avg       0.89      0.89      0.89     29673\n",
      "weighted avg       0.89      0.89      0.89     29673\n",
      "\n",
      "acc:  0.8936406834496007\n",
      "pre:  0.8605218983671601\n",
      "rec:  0.8946533396795177\n",
      "ma F1:  0.8917110676631446\n",
      "mi F1:  0.8936406834496007\n",
      "we F1:  0.8938842602971715\n",
      "29673 464\n",
      "Loss:  0.06585269421339035\n",
      "Loss:  0.03945504501461983\n",
      "Loss:  0.0467967614531517\n",
      "54 **********\n",
      "Epoch:  2875.6341381073  fold:  5  kers:  32\n",
      "epoch:  55\n",
      "29673 464\n",
      "Loss:  0.06831938028335571\n",
      "Loss:  0.08211349695920944\n",
      "Loss:  0.07295728474855423\n",
      "55 **********\n",
      "Epoch:  2914.9958930015564  fold:  5  kers:  32\n",
      "epoch:  56\n",
      "29673 464\n",
      "Loss:  0.03587571159005165\n",
      "Loss:  0.07368206232786179\n",
      "Loss:  0.0601244792342186\n",
      "56 **********\n",
      "Epoch:  2954.3017966747284  fold:  5  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.0683460459113121\n",
      "Eval Loss:  0.13212409615516663\n",
      "Eval Loss:  0.0439312607049942\n",
      "[[3042   55]\n",
      " [  36   85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.61      0.70      0.65       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.80      0.84      0.82      3218\n",
      "weighted avg       0.97      0.97      0.97      3218\n",
      "\n",
      "acc:  0.9717215661901802\n",
      "pre:  0.6071428571428571\n",
      "rec:  0.7024793388429752\n",
      "ma F1:  0.8183020770316596\n",
      "mi F1:  0.9717215661901802\n",
      "we F1:  0.9727073525594773\n",
      "Eval Loss:  0.25939592719078064\n",
      "Eval Loss:  0.2450171858072281\n",
      "Eval Loss:  0.2745365500450134\n",
      "Eval Loss:  0.26880666613578796\n",
      "Eval Loss:  0.20650355517864227\n",
      "Eval Loss:  0.34059426188468933\n",
      "Eval Loss:  0.2445012331008911\n",
      "Eval Loss:  0.23139019310474396\n",
      "Eval Loss:  0.2236538529396057\n",
      "Eval Loss:  0.27206575870513916\n",
      "Eval Loss:  0.22999535501003265\n",
      "Eval Loss:  0.20572559535503387\n",
      "Eval Loss:  0.19197151064872742\n",
      "Eval Loss:  0.2027042806148529\n",
      "Eval Loss:  0.17820674180984497\n",
      "Eval Loss:  0.2580246925354004\n",
      "Eval Loss:  0.23821981251239777\n",
      "Eval Loss:  0.2792118489742279\n",
      "Eval Loss:  0.33015477657318115\n",
      "Eval Loss:  0.19606901705265045\n",
      "Eval Loss:  0.22761595249176025\n",
      "Eval Loss:  0.28512221574783325\n",
      "Eval Loss:  0.25525709986686707\n",
      "Eval Loss:  0.21976140141487122\n",
      "Eval Loss:  0.34650719165802\n",
      "Eval Loss:  0.25944048166275024\n",
      "Eval Loss:  0.22790944576263428\n",
      "Eval Loss:  0.24244250357151031\n",
      "Eval Loss:  0.1818520724773407\n",
      "[[15518  1549]\n",
      " [ 1405 11201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91     17067\n",
      "           1       0.88      0.89      0.88     12606\n",
      "\n",
      "    accuracy                           0.90     29673\n",
      "   macro avg       0.90      0.90      0.90     29673\n",
      "weighted avg       0.90      0.90      0.90     29673\n",
      "\n",
      "acc:  0.9004482189195565\n",
      "pre:  0.8785098039215686\n",
      "rec:  0.8885451372362367\n",
      "ma F1:  0.898295530254646\n",
      "mi F1:  0.9004482189195565\n",
      "we F1:  0.9005200250737716\n",
      "29673 464\n",
      "Loss:  0.05981723219156265\n",
      "Loss:  0.05934412404894829\n",
      "Loss:  0.05776149779558182\n",
      "57 **********\n",
      "Epoch:  3032.065871477127  fold:  5  kers:  32\n",
      "epoch:  58\n",
      "29673 464\n",
      "Loss:  0.05923808738589287\n",
      "Loss:  0.08661827445030212\n",
      "Loss:  0.05057738348841667\n",
      "58 **********\n",
      "Epoch:  3071.363796710968  fold:  5  kers:  32\n",
      "epoch:  59\n",
      "29673 464\n",
      "Loss:  0.045690905302762985\n",
      "Loss:  0.08373023569583893\n",
      "Loss:  0.07122668623924255\n",
      "59 **********\n",
      "Epoch:  3110.7255516052246  fold:  5  kers:  32\n",
      "Eval Loss:  0.06657908856868744\n",
      "Eval Loss:  0.14772503077983856\n",
      "Eval Loss:  0.04251767322421074\n",
      "[[3040   57]\n",
      " [  26   95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3097\n",
      "           1       0.62      0.79      0.70       121\n",
      "\n",
      "    accuracy                           0.97      3218\n",
      "   macro avg       0.81      0.88      0.84      3218\n",
      "weighted avg       0.98      0.97      0.98      3218\n",
      "\n",
      "acc:  0.9742075823492853\n",
      "pre:  0.625\n",
      "rec:  0.7851239669421488\n",
      "ma F1:  0.8412516144140353\n",
      "mi F1:  0.9742075823492853\n",
      "we F1:  0.9756071188538668\n",
      "update!  Acc:  0.9742075823492853\n",
      "Epoch:  3114.4835035800934  fold:  5  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29479 3412\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29479 461\n",
      "Loss:  0.16938753426074982\n",
      "Loss:  0.16039413213729858\n",
      "Loss:  0.1584862768650055\n",
      "0 **********\n",
      "Epoch:  51.79052233695984  fold:  6  kers:  32\n",
      "epoch:  1\n",
      "29479 461\n",
      "Loss:  0.16137060523033142\n",
      "Loss:  0.14760559797286987\n",
      "Loss:  0.13826653361320496\n",
      "1 **********\n",
      "Epoch:  91.31683707237244  fold:  6  kers:  32\n",
      "epoch:  2\n",
      "29479 461\n",
      "Loss:  0.12835142016410828\n",
      "Loss:  0.13553188741207123\n",
      "Loss:  0.11470334976911545\n",
      "2 **********\n",
      "Epoch:  130.88603711128235  fold:  6  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.10033568739891052\n",
      "Eval Loss:  0.2693008780479431\n",
      "Eval Loss:  0.5427846312522888\n",
      "[[1780  452]\n",
      " [ 112 1068]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.86      2232\n",
      "           1       0.70      0.91      0.79      1180\n",
      "\n",
      "    accuracy                           0.83      3412\n",
      "   macro avg       0.82      0.85      0.83      3412\n",
      "weighted avg       0.86      0.83      0.84      3412\n",
      "\n",
      "acc:  0.8347010550996483\n",
      "pre:  0.7026315789473684\n",
      "rec:  0.9050847457627119\n",
      "ma F1:  0.8271753421704925\n",
      "mi F1:  0.8347010550996482\n",
      "we F1:  0.8382947944197507\n",
      "update!  Acc:  0.8347010550996483\n",
      "Eval Loss:  0.5469509363174438\n",
      "Eval Loss:  0.5315154194831848\n",
      "Eval Loss:  0.5323266386985779\n",
      "Eval Loss:  0.4905816316604614\n",
      "Eval Loss:  0.4920508861541748\n",
      "Eval Loss:  0.47580844163894653\n",
      "Eval Loss:  0.46756604313850403\n",
      "Eval Loss:  0.4896732568740845\n",
      "Eval Loss:  0.44580867886543274\n",
      "Eval Loss:  0.43116307258605957\n",
      "Eval Loss:  0.40068331360816956\n",
      "Eval Loss:  0.5413260459899902\n",
      "Eval Loss:  0.4630880653858185\n",
      "Eval Loss:  0.44475221633911133\n",
      "Eval Loss:  0.43080300092697144\n",
      "Eval Loss:  0.3993681073188782\n",
      "Eval Loss:  0.48252180218696594\n",
      "Eval Loss:  0.5124649405479431\n",
      "Eval Loss:  0.5193387866020203\n",
      "Eval Loss:  0.5135114192962646\n",
      "Eval Loss:  0.4163375496864319\n",
      "Eval Loss:  0.4003729522228241\n",
      "Eval Loss:  0.4866116940975189\n",
      "Eval Loss:  0.5738103985786438\n",
      "Eval Loss:  0.5075558423995972\n",
      "Eval Loss:  0.4834597706794739\n",
      "Eval Loss:  0.3943099081516266\n",
      "Eval Loss:  0.40493303537368774\n",
      "[[14960  2972]\n",
      " [ 3056  8491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83     17932\n",
      "           1       0.74      0.74      0.74     11547\n",
      "\n",
      "    accuracy                           0.80     29479\n",
      "   macro avg       0.79      0.78      0.79     29479\n",
      "weighted avg       0.80      0.80      0.80     29479\n",
      "\n",
      "acc:  0.7955154516774653\n",
      "pre:  0.7407310477187473\n",
      "rec:  0.7353425132068936\n",
      "ma F1:  0.7851701431499369\n",
      "mi F1:  0.7955154516774653\n",
      "we F1:  0.7953811177902629\n",
      "29479 461\n",
      "Loss:  0.1100630909204483\n",
      "Loss:  0.11072288453578949\n",
      "Loss:  0.11379289627075195\n",
      "3 **********\n",
      "Epoch:  209.23454928398132  fold:  6  kers:  32\n",
      "epoch:  4\n",
      "29479 461\n",
      "Loss:  0.11026567220687866\n",
      "Loss:  0.12659548223018646\n",
      "Loss:  0.11955264955759048\n",
      "4 **********\n",
      "Epoch:  248.64816522598267  fold:  6  kers:  32\n",
      "epoch:  5\n",
      "29479 461\n",
      "Loss:  0.07240431755781174\n",
      "Loss:  0.08521485328674316\n",
      "Loss:  0.12149055302143097\n",
      "5 **********\n",
      "Epoch:  287.98897552490234  fold:  6  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.07617902010679245\n",
      "Eval Loss:  0.1625358909368515\n",
      "Eval Loss:  0.4482268691062927\n",
      "[[1933  299]\n",
      " [ 138 1042]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      2232\n",
      "           1       0.78      0.88      0.83      1180\n",
      "\n",
      "    accuracy                           0.87      3412\n",
      "   macro avg       0.86      0.87      0.86      3412\n",
      "weighted avg       0.88      0.87      0.87      3412\n",
      "\n",
      "acc:  0.8719226260257913\n",
      "pre:  0.7770320656226697\n",
      "rec:  0.8830508474576271\n",
      "ma F1:  0.8625495178174725\n",
      "mi F1:  0.8719226260257913\n",
      "we F1:  0.873616307755914\n",
      "update!  Acc:  0.8719226260257913\n",
      "Eval Loss:  0.44006675481796265\n",
      "Eval Loss:  0.4711166024208069\n",
      "Eval Loss:  0.4695381820201874\n",
      "Eval Loss:  0.3791908025741577\n",
      "Eval Loss:  0.4830727279186249\n",
      "Eval Loss:  0.4595767557621002\n",
      "Eval Loss:  0.4913513660430908\n",
      "Eval Loss:  0.4163917899131775\n",
      "Eval Loss:  0.38483935594558716\n",
      "Eval Loss:  0.38329797983169556\n",
      "Eval Loss:  0.32259872555732727\n",
      "Eval Loss:  0.4616668224334717\n",
      "Eval Loss:  0.4035978317260742\n",
      "Eval Loss:  0.389959454536438\n",
      "Eval Loss:  0.36301711201667786\n",
      "Eval Loss:  0.37306544184684753\n",
      "Eval Loss:  0.44002658128738403\n",
      "Eval Loss:  0.5071707367897034\n",
      "Eval Loss:  0.47687286138534546\n",
      "Eval Loss:  0.4235897958278656\n",
      "Eval Loss:  0.3854982256889343\n",
      "Eval Loss:  0.37000954151153564\n",
      "Eval Loss:  0.45244520902633667\n",
      "Eval Loss:  0.5145519375801086\n",
      "Eval Loss:  0.5030357241630554\n",
      "Eval Loss:  0.45519399642944336\n",
      "Eval Loss:  0.3771289587020874\n",
      "Eval Loss:  0.337771475315094\n",
      "[[16294  1638]\n",
      " [ 3149  8398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87     17932\n",
      "           1       0.84      0.73      0.78     11547\n",
      "\n",
      "    accuracy                           0.84     29479\n",
      "   macro avg       0.84      0.82      0.83     29479\n",
      "weighted avg       0.84      0.84      0.84     29479\n",
      "\n",
      "acc:  0.8376132161877947\n",
      "pre:  0.8367875647668394\n",
      "rec:  0.7272884731965013\n",
      "ma F1:  0.8250624006228116\n",
      "mi F1:  0.8376132161877947\n",
      "we F1:  0.8352114580420641\n",
      "29479 461\n",
      "Loss:  0.10265551507472992\n",
      "Loss:  0.08721885830163956\n",
      "Loss:  0.11031439900398254\n",
      "6 **********\n",
      "Epoch:  365.50770711898804  fold:  6  kers:  32\n",
      "epoch:  7\n",
      "29479 461\n",
      "Loss:  0.11699375510215759\n",
      "Loss:  0.06845385581254959\n",
      "Loss:  0.10734115540981293\n",
      "7 **********\n",
      "Epoch:  404.6241171360016  fold:  6  kers:  32\n",
      "epoch:  8\n",
      "29479 461\n",
      "Loss:  0.1384054720401764\n",
      "Loss:  0.10950678586959839\n",
      "Loss:  0.09064994007349014\n",
      "8 **********\n",
      "Epoch:  443.68866658210754  fold:  6  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.06244843453168869\n",
      "Eval Loss:  0.14664848148822784\n",
      "Eval Loss:  0.41493454575538635\n",
      "[[1973  259]\n",
      " [ 143 1037]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91      2232\n",
      "           1       0.80      0.88      0.84      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.88      0.87      3412\n",
      "weighted avg       0.89      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8821805392731535\n",
      "pre:  0.8001543209876543\n",
      "rec:  0.8788135593220339\n",
      "ma F1:  0.8725925276397667\n",
      "mi F1:  0.8821805392731535\n",
      "we F1:  0.8833687971251545\n",
      "update!  Acc:  0.8821805392731535\n",
      "Eval Loss:  0.39377737045288086\n",
      "Eval Loss:  0.4005885422229767\n",
      "Eval Loss:  0.38113901019096375\n",
      "Eval Loss:  0.3249613344669342\n",
      "Eval Loss:  0.4514514207839966\n",
      "Eval Loss:  0.41298285126686096\n",
      "Eval Loss:  0.43721985816955566\n",
      "Eval Loss:  0.3879019618034363\n",
      "Eval Loss:  0.32360655069351196\n",
      "Eval Loss:  0.345922589302063\n",
      "Eval Loss:  0.30023080110549927\n",
      "Eval Loss:  0.4242902100086212\n",
      "Eval Loss:  0.3742509186267853\n",
      "Eval Loss:  0.3672873079776764\n",
      "Eval Loss:  0.3076762557029724\n",
      "Eval Loss:  0.33072659373283386\n",
      "Eval Loss:  0.36901339888572693\n",
      "Eval Loss:  0.4430552124977112\n",
      "Eval Loss:  0.43449312448501587\n",
      "Eval Loss:  0.3261141777038574\n",
      "Eval Loss:  0.3314801752567291\n",
      "Eval Loss:  0.3225008249282837\n",
      "Eval Loss:  0.4031091034412384\n",
      "Eval Loss:  0.4298458993434906\n",
      "Eval Loss:  0.4685027599334717\n",
      "Eval Loss:  0.40810298919677734\n",
      "Eval Loss:  0.346508651971817\n",
      "Eval Loss:  0.26985597610473633\n",
      "[[16773  1159]\n",
      " [ 3029  8518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     17932\n",
      "           1       0.88      0.74      0.80     11547\n",
      "\n",
      "    accuracy                           0.86     29479\n",
      "   macro avg       0.86      0.84      0.85     29479\n",
      "weighted avg       0.86      0.86      0.86     29479\n",
      "\n",
      "acc:  0.8579327656976152\n",
      "pre:  0.8802314766973236\n",
      "rec:  0.7376807828873301\n",
      "ma F1:  0.8458443886102474\n",
      "mi F1:  0.8579327656976152\n",
      "we F1:  0.855194393177521\n",
      "29479 461\n",
      "Loss:  0.05814924091100693\n",
      "Loss:  0.07654159516096115\n",
      "Loss:  0.08309329301118851\n",
      "9 **********\n",
      "Epoch:  521.4427676200867  fold:  6  kers:  32\n",
      "epoch:  10\n",
      "29479 461\n",
      "Loss:  0.09606354683637619\n",
      "Loss:  0.12425731122493744\n",
      "Loss:  0.09829860180616379\n",
      "10 **********\n",
      "Epoch:  560.5521991252899  fold:  6  kers:  32\n",
      "epoch:  11\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08834438025951385\n",
      "Loss:  0.08126291632652283\n",
      "Loss:  0.1520383656024933\n",
      "11 **********\n",
      "Epoch:  599.7643518447876  fold:  6  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.04517477750778198\n",
      "Eval Loss:  0.16450601816177368\n",
      "Eval Loss:  0.391172856092453\n",
      "[[2049  183]\n",
      " [ 177 1003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2232\n",
      "           1       0.85      0.85      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8944900351699883\n",
      "pre:  0.845699831365936\n",
      "rec:  0.85\n",
      "ma F1:  0.8835453810088866\n",
      "mi F1:  0.8944900351699883\n",
      "we F1:  0.8945528152129774\n",
      "update!  Acc:  0.8944900351699883\n",
      "Eval Loss:  0.42034709453582764\n",
      "Eval Loss:  0.39791128039360046\n",
      "Eval Loss:  0.3763459026813507\n",
      "Eval Loss:  0.34663546085357666\n",
      "Eval Loss:  0.4545668661594391\n",
      "Eval Loss:  0.39493274688720703\n",
      "Eval Loss:  0.4511752724647522\n",
      "Eval Loss:  0.4074319005012512\n",
      "Eval Loss:  0.30884888768196106\n",
      "Eval Loss:  0.3619021475315094\n",
      "Eval Loss:  0.346373975276947\n",
      "Eval Loss:  0.4391931891441345\n",
      "Eval Loss:  0.40120118856430054\n",
      "Eval Loss:  0.385319322347641\n",
      "Eval Loss:  0.34086018800735474\n",
      "Eval Loss:  0.3761279881000519\n",
      "Eval Loss:  0.3968254327774048\n",
      "Eval Loss:  0.4413308799266815\n",
      "Eval Loss:  0.4684547483921051\n",
      "Eval Loss:  0.34938323497772217\n",
      "Eval Loss:  0.3365260064601898\n",
      "Eval Loss:  0.33499017357826233\n",
      "Eval Loss:  0.4159005582332611\n",
      "Eval Loss:  0.4300304651260376\n",
      "Eval Loss:  0.4630010724067688\n",
      "Eval Loss:  0.42118966579437256\n",
      "Eval Loss:  0.35411709547042847\n",
      "Eval Loss:  0.2618359327316284\n",
      "[[17155   777]\n",
      " [ 3536  8011]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     17932\n",
      "           1       0.91      0.69      0.79     11547\n",
      "\n",
      "    accuracy                           0.85     29479\n",
      "   macro avg       0.87      0.83      0.84     29479\n",
      "weighted avg       0.86      0.85      0.85     29479\n",
      "\n",
      "acc:  0.8536924590386377\n",
      "pre:  0.9115839781520255\n",
      "rec:  0.6937732744435784\n",
      "ma F1:  0.838116709143288\n",
      "mi F1:  0.8536924590386377\n",
      "we F1:  0.8489928205914297\n",
      "29479 461\n",
      "Loss:  0.07514546811580658\n",
      "Loss:  0.11574782431125641\n",
      "Loss:  0.09881088137626648\n",
      "12 **********\n",
      "Epoch:  677.6072156429291  fold:  6  kers:  32\n",
      "epoch:  13\n",
      "29479 461\n",
      "Loss:  0.10020049661397934\n",
      "Loss:  0.11139506101608276\n",
      "Loss:  0.08867665380239487\n",
      "13 **********\n",
      "Epoch:  716.7824695110321  fold:  6  kers:  32\n",
      "epoch:  14\n",
      "29479 461\n",
      "Loss:  0.07101140916347504\n",
      "Loss:  0.05015358328819275\n",
      "Loss:  0.06521144509315491\n",
      "14 **********\n",
      "Epoch:  755.9936265945435  fold:  6  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.05505237355828285\n",
      "Eval Loss:  0.12001632153987885\n",
      "Eval Loss:  0.4083455204963684\n",
      "[[1948  284]\n",
      " [ 114 1066]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91      2232\n",
      "           1       0.79      0.90      0.84      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.89      0.88      3412\n",
      "weighted avg       0.89      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8833528722157092\n",
      "pre:  0.7896296296296297\n",
      "rec:  0.9033898305084745\n",
      "ma F1:  0.8750001380729799\n",
      "mi F1:  0.8833528722157091\n",
      "we F1:  0.8849628096355097\n",
      "Eval Loss:  0.37848153710365295\n",
      "Eval Loss:  0.3606996238231659\n",
      "Eval Loss:  0.306367963552475\n",
      "Eval Loss:  0.2944332957267761\n",
      "Eval Loss:  0.3924673795700073\n",
      "Eval Loss:  0.38067391514778137\n",
      "Eval Loss:  0.3761660158634186\n",
      "Eval Loss:  0.31840941309928894\n",
      "Eval Loss:  0.2635999917984009\n",
      "Eval Loss:  0.3047889471054077\n",
      "Eval Loss:  0.28804829716682434\n",
      "Eval Loss:  0.39177289605140686\n",
      "Eval Loss:  0.34722545742988586\n",
      "Eval Loss:  0.3523481488227844\n",
      "Eval Loss:  0.278579443693161\n",
      "Eval Loss:  0.2932111620903015\n",
      "Eval Loss:  0.3091147243976593\n",
      "Eval Loss:  0.39576947689056396\n",
      "Eval Loss:  0.41278618574142456\n",
      "Eval Loss:  0.2549261152744293\n",
      "Eval Loss:  0.2528696060180664\n",
      "Eval Loss:  0.2804567515850067\n",
      "Eval Loss:  0.35635465383529663\n",
      "Eval Loss:  0.32901936769485474\n",
      "Eval Loss:  0.41542112827301025\n",
      "Eval Loss:  0.33745962381362915\n",
      "Eval Loss:  0.2689063847064972\n",
      "Eval Loss:  0.19394542276859283\n",
      "[[16574  1358]\n",
      " [ 2318  9229]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     17932\n",
      "           1       0.87      0.80      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.87      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.87     29479\n",
      "\n",
      "acc:  0.8753010617727874\n",
      "pre:  0.871729479550392\n",
      "rec:  0.7992552178054906\n",
      "ma F1:  0.86704723236803\n",
      "mi F1:  0.8753010617727874\n",
      "we F1:  0.874222276717843\n",
      "29479 461\n",
      "Loss:  0.0837460309267044\n",
      "Loss:  0.06802553683519363\n",
      "Loss:  0.0878358706831932\n",
      "15 **********\n",
      "Epoch:  833.840479850769  fold:  6  kers:  32\n",
      "epoch:  16\n",
      "29479 461\n",
      "Loss:  0.07783129066228867\n",
      "Loss:  0.04991394653916359\n",
      "Loss:  0.060089677572250366\n",
      "16 **********\n",
      "Epoch:  873.1064903736115  fold:  6  kers:  32\n",
      "epoch:  17\n",
      "29479 461\n",
      "Loss:  0.10387466847896576\n",
      "Loss:  0.08412668853998184\n",
      "Loss:  0.09219281375408173\n",
      "17 **********\n",
      "Epoch:  912.2368636131287  fold:  6  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.04376177489757538\n",
      "Eval Loss:  0.13766798377037048\n",
      "Eval Loss:  0.35014528036117554\n",
      "[[2016  216]\n",
      " [ 137 1043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      2232\n",
      "           1       0.83      0.88      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.88      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8965416178194607\n",
      "pre:  0.8284352660841938\n",
      "rec:  0.8838983050847458\n",
      "ma F1:  0.8873834211546221\n",
      "mi F1:  0.8965416178194608\n",
      "we F1:  0.897285191854941\n",
      "update!  Acc:  0.8965416178194607\n",
      "Eval Loss:  0.37313979864120483\n",
      "Eval Loss:  0.35892102122306824\n",
      "Eval Loss:  0.3002249598503113\n",
      "Eval Loss:  0.29878470301628113\n",
      "Eval Loss:  0.38579005002975464\n",
      "Eval Loss:  0.3452463150024414\n",
      "Eval Loss:  0.37605252861976624\n",
      "Eval Loss:  0.3364406228065491\n",
      "Eval Loss:  0.25228554010391235\n",
      "Eval Loss:  0.3034480810165405\n",
      "Eval Loss:  0.3105470836162567\n",
      "Eval Loss:  0.3842344582080841\n",
      "Eval Loss:  0.3646949231624603\n",
      "Eval Loss:  0.34744691848754883\n",
      "Eval Loss:  0.2885333001613617\n",
      "Eval Loss:  0.3158005475997925\n",
      "Eval Loss:  0.3303179144859314\n",
      "Eval Loss:  0.39170217514038086\n",
      "Eval Loss:  0.4453323483467102\n",
      "Eval Loss:  0.27327463030815125\n",
      "Eval Loss:  0.27273744344711304\n",
      "Eval Loss:  0.2882862985134125\n",
      "Eval Loss:  0.3585044741630554\n",
      "Eval Loss:  0.344146728515625\n",
      "Eval Loss:  0.3996690809726715\n",
      "Eval Loss:  0.3365332782268524\n",
      "Eval Loss:  0.26650673151016235\n",
      "Eval Loss:  0.20117007195949554\n",
      "[[17000   932]\n",
      " [ 2781  8766]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     17932\n",
      "           1       0.90      0.76      0.83     11547\n",
      "\n",
      "    accuracy                           0.87     29479\n",
      "   macro avg       0.88      0.85      0.86     29479\n",
      "weighted avg       0.88      0.87      0.87     29479\n",
      "\n",
      "acc:  0.87404593100173\n",
      "pre:  0.9038977108682202\n",
      "rec:  0.7591582229150429\n",
      "ma F1:  0.8633876758953212\n",
      "mi F1:  0.87404593100173\n",
      "we F1:  0.8716525482361545\n",
      "29479 461\n",
      "Loss:  0.05905739590525627\n",
      "Loss:  0.09202437102794647\n",
      "Loss:  0.11123000830411911\n",
      "18 **********\n",
      "Epoch:  989.9111785888672  fold:  6  kers:  32\n",
      "epoch:  19\n",
      "29479 461\n",
      "Loss:  0.10593321174383163\n",
      "Loss:  0.08381997048854828\n",
      "Loss:  0.06160419434309006\n",
      "19 **********\n",
      "Epoch:  1029.0335731506348  fold:  6  kers:  32\n",
      "epoch:  20\n",
      "29479 461\n",
      "Loss:  0.07368811219930649\n",
      "Loss:  0.1062185987830162\n",
      "Loss:  0.07501865923404694\n",
      "20 **********\n",
      "Epoch:  1068.1639466285706  fold:  6  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.042729608714580536\n",
      "Eval Loss:  0.13131146132946014\n",
      "Eval Loss:  0.3877200186252594\n",
      "[[2014  218]\n",
      " [ 132 1048]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      2232\n",
      "           1       0.83      0.89      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.88      0.90      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8974208675263775\n",
      "pre:  0.8278041074249605\n",
      "rec:  0.888135593220339\n",
      "ma F1:  0.8884820295635615\n",
      "mi F1:  0.8974208675263775\n",
      "we F1:  0.8982166646949097\n",
      "update!  Acc:  0.8974208675263775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.34269800782203674\n",
      "Eval Loss:  0.3531549572944641\n",
      "Eval Loss:  0.279299795627594\n",
      "Eval Loss:  0.30300372838974\n",
      "Eval Loss:  0.37413179874420166\n",
      "Eval Loss:  0.3362451195716858\n",
      "Eval Loss:  0.3664323091506958\n",
      "Eval Loss:  0.30975157022476196\n",
      "Eval Loss:  0.23885171115398407\n",
      "Eval Loss:  0.27031874656677246\n",
      "Eval Loss:  0.31078043580055237\n",
      "Eval Loss:  0.36632537841796875\n",
      "Eval Loss:  0.354761004447937\n",
      "Eval Loss:  0.32684797048568726\n",
      "Eval Loss:  0.29760831594467163\n",
      "Eval Loss:  0.2969369888305664\n",
      "Eval Loss:  0.30762654542922974\n",
      "Eval Loss:  0.38151994347572327\n",
      "Eval Loss:  0.42134109139442444\n",
      "Eval Loss:  0.24955099821090698\n",
      "Eval Loss:  0.25390541553497314\n",
      "Eval Loss:  0.2789883613586426\n",
      "Eval Loss:  0.35663947463035583\n",
      "Eval Loss:  0.30412161350250244\n",
      "Eval Loss:  0.36315613985061646\n",
      "Eval Loss:  0.31745412945747375\n",
      "Eval Loss:  0.24578872323036194\n",
      "Eval Loss:  0.1806725114583969\n",
      "[[16955   977]\n",
      " [ 2544  9003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17932\n",
      "           1       0.90      0.78      0.84     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.89      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8805590420299196\n",
      "pre:  0.9021042084168337\n",
      "rec:  0.7796830345544298\n",
      "ma F1:  0.8711857730458291\n",
      "mi F1:  0.8805590420299196\n",
      "we F1:  0.8787119705387135\n",
      "29479 461\n",
      "Loss:  0.11178664863109589\n",
      "Loss:  0.06427258253097534\n",
      "Loss:  0.0915374681353569\n",
      "21 **********\n",
      "Epoch:  1146.1195087432861  fold:  6  kers:  32\n",
      "epoch:  22\n",
      "29479 461\n",
      "Loss:  0.06194490194320679\n",
      "Loss:  0.1022673100233078\n",
      "Loss:  0.09860941022634506\n",
      "22 **********\n",
      "Epoch:  1189.675050497055  fold:  6  kers:  32\n",
      "epoch:  23\n",
      "29479 461\n",
      "Loss:  0.0668710470199585\n",
      "Loss:  0.09617066383361816\n",
      "Loss:  0.09096364676952362\n",
      "23 **********\n",
      "Epoch:  1228.7705171108246  fold:  6  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.03627420961856842\n",
      "Eval Loss:  0.12395356595516205\n",
      "Eval Loss:  0.32821208238601685\n",
      "[[2025  207]\n",
      " [ 140 1040]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92      2232\n",
      "           1       0.83      0.88      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.88      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8983001172332943\n",
      "pre:  0.8340016038492382\n",
      "rec:  0.8813559322033898\n",
      "ma F1:  0.8890538450992778\n",
      "mi F1:  0.8983001172332943\n",
      "we F1:  0.8989290514799736\n",
      "update!  Acc:  0.8983001172332943\n",
      "Eval Loss:  0.36536577343940735\n",
      "Eval Loss:  0.34713923931121826\n",
      "Eval Loss:  0.27596592903137207\n",
      "Eval Loss:  0.31157878041267395\n",
      "Eval Loss:  0.3646067678928375\n",
      "Eval Loss:  0.3080446422100067\n",
      "Eval Loss:  0.3618420362472534\n",
      "Eval Loss:  0.3220488429069519\n",
      "Eval Loss:  0.23559240996837616\n",
      "Eval Loss:  0.28810736536979675\n",
      "Eval Loss:  0.29986709356307983\n",
      "Eval Loss:  0.35660672187805176\n",
      "Eval Loss:  0.38086041808128357\n",
      "Eval Loss:  0.29999271035194397\n",
      "Eval Loss:  0.28671786189079285\n",
      "Eval Loss:  0.2894890308380127\n",
      "Eval Loss:  0.3071011006832123\n",
      "Eval Loss:  0.3918481469154358\n",
      "Eval Loss:  0.4431251287460327\n",
      "Eval Loss:  0.2551390528678894\n",
      "Eval Loss:  0.277334064245224\n",
      "Eval Loss:  0.264574259519577\n",
      "Eval Loss:  0.3195820450782776\n",
      "Eval Loss:  0.3345104455947876\n",
      "Eval Loss:  0.3447037935256958\n",
      "Eval Loss:  0.32060056924819946\n",
      "Eval Loss:  0.2445993721485138\n",
      "Eval Loss:  0.17843638360500336\n",
      "[[17119   813]\n",
      " [ 2689  8858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91     17932\n",
      "           1       0.92      0.77      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.89      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8812035686420842\n",
      "pre:  0.9159342363767966\n",
      "rec:  0.7671256603446782\n",
      "ma F1:  0.8710793317589434\n",
      "mi F1:  0.8812035686420842\n",
      "we F1:  0.8789044440333476\n",
      "29479 461\n",
      "Loss:  0.08452509343624115\n",
      "Loss:  0.10343680530786514\n",
      "Loss:  0.053613923490047455\n",
      "24 **********\n",
      "Epoch:  1306.1835305690765  fold:  6  kers:  32\n",
      "epoch:  25\n",
      "29479 461\n",
      "Loss:  0.05988062545657158\n",
      "Loss:  0.06846461445093155\n",
      "Loss:  0.06531543284654617\n",
      "25 **********\n",
      "Epoch:  1345.329861164093  fold:  6  kers:  32\n",
      "epoch:  26\n",
      "29479 461\n",
      "Loss:  0.08612105250358582\n",
      "Loss:  0.05645478889346123\n",
      "Loss:  0.0978379100561142\n",
      "26 **********\n",
      "Epoch:  1384.362496137619  fold:  6  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.034377578645944595\n",
      "Eval Loss:  0.1541658341884613\n",
      "Eval Loss:  0.3383308947086334\n",
      "[[2077  155]\n",
      " [ 188  992]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      2232\n",
      "           1       0.86      0.84      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.89947245017585\n",
      "pre:  0.8648648648648649\n",
      "rec:  0.8406779661016949\n",
      "ma F1:  0.8881634215581242\n",
      "mi F1:  0.89947245017585\n",
      "we F1:  0.8991284889367854\n",
      "update!  Acc:  0.89947245017585\n",
      "Eval Loss:  0.3507481813430786\n",
      "Eval Loss:  0.37023141980171204\n",
      "Eval Loss:  0.2884465456008911\n",
      "Eval Loss:  0.3083166778087616\n",
      "Eval Loss:  0.363259494304657\n",
      "Eval Loss:  0.3140427768230438\n",
      "Eval Loss:  0.3626610338687897\n",
      "Eval Loss:  0.30590322613716125\n",
      "Eval Loss:  0.24114859104156494\n",
      "Eval Loss:  0.2777126431465149\n",
      "Eval Loss:  0.3151682913303375\n",
      "Eval Loss:  0.3836146891117096\n",
      "Eval Loss:  0.37534040212631226\n",
      "Eval Loss:  0.2853720784187317\n",
      "Eval Loss:  0.29119259119033813\n",
      "Eval Loss:  0.30642372369766235\n",
      "Eval Loss:  0.33217230439186096\n",
      "Eval Loss:  0.37981730699539185\n",
      "Eval Loss:  0.4542795717716217\n",
      "Eval Loss:  0.25618115067481995\n",
      "Eval Loss:  0.27839887142181396\n",
      "Eval Loss:  0.2852398157119751\n",
      "Eval Loss:  0.34107518196105957\n",
      "Eval Loss:  0.3420439660549164\n",
      "Eval Loss:  0.3350985050201416\n",
      "Eval Loss:  0.33029815554618835\n",
      "Eval Loss:  0.24474601447582245\n",
      "Eval Loss:  0.19339777529239655\n",
      "[[17238   694]\n",
      " [ 2855  8692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     17932\n",
      "           1       0.93      0.75      0.83     11547\n",
      "\n",
      "    accuracy                           0.88     29479\n",
      "   macro avg       0.89      0.86      0.87     29479\n",
      "weighted avg       0.88      0.88      0.88     29479\n",
      "\n",
      "acc:  0.8796092133383087\n",
      "pre:  0.9260600894949925\n",
      "rec:  0.7527496319390318\n",
      "ma F1:  0.8685628752050192\n",
      "mi F1:  0.8796092133383087\n",
      "we F1:  0.8768159607398954\n",
      "29479 461\n",
      "Loss:  0.07352714985609055\n",
      "Loss:  0.08263134211301804\n",
      "Loss:  0.07895530760288239\n",
      "27 **********\n",
      "Epoch:  1461.8024373054504  fold:  6  kers:  32\n",
      "epoch:  28\n",
      "29479 461\n",
      "Loss:  0.060222700238227844\n",
      "Loss:  0.07879555225372314\n",
      "Loss:  0.06320270150899887\n",
      "28 **********\n",
      "Epoch:  1500.8649916648865  fold:  6  kers:  32\n",
      "epoch:  29\n",
      "29479 461\n",
      "Loss:  0.06919156014919281\n",
      "Loss:  0.04315636679530144\n",
      "Loss:  0.09215303510427475\n",
      "29 **********\n",
      "Epoch:  1539.8716957569122  fold:  6  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.04591698199510574\n",
      "Eval Loss:  0.12876155972480774\n",
      "Eval Loss:  0.3276033401489258\n",
      "[[2036  196]\n",
      " [ 159 1021]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      2232\n",
      "           1       0.84      0.87      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.88      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8959554513481829\n",
      "pre:  0.8389482333607231\n",
      "rec:  0.8652542372881356\n",
      "ma F1:  0.8858542306714053\n",
      "mi F1:  0.8959554513481829\n",
      "we F1:  0.8963236731856615\n",
      "Eval Loss:  0.3403196334838867\n",
      "Eval Loss:  0.3614490330219269\n",
      "Eval Loss:  0.24344424903392792\n",
      "Eval Loss:  0.2990168035030365\n",
      "Eval Loss:  0.34467917680740356\n",
      "Eval Loss:  0.311822772026062\n",
      "Eval Loss:  0.3087663948535919\n",
      "Eval Loss:  0.26619186997413635\n",
      "Eval Loss:  0.21005398035049438\n",
      "Eval Loss:  0.24161893129348755\n",
      "Eval Loss:  0.270471453666687\n",
      "Eval Loss:  0.33559855818748474\n",
      "Eval Loss:  0.35170480608940125\n",
      "Eval Loss:  0.25042593479156494\n",
      "Eval Loss:  0.27768969535827637\n",
      "Eval Loss:  0.26951977610588074\n",
      "Eval Loss:  0.2870852053165436\n",
      "Eval Loss:  0.36689940094947815\n",
      "Eval Loss:  0.39619261026382446\n",
      "Eval Loss:  0.2222682535648346\n",
      "Eval Loss:  0.2525973916053772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.250433087348938\n",
      "Eval Loss:  0.2849022448062897\n",
      "Eval Loss:  0.30895769596099854\n",
      "Eval Loss:  0.3086431324481964\n",
      "Eval Loss:  0.3045467436313629\n",
      "Eval Loss:  0.21928611397743225\n",
      "Eval Loss:  0.15582901239395142\n",
      "[[16925  1007]\n",
      " [ 2211  9336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     17932\n",
      "           1       0.90      0.81      0.85     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.89      0.88      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8908375453712812\n",
      "pre:  0.902639466305714\n",
      "rec:  0.8085216939464797\n",
      "ma F1:  0.8830894049596009\n",
      "mi F1:  0.8908375453712811\n",
      "we F1:  0.8896082976369731\n",
      "29479 461\n",
      "Loss:  0.11089470237493515\n",
      "Loss:  0.1054868996143341\n",
      "Loss:  0.034939929842948914\n",
      "30 **********\n",
      "Epoch:  1617.2617704868317  fold:  6  kers:  32\n",
      "epoch:  31\n",
      "29479 461\n",
      "Loss:  0.07089527696371078\n",
      "Loss:  0.09636145085096359\n",
      "Loss:  0.07303735613822937\n",
      "31 **********\n",
      "Epoch:  1656.2794451713562  fold:  6  kers:  32\n",
      "epoch:  32\n",
      "29479 461\n",
      "Loss:  0.06887830793857574\n",
      "Loss:  0.07068675756454468\n",
      "Loss:  0.06357438862323761\n",
      "32 **********\n",
      "Epoch:  1695.2991144657135  fold:  6  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.03858483210206032\n",
      "Eval Loss:  0.12619520723819733\n",
      "Eval Loss:  0.32429876923561096\n",
      "[[2051  181]\n",
      " [ 166 1014]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      2232\n",
      "           1       0.85      0.86      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.8983001172332943\n",
      "pre:  0.8485355648535565\n",
      "rec:  0.8593220338983051\n",
      "ma F1:  0.8879498408867753\n",
      "mi F1:  0.8983001172332943\n",
      "we F1:  0.8984498319345458\n",
      "Eval Loss:  0.3599388599395752\n",
      "Eval Loss:  0.3567965626716614\n",
      "Eval Loss:  0.2612549662590027\n",
      "Eval Loss:  0.29790782928466797\n",
      "Eval Loss:  0.351413756608963\n",
      "Eval Loss:  0.2898262143135071\n",
      "Eval Loss:  0.3117905557155609\n",
      "Eval Loss:  0.2670263350009918\n",
      "Eval Loss:  0.22166317701339722\n",
      "Eval Loss:  0.26098695397377014\n",
      "Eval Loss:  0.27574917674064636\n",
      "Eval Loss:  0.34608179330825806\n",
      "Eval Loss:  0.36194291710853577\n",
      "Eval Loss:  0.26192447543144226\n",
      "Eval Loss:  0.275445818901062\n",
      "Eval Loss:  0.25802773237228394\n",
      "Eval Loss:  0.27965959906578064\n",
      "Eval Loss:  0.35197216272354126\n",
      "Eval Loss:  0.4115934371948242\n",
      "Eval Loss:  0.23567096889019012\n",
      "Eval Loss:  0.2588394582271576\n",
      "Eval Loss:  0.25720107555389404\n",
      "Eval Loss:  0.2860485315322876\n",
      "Eval Loss:  0.33891844749450684\n",
      "Eval Loss:  0.3093845546245575\n",
      "Eval Loss:  0.30156928300857544\n",
      "Eval Loss:  0.21559444069862366\n",
      "Eval Loss:  0.17068928480148315\n",
      "[[17153   779]\n",
      " [ 2458  9089]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17932\n",
      "           1       0.92      0.79      0.85     11547\n",
      "\n",
      "    accuracy                           0.89     29479\n",
      "   macro avg       0.90      0.87      0.88     29479\n",
      "weighted avg       0.89      0.89      0.89     29479\n",
      "\n",
      "acc:  0.8901930187591166\n",
      "pre:  0.921057965139846\n",
      "rec:  0.7871308564995236\n",
      "ma F1:  0.8813115674678559\n",
      "mi F1:  0.8901930187591166\n",
      "we F1:  0.8883438177772184\n",
      "29479 461\n",
      "Loss:  0.08099044859409332\n",
      "Loss:  0.06041935086250305\n",
      "Loss:  0.08538749068975449\n",
      "33 **********\n",
      "Epoch:  1772.7749600410461  fold:  6  kers:  32\n",
      "epoch:  34\n",
      "29479 461\n",
      "Loss:  0.05389274284243584\n",
      "Loss:  0.057216085493564606\n",
      "Loss:  0.09358873218297958\n",
      "34 **********\n",
      "Epoch:  1811.9532055854797  fold:  6  kers:  32\n",
      "epoch:  35\n",
      "29479 461\n",
      "Loss:  0.07480309158563614\n",
      "Loss:  0.08667106181383133\n",
      "Loss:  0.05646722763776779\n",
      "35 **********\n",
      "Epoch:  1851.2102398872375  fold:  6  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.05073456093668938\n",
      "Eval Loss:  0.08234228938817978\n",
      "Eval Loss:  0.3868311643600464\n",
      "[[1900  332]\n",
      " [  90 1090]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90      2232\n",
      "           1       0.77      0.92      0.84      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.86      0.89      0.87      3412\n",
      "weighted avg       0.89      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8763188745603752\n",
      "pre:  0.7665260196905767\n",
      "rec:  0.923728813559322\n",
      "ma F1:  0.8689322173556688\n",
      "mi F1:  0.876318874560375\n",
      "we F1:  0.8785257523919047\n",
      "Eval Loss:  0.3464490473270416\n",
      "Eval Loss:  0.35280582308769226\n",
      "Eval Loss:  0.24576538801193237\n",
      "Eval Loss:  0.2518031597137451\n",
      "Eval Loss:  0.3176197111606598\n",
      "Eval Loss:  0.34202679991722107\n",
      "Eval Loss:  0.2837344706058502\n",
      "Eval Loss:  0.23686188459396362\n",
      "Eval Loss:  0.21039965748786926\n",
      "Eval Loss:  0.22693820297718048\n",
      "Eval Loss:  0.23583130538463593\n",
      "Eval Loss:  0.3437579274177551\n",
      "Eval Loss:  0.31906557083129883\n",
      "Eval Loss:  0.23645208775997162\n",
      "Eval Loss:  0.24088671803474426\n",
      "Eval Loss:  0.23157228529453278\n",
      "Eval Loss:  0.24143871665000916\n",
      "Eval Loss:  0.34742552042007446\n",
      "Eval Loss:  0.36640870571136475\n",
      "Eval Loss:  0.19081449508666992\n",
      "Eval Loss:  0.2456384152173996\n",
      "Eval Loss:  0.24499647319316864\n",
      "Eval Loss:  0.23778048157691956\n",
      "Eval Loss:  0.314130961894989\n",
      "Eval Loss:  0.29783451557159424\n",
      "Eval Loss:  0.29055607318878174\n",
      "Eval Loss:  0.20617403090000153\n",
      "Eval Loss:  0.16061031818389893\n",
      "[[16380  1552]\n",
      " [ 1488 10059]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92     17932\n",
      "           1       0.87      0.87      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.89      0.89      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8968757420536653\n",
      "pre:  0.866333649125829\n",
      "rec:  0.871135359833723\n",
      "ma F1:  0.8919058341507284\n",
      "mi F1:  0.8968757420536653\n",
      "we F1:  0.8969260622729008\n",
      "29479 461\n",
      "Loss:  0.06199125573039055\n",
      "Loss:  0.06482023745775223\n",
      "Loss:  0.058658577501773834\n",
      "36 **********\n",
      "Epoch:  1928.4826290607452  fold:  6  kers:  32\n",
      "epoch:  37\n",
      "29479 461\n",
      "Loss:  0.09015130996704102\n",
      "Loss:  0.06716879457235336\n",
      "Loss:  0.04891730099916458\n",
      "37 **********\n",
      "Epoch:  1967.5362076759338  fold:  6  kers:  32\n",
      "epoch:  38\n",
      "29479 461\n",
      "Loss:  0.06308776885271072\n",
      "Loss:  0.047801703214645386\n",
      "Loss:  0.06150364130735397\n",
      "38 **********\n",
      "Epoch:  2006.5429120063782  fold:  6  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.04699638858437538\n",
      "Eval Loss:  0.07418593019247055\n",
      "Eval Loss:  0.3541572690010071\n",
      "[[1963  269]\n",
      " [ 103 1077]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      2232\n",
      "           1       0.80      0.91      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.90      0.88      3412\n",
      "weighted avg       0.90      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8909730363423212\n",
      "pre:  0.8001485884101041\n",
      "rec:  0.9127118644067796\n",
      "ma F1:  0.883089853425722\n",
      "mi F1:  0.8909730363423212\n",
      "we F1:  0.8924500209519775\n",
      "Eval Loss:  0.3504396378993988\n",
      "Eval Loss:  0.3357488811016083\n",
      "Eval Loss:  0.2405383586883545\n",
      "Eval Loss:  0.2833252549171448\n",
      "Eval Loss:  0.31549501419067383\n",
      "Eval Loss:  0.3192756772041321\n",
      "Eval Loss:  0.2866508960723877\n",
      "Eval Loss:  0.23857200145721436\n",
      "Eval Loss:  0.20716209709644318\n",
      "Eval Loss:  0.22499263286590576\n",
      "Eval Loss:  0.2340916395187378\n",
      "Eval Loss:  0.313879132270813\n",
      "Eval Loss:  0.33284834027290344\n",
      "Eval Loss:  0.22118328511714935\n",
      "Eval Loss:  0.23565733432769775\n",
      "Eval Loss:  0.21568898856639862\n",
      "Eval Loss:  0.2236832082271576\n",
      "Eval Loss:  0.3307091295719147\n",
      "Eval Loss:  0.3563571572303772\n",
      "Eval Loss:  0.1951211392879486\n",
      "Eval Loss:  0.2538866102695465\n",
      "Eval Loss:  0.2316211313009262\n",
      "Eval Loss:  0.21368545293807983\n",
      "Eval Loss:  0.30270132422447205\n",
      "Eval Loss:  0.2975543737411499\n",
      "Eval Loss:  0.2703995108604431\n",
      "Eval Loss:  0.20427730679512024\n",
      "Eval Loss:  0.16289696097373962\n",
      "[[16600  1332]\n",
      " [ 1669  9878]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     17932\n",
      "           1       0.88      0.86      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.89      0.89      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8981987177312664\n",
      "pre:  0.8811775200713649\n",
      "rec:  0.855460292716723\n",
      "ma F1:  0.8926151127294201\n",
      "mi F1:  0.8981987177312664\n",
      "we F1:  0.8979187898994272\n",
      "29479 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06649596989154816\n",
      "Loss:  0.08378790318965912\n",
      "Loss:  0.06343871355056763\n",
      "39 **********\n",
      "Epoch:  2084.1214826107025  fold:  6  kers:  32\n",
      "epoch:  40\n",
      "29479 461\n",
      "Loss:  0.059246961027383804\n",
      "Loss:  0.05068829655647278\n",
      "Loss:  0.058022528886795044\n",
      "40 **********\n",
      "Epoch:  2123.5141541957855  fold:  6  kers:  32\n",
      "epoch:  41\n",
      "29479 461\n",
      "Loss:  0.0672500729560852\n",
      "Loss:  0.07197123020887375\n",
      "Loss:  0.05179676041007042\n",
      "41 **********\n",
      "Epoch:  2162.7173330783844  fold:  6  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.03715667501091957\n",
      "Eval Loss:  0.11308419704437256\n",
      "Eval Loss:  0.36110812425613403\n",
      "[[2052  180]\n",
      " [ 157 1023]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      2232\n",
      "           1       0.85      0.87      0.86      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.89      0.89      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.9012309495896834\n",
      "pre:  0.8503740648379052\n",
      "rec:  0.8669491525423729\n",
      "ma F1:  0.8913489049271264\n",
      "mi F1:  0.9012309495896834\n",
      "we F1:  0.9014518310544445\n",
      "update!  Acc:  0.9012309495896834\n",
      "Eval Loss:  0.31243130564689636\n",
      "Eval Loss:  0.34045687317848206\n",
      "Eval Loss:  0.2302071452140808\n",
      "Eval Loss:  0.2809697389602661\n",
      "Eval Loss:  0.3234400153160095\n",
      "Eval Loss:  0.27789974212646484\n",
      "Eval Loss:  0.28443238139152527\n",
      "Eval Loss:  0.2358444482088089\n",
      "Eval Loss:  0.1934971958398819\n",
      "Eval Loss:  0.22103065252304077\n",
      "Eval Loss:  0.2589106857776642\n",
      "Eval Loss:  0.316129207611084\n",
      "Eval Loss:  0.3443123698234558\n",
      "Eval Loss:  0.2368323653936386\n",
      "Eval Loss:  0.2449934333562851\n",
      "Eval Loss:  0.23058953881263733\n",
      "Eval Loss:  0.22993330657482147\n",
      "Eval Loss:  0.32400766015052795\n",
      "Eval Loss:  0.3724323511123657\n",
      "Eval Loss:  0.20085348188877106\n",
      "Eval Loss:  0.24675719439983368\n",
      "Eval Loss:  0.22645384073257446\n",
      "Eval Loss:  0.2266889214515686\n",
      "Eval Loss:  0.2951774597167969\n",
      "Eval Loss:  0.29507020115852356\n",
      "Eval Loss:  0.25395819544792175\n",
      "Eval Loss:  0.19871892035007477\n",
      "Eval Loss:  0.15776179730892181\n",
      "[[17038   894]\n",
      " [ 2112  9435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     17932\n",
      "           1       0.91      0.82      0.86     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.88      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.8980291054649072\n",
      "pre:  0.9134475747894278\n",
      "rec:  0.8170953494414134\n",
      "ma F1:  0.8907627749895171\n",
      "mi F1:  0.8980291054649072\n",
      "we F1:  0.896865039896181\n",
      "29479 461\n",
      "Loss:  0.05213986709713936\n",
      "Loss:  0.0558733269572258\n",
      "Loss:  0.047552164644002914\n",
      "42 **********\n",
      "Epoch:  2240.385663986206  fold:  6  kers:  32\n",
      "epoch:  43\n",
      "29479 461\n",
      "Loss:  0.06562856584787369\n",
      "Loss:  0.0700112134218216\n",
      "Loss:  0.047206152230501175\n",
      "43 **********\n",
      "Epoch:  2279.535983800888  fold:  6  kers:  32\n",
      "epoch:  44\n",
      "29479 461\n",
      "Loss:  0.09262577444314957\n",
      "Loss:  0.05956138297915459\n",
      "Loss:  0.09307872503995895\n",
      "44 **********\n",
      "Epoch:  2318.7102398872375  fold:  6  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.038741741329431534\n",
      "Eval Loss:  0.08154142647981644\n",
      "Eval Loss:  0.3216160535812378\n",
      "[[1980  252]\n",
      " [ 123 1057]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      2232\n",
      "           1       0.81      0.90      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.87      0.89      0.88      3412\n",
      "weighted avg       0.90      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8900937866354045\n",
      "pre:  0.8074866310160428\n",
      "rec:  0.8957627118644068\n",
      "ma F1:  0.8814159464272557\n",
      "mi F1:  0.8900937866354045\n",
      "we F1:  0.8913066158735965\n",
      "Eval Loss:  0.31687161326408386\n",
      "Eval Loss:  0.3370685577392578\n",
      "Eval Loss:  0.24417981505393982\n",
      "Eval Loss:  0.2370300590991974\n",
      "Eval Loss:  0.29212966561317444\n",
      "Eval Loss:  0.30133968591690063\n",
      "Eval Loss:  0.26342472434043884\n",
      "Eval Loss:  0.22237378358840942\n",
      "Eval Loss:  0.2029927521944046\n",
      "Eval Loss:  0.20486420392990112\n",
      "Eval Loss:  0.23180460929870605\n",
      "Eval Loss:  0.3200633227825165\n",
      "Eval Loss:  0.31312164664268494\n",
      "Eval Loss:  0.22419710457324982\n",
      "Eval Loss:  0.22299188375473022\n",
      "Eval Loss:  0.21186615526676178\n",
      "Eval Loss:  0.21851862967014313\n",
      "Eval Loss:  0.31263551115989685\n",
      "Eval Loss:  0.35257622599601746\n",
      "Eval Loss:  0.18970753252506256\n",
      "Eval Loss:  0.2362404465675354\n",
      "Eval Loss:  0.21612662076950073\n",
      "Eval Loss:  0.21016350388526917\n",
      "Eval Loss:  0.2819547951221466\n",
      "Eval Loss:  0.26795804500579834\n",
      "Eval Loss:  0.2551495432853699\n",
      "Eval Loss:  0.18257910013198853\n",
      "Eval Loss:  0.15739993751049042\n",
      "[[16756  1176]\n",
      " [ 1652  9895]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     17932\n",
      "           1       0.89      0.86      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9040673021472913\n",
      "pre:  0.8937765332851594\n",
      "rec:  0.8569325365895903\n",
      "ma F1:  0.8985731285951308\n",
      "mi F1:  0.9040673021472913\n",
      "we F1:  0.9036861293429146\n",
      "29479 461\n",
      "Loss:  0.08598965406417847\n",
      "Loss:  0.04879358410835266\n",
      "Loss:  0.03896679729223251\n",
      "45 **********\n",
      "Epoch:  2396.4583582878113  fold:  6  kers:  32\n",
      "epoch:  46\n",
      "29479 461\n",
      "Loss:  0.042468976229429245\n",
      "Loss:  0.051700763404369354\n",
      "Loss:  0.08473237603902817\n",
      "46 **********\n",
      "Epoch:  2435.7722401618958  fold:  6  kers:  32\n",
      "epoch:  47\n",
      "29479 461\n",
      "Loss:  0.06084673851728439\n",
      "Loss:  0.0944214016199112\n",
      "Loss:  0.06788481026887894\n",
      "47 **********\n",
      "Epoch:  2475.013317346573  fold:  6  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.042116109281778336\n",
      "Eval Loss:  0.09639020264148712\n",
      "Eval Loss:  0.33769938349723816\n",
      "[[2028  204]\n",
      " [ 157 1023]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      2232\n",
      "           1       0.83      0.87      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.89      0.88      3412\n",
      "weighted avg       0.90      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8941969519343493\n",
      "pre:  0.8337408312958435\n",
      "rec:  0.8669491525423729\n",
      "ma F1:  0.884145545983674\n",
      "mi F1:  0.8941969519343493\n",
      "we F1:  0.8946670176852765\n",
      "Eval Loss:  0.30981484055519104\n",
      "Eval Loss:  0.35272955894470215\n",
      "Eval Loss:  0.2352353036403656\n",
      "Eval Loss:  0.25881484150886536\n",
      "Eval Loss:  0.3042047619819641\n",
      "Eval Loss:  0.2931121289730072\n",
      "Eval Loss:  0.26269659399986267\n",
      "Eval Loss:  0.2129800170660019\n",
      "Eval Loss:  0.19149652123451233\n",
      "Eval Loss:  0.21324363350868225\n",
      "Eval Loss:  0.24454279243946075\n",
      "Eval Loss:  0.3097468316555023\n",
      "Eval Loss:  0.31871747970581055\n",
      "Eval Loss:  0.21093891561031342\n",
      "Eval Loss:  0.22087226808071136\n",
      "Eval Loss:  0.21032853424549103\n",
      "Eval Loss:  0.23481085896492004\n",
      "Eval Loss:  0.3307134509086609\n",
      "Eval Loss:  0.351485937833786\n",
      "Eval Loss:  0.1860712468624115\n",
      "Eval Loss:  0.22220510244369507\n",
      "Eval Loss:  0.22253136336803436\n",
      "Eval Loss:  0.22839541733264923\n",
      "Eval Loss:  0.29485246539115906\n",
      "Eval Loss:  0.26733049750328064\n",
      "Eval Loss:  0.2553485333919525\n",
      "Eval Loss:  0.18848936259746552\n",
      "Eval Loss:  0.15896037220954895\n",
      "[[16893  1039]\n",
      " [ 1811  9736]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     17932\n",
      "           1       0.90      0.84      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.90      0.89      0.90     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.9033210081753112\n",
      "pre:  0.9035730858468678\n",
      "rec:  0.8431627262492423\n",
      "ma F1:  0.8972654665582651\n",
      "mi F1:  0.9033210081753111\n",
      "we F1:  0.9026678185527935\n",
      "29479 461\n",
      "Loss:  0.09171827137470245\n",
      "Loss:  0.05589484050869942\n",
      "Loss:  0.06805428862571716\n",
      "48 **********\n",
      "Epoch:  2552.7295196056366  fold:  6  kers:  32\n",
      "epoch:  49\n",
      "29479 461\n",
      "Loss:  0.08398783951997757\n",
      "Loss:  0.07648838311433792\n",
      "Loss:  0.07384835928678513\n",
      "49 **********\n",
      "Epoch:  2591.813018321991  fold:  6  kers:  32\n",
      "epoch:  50\n",
      "29479 461\n",
      "Loss:  0.056646157056093216\n",
      "Loss:  0.056914396584033966\n",
      "Loss:  0.0839216411113739\n",
      "50 **********\n",
      "Epoch:  2630.909482717514  fold:  6  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.035007454454898834\n",
      "Eval Loss:  0.0967545360326767\n",
      "Eval Loss:  0.3435041606426239\n",
      "[[2058  174]\n",
      " [ 193  987]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2232\n",
      "           1       0.85      0.84      0.84      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.88      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.8924384525205158\n",
      "pre:  0.8501291989664083\n",
      "rec:  0.8364406779661017\n",
      "ma F1:  0.8806822832432704\n",
      "mi F1:  0.8924384525205157\n",
      "we F1:  0.8922298930282024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3083733916282654\n",
      "Eval Loss:  0.3427794575691223\n",
      "Eval Loss:  0.239132359623909\n",
      "Eval Loss:  0.2741961181163788\n",
      "Eval Loss:  0.30208632349967957\n",
      "Eval Loss:  0.26416635513305664\n",
      "Eval Loss:  0.29034656286239624\n",
      "Eval Loss:  0.22132019698619843\n",
      "Eval Loss:  0.20689894258975983\n",
      "Eval Loss:  0.20997345447540283\n",
      "Eval Loss:  0.2550550103187561\n",
      "Eval Loss:  0.3304049074649811\n",
      "Eval Loss:  0.3408195376396179\n",
      "Eval Loss:  0.22280046343803406\n",
      "Eval Loss:  0.2170603722333908\n",
      "Eval Loss:  0.22552859783172607\n",
      "Eval Loss:  0.24732740223407745\n",
      "Eval Loss:  0.31488513946533203\n",
      "Eval Loss:  0.36199039220809937\n",
      "Eval Loss:  0.19805976748466492\n",
      "Eval Loss:  0.22917325794696808\n",
      "Eval Loss:  0.21783462166786194\n",
      "Eval Loss:  0.23282545804977417\n",
      "Eval Loss:  0.3007097542285919\n",
      "Eval Loss:  0.27933213114738464\n",
      "Eval Loss:  0.2486022263765335\n",
      "Eval Loss:  0.19853748381137848\n",
      "Eval Loss:  0.16095221042633057\n",
      "[[17133   799]\n",
      " [ 2094  9453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     17932\n",
      "           1       0.92      0.82      0.87     11547\n",
      "\n",
      "    accuracy                           0.90     29479\n",
      "   macro avg       0.91      0.89      0.89     29479\n",
      "weighted avg       0.90      0.90      0.90     29479\n",
      "\n",
      "acc:  0.901862342684623\n",
      "pre:  0.9220639875146313\n",
      "rec:  0.8186541958950376\n",
      "ma F1:  0.8947164327655259\n",
      "mi F1:  0.901862342684623\n",
      "we F1:  0.9006574008427961\n",
      "29479 461\n",
      "Loss:  0.047903355211019516\n",
      "Loss:  0.061338700354099274\n",
      "Loss:  0.06836307793855667\n",
      "51 **********\n",
      "Epoch:  2708.5907785892487  fold:  6  kers:  32\n",
      "epoch:  52\n",
      "29479 461\n",
      "Loss:  0.07390306144952774\n",
      "Loss:  0.1051725521683693\n",
      "Loss:  0.06888233125209808\n",
      "52 **********\n",
      "Epoch:  2747.7869758605957  fold:  6  kers:  32\n",
      "epoch:  53\n",
      "29479 461\n",
      "Loss:  0.04055091738700867\n",
      "Loss:  0.040892910212278366\n",
      "Loss:  0.05546827241778374\n",
      "53 **********\n",
      "Epoch:  2787.1437437534332  fold:  6  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.04946492239832878\n",
      "Eval Loss:  0.08615484088659286\n",
      "Eval Loss:  0.3406635820865631\n",
      "[[2003  229]\n",
      " [ 141 1039]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92      2232\n",
      "           1       0.82      0.88      0.85      1180\n",
      "\n",
      "    accuracy                           0.89      3412\n",
      "   macro avg       0.88      0.89      0.88      3412\n",
      "weighted avg       0.89      0.89      0.89      3412\n",
      "\n",
      "acc:  0.891559202813599\n",
      "pre:  0.8194006309148265\n",
      "rec:  0.8805084745762712\n",
      "ma F1:  0.8821520533868636\n",
      "mi F1:  0.891559202813599\n",
      "we F1:  0.8924179467446705\n",
      "Eval Loss:  0.3109033405780792\n",
      "Eval Loss:  0.35469985008239746\n",
      "Eval Loss:  0.24348700046539307\n",
      "Eval Loss:  0.25160375237464905\n",
      "Eval Loss:  0.2846595048904419\n",
      "Eval Loss:  0.2838591933250427\n",
      "Eval Loss:  0.26141881942749023\n",
      "Eval Loss:  0.2061987966299057\n",
      "Eval Loss:  0.1934136301279068\n",
      "Eval Loss:  0.18855492770671844\n",
      "Eval Loss:  0.22482942044734955\n",
      "Eval Loss:  0.3030993640422821\n",
      "Eval Loss:  0.30488184094429016\n",
      "Eval Loss:  0.2116224467754364\n",
      "Eval Loss:  0.20141802728176117\n",
      "Eval Loss:  0.20106306672096252\n",
      "Eval Loss:  0.22392164170742035\n",
      "Eval Loss:  0.3117588758468628\n",
      "Eval Loss:  0.33760538697242737\n",
      "Eval Loss:  0.1726004183292389\n",
      "Eval Loss:  0.22363020479679108\n",
      "Eval Loss:  0.22538216412067413\n",
      "Eval Loss:  0.2133771926164627\n",
      "Eval Loss:  0.2783048450946808\n",
      "Eval Loss:  0.26046764850616455\n",
      "Eval Loss:  0.23379270732402802\n",
      "Eval Loss:  0.1831604242324829\n",
      "Eval Loss:  0.15988722443580627\n",
      "[[16776  1156]\n",
      " [ 1590  9957]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     17932\n",
      "           1       0.90      0.86      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.90      0.90      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9068489433155806\n",
      "pre:  0.8959776837937551\n",
      "rec:  0.8623018965965186\n",
      "ma F1:  0.9015828740780021\n",
      "mi F1:  0.9068489433155806\n",
      "we F1:  0.9065137806745616\n",
      "29479 461\n",
      "Loss:  0.05659585818648338\n",
      "Loss:  0.05427984893321991\n",
      "Loss:  0.07996676117181778\n",
      "54 **********\n",
      "Epoch:  2864.778165578842  fold:  6  kers:  32\n",
      "epoch:  55\n",
      "29479 461\n",
      "Loss:  0.07948582619428635\n",
      "Loss:  0.04658013582229614\n",
      "Loss:  0.05448592081665993\n",
      "55 **********\n",
      "Epoch:  2903.9474346637726  fold:  6  kers:  32\n",
      "epoch:  56\n",
      "29479 461\n",
      "Loss:  0.04553714767098427\n",
      "Loss:  0.05061823129653931\n",
      "Loss:  0.08273904025554657\n",
      "56 **********\n",
      "Epoch:  2943.04389834404  fold:  6  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.035038769245147705\n",
      "Eval Loss:  0.09267690032720566\n",
      "Eval Loss:  0.3576447367668152\n",
      "[[2018  214]\n",
      " [ 184  996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      2232\n",
      "           1       0.82      0.84      0.83      1180\n",
      "\n",
      "    accuracy                           0.88      3412\n",
      "   macro avg       0.87      0.87      0.87      3412\n",
      "weighted avg       0.88      0.88      0.88      3412\n",
      "\n",
      "acc:  0.8833528722157092\n",
      "pre:  0.8231404958677686\n",
      "rec:  0.8440677966101695\n",
      "ma F1:  0.8718559325712496\n",
      "mi F1:  0.8833528722157091\n",
      "we F1:  0.8836903557669165\n",
      "Eval Loss:  0.30394527316093445\n",
      "Eval Loss:  0.3377660810947418\n",
      "Eval Loss:  0.23525796830654144\n",
      "Eval Loss:  0.2475583702325821\n",
      "Eval Loss:  0.30238234996795654\n",
      "Eval Loss:  0.2722974121570587\n",
      "Eval Loss:  0.25975093245506287\n",
      "Eval Loss:  0.2110527902841568\n",
      "Eval Loss:  0.19576773047447205\n",
      "Eval Loss:  0.20897641777992249\n",
      "Eval Loss:  0.2449076771736145\n",
      "Eval Loss:  0.30778101086616516\n",
      "Eval Loss:  0.3072221279144287\n",
      "Eval Loss:  0.2183411717414856\n",
      "Eval Loss:  0.2212277501821518\n",
      "Eval Loss:  0.2092558741569519\n",
      "Eval Loss:  0.2269885241985321\n",
      "Eval Loss:  0.3132871687412262\n",
      "Eval Loss:  0.3715795874595642\n",
      "Eval Loss:  0.1927448809146881\n",
      "Eval Loss:  0.22025157511234283\n",
      "Eval Loss:  0.21217550337314606\n",
      "Eval Loss:  0.2075977325439453\n",
      "Eval Loss:  0.3093731701374054\n",
      "Eval Loss:  0.28647032380104065\n",
      "Eval Loss:  0.2468482106924057\n",
      "Eval Loss:  0.1882922351360321\n",
      "Eval Loss:  0.1542644202709198\n",
      "[[17006   926]\n",
      " [ 1842  9705]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     17932\n",
      "           1       0.91      0.84      0.88     11547\n",
      "\n",
      "    accuracy                           0.91     29479\n",
      "   macro avg       0.91      0.89      0.90     29479\n",
      "weighted avg       0.91      0.91      0.91     29479\n",
      "\n",
      "acc:  0.9061026493436005\n",
      "pre:  0.9128962468253222\n",
      "rec:  0.8404780462457782\n",
      "ma F1:  0.8999666693980402\n",
      "mi F1:  0.9061026493436005\n",
      "we F1:  0.9053328153989172\n",
      "29479 461\n",
      "Loss:  0.050160422921180725\n",
      "Loss:  0.05016552656888962\n",
      "Loss:  0.04910740628838539\n",
      "57 **********\n",
      "Epoch:  3020.798996925354  fold:  6  kers:  32\n",
      "epoch:  58\n",
      "29479 461\n",
      "Loss:  0.060200728476047516\n",
      "Loss:  0.10216842591762543\n",
      "Loss:  0.08247854560613632\n",
      "58 **********\n",
      "Epoch:  3060.0430665016174  fold:  6  kers:  32\n",
      "epoch:  59\n",
      "29479 461\n",
      "Loss:  0.07740621268749237\n",
      "Loss:  0.09092821925878525\n",
      "Loss:  0.054472416639328\n",
      "59 **********\n",
      "Epoch:  3099.238266468048  fold:  6  kers:  32\n",
      "Eval Loss:  0.03880072385072708\n",
      "Eval Loss:  0.09602353721857071\n",
      "Eval Loss:  0.3445919156074524\n",
      "[[2058  174]\n",
      " [ 182  998]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2232\n",
      "           1       0.85      0.85      0.85      1180\n",
      "\n",
      "    accuracy                           0.90      3412\n",
      "   macro avg       0.89      0.88      0.88      3412\n",
      "weighted avg       0.90      0.90      0.90      3412\n",
      "\n",
      "acc:  0.895662368112544\n",
      "pre:  0.8515358361774744\n",
      "rec:  0.8457627118644068\n",
      "ma F1:  0.8845165078553783\n",
      "mi F1:  0.895662368112544\n",
      "we F1:  0.8955782484124898\n",
      "update!  Acc:  0.9012309495896834\n",
      "Epoch:  3103.225605249405  fold:  6  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29460 3431\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29460 461\n",
      "Loss:  0.17007353901863098\n",
      "Loss:  0.1697433441877365\n",
      "Loss:  0.14681164920330048\n",
      "0 **********\n",
      "Epoch:  51.62895464897156  fold:  7  kers:  32\n",
      "epoch:  1\n",
      "29460 461\n",
      "Loss:  0.14224980771541595\n",
      "Loss:  0.13575758039951324\n",
      "Loss:  0.113980233669281\n",
      "1 **********\n",
      "Epoch:  90.82116270065308  fold:  7  kers:  32\n",
      "epoch:  2\n",
      "29460 461\n",
      "Loss:  0.10311746597290039\n",
      "Loss:  0.12177518755197525\n",
      "Loss:  0.10741668194532394\n",
      "2 **********\n",
      "Epoch:  129.97846388816833  fold:  7  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.7631404995918274\n",
      "Eval Loss:  0.17624880373477936\n",
      "Eval Loss:  1.7769185304641724\n",
      "[[1632  495]\n",
      " [ 637  667]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74      2127\n",
      "           1       0.57      0.51      0.54      1304\n",
      "\n",
      "    accuracy                           0.67      3431\n",
      "   macro avg       0.65      0.64      0.64      3431\n",
      "weighted avg       0.66      0.67      0.67      3431\n",
      "\n",
      "acc:  0.6700670358496065\n",
      "pre:  0.5740103270223752\n",
      "rec:  0.5115030674846626\n",
      "ma F1:  0.6417250955118824\n",
      "mi F1:  0.6700670358496065\n",
      "we F1:  0.6658965119864388\n",
      "update!  Acc:  0.6700670358496065\n",
      "Eval Loss:  0.4340154826641083\n",
      "Eval Loss:  0.37804198265075684\n",
      "Eval Loss:  0.4242347180843353\n",
      "Eval Loss:  0.45239007472991943\n",
      "Eval Loss:  0.3926181495189667\n",
      "Eval Loss:  0.41445600986480713\n",
      "Eval Loss:  0.3725132346153259\n",
      "Eval Loss:  0.3801428973674774\n",
      "Eval Loss:  0.417252779006958\n",
      "Eval Loss:  0.5102840065956116\n",
      "Eval Loss:  0.46669355034828186\n",
      "Eval Loss:  0.4711345434188843\n",
      "Eval Loss:  0.38875314593315125\n",
      "Eval Loss:  0.38757163286209106\n",
      "Eval Loss:  0.39871397614479065\n",
      "Eval Loss:  0.3865339457988739\n",
      "Eval Loss:  0.40455856919288635\n",
      "Eval Loss:  0.4999723732471466\n",
      "Eval Loss:  0.35098206996917725\n",
      "Eval Loss:  0.5214205384254456\n",
      "Eval Loss:  0.33192282915115356\n",
      "Eval Loss:  0.44576382637023926\n",
      "Eval Loss:  0.3662221431732178\n",
      "Eval Loss:  0.4387059807777405\n",
      "Eval Loss:  0.40090060234069824\n",
      "Eval Loss:  0.5069386959075928\n",
      "Eval Loss:  0.30706754326820374\n",
      "Eval Loss:  0.3865063786506653\n",
      "[[15039  2998]\n",
      " [ 2531  8892]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84     18037\n",
      "           1       0.75      0.78      0.76     11423\n",
      "\n",
      "    accuracy                           0.81     29460\n",
      "   macro avg       0.80      0.81      0.80     29460\n",
      "weighted avg       0.81      0.81      0.81     29460\n",
      "\n",
      "acc:  0.8123217922606925\n",
      "pre:  0.7478553406223717\n",
      "rec:  0.7784294843736321\n",
      "ma F1:  0.8037788646678976\n",
      "mi F1:  0.8123217922606925\n",
      "we F1:  0.8129708157169858\n",
      "29460 461\n",
      "Loss:  0.10158955305814743\n",
      "Loss:  0.097614586353302\n",
      "Loss:  0.10758107155561447\n",
      "3 **********\n",
      "Epoch:  207.94100785255432  fold:  7  kers:  32\n",
      "epoch:  4\n",
      "29460 461\n",
      "Loss:  0.0938071459531784\n",
      "Loss:  0.11112286895513535\n",
      "Loss:  0.08059915155172348\n",
      "4 **********\n",
      "Epoch:  247.33068799972534  fold:  7  kers:  32\n",
      "epoch:  5\n",
      "29460 461\n",
      "Loss:  0.10029411315917969\n",
      "Loss:  0.09033756703138351\n",
      "Loss:  0.09449983388185501\n",
      "5 **********\n",
      "Epoch:  286.58872056007385  fold:  7  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.7164241671562195\n",
      "Eval Loss:  0.1240684986114502\n",
      "Eval Loss:  1.7413113117218018\n",
      "[[1809  318]\n",
      " [ 667  637]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79      2127\n",
      "           1       0.67      0.49      0.56      1304\n",
      "\n",
      "    accuracy                           0.71      3431\n",
      "   macro avg       0.70      0.67      0.67      3431\n",
      "weighted avg       0.71      0.71      0.70      3431\n",
      "\n",
      "acc:  0.7129116875546488\n",
      "pre:  0.6670157068062827\n",
      "rec:  0.48849693251533743\n",
      "ma F1:  0.674987740639537\n",
      "mi F1:  0.7129116875546487\n",
      "we F1:  0.7016186351029645\n",
      "update!  Acc:  0.7129116875546488\n",
      "Eval Loss:  0.4405059218406677\n",
      "Eval Loss:  0.4244800806045532\n",
      "Eval Loss:  0.40118902921676636\n",
      "Eval Loss:  0.5124831199645996\n",
      "Eval Loss:  0.36840206384658813\n",
      "Eval Loss:  0.38305506110191345\n",
      "Eval Loss:  0.27430397272109985\n",
      "Eval Loss:  0.28957539796829224\n",
      "Eval Loss:  0.39249804615974426\n",
      "Eval Loss:  0.47743621468544006\n",
      "Eval Loss:  0.4644926190376282\n",
      "Eval Loss:  0.4066498279571533\n",
      "Eval Loss:  0.379030704498291\n",
      "Eval Loss:  0.2565717101097107\n",
      "Eval Loss:  0.3702394664287567\n",
      "Eval Loss:  0.3423088788986206\n",
      "Eval Loss:  0.3848177492618561\n",
      "Eval Loss:  0.4862369894981384\n",
      "Eval Loss:  0.26990506052970886\n",
      "Eval Loss:  0.4694029688835144\n",
      "Eval Loss:  0.2413012683391571\n",
      "Eval Loss:  0.40518033504486084\n",
      "Eval Loss:  0.27624544501304626\n",
      "Eval Loss:  0.38736414909362793\n",
      "Eval Loss:  0.277929425239563\n",
      "Eval Loss:  0.49577850103378296\n",
      "Eval Loss:  0.2823708653450012\n",
      "Eval Loss:  0.39090073108673096\n",
      "[[16550  1487]\n",
      " [ 3154  8269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88     18037\n",
      "           1       0.85      0.72      0.78     11423\n",
      "\n",
      "    accuracy                           0.84     29460\n",
      "   macro avg       0.84      0.82      0.83     29460\n",
      "weighted avg       0.84      0.84      0.84     29460\n",
      "\n",
      "acc:  0.8424643584521385\n",
      "pre:  0.8475809758097581\n",
      "rec:  0.7238903965683271\n",
      "ma F1:  0.8289490630758658\n",
      "mi F1:  0.8424643584521385\n",
      "we F1:  0.8397436728595474\n",
      "29460 461\n",
      "Loss:  0.10454098135232925\n",
      "Loss:  0.06829269230365753\n",
      "Loss:  0.11210472136735916\n",
      "6 **********\n",
      "Epoch:  364.41363191604614  fold:  7  kers:  32\n",
      "epoch:  7\n",
      "29460 461\n",
      "Loss:  0.0724504366517067\n",
      "Loss:  0.09653159976005554\n",
      "Loss:  0.05878210812807083\n",
      "7 **********\n",
      "Epoch:  403.6517174243927  fold:  7  kers:  32\n",
      "epoch:  8\n",
      "29460 461\n",
      "Loss:  0.09340915083885193\n",
      "Loss:  0.09217068552970886\n",
      "Loss:  0.06727185100317001\n",
      "8 **********\n",
      "Epoch:  442.740202665329  fold:  7  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.8484316468238831\n",
      "Eval Loss:  0.07668914645910263\n",
      "Eval Loss:  2.307729959487915\n",
      "[[2040   87]\n",
      " [ 856  448]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81      2127\n",
      "           1       0.84      0.34      0.49      1304\n",
      "\n",
      "    accuracy                           0.73      3431\n",
      "   macro avg       0.77      0.65      0.65      3431\n",
      "weighted avg       0.75      0.73      0.69      3431\n",
      "\n",
      "acc:  0.7251530166132323\n",
      "pre:  0.8373831775700935\n",
      "rec:  0.34355828220858897\n",
      "ma F1:  0.6497424517150416\n",
      "mi F1:  0.7251530166132323\n",
      "we F1:  0.6887266821869078\n",
      "update!  Acc:  0.7251530166132323\n",
      "Eval Loss:  0.44350558519363403\n",
      "Eval Loss:  0.4193437397480011\n",
      "Eval Loss:  0.36261144280433655\n",
      "Eval Loss:  0.5723307728767395\n",
      "Eval Loss:  0.37274882197380066\n",
      "Eval Loss:  0.35208019614219666\n",
      "Eval Loss:  0.2875113785266876\n",
      "Eval Loss:  0.27246367931365967\n",
      "Eval Loss:  0.39548781514167786\n",
      "Eval Loss:  0.4866238236427307\n",
      "Eval Loss:  0.4962932765483856\n",
      "Eval Loss:  0.43902695178985596\n",
      "Eval Loss:  0.37262409925460815\n",
      "Eval Loss:  0.2692677974700928\n",
      "Eval Loss:  0.3660210967063904\n",
      "Eval Loss:  0.33526474237442017\n",
      "Eval Loss:  0.3985097110271454\n",
      "Eval Loss:  0.5006183981895447\n",
      "Eval Loss:  0.2404291033744812\n",
      "Eval Loss:  0.46374693512916565\n",
      "Eval Loss:  0.24566662311553955\n",
      "Eval Loss:  0.38479456305503845\n",
      "Eval Loss:  0.29732266068458557\n",
      "Eval Loss:  0.37014472484588623\n",
      "Eval Loss:  0.2785699963569641\n",
      "Eval Loss:  0.5075133442878723\n",
      "Eval Loss:  0.31694164872169495\n",
      "Eval Loss:  0.4060699939727783\n",
      "[[17266   771]\n",
      " [ 3727  7696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88     18037\n",
      "           1       0.91      0.67      0.77     11423\n",
      "\n",
      "    accuracy                           0.85     29460\n",
      "   macro avg       0.87      0.82      0.83     29460\n",
      "weighted avg       0.86      0.85      0.84     29460\n",
      "\n",
      "acc:  0.8473183978275628\n",
      "pre:  0.9089405928900437\n",
      "rec:  0.6737284426157751\n",
      "ma F1:  0.8293057627867955\n",
      "mi F1:  0.8473183978275628\n",
      "we F1:  0.841754620483727\n",
      "29460 461\n",
      "Loss:  0.11199522018432617\n",
      "Loss:  0.08096063882112503\n",
      "Loss:  0.08408846706151962\n",
      "9 **********\n",
      "Epoch:  520.7276799678802  fold:  7  kers:  32\n",
      "epoch:  10\n",
      "29460 461\n",
      "Loss:  0.07530689984560013\n",
      "Loss:  0.10007651150226593\n",
      "Loss:  0.07963951677083969\n",
      "10 **********\n",
      "Epoch:  559.9597814083099  fold:  7  kers:  32\n",
      "epoch:  11\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.09594330191612244\n",
      "Loss:  0.10989762842655182\n",
      "Loss:  0.08922775089740753\n",
      "11 **********\n",
      "Epoch:  599.2626931667328  fold:  7  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.7963769435882568\n",
      "Eval Loss:  0.08603618294000626\n",
      "Eval Loss:  2.123976469039917\n",
      "[[2041   86]\n",
      " [ 812  492]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      2127\n",
      "           1       0.85      0.38      0.52      1304\n",
      "\n",
      "    accuracy                           0.74      3431\n",
      "   macro avg       0.78      0.67      0.67      3431\n",
      "weighted avg       0.77      0.74      0.71      3431\n",
      "\n",
      "acc:  0.7382687263188574\n",
      "pre:  0.8512110726643599\n",
      "rec:  0.3773006134969325\n",
      "ma F1:  0.6712633744329071\n",
      "mi F1:  0.7382687263188574\n",
      "we F1:  0.7068640229817368\n",
      "update!  Acc:  0.7382687263188574\n",
      "Eval Loss:  0.4232909083366394\n",
      "Eval Loss:  0.4127461910247803\n",
      "Eval Loss:  0.32940173149108887\n",
      "Eval Loss:  0.5560615658760071\n",
      "Eval Loss:  0.3406442701816559\n",
      "Eval Loss:  0.33709269762039185\n",
      "Eval Loss:  0.24394650757312775\n",
      "Eval Loss:  0.2527582347393036\n",
      "Eval Loss:  0.39196789264678955\n",
      "Eval Loss:  0.45810559391975403\n",
      "Eval Loss:  0.46702975034713745\n",
      "Eval Loss:  0.36912259459495544\n",
      "Eval Loss:  0.3506603240966797\n",
      "Eval Loss:  0.2235841155052185\n",
      "Eval Loss:  0.3305046260356903\n",
      "Eval Loss:  0.31530526280403137\n",
      "Eval Loss:  0.3565533757209778\n",
      "Eval Loss:  0.45575273036956787\n",
      "Eval Loss:  0.23371869325637817\n",
      "Eval Loss:  0.4186191260814667\n",
      "Eval Loss:  0.22414711117744446\n",
      "Eval Loss:  0.3511159420013428\n",
      "Eval Loss:  0.25630417466163635\n",
      "Eval Loss:  0.32551202178001404\n",
      "Eval Loss:  0.22421972453594208\n",
      "Eval Loss:  0.46858975291252136\n",
      "Eval Loss:  0.32093170285224915\n",
      "Eval Loss:  0.3737356662750244\n",
      "[[17262   775]\n",
      " [ 3385  8038]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89     18037\n",
      "           1       0.91      0.70      0.79     11423\n",
      "\n",
      "    accuracy                           0.86     29460\n",
      "   macro avg       0.87      0.83      0.84     29460\n",
      "weighted avg       0.87      0.86      0.85     29460\n",
      "\n",
      "acc:  0.8587915818058385\n",
      "pre:  0.9120617269942131\n",
      "rec:  0.7036680381686072\n",
      "ma F1:  0.8434438878191125\n",
      "mi F1:  0.8587915818058385\n",
      "we F1:  0.8544488366513118\n",
      "29460 461\n",
      "Loss:  0.07014483213424683\n",
      "Loss:  0.08711053431034088\n",
      "Loss:  0.07226908206939697\n",
      "12 **********\n",
      "Epoch:  677.1464478969574  fold:  7  kers:  32\n",
      "epoch:  13\n",
      "29460 461\n",
      "Loss:  0.0897284522652626\n",
      "Loss:  0.06095420569181442\n",
      "Loss:  0.09654155373573303\n",
      "13 **********\n",
      "Epoch:  716.201024055481  fold:  7  kers:  32\n",
      "epoch:  14\n",
      "29460 461\n",
      "Loss:  0.04457123950123787\n",
      "Loss:  0.07540155947208405\n",
      "Loss:  0.05922580510377884\n",
      "14 **********\n",
      "Epoch:  755.359322309494  fold:  7  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.6736917495727539\n",
      "Eval Loss:  0.093266062438488\n",
      "Eval Loss:  1.8793236017227173\n",
      "[[2029   98]\n",
      " [ 749  555]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.83      2127\n",
      "           1       0.85      0.43      0.57      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.79      0.69      0.70      3431\n",
      "weighted avg       0.78      0.75      0.73      3431\n",
      "\n",
      "acc:  0.753133197318566\n",
      "pre:  0.8499234303215927\n",
      "rec:  0.4256134969325153\n",
      "ma F1:  0.6972568739624663\n",
      "mi F1:  0.7531331973185661\n",
      "we F1:  0.7284551196355125\n",
      "update!  Acc:  0.753133197318566\n",
      "Eval Loss:  0.38553738594055176\n",
      "Eval Loss:  0.3779948949813843\n",
      "Eval Loss:  0.2975773215293884\n",
      "Eval Loss:  0.5037212371826172\n",
      "Eval Loss:  0.29687827825546265\n",
      "Eval Loss:  0.3042508661746979\n",
      "Eval Loss:  0.20878109335899353\n",
      "Eval Loss:  0.24144205451011658\n",
      "Eval Loss:  0.36721575260162354\n",
      "Eval Loss:  0.4407156705856323\n",
      "Eval Loss:  0.4347023069858551\n",
      "Eval Loss:  0.3478643000125885\n",
      "Eval Loss:  0.3085436224937439\n",
      "Eval Loss:  0.19651973247528076\n",
      "Eval Loss:  0.29194483160972595\n",
      "Eval Loss:  0.28125306963920593\n",
      "Eval Loss:  0.3417711853981018\n",
      "Eval Loss:  0.4115951359272003\n",
      "Eval Loss:  0.2159738540649414\n",
      "Eval Loss:  0.3904910981655121\n",
      "Eval Loss:  0.21361875534057617\n",
      "Eval Loss:  0.33039426803588867\n",
      "Eval Loss:  0.22704291343688965\n",
      "Eval Loss:  0.2860601544380188\n",
      "Eval Loss:  0.18917632102966309\n",
      "Eval Loss:  0.4141755700111389\n",
      "Eval Loss:  0.29278242588043213\n",
      "Eval Loss:  0.348268061876297\n",
      "[[17251   786]\n",
      " [ 3113  8310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     18037\n",
      "           1       0.91      0.73      0.81     11423\n",
      "\n",
      "    accuracy                           0.87     29460\n",
      "   macro avg       0.88      0.84      0.85     29460\n",
      "weighted avg       0.87      0.87      0.86     29460\n",
      "\n",
      "acc:  0.8676510522742702\n",
      "pre:  0.9135883905013192\n",
      "rec:  0.7274796463275847\n",
      "ma F1:  0.8542235895011014\n",
      "mi F1:  0.8676510522742702\n",
      "we F1:  0.8641563977755381\n",
      "29460 461\n",
      "Loss:  0.09906114637851715\n",
      "Loss:  0.07919386029243469\n",
      "Loss:  0.12491538375616074\n",
      "15 **********\n",
      "Epoch:  832.8630928993225  fold:  7  kers:  32\n",
      "epoch:  16\n",
      "29460 461\n",
      "Loss:  0.03741791844367981\n",
      "Loss:  0.07641437649726868\n",
      "Loss:  0.056781668215990067\n",
      "16 **********\n",
      "Epoch:  871.8837597370148  fold:  7  kers:  32\n",
      "epoch:  17\n",
      "29460 461\n",
      "Loss:  0.03616856038570404\n",
      "Loss:  0.0715533122420311\n",
      "Loss:  0.05128062143921852\n",
      "17 **********\n",
      "Epoch:  910.8246397972107  fold:  7  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.6506503224372864\n",
      "Eval Loss:  0.09389045089483261\n",
      "Eval Loss:  2.0284688472747803\n",
      "[[2029   98]\n",
      " [ 748  556]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.83      2127\n",
      "           1       0.85      0.43      0.57      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.79      0.69      0.70      3431\n",
      "weighted avg       0.78      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7534246575342466\n",
      "pre:  0.8501529051987767\n",
      "rec:  0.4263803680981595\n",
      "ma F1:  0.6977071103283138\n",
      "mi F1:  0.7534246575342466\n",
      "we F1:  0.7288378240760955\n",
      "update!  Acc:  0.7534246575342466\n",
      "Eval Loss:  0.3525390923023224\n",
      "Eval Loss:  0.34474384784698486\n",
      "Eval Loss:  0.2807474136352539\n",
      "Eval Loss:  0.445532888174057\n",
      "Eval Loss:  0.28163039684295654\n",
      "Eval Loss:  0.2809908092021942\n",
      "Eval Loss:  0.19250032305717468\n",
      "Eval Loss:  0.2377668023109436\n",
      "Eval Loss:  0.3382400870323181\n",
      "Eval Loss:  0.42733919620513916\n",
      "Eval Loss:  0.39262548089027405\n",
      "Eval Loss:  0.3355713188648224\n",
      "Eval Loss:  0.2875271141529083\n",
      "Eval Loss:  0.1934279501438141\n",
      "Eval Loss:  0.2647523581981659\n",
      "Eval Loss:  0.26220443844795227\n",
      "Eval Loss:  0.3141622543334961\n",
      "Eval Loss:  0.4035623371601105\n",
      "Eval Loss:  0.21845468878746033\n",
      "Eval Loss:  0.37765929102897644\n",
      "Eval Loss:  0.20321513712406158\n",
      "Eval Loss:  0.32027915120124817\n",
      "Eval Loss:  0.22236323356628418\n",
      "Eval Loss:  0.283713161945343\n",
      "Eval Loss:  0.17757995426654816\n",
      "Eval Loss:  0.37226736545562744\n",
      "Eval Loss:  0.27630388736724854\n",
      "Eval Loss:  0.3219553828239441\n",
      "[[17213   824]\n",
      " [ 2821  8602]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18037\n",
      "           1       0.91      0.75      0.83     11423\n",
      "\n",
      "    accuracy                           0.88     29460\n",
      "   macro avg       0.89      0.85      0.86     29460\n",
      "weighted avg       0.88      0.88      0.87     29460\n",
      "\n",
      "acc:  0.8762729124236253\n",
      "pre:  0.9125822193931679\n",
      "rec:  0.7530421080276635\n",
      "ma F1:  0.86471465255034\n",
      "mi F1:  0.8762729124236253\n",
      "we F1:  0.8735924055176967\n",
      "29460 461\n",
      "Loss:  0.07055003941059113\n",
      "Loss:  0.05799787491559982\n",
      "Loss:  0.08110075443983078\n",
      "18 **********\n",
      "Epoch:  988.4071998596191  fold:  7  kers:  32\n",
      "epoch:  19\n",
      "29460 461\n",
      "Loss:  0.07668331265449524\n",
      "Loss:  0.052949778735637665\n",
      "Loss:  0.0736924409866333\n",
      "19 **********\n",
      "Epoch:  1027.4647676944733  fold:  7  kers:  32\n",
      "epoch:  20\n",
      "29460 461\n",
      "Loss:  0.0718461275100708\n",
      "Loss:  0.08877597749233246\n",
      "Loss:  0.0720529779791832\n",
      "20 **********\n",
      "Epoch:  1066.5781865119934  fold:  7  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.579008162021637\n",
      "Eval Loss:  0.14772385358810425\n",
      "Eval Loss:  1.9697465896606445\n",
      "[[2008  119]\n",
      " [ 718  586]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83      2127\n",
      "           1       0.83      0.45      0.58      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.70      0.71      3431\n",
      "weighted avg       0.77      0.76      0.73      3431\n",
      "\n",
      "acc:  0.7560477994753716\n",
      "pre:  0.8312056737588652\n",
      "rec:  0.4493865030674847\n",
      "ma F1:  0.7054520883102076\n",
      "mi F1:  0.7560477994753715\n",
      "we F1:  0.7347349788087517\n",
      "update!  Acc:  0.7560477994753716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3049350082874298\n",
      "Eval Loss:  0.31790775060653687\n",
      "Eval Loss:  0.2798464000225067\n",
      "Eval Loss:  0.4025706350803375\n",
      "Eval Loss:  0.26806560158729553\n",
      "Eval Loss:  0.25774669647216797\n",
      "Eval Loss:  0.1841423660516739\n",
      "Eval Loss:  0.22579875588417053\n",
      "Eval Loss:  0.32403746247291565\n",
      "Eval Loss:  0.39953163266181946\n",
      "Eval Loss:  0.3787703812122345\n",
      "Eval Loss:  0.31644201278686523\n",
      "Eval Loss:  0.26122698187828064\n",
      "Eval Loss:  0.19345153868198395\n",
      "Eval Loss:  0.23137760162353516\n",
      "Eval Loss:  0.24509413540363312\n",
      "Eval Loss:  0.3025157153606415\n",
      "Eval Loss:  0.3717193603515625\n",
      "Eval Loss:  0.20785842835903168\n",
      "Eval Loss:  0.3442624807357788\n",
      "Eval Loss:  0.200882226228714\n",
      "Eval Loss:  0.3060224652290344\n",
      "Eval Loss:  0.22750324010849\n",
      "Eval Loss:  0.2748733162879944\n",
      "Eval Loss:  0.16971638798713684\n",
      "Eval Loss:  0.31488633155822754\n",
      "Eval Loss:  0.23515988886356354\n",
      "Eval Loss:  0.30360400676727295\n",
      "[[17057   980]\n",
      " [ 2405  9018]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18037\n",
      "           1       0.90      0.79      0.84     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.88     29460\n",
      "\n",
      "acc:  0.8850984385607603\n",
      "pre:  0.9019803960792159\n",
      "rec:  0.7894598616825702\n",
      "ma F1:  0.8758542124371219\n",
      "mi F1:  0.8850984385607604\n",
      "we F1:  0.8834597991496166\n",
      "29460 461\n",
      "Loss:  0.0787353664636612\n",
      "Loss:  0.09580769389867783\n",
      "Loss:  0.06520099937915802\n",
      "21 **********\n",
      "Epoch:  1144.3352799415588  fold:  7  kers:  32\n",
      "epoch:  22\n",
      "29460 461\n",
      "Loss:  0.0850219875574112\n",
      "Loss:  0.05401083827018738\n",
      "Loss:  0.07112859934568405\n",
      "22 **********\n",
      "Epoch:  1183.4197759628296  fold:  7  kers:  32\n",
      "epoch:  23\n",
      "29460 461\n",
      "Loss:  0.050030920654535294\n",
      "Loss:  0.06121271103620529\n",
      "Loss:  0.06927403807640076\n",
      "23 **********\n",
      "Epoch:  1222.5082612037659  fold:  7  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.5694499611854553\n",
      "Eval Loss:  0.11513851583003998\n",
      "Eval Loss:  1.7680310010910034\n",
      "[[1974  153]\n",
      " [ 654  650]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      2127\n",
      "           1       0.81      0.50      0.62      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.71      0.72      3431\n",
      "weighted avg       0.77      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7647916059457884\n",
      "pre:  0.8094645080946451\n",
      "rec:  0.49846625766871167\n",
      "ma F1:  0.7236374470557059\n",
      "mi F1:  0.7647916059457883\n",
      "we F1:  0.7492189219549036\n",
      "update!  Acc:  0.7647916059457884\n",
      "Eval Loss:  0.2920048236846924\n",
      "Eval Loss:  0.2857109010219574\n",
      "Eval Loss:  0.25038230419158936\n",
      "Eval Loss:  0.3832131624221802\n",
      "Eval Loss:  0.22502928972244263\n",
      "Eval Loss:  0.2488677054643631\n",
      "Eval Loss:  0.17101529240608215\n",
      "Eval Loss:  0.22051841020584106\n",
      "Eval Loss:  0.3160628378391266\n",
      "Eval Loss:  0.38471245765686035\n",
      "Eval Loss:  0.3608783483505249\n",
      "Eval Loss:  0.26747119426727295\n",
      "Eval Loss:  0.24607092142105103\n",
      "Eval Loss:  0.17402158677577972\n",
      "Eval Loss:  0.23768848180770874\n",
      "Eval Loss:  0.21773691475391388\n",
      "Eval Loss:  0.2773069739341736\n",
      "Eval Loss:  0.33469703793525696\n",
      "Eval Loss:  0.20847541093826294\n",
      "Eval Loss:  0.29572492837905884\n",
      "Eval Loss:  0.18740040063858032\n",
      "Eval Loss:  0.2850220501422882\n",
      "Eval Loss:  0.19259709119796753\n",
      "Eval Loss:  0.24563908576965332\n",
      "Eval Loss:  0.14865195751190186\n",
      "Eval Loss:  0.31452667713165283\n",
      "Eval Loss:  0.26730698347091675\n",
      "Eval Loss:  0.3050033748149872\n",
      "[[16957  1080]\n",
      " [ 2124  9299]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     18037\n",
      "           1       0.90      0.81      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.89      0.88      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8912423625254583\n",
      "pre:  0.8959437325368532\n",
      "rec:  0.8140593539350434\n",
      "ma F1:  0.8833608497076284\n",
      "mi F1:  0.8912423625254583\n",
      "we F1:  0.8901678914648922\n",
      "29460 461\n",
      "Loss:  0.07238079607486725\n",
      "Loss:  0.09196227043867111\n",
      "Loss:  0.09607856720685959\n",
      "24 **********\n",
      "Epoch:  1300.1237332820892  fold:  7  kers:  32\n",
      "epoch:  25\n",
      "29460 461\n",
      "Loss:  0.06365125626325607\n",
      "Loss:  0.07352079451084137\n",
      "Loss:  0.08773452788591385\n",
      "25 **********\n",
      "Epoch:  1339.174320936203  fold:  7  kers:  32\n",
      "epoch:  26\n",
      "29460 461\n",
      "Loss:  0.06356382369995117\n",
      "Loss:  0.08889918774366379\n",
      "Loss:  0.05584905669093132\n",
      "26 **********\n",
      "Epoch:  1378.2747731208801  fold:  7  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.518498420715332\n",
      "Eval Loss:  0.13784804940223694\n",
      "Eval Loss:  1.753411889076233\n",
      "[[1968  159]\n",
      " [ 664  640]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83      2127\n",
      "           1       0.80      0.49      0.61      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.71      0.72      3431\n",
      "weighted avg       0.77      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7601282424948994\n",
      "pre:  0.8010012515644556\n",
      "rec:  0.49079754601226994\n",
      "ma F1:  0.7178594063634167\n",
      "mi F1:  0.7601282424948994\n",
      "we F1:  0.7440546263455028\n",
      "Eval Loss:  0.261136919260025\n",
      "Eval Loss:  0.27587756514549255\n",
      "Eval Loss:  0.23927940428256989\n",
      "Eval Loss:  0.36380934715270996\n",
      "Eval Loss:  0.22522202134132385\n",
      "Eval Loss:  0.22600536048412323\n",
      "Eval Loss:  0.1598293036222458\n",
      "Eval Loss:  0.2091141939163208\n",
      "Eval Loss:  0.2977210283279419\n",
      "Eval Loss:  0.3878345489501953\n",
      "Eval Loss:  0.36830711364746094\n",
      "Eval Loss:  0.264468252658844\n",
      "Eval Loss:  0.22419603168964386\n",
      "Eval Loss:  0.16945840418338776\n",
      "Eval Loss:  0.2182101458311081\n",
      "Eval Loss:  0.213003009557724\n",
      "Eval Loss:  0.2730836868286133\n",
      "Eval Loss:  0.3184907138347626\n",
      "Eval Loss:  0.19799469411373138\n",
      "Eval Loss:  0.2866533100605011\n",
      "Eval Loss:  0.1897614747285843\n",
      "Eval Loss:  0.2774946391582489\n",
      "Eval Loss:  0.19941753149032593\n",
      "Eval Loss:  0.22490178048610687\n",
      "Eval Loss:  0.15630346536636353\n",
      "Eval Loss:  0.2965345084667206\n",
      "Eval Loss:  0.23876143991947174\n",
      "Eval Loss:  0.2844619154930115\n",
      "[[16991  1046]\n",
      " [ 2027  9396]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92     18037\n",
      "           1       0.90      0.82      0.86     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.88      0.89     29460\n",
      "weighted avg       0.90      0.90      0.89     29460\n",
      "\n",
      "acc:  0.8956890699253225\n",
      "pre:  0.8998276192300325\n",
      "rec:  0.8225509936093846\n",
      "ma F1:  0.8882624863140782\n",
      "mi F1:  0.8956890699253225\n",
      "we F1:  0.8947298232468983\n",
      "29460 461\n",
      "Loss:  0.06314317882061005\n",
      "Loss:  0.050445251166820526\n",
      "Loss:  0.09510640799999237\n",
      "27 **********\n",
      "Epoch:  1455.6827998161316  fold:  7  kers:  32\n",
      "epoch:  28\n",
      "29460 461\n",
      "Loss:  0.08435282856225967\n",
      "Loss:  0.07494513690471649\n",
      "Loss:  0.08977825939655304\n",
      "28 **********\n",
      "Epoch:  1494.7493438720703  fold:  7  kers:  32\n",
      "epoch:  29\n",
      "29460 461\n",
      "Loss:  0.09570853412151337\n",
      "Loss:  0.0452159158885479\n",
      "Loss:  0.07977108657360077\n",
      "29 **********\n",
      "Epoch:  1533.7361011505127  fold:  7  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.6204010844230652\n",
      "Eval Loss:  0.05535498633980751\n",
      "Eval Loss:  2.1764049530029297\n",
      "[[2013  114]\n",
      " [ 740  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82      2127\n",
      "           1       0.83      0.43      0.57      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.78      0.69      0.70      3431\n",
      "weighted avg       0.77      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7510929758088021\n",
      "pre:  0.831858407079646\n",
      "rec:  0.4325153374233129\n",
      "ma F1:  0.697061049445005\n",
      "mi F1:  0.751092975808802\n",
      "we F1:  0.7277499903679898\n",
      "Eval Loss:  0.2692773640155792\n",
      "Eval Loss:  0.28877949714660645\n",
      "Eval Loss:  0.2576413154602051\n",
      "Eval Loss:  0.4045824408531189\n",
      "Eval Loss:  0.21840792894363403\n",
      "Eval Loss:  0.21512386202812195\n",
      "Eval Loss:  0.16372649371623993\n",
      "Eval Loss:  0.20998811721801758\n",
      "Eval Loss:  0.28848889470100403\n",
      "Eval Loss:  0.3976537883281708\n",
      "Eval Loss:  0.39377766847610474\n",
      "Eval Loss:  0.2850120961666107\n",
      "Eval Loss:  0.22939135134220123\n",
      "Eval Loss:  0.1692931056022644\n",
      "Eval Loss:  0.23129583895206451\n",
      "Eval Loss:  0.22538472712039948\n",
      "Eval Loss:  0.2760489583015442\n",
      "Eval Loss:  0.37701815366744995\n",
      "Eval Loss:  0.2112232893705368\n",
      "Eval Loss:  0.306564599275589\n",
      "Eval Loss:  0.2090829759836197\n",
      "Eval Loss:  0.27527672052383423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.21522285044193268\n",
      "Eval Loss:  0.23074498772621155\n",
      "Eval Loss:  0.15673883259296417\n",
      "Eval Loss:  0.32402870059013367\n",
      "Eval Loss:  0.2766674757003784\n",
      "Eval Loss:  0.29806622862815857\n",
      "[[17289   748]\n",
      " [ 2428  8995]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18037\n",
      "           1       0.92      0.79      0.85     11423\n",
      "\n",
      "    accuracy                           0.89     29460\n",
      "   macro avg       0.90      0.87      0.88     29460\n",
      "weighted avg       0.89      0.89      0.89     29460\n",
      "\n",
      "acc:  0.8921928038017651\n",
      "pre:  0.92322693215642\n",
      "rec:  0.7874463801103038\n",
      "ma F1:  0.8829122466401513\n",
      "mi F1:  0.8921928038017651\n",
      "we F1:  0.8903129706655809\n",
      "29460 461\n",
      "Loss:  0.0765376016497612\n",
      "Loss:  0.07182435691356659\n",
      "Loss:  0.09559184312820435\n",
      "30 **********\n",
      "Epoch:  1611.8721809387207  fold:  7  kers:  32\n",
      "epoch:  31\n",
      "29460 461\n",
      "Loss:  0.04862122982740402\n",
      "Loss:  0.07644357532262802\n",
      "Loss:  0.08456353098154068\n",
      "31 **********\n",
      "Epoch:  1650.9127943515778  fold:  7  kers:  32\n",
      "epoch:  32\n",
      "29460 461\n",
      "Loss:  0.10146941244602203\n",
      "Loss:  0.034707531332969666\n",
      "Loss:  0.06912505626678467\n",
      "32 **********\n",
      "Epoch:  1689.884592294693  fold:  7  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.4940168559551239\n",
      "Eval Loss:  0.10101574659347534\n",
      "Eval Loss:  1.7107467651367188\n",
      "[[1953  174]\n",
      " [ 633  671]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83      2127\n",
      "           1       0.79      0.51      0.62      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.77      0.72      0.73      3431\n",
      "weighted avg       0.77      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7647916059457884\n",
      "pre:  0.7940828402366864\n",
      "rec:  0.5145705521472392\n",
      "ma F1:  0.7266239919148811\n",
      "mi F1:  0.7647916059457883\n",
      "we F1:  0.7511262901578114\n",
      "Eval Loss:  0.23247118294239044\n",
      "Eval Loss:  0.24972586333751678\n",
      "Eval Loss:  0.241155743598938\n",
      "Eval Loss:  0.33990076184272766\n",
      "Eval Loss:  0.20571820437908173\n",
      "Eval Loss:  0.19259729981422424\n",
      "Eval Loss:  0.14362330734729767\n",
      "Eval Loss:  0.2140870988368988\n",
      "Eval Loss:  0.27701014280319214\n",
      "Eval Loss:  0.3554796874523163\n",
      "Eval Loss:  0.3668363690376282\n",
      "Eval Loss:  0.24601127207279205\n",
      "Eval Loss:  0.21337196230888367\n",
      "Eval Loss:  0.15892831981182098\n",
      "Eval Loss:  0.20562858879566193\n",
      "Eval Loss:  0.2121821939945221\n",
      "Eval Loss:  0.25112417340278625\n",
      "Eval Loss:  0.29672953486442566\n",
      "Eval Loss:  0.20483677089214325\n",
      "Eval Loss:  0.27036088705062866\n",
      "Eval Loss:  0.18442639708518982\n",
      "Eval Loss:  0.2558031678199768\n",
      "Eval Loss:  0.19586195051670074\n",
      "Eval Loss:  0.19695238769054413\n",
      "Eval Loss:  0.1556648313999176\n",
      "Eval Loss:  0.26749664545059204\n",
      "Eval Loss:  0.21120157837867737\n",
      "Eval Loss:  0.27304813265800476\n",
      "[[16963  1074]\n",
      " [ 1825  9598]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18037\n",
      "           1       0.90      0.84      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.90     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9015953835709436\n",
      "pre:  0.8993628185907047\n",
      "rec:  0.8402346143745075\n",
      "ma F1:  0.8950350758090065\n",
      "mi F1:  0.9015953835709436\n",
      "we F1:  0.9009264370496654\n",
      "29460 461\n",
      "Loss:  0.04224267229437828\n",
      "Loss:  0.0725625604391098\n",
      "Loss:  0.05860716849565506\n",
      "33 **********\n",
      "Epoch:  1767.4212746620178  fold:  7  kers:  32\n",
      "epoch:  34\n",
      "29460 461\n",
      "Loss:  0.05575985834002495\n",
      "Loss:  0.057376112788915634\n",
      "Loss:  0.06980635970830917\n",
      "34 **********\n",
      "Epoch:  1806.4529120922089  fold:  7  kers:  32\n",
      "epoch:  35\n",
      "29460 461\n",
      "Loss:  0.06542520225048065\n",
      "Loss:  0.06286390125751495\n",
      "Loss:  0.06980579346418381\n",
      "35 **********\n",
      "Epoch:  1845.598245382309  fold:  7  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.6205224394798279\n",
      "Eval Loss:  0.06721866130828857\n",
      "Eval Loss:  1.9924122095108032\n",
      "[[1961  166]\n",
      " [ 647  657]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83      2127\n",
      "           1       0.80      0.50      0.62      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.71      0.72      3431\n",
      "weighted avg       0.77      0.76      0.75      3431\n",
      "\n",
      "acc:  0.763042844651705\n",
      "pre:  0.7982989064398542\n",
      "rec:  0.5038343558282209\n",
      "ma F1:  0.7230357017856105\n",
      "mi F1:  0.763042844651705\n",
      "we F1:  0.7482856086711901\n",
      "Eval Loss:  0.25096097588539124\n",
      "Eval Loss:  0.24695484340190887\n",
      "Eval Loss:  0.22911855578422546\n",
      "Eval Loss:  0.3622867465019226\n",
      "Eval Loss:  0.20362916588783264\n",
      "Eval Loss:  0.18631070852279663\n",
      "Eval Loss:  0.15561261773109436\n",
      "Eval Loss:  0.21633313596248627\n",
      "Eval Loss:  0.2747911810874939\n",
      "Eval Loss:  0.36788901686668396\n",
      "Eval Loss:  0.3675505816936493\n",
      "Eval Loss:  0.25475239753723145\n",
      "Eval Loss:  0.2069268524646759\n",
      "Eval Loss:  0.15806198120117188\n",
      "Eval Loss:  0.21432839334011078\n",
      "Eval Loss:  0.21018673479557037\n",
      "Eval Loss:  0.2598266005516052\n",
      "Eval Loss:  0.31692391633987427\n",
      "Eval Loss:  0.19639670848846436\n",
      "Eval Loss:  0.2764654755592346\n",
      "Eval Loss:  0.20047612488269806\n",
      "Eval Loss:  0.25687354803085327\n",
      "Eval Loss:  0.2035609483718872\n",
      "Eval Loss:  0.2063712328672409\n",
      "Eval Loss:  0.15813998878002167\n",
      "Eval Loss:  0.29611924290657043\n",
      "Eval Loss:  0.2236364781856537\n",
      "Eval Loss:  0.274177223443985\n",
      "[[17098   939]\n",
      " [ 1993  9430]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18037\n",
      "           1       0.91      0.83      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.90      0.89      0.89     29460\n",
      "weighted avg       0.90      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9004752206381534\n",
      "pre:  0.9094416047834892\n",
      "rec:  0.8255274446292568\n",
      "ma F1:  0.8932425816819441\n",
      "mi F1:  0.9004752206381534\n",
      "we F1:  0.8994810629099526\n",
      "29460 461\n",
      "Loss:  0.07782605290412903\n",
      "Loss:  0.07894932478666306\n",
      "Loss:  0.05753325670957565\n",
      "36 **********\n",
      "Epoch:  1927.9660103321075  fold:  7  kers:  32\n",
      "epoch:  37\n",
      "29460 461\n",
      "Loss:  0.08168802410364151\n",
      "Loss:  0.05153868719935417\n",
      "Loss:  0.07206401973962784\n",
      "37 **********\n",
      "Epoch:  1967.211077451706  fold:  7  kers:  32\n",
      "epoch:  38\n",
      "29460 461\n",
      "Loss:  0.050125572830438614\n",
      "Loss:  0.0408259853720665\n",
      "Loss:  0.040661510080099106\n",
      "38 **********\n",
      "Epoch:  2006.4032852649689  fold:  7  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.5207940936088562\n",
      "Eval Loss:  0.07468566298484802\n",
      "Eval Loss:  1.7267603874206543\n",
      "[[1883  244]\n",
      " [ 598  706]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82      2127\n",
      "           1       0.74      0.54      0.63      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.75      0.71      0.72      3431\n",
      "weighted avg       0.75      0.75      0.74      3431\n",
      "\n",
      "acc:  0.7545904983969688\n",
      "pre:  0.7431578947368421\n",
      "rec:  0.5414110429447853\n",
      "ma F1:  0.7218580933279108\n",
      "mi F1:  0.7545904983969688\n",
      "we F1:  0.7447457478494356\n",
      "Eval Loss:  0.23405778408050537\n",
      "Eval Loss:  0.24454344809055328\n",
      "Eval Loss:  0.22574245929718018\n",
      "Eval Loss:  0.3274730145931244\n",
      "Eval Loss:  0.2030574381351471\n",
      "Eval Loss:  0.194225013256073\n",
      "Eval Loss:  0.1474476158618927\n",
      "Eval Loss:  0.1970117837190628\n",
      "Eval Loss:  0.27875447273254395\n",
      "Eval Loss:  0.35695475339889526\n",
      "Eval Loss:  0.3698684275150299\n",
      "Eval Loss:  0.26496657729148865\n",
      "Eval Loss:  0.19955408573150635\n",
      "Eval Loss:  0.14775946736335754\n",
      "Eval Loss:  0.1974191516637802\n",
      "Eval Loss:  0.1939014494419098\n",
      "Eval Loss:  0.2395329475402832\n",
      "Eval Loss:  0.30963411927223206\n",
      "Eval Loss:  0.2087133228778839\n",
      "Eval Loss:  0.27061137557029724\n",
      "Eval Loss:  0.18377168476581573\n",
      "Eval Loss:  0.2511218786239624\n",
      "Eval Loss:  0.2087467759847641\n",
      "Eval Loss:  0.21042664349079132\n",
      "Eval Loss:  0.15187278389930725\n",
      "Eval Loss:  0.30125531554222107\n",
      "Eval Loss:  0.19747363030910492\n",
      "Eval Loss:  0.25494468212127686\n",
      "[[17056   981]\n",
      " [ 1820  9603]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18037\n",
      "           1       0.91      0.84      0.87     11423\n",
      "\n",
      "    accuracy                           0.90     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.90      0.90     29460\n",
      "\n",
      "acc:  0.9049219280380176\n",
      "pre:  0.907312925170068\n",
      "rec:  0.8406723277597828\n",
      "ma F1:  0.8984205948681192\n",
      "mi F1:  0.9049219280380176\n",
      "we F1:  0.9041900591892932\n",
      "29460 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0724390298128128\n",
      "Loss:  0.08726541697978973\n",
      "Loss:  0.05501728877425194\n",
      "39 **********\n",
      "Epoch:  2083.8432264328003  fold:  7  kers:  32\n",
      "epoch:  40\n",
      "29460 461\n",
      "Loss:  0.05228940024971962\n",
      "Loss:  0.07481817901134491\n",
      "Loss:  0.03500869870185852\n",
      "40 **********\n",
      "Epoch:  2122.8379621505737  fold:  7  kers:  32\n",
      "epoch:  41\n",
      "29460 461\n",
      "Loss:  0.06630709022283554\n",
      "Loss:  0.05012905225157738\n",
      "Loss:  0.05928464233875275\n",
      "41 **********\n",
      "Epoch:  2161.86261844635  fold:  7  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.4695458710193634\n",
      "Eval Loss:  0.13523989915847778\n",
      "Eval Loss:  1.5214369297027588\n",
      "[[1878  249]\n",
      " [ 572  732]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      2127\n",
      "           1       0.75      0.56      0.64      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.76      0.72      0.73      3431\n",
      "weighted avg       0.76      0.76      0.75      3431\n",
      "\n",
      "acc:  0.7607111629262606\n",
      "pre:  0.746177370030581\n",
      "rec:  0.5613496932515337\n",
      "ma F1:  0.730662541133027\n",
      "mi F1:  0.7607111629262606\n",
      "we F1:  0.7522419614958814\n",
      "Eval Loss:  0.22524987161159515\n",
      "Eval Loss:  0.22349584102630615\n",
      "Eval Loss:  0.241883784532547\n",
      "Eval Loss:  0.31583255529403687\n",
      "Eval Loss:  0.2152692824602127\n",
      "Eval Loss:  0.17986707389354706\n",
      "Eval Loss:  0.1413988322019577\n",
      "Eval Loss:  0.2289333939552307\n",
      "Eval Loss:  0.2838002145290375\n",
      "Eval Loss:  0.3350401222705841\n",
      "Eval Loss:  0.34595581889152527\n",
      "Eval Loss:  0.24343103170394897\n",
      "Eval Loss:  0.20319616794586182\n",
      "Eval Loss:  0.16616420447826385\n",
      "Eval Loss:  0.2037716805934906\n",
      "Eval Loss:  0.19798216223716736\n",
      "Eval Loss:  0.23588839173316956\n",
      "Eval Loss:  0.271629273891449\n",
      "Eval Loss:  0.1882699579000473\n",
      "Eval Loss:  0.2438216209411621\n",
      "Eval Loss:  0.19508717954158783\n",
      "Eval Loss:  0.23999786376953125\n",
      "Eval Loss:  0.20658326148986816\n",
      "Eval Loss:  0.2081947922706604\n",
      "Eval Loss:  0.17533063888549805\n",
      "Eval Loss:  0.27731069922447205\n",
      "Eval Loss:  0.17804133892059326\n",
      "Eval Loss:  0.2572467625141144\n",
      "[[16813  1224]\n",
      " [ 1535  9888]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     18037\n",
      "           1       0.89      0.87      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.90      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9063475899524779\n",
      "pre:  0.8898488120950324\n",
      "rec:  0.8656219907204762\n",
      "ma F1:  0.9008701380616945\n",
      "mi F1:  0.9063475899524779\n",
      "we F1:  0.9061015989722565\n",
      "29460 461\n",
      "Loss:  0.08349771797657013\n",
      "Loss:  0.07256132364273071\n",
      "Loss:  0.06465701758861542\n",
      "42 **********\n",
      "Epoch:  2239.3524267673492  fold:  7  kers:  32\n",
      "epoch:  43\n",
      "29460 461\n",
      "Loss:  0.09017157554626465\n",
      "Loss:  0.09412168711423874\n",
      "Loss:  0.06870382279157639\n",
      "43 **********\n",
      "Epoch:  2278.3561387062073  fold:  7  kers:  32\n",
      "epoch:  44\n",
      "29460 461\n",
      "Loss:  0.08251631259918213\n",
      "Loss:  0.07107855379581451\n",
      "Loss:  0.0658644437789917\n",
      "44 **********\n",
      "Epoch:  2317.4984798431396  fold:  7  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.556084394454956\n",
      "Eval Loss:  0.04963584989309311\n",
      "Eval Loss:  1.925325632095337\n",
      "[[1986  141]\n",
      " [ 681  623]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.83      2127\n",
      "           1       0.82      0.48      0.60      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.71      0.72      3431\n",
      "weighted avg       0.77      0.76      0.74      3431\n",
      "\n",
      "acc:  0.76041970271058\n",
      "pre:  0.8154450261780105\n",
      "rec:  0.47776073619631904\n",
      "ma F1:  0.7155250881784048\n",
      "mi F1:  0.76041970271058\n",
      "we F1:  0.7426331349575539\n",
      "Eval Loss:  0.22742004692554474\n",
      "Eval Loss:  0.21511900424957275\n",
      "Eval Loss:  0.24495208263397217\n",
      "Eval Loss:  0.3422979712486267\n",
      "Eval Loss:  0.20735707879066467\n",
      "Eval Loss:  0.1862393170595169\n",
      "Eval Loss:  0.16622436046600342\n",
      "Eval Loss:  0.2047298699617386\n",
      "Eval Loss:  0.27339819073677063\n",
      "Eval Loss:  0.346484899520874\n",
      "Eval Loss:  0.3807393014431\n",
      "Eval Loss:  0.26963359117507935\n",
      "Eval Loss:  0.21768008172512054\n",
      "Eval Loss:  0.16804125905036926\n",
      "Eval Loss:  0.19262701272964478\n",
      "Eval Loss:  0.21566452085971832\n",
      "Eval Loss:  0.25478407740592957\n",
      "Eval Loss:  0.28230127692222595\n",
      "Eval Loss:  0.1951172798871994\n",
      "Eval Loss:  0.2640215754508972\n",
      "Eval Loss:  0.2000114619731903\n",
      "Eval Loss:  0.25300121307373047\n",
      "Eval Loss:  0.2201259583234787\n",
      "Eval Loss:  0.22094501554965973\n",
      "Eval Loss:  0.1716817021369934\n",
      "Eval Loss:  0.30858173966407776\n",
      "Eval Loss:  0.17182864248752594\n",
      "Eval Loss:  0.2570403218269348\n",
      "[[17091   946]\n",
      " [ 1837  9586]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18037\n",
      "           1       0.91      0.84      0.87     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.90     29460\n",
      "\n",
      "acc:  0.9055329260013578\n",
      "pre:  0.9101785036080516\n",
      "rec:  0.8391841022498469\n",
      "ma F1:  0.898976642797296\n",
      "mi F1:  0.9055329260013578\n",
      "we F1:  0.9047545584684038\n",
      "29460 461\n",
      "Loss:  0.06845701485872269\n",
      "Loss:  0.06342369318008423\n",
      "Loss:  0.06575373560190201\n",
      "45 **********\n",
      "Epoch:  2394.939418554306  fold:  7  kers:  32\n",
      "epoch:  46\n",
      "29460 461\n",
      "Loss:  0.06443999707698822\n",
      "Loss:  0.07095127552747726\n",
      "Loss:  0.05964874476194382\n",
      "46 **********\n",
      "Epoch:  2433.9790346622467  fold:  7  kers:  32\n",
      "epoch:  47\n",
      "29460 461\n",
      "Loss:  0.07072331756353378\n",
      "Loss:  0.07827069610357285\n",
      "Loss:  0.06603214889764786\n",
      "47 **********\n",
      "Epoch:  2473.0226407051086  fold:  7  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.571516752243042\n",
      "Eval Loss:  0.048964500427246094\n",
      "Eval Loss:  1.9358619451522827\n",
      "[[2002  125]\n",
      " [ 695  609]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83      2127\n",
      "           1       0.83      0.47      0.60      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.79      0.70      0.71      3431\n",
      "weighted avg       0.78      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7610026231419411\n",
      "pre:  0.829700272479564\n",
      "rec:  0.46702453987730064\n",
      "ma F1:  0.7138306667512941\n",
      "mi F1:  0.7610026231419411\n",
      "we F1:  0.7417003868586182\n",
      "Eval Loss:  0.225955992937088\n",
      "Eval Loss:  0.22128330171108246\n",
      "Eval Loss:  0.22571834921836853\n",
      "Eval Loss:  0.3589736223220825\n",
      "Eval Loss:  0.19925886392593384\n",
      "Eval Loss:  0.18968017399311066\n",
      "Eval Loss:  0.15556010603904724\n",
      "Eval Loss:  0.21790747344493866\n",
      "Eval Loss:  0.2838381230831146\n",
      "Eval Loss:  0.3442985415458679\n",
      "Eval Loss:  0.3729490041732788\n",
      "Eval Loss:  0.2697427570819855\n",
      "Eval Loss:  0.20442934334278107\n",
      "Eval Loss:  0.16662566363811493\n",
      "Eval Loss:  0.2064846009016037\n",
      "Eval Loss:  0.2073826938867569\n",
      "Eval Loss:  0.24699115753173828\n",
      "Eval Loss:  0.2841619849205017\n",
      "Eval Loss:  0.20097139477729797\n",
      "Eval Loss:  0.26946306228637695\n",
      "Eval Loss:  0.19032341241836548\n",
      "Eval Loss:  0.24294567108154297\n",
      "Eval Loss:  0.20243364572525024\n",
      "Eval Loss:  0.2218456268310547\n",
      "Eval Loss:  0.17148874700069427\n",
      "Eval Loss:  0.32197073101997375\n",
      "Eval Loss:  0.17898626625537872\n",
      "Eval Loss:  0.24957063794136047\n",
      "[[17226   811]\n",
      " [ 1919  9504]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     18037\n",
      "           1       0.92      0.83      0.87     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9073319755600815\n",
      "pre:  0.9213766359670383\n",
      "rec:  0.8320056027313315\n",
      "ma F1:  0.9004954228250819\n",
      "mi F1:  0.9073319755600814\n",
      "we F1:  0.9063510249733968\n",
      "29460 461\n",
      "Loss:  0.07646085321903229\n",
      "Loss:  0.04320250079035759\n",
      "Loss:  0.05328693985939026\n",
      "48 **********\n",
      "Epoch:  2550.470559835434  fold:  7  kers:  32\n",
      "epoch:  49\n",
      "29460 461\n",
      "Loss:  0.052541352808475494\n",
      "Loss:  0.07064390182495117\n",
      "Loss:  0.0792652815580368\n",
      "49 **********\n",
      "Epoch:  2589.483247756958  fold:  7  kers:  32\n",
      "epoch:  50\n",
      "29460 461\n",
      "Loss:  0.05447345972061157\n",
      "Loss:  0.0872768983244896\n",
      "Loss:  0.08051592111587524\n",
      "50 **********\n",
      "Epoch:  2628.4809761047363  fold:  7  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.45568856596946716\n",
      "Eval Loss:  0.10449913144111633\n",
      "Eval Loss:  1.401442527770996\n",
      "[[1886  241]\n",
      " [ 526  778]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      2127\n",
      "           1       0.76      0.60      0.67      1304\n",
      "\n",
      "    accuracy                           0.78      3431\n",
      "   macro avg       0.77      0.74      0.75      3431\n",
      "weighted avg       0.77      0.78      0.77      3431\n",
      "\n",
      "acc:  0.7764500145730108\n",
      "pre:  0.7634936211972522\n",
      "rec:  0.5966257668711656\n",
      "ma F1:  0.7504217762791825\n",
      "mi F1:  0.7764500145730108\n",
      "we F1:  0.7697550254811867\n",
      "update!  Acc:  0.7764500145730108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.19625622034072876\n",
      "Eval Loss:  0.20587408542633057\n",
      "Eval Loss:  0.25047779083251953\n",
      "Eval Loss:  0.3131427466869354\n",
      "Eval Loss:  0.19847379624843597\n",
      "Eval Loss:  0.18030805885791779\n",
      "Eval Loss:  0.1486353576183319\n",
      "Eval Loss:  0.2249765247106552\n",
      "Eval Loss:  0.30854350328445435\n",
      "Eval Loss:  0.3381534218788147\n",
      "Eval Loss:  0.3645152747631073\n",
      "Eval Loss:  0.23886927962303162\n",
      "Eval Loss:  0.18160435557365417\n",
      "Eval Loss:  0.17152878642082214\n",
      "Eval Loss:  0.20221339166164398\n",
      "Eval Loss:  0.18847331404685974\n",
      "Eval Loss:  0.25712913274765015\n",
      "Eval Loss:  0.25923168659210205\n",
      "Eval Loss:  0.1898067146539688\n",
      "Eval Loss:  0.2541145086288452\n",
      "Eval Loss:  0.19785961508750916\n",
      "Eval Loss:  0.24798060953617096\n",
      "Eval Loss:  0.192745640873909\n",
      "Eval Loss:  0.2041907012462616\n",
      "Eval Loss:  0.17645958065986633\n",
      "Eval Loss:  0.28680726885795593\n",
      "Eval Loss:  0.14019978046417236\n",
      "Eval Loss:  0.2427998185157776\n",
      "[[16788  1249]\n",
      " [ 1427  9996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     18037\n",
      "           1       0.89      0.88      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9091649694501018\n",
      "pre:  0.8889284126278346\n",
      "rec:  0.8750765998424231\n",
      "ma F1:  0.9040657518422743\n",
      "mi F1:  0.9091649694501018\n",
      "we F1:  0.9090313327106742\n",
      "29460 461\n",
      "Loss:  0.046424321830272675\n",
      "Loss:  0.08926289528608322\n",
      "Loss:  0.08721235394477844\n",
      "51 **********\n",
      "Epoch:  2705.9807572364807  fold:  7  kers:  32\n",
      "epoch:  52\n",
      "29460 461\n",
      "Loss:  0.07724887877702713\n",
      "Loss:  0.04221871867775917\n",
      "Loss:  0.08591613918542862\n",
      "52 **********\n",
      "Epoch:  2745.0213708877563  fold:  7  kers:  32\n",
      "epoch:  53\n",
      "29460 461\n",
      "Loss:  0.06634650379419327\n",
      "Loss:  0.03354724124073982\n",
      "Loss:  0.03976758196949959\n",
      "53 **********\n",
      "Epoch:  2784.0899090766907  fold:  7  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.627651572227478\n",
      "Eval Loss:  0.05089776590466499\n",
      "Eval Loss:  2.1690783500671387\n",
      "[[1980  147]\n",
      " [ 704  600]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82      2127\n",
      "           1       0.80      0.46      0.59      1304\n",
      "\n",
      "    accuracy                           0.75      3431\n",
      "   macro avg       0.77      0.70      0.70      3431\n",
      "weighted avg       0.76      0.75      0.73      3431\n",
      "\n",
      "acc:  0.7519673564558438\n",
      "pre:  0.8032128514056225\n",
      "rec:  0.4601226993865031\n",
      "ma F1:  0.7040970731688038\n",
      "mi F1:  0.7519673564558438\n",
      "we F1:  0.73264580008564\n",
      "Eval Loss:  0.24167244136333466\n",
      "Eval Loss:  0.2157357633113861\n",
      "Eval Loss:  0.23172442615032196\n",
      "Eval Loss:  0.340069055557251\n",
      "Eval Loss:  0.19481706619262695\n",
      "Eval Loss:  0.186006098985672\n",
      "Eval Loss:  0.17536979913711548\n",
      "Eval Loss:  0.20394262671470642\n",
      "Eval Loss:  0.27216631174087524\n",
      "Eval Loss:  0.35141122341156006\n",
      "Eval Loss:  0.3678377866744995\n",
      "Eval Loss:  0.26247644424438477\n",
      "Eval Loss:  0.19797760248184204\n",
      "Eval Loss:  0.1603536158800125\n",
      "Eval Loss:  0.21476873755455017\n",
      "Eval Loss:  0.2118680775165558\n",
      "Eval Loss:  0.2508828043937683\n",
      "Eval Loss:  0.2850044071674347\n",
      "Eval Loss:  0.19934332370758057\n",
      "Eval Loss:  0.2698045074939728\n",
      "Eval Loss:  0.2114367038011551\n",
      "Eval Loss:  0.2616238594055176\n",
      "Eval Loss:  0.2192668914794922\n",
      "Eval Loss:  0.21069104969501495\n",
      "Eval Loss:  0.16130101680755615\n",
      "Eval Loss:  0.3387621343135834\n",
      "Eval Loss:  0.16766846179962158\n",
      "Eval Loss:  0.22466318309307098\n",
      "[[17332   705]\n",
      " [ 2044  9379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     18037\n",
      "           1       0.93      0.82      0.87     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.89      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9066870332654446\n",
      "pre:  0.9300872669575565\n",
      "rec:  0.8210627680994484\n",
      "ma F1:  0.8993520083532467\n",
      "mi F1:  0.9066870332654446\n",
      "we F1:  0.9054520781092228\n",
      "29460 461\n",
      "Loss:  0.09030500054359436\n",
      "Loss:  0.06663883477449417\n",
      "Loss:  0.03832383453845978\n",
      "54 **********\n",
      "Epoch:  2861.5996634960175  fold:  7  kers:  32\n",
      "epoch:  55\n",
      "29460 461\n",
      "Loss:  0.06611869484186172\n",
      "Loss:  0.08644494414329529\n",
      "Loss:  0.05896006152033806\n",
      "55 **********\n",
      "Epoch:  2900.6921384334564  fold:  7  kers:  32\n",
      "epoch:  56\n",
      "29460 461\n",
      "Loss:  0.05757072567939758\n",
      "Loss:  0.07267185300588608\n",
      "Loss:  0.03780631348490715\n",
      "56 **********\n",
      "Epoch:  2939.864399909973  fold:  7  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.5692474842071533\n",
      "Eval Loss:  0.056440871208906174\n",
      "Eval Loss:  2.221085786819458\n",
      "[[1984  143]\n",
      " [ 685  619]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.83      2127\n",
      "           1       0.81      0.47      0.60      1304\n",
      "\n",
      "    accuracy                           0.76      3431\n",
      "   macro avg       0.78      0.70      0.71      3431\n",
      "weighted avg       0.77      0.76      0.74      3431\n",
      "\n",
      "acc:  0.7586709414164966\n",
      "pre:  0.8123359580052494\n",
      "rec:  0.4746932515337423\n",
      "ma F1:  0.7132908433697975\n",
      "mi F1:  0.7586709414164966\n",
      "we F1:  0.740651884170115\n",
      "Eval Loss:  0.2352762222290039\n",
      "Eval Loss:  0.19781827926635742\n",
      "Eval Loss:  0.2240830957889557\n",
      "Eval Loss:  0.3467167913913727\n",
      "Eval Loss:  0.19305181503295898\n",
      "Eval Loss:  0.17359250783920288\n",
      "Eval Loss:  0.1593296080827713\n",
      "Eval Loss:  0.18944470584392548\n",
      "Eval Loss:  0.28350040316581726\n",
      "Eval Loss:  0.3591082692146301\n",
      "Eval Loss:  0.3633754253387451\n",
      "Eval Loss:  0.27423757314682007\n",
      "Eval Loss:  0.21082429587841034\n",
      "Eval Loss:  0.1603478491306305\n",
      "Eval Loss:  0.19578905403614044\n",
      "Eval Loss:  0.20523829758167267\n",
      "Eval Loss:  0.24910952150821686\n",
      "Eval Loss:  0.2730155289173126\n",
      "Eval Loss:  0.20916421711444855\n",
      "Eval Loss:  0.26080068945884705\n",
      "Eval Loss:  0.19390560686588287\n",
      "Eval Loss:  0.25009235739707947\n",
      "Eval Loss:  0.22600777447223663\n",
      "Eval Loss:  0.19684185087680817\n",
      "Eval Loss:  0.16631799936294556\n",
      "Eval Loss:  0.27675482630729675\n",
      "Eval Loss:  0.1590459793806076\n",
      "Eval Loss:  0.22834987938404083\n",
      "[[17199   838]\n",
      " [ 1838  9585]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     18037\n",
      "           1       0.92      0.84      0.88     11423\n",
      "\n",
      "    accuracy                           0.91     29460\n",
      "   macro avg       0.91      0.90      0.90     29460\n",
      "weighted avg       0.91      0.91      0.91     29460\n",
      "\n",
      "acc:  0.9091649694501018\n",
      "pre:  0.9196008826633407\n",
      "rec:  0.8390965595727917\n",
      "ma F1:  0.902663107612725\n",
      "mi F1:  0.9091649694501018\n",
      "we F1:  0.9083110343519436\n",
      "29460 461\n",
      "Loss:  0.05838705226778984\n",
      "Loss:  0.09481850266456604\n",
      "Loss:  0.06566080451011658\n",
      "57 **********\n",
      "Epoch:  3017.3222930431366  fold:  7  kers:  32\n",
      "epoch:  58\n",
      "29460 461\n",
      "Loss:  0.056310202926397324\n",
      "Loss:  0.043129682540893555\n",
      "Loss:  0.032808855175971985\n",
      "58 **********\n",
      "Epoch:  3056.4925606250763  fold:  7  kers:  32\n",
      "epoch:  59\n",
      "29460 461\n",
      "Loss:  0.07492230087518692\n",
      "Loss:  0.05156540498137474\n",
      "Loss:  0.061625245958566666\n",
      "59 **********\n",
      "Epoch:  3095.6638238430023  fold:  7  kers:  32\n",
      "Eval Loss:  0.47450169920921326\n",
      "Eval Loss:  0.08365190029144287\n",
      "Eval Loss:  1.6461892127990723\n",
      "[[1928  199]\n",
      " [ 598  706]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      2127\n",
      "           1       0.78      0.54      0.64      1304\n",
      "\n",
      "    accuracy                           0.77      3431\n",
      "   macro avg       0.77      0.72      0.73      3431\n",
      "weighted avg       0.77      0.77      0.76      3431\n",
      "\n",
      "acc:  0.767706208102594\n",
      "pre:  0.7801104972375691\n",
      "rec:  0.5414110429447853\n",
      "ma F1:  0.7339579589466416\n",
      "mi F1:  0.767706208102594\n",
      "we F1:  0.7566869352603477\n",
      "update!  Acc:  0.7764500145730108\n",
      "Epoch:  3099.68008518219  fold:  7  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29817 3074\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29817 466\n",
      "Loss:  0.17482487857341766\n",
      "Loss:  0.16597215831279755\n",
      "Loss:  0.15796232223510742\n",
      "0 **********\n",
      "Epoch:  52.01691746711731  fold:  8  kers:  32\n",
      "epoch:  1\n",
      "29817 466\n",
      "Loss:  0.13096779584884644\n",
      "Loss:  0.12152186036109924\n",
      "Loss:  0.10698296129703522\n",
      "1 **********\n",
      "Epoch:  91.83245849609375  fold:  8  kers:  32\n",
      "epoch:  2\n",
      "29817 466\n",
      "Loss:  0.12332809716463089\n",
      "Loss:  0.11350422352552414\n",
      "Loss:  0.0931958332657814\n",
      "2 **********\n",
      "Epoch:  131.66295981407166  fold:  8  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.2549038827419281\n",
      "Eval Loss:  0.8935518860816956\n",
      "Eval Loss:  0.22321952879428864\n",
      "[[1848  225]\n",
      " [ 436  565]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85      2073\n",
      "           1       0.72      0.56      0.63      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.76      0.73      0.74      3074\n",
      "weighted avg       0.78      0.78      0.78      3074\n",
      "\n",
      "acc:  0.7849707221860768\n",
      "pre:  0.7151898734177216\n",
      "rec:  0.5644355644355644\n",
      "ma F1:  0.7396112739250277\n",
      "mi F1:  0.7849707221860768\n",
      "we F1:  0.7775109843972371\n",
      "update!  Acc:  0.7849707221860768\n",
      "Eval Loss:  0.4928663671016693\n",
      "Eval Loss:  0.43803855776786804\n",
      "Eval Loss:  0.44447198510169983\n",
      "Eval Loss:  0.37969011068344116\n",
      "Eval Loss:  0.48115164041519165\n",
      "Eval Loss:  0.442008376121521\n",
      "Eval Loss:  0.40807804465293884\n",
      "Eval Loss:  0.4778802990913391\n",
      "Eval Loss:  0.4722934365272522\n",
      "Eval Loss:  0.4126405417919159\n",
      "Eval Loss:  0.4736173152923584\n",
      "Eval Loss:  0.5550870895385742\n",
      "Eval Loss:  0.4799627363681793\n",
      "Eval Loss:  0.43362295627593994\n",
      "Eval Loss:  0.4727238416671753\n",
      "Eval Loss:  0.5280339121818542\n",
      "Eval Loss:  0.40944239497184753\n",
      "Eval Loss:  0.417827844619751\n",
      "Eval Loss:  0.38220345973968506\n",
      "Eval Loss:  0.4931774139404297\n",
      "Eval Loss:  0.45524832606315613\n",
      "Eval Loss:  0.4864564836025238\n",
      "Eval Loss:  0.4903709888458252\n",
      "Eval Loss:  0.38223326206207275\n",
      "Eval Loss:  0.44822362065315247\n",
      "Eval Loss:  0.3758847117424011\n",
      "Eval Loss:  0.45625200867652893\n",
      "Eval Loss:  0.39617684483528137\n",
      "Eval Loss:  0.48579803109169006\n",
      "[[15584  2507]\n",
      " [ 3440  8286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84     18091\n",
      "           1       0.77      0.71      0.74     11726\n",
      "\n",
      "    accuracy                           0.80     29817\n",
      "   macro avg       0.79      0.78      0.79     29817\n",
      "weighted avg       0.80      0.80      0.80     29817\n",
      "\n",
      "acc:  0.8005500217996445\n",
      "pre:  0.7677198184008154\n",
      "rec:  0.7066348285860481\n",
      "ma F1:  0.7878400921874543\n",
      "mi F1:  0.8005500217996445\n",
      "we F1:  0.798925143157801\n",
      "29817 466\n",
      "Loss:  0.11377570778131485\n",
      "Loss:  0.11308252066373825\n",
      "Loss:  0.0932716652750969\n",
      "3 **********\n",
      "Epoch:  209.7481758594513  fold:  8  kers:  32\n",
      "epoch:  4\n",
      "29817 466\n",
      "Loss:  0.0820665955543518\n",
      "Loss:  0.09766694903373718\n",
      "Loss:  0.10639407485723495\n",
      "4 **********\n",
      "Epoch:  249.30441045761108  fold:  8  kers:  32\n",
      "epoch:  5\n",
      "29817 466\n",
      "Loss:  0.08876338601112366\n",
      "Loss:  0.09594976902008057\n",
      "Loss:  0.09933389723300934\n",
      "5 **********\n",
      "Epoch:  289.0212161540985  fold:  8  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.43460503220558167\n",
      "Eval Loss:  1.1278170347213745\n",
      "Eval Loss:  0.3209967613220215\n",
      "[[1682  391]\n",
      " [ 296  705]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      2073\n",
      "           1       0.64      0.70      0.67      1001\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.75      0.76      0.75      3074\n",
      "weighted avg       0.78      0.78      0.78      3074\n",
      "\n",
      "acc:  0.7765126870527\n",
      "pre:  0.6432481751824818\n",
      "rec:  0.7042957042957043\n",
      "ma F1:  0.7514006856075734\n",
      "mi F1:  0.7765126870527\n",
      "we F1:  0.778954488626177\n",
      "Eval Loss:  0.3951698839664459\n",
      "Eval Loss:  0.34152764081954956\n",
      "Eval Loss:  0.3247261643409729\n",
      "Eval Loss:  0.31185010075569153\n",
      "Eval Loss:  0.44015222787857056\n",
      "Eval Loss:  0.3271006643772125\n",
      "Eval Loss:  0.3012498617172241\n",
      "Eval Loss:  0.36513060331344604\n",
      "Eval Loss:  0.35960885882377625\n",
      "Eval Loss:  0.2614530324935913\n",
      "Eval Loss:  0.3514877259731293\n",
      "Eval Loss:  0.3745552897453308\n",
      "Eval Loss:  0.3691351115703583\n",
      "Eval Loss:  0.32629939913749695\n",
      "Eval Loss:  0.3244065046310425\n",
      "Eval Loss:  0.3106519281864166\n",
      "Eval Loss:  0.34868156909942627\n",
      "Eval Loss:  0.4262698292732239\n",
      "Eval Loss:  0.3572472929954529\n",
      "Eval Loss:  0.3796142041683197\n",
      "Eval Loss:  0.3282651901245117\n",
      "Eval Loss:  0.3601532578468323\n",
      "Eval Loss:  0.390817791223526\n",
      "Eval Loss:  0.22914239764213562\n",
      "Eval Loss:  0.3548946678638458\n",
      "Eval Loss:  0.30475398898124695\n",
      "Eval Loss:  0.3042703866958618\n",
      "Eval Loss:  0.3545365035533905\n",
      "Eval Loss:  0.36476248502731323\n",
      "[[15529  2562]\n",
      " [ 1899  9827]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87     18091\n",
      "           1       0.79      0.84      0.82     11726\n",
      "\n",
      "    accuracy                           0.85     29817\n",
      "   macro avg       0.84      0.85      0.84     29817\n",
      "weighted avg       0.85      0.85      0.85     29817\n",
      "\n",
      "acc:  0.850387362913774\n",
      "pre:  0.7932036483977722\n",
      "rec:  0.8380521917107283\n",
      "ma F1:  0.8447083257930708\n",
      "mi F1:  0.8503873629137739\n",
      "we F1:  0.8510476929051852\n",
      "29817 466\n",
      "Loss:  0.10123392939567566\n",
      "Loss:  0.11768614500761032\n",
      "Loss:  0.07522024214267731\n",
      "6 **********\n",
      "Epoch:  366.91993021965027  fold:  8  kers:  32\n",
      "epoch:  7\n",
      "29817 466\n",
      "Loss:  0.09440182894468307\n",
      "Loss:  0.06576477736234665\n",
      "Loss:  0.07638061791658401\n",
      "7 **********\n",
      "Epoch:  406.4322826862335  fold:  8  kers:  32\n",
      "epoch:  8\n",
      "29817 466\n",
      "Loss:  0.08248487859964371\n",
      "Loss:  0.09192056208848953\n",
      "Loss:  0.07778410613536835\n",
      "8 **********\n",
      "Epoch:  445.9605917930603  fold:  8  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.23897376656532288\n",
      "Eval Loss:  1.8310247659683228\n",
      "Eval Loss:  0.1288924217224121\n",
      "[[1902  171]\n",
      " [ 586  415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83      2073\n",
      "           1       0.71      0.41      0.52      1001\n",
      "\n",
      "    accuracy                           0.75      3074\n",
      "   macro avg       0.74      0.67      0.68      3074\n",
      "weighted avg       0.75      0.75      0.73      3074\n",
      "\n",
      "acc:  0.7537410540013012\n",
      "pre:  0.7081911262798635\n",
      "rec:  0.4145854145854146\n",
      "ma F1:  0.6785134977004982\n",
      "mi F1:  0.7537410540013012\n",
      "we F1:  0.7327461408440495\n",
      "Eval Loss:  0.44757917523384094\n",
      "Eval Loss:  0.373485803604126\n",
      "Eval Loss:  0.3677327036857605\n",
      "Eval Loss:  0.3931248188018799\n",
      "Eval Loss:  0.3829670548439026\n",
      "Eval Loss:  0.39284375309944153\n",
      "Eval Loss:  0.41562098264694214\n",
      "Eval Loss:  0.4407736361026764\n",
      "Eval Loss:  0.45776131749153137\n",
      "Eval Loss:  0.3669849634170532\n",
      "Eval Loss:  0.44112148880958557\n",
      "Eval Loss:  0.45434269309043884\n",
      "Eval Loss:  0.44308993220329285\n",
      "Eval Loss:  0.43764591217041016\n",
      "Eval Loss:  0.4292159974575043\n",
      "Eval Loss:  0.42558053135871887\n",
      "Eval Loss:  0.34977418184280396\n",
      "Eval Loss:  0.38833799958229065\n",
      "Eval Loss:  0.4161217510700226\n",
      "Eval Loss:  0.43687909841537476\n",
      "Eval Loss:  0.3390931487083435\n",
      "Eval Loss:  0.49752146005630493\n",
      "Eval Loss:  0.4575318992137909\n",
      "Eval Loss:  0.2687133252620697\n",
      "Eval Loss:  0.3838087022304535\n",
      "Eval Loss:  0.3826373219490051\n",
      "Eval Loss:  0.3619748651981354\n",
      "Eval Loss:  0.36859649419784546\n",
      "Eval Loss:  0.3810412585735321\n",
      "[[17353   738]\n",
      " [ 3983  7743]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88     18091\n",
      "           1       0.91      0.66      0.77     11726\n",
      "\n",
      "    accuracy                           0.84     29817\n",
      "   macro avg       0.86      0.81      0.82     29817\n",
      "weighted avg       0.85      0.84      0.84     29817\n",
      "\n",
      "acc:  0.841667505114532\n",
      "pre:  0.9129819596745666\n",
      "rec:  0.6603274774006481\n",
      "ma F1:  0.8233139053809281\n",
      "mi F1:  0.841667505114532\n",
      "we F1:  0.8354700617081277\n",
      "29817 466\n",
      "Loss:  0.07131680101156235\n",
      "Loss:  0.08153719455003738\n",
      "Loss:  0.10641943663358688\n",
      "9 **********\n",
      "Epoch:  523.7795197963715  fold:  8  kers:  32\n",
      "epoch:  10\n",
      "29817 466\n",
      "Loss:  0.07795698940753937\n",
      "Loss:  0.11362660676240921\n",
      "Loss:  0.06511407345533371\n",
      "10 **********\n",
      "Epoch:  563.2938663959503  fold:  8  kers:  32\n",
      "epoch:  11\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08028199523687363\n",
      "Loss:  0.06761498749256134\n",
      "Loss:  0.06390775740146637\n",
      "11 **********\n",
      "Epoch:  602.7473757266998  fold:  8  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.25353512167930603\n",
      "Eval Loss:  1.7281920909881592\n",
      "Eval Loss:  0.12149231880903244\n",
      "[[1782  291]\n",
      " [ 504  497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      2073\n",
      "           1       0.63      0.50      0.56      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.71      0.68      0.69      3074\n",
      "weighted avg       0.73      0.74      0.73      3074\n",
      "\n",
      "acc:  0.7413793103448276\n",
      "pre:  0.6307106598984772\n",
      "rec:  0.4965034965034965\n",
      "ma F1:  0.6866181916945222\n",
      "mi F1:  0.7413793103448276\n",
      "we F1:  0.7323021755024033\n",
      "Eval Loss:  0.3718351125717163\n",
      "Eval Loss:  0.31779733300209045\n",
      "Eval Loss:  0.32783693075180054\n",
      "Eval Loss:  0.35508090257644653\n",
      "Eval Loss:  0.35363948345184326\n",
      "Eval Loss:  0.351014643907547\n",
      "Eval Loss:  0.35186442732810974\n",
      "Eval Loss:  0.36323660612106323\n",
      "Eval Loss:  0.35668858885765076\n",
      "Eval Loss:  0.3129775822162628\n",
      "Eval Loss:  0.35781732201576233\n",
      "Eval Loss:  0.36197271943092346\n",
      "Eval Loss:  0.3792046904563904\n",
      "Eval Loss:  0.3654136657714844\n",
      "Eval Loss:  0.33507880568504333\n",
      "Eval Loss:  0.34255027770996094\n",
      "Eval Loss:  0.32940196990966797\n",
      "Eval Loss:  0.366144061088562\n",
      "Eval Loss:  0.3827117681503296\n",
      "Eval Loss:  0.37904489040374756\n",
      "Eval Loss:  0.24983543157577515\n",
      "Eval Loss:  0.41384249925613403\n",
      "Eval Loss:  0.4043501615524292\n",
      "Eval Loss:  0.224796861410141\n",
      "Eval Loss:  0.3174353241920471\n",
      "Eval Loss:  0.3402406871318817\n",
      "Eval Loss:  0.2859985828399658\n",
      "Eval Loss:  0.3492579460144043\n",
      "Eval Loss:  0.3195933699607849\n",
      "[[17217   874]\n",
      " [ 3272  8454]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18091\n",
      "           1       0.91      0.72      0.80     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.87      0.84      0.85     29817\n",
      "weighted avg       0.87      0.86      0.86     29817\n",
      "\n",
      "acc:  0.8609518060167018\n",
      "pre:  0.9063036020583191\n",
      "rec:  0.7209619648644039\n",
      "ma F1:  0.847806396083477\n",
      "mi F1:  0.8609518060167018\n",
      "we F1:  0.8573545570129505\n",
      "29817 466\n",
      "Loss:  0.09052026271820068\n",
      "Loss:  0.11097818613052368\n",
      "Loss:  0.05375105142593384\n",
      "12 **********\n",
      "Epoch:  680.7228853702545  fold:  8  kers:  32\n",
      "epoch:  13\n",
      "29817 466\n",
      "Loss:  0.10218199342489243\n",
      "Loss:  0.11692152917385101\n",
      "Loss:  0.10399173200130463\n",
      "13 **********\n",
      "Epoch:  720.2142930030823  fold:  8  kers:  32\n",
      "epoch:  14\n",
      "29817 466\n",
      "Loss:  0.08604864776134491\n",
      "Loss:  0.07838023453950882\n",
      "Loss:  0.08596540242433548\n",
      "14 **********\n",
      "Epoch:  759.7216579914093  fold:  8  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.27256062626838684\n",
      "Eval Loss:  1.8286986351013184\n",
      "Eval Loss:  0.11340349167585373\n",
      "[[1789  284]\n",
      " [ 606  395]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80      2073\n",
      "           1       0.58      0.39      0.47      1001\n",
      "\n",
      "    accuracy                           0.71      3074\n",
      "   macro avg       0.66      0.63      0.64      3074\n",
      "weighted avg       0.69      0.71      0.69      3074\n",
      "\n",
      "acc:  0.7104749512036435\n",
      "pre:  0.5817378497790869\n",
      "rec:  0.3946053946053946\n",
      "ma F1:  0.6355219124355204\n",
      "mi F1:  0.7104749512036435\n",
      "we F1:  0.6931615520046939\n",
      "Eval Loss:  0.39977291226387024\n",
      "Eval Loss:  0.34414422512054443\n",
      "Eval Loss:  0.361328125\n",
      "Eval Loss:  0.39202603697776794\n",
      "Eval Loss:  0.3347335159778595\n",
      "Eval Loss:  0.3855944871902466\n",
      "Eval Loss:  0.4075498580932617\n",
      "Eval Loss:  0.406281977891922\n",
      "Eval Loss:  0.39930257201194763\n",
      "Eval Loss:  0.35106950998306274\n",
      "Eval Loss:  0.39673492312431335\n",
      "Eval Loss:  0.3994733691215515\n",
      "Eval Loss:  0.4009672701358795\n",
      "Eval Loss:  0.412583589553833\n",
      "Eval Loss:  0.3891001343727112\n",
      "Eval Loss:  0.3897007405757904\n",
      "Eval Loss:  0.35415467619895935\n",
      "Eval Loss:  0.3689609467983246\n",
      "Eval Loss:  0.3922024965286255\n",
      "Eval Loss:  0.4044146239757538\n",
      "Eval Loss:  0.27159300446510315\n",
      "Eval Loss:  0.46204468607902527\n",
      "Eval Loss:  0.44753924012184143\n",
      "Eval Loss:  0.23447619378566742\n",
      "Eval Loss:  0.34721484780311584\n",
      "Eval Loss:  0.37543201446533203\n",
      "Eval Loss:  0.3070175349712372\n",
      "Eval Loss:  0.3681749701499939\n",
      "Eval Loss:  0.34905949234962463\n",
      "[[17495   596]\n",
      " [ 3889  7837]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89     18091\n",
      "           1       0.93      0.67      0.78     11726\n",
      "\n",
      "    accuracy                           0.85     29817\n",
      "   macro avg       0.87      0.82      0.83     29817\n",
      "weighted avg       0.86      0.85      0.84     29817\n",
      "\n",
      "acc:  0.8495824529630748\n",
      "pre:  0.9293252697735088\n",
      "rec:  0.6683438512706805\n",
      "ma F1:  0.8319512566671906\n",
      "mi F1:  0.8495824529630748\n",
      "we F1:  0.8435709050854244\n",
      "29817 466\n",
      "Loss:  0.10528752207756042\n",
      "Loss:  0.08011527359485626\n",
      "Loss:  0.05999100208282471\n",
      "15 **********\n",
      "Epoch:  837.7520215511322  fold:  8  kers:  32\n",
      "epoch:  16\n",
      "29817 466\n",
      "Loss:  0.09288769960403442\n",
      "Loss:  0.09299295395612717\n",
      "Loss:  0.08255039155483246\n",
      "16 **********\n",
      "Epoch:  877.2683625221252  fold:  8  kers:  32\n",
      "epoch:  17\n",
      "29817 466\n",
      "Loss:  0.08307420462369919\n",
      "Loss:  0.08460257947444916\n",
      "Loss:  0.07186008244752884\n",
      "17 **********\n",
      "Epoch:  916.8495304584503  fold:  8  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.2153034806251526\n",
      "Eval Loss:  1.5665854215621948\n",
      "Eval Loss:  0.12087831646203995\n",
      "[[1825  248]\n",
      " [ 552  449]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      2073\n",
      "           1       0.64      0.45      0.53      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.71      0.66      0.67      3074\n",
      "weighted avg       0.73      0.74      0.73      3074\n",
      "\n",
      "acc:  0.7397527651268705\n",
      "pre:  0.6441893830703013\n",
      "rec:  0.4485514485514486\n",
      "ma F1:  0.6745410992443193\n",
      "mi F1:  0.7397527651268706\n",
      "we F1:  0.7253455366179349\n",
      "Eval Loss:  0.37671494483947754\n",
      "Eval Loss:  0.30295494198799133\n",
      "Eval Loss:  0.3326279819011688\n",
      "Eval Loss:  0.3585619628429413\n",
      "Eval Loss:  0.3041856586933136\n",
      "Eval Loss:  0.3468303382396698\n",
      "Eval Loss:  0.37539806962013245\n",
      "Eval Loss:  0.35988950729370117\n",
      "Eval Loss:  0.34294477105140686\n",
      "Eval Loss:  0.3161182105541229\n",
      "Eval Loss:  0.367025226354599\n",
      "Eval Loss:  0.3500973880290985\n",
      "Eval Loss:  0.39032086730003357\n",
      "Eval Loss:  0.3445602357387543\n",
      "Eval Loss:  0.3437148928642273\n",
      "Eval Loss:  0.3394303023815155\n",
      "Eval Loss:  0.33269795775413513\n",
      "Eval Loss:  0.3383570909500122\n",
      "Eval Loss:  0.3670549690723419\n",
      "Eval Loss:  0.3557974100112915\n",
      "Eval Loss:  0.23277239501476288\n",
      "Eval Loss:  0.42183130979537964\n",
      "Eval Loss:  0.3886393904685974\n",
      "Eval Loss:  0.1939949244260788\n",
      "Eval Loss:  0.3160383701324463\n",
      "Eval Loss:  0.32778605818748474\n",
      "Eval Loss:  0.26307275891304016\n",
      "Eval Loss:  0.3437815010547638\n",
      "Eval Loss:  0.318326860666275\n",
      "[[17412   679]\n",
      " [ 3426  8300]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89     18091\n",
      "           1       0.92      0.71      0.80     11726\n",
      "\n",
      "    accuracy                           0.86     29817\n",
      "   macro avg       0.88      0.84      0.85     29817\n",
      "weighted avg       0.87      0.86      0.86     29817\n",
      "\n",
      "acc:  0.8623268605158131\n",
      "pre:  0.9243791068047666\n",
      "rec:  0.7078287566092444\n",
      "ma F1:  0.8481451650358041\n",
      "mi F1:  0.8623268605158131\n",
      "we F1:  0.858051496437281\n",
      "29817 466\n",
      "Loss:  0.055123426020145416\n",
      "Loss:  0.0823698490858078\n",
      "Loss:  0.08217006921768188\n",
      "18 **********\n",
      "Epoch:  994.9177918434143  fold:  8  kers:  32\n",
      "epoch:  19\n",
      "29817 466\n",
      "Loss:  0.05889987200498581\n",
      "Loss:  0.08586698025465012\n",
      "Loss:  0.1006709635257721\n",
      "19 **********\n",
      "Epoch:  1034.6435732841492  fold:  8  kers:  32\n",
      "epoch:  20\n",
      "29817 466\n",
      "Loss:  0.09732609242200851\n",
      "Loss:  0.06518042832612991\n",
      "Loss:  0.07887043058872223\n",
      "20 **********\n",
      "Epoch:  1074.1988108158112  fold:  8  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.3125423491001129\n",
      "Eval Loss:  1.4893839359283447\n",
      "Eval Loss:  0.13141445815563202\n",
      "[[1743  330]\n",
      " [ 485  516]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      2073\n",
      "           1       0.61      0.52      0.56      1001\n",
      "\n",
      "    accuracy                           0.73      3074\n",
      "   macro avg       0.70      0.68      0.68      3074\n",
      "weighted avg       0.73      0.73      0.73      3074\n",
      "\n",
      "acc:  0.7348731294729993\n",
      "pre:  0.6099290780141844\n",
      "rec:  0.5154845154845155\n",
      "ma F1:  0.6846265464762038\n",
      "mi F1:  0.7348731294729993\n",
      "we F1:  0.7285257616127684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3410671055316925\n",
      "Eval Loss:  0.2883104681968689\n",
      "Eval Loss:  0.308879017829895\n",
      "Eval Loss:  0.33310332894325256\n",
      "Eval Loss:  0.2714780569076538\n",
      "Eval Loss:  0.33114340901374817\n",
      "Eval Loss:  0.34887149930000305\n",
      "Eval Loss:  0.34018048644065857\n",
      "Eval Loss:  0.3105807602405548\n",
      "Eval Loss:  0.29403331875801086\n",
      "Eval Loss:  0.33104151487350464\n",
      "Eval Loss:  0.3149416148662567\n",
      "Eval Loss:  0.3543030619621277\n",
      "Eval Loss:  0.301952987909317\n",
      "Eval Loss:  0.3231186270713806\n",
      "Eval Loss:  0.30143994092941284\n",
      "Eval Loss:  0.30546835064888\n",
      "Eval Loss:  0.32632938027381897\n",
      "Eval Loss:  0.3507090210914612\n",
      "Eval Loss:  0.3301381766796112\n",
      "Eval Loss:  0.21324273943901062\n",
      "Eval Loss:  0.3889404535293579\n",
      "Eval Loss:  0.37769725918769836\n",
      "Eval Loss:  0.17048221826553345\n",
      "Eval Loss:  0.28495147824287415\n",
      "Eval Loss:  0.3129497766494751\n",
      "Eval Loss:  0.230597123503685\n",
      "Eval Loss:  0.32490405440330505\n",
      "Eval Loss:  0.30735528469085693\n",
      "[[17272   819]\n",
      " [ 3034  8692]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90     18091\n",
      "           1       0.91      0.74      0.82     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.88      0.85      0.86     29817\n",
      "weighted avg       0.88      0.87      0.87     29817\n",
      "\n",
      "acc:  0.8707784149981554\n",
      "pre:  0.9138891809483756\n",
      "rec:  0.7412587412587412\n",
      "ma F1:  0.8591124900378428\n",
      "mi F1:  0.8707784149981554\n",
      "we F1:  0.8677667572141121\n",
      "29817 466\n",
      "Loss:  0.07446127384901047\n",
      "Loss:  0.08170206099748611\n",
      "Loss:  0.07692908495664597\n",
      "21 **********\n",
      "Epoch:  1152.1384160518646  fold:  8  kers:  32\n",
      "epoch:  22\n",
      "29817 466\n",
      "Loss:  0.09491150826215744\n",
      "Loss:  0.08899513632059097\n",
      "Loss:  0.08410662412643433\n",
      "22 **********\n",
      "Epoch:  1191.6856746673584  fold:  8  kers:  32\n",
      "epoch:  23\n",
      "29817 466\n",
      "Loss:  0.0888163149356842\n",
      "Loss:  0.07831565290689468\n",
      "Loss:  0.09503394365310669\n",
      "23 **********\n",
      "Epoch:  1231.20201587677  fold:  8  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.4667039215564728\n",
      "Eval Loss:  1.520378589630127\n",
      "Eval Loss:  0.15272556245326996\n",
      "[[1686  387]\n",
      " [ 446  555]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      2073\n",
      "           1       0.59      0.55      0.57      1001\n",
      "\n",
      "    accuracy                           0.73      3074\n",
      "   macro avg       0.69      0.68      0.69      3074\n",
      "weighted avg       0.73      0.73      0.73      3074\n",
      "\n",
      "acc:  0.7290175666883539\n",
      "pre:  0.589171974522293\n",
      "rec:  0.5544455544455544\n",
      "ma F1:  0.686592010222372\n",
      "mi F1:  0.7290175666883539\n",
      "we F1:  0.7268043855818173\n",
      "Eval Loss:  0.317340224981308\n",
      "Eval Loss:  0.28018730878829956\n",
      "Eval Loss:  0.3137914538383484\n",
      "Eval Loss:  0.3489218056201935\n",
      "Eval Loss:  0.25303637981414795\n",
      "Eval Loss:  0.3327994644641876\n",
      "Eval Loss:  0.3301681876182556\n",
      "Eval Loss:  0.3369559645652771\n",
      "Eval Loss:  0.3125956654548645\n",
      "Eval Loss:  0.29693248867988586\n",
      "Eval Loss:  0.31061428785324097\n",
      "Eval Loss:  0.296747088432312\n",
      "Eval Loss:  0.32582587003707886\n",
      "Eval Loss:  0.25765469670295715\n",
      "Eval Loss:  0.2991315722465515\n",
      "Eval Loss:  0.2728329598903656\n",
      "Eval Loss:  0.27662327885627747\n",
      "Eval Loss:  0.32231852412223816\n",
      "Eval Loss:  0.32409799098968506\n",
      "Eval Loss:  0.3336879312992096\n",
      "Eval Loss:  0.1930634081363678\n",
      "Eval Loss:  0.36709466576576233\n",
      "Eval Loss:  0.38779473304748535\n",
      "Eval Loss:  0.15340107679367065\n",
      "Eval Loss:  0.2846744656562805\n",
      "Eval Loss:  0.3359088897705078\n",
      "Eval Loss:  0.1978951096534729\n",
      "Eval Loss:  0.3152376115322113\n",
      "Eval Loss:  0.2918815016746521\n",
      "[[17105   986]\n",
      " [ 2764  8962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     18091\n",
      "           1       0.90      0.76      0.83     11726\n",
      "\n",
      "    accuracy                           0.87     29817\n",
      "   macro avg       0.88      0.85      0.86     29817\n",
      "weighted avg       0.88      0.87      0.87     29817\n",
      "\n",
      "acc:  0.8742328202032398\n",
      "pre:  0.9008845999195818\n",
      "rec:  0.764284495991813\n",
      "ma F1:  0.8640967194405693\n",
      "mi F1:  0.8742328202032398\n",
      "we F1:  0.8720196325382481\n",
      "29817 466\n",
      "Loss:  0.0403299555182457\n",
      "Loss:  0.10194367915391922\n",
      "Loss:  0.10469517111778259\n",
      "24 **********\n",
      "Epoch:  1309.330117225647  fold:  8  kers:  32\n",
      "epoch:  25\n",
      "29817 466\n",
      "Loss:  0.05916162580251694\n",
      "Loss:  0.07501691579818726\n",
      "Loss:  0.05381738394498825\n",
      "25 **********\n",
      "Epoch:  1349.013013124466  fold:  8  kers:  32\n",
      "epoch:  26\n",
      "29817 466\n",
      "Loss:  0.058685243129730225\n",
      "Loss:  0.07206694781780243\n",
      "Loss:  0.07687743753194809\n",
      "26 **********\n",
      "Epoch:  1388.6171197891235  fold:  8  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.4442705810070038\n",
      "Eval Loss:  1.2750728130340576\n",
      "Eval Loss:  0.1442967653274536\n",
      "[[1693  380]\n",
      " [ 359  642]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      2073\n",
      "           1       0.63      0.64      0.63      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.73      0.73      0.73      3074\n",
      "weighted avg       0.76      0.76      0.76      3074\n",
      "\n",
      "acc:  0.7595966167859467\n",
      "pre:  0.6281800391389433\n",
      "rec:  0.6413586413586414\n",
      "ma F1:  0.7277747120238469\n",
      "mi F1:  0.7595966167859467\n",
      "we F1:  0.7602324493263882\n",
      "Eval Loss:  0.3102869987487793\n",
      "Eval Loss:  0.2641370892524719\n",
      "Eval Loss:  0.27506884932518005\n",
      "Eval Loss:  0.30034828186035156\n",
      "Eval Loss:  0.24556097388267517\n",
      "Eval Loss:  0.30664730072021484\n",
      "Eval Loss:  0.3062115013599396\n",
      "Eval Loss:  0.3088550865650177\n",
      "Eval Loss:  0.2950524091720581\n",
      "Eval Loss:  0.2570994198322296\n",
      "Eval Loss:  0.2895498275756836\n",
      "Eval Loss:  0.2638474404811859\n",
      "Eval Loss:  0.30762979388237\n",
      "Eval Loss:  0.2295953631401062\n",
      "Eval Loss:  0.2799127697944641\n",
      "Eval Loss:  0.23206645250320435\n",
      "Eval Loss:  0.25980082154273987\n",
      "Eval Loss:  0.29526007175445557\n",
      "Eval Loss:  0.29814067482948303\n",
      "Eval Loss:  0.29366111755371094\n",
      "Eval Loss:  0.18400897085666656\n",
      "Eval Loss:  0.3509828746318817\n",
      "Eval Loss:  0.35283342003822327\n",
      "Eval Loss:  0.14872446656227112\n",
      "Eval Loss:  0.2531532645225525\n",
      "Eval Loss:  0.28382807970046997\n",
      "Eval Loss:  0.19562704861164093\n",
      "Eval Loss:  0.2849815785884857\n",
      "Eval Loss:  0.2768806219100952\n",
      "[[16985  1106]\n",
      " [ 2385  9341]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18091\n",
      "           1       0.89      0.80      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.87      0.87     29817\n",
      "weighted avg       0.88      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8829191400878693\n",
      "pre:  0.8941322867808941\n",
      "rec:  0.796605833191199\n",
      "ma F1:  0.8746830054630106\n",
      "mi F1:  0.8829191400878693\n",
      "we F1:  0.8815410636638511\n",
      "29817 466\n",
      "Loss:  0.09116005897521973\n",
      "Loss:  0.06828782707452774\n",
      "Loss:  0.050459254533052444\n",
      "27 **********\n",
      "Epoch:  1466.5387735366821  fold:  8  kers:  32\n",
      "epoch:  28\n",
      "29817 466\n",
      "Loss:  0.07581550627946854\n",
      "Loss:  0.08919649571180344\n",
      "Loss:  0.09305964410305023\n",
      "28 **********\n",
      "Epoch:  1506.1498613357544  fold:  8  kers:  32\n",
      "epoch:  29\n",
      "29817 466\n",
      "Loss:  0.06274592131376266\n",
      "Loss:  0.08376628905534744\n",
      "Loss:  0.06775014102458954\n",
      "29 **********\n",
      "Epoch:  1545.6412689685822  fold:  8  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.5013816356658936\n",
      "Eval Loss:  1.3941233158111572\n",
      "Eval Loss:  0.1418987363576889\n",
      "[[1690  383]\n",
      " [ 422  579]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      2073\n",
      "           1       0.60      0.58      0.59      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.70      0.70      0.70      3074\n",
      "weighted avg       0.74      0.74      0.74      3074\n",
      "\n",
      "acc:  0.7381262199089135\n",
      "pre:  0.6018711018711018\n",
      "rec:  0.5784215784215784\n",
      "ma F1:  0.6987798769469353\n",
      "mi F1:  0.7381262199089136\n",
      "we F1:  0.7367450251514723\n",
      "Eval Loss:  0.3208765983581543\n",
      "Eval Loss:  0.27731946110725403\n",
      "Eval Loss:  0.3058459460735321\n",
      "Eval Loss:  0.3301084041595459\n",
      "Eval Loss:  0.2411036193370819\n",
      "Eval Loss:  0.32400745153427124\n",
      "Eval Loss:  0.3300776183605194\n",
      "Eval Loss:  0.3422897458076477\n",
      "Eval Loss:  0.29434970021247864\n",
      "Eval Loss:  0.2919570207595825\n",
      "Eval Loss:  0.29712972044944763\n",
      "Eval Loss:  0.27420127391815186\n",
      "Eval Loss:  0.3080093562602997\n",
      "Eval Loss:  0.257549524307251\n",
      "Eval Loss:  0.2992440164089203\n",
      "Eval Loss:  0.2720382809638977\n",
      "Eval Loss:  0.2669028043746948\n",
      "Eval Loss:  0.2971671521663666\n",
      "Eval Loss:  0.3063506484031677\n",
      "Eval Loss:  0.3237745463848114\n",
      "Eval Loss:  0.19698859751224518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.36017948389053345\n",
      "Eval Loss:  0.3860722780227661\n",
      "Eval Loss:  0.14847517013549805\n",
      "Eval Loss:  0.2872522175312042\n",
      "Eval Loss:  0.33388352394104004\n",
      "Eval Loss:  0.1994677484035492\n",
      "Eval Loss:  0.2857036292552948\n",
      "Eval Loss:  0.29013779759407043\n",
      "[[17064  1027]\n",
      " [ 2626  9100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     18091\n",
      "           1       0.90      0.78      0.83     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.88      0.86      0.87     29817\n",
      "weighted avg       0.88      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8774859979206493\n",
      "pre:  0.8985879332477535\n",
      "rec:  0.7760532150776053\n",
      "ma F1:  0.868074392416006\n",
      "mi F1:  0.8774859979206493\n",
      "we F1:  0.8755963498541093\n",
      "29817 466\n",
      "Loss:  0.05692484229803085\n",
      "Loss:  0.06759025901556015\n",
      "Loss:  0.09498418867588043\n",
      "30 **********\n",
      "Epoch:  1623.5569386482239  fold:  8  kers:  32\n",
      "epoch:  31\n",
      "29817 466\n",
      "Loss:  0.06849751621484756\n",
      "Loss:  0.08273786306381226\n",
      "Loss:  0.08283445984125137\n",
      "31 **********\n",
      "Epoch:  1663.0553278923035  fold:  8  kers:  32\n",
      "epoch:  32\n",
      "29817 466\n",
      "Loss:  0.05607728660106659\n",
      "Loss:  0.07597227394580841\n",
      "Loss:  0.08239337801933289\n",
      "32 **********\n",
      "Epoch:  1702.5108318328857  fold:  8  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.5141783356666565\n",
      "Eval Loss:  1.2715978622436523\n",
      "Eval Loss:  0.16175711154937744\n",
      "[[1647  426]\n",
      " [ 361  640]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      2073\n",
      "           1       0.60      0.64      0.62      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.71      0.72      0.71      3074\n",
      "weighted avg       0.75      0.74      0.75      3074\n",
      "\n",
      "acc:  0.7439817826935589\n",
      "pre:  0.600375234521576\n",
      "rec:  0.6393606393606394\n",
      "ma F1:  0.7132050339597509\n",
      "mi F1:  0.7439817826935589\n",
      "we F1:  0.7459683652831294\n",
      "Eval Loss:  0.2936341464519501\n",
      "Eval Loss:  0.2586437165737152\n",
      "Eval Loss:  0.2637672424316406\n",
      "Eval Loss:  0.298117071390152\n",
      "Eval Loss:  0.2235119342803955\n",
      "Eval Loss:  0.2933780550956726\n",
      "Eval Loss:  0.2901092767715454\n",
      "Eval Loss:  0.3086930513381958\n",
      "Eval Loss:  0.3006574511528015\n",
      "Eval Loss:  0.2505737841129303\n",
      "Eval Loss:  0.2648763954639435\n",
      "Eval Loss:  0.2590848505496979\n",
      "Eval Loss:  0.27972784638404846\n",
      "Eval Loss:  0.23839595913887024\n",
      "Eval Loss:  0.2706235647201538\n",
      "Eval Loss:  0.2308647483587265\n",
      "Eval Loss:  0.26214635372161865\n",
      "Eval Loss:  0.2756669223308563\n",
      "Eval Loss:  0.2855360209941864\n",
      "Eval Loss:  0.2976318895816803\n",
      "Eval Loss:  0.1814676970243454\n",
      "Eval Loss:  0.3293420970439911\n",
      "Eval Loss:  0.35926130414009094\n",
      "Eval Loss:  0.1418347954750061\n",
      "Eval Loss:  0.2559504210948944\n",
      "Eval Loss:  0.30930307507514954\n",
      "Eval Loss:  0.1839689016342163\n",
      "Eval Loss:  0.26356595754623413\n",
      "Eval Loss:  0.2586168050765991\n",
      "[[16987  1104]\n",
      " [ 2263  9463]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     18091\n",
      "           1       0.90      0.81      0.85     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.89      0.87      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8870778414998155\n",
      "pre:  0.8955238005110249\n",
      "rec:  0.8070100631076241\n",
      "ma F1:  0.8793985299986572\n",
      "mi F1:  0.8870778414998156\n",
      "we F1:  0.8858949172534251\n",
      "29817 466\n",
      "Loss:  0.08663064986467361\n",
      "Loss:  0.0539683923125267\n",
      "Loss:  0.08407855033874512\n",
      "33 **********\n",
      "Epoch:  1780.5641334056854  fold:  8  kers:  32\n",
      "epoch:  34\n",
      "29817 466\n",
      "Loss:  0.057607438415288925\n",
      "Loss:  0.0748404785990715\n",
      "Loss:  0.04929545521736145\n",
      "34 **********\n",
      "Epoch:  1820.0964317321777  fold:  8  kers:  32\n",
      "epoch:  35\n",
      "29817 466\n",
      "Loss:  0.06117774546146393\n",
      "Loss:  0.047613926231861115\n",
      "Loss:  0.057852502912282944\n",
      "35 **********\n",
      "Epoch:  1859.7743411064148  fold:  8  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.5362772941589355\n",
      "Eval Loss:  1.2179051637649536\n",
      "Eval Loss:  0.1810784488916397\n",
      "[[1596  477]\n",
      " [ 312  689]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80      2073\n",
      "           1       0.59      0.69      0.64      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.71      0.73      0.72      3074\n",
      "weighted avg       0.76      0.74      0.75      3074\n",
      "\n",
      "acc:  0.743331164606376\n",
      "pre:  0.5909090909090909\n",
      "rec:  0.6883116883116883\n",
      "ma F1:  0.7188553798517114\n",
      "mi F1:  0.743331164606376\n",
      "we F1:  0.7477837605099258\n",
      "Eval Loss:  0.30233898758888245\n",
      "Eval Loss:  0.25196290016174316\n",
      "Eval Loss:  0.2695770859718323\n",
      "Eval Loss:  0.29425767064094543\n",
      "Eval Loss:  0.22320446372032166\n",
      "Eval Loss:  0.30417516827583313\n",
      "Eval Loss:  0.28836655616760254\n",
      "Eval Loss:  0.300890177488327\n",
      "Eval Loss:  0.28210949897766113\n",
      "Eval Loss:  0.24816539883613586\n",
      "Eval Loss:  0.2537889778614044\n",
      "Eval Loss:  0.23645107448101044\n",
      "Eval Loss:  0.25823974609375\n",
      "Eval Loss:  0.22579795122146606\n",
      "Eval Loss:  0.25717854499816895\n",
      "Eval Loss:  0.2116299420595169\n",
      "Eval Loss:  0.2709640860557556\n",
      "Eval Loss:  0.2853655517101288\n",
      "Eval Loss:  0.2935775816440582\n",
      "Eval Loss:  0.2923305034637451\n",
      "Eval Loss:  0.17360305786132812\n",
      "Eval Loss:  0.3305482268333435\n",
      "Eval Loss:  0.36351022124290466\n",
      "Eval Loss:  0.1460915207862854\n",
      "Eval Loss:  0.24567466974258423\n",
      "Eval Loss:  0.30567479133605957\n",
      "Eval Loss:  0.17194578051567078\n",
      "Eval Loss:  0.25680652260780334\n",
      "Eval Loss:  0.2501523494720459\n",
      "[[16725  1366]\n",
      " [ 1932  9794]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     18091\n",
      "           1       0.88      0.84      0.86     11726\n",
      "\n",
      "    accuracy                           0.89     29817\n",
      "   macro avg       0.89      0.88      0.88     29817\n",
      "weighted avg       0.89      0.89      0.89     29817\n",
      "\n",
      "acc:  0.8893919576080759\n",
      "pre:  0.8775985663082437\n",
      "rec:  0.8352379327989085\n",
      "ma F1:  0.8830740262612855\n",
      "mi F1:  0.8893919576080759\n",
      "we F1:  0.8888760220804054\n",
      "29817 466\n",
      "Loss:  0.06154134124517441\n",
      "Loss:  0.06897270679473877\n",
      "Loss:  0.0536382757127285\n",
      "36 **********\n",
      "Epoch:  1937.6311678886414  fold:  8  kers:  32\n",
      "epoch:  37\n",
      "29817 466\n",
      "Loss:  0.07112091034650803\n",
      "Loss:  0.06135379523038864\n",
      "Loss:  0.053255606442689896\n",
      "37 **********\n",
      "Epoch:  1977.1993703842163  fold:  8  kers:  32\n",
      "epoch:  38\n",
      "29817 466\n",
      "Loss:  0.06902680546045303\n",
      "Loss:  0.06685182452201843\n",
      "Loss:  0.06613892316818237\n",
      "38 **********\n",
      "Epoch:  2016.6788108348846  fold:  8  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.4140602946281433\n",
      "Eval Loss:  1.2925878763198853\n",
      "Eval Loss:  0.11618823558092117\n",
      "[[1715  358]\n",
      " [ 420  581]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      2073\n",
      "           1       0.62      0.58      0.60      1001\n",
      "\n",
      "    accuracy                           0.75      3074\n",
      "   macro avg       0.71      0.70      0.71      3074\n",
      "weighted avg       0.74      0.75      0.74      3074\n",
      "\n",
      "acc:  0.7469095640858816\n",
      "pre:  0.6187433439829606\n",
      "rec:  0.5804195804195804\n",
      "ma F1:  0.7070415703030065\n",
      "mi F1:  0.7469095640858815\n",
      "we F1:  0.7447298325033963\n",
      "Eval Loss:  0.32335415482521057\n",
      "Eval Loss:  0.25462427735328674\n",
      "Eval Loss:  0.2893141806125641\n",
      "Eval Loss:  0.31282714009284973\n",
      "Eval Loss:  0.23135323822498322\n",
      "Eval Loss:  0.31412357091903687\n",
      "Eval Loss:  0.3386642634868622\n",
      "Eval Loss:  0.32979482412338257\n",
      "Eval Loss:  0.3129311800003052\n",
      "Eval Loss:  0.2574082314968109\n",
      "Eval Loss:  0.297452449798584\n",
      "Eval Loss:  0.27399900555610657\n",
      "Eval Loss:  0.29970017075538635\n",
      "Eval Loss:  0.2432388812303543\n",
      "Eval Loss:  0.2858995795249939\n",
      "Eval Loss:  0.27550971508026123\n",
      "Eval Loss:  0.2772713303565979\n",
      "Eval Loss:  0.26410964131355286\n",
      "Eval Loss:  0.2661953568458557\n",
      "Eval Loss:  0.31808605790138245\n",
      "Eval Loss:  0.18849347531795502\n",
      "Eval Loss:  0.36385446786880493\n",
      "Eval Loss:  0.36771348118782043\n",
      "Eval Loss:  0.15942630171775818\n",
      "Eval Loss:  0.2759864032268524\n",
      "Eval Loss:  0.3032147288322449\n",
      "Eval Loss:  0.2102746218442917\n",
      "Eval Loss:  0.26229414343833923\n",
      "Eval Loss:  0.2738319933414459\n",
      "[[17380   711]\n",
      " [ 2795  8931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     18091\n",
      "           1       0.93      0.76      0.84     11726\n",
      "\n",
      "    accuracy                           0.88     29817\n",
      "   macro avg       0.89      0.86      0.87     29817\n",
      "weighted avg       0.89      0.88      0.88     29817\n",
      "\n",
      "acc:  0.8824160713686823\n",
      "pre:  0.9262601120099564\n",
      "rec:  0.761640798226164\n",
      "ma F1:  0.8721505350348306\n",
      "mi F1:  0.8824160713686823\n",
      "we F1:  0.8798840110396792\n",
      "29817 466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06584801524877548\n",
      "Loss:  0.07710839062929153\n",
      "Loss:  0.09029657393693924\n",
      "39 **********\n",
      "Epoch:  2094.658310174942  fold:  8  kers:  32\n",
      "epoch:  40\n",
      "29817 466\n",
      "Loss:  0.09155257791280746\n",
      "Loss:  0.0652807429432869\n",
      "Loss:  0.06780286878347397\n",
      "40 **********\n",
      "Epoch:  2134.2045702934265  fold:  8  kers:  32\n",
      "epoch:  41\n",
      "29817 466\n",
      "Loss:  0.05620608478784561\n",
      "Loss:  0.08442839235067368\n",
      "Loss:  0.06525071710348129\n",
      "41 **********\n",
      "Epoch:  2173.660074710846  fold:  8  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.8134298920631409\n",
      "Eval Loss:  1.1949512958526611\n",
      "Eval Loss:  0.1497189849615097\n",
      "[[1575  498]\n",
      " [ 311  690]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80      2073\n",
      "           1       0.58      0.69      0.63      1001\n",
      "\n",
      "    accuracy                           0.74      3074\n",
      "   macro avg       0.71      0.72      0.71      3074\n",
      "weighted avg       0.75      0.74      0.74      3074\n",
      "\n",
      "acc:  0.7368249837345479\n",
      "pre:  0.5808080808080808\n",
      "rec:  0.6893106893106893\n",
      "ma F1:  0.7130401600415219\n",
      "mi F1:  0.7368249837345479\n",
      "we F1:  0.7418507035431307\n",
      "Eval Loss:  0.2895984351634979\n",
      "Eval Loss:  0.2456807792186737\n",
      "Eval Loss:  0.2645118534564972\n",
      "Eval Loss:  0.27140164375305176\n",
      "Eval Loss:  0.23236042261123657\n",
      "Eval Loss:  0.2843022346496582\n",
      "Eval Loss:  0.27071768045425415\n",
      "Eval Loss:  0.2971872389316559\n",
      "Eval Loss:  0.2950243055820465\n",
      "Eval Loss:  0.22162486612796783\n",
      "Eval Loss:  0.2335943579673767\n",
      "Eval Loss:  0.23370644450187683\n",
      "Eval Loss:  0.23524343967437744\n",
      "Eval Loss:  0.22245799005031586\n",
      "Eval Loss:  0.23904599249362946\n",
      "Eval Loss:  0.20718786120414734\n",
      "Eval Loss:  0.2582414746284485\n",
      "Eval Loss:  0.24814295768737793\n",
      "Eval Loss:  0.2597317397594452\n",
      "Eval Loss:  0.2739708423614502\n",
      "Eval Loss:  0.16353684663772583\n",
      "Eval Loss:  0.2968650162220001\n",
      "Eval Loss:  0.34280022978782654\n",
      "Eval Loss:  0.1248413622379303\n",
      "Eval Loss:  0.2397688776254654\n",
      "Eval Loss:  0.27938926219940186\n",
      "Eval Loss:  0.18174844980239868\n",
      "Eval Loss:  0.22991831600666046\n",
      "Eval Loss:  0.25512105226516724\n",
      "[[16888  1203]\n",
      " [ 1918  9808]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     18091\n",
      "           1       0.89      0.84      0.86     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.89      0.88      0.89     29817\n",
      "weighted avg       0.90      0.90      0.89     29817\n",
      "\n",
      "acc:  0.895328168494483\n",
      "pre:  0.8907456180183453\n",
      "rec:  0.8364318608221047\n",
      "ma F1:  0.8890739633751414\n",
      "mi F1:  0.895328168494483\n",
      "we F1:  0.894696564446414\n",
      "29817 466\n",
      "Loss:  0.04683090001344681\n",
      "Loss:  0.05115192010998726\n",
      "Loss:  0.03372262045741081\n",
      "42 **********\n",
      "Epoch:  2257.0261704921722  fold:  8  kers:  32\n",
      "epoch:  43\n",
      "29817 466\n",
      "Loss:  0.05039665848016739\n",
      "Loss:  0.05864401161670685\n",
      "Loss:  0.06677315384149551\n",
      "43 **********\n",
      "Epoch:  2296.524559736252  fold:  8  kers:  32\n",
      "epoch:  44\n",
      "29817 466\n",
      "Loss:  0.057148974388837814\n",
      "Loss:  0.05963917449116707\n",
      "Loss:  0.06976915150880814\n",
      "44 **********\n",
      "Epoch:  2336.0987465381622  fold:  8  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.5368703007698059\n",
      "Eval Loss:  1.2238311767578125\n",
      "Eval Loss:  0.10980939865112305\n",
      "[[1696  377]\n",
      " [ 356  645]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      2073\n",
      "           1       0.63      0.64      0.64      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.73      0.73      0.73      3074\n",
      "weighted avg       0.76      0.76      0.76      3074\n",
      "\n",
      "acc:  0.7615484710474951\n",
      "pre:  0.6311154598825832\n",
      "rec:  0.6443556443556444\n",
      "ma F1:  0.7299849308707441\n",
      "mi F1:  0.7615484710474951\n",
      "we F1:  0.7621791412127776\n",
      "Eval Loss:  0.30786171555519104\n",
      "Eval Loss:  0.23536567389965057\n",
      "Eval Loss:  0.26322877407073975\n",
      "Eval Loss:  0.2871737778186798\n",
      "Eval Loss:  0.2322821319103241\n",
      "Eval Loss:  0.27798181772232056\n",
      "Eval Loss:  0.3065781891345978\n",
      "Eval Loss:  0.2994530498981476\n",
      "Eval Loss:  0.28944820165634155\n",
      "Eval Loss:  0.23585565388202667\n",
      "Eval Loss:  0.2416362762451172\n",
      "Eval Loss:  0.24174335598945618\n",
      "Eval Loss:  0.2583024501800537\n",
      "Eval Loss:  0.20627301931381226\n",
      "Eval Loss:  0.23225176334381104\n",
      "Eval Loss:  0.23829518258571625\n",
      "Eval Loss:  0.27309027314186096\n",
      "Eval Loss:  0.24064408242702484\n",
      "Eval Loss:  0.26365992426872253\n",
      "Eval Loss:  0.283150851726532\n",
      "Eval Loss:  0.1634940803050995\n",
      "Eval Loss:  0.32685306668281555\n",
      "Eval Loss:  0.32911550998687744\n",
      "Eval Loss:  0.14807383716106415\n",
      "Eval Loss:  0.2563004791736603\n",
      "Eval Loss:  0.2774169445037842\n",
      "Eval Loss:  0.18483257293701172\n",
      "Eval Loss:  0.23549816012382507\n",
      "Eval Loss:  0.24785155057907104\n",
      "[[17310   781]\n",
      " [ 2345  9381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18091\n",
      "           1       0.92      0.80      0.86     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.88      0.89     29817\n",
      "weighted avg       0.90      0.90      0.89     29817\n",
      "\n",
      "acc:  0.8951604789214207\n",
      "pre:  0.923145050186971\n",
      "rec:  0.800017056114617\n",
      "ma F1:  0.8871826476210793\n",
      "mi F1:  0.8951604789214207\n",
      "we F1:  0.8935868469181751\n",
      "29817 466\n",
      "Loss:  0.06329585611820221\n",
      "Loss:  0.05551777780056\n",
      "Loss:  0.05648832768201828\n",
      "45 **********\n",
      "Epoch:  2414.084228992462  fold:  8  kers:  32\n",
      "epoch:  46\n",
      "29817 466\n",
      "Loss:  0.043355219066143036\n",
      "Loss:  0.06240718066692352\n",
      "Loss:  0.06979048997163773\n",
      "46 **********\n",
      "Epoch:  2453.6274983882904  fold:  8  kers:  32\n",
      "epoch:  47\n",
      "29817 466\n",
      "Loss:  0.07966119796037674\n",
      "Loss:  0.08986277133226395\n",
      "Loss:  0.06458433717489243\n",
      "47 **********\n",
      "Epoch:  2493.1159148216248  fold:  8  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.8095479011535645\n",
      "Eval Loss:  1.0665488243103027\n",
      "Eval Loss:  0.12136175483465195\n",
      "[[1613  460]\n",
      " [ 297  704]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81      2073\n",
      "           1       0.60      0.70      0.65      1001\n",
      "\n",
      "    accuracy                           0.75      3074\n",
      "   macro avg       0.72      0.74      0.73      3074\n",
      "weighted avg       0.77      0.75      0.76      3074\n",
      "\n",
      "acc:  0.7537410540013012\n",
      "pre:  0.6048109965635738\n",
      "rec:  0.7032967032967034\n",
      "ma F1:  0.7301443374526495\n",
      "mi F1:  0.7537410540013012\n",
      "we F1:  0.7579723684099153\n",
      "Eval Loss:  0.2872259020805359\n",
      "Eval Loss:  0.23726864159107208\n",
      "Eval Loss:  0.24997135996818542\n",
      "Eval Loss:  0.2667973041534424\n",
      "Eval Loss:  0.24407190084457397\n",
      "Eval Loss:  0.27101483941078186\n",
      "Eval Loss:  0.278683066368103\n",
      "Eval Loss:  0.2807226777076721\n",
      "Eval Loss:  0.2920195460319519\n",
      "Eval Loss:  0.22358104586601257\n",
      "Eval Loss:  0.20539510250091553\n",
      "Eval Loss:  0.22470396757125854\n",
      "Eval Loss:  0.24299316108226776\n",
      "Eval Loss:  0.22065693140029907\n",
      "Eval Loss:  0.21822263300418854\n",
      "Eval Loss:  0.20101363956928253\n",
      "Eval Loss:  0.2644727826118469\n",
      "Eval Loss:  0.2538866400718689\n",
      "Eval Loss:  0.2801622450351715\n",
      "Eval Loss:  0.27960553765296936\n",
      "Eval Loss:  0.15943041443824768\n",
      "Eval Loss:  0.288427472114563\n",
      "Eval Loss:  0.33555516600608826\n",
      "Eval Loss:  0.12896066904067993\n",
      "Eval Loss:  0.23217423260211945\n",
      "Eval Loss:  0.2827182710170746\n",
      "Eval Loss:  0.17236489057540894\n",
      "Eval Loss:  0.22317509353160858\n",
      "Eval Loss:  0.24060264229774475\n",
      "[[16873  1218]\n",
      " [ 1791  9935]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     18091\n",
      "           1       0.89      0.85      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8990844149310796\n",
      "pre:  0.8907917152335695\n",
      "rec:  0.847262493603957\n",
      "ma F1:  0.8933078006705402\n",
      "mi F1:  0.8990844149310796\n",
      "we F1:  0.8986073322024418\n",
      "29817 466\n",
      "Loss:  0.06907927989959717\n",
      "Loss:  0.07506585121154785\n",
      "Loss:  0.0635996088385582\n",
      "48 **********\n",
      "Epoch:  2571.080453157425  fold:  8  kers:  32\n",
      "epoch:  49\n",
      "29817 466\n",
      "Loss:  0.05762586370110512\n",
      "Loss:  0.05048797279596329\n",
      "Loss:  0.05264168232679367\n",
      "49 **********\n",
      "Epoch:  2610.6087625026703  fold:  8  kers:  32\n",
      "epoch:  50\n",
      "29817 466\n",
      "Loss:  0.08960428088903427\n",
      "Loss:  0.07772304862737656\n",
      "Loss:  0.050760746002197266\n",
      "50 **********\n",
      "Epoch:  2650.083215713501  fold:  8  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  1.0776288509368896\n",
      "Eval Loss:  1.020261287689209\n",
      "Eval Loss:  0.148758664727211\n",
      "[[1533  540]\n",
      " [ 230  771]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80      2073\n",
      "           1       0.59      0.77      0.67      1001\n",
      "\n",
      "    accuracy                           0.75      3074\n",
      "   macro avg       0.73      0.75      0.73      3074\n",
      "weighted avg       0.78      0.75      0.76      3074\n",
      "\n",
      "acc:  0.7495120364346128\n",
      "pre:  0.5881006864988558\n",
      "rec:  0.7702297702297702\n",
      "ma F1:  0.7331125451468694\n",
      "mi F1:  0.7495120364346128\n",
      "we F1:  0.7561837454886818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.27875420451164246\n",
      "Eval Loss:  0.24409113824367523\n",
      "Eval Loss:  0.22244146466255188\n",
      "Eval Loss:  0.2573786973953247\n",
      "Eval Loss:  0.24658910930156708\n",
      "Eval Loss:  0.26199087500572205\n",
      "Eval Loss:  0.2682860791683197\n",
      "Eval Loss:  0.26107776165008545\n",
      "Eval Loss:  0.280918687582016\n",
      "Eval Loss:  0.21667683124542236\n",
      "Eval Loss:  0.19496145844459534\n",
      "Eval Loss:  0.19595184922218323\n",
      "Eval Loss:  0.22573170065879822\n",
      "Eval Loss:  0.1901896893978119\n",
      "Eval Loss:  0.21891744434833527\n",
      "Eval Loss:  0.16128677129745483\n",
      "Eval Loss:  0.2851863503456116\n",
      "Eval Loss:  0.27638596296310425\n",
      "Eval Loss:  0.28448665142059326\n",
      "Eval Loss:  0.25558507442474365\n",
      "Eval Loss:  0.15883773565292358\n",
      "Eval Loss:  0.2768727242946625\n",
      "Eval Loss:  0.3318236470222473\n",
      "Eval Loss:  0.14336763322353363\n",
      "Eval Loss:  0.19496290385723114\n",
      "Eval Loss:  0.2708492577075958\n",
      "Eval Loss:  0.16276757419109344\n",
      "Eval Loss:  0.22461716830730438\n",
      "Eval Loss:  0.2237754911184311\n",
      "[[16563  1528]\n",
      " [ 1458 10268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     18091\n",
      "           1       0.87      0.88      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.89      0.90      0.90     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8998557869671664\n",
      "pre:  0.8704645642590708\n",
      "rec:  0.8756609244414122\n",
      "ma F1:  0.895183908468385\n",
      "mi F1:  0.8998557869671664\n",
      "we F1:  0.89990773795921\n",
      "29817 466\n",
      "Loss:  0.0557892881333828\n",
      "Loss:  0.10061998665332794\n",
      "Loss:  0.0823582112789154\n",
      "51 **********\n",
      "Epoch:  2727.988911628723  fold:  8  kers:  32\n",
      "epoch:  52\n",
      "29817 466\n",
      "Loss:  0.057635605335235596\n",
      "Loss:  0.06859613209962845\n",
      "Loss:  0.08887920528650284\n",
      "52 **********\n",
      "Epoch:  2767.5122344493866  fold:  8  kers:  32\n",
      "epoch:  53\n",
      "29817 466\n",
      "Loss:  0.06842783093452454\n",
      "Loss:  0.06749565899372101\n",
      "Loss:  0.04372311383485794\n",
      "53 **********\n",
      "Epoch:  2807.130303621292  fold:  8  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.6185736060142517\n",
      "Eval Loss:  1.032214641571045\n",
      "Eval Loss:  0.10306698828935623\n",
      "[[1850  223]\n",
      " [ 368  633]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      2073\n",
      "           1       0.74      0.63      0.68      1001\n",
      "\n",
      "    accuracy                           0.81      3074\n",
      "   macro avg       0.79      0.76      0.77      3074\n",
      "weighted avg       0.80      0.81      0.80      3074\n",
      "\n",
      "acc:  0.8077423552374756\n",
      "pre:  0.7394859813084113\n",
      "rec:  0.6323676323676324\n",
      "ma F1:  0.772007308379977\n",
      "mi F1:  0.8077423552374756\n",
      "we F1:  0.8034846873703126\n",
      "update!  Acc:  0.8077423552374756\n",
      "Eval Loss:  0.29663655161857605\n",
      "Eval Loss:  0.23483239114284515\n",
      "Eval Loss:  0.22377988696098328\n",
      "Eval Loss:  0.2736215591430664\n",
      "Eval Loss:  0.26212576031684875\n",
      "Eval Loss:  0.2616026997566223\n",
      "Eval Loss:  0.31880879402160645\n",
      "Eval Loss:  0.2801055610179901\n",
      "Eval Loss:  0.2949402630329132\n",
      "Eval Loss:  0.20841118693351746\n",
      "Eval Loss:  0.20897899568080902\n",
      "Eval Loss:  0.228361114859581\n",
      "Eval Loss:  0.24815250933170319\n",
      "Eval Loss:  0.22012664377689362\n",
      "Eval Loss:  0.22304667532444\n",
      "Eval Loss:  0.22873488068580627\n",
      "Eval Loss:  0.28172022104263306\n",
      "Eval Loss:  0.24533763527870178\n",
      "Eval Loss:  0.2734675705432892\n",
      "Eval Loss:  0.26573002338409424\n",
      "Eval Loss:  0.17218606173992157\n",
      "Eval Loss:  0.2965632379055023\n",
      "Eval Loss:  0.3199029266834259\n",
      "Eval Loss:  0.1540384143590927\n",
      "Eval Loss:  0.2380068600177765\n",
      "Eval Loss:  0.2498074471950531\n",
      "Eval Loss:  0.17092952132225037\n",
      "Eval Loss:  0.21006298065185547\n",
      "Eval Loss:  0.24077947437763214\n",
      "[[17328   763]\n",
      " [ 2236  9490]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18091\n",
      "           1       0.93      0.81      0.86     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.91      0.88      0.89     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.8994197940772043\n",
      "pre:  0.9255827562664586\n",
      "rec:  0.8093126385809313\n",
      "ma F1:  0.8919537171951578\n",
      "mi F1:  0.8994197940772043\n",
      "we F1:  0.8980166898098844\n",
      "29817 466\n",
      "Loss:  0.05808112025260925\n",
      "Loss:  0.06383860856294632\n",
      "Loss:  0.07353819906711578\n",
      "54 **********\n",
      "Epoch:  2884.8494987487793  fold:  8  kers:  32\n",
      "epoch:  55\n",
      "29817 466\n",
      "Loss:  0.06376836448907852\n",
      "Loss:  0.0871841311454773\n",
      "Loss:  0.05446279048919678\n",
      "55 **********\n",
      "Epoch:  2924.1763463020325  fold:  8  kers:  32\n",
      "epoch:  56\n",
      "29817 466\n",
      "Loss:  0.04545142874121666\n",
      "Loss:  0.04054773971438408\n",
      "Loss:  0.0355217382311821\n",
      "56 **********\n",
      "Epoch:  2963.603925228119  fold:  8  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.8310734033584595\n",
      "Eval Loss:  1.0523391962051392\n",
      "Eval Loss:  0.10508284717798233\n",
      "[[1672  401]\n",
      " [ 329  672]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      2073\n",
      "           1       0.63      0.67      0.65      1001\n",
      "\n",
      "    accuracy                           0.76      3074\n",
      "   macro avg       0.73      0.74      0.73      3074\n",
      "weighted avg       0.77      0.76      0.76      3074\n",
      "\n",
      "acc:  0.7625243981782693\n",
      "pre:  0.6262814538676608\n",
      "rec:  0.6713286713286714\n",
      "ma F1:  0.7344190337957052\n",
      "mi F1:  0.7625243981782693\n",
      "we F1:  0.7645479844138139\n",
      "Eval Loss:  0.2938590347766876\n",
      "Eval Loss:  0.23869630694389343\n",
      "Eval Loss:  0.2374926060438156\n",
      "Eval Loss:  0.25470420718193054\n",
      "Eval Loss:  0.2418769747018814\n",
      "Eval Loss:  0.26032280921936035\n",
      "Eval Loss:  0.3075478971004486\n",
      "Eval Loss:  0.2732018530368805\n",
      "Eval Loss:  0.28856581449508667\n",
      "Eval Loss:  0.21566849946975708\n",
      "Eval Loss:  0.20717152953147888\n",
      "Eval Loss:  0.20525072515010834\n",
      "Eval Loss:  0.21825918555259705\n",
      "Eval Loss:  0.21916747093200684\n",
      "Eval Loss:  0.22283333539962769\n",
      "Eval Loss:  0.20954544842243195\n",
      "Eval Loss:  0.27508819103240967\n",
      "Eval Loss:  0.24958330392837524\n",
      "Eval Loss:  0.2501175105571747\n",
      "Eval Loss:  0.26198452711105347\n",
      "Eval Loss:  0.1668914258480072\n",
      "Eval Loss:  0.279804527759552\n",
      "Eval Loss:  0.3131815195083618\n",
      "Eval Loss:  0.1397784948348999\n",
      "Eval Loss:  0.23227465152740479\n",
      "Eval Loss:  0.2758026421070099\n",
      "Eval Loss:  0.16349008679389954\n",
      "Eval Loss:  0.20154841244220734\n",
      "Eval Loss:  0.24262279272079468\n",
      "[[17110   981]\n",
      " [ 1945  9781]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18091\n",
      "           1       0.91      0.83      0.87     11726\n",
      "\n",
      "    accuracy                           0.90     29817\n",
      "   macro avg       0.90      0.89      0.90     29817\n",
      "weighted avg       0.90      0.90      0.90     29817\n",
      "\n",
      "acc:  0.9018680618439145\n",
      "pre:  0.9088459394164653\n",
      "rec:  0.8341292853487975\n",
      "ma F1:  0.8955579518035527\n",
      "mi F1:  0.9018680618439145\n",
      "we F1:  0.9010380787522364\n",
      "29817 466\n",
      "Loss:  0.08552880585193634\n",
      "Loss:  0.0862436592578888\n",
      "Loss:  0.05714370310306549\n",
      "57 **********\n",
      "Epoch:  3041.355034828186  fold:  8  kers:  32\n",
      "epoch:  58\n",
      "29817 466\n",
      "Loss:  0.046359919011592865\n",
      "Loss:  0.07990401238203049\n",
      "Loss:  0.05400059372186661\n",
      "58 **********\n",
      "Epoch:  3080.8245010375977  fold:  8  kers:  32\n",
      "epoch:  59\n",
      "29817 466\n",
      "Loss:  0.06138454005122185\n",
      "Loss:  0.03889084234833717\n",
      "Loss:  0.04551699757575989\n",
      "59 **********\n",
      "Epoch:  3120.2141811847687  fold:  8  kers:  32\n",
      "Eval Loss:  0.7296358346939087\n",
      "Eval Loss:  1.0000532865524292\n",
      "Eval Loss:  0.10996855050325394\n",
      "[[1731  342]\n",
      " [ 315  686]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84      2073\n",
      "           1       0.67      0.69      0.68      1001\n",
      "\n",
      "    accuracy                           0.79      3074\n",
      "   macro avg       0.76      0.76      0.76      3074\n",
      "weighted avg       0.79      0.79      0.79      3074\n",
      "\n",
      "acc:  0.7862719583604424\n",
      "pre:  0.6673151750972762\n",
      "rec:  0.6853146853146853\n",
      "ma F1:  0.7583452179378617\n",
      "mi F1:  0.7862719583604425\n",
      "we F1:  0.7869935105053322\n",
      "update!  Acc:  0.8077423552374756\n",
      "Epoch:  3123.8005933761597  fold:  8  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29483 3408\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29483 461\n",
      "Loss:  0.1729867309331894\n",
      "Loss:  0.16749541461467743\n",
      "Loss:  0.152712881565094\n",
      "0 **********\n",
      "Epoch:  51.83141279220581  fold:  9  kers:  32\n",
      "epoch:  1\n",
      "29483 461\n",
      "Loss:  0.13898399472236633\n",
      "Loss:  0.13864967226982117\n",
      "Loss:  0.12876984477043152\n",
      "1 **********\n",
      "Epoch:  91.17721009254456  fold:  9  kers:  32\n",
      "epoch:  2\n",
      "29483 461\n",
      "Loss:  0.1040862649679184\n",
      "Loss:  0.10925779491662979\n",
      "Loss:  0.15262502431869507\n",
      "2 **********\n",
      "Epoch:  130.40033531188965  fold:  9  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.21747927367687225\n",
      "Eval Loss:  1.0295259952545166\n",
      "Eval Loss:  0.3924970030784607\n",
      "[[1516  226]\n",
      " [ 434 1232]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      1742\n",
      "           1       0.84      0.74      0.79      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.81      0.80      0.80      3408\n",
      "weighted avg       0.81      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8063380281690141\n",
      "pre:  0.8449931412894376\n",
      "rec:  0.7394957983193278\n",
      "ma F1:  0.8049837486457205\n",
      "mi F1:  0.8063380281690141\n",
      "we F1:  0.8053461614758977\n",
      "update!  Acc:  0.8063380281690141\n",
      "Eval Loss:  0.4107283055782318\n",
      "Eval Loss:  0.5163931250572205\n",
      "Eval Loss:  0.533494234085083\n",
      "Eval Loss:  0.5847333669662476\n",
      "Eval Loss:  0.4216626286506653\n",
      "Eval Loss:  0.49284982681274414\n",
      "Eval Loss:  0.4162426292896271\n",
      "Eval Loss:  0.4841546416282654\n",
      "Eval Loss:  0.39361852407455444\n",
      "Eval Loss:  0.30800265073776245\n",
      "Eval Loss:  0.4308500587940216\n",
      "Eval Loss:  0.3972538411617279\n",
      "Eval Loss:  0.47249770164489746\n",
      "Eval Loss:  0.5028272867202759\n",
      "Eval Loss:  0.4212057888507843\n",
      "Eval Loss:  0.4947953522205353\n",
      "Eval Loss:  0.4670093357563019\n",
      "Eval Loss:  0.3973435163497925\n",
      "Eval Loss:  0.4189720153808594\n",
      "Eval Loss:  0.49465328454971313\n",
      "Eval Loss:  0.4910372197628021\n",
      "Eval Loss:  0.44104698300361633\n",
      "Eval Loss:  0.4874722957611084\n",
      "Eval Loss:  0.42901521921157837\n",
      "Eval Loss:  0.3760876953601837\n",
      "Eval Loss:  0.5238037705421448\n",
      "Eval Loss:  0.4782998263835907\n",
      "Eval Loss:  0.537493884563446\n",
      "[[15897  2525]\n",
      " [ 3519  7542]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84     18422\n",
      "           1       0.75      0.68      0.71     11061\n",
      "\n",
      "    accuracy                           0.80     29483\n",
      "   macro avg       0.78      0.77      0.78     29483\n",
      "weighted avg       0.79      0.80      0.79     29483\n",
      "\n",
      "acc:  0.7950005087677645\n",
      "pre:  0.749180490712228\n",
      "rec:  0.6818551668022783\n",
      "ma F1:  0.7771002573617466\n",
      "mi F1:  0.7950005087677645\n",
      "we F1:  0.7928709037530928\n",
      "29483 461\n",
      "Loss:  0.1260799616575241\n",
      "Loss:  0.11251041293144226\n",
      "Loss:  0.08915414661169052\n",
      "3 **********\n",
      "Epoch:  208.33595180511475  fold:  9  kers:  32\n",
      "epoch:  4\n",
      "29483 461\n",
      "Loss:  0.1005130335688591\n",
      "Loss:  0.13139745593070984\n",
      "Loss:  0.11509391665458679\n",
      "4 **********\n",
      "Epoch:  247.6189169883728  fold:  9  kers:  32\n",
      "epoch:  5\n",
      "29483 461\n",
      "Loss:  0.09785249829292297\n",
      "Loss:  0.12037237733602524\n",
      "Loss:  0.07368896156549454\n",
      "5 **********\n",
      "Epoch:  286.9766821861267  fold:  9  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.0883895680308342\n",
      "Eval Loss:  1.8800138235092163\n",
      "Eval Loss:  0.3474487364292145\n",
      "[[1677   65]\n",
      " [ 643 1023]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.83      1742\n",
      "           1       0.94      0.61      0.74      1666\n",
      "\n",
      "    accuracy                           0.79      3408\n",
      "   macro avg       0.83      0.79      0.78      3408\n",
      "weighted avg       0.83      0.79      0.79      3408\n",
      "\n",
      "acc:  0.7922535211267606\n",
      "pre:  0.9402573529411765\n",
      "rec:  0.614045618247299\n",
      "ma F1:  0.7843105073967878\n",
      "mi F1:  0.7922535211267606\n",
      "we F1:  0.7852335487476715\n",
      "Eval Loss:  0.3445257544517517\n",
      "Eval Loss:  0.4832296371459961\n",
      "Eval Loss:  0.5350189805030823\n",
      "Eval Loss:  0.5699651837348938\n",
      "Eval Loss:  0.4436546862125397\n",
      "Eval Loss:  0.5120682120323181\n",
      "Eval Loss:  0.42286258935928345\n",
      "Eval Loss:  0.5047634840011597\n",
      "Eval Loss:  0.33950963616371155\n",
      "Eval Loss:  0.31078916788101196\n",
      "Eval Loss:  0.45879247784614563\n",
      "Eval Loss:  0.3319131135940552\n",
      "Eval Loss:  0.40457451343536377\n",
      "Eval Loss:  0.4961515963077545\n",
      "Eval Loss:  0.45556339621543884\n",
      "Eval Loss:  0.5008728504180908\n",
      "Eval Loss:  0.4298084080219269\n",
      "Eval Loss:  0.3862608075141907\n",
      "Eval Loss:  0.3741169273853302\n",
      "Eval Loss:  0.48730677366256714\n",
      "Eval Loss:  0.48893314599990845\n",
      "Eval Loss:  0.5407920479774475\n",
      "Eval Loss:  0.46812567114830017\n",
      "Eval Loss:  0.4048215448856354\n",
      "Eval Loss:  0.41516533493995667\n",
      "Eval Loss:  0.4793570041656494\n",
      "Eval Loss:  0.4261220693588257\n",
      "Eval Loss:  0.5746819972991943\n",
      "[[17714   708]\n",
      " [ 4551  6510]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87     18422\n",
      "           1       0.90      0.59      0.71     11061\n",
      "\n",
      "    accuracy                           0.82     29483\n",
      "   macro avg       0.85      0.78      0.79     29483\n",
      "weighted avg       0.84      0.82      0.81     29483\n",
      "\n",
      "acc:  0.8216260217752603\n",
      "pre:  0.9019118869492935\n",
      "rec:  0.5885543802549498\n",
      "ma F1:  0.7915188752009124\n",
      "mi F1:  0.8216260217752603\n",
      "we F1:  0.8112991952592644\n",
      "29483 461\n",
      "Loss:  0.10727386921644211\n",
      "Loss:  0.0928395539522171\n",
      "Loss:  0.07393740117549896\n",
      "6 **********\n",
      "Epoch:  364.92725801467896  fold:  9  kers:  32\n",
      "epoch:  7\n",
      "29483 461\n",
      "Loss:  0.07894175499677658\n",
      "Loss:  0.09675851464271545\n",
      "Loss:  0.07429257035255432\n",
      "7 **********\n",
      "Epoch:  404.2152101993561  fold:  9  kers:  32\n",
      "epoch:  8\n",
      "29483 461\n",
      "Loss:  0.11593230068683624\n",
      "Loss:  0.052363041788339615\n",
      "Loss:  0.07922691851854324\n",
      "8 **********\n",
      "Epoch:  443.4642663002014  fold:  9  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.06987936049699783\n",
      "Eval Loss:  1.4972034692764282\n",
      "Eval Loss:  0.22100865840911865\n",
      "[[1620  122]\n",
      " [ 478 1188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84      1742\n",
      "           1       0.91      0.71      0.80      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.84      0.82      0.82      3408\n",
      "weighted avg       0.84      0.82      0.82      3408\n",
      "\n",
      "acc:  0.823943661971831\n",
      "pre:  0.9068702290076336\n",
      "rec:  0.7130852340936374\n",
      "ma F1:  0.8210685483870968\n",
      "mi F1:  0.823943661971831\n",
      "we F1:  0.8215743554066331\n",
      "update!  Acc:  0.823943661971831\n",
      "Eval Loss:  0.3000994622707367\n",
      "Eval Loss:  0.33142444491386414\n",
      "Eval Loss:  0.3747645616531372\n",
      "Eval Loss:  0.39514824748039246\n",
      "Eval Loss:  0.3412766456604004\n",
      "Eval Loss:  0.41522151231765747\n",
      "Eval Loss:  0.31113675236701965\n",
      "Eval Loss:  0.35852521657943726\n",
      "Eval Loss:  0.32457229495048523\n",
      "Eval Loss:  0.2488473802804947\n",
      "Eval Loss:  0.31072553992271423\n",
      "Eval Loss:  0.31796130537986755\n",
      "Eval Loss:  0.27655839920043945\n",
      "Eval Loss:  0.33690518140792847\n",
      "Eval Loss:  0.3083786368370056\n",
      "Eval Loss:  0.35498008131980896\n",
      "Eval Loss:  0.29074832797050476\n",
      "Eval Loss:  0.3202460706233978\n",
      "Eval Loss:  0.2980806231498718\n",
      "Eval Loss:  0.32293862104415894\n",
      "Eval Loss:  0.3345004618167877\n",
      "Eval Loss:  0.39607954025268555\n",
      "Eval Loss:  0.3443850874900818\n",
      "Eval Loss:  0.25055956840515137\n",
      "Eval Loss:  0.3189117908477783\n",
      "Eval Loss:  0.2860054075717926\n",
      "Eval Loss:  0.26892784237861633\n",
      "Eval Loss:  0.35483360290527344\n",
      "[[17027  1395]\n",
      " [ 2554  8507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90     18422\n",
      "           1       0.86      0.77      0.81     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.86      0.85      0.85     29483\n",
      "weighted avg       0.87      0.87      0.86     29483\n",
      "\n",
      "acc:  0.8660584065393616\n",
      "pre:  0.859119369824278\n",
      "rec:  0.7690986348431426\n",
      "ma F1:  0.8538538125915835\n",
      "mi F1:  0.8660584065393616\n",
      "we F1:  0.8643981806725218\n",
      "29483 461\n",
      "Loss:  0.09380190819501877\n",
      "Loss:  0.11150607466697693\n",
      "Loss:  0.07941858470439911\n",
      "9 **********\n",
      "Epoch:  521.4786713123322  fold:  9  kers:  32\n",
      "epoch:  10\n",
      "29483 461\n",
      "Loss:  0.12555354833602905\n",
      "Loss:  0.07870082557201385\n",
      "Loss:  0.06778804957866669\n",
      "10 **********\n",
      "Epoch:  560.7845754623413  fold:  9  kers:  32\n",
      "epoch:  11\n",
      "29483 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06927871704101562\n",
      "Loss:  0.08269970864057541\n",
      "Loss:  0.08753316104412079\n",
      "11 **********\n",
      "Epoch:  600.0615568161011  fold:  9  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.05644943192601204\n",
      "Eval Loss:  1.6699005365371704\n",
      "Eval Loss:  0.2636141777038574\n",
      "[[1663   79]\n",
      " [ 555 1111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84      1742\n",
      "           1       0.93      0.67      0.78      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.81      0.81      3408\n",
      "weighted avg       0.84      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8139671361502347\n",
      "pre:  0.9336134453781513\n",
      "rec:  0.6668667466986795\n",
      "ma F1:  0.8089550971903914\n",
      "mi F1:  0.8139671361502347\n",
      "we F1:  0.8096451605254423\n",
      "Eval Loss:  0.27662840485572815\n",
      "Eval Loss:  0.3749701678752899\n",
      "Eval Loss:  0.3847482204437256\n",
      "Eval Loss:  0.41926413774490356\n",
      "Eval Loss:  0.373776912689209\n",
      "Eval Loss:  0.420382559299469\n",
      "Eval Loss:  0.32945406436920166\n",
      "Eval Loss:  0.3891182243824005\n",
      "Eval Loss:  0.3096202611923218\n",
      "Eval Loss:  0.2555418908596039\n",
      "Eval Loss:  0.3400263488292694\n",
      "Eval Loss:  0.3014240264892578\n",
      "Eval Loss:  0.2844027280807495\n",
      "Eval Loss:  0.3593905568122864\n",
      "Eval Loss:  0.3238074481487274\n",
      "Eval Loss:  0.3774683177471161\n",
      "Eval Loss:  0.30747538805007935\n",
      "Eval Loss:  0.2977202534675598\n",
      "Eval Loss:  0.2865596115589142\n",
      "Eval Loss:  0.3378989100456238\n",
      "Eval Loss:  0.3651643693447113\n",
      "Eval Loss:  0.45130693912506104\n",
      "Eval Loss:  0.3636127710342407\n",
      "Eval Loss:  0.26144132018089294\n",
      "Eval Loss:  0.3426019251346588\n",
      "Eval Loss:  0.32842665910720825\n",
      "Eval Loss:  0.2949647307395935\n",
      "Eval Loss:  0.43150967359542847\n",
      "[[17574   848]\n",
      " [ 3249  7812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.90     18422\n",
      "           1       0.90      0.71      0.79     11061\n",
      "\n",
      "    accuracy                           0.86     29483\n",
      "   macro avg       0.87      0.83      0.84     29483\n",
      "weighted avg       0.87      0.86      0.86     29483\n",
      "\n",
      "acc:  0.8610385645965472\n",
      "pre:  0.9020785219399539\n",
      "rec:  0.7062652563059398\n",
      "ma F1:  0.8439282249063828\n",
      "mi F1:  0.8610385645965472\n",
      "we F1:  0.8568302132754976\n",
      "29483 461\n",
      "Loss:  0.09152696281671524\n",
      "Loss:  0.1391337811946869\n",
      "Loss:  0.08240491896867752\n",
      "12 **********\n",
      "Epoch:  677.8116688728333  fold:  9  kers:  32\n",
      "epoch:  13\n",
      "29483 461\n",
      "Loss:  0.08106876909732819\n",
      "Loss:  0.0732123926281929\n",
      "Loss:  0.0812687873840332\n",
      "13 **********\n",
      "Epoch:  716.9230926036835  fold:  9  kers:  32\n",
      "epoch:  14\n",
      "29483 461\n",
      "Loss:  0.05844677612185478\n",
      "Loss:  0.10860556364059448\n",
      "Loss:  0.07601173222064972\n",
      "14 **********\n",
      "Epoch:  755.9906339645386  fold:  9  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.04357471317052841\n",
      "Eval Loss:  1.9170606136322021\n",
      "Eval Loss:  0.27821430563926697\n",
      "[[1679   63]\n",
      " [ 617 1049]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83      1742\n",
      "           1       0.94      0.63      0.76      1666\n",
      "\n",
      "    accuracy                           0.80      3408\n",
      "   macro avg       0.84      0.80      0.79      3408\n",
      "weighted avg       0.83      0.80      0.79      3408\n",
      "\n",
      "acc:  0.8004694835680751\n",
      "pre:  0.9433453237410072\n",
      "rec:  0.6296518607442977\n",
      "ma F1:  0.7934096921577626\n",
      "mi F1:  0.8004694835680752\n",
      "we F1:  0.7942613495342448\n",
      "Eval Loss:  0.2607067823410034\n",
      "Eval Loss:  0.38750600814819336\n",
      "Eval Loss:  0.4217040538787842\n",
      "Eval Loss:  0.4245508015155792\n",
      "Eval Loss:  0.3854149580001831\n",
      "Eval Loss:  0.41392529010772705\n",
      "Eval Loss:  0.3338470757007599\n",
      "Eval Loss:  0.38597404956817627\n",
      "Eval Loss:  0.3062937557697296\n",
      "Eval Loss:  0.25556352734565735\n",
      "Eval Loss:  0.3471311330795288\n",
      "Eval Loss:  0.3166877031326294\n",
      "Eval Loss:  0.2791875898838043\n",
      "Eval Loss:  0.3730529248714447\n",
      "Eval Loss:  0.32620304822921753\n",
      "Eval Loss:  0.39160647988319397\n",
      "Eval Loss:  0.3124202489852905\n",
      "Eval Loss:  0.2933822572231293\n",
      "Eval Loss:  0.29132726788520813\n",
      "Eval Loss:  0.3558489978313446\n",
      "Eval Loss:  0.3843293786048889\n",
      "Eval Loss:  0.4685026705265045\n",
      "Eval Loss:  0.3608676493167877\n",
      "Eval Loss:  0.26941797137260437\n",
      "Eval Loss:  0.34094005823135376\n",
      "Eval Loss:  0.3659634590148926\n",
      "Eval Loss:  0.300127774477005\n",
      "Eval Loss:  0.4422747492790222\n",
      "[[17808   614]\n",
      " [ 3521  7540]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     18422\n",
      "           1       0.92      0.68      0.78     11061\n",
      "\n",
      "    accuracy                           0.86     29483\n",
      "   macro avg       0.88      0.82      0.84     29483\n",
      "weighted avg       0.87      0.86      0.85     29483\n",
      "\n",
      "acc:  0.8597496862598786\n",
      "pre:  0.9246995339710572\n",
      "rec:  0.6816743513244734\n",
      "ma F1:  0.8403904992942242\n",
      "mi F1:  0.8597496862598786\n",
      "we F1:  0.854268856837483\n",
      "29483 461\n",
      "Loss:  0.07177430391311646\n",
      "Loss:  0.09476957470178604\n",
      "Loss:  0.06771331280469894\n",
      "15 **********\n",
      "Epoch:  833.7706665992737  fold:  9  kers:  32\n",
      "epoch:  16\n",
      "29483 461\n",
      "Loss:  0.048378970474004745\n",
      "Loss:  0.07531373202800751\n",
      "Loss:  0.08171950280666351\n",
      "16 **********\n",
      "Epoch:  872.8731141090393  fold:  9  kers:  32\n",
      "epoch:  17\n",
      "29483 461\n",
      "Loss:  0.08754277229309082\n",
      "Loss:  0.07832632958889008\n",
      "Loss:  0.05989864841103554\n",
      "17 **********\n",
      "Epoch:  911.9576098918915  fold:  9  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.050300441682338715\n",
      "Eval Loss:  1.6375091075897217\n",
      "Eval Loss:  0.21821554005146027\n",
      "[[1649   93]\n",
      " [ 517 1149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84      1742\n",
      "           1       0.93      0.69      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.84      0.82      0.82      3408\n",
      "weighted avg       0.84      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8210093896713615\n",
      "pre:  0.9251207729468599\n",
      "rec:  0.6896758703481393\n",
      "ma F1:  0.8170718830206158\n",
      "mi F1:  0.8210093896713615\n",
      "we F1:  0.8176703840315293\n",
      "Eval Loss:  0.25687694549560547\n",
      "Eval Loss:  0.3170868158340454\n",
      "Eval Loss:  0.33333462476730347\n",
      "Eval Loss:  0.35193318128585815\n",
      "Eval Loss:  0.33493921160697937\n",
      "Eval Loss:  0.3525548577308655\n",
      "Eval Loss:  0.28504490852355957\n",
      "Eval Loss:  0.34181496500968933\n",
      "Eval Loss:  0.2794671654701233\n",
      "Eval Loss:  0.2233622521162033\n",
      "Eval Loss:  0.2808467149734497\n",
      "Eval Loss:  0.29419180750846863\n",
      "Eval Loss:  0.24249568581581116\n",
      "Eval Loss:  0.30890554189682007\n",
      "Eval Loss:  0.2771957218647003\n",
      "Eval Loss:  0.3310205936431885\n",
      "Eval Loss:  0.2560933828353882\n",
      "Eval Loss:  0.2833877205848694\n",
      "Eval Loss:  0.2695203721523285\n",
      "Eval Loss:  0.2940250635147095\n",
      "Eval Loss:  0.3141758441925049\n",
      "Eval Loss:  0.380742609500885\n",
      "Eval Loss:  0.29282277822494507\n",
      "Eval Loss:  0.20861715078353882\n",
      "Eval Loss:  0.3096335828304291\n",
      "Eval Loss:  0.27623122930526733\n",
      "Eval Loss:  0.2572469711303711\n",
      "Eval Loss:  0.33123496174812317\n",
      "[[17487   935]\n",
      " [ 2648  8413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18422\n",
      "           1       0.90      0.76      0.82     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.88      0.85      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.878472339992538\n",
      "pre:  0.8999786050492083\n",
      "rec:  0.7606003073863122\n",
      "ma F1:  0.8657564218226363\n",
      "mi F1:  0.8784723399925379\n",
      "we F1:  0.8760718145544686\n",
      "29483 461\n",
      "Loss:  0.08731462806463242\n",
      "Loss:  0.08698800951242447\n",
      "Loss:  0.07757780700922012\n",
      "18 **********\n",
      "Epoch:  989.5651035308838  fold:  9  kers:  32\n",
      "epoch:  19\n",
      "29483 461\n",
      "Loss:  0.08278846740722656\n",
      "Loss:  0.08526556193828583\n",
      "Loss:  0.07589730620384216\n",
      "19 **********\n",
      "Epoch:  1028.7084422111511  fold:  9  kers:  32\n",
      "epoch:  20\n",
      "29483 461\n",
      "Loss:  0.08227710425853729\n",
      "Loss:  0.0734737366437912\n",
      "Loss:  0.1042468249797821\n",
      "20 **********\n",
      "Epoch:  1067.8238554000854  fold:  9  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.0519607812166214\n",
      "Eval Loss:  1.6991592645645142\n",
      "Eval Loss:  0.19358664751052856\n",
      "[[1659   83]\n",
      " [ 532 1134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84      1742\n",
      "           1       0.93      0.68      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.84      0.82      0.82      3408\n",
      "weighted avg       0.84      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8195422535211268\n",
      "pre:  0.9317995069843878\n",
      "rec:  0.680672268907563\n",
      "ma F1:  0.8151556786369398\n",
      "mi F1:  0.8195422535211268\n",
      "we F1:  0.8157906875725556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2590915262699127\n",
      "Eval Loss:  0.3086788058280945\n",
      "Eval Loss:  0.3205941617488861\n",
      "Eval Loss:  0.3514724373817444\n",
      "Eval Loss:  0.32262682914733887\n",
      "Eval Loss:  0.3285233676433563\n",
      "Eval Loss:  0.27271613478660583\n",
      "Eval Loss:  0.3288836181163788\n",
      "Eval Loss:  0.2714002728462219\n",
      "Eval Loss:  0.2160329967737198\n",
      "Eval Loss:  0.27149954438209534\n",
      "Eval Loss:  0.30032333731651306\n",
      "Eval Loss:  0.24204140901565552\n",
      "Eval Loss:  0.3086027204990387\n",
      "Eval Loss:  0.2777440845966339\n",
      "Eval Loss:  0.32133936882019043\n",
      "Eval Loss:  0.2613300681114197\n",
      "Eval Loss:  0.26948681473731995\n",
      "Eval Loss:  0.2579856812953949\n",
      "Eval Loss:  0.2918562889099121\n",
      "Eval Loss:  0.32176992297172546\n",
      "Eval Loss:  0.36661583185195923\n",
      "Eval Loss:  0.2771390974521637\n",
      "Eval Loss:  0.1900300830602646\n",
      "Eval Loss:  0.2963205575942993\n",
      "Eval Loss:  0.2636232376098633\n",
      "Eval Loss:  0.26657912135124207\n",
      "Eval Loss:  0.31989341974258423\n",
      "[[17506   916]\n",
      " [ 2624  8437]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18422\n",
      "           1       0.90      0.76      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.89      0.86      0.87     29483\n",
      "weighted avg       0.88      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8799308075840315\n",
      "pre:  0.9020635090345344\n",
      "rec:  0.762770093119971\n",
      "ma F1:  0.8673827827470022\n",
      "mi F1:  0.8799308075840315\n",
      "we F1:  0.877567589321638\n",
      "29483 461\n",
      "Loss:  0.10142526030540466\n",
      "Loss:  0.10037413984537125\n",
      "Loss:  0.07403590530157089\n",
      "21 **********\n",
      "Epoch:  1145.391455411911  fold:  9  kers:  32\n",
      "epoch:  22\n",
      "29483 461\n",
      "Loss:  0.08570462465286255\n",
      "Loss:  0.0766458660364151\n",
      "Loss:  0.07028356939554214\n",
      "22 **********\n",
      "Epoch:  1184.4729595184326  fold:  9  kers:  32\n",
      "epoch:  23\n",
      "29483 461\n",
      "Loss:  0.07316482812166214\n",
      "Loss:  0.0985414907336235\n",
      "Loss:  0.04029786214232445\n",
      "23 **********\n",
      "Epoch:  1223.6262714862823  fold:  9  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.035650819540023804\n",
      "Eval Loss:  1.903804063796997\n",
      "Eval Loss:  0.22246937453746796\n",
      "[[1692   50]\n",
      " [ 639 1027]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83      1742\n",
      "           1       0.95      0.62      0.75      1666\n",
      "\n",
      "    accuracy                           0.80      3408\n",
      "   macro avg       0.84      0.79      0.79      3408\n",
      "weighted avg       0.84      0.80      0.79      3408\n",
      "\n",
      "acc:  0.7978286384976526\n",
      "pre:  0.9535747446610956\n",
      "rec:  0.6164465786314526\n",
      "ma F1:  0.789826193299302\n",
      "mi F1:  0.7978286384976526\n",
      "we F1:  0.7907407584648277\n",
      "Eval Loss:  0.27132293581962585\n",
      "Eval Loss:  0.33969831466674805\n",
      "Eval Loss:  0.34228676557540894\n",
      "Eval Loss:  0.347747802734375\n",
      "Eval Loss:  0.352377325296402\n",
      "Eval Loss:  0.35461002588272095\n",
      "Eval Loss:  0.3064821660518646\n",
      "Eval Loss:  0.3362617790699005\n",
      "Eval Loss:  0.26947295665740967\n",
      "Eval Loss:  0.2165897637605667\n",
      "Eval Loss:  0.27676090598106384\n",
      "Eval Loss:  0.29715394973754883\n",
      "Eval Loss:  0.24363258481025696\n",
      "Eval Loss:  0.3209518790245056\n",
      "Eval Loss:  0.27901142835617065\n",
      "Eval Loss:  0.3721679449081421\n",
      "Eval Loss:  0.27213254570961\n",
      "Eval Loss:  0.2693021297454834\n",
      "Eval Loss:  0.24856823682785034\n",
      "Eval Loss:  0.3086473047733307\n",
      "Eval Loss:  0.3550362288951874\n",
      "Eval Loss:  0.4057365953922272\n",
      "Eval Loss:  0.28803110122680664\n",
      "Eval Loss:  0.22009114921092987\n",
      "Eval Loss:  0.3018244206905365\n",
      "Eval Loss:  0.29454275965690613\n",
      "Eval Loss:  0.27330243587493896\n",
      "Eval Loss:  0.37369269132614136\n",
      "[[17843   579]\n",
      " [ 3140  7921]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91     18422\n",
      "           1       0.93      0.72      0.81     11061\n",
      "\n",
      "    accuracy                           0.87     29483\n",
      "   macro avg       0.89      0.84      0.86     29483\n",
      "weighted avg       0.88      0.87      0.87     29483\n",
      "\n",
      "acc:  0.8738595122613031\n",
      "pre:  0.9318823529411765\n",
      "rec:  0.7161196998463069\n",
      "ma F1:  0.8577489548683308\n",
      "mi F1:  0.8738595122613031\n",
      "we F1:  0.8697011633917807\n",
      "29483 461\n",
      "Loss:  0.04074432700872421\n",
      "Loss:  0.0859021469950676\n",
      "Loss:  0.06463179737329483\n",
      "24 **********\n",
      "Epoch:  1301.3424739837646  fold:  9  kers:  32\n",
      "epoch:  25\n",
      "29483 461\n",
      "Loss:  0.06283024698495865\n",
      "Loss:  0.0660984143614769\n",
      "Loss:  0.12132548540830612\n",
      "25 **********\n",
      "Epoch:  1340.4509060382843  fold:  9  kers:  32\n",
      "epoch:  26\n",
      "29483 461\n",
      "Loss:  0.06945878267288208\n",
      "Loss:  0.1140662357211113\n",
      "Loss:  0.06231633573770523\n",
      "26 **********\n",
      "Epoch:  1379.6740317344666  fold:  9  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.03137551248073578\n",
      "Eval Loss:  1.8552091121673584\n",
      "Eval Loss:  0.19512377679347992\n",
      "[[1686   56]\n",
      " [ 611 1055]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83      1742\n",
      "           1       0.95      0.63      0.76      1666\n",
      "\n",
      "    accuracy                           0.80      3408\n",
      "   macro avg       0.84      0.80      0.80      3408\n",
      "weighted avg       0.84      0.80      0.80      3408\n",
      "\n",
      "acc:  0.8042840375586855\n",
      "pre:  0.9495949594959496\n",
      "rec:  0.6332533013205283\n",
      "ma F1:  0.797336430729448\n",
      "mi F1:  0.8042840375586854\n",
      "we F1:  0.7981732264806715\n",
      "Eval Loss:  0.267151415348053\n",
      "Eval Loss:  0.31939801573753357\n",
      "Eval Loss:  0.3183973431587219\n",
      "Eval Loss:  0.322668194770813\n",
      "Eval Loss:  0.32746416330337524\n",
      "Eval Loss:  0.3266235589981079\n",
      "Eval Loss:  0.3124230206012726\n",
      "Eval Loss:  0.3154064118862152\n",
      "Eval Loss:  0.2509923577308655\n",
      "Eval Loss:  0.19980569183826447\n",
      "Eval Loss:  0.2389240562915802\n",
      "Eval Loss:  0.2838875353336334\n",
      "Eval Loss:  0.22921442985534668\n",
      "Eval Loss:  0.3007718026638031\n",
      "Eval Loss:  0.26069343090057373\n",
      "Eval Loss:  0.34056752920150757\n",
      "Eval Loss:  0.25190454721450806\n",
      "Eval Loss:  0.2648388147354126\n",
      "Eval Loss:  0.24014496803283691\n",
      "Eval Loss:  0.2957124412059784\n",
      "Eval Loss:  0.3508041799068451\n",
      "Eval Loss:  0.3802598714828491\n",
      "Eval Loss:  0.27425265312194824\n",
      "Eval Loss:  0.1945677399635315\n",
      "Eval Loss:  0.29751574993133545\n",
      "Eval Loss:  0.2681799530982971\n",
      "Eval Loss:  0.2682427167892456\n",
      "Eval Loss:  0.3329819440841675\n",
      "[[17797   625]\n",
      " [ 2853  8208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     18422\n",
      "           1       0.93      0.74      0.83     11061\n",
      "\n",
      "    accuracy                           0.88     29483\n",
      "   macro avg       0.90      0.85      0.87     29483\n",
      "weighted avg       0.89      0.88      0.88     29483\n",
      "\n",
      "acc:  0.8820337143438591\n",
      "pre:  0.9292426129287897\n",
      "rec:  0.74206672091131\n",
      "ma F1:  0.8680791338030959\n",
      "mi F1:  0.8820337143438591\n",
      "we F1:  0.8787913735945819\n",
      "29483 461\n",
      "Loss:  0.0656638890504837\n",
      "Loss:  0.06222743168473244\n",
      "Loss:  0.058630362153053284\n",
      "27 **********\n",
      "Epoch:  1457.1947567462921  fold:  9  kers:  32\n",
      "epoch:  28\n",
      "29483 461\n",
      "Loss:  0.0742742046713829\n",
      "Loss:  0.08237511664628983\n",
      "Loss:  0.08666928857564926\n",
      "28 **********\n",
      "Epoch:  1496.3889594078064  fold:  9  kers:  32\n",
      "epoch:  29\n",
      "29483 461\n",
      "Loss:  0.10384030640125275\n",
      "Loss:  0.043907590210437775\n",
      "Loss:  0.03784000128507614\n",
      "29 **********\n",
      "Epoch:  1535.571194410324  fold:  9  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.031169719994068146\n",
      "Eval Loss:  1.7228764295578003\n",
      "Eval Loss:  0.17708101868629456\n",
      "[[1672   70]\n",
      " [ 565 1101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84      1742\n",
      "           1       0.94      0.66      0.78      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.81      0.81      3408\n",
      "weighted avg       0.84      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8136737089201878\n",
      "pre:  0.9402220324508966\n",
      "rec:  0.6608643457382953\n",
      "ma F1:  0.8082920882748635\n",
      "mi F1:  0.8136737089201878\n",
      "we F1:  0.8090083810402658\n",
      "Eval Loss:  0.27620580792427063\n",
      "Eval Loss:  0.2850678861141205\n",
      "Eval Loss:  0.290438711643219\n",
      "Eval Loss:  0.2916417121887207\n",
      "Eval Loss:  0.30230969190597534\n",
      "Eval Loss:  0.3116961717605591\n",
      "Eval Loss:  0.2889913022518158\n",
      "Eval Loss:  0.3094646632671356\n",
      "Eval Loss:  0.2425016462802887\n",
      "Eval Loss:  0.17231231927871704\n",
      "Eval Loss:  0.20503997802734375\n",
      "Eval Loss:  0.26763999462127686\n",
      "Eval Loss:  0.20782355964183807\n",
      "Eval Loss:  0.26072898507118225\n",
      "Eval Loss:  0.229075625538826\n",
      "Eval Loss:  0.33927908539772034\n",
      "Eval Loss:  0.22568397223949432\n",
      "Eval Loss:  0.25521039962768555\n",
      "Eval Loss:  0.22742155194282532\n",
      "Eval Loss:  0.26671940088272095\n",
      "Eval Loss:  0.3307158946990967\n",
      "Eval Loss:  0.3595885932445526\n",
      "Eval Loss:  0.24682554602622986\n",
      "Eval Loss:  0.16638058423995972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.28656482696533203\n",
      "Eval Loss:  0.2415975034236908\n",
      "Eval Loss:  0.2552894651889801\n",
      "Eval Loss:  0.3003911077976227\n",
      "[[17601   821]\n",
      " [ 2424  8637]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18422\n",
      "           1       0.91      0.78      0.84     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.90      0.87      0.88     29483\n",
      "weighted avg       0.89      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8899365736186955\n",
      "pre:  0.9131951786847113\n",
      "rec:  0.7808516409004611\n",
      "ma F1:  0.8787259937977496\n",
      "mi F1:  0.8899365736186955\n",
      "we F1:  0.8879318257993094\n",
      "29483 461\n",
      "Loss:  0.08930827677249908\n",
      "Loss:  0.06662056595087051\n",
      "Loss:  0.044317495077848434\n",
      "30 **********\n",
      "Epoch:  1613.142783164978  fold:  9  kers:  32\n",
      "epoch:  31\n",
      "29483 461\n",
      "Loss:  0.07287780195474625\n",
      "Loss:  0.08435332030057907\n",
      "Loss:  0.07131784409284592\n",
      "31 **********\n",
      "Epoch:  1652.2282769680023  fold:  9  kers:  32\n",
      "epoch:  32\n",
      "29483 461\n",
      "Loss:  0.08514856547117233\n",
      "Loss:  0.06289753317832947\n",
      "Loss:  0.08701818436384201\n",
      "32 **********\n",
      "Epoch:  1691.3606450557709  fold:  9  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.03434718772768974\n",
      "Eval Loss:  1.445787787437439\n",
      "Eval Loss:  0.13916240632534027\n",
      "[[1642  100]\n",
      " [ 471 1195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      1742\n",
      "           1       0.92      0.72      0.81      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.83      0.83      3408\n",
      "\n",
      "acc:  0.8324530516431925\n",
      "pre:  0.9227799227799228\n",
      "rec:  0.7172869147659063\n",
      "ma F1:  0.829520208889362\n",
      "mi F1:  0.8324530516431925\n",
      "we F1:  0.8300188577692079\n",
      "update!  Acc:  0.8324530516431925\n",
      "Eval Loss:  0.30981913208961487\n",
      "Eval Loss:  0.24386465549468994\n",
      "Eval Loss:  0.2606309950351715\n",
      "Eval Loss:  0.2814803123474121\n",
      "Eval Loss:  0.2795947194099426\n",
      "Eval Loss:  0.29572170972824097\n",
      "Eval Loss:  0.2748279869556427\n",
      "Eval Loss:  0.2955019176006317\n",
      "Eval Loss:  0.24058058857917786\n",
      "Eval Loss:  0.1700626015663147\n",
      "Eval Loss:  0.17908425629138947\n",
      "Eval Loss:  0.26447123289108276\n",
      "Eval Loss:  0.2026389092206955\n",
      "Eval Loss:  0.22832636535167694\n",
      "Eval Loss:  0.21583043038845062\n",
      "Eval Loss:  0.3048804700374603\n",
      "Eval Loss:  0.21062274277210236\n",
      "Eval Loss:  0.24843963980674744\n",
      "Eval Loss:  0.21667325496673584\n",
      "Eval Loss:  0.22903312742710114\n",
      "Eval Loss:  0.3051436245441437\n",
      "Eval Loss:  0.31739264726638794\n",
      "Eval Loss:  0.23000669479370117\n",
      "Eval Loss:  0.15589407086372375\n",
      "Eval Loss:  0.28065139055252075\n",
      "Eval Loss:  0.21840760111808777\n",
      "Eval Loss:  0.2575621008872986\n",
      "Eval Loss:  0.26596349477767944\n",
      "[[17277  1145]\n",
      " [ 1924  9137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18422\n",
      "           1       0.89      0.83      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.89      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8959061153885289\n",
      "pre:  0.8886403423458471\n",
      "rec:  0.8260555103516861\n",
      "ma F1:  0.887316669683089\n",
      "mi F1:  0.8959061153885289\n",
      "we F1:  0.8950841033240894\n",
      "29483 461\n",
      "Loss:  0.07717262208461761\n",
      "Loss:  0.0636773630976677\n",
      "Loss:  0.08021146804094315\n",
      "33 **********\n",
      "Epoch:  1768.7975943088531  fold:  9  kers:  32\n",
      "epoch:  34\n",
      "29483 461\n",
      "Loss:  0.06567761301994324\n",
      "Loss:  0.052769437432289124\n",
      "Loss:  0.05802466347813606\n",
      "34 **********\n",
      "Epoch:  1807.7504425048828  fold:  9  kers:  32\n",
      "epoch:  35\n",
      "29483 461\n",
      "Loss:  0.050195787101984024\n",
      "Loss:  0.05105991289019585\n",
      "Loss:  0.041489191353321075\n",
      "35 **********\n",
      "Epoch:  1846.8748314380646  fold:  9  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.03460570052266121\n",
      "Eval Loss:  1.4528563022613525\n",
      "Eval Loss:  0.1454983353614807\n",
      "[[1642  100]\n",
      " [ 490 1176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85      1742\n",
      "           1       0.92      0.71      0.80      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.82      0.82      3408\n",
      "weighted avg       0.84      0.83      0.82      3408\n",
      "\n",
      "acc:  0.8268779342723005\n",
      "pre:  0.9216300940438872\n",
      "rec:  0.7058823529411765\n",
      "ma F1:  0.8235793926074473\n",
      "mi F1:  0.8268779342723006\n",
      "we F1:  0.8241173521922731\n",
      "Eval Loss:  0.2955748736858368\n",
      "Eval Loss:  0.24334168434143066\n",
      "Eval Loss:  0.2579119801521301\n",
      "Eval Loss:  0.2811047434806824\n",
      "Eval Loss:  0.265132337808609\n",
      "Eval Loss:  0.2903166115283966\n",
      "Eval Loss:  0.2616020739078522\n",
      "Eval Loss:  0.2736603915691376\n",
      "Eval Loss:  0.24088548123836517\n",
      "Eval Loss:  0.16204266250133514\n",
      "Eval Loss:  0.17455866932868958\n",
      "Eval Loss:  0.26682737469673157\n",
      "Eval Loss:  0.20901253819465637\n",
      "Eval Loss:  0.22784587740898132\n",
      "Eval Loss:  0.20891354978084564\n",
      "Eval Loss:  0.2851859927177429\n",
      "Eval Loss:  0.20308035612106323\n",
      "Eval Loss:  0.25828221440315247\n",
      "Eval Loss:  0.21492329239845276\n",
      "Eval Loss:  0.2438558042049408\n",
      "Eval Loss:  0.28387463092803955\n",
      "Eval Loss:  0.32472437620162964\n",
      "Eval Loss:  0.22207075357437134\n",
      "Eval Loss:  0.15048496425151825\n",
      "Eval Loss:  0.271909236907959\n",
      "Eval Loss:  0.23054346442222595\n",
      "Eval Loss:  0.23911403119564056\n",
      "Eval Loss:  0.2666761875152588\n",
      "[[17349  1073]\n",
      " [ 1898  9163]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18422\n",
      "           1       0.90      0.83      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.89      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8992300647830953\n",
      "pre:  0.8951738960531458\n",
      "rec:  0.8284061115631498\n",
      "ma F1:  0.8908127816088312\n",
      "mi F1:  0.8992300647830952\n",
      "we F1:  0.8983817556432507\n",
      "29483 461\n",
      "Loss:  0.11027661710977554\n",
      "Loss:  0.0911780372262001\n",
      "Loss:  0.04292880743741989\n",
      "36 **********\n",
      "Epoch:  1924.1751463413239  fold:  9  kers:  32\n",
      "epoch:  37\n",
      "29483 461\n",
      "Loss:  0.055219318717718124\n",
      "Loss:  0.0697568729519844\n",
      "Loss:  0.0708162784576416\n",
      "37 **********\n",
      "Epoch:  1963.2985382080078  fold:  9  kers:  32\n",
      "epoch:  38\n",
      "29483 461\n",
      "Loss:  0.055119894444942474\n",
      "Loss:  0.05227798968553543\n",
      "Loss:  0.06417492777109146\n",
      "38 **********\n",
      "Epoch:  2002.39599943161  fold:  9  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.032639533281326294\n",
      "Eval Loss:  1.4490245580673218\n",
      "Eval Loss:  0.17861993610858917\n",
      "[[1683   59]\n",
      " [ 571 1095]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.97      0.84      1742\n",
      "           1       0.95      0.66      0.78      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.85      0.81      0.81      3408\n",
      "weighted avg       0.85      0.82      0.81      3408\n",
      "\n",
      "acc:  0.8151408450704225\n",
      "pre:  0.9488734835355286\n",
      "rec:  0.6572629051620649\n",
      "ma F1:  0.8094690435115968\n",
      "mi F1:  0.8151408450704225\n",
      "we F1:  0.810202133508996\n",
      "Eval Loss:  0.2558595836162567\n",
      "Eval Loss:  0.2681347727775574\n",
      "Eval Loss:  0.27350810170173645\n",
      "Eval Loss:  0.2768746316432953\n",
      "Eval Loss:  0.2938065230846405\n",
      "Eval Loss:  0.2839406132698059\n",
      "Eval Loss:  0.30000659823417664\n",
      "Eval Loss:  0.2928868234157562\n",
      "Eval Loss:  0.23580899834632874\n",
      "Eval Loss:  0.16731545329093933\n",
      "Eval Loss:  0.18836304545402527\n",
      "Eval Loss:  0.26561519503593445\n",
      "Eval Loss:  0.19998610019683838\n",
      "Eval Loss:  0.23693963885307312\n",
      "Eval Loss:  0.2071039080619812\n",
      "Eval Loss:  0.28926828503608704\n",
      "Eval Loss:  0.21704696118831635\n",
      "Eval Loss:  0.2403251826763153\n",
      "Eval Loss:  0.21313579380512238\n",
      "Eval Loss:  0.25860410928726196\n",
      "Eval Loss:  0.3027351498603821\n",
      "Eval Loss:  0.34131327271461487\n",
      "Eval Loss:  0.2487957924604416\n",
      "Eval Loss:  0.16593413054943085\n",
      "Eval Loss:  0.26854777336120605\n",
      "Eval Loss:  0.2405751794576645\n",
      "Eval Loss:  0.24542398750782013\n",
      "Eval Loss:  0.2866397798061371\n",
      "[[17760   662]\n",
      " [ 2452  8609]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     18422\n",
      "           1       0.93      0.78      0.85     11061\n",
      "\n",
      "    accuracy                           0.89     29483\n",
      "   macro avg       0.90      0.87      0.88     29483\n",
      "weighted avg       0.90      0.89      0.89     29483\n",
      "\n",
      "acc:  0.8943798120951056\n",
      "pre:  0.9285945421205911\n",
      "rec:  0.7783202242111925\n",
      "ma F1:  0.883119918928028\n",
      "mi F1:  0.8943798120951055\n",
      "we F1:  0.8921772977503271\n",
      "29483 461\n",
      "Loss:  0.043277837336063385\n",
      "Loss:  0.06957775354385376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.043569862842559814\n",
      "39 **********\n",
      "Epoch:  2079.7102768421173  fold:  9  kers:  32\n",
      "epoch:  40\n",
      "29483 461\n",
      "Loss:  0.0837000384926796\n",
      "Loss:  0.09854719787836075\n",
      "Loss:  0.07733464986085892\n",
      "40 **********\n",
      "Epoch:  2118.7987625598907  fold:  9  kers:  32\n",
      "epoch:  41\n",
      "29483 461\n",
      "Loss:  0.05948668718338013\n",
      "Loss:  0.06735893338918686\n",
      "Loss:  0.05975104868412018\n",
      "41 **********\n",
      "Epoch:  2157.8663036823273  fold:  9  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.031536515802145004\n",
      "Eval Loss:  1.387575387954712\n",
      "Eval Loss:  0.13665375113487244\n",
      "[[1661   81]\n",
      " [ 499 1167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85      1742\n",
      "           1       0.94      0.70      0.80      1666\n",
      "\n",
      "    accuracy                           0.83      3408\n",
      "   macro avg       0.85      0.83      0.83      3408\n",
      "weighted avg       0.85      0.83      0.83      3408\n",
      "\n",
      "acc:  0.82981220657277\n",
      "pre:  0.9350961538461539\n",
      "rec:  0.7004801920768308\n",
      "ma F1:  0.8261595781618776\n",
      "mi F1:  0.82981220657277\n",
      "we F1:  0.8267215209943225\n",
      "Eval Loss:  0.3183336853981018\n",
      "Eval Loss:  0.23026356101036072\n",
      "Eval Loss:  0.246236190199852\n",
      "Eval Loss:  0.2846950888633728\n",
      "Eval Loss:  0.2453104853630066\n",
      "Eval Loss:  0.2658042907714844\n",
      "Eval Loss:  0.2682909071445465\n",
      "Eval Loss:  0.2919136881828308\n",
      "Eval Loss:  0.23324763774871826\n",
      "Eval Loss:  0.15811997652053833\n",
      "Eval Loss:  0.16893355548381805\n",
      "Eval Loss:  0.2673925459384918\n",
      "Eval Loss:  0.2087947428226471\n",
      "Eval Loss:  0.22384102642536163\n",
      "Eval Loss:  0.197257399559021\n",
      "Eval Loss:  0.26584410667419434\n",
      "Eval Loss:  0.22018763422966003\n",
      "Eval Loss:  0.25132954120635986\n",
      "Eval Loss:  0.22039538621902466\n",
      "Eval Loss:  0.2264520674943924\n",
      "Eval Loss:  0.2847248613834381\n",
      "Eval Loss:  0.332466185092926\n",
      "Eval Loss:  0.2178228497505188\n",
      "Eval Loss:  0.16700968146324158\n",
      "Eval Loss:  0.27187004685401917\n",
      "Eval Loss:  0.2261005938053131\n",
      "Eval Loss:  0.23575769364833832\n",
      "Eval Loss:  0.25660470128059387\n",
      "[[17323  1099]\n",
      " [ 1802  9259]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     18422\n",
      "           1       0.89      0.84      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.89      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9016043143506427\n",
      "pre:  0.8938984359915042\n",
      "rec:  0.837085254497785\n",
      "ma F1:  0.8936481698715191\n",
      "mi F1:  0.9016043143506427\n",
      "we F1:  0.900910716933874\n",
      "29483 461\n",
      "Loss:  0.06602595001459122\n",
      "Loss:  0.07059470564126968\n",
      "Loss:  0.08834143728017807\n",
      "42 **********\n",
      "Epoch:  2235.27632522583  fold:  9  kers:  32\n",
      "epoch:  43\n",
      "29483 461\n",
      "Loss:  0.061647213995456696\n",
      "Loss:  0.06979174166917801\n",
      "Loss:  0.047265660017728806\n",
      "43 **********\n",
      "Epoch:  2274.306965112686  fold:  9  kers:  32\n",
      "epoch:  44\n",
      "29483 461\n",
      "Loss:  0.05882369726896286\n",
      "Loss:  0.049013085663318634\n",
      "Loss:  0.08580136299133301\n",
      "44 **********\n",
      "Epoch:  2313.356554031372  fold:  9  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.0264432355761528\n",
      "Eval Loss:  1.5129748582839966\n",
      "Eval Loss:  0.1859125792980194\n",
      "[[1671   71]\n",
      " [ 561 1105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84      1742\n",
      "           1       0.94      0.66      0.78      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.81      0.81      3408\n",
      "weighted avg       0.84      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8145539906103286\n",
      "pre:  0.939625850340136\n",
      "rec:  0.6632653061224489\n",
      "ma F1:  0.8092938371051526\n",
      "mi F1:  0.8145539906103286\n",
      "we F1:  0.8100001474698051\n",
      "Eval Loss:  0.2567838132381439\n",
      "Eval Loss:  0.2562885880470276\n",
      "Eval Loss:  0.2666855454444885\n",
      "Eval Loss:  0.27997010946273804\n",
      "Eval Loss:  0.28284531831741333\n",
      "Eval Loss:  0.2489784061908722\n",
      "Eval Loss:  0.2771351933479309\n",
      "Eval Loss:  0.2875198721885681\n",
      "Eval Loss:  0.22261354327201843\n",
      "Eval Loss:  0.1646725982427597\n",
      "Eval Loss:  0.17018471658229828\n",
      "Eval Loss:  0.2588486969470978\n",
      "Eval Loss:  0.1952839493751526\n",
      "Eval Loss:  0.23748962581157684\n",
      "Eval Loss:  0.20486274361610413\n",
      "Eval Loss:  0.28267616033554077\n",
      "Eval Loss:  0.20321643352508545\n",
      "Eval Loss:  0.23837144672870636\n",
      "Eval Loss:  0.2022882103919983\n",
      "Eval Loss:  0.24762287735939026\n",
      "Eval Loss:  0.2915380001068115\n",
      "Eval Loss:  0.32986077666282654\n",
      "Eval Loss:  0.23219648003578186\n",
      "Eval Loss:  0.15892919898033142\n",
      "Eval Loss:  0.26998966932296753\n",
      "Eval Loss:  0.22714096307754517\n",
      "Eval Loss:  0.22788769006729126\n",
      "Eval Loss:  0.2806966304779053\n",
      "[[17704   718]\n",
      " [ 2233  8828]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     18422\n",
      "           1       0.92      0.80      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.91      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.8999084218023946\n",
      "pre:  0.9247852503666457\n",
      "rec:  0.798119519030829\n",
      "ma F1:  0.8899325679906148\n",
      "mi F1:  0.8999084218023946\n",
      "we F1:  0.8982056932619656\n",
      "29483 461\n",
      "Loss:  0.09542754292488098\n",
      "Loss:  0.04237687960267067\n",
      "Loss:  0.05631685629487038\n",
      "45 **********\n",
      "Epoch:  2390.8952317237854  fold:  9  kers:  32\n",
      "epoch:  46\n",
      "29483 461\n",
      "Loss:  0.07034213095903397\n",
      "Loss:  0.06389957666397095\n",
      "Loss:  0.056412648409605026\n",
      "46 **********\n",
      "Epoch:  2430.025605201721  fold:  9  kers:  32\n",
      "epoch:  47\n",
      "29483 461\n",
      "Loss:  0.07496096193790436\n",
      "Loss:  0.07112503051757812\n",
      "Loss:  0.0805637389421463\n",
      "47 **********\n",
      "Epoch:  2469.1988632678986  fold:  9  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.029115647077560425\n",
      "Eval Loss:  1.4633032083511353\n",
      "Eval Loss:  0.20072555541992188\n",
      "[[1663   79]\n",
      " [ 569 1097]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84      1742\n",
      "           1       0.93      0.66      0.77      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.84      0.81      0.80      3408\n",
      "weighted avg       0.84      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8098591549295775\n",
      "pre:  0.9328231292517006\n",
      "rec:  0.6584633853541416\n",
      "ma F1:  0.8044658329812323\n",
      "mi F1:  0.8098591549295775\n",
      "we F1:  0.8051900246209395\n",
      "Eval Loss:  0.28249087929725647\n",
      "Eval Loss:  0.24914424121379852\n",
      "Eval Loss:  0.27383577823638916\n",
      "Eval Loss:  0.292193740606308\n",
      "Eval Loss:  0.2727430760860443\n",
      "Eval Loss:  0.2576758861541748\n",
      "Eval Loss:  0.281990110874176\n",
      "Eval Loss:  0.28653955459594727\n",
      "Eval Loss:  0.22484897077083588\n",
      "Eval Loss:  0.15856759250164032\n",
      "Eval Loss:  0.16045363247394562\n",
      "Eval Loss:  0.24874630570411682\n",
      "Eval Loss:  0.2050609290599823\n",
      "Eval Loss:  0.2297547459602356\n",
      "Eval Loss:  0.19281822443008423\n",
      "Eval Loss:  0.28785771131515503\n",
      "Eval Loss:  0.21130894124507904\n",
      "Eval Loss:  0.24454282224178314\n",
      "Eval Loss:  0.2009757161140442\n",
      "Eval Loss:  0.24260729551315308\n",
      "Eval Loss:  0.2859509587287903\n",
      "Eval Loss:  0.3439200818538666\n",
      "Eval Loss:  0.2193181961774826\n",
      "Eval Loss:  0.159860298037529\n",
      "Eval Loss:  0.26526033878326416\n",
      "Eval Loss:  0.22130809724330902\n",
      "Eval Loss:  0.21969513595104218\n",
      "Eval Loss:  0.2746307849884033\n",
      "[[17580   842]\n",
      " [ 2088  8973]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     18422\n",
      "           1       0.91      0.81      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.88      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9006206966726589\n",
      "pre:  0.9142129393785023\n",
      "rec:  0.8112286411716843\n",
      "ma F1:  0.891362182557814\n",
      "mi F1:  0.9006206966726589\n",
      "we F1:  0.8992803796531286\n",
      "29483 461\n",
      "Loss:  0.057619594037532806\n",
      "Loss:  0.0867755338549614\n",
      "Loss:  0.05891503393650055\n",
      "48 **********\n",
      "Epoch:  2546.441333055496  fold:  9  kers:  32\n",
      "epoch:  49\n",
      "29483 461\n",
      "Loss:  0.07630357891321182\n",
      "Loss:  0.08533830940723419\n",
      "Loss:  0.06952839344739914\n",
      "49 **********\n",
      "Epoch:  2585.531813144684  fold:  9  kers:  32\n",
      "epoch:  50\n",
      "29483 461\n",
      "Loss:  0.04948302358388901\n",
      "Loss:  0.07203507423400879\n",
      "Loss:  0.10548662394285202\n",
      "50 **********\n",
      "Epoch:  2624.5105917453766  fold:  9  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.024487048387527466\n",
      "Eval Loss:  1.4643356800079346\n",
      "Eval Loss:  0.19299164414405823\n",
      "[[1666   76]\n",
      " [ 536 1130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.84      1742\n",
      "           1       0.94      0.68      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.85      0.82      0.82      3408\n",
      "weighted avg       0.84      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8204225352112676\n",
      "pre:  0.9369817578772802\n",
      "rec:  0.6782713085234093\n",
      "ma F1:  0.8158678321006627\n",
      "mi F1:  0.8204225352112676\n",
      "we F1:  0.8165136482133605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2777025103569031\n",
      "Eval Loss:  0.23206067085266113\n",
      "Eval Loss:  0.29039788246154785\n",
      "Eval Loss:  0.2627592086791992\n",
      "Eval Loss:  0.2638469934463501\n",
      "Eval Loss:  0.24738435447216034\n",
      "Eval Loss:  0.27907487750053406\n",
      "Eval Loss:  0.287504106760025\n",
      "Eval Loss:  0.20969727635383606\n",
      "Eval Loss:  0.18597187101840973\n",
      "Eval Loss:  0.1636505424976349\n",
      "Eval Loss:  0.25048238039016724\n",
      "Eval Loss:  0.19660663604736328\n",
      "Eval Loss:  0.21924859285354614\n",
      "Eval Loss:  0.20595334470272064\n",
      "Eval Loss:  0.2938074767589569\n",
      "Eval Loss:  0.19350478053092957\n",
      "Eval Loss:  0.24407824873924255\n",
      "Eval Loss:  0.201751708984375\n",
      "Eval Loss:  0.2363315373659134\n",
      "Eval Loss:  0.2568804919719696\n",
      "Eval Loss:  0.3162560760974884\n",
      "Eval Loss:  0.246867835521698\n",
      "Eval Loss:  0.1648314744234085\n",
      "Eval Loss:  0.26843735575675964\n",
      "Eval Loss:  0.2104196548461914\n",
      "Eval Loss:  0.21964922547340393\n",
      "Eval Loss:  0.25795453786849976\n",
      "[[17509   913]\n",
      " [ 1955  9106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     18422\n",
      "           1       0.91      0.82      0.86     11061\n",
      "\n",
      "    accuracy                           0.90     29483\n",
      "   macro avg       0.90      0.89      0.89     29483\n",
      "weighted avg       0.90      0.90      0.90     29483\n",
      "\n",
      "acc:  0.9027236034324865\n",
      "pre:  0.9088731410320391\n",
      "rec:  0.8232528704457102\n",
      "ma F1:  0.8941230412499859\n",
      "mi F1:  0.9027236034324865\n",
      "we F1:  0.9016571050635509\n",
      "29483 461\n",
      "Loss:  0.057435542345047\n",
      "Loss:  0.03590155392885208\n",
      "Loss:  0.06330370903015137\n",
      "51 **********\n",
      "Epoch:  2702.205850124359  fold:  9  kers:  32\n",
      "epoch:  52\n",
      "29483 461\n",
      "Loss:  0.05569770932197571\n",
      "Loss:  0.03876136615872383\n",
      "Loss:  0.031393133103847504\n",
      "52 **********\n",
      "Epoch:  2741.257434129715  fold:  9  kers:  32\n",
      "epoch:  53\n",
      "29483 461\n",
      "Loss:  0.07196057587862015\n",
      "Loss:  0.06877867132425308\n",
      "Loss:  0.05646003782749176\n",
      "53 **********\n",
      "Epoch:  2780.303034067154  fold:  9  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.02392951026558876\n",
      "Eval Loss:  1.340434193611145\n",
      "Eval Loss:  0.17783509194850922\n",
      "[[1637  105]\n",
      " [ 507 1159]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      1742\n",
      "           1       0.92      0.70      0.79      1666\n",
      "\n",
      "    accuracy                           0.82      3408\n",
      "   macro avg       0.84      0.82      0.82      3408\n",
      "weighted avg       0.84      0.82      0.82      3408\n",
      "\n",
      "acc:  0.8204225352112676\n",
      "pre:  0.9169303797468354\n",
      "rec:  0.6956782713085234\n",
      "ma F1:  0.8168189299471806\n",
      "mi F1:  0.8204225352112676\n",
      "we F1:  0.8173918881063242\n",
      "Eval Loss:  0.29928693175315857\n",
      "Eval Loss:  0.19694487750530243\n",
      "Eval Loss:  0.23849569261074066\n",
      "Eval Loss:  0.2625121772289276\n",
      "Eval Loss:  0.24273772537708282\n",
      "Eval Loss:  0.23817867040634155\n",
      "Eval Loss:  0.25160476565361023\n",
      "Eval Loss:  0.2931281328201294\n",
      "Eval Loss:  0.23712438344955444\n",
      "Eval Loss:  0.1635623425245285\n",
      "Eval Loss:  0.14846132695674896\n",
      "Eval Loss:  0.2449355125427246\n",
      "Eval Loss:  0.18800362944602966\n",
      "Eval Loss:  0.20287059247493744\n",
      "Eval Loss:  0.19526202976703644\n",
      "Eval Loss:  0.27359482645988464\n",
      "Eval Loss:  0.19831110537052155\n",
      "Eval Loss:  0.24589776992797852\n",
      "Eval Loss:  0.20407897233963013\n",
      "Eval Loss:  0.2142113894224167\n",
      "Eval Loss:  0.2633931040763855\n",
      "Eval Loss:  0.3212403357028961\n",
      "Eval Loss:  0.20408344268798828\n",
      "Eval Loss:  0.1562384068965912\n",
      "Eval Loss:  0.25791606307029724\n",
      "Eval Loss:  0.20702172815799713\n",
      "Eval Loss:  0.21848879754543304\n",
      "Eval Loss:  0.2373068928718567\n",
      "[[17370  1052]\n",
      " [ 1733  9328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     18422\n",
      "           1       0.90      0.84      0.87     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.90      0.89      0.90     29483\n",
      "weighted avg       0.91      0.91      0.90     29483\n",
      "\n",
      "acc:  0.9055387850625785\n",
      "pre:  0.8986512524084779\n",
      "rec:  0.843323388482054\n",
      "ma F1:  0.8979457408817919\n",
      "mi F1:  0.9055387850625785\n",
      "we F1:  0.9048958028333921\n",
      "29483 461\n",
      "Loss:  0.060841258615255356\n",
      "Loss:  0.04451237991452217\n",
      "Loss:  0.0605088546872139\n",
      "54 **********\n",
      "Epoch:  2857.6372582912445  fold:  9  kers:  32\n",
      "epoch:  55\n",
      "29483 461\n",
      "Loss:  0.06071670353412628\n",
      "Loss:  0.052357595413923264\n",
      "Loss:  0.04957788437604904\n",
      "55 **********\n",
      "Epoch:  2896.7706236839294  fold:  9  kers:  32\n",
      "epoch:  56\n",
      "29483 461\n",
      "Loss:  0.053751733154058456\n",
      "Loss:  0.0797768086194992\n",
      "Loss:  0.03575129434466362\n",
      "56 **********\n",
      "Epoch:  2935.9319140911102  fold:  9  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.024729643017053604\n",
      "Eval Loss:  1.2314409017562866\n",
      "Eval Loss:  0.14612162113189697\n",
      "[[1605  137]\n",
      " [ 418 1248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85      1742\n",
      "           1       0.90      0.75      0.82      1666\n",
      "\n",
      "    accuracy                           0.84      3408\n",
      "   macro avg       0.85      0.84      0.84      3408\n",
      "weighted avg       0.85      0.84      0.84      3408\n",
      "\n",
      "acc:  0.8371478873239436\n",
      "pre:  0.9010830324909748\n",
      "rec:  0.7490996398559424\n",
      "ma F1:  0.8353410350730803\n",
      "mi F1:  0.8371478873239436\n",
      "we F1:  0.8357256870928721\n",
      "update!  Acc:  0.8371478873239436\n",
      "Eval Loss:  0.28478389978408813\n",
      "Eval Loss:  0.19760316610336304\n",
      "Eval Loss:  0.25310438871383667\n",
      "Eval Loss:  0.2492215931415558\n",
      "Eval Loss:  0.23590698838233948\n",
      "Eval Loss:  0.24534623324871063\n",
      "Eval Loss:  0.2449202537536621\n",
      "Eval Loss:  0.2819373309612274\n",
      "Eval Loss:  0.2192939668893814\n",
      "Eval Loss:  0.15027883648872375\n",
      "Eval Loss:  0.14290909469127655\n",
      "Eval Loss:  0.24440668523311615\n",
      "Eval Loss:  0.19045700132846832\n",
      "Eval Loss:  0.20900578796863556\n",
      "Eval Loss:  0.19057445228099823\n",
      "Eval Loss:  0.2504112124443054\n",
      "Eval Loss:  0.186655193567276\n",
      "Eval Loss:  0.23380407691001892\n",
      "Eval Loss:  0.20446501672267914\n",
      "Eval Loss:  0.19072118401527405\n",
      "Eval Loss:  0.25759652256965637\n",
      "Eval Loss:  0.3081820011138916\n",
      "Eval Loss:  0.20114000141620636\n",
      "Eval Loss:  0.16221103072166443\n",
      "Eval Loss:  0.24077007174491882\n",
      "Eval Loss:  0.2011750042438507\n",
      "Eval Loss:  0.19490914046764374\n",
      "Eval Loss:  0.2338823825120926\n",
      "[[17341  1081]\n",
      " [ 1606  9455]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     18422\n",
      "           1       0.90      0.85      0.88     11061\n",
      "\n",
      "    accuracy                           0.91     29483\n",
      "   macro avg       0.91      0.90      0.90     29483\n",
      "weighted avg       0.91      0.91      0.91     29483\n",
      "\n",
      "acc:  0.9088627344571448\n",
      "pre:  0.8973993925588458\n",
      "rec:  0.8548051713226652\n",
      "ma F1:  0.9018400260710783\n",
      "mi F1:  0.9088627344571448\n",
      "we F1:  0.908395206952366\n",
      "29483 461\n",
      "Loss:  0.0692700520157814\n",
      "Loss:  0.061882384121418\n",
      "Loss:  0.039961427450180054\n",
      "57 **********\n",
      "Epoch:  3013.3947942256927  fold:  9  kers:  32\n",
      "epoch:  58\n",
      "29483 461\n",
      "Loss:  0.06656865775585175\n",
      "Loss:  0.06754597276449203\n",
      "Loss:  0.10277070850133896\n",
      "58 **********\n",
      "Epoch:  3052.5690500736237  fold:  9  kers:  32\n",
      "epoch:  59\n",
      "29483 461\n",
      "Loss:  0.058704834431409836\n",
      "Loss:  0.10133752971887589\n",
      "Loss:  0.03592916578054428\n",
      "59 **********\n",
      "Epoch:  3091.6076691150665  fold:  9  kers:  32\n",
      "Eval Loss:  0.017842214554548264\n",
      "Eval Loss:  1.1941039562225342\n",
      "Eval Loss:  0.19587647914886475\n",
      "[[1631  111]\n",
      " [ 521 1145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      1742\n",
      "           1       0.91      0.69      0.78      1666\n",
      "\n",
      "    accuracy                           0.81      3408\n",
      "   macro avg       0.83      0.81      0.81      3408\n",
      "weighted avg       0.83      0.81      0.81      3408\n",
      "\n",
      "acc:  0.8145539906103286\n",
      "pre:  0.9116242038216561\n",
      "rec:  0.6872749099639855\n",
      "ma F1:  0.810704405978133\n",
      "mi F1:  0.8145539906103286\n",
      "we F1:  0.8113063986366655\n",
      "update!  Acc:  0.8371478873239436\n",
      "Epoch:  3095.579050540924  fold:  9  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "*********\n",
      "29871 3020\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "29871 467\n",
      "Loss:  0.16751937568187714\n",
      "Loss:  0.1659240871667862\n",
      "Loss:  0.16921573877334595\n",
      "0 **********\n",
      "Epoch:  52.07875180244446  fold:  10  kers:  32\n",
      "epoch:  1\n",
      "29871 467\n",
      "Loss:  0.13078826665878296\n",
      "Loss:  0.13242802023887634\n",
      "Loss:  0.1268257051706314\n",
      "1 **********\n",
      "Epoch:  92.08179211616516  fold:  10  kers:  32\n",
      "epoch:  2\n",
      "29871 467\n",
      "Loss:  0.12668336927890778\n",
      "Loss:  0.11101389676332474\n",
      "Loss:  0.10185381025075912\n",
      "2 **********\n",
      "Epoch:  131.80956840515137  fold:  10  kers:  32\n",
      "epoch:  3\n",
      "Eval Loss:  0.5076748728752136\n",
      "Eval Loss:  0.32066118717193604\n",
      "Eval Loss:  0.14308279752731323\n",
      "[[1472  279]\n",
      " [ 162 1107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87      1751\n",
      "           1       0.80      0.87      0.83      1269\n",
      "\n",
      "    accuracy                           0.85      3020\n",
      "   macro avg       0.85      0.86      0.85      3020\n",
      "weighted avg       0.86      0.85      0.85      3020\n",
      "\n",
      "acc:  0.8539735099337749\n",
      "pre:  0.7987012987012987\n",
      "rec:  0.8723404255319149\n",
      "ma F1:  0.8518088275793005\n",
      "mi F1:  0.8539735099337749\n",
      "we F1:  0.8546673944145242\n",
      "update!  Acc:  0.8539735099337749\n",
      "Eval Loss:  0.4807319939136505\n",
      "Eval Loss:  0.4510745108127594\n",
      "Eval Loss:  0.42192232608795166\n",
      "Eval Loss:  0.4679134488105774\n",
      "Eval Loss:  0.3801872134208679\n",
      "Eval Loss:  0.4092302620410919\n",
      "Eval Loss:  0.4505883455276489\n",
      "Eval Loss:  0.4840429425239563\n",
      "Eval Loss:  0.5205457806587219\n",
      "Eval Loss:  0.46126943826675415\n",
      "Eval Loss:  0.49832791090011597\n",
      "Eval Loss:  0.5175930261611938\n",
      "Eval Loss:  0.3358622193336487\n",
      "Eval Loss:  0.45740845799446106\n",
      "Eval Loss:  0.36469167470932007\n",
      "Eval Loss:  0.44564634561538696\n",
      "Eval Loss:  0.46193236112594604\n",
      "Eval Loss:  0.39540010690689087\n",
      "Eval Loss:  0.44008010625839233\n",
      "Eval Loss:  0.4992775321006775\n",
      "Eval Loss:  0.4625578224658966\n",
      "Eval Loss:  0.4727070927619934\n",
      "Eval Loss:  0.43776246905326843\n",
      "Eval Loss:  0.42691436409950256\n",
      "Eval Loss:  0.4795132875442505\n",
      "Eval Loss:  0.36984574794769287\n",
      "Eval Loss:  0.4201914668083191\n",
      "Eval Loss:  0.4646146595478058\n",
      "Eval Loss:  0.44649162888526917\n",
      "[[15150  3263]\n",
      " [ 3042  8416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83     18413\n",
      "           1       0.72      0.73      0.73     11458\n",
      "\n",
      "    accuracy                           0.79     29871\n",
      "   macro avg       0.78      0.78      0.78     29871\n",
      "weighted avg       0.79      0.79      0.79     29871\n",
      "\n",
      "acc:  0.7889257139031167\n",
      "pre:  0.7206096412364073\n",
      "rec:  0.7345086402513528\n",
      "ma F1:  0.7776242657914947\n",
      "mi F1:  0.7889257139031166\n",
      "we F1:  0.7892966108488649\n",
      "29871 467\n",
      "Loss:  0.12340961396694183\n",
      "Loss:  0.10504455119371414\n",
      "Loss:  0.10054464638233185\n",
      "3 **********\n",
      "Epoch:  210.31565880775452  fold:  10  kers:  32\n",
      "epoch:  4\n",
      "29871 467\n",
      "Loss:  0.0886954516172409\n",
      "Loss:  0.09187359362840652\n",
      "Loss:  0.10262885689735413\n",
      "4 **********\n",
      "Epoch:  250.021493434906  fold:  10  kers:  32\n",
      "epoch:  5\n",
      "29871 467\n",
      "Loss:  0.09617602080106735\n",
      "Loss:  0.12870270013809204\n",
      "Loss:  0.10247547924518585\n",
      "5 **********\n",
      "Epoch:  289.67247462272644  fold:  10  kers:  32\n",
      "epoch:  6\n",
      "Eval Loss:  0.6037802696228027\n",
      "Eval Loss:  0.18733108043670654\n",
      "Eval Loss:  0.12991012632846832\n",
      "[[1622  129]\n",
      " [ 236 1033]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      1751\n",
      "           1       0.89      0.81      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.88      0.87      0.87      3020\n",
      "weighted avg       0.88      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8791390728476821\n",
      "pre:  0.8889845094664371\n",
      "rec:  0.814026792750197\n",
      "ma F1:  0.8743599887798216\n",
      "mi F1:  0.8791390728476821\n",
      "we F1:  0.8782708860985122\n",
      "update!  Acc:  0.8791390728476821\n",
      "Eval Loss:  0.45572739839553833\n",
      "Eval Loss:  0.3747064173221588\n",
      "Eval Loss:  0.36714881658554077\n",
      "Eval Loss:  0.3792712688446045\n",
      "Eval Loss:  0.31799963116645813\n",
      "Eval Loss:  0.33476749062538147\n",
      "Eval Loss:  0.4274597465991974\n",
      "Eval Loss:  0.45975226163864136\n",
      "Eval Loss:  0.4850694239139557\n",
      "Eval Loss:  0.32117733359336853\n",
      "Eval Loss:  0.4240831732749939\n",
      "Eval Loss:  0.38201287388801575\n",
      "Eval Loss:  0.2768307328224182\n",
      "Eval Loss:  0.3967306613922119\n",
      "Eval Loss:  0.28839150071144104\n",
      "Eval Loss:  0.3797382414340973\n",
      "Eval Loss:  0.38902580738067627\n",
      "Eval Loss:  0.32031092047691345\n",
      "Eval Loss:  0.3620464503765106\n",
      "Eval Loss:  0.4742075204849243\n",
      "Eval Loss:  0.3855380415916443\n",
      "Eval Loss:  0.4707726240158081\n",
      "Eval Loss:  0.3636360764503479\n",
      "Eval Loss:  0.33406513929367065\n",
      "Eval Loss:  0.4546305537223816\n",
      "Eval Loss:  0.2900126278400421\n",
      "Eval Loss:  0.4071400463581085\n",
      "Eval Loss:  0.44328802824020386\n",
      "Eval Loss:  0.4204390347003937\n",
      "[[17100  1313]\n",
      " [ 3602  7856]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87     18413\n",
      "           1       0.86      0.69      0.76     11458\n",
      "\n",
      "    accuracy                           0.84     29871\n",
      "   macro avg       0.84      0.81      0.82     29871\n",
      "weighted avg       0.84      0.84      0.83     29871\n",
      "\n",
      "acc:  0.8354591409728499\n",
      "pre:  0.856800087250518\n",
      "rec:  0.6856344911851981\n",
      "ma F1:  0.8180324780548319\n",
      "mi F1:  0.8354591409728499\n",
      "we F1:  0.831143949343756\n",
      "29871 467\n",
      "Loss:  0.10738252848386765\n",
      "Loss:  0.09579963982105255\n",
      "Loss:  0.10507899522781372\n",
      "6 **********\n",
      "Epoch:  367.63900804519653  fold:  10  kers:  32\n",
      "epoch:  7\n",
      "29871 467\n",
      "Loss:  0.09273314476013184\n",
      "Loss:  0.13007435202598572\n",
      "Loss:  0.07526645809412003\n",
      "7 **********\n",
      "Epoch:  407.26505637168884  fold:  10  kers:  32\n",
      "epoch:  8\n",
      "29871 467\n",
      "Loss:  0.07650388032197952\n",
      "Loss:  0.0849117711186409\n",
      "Loss:  0.12823447585105896\n",
      "8 **********\n",
      "Epoch:  446.8751471042633  fold:  10  kers:  32\n",
      "epoch:  9\n",
      "Eval Loss:  0.6229368448257446\n",
      "Eval Loss:  0.15233583748340607\n",
      "Eval Loss:  0.12429463118314743\n",
      "[[1633  118]\n",
      " [ 252 1017]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      1751\n",
      "           1       0.90      0.80      0.85      1269\n",
      "\n",
      "    accuracy                           0.88      3020\n",
      "   macro avg       0.88      0.87      0.87      3020\n",
      "weighted avg       0.88      0.88      0.88      3020\n",
      "\n",
      "acc:  0.8774834437086093\n",
      "pre:  0.8960352422907489\n",
      "rec:  0.8014184397163121\n",
      "ma F1:  0.8721648371159911\n",
      "mi F1:  0.8774834437086093\n",
      "we F1:  0.8763264740926826\n",
      "Eval Loss:  0.4438035488128662\n",
      "Eval Loss:  0.34187376499176025\n",
      "Eval Loss:  0.3651485741138458\n",
      "Eval Loss:  0.35323670506477356\n",
      "Eval Loss:  0.323324978351593\n",
      "Eval Loss:  0.29953673481941223\n",
      "Eval Loss:  0.42580685019493103\n",
      "Eval Loss:  0.4441048800945282\n",
      "Eval Loss:  0.4635220766067505\n",
      "Eval Loss:  0.2941024899482727\n",
      "Eval Loss:  0.36474621295928955\n",
      "Eval Loss:  0.32893604040145874\n",
      "Eval Loss:  0.26770585775375366\n",
      "Eval Loss:  0.3480800688266754\n",
      "Eval Loss:  0.29583972692489624\n",
      "Eval Loss:  0.3473701775074005\n",
      "Eval Loss:  0.3898417055606842\n",
      "Eval Loss:  0.3062951862812042\n",
      "Eval Loss:  0.32876577973365784\n",
      "Eval Loss:  0.46953532099723816\n",
      "Eval Loss:  0.34559014439582825\n",
      "Eval Loss:  0.4684998691082001\n",
      "Eval Loss:  0.3613244593143463\n",
      "Eval Loss:  0.32365402579307556\n",
      "Eval Loss:  0.42258214950561523\n",
      "Eval Loss:  0.2670571506023407\n",
      "Eval Loss:  0.37984776496887207\n",
      "Eval Loss:  0.4388229250907898\n",
      "Eval Loss:  0.4094817042350769\n",
      "[[17370  1043]\n",
      " [ 3632  7826]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88     18413\n",
      "           1       0.88      0.68      0.77     11458\n",
      "\n",
      "    accuracy                           0.84     29871\n",
      "   macro avg       0.85      0.81      0.83     29871\n",
      "weighted avg       0.85      0.84      0.84     29871\n",
      "\n",
      "acc:  0.8434936895316528\n",
      "pre:  0.8823993685872139\n",
      "rec:  0.6830162331995112\n",
      "ma F1:  0.8257003323580304\n",
      "mi F1:  0.8434936895316528\n",
      "we F1:  0.8386668871717923\n",
      "29871 467\n",
      "Loss:  0.11402460932731628\n",
      "Loss:  0.08266256749629974\n",
      "Loss:  0.08733393251895905\n",
      "9 **********\n",
      "Epoch:  524.7399518489838  fold:  10  kers:  32\n",
      "epoch:  10\n",
      "29871 467\n",
      "Loss:  0.09054243564605713\n",
      "Loss:  0.09181071817874908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.08517464995384216\n",
      "10 **********\n",
      "Epoch:  564.4487791061401  fold:  10  kers:  32\n",
      "epoch:  11\n",
      "29871 467\n",
      "Loss:  0.11254209280014038\n",
      "Loss:  0.09814788401126862\n",
      "Loss:  0.08646339178085327\n",
      "11 **********\n",
      "Epoch:  603.9930455684662  fold:  10  kers:  32\n",
      "epoch:  12\n",
      "Eval Loss:  0.485920250415802\n",
      "Eval Loss:  0.16466611623764038\n",
      "Eval Loss:  0.15357640385627747\n",
      "[[1603  148]\n",
      " [ 181 1088]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1751\n",
      "           1       0.88      0.86      0.87      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.89      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8910596026490066\n",
      "pre:  0.8802588996763754\n",
      "rec:  0.8573680063041765\n",
      "ma F1:  0.8877966838600027\n",
      "mi F1:  0.8910596026490066\n",
      "we F1:  0.8908505224159248\n",
      "update!  Acc:  0.8910596026490066\n",
      "Eval Loss:  0.3672671318054199\n",
      "Eval Loss:  0.3237600028514862\n",
      "Eval Loss:  0.3306562900543213\n",
      "Eval Loss:  0.33124443888664246\n",
      "Eval Loss:  0.2531611919403076\n",
      "Eval Loss:  0.27916863560676575\n",
      "Eval Loss:  0.3901732861995697\n",
      "Eval Loss:  0.37897762656211853\n",
      "Eval Loss:  0.4144420921802521\n",
      "Eval Loss:  0.2424323409795761\n",
      "Eval Loss:  0.28522995114326477\n",
      "Eval Loss:  0.2684502899646759\n",
      "Eval Loss:  0.26378265023231506\n",
      "Eval Loss:  0.29251420497894287\n",
      "Eval Loss:  0.2382226586341858\n",
      "Eval Loss:  0.3179301917552948\n",
      "Eval Loss:  0.34221526980400085\n",
      "Eval Loss:  0.25253739953041077\n",
      "Eval Loss:  0.29277196526527405\n",
      "Eval Loss:  0.4157467484474182\n",
      "Eval Loss:  0.3027040362358093\n",
      "Eval Loss:  0.4331206977367401\n",
      "Eval Loss:  0.35684794187545776\n",
      "Eval Loss:  0.30056318640708923\n",
      "Eval Loss:  0.3965684175491333\n",
      "Eval Loss:  0.2521529495716095\n",
      "Eval Loss:  0.3666034936904907\n",
      "Eval Loss:  0.3959246277809143\n",
      "Eval Loss:  0.36456185579299927\n",
      "[[16943  1470]\n",
      " [ 2723  8735]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     18413\n",
      "           1       0.86      0.76      0.81     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.86      0.84      0.85     29871\n",
      "weighted avg       0.86      0.86      0.86     29871\n",
      "\n",
      "acc:  0.8596297412205819\n",
      "pre:  0.855952964233219\n",
      "rec:  0.762349450165823\n",
      "ma F1:  0.8481654908645359\n",
      "mi F1:  0.8596297412205819\n",
      "we F1:  0.8578796552439584\n",
      "29871 467\n",
      "Loss:  0.07266556471586227\n",
      "Loss:  0.07153670489788055\n",
      "Loss:  0.07310520857572556\n",
      "12 **********\n",
      "Epoch:  682.2029280662537  fold:  10  kers:  32\n",
      "epoch:  13\n",
      "29871 467\n",
      "Loss:  0.07737037539482117\n",
      "Loss:  0.08735188841819763\n",
      "Loss:  0.07722772657871246\n",
      "13 **********\n",
      "Epoch:  721.8748531341553  fold:  10  kers:  32\n",
      "epoch:  14\n",
      "29871 467\n",
      "Loss:  0.08381859213113785\n",
      "Loss:  0.10027776658535004\n",
      "Loss:  0.0706455260515213\n",
      "14 **********\n",
      "Epoch:  761.5617392063141  fold:  10  kers:  32\n",
      "epoch:  15\n",
      "Eval Loss:  0.5770025253295898\n",
      "Eval Loss:  0.12800586223602295\n",
      "Eval Loss:  0.10656502097845078\n",
      "[[1658   93]\n",
      " [ 237 1032]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1751\n",
      "           1       0.92      0.81      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.88      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.890728476821192\n",
      "pre:  0.9173333333333333\n",
      "rec:  0.8132387706855791\n",
      "ma F1:  0.8858226201818313\n",
      "mi F1:  0.8907284768211922\n",
      "we F1:  0.8895999730575053\n",
      "Eval Loss:  0.3933470547199249\n",
      "Eval Loss:  0.297341912984848\n",
      "Eval Loss:  0.3644602596759796\n",
      "Eval Loss:  0.32385900616645813\n",
      "Eval Loss:  0.30212855339050293\n",
      "Eval Loss:  0.28939250111579895\n",
      "Eval Loss:  0.4033854007720947\n",
      "Eval Loss:  0.3956839144229889\n",
      "Eval Loss:  0.45017218589782715\n",
      "Eval Loss:  0.27092689275741577\n",
      "Eval Loss:  0.3451803922653198\n",
      "Eval Loss:  0.32082509994506836\n",
      "Eval Loss:  0.24174511432647705\n",
      "Eval Loss:  0.33277735114097595\n",
      "Eval Loss:  0.27997422218322754\n",
      "Eval Loss:  0.3174278438091278\n",
      "Eval Loss:  0.3753235340118408\n",
      "Eval Loss:  0.28727948665618896\n",
      "Eval Loss:  0.3016660809516907\n",
      "Eval Loss:  0.4272036552429199\n",
      "Eval Loss:  0.3286437392234802\n",
      "Eval Loss:  0.44973787665367126\n",
      "Eval Loss:  0.3653263747692108\n",
      "Eval Loss:  0.3247870206832886\n",
      "Eval Loss:  0.40380194783210754\n",
      "Eval Loss:  0.2411487102508545\n",
      "Eval Loss:  0.35720956325531006\n",
      "Eval Loss:  0.4219646751880646\n",
      "Eval Loss:  0.37383949756622314\n",
      "[[17579   834]\n",
      " [ 3642  7816]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     18413\n",
      "           1       0.90      0.68      0.78     11458\n",
      "\n",
      "    accuracy                           0.85     29871\n",
      "   macro avg       0.87      0.82      0.83     29871\n",
      "weighted avg       0.86      0.85      0.85     29871\n",
      "\n",
      "acc:  0.8501556693783268\n",
      "pre:  0.9035838150289017\n",
      "rec:  0.6821434805376156\n",
      "ma F1:  0.8322343444908018\n",
      "mi F1:  0.8501556693783267\n",
      "we F1:  0.845001200435976\n",
      "29871 467\n",
      "Loss:  0.09563817083835602\n",
      "Loss:  0.1158752292394638\n",
      "Loss:  0.08957210183143616\n",
      "15 **********\n",
      "Epoch:  839.656928062439  fold:  10  kers:  32\n",
      "epoch:  16\n",
      "29871 467\n",
      "Loss:  0.06139083579182625\n",
      "Loss:  0.11262676864862442\n",
      "Loss:  0.09203822165727615\n",
      "16 **********\n",
      "Epoch:  879.335834980011  fold:  10  kers:  32\n",
      "epoch:  17\n",
      "29871 467\n",
      "Loss:  0.0414438471198082\n",
      "Loss:  0.06756014376878738\n",
      "Loss:  0.09261056035757065\n",
      "17 **********\n",
      "Epoch:  919.0177335739136  fold:  10  kers:  32\n",
      "epoch:  18\n",
      "Eval Loss:  0.4943513572216034\n",
      "Eval Loss:  0.14596155285835266\n",
      "Eval Loss:  0.12298176437616348\n",
      "[[1638  113]\n",
      " [ 188 1081]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      1751\n",
      "           1       0.91      0.85      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9003311258278146\n",
      "pre:  0.9053601340033501\n",
      "rec:  0.8518518518518519\n",
      "ma F1:  0.8968212917122533\n",
      "mi F1:  0.9003311258278146\n",
      "we F1:  0.8998585269792203\n",
      "update!  Acc:  0.9003311258278146\n",
      "Eval Loss:  0.33819034695625305\n",
      "Eval Loss:  0.30092573165893555\n",
      "Eval Loss:  0.3281439542770386\n",
      "Eval Loss:  0.30568015575408936\n",
      "Eval Loss:  0.23821356892585754\n",
      "Eval Loss:  0.27762889862060547\n",
      "Eval Loss:  0.37444445490837097\n",
      "Eval Loss:  0.3493107855319977\n",
      "Eval Loss:  0.41123002767562866\n",
      "Eval Loss:  0.23872236907482147\n",
      "Eval Loss:  0.26952943205833435\n",
      "Eval Loss:  0.25255972146987915\n",
      "Eval Loss:  0.2656782865524292\n",
      "Eval Loss:  0.270026832818985\n",
      "Eval Loss:  0.24834415316581726\n",
      "Eval Loss:  0.28376418352127075\n",
      "Eval Loss:  0.33643099665641785\n",
      "Eval Loss:  0.21483933925628662\n",
      "Eval Loss:  0.2498089224100113\n",
      "Eval Loss:  0.39627164602279663\n",
      "Eval Loss:  0.2876584529876709\n",
      "Eval Loss:  0.4089258909225464\n",
      "Eval Loss:  0.3429711163043976\n",
      "Eval Loss:  0.294943243265152\n",
      "Eval Loss:  0.3782394528388977\n",
      "Eval Loss:  0.25025123357772827\n",
      "Eval Loss:  0.3408080041408539\n",
      "Eval Loss:  0.36454951763153076\n",
      "Eval Loss:  0.3213706910610199\n",
      "[[17119  1294]\n",
      " [ 2600  8858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     18413\n",
      "           1       0.87      0.77      0.82     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.87      0.85      0.86     29871\n",
      "weighted avg       0.87      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8696394496334238\n",
      "pre:  0.8725374310480694\n",
      "rec:  0.7730843079071391\n",
      "ma F1:  0.8588433451631254\n",
      "mi F1:  0.8696394496334237\n",
      "we F1:  0.8679326692874355\n",
      "29871 467\n",
      "Loss:  0.09633761644363403\n",
      "Loss:  0.08118941634893417\n",
      "Loss:  0.06143844127655029\n",
      "18 **********\n",
      "Epoch:  997.1268854141235  fold:  10  kers:  32\n",
      "epoch:  19\n",
      "29871 467\n",
      "Loss:  0.08837220817804337\n",
      "Loss:  0.044045016169548035\n",
      "Loss:  0.1084529459476471\n",
      "19 **********\n",
      "Epoch:  1036.8247413635254  fold:  10  kers:  32\n",
      "epoch:  20\n",
      "29871 467\n",
      "Loss:  0.08131039142608643\n",
      "Loss:  0.059065334498882294\n",
      "Loss:  0.06642938405275345\n",
      "20 **********\n",
      "Epoch:  1076.4388213157654  fold:  10  kers:  32\n",
      "epoch:  21\n",
      "Eval Loss:  0.6908188462257385\n",
      "Eval Loss:  0.105122871696949\n",
      "Eval Loss:  0.09214087575674057\n",
      "[[1673   78]\n",
      " [ 269 1000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      1751\n",
      "           1       0.93      0.79      0.85      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.89      0.87      0.88      3020\n",
      "weighted avg       0.89      0.89      0.88      3020\n",
      "\n",
      "acc:  0.8850993377483444\n",
      "pre:  0.9276437847866419\n",
      "rec:  0.7880220646178093\n",
      "ma F1:  0.8790950670616609\n",
      "mi F1:  0.8850993377483444\n",
      "we F1:  0.8833953025311727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.3497443199157715\n",
      "Eval Loss:  0.2921624183654785\n",
      "Eval Loss:  0.38027679920196533\n",
      "Eval Loss:  0.29653218388557434\n",
      "Eval Loss:  0.28553906083106995\n",
      "Eval Loss:  0.30335307121276855\n",
      "Eval Loss:  0.3821483850479126\n",
      "Eval Loss:  0.3717162609100342\n",
      "Eval Loss:  0.4473816156387329\n",
      "Eval Loss:  0.2577405571937561\n",
      "Eval Loss:  0.3128097653388977\n",
      "Eval Loss:  0.3033272922039032\n",
      "Eval Loss:  0.2398490607738495\n",
      "Eval Loss:  0.3246442675590515\n",
      "Eval Loss:  0.2957316040992737\n",
      "Eval Loss:  0.2972263991832733\n",
      "Eval Loss:  0.36909395456314087\n",
      "Eval Loss:  0.25220656394958496\n",
      "Eval Loss:  0.2898397147655487\n",
      "Eval Loss:  0.39882826805114746\n",
      "Eval Loss:  0.3305627107620239\n",
      "Eval Loss:  0.4128150939941406\n",
      "Eval Loss:  0.37023067474365234\n",
      "Eval Loss:  0.31621253490448\n",
      "Eval Loss:  0.41012755036354065\n",
      "Eval Loss:  0.24249646067619324\n",
      "Eval Loss:  0.34939831495285034\n",
      "Eval Loss:  0.39954641461372375\n",
      "Eval Loss:  0.3417803943157196\n",
      "[[17669   744]\n",
      " [ 3445  8013]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89     18413\n",
      "           1       0.92      0.70      0.79     11458\n",
      "\n",
      "    accuracy                           0.86     29871\n",
      "   macro avg       0.88      0.83      0.84     29871\n",
      "weighted avg       0.87      0.86      0.86     29871\n",
      "\n",
      "acc:  0.8597636503632285\n",
      "pre:  0.9150393970537856\n",
      "rec:  0.6993367079769593\n",
      "ma F1:  0.843399724122112\n",
      "mi F1:  0.8597636503632285\n",
      "we F1:  0.8551862927848052\n",
      "29871 467\n",
      "Loss:  0.07031218707561493\n",
      "Loss:  0.06520656496286392\n",
      "Loss:  0.07908979058265686\n",
      "21 **********\n",
      "Epoch:  1154.501098871231  fold:  10  kers:  32\n",
      "epoch:  22\n",
      "29871 467\n",
      "Loss:  0.08521221578121185\n",
      "Loss:  0.06119796633720398\n",
      "Loss:  0.07029696553945541\n",
      "22 **********\n",
      "Epoch:  1194.1899785995483  fold:  10  kers:  32\n",
      "epoch:  23\n",
      "29871 467\n",
      "Loss:  0.07992936670780182\n",
      "Loss:  0.05669364333152771\n",
      "Loss:  0.08245279639959335\n",
      "23 **********\n",
      "Epoch:  1233.8599095344543  fold:  10  kers:  32\n",
      "epoch:  24\n",
      "Eval Loss:  0.5020297765731812\n",
      "Eval Loss:  0.12635886669158936\n",
      "Eval Loss:  0.09397602081298828\n",
      "[[1662   89]\n",
      " [ 208 1061]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1751\n",
      "           1       0.92      0.84      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.91      0.89      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9016556291390728\n",
      "pre:  0.922608695652174\n",
      "rec:  0.8360914105594957\n",
      "ma F1:  0.8976002257740691\n",
      "mi F1:  0.9016556291390728\n",
      "we F1:  0.9008526457772835\n",
      "update!  Acc:  0.9016556291390728\n",
      "Eval Loss:  0.29713600873947144\n",
      "Eval Loss:  0.2888716161251068\n",
      "Eval Loss:  0.34438082575798035\n",
      "Eval Loss:  0.2985868453979492\n",
      "Eval Loss:  0.26183292269706726\n",
      "Eval Loss:  0.27126091718673706\n",
      "Eval Loss:  0.36056262254714966\n",
      "Eval Loss:  0.32663077116012573\n",
      "Eval Loss:  0.41025203466415405\n",
      "Eval Loss:  0.22344651818275452\n",
      "Eval Loss:  0.2669355869293213\n",
      "Eval Loss:  0.2579127252101898\n",
      "Eval Loss:  0.24740540981292725\n",
      "Eval Loss:  0.2598208785057068\n",
      "Eval Loss:  0.2639380693435669\n",
      "Eval Loss:  0.2633875012397766\n",
      "Eval Loss:  0.33052536845207214\n",
      "Eval Loss:  0.20538902282714844\n",
      "Eval Loss:  0.23773546516895294\n",
      "Eval Loss:  0.35014083981513977\n",
      "Eval Loss:  0.2789672017097473\n",
      "Eval Loss:  0.394683837890625\n",
      "Eval Loss:  0.3363298773765564\n",
      "Eval Loss:  0.296907901763916\n",
      "Eval Loss:  0.3679152727127075\n",
      "Eval Loss:  0.23324093222618103\n",
      "Eval Loss:  0.3385772407054901\n",
      "Eval Loss:  0.32952550053596497\n",
      "Eval Loss:  0.2942175269126892\n",
      "[[17331  1082]\n",
      " [ 2679  8779]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     18413\n",
      "           1       0.89      0.77      0.82     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.88      0.85      0.86     29871\n",
      "weighted avg       0.88      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8740919286264269\n",
      "pre:  0.8902748199979718\n",
      "rec:  0.7661895618781638\n",
      "ma F1:  0.8628502580261814\n",
      "mi F1:  0.8740919286264269\n",
      "we F1:  0.8719926596895008\n",
      "29871 467\n",
      "Loss:  0.06707185506820679\n",
      "Loss:  0.06370637565851212\n",
      "Loss:  0.08484397083520889\n",
      "24 **********\n",
      "Epoch:  1311.921189546585  fold:  10  kers:  32\n",
      "epoch:  25\n",
      "29871 467\n",
      "Loss:  0.10993336141109467\n",
      "Loss:  0.06544485688209534\n",
      "Loss:  0.0672413557767868\n",
      "25 **********\n",
      "Epoch:  1351.453488111496  fold:  10  kers:  32\n",
      "epoch:  26\n",
      "29871 467\n",
      "Loss:  0.07699064910411835\n",
      "Loss:  0.049218498170375824\n",
      "Loss:  0.10025614500045776\n",
      "26 **********\n",
      "Epoch:  1391.0625813007355  fold:  10  kers:  32\n",
      "epoch:  27\n",
      "Eval Loss:  0.6182281970977783\n",
      "Eval Loss:  0.10715500265359879\n",
      "Eval Loss:  0.07662791013717651\n",
      "[[1669   82]\n",
      " [ 244 1025]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1751\n",
      "           1       0.93      0.81      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.88      0.89      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8920529801324504\n",
      "pre:  0.9259259259259259\n",
      "rec:  0.8077226162332545\n",
      "ma F1:  0.8869104068339877\n",
      "mi F1:  0.8920529801324504\n",
      "we F1:  0.8907593514455698\n",
      "Eval Loss:  0.30764269828796387\n",
      "Eval Loss:  0.2654467821121216\n",
      "Eval Loss:  0.3432525098323822\n",
      "Eval Loss:  0.28054720163345337\n",
      "Eval Loss:  0.25968238711357117\n",
      "Eval Loss:  0.2834838926792145\n",
      "Eval Loss:  0.3394092917442322\n",
      "Eval Loss:  0.34134525060653687\n",
      "Eval Loss:  0.4027387499809265\n",
      "Eval Loss:  0.22962230443954468\n",
      "Eval Loss:  0.2733211815357208\n",
      "Eval Loss:  0.27647140622138977\n",
      "Eval Loss:  0.24833986163139343\n",
      "Eval Loss:  0.2874383330345154\n",
      "Eval Loss:  0.285880982875824\n",
      "Eval Loss:  0.2728784680366516\n",
      "Eval Loss:  0.32975953817367554\n",
      "Eval Loss:  0.23264320194721222\n",
      "Eval Loss:  0.25187087059020996\n",
      "Eval Loss:  0.36288684606552124\n",
      "Eval Loss:  0.29893359541893005\n",
      "Eval Loss:  0.376714289188385\n",
      "Eval Loss:  0.33950862288475037\n",
      "Eval Loss:  0.28773242235183716\n",
      "Eval Loss:  0.3495147228240967\n",
      "Eval Loss:  0.2377997189760208\n",
      "Eval Loss:  0.3204626441001892\n",
      "Eval Loss:  0.3530657887458801\n",
      "Eval Loss:  0.29305487871170044\n",
      "[[17634   779]\n",
      " [ 3103  8355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     18413\n",
      "           1       0.91      0.73      0.81     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.88      0.84      0.86     29871\n",
      "weighted avg       0.88      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8700411770613639\n",
      "pre:  0.9147142544339829\n",
      "rec:  0.7291848490137894\n",
      "ma F1:  0.8561615491787906\n",
      "mi F1:  0.8700411770613639\n",
      "we F1:  0.8665649128950637\n",
      "29871 467\n",
      "Loss:  0.06592097133398056\n",
      "Loss:  0.07965333759784698\n",
      "Loss:  0.0627298355102539\n",
      "27 **********\n",
      "Epoch:  1468.9912159442902  fold:  10  kers:  32\n",
      "epoch:  28\n",
      "29871 467\n",
      "Loss:  0.10522562265396118\n",
      "Loss:  0.08747369050979614\n",
      "Loss:  0.08209151029586792\n",
      "28 **********\n",
      "Epoch:  1508.6013066768646  fold:  10  kers:  32\n",
      "epoch:  29\n",
      "29871 467\n",
      "Loss:  0.046722330152988434\n",
      "Loss:  0.059821292757987976\n",
      "Loss:  0.0751911848783493\n",
      "29 **********\n",
      "Epoch:  1548.126624584198  fold:  10  kers:  32\n",
      "epoch:  30\n",
      "Eval Loss:  0.624917209148407\n",
      "Eval Loss:  0.09968160837888718\n",
      "Eval Loss:  0.0664244070649147\n",
      "[[1672   79]\n",
      " [ 255 1014]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1751\n",
      "           1       0.93      0.80      0.86      1269\n",
      "\n",
      "    accuracy                           0.89      3020\n",
      "   macro avg       0.90      0.88      0.88      3020\n",
      "weighted avg       0.89      0.89      0.89      3020\n",
      "\n",
      "acc:  0.8894039735099337\n",
      "pre:  0.9277218664226898\n",
      "rec:  0.7990543735224587\n",
      "ma F1:  0.8838920942842055\n",
      "mi F1:  0.8894039735099337\n",
      "we F1:  0.8879296714677937\n",
      "Eval Loss:  0.29922574758529663\n",
      "Eval Loss:  0.26341503858566284\n",
      "Eval Loss:  0.36466845870018005\n",
      "Eval Loss:  0.27686065435409546\n",
      "Eval Loss:  0.26023197174072266\n",
      "Eval Loss:  0.2918941378593445\n",
      "Eval Loss:  0.33940020203590393\n",
      "Eval Loss:  0.3232594430446625\n",
      "Eval Loss:  0.4145016670227051\n",
      "Eval Loss:  0.22809629142284393\n",
      "Eval Loss:  0.2774318754673004\n",
      "Eval Loss:  0.28677740693092346\n",
      "Eval Loss:  0.2308478057384491\n",
      "Eval Loss:  0.30796709656715393\n",
      "Eval Loss:  0.2854269742965698\n",
      "Eval Loss:  0.2807295620441437\n",
      "Eval Loss:  0.34421566128730774\n",
      "Eval Loss:  0.23010464012622833\n",
      "Eval Loss:  0.2595829367637634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.36710286140441895\n",
      "Eval Loss:  0.3147123456001282\n",
      "Eval Loss:  0.3933536112308502\n",
      "Eval Loss:  0.3616689443588257\n",
      "Eval Loss:  0.2882269024848938\n",
      "Eval Loss:  0.3754023313522339\n",
      "Eval Loss:  0.22544455528259277\n",
      "Eval Loss:  0.33594974875450134\n",
      "Eval Loss:  0.35389140248298645\n",
      "Eval Loss:  0.2870205044746399\n",
      "[[17690   723]\n",
      " [ 3147  8311]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     18413\n",
      "           1       0.92      0.73      0.81     11458\n",
      "\n",
      "    accuracy                           0.87     29871\n",
      "   macro avg       0.88      0.84      0.86     29871\n",
      "weighted avg       0.88      0.87      0.87     29871\n",
      "\n",
      "acc:  0.8704429044893041\n",
      "pre:  0.9199690059774186\n",
      "rec:  0.7253447373014488\n",
      "ma F1:  0.8562735434427727\n",
      "mi F1:  0.8704429044893041\n",
      "we F1:  0.8667808369792505\n",
      "29871 467\n",
      "Loss:  0.07091591507196426\n",
      "Loss:  0.06353817135095596\n",
      "Loss:  0.09497825801372528\n",
      "30 **********\n",
      "Epoch:  1626.0223472118378  fold:  10  kers:  32\n",
      "epoch:  31\n",
      "29871 467\n",
      "Loss:  0.06072227284312248\n",
      "Loss:  0.07839735597372055\n",
      "Loss:  0.08088404685258865\n",
      "31 **********\n",
      "Epoch:  1665.610496044159  fold:  10  kers:  32\n",
      "epoch:  32\n",
      "29871 467\n",
      "Loss:  0.07913078367710114\n",
      "Loss:  0.08401554822921753\n",
      "Loss:  0.09265508502721786\n",
      "32 **********\n",
      "Epoch:  1705.1398026943207  fold:  10  kers:  32\n",
      "epoch:  33\n",
      "Eval Loss:  0.5087336897850037\n",
      "Eval Loss:  0.11117637902498245\n",
      "Eval Loss:  0.07431913912296295\n",
      "[[1662   89]\n",
      " [ 205 1064]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1751\n",
      "           1       0.92      0.84      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.91      0.89      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9026490066225166\n",
      "pre:  0.9228100607111882\n",
      "rec:  0.8384554767533491\n",
      "ma F1:  0.8986761759602757\n",
      "mi F1:  0.9026490066225166\n",
      "we F1:  0.9018783571963962\n",
      "update!  Acc:  0.9026490066225166\n",
      "Eval Loss:  0.2555215060710907\n",
      "Eval Loss:  0.2619383931159973\n",
      "Eval Loss:  0.3401574194431305\n",
      "Eval Loss:  0.24906671047210693\n",
      "Eval Loss:  0.231121227145195\n",
      "Eval Loss:  0.27897408604621887\n",
      "Eval Loss:  0.31474289298057556\n",
      "Eval Loss:  0.29193952679634094\n",
      "Eval Loss:  0.37945839762687683\n",
      "Eval Loss:  0.21449698507785797\n",
      "Eval Loss:  0.23097053170204163\n",
      "Eval Loss:  0.2515246868133545\n",
      "Eval Loss:  0.2267966866493225\n",
      "Eval Loss:  0.2855238616466522\n",
      "Eval Loss:  0.2522907257080078\n",
      "Eval Loss:  0.25189343094825745\n",
      "Eval Loss:  0.30784302949905396\n",
      "Eval Loss:  0.1953955590724945\n",
      "Eval Loss:  0.2384108006954193\n",
      "Eval Loss:  0.34894031286239624\n",
      "Eval Loss:  0.28801465034484863\n",
      "Eval Loss:  0.37623271346092224\n",
      "Eval Loss:  0.3410206437110901\n",
      "Eval Loss:  0.2706455886363983\n",
      "Eval Loss:  0.34252238273620605\n",
      "Eval Loss:  0.2252987027168274\n",
      "Eval Loss:  0.3133946359157562\n",
      "Eval Loss:  0.3129103183746338\n",
      "Eval Loss:  0.2556353509426117\n",
      "[[17447   966]\n",
      " [ 2568  8890]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     18413\n",
      "           1       0.90      0.78      0.83     11458\n",
      "\n",
      "    accuracy                           0.88     29871\n",
      "   macro avg       0.89      0.86      0.87     29871\n",
      "weighted avg       0.88      0.88      0.88     29871\n",
      "\n",
      "acc:  0.881691272471628\n",
      "pre:  0.9019886363636364\n",
      "rec:  0.7758771164252051\n",
      "ma F1:  0.8711146475361309\n",
      "mi F1:  0.881691272471628\n",
      "we F1:  0.8797111680954838\n",
      "29871 467\n",
      "Loss:  0.06508640199899673\n",
      "Loss:  0.08984449505805969\n",
      "Loss:  0.06684780865907669\n",
      "33 **********\n",
      "Epoch:  1783.2698991298676  fold:  10  kers:  32\n",
      "epoch:  34\n",
      "29871 467\n",
      "Loss:  0.06598173826932907\n",
      "Loss:  0.09118577092885971\n",
      "Loss:  0.09863046556711197\n",
      "34 **********\n",
      "Epoch:  1822.8899626731873  fold:  10  kers:  32\n",
      "epoch:  35\n",
      "29871 467\n",
      "Loss:  0.08285069465637207\n",
      "Loss:  0.08332797139883041\n",
      "Loss:  0.08104939013719559\n",
      "35 **********\n",
      "Epoch:  1862.5020480155945  fold:  10  kers:  32\n",
      "epoch:  36\n",
      "Eval Loss:  0.34688910841941833\n",
      "Eval Loss:  0.14219103753566742\n",
      "Eval Loss:  0.08290001004934311\n",
      "[[1636  115]\n",
      " [ 160 1109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1751\n",
      "           1       0.91      0.87      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9089403973509934\n",
      "pre:  0.9060457516339869\n",
      "rec:  0.8739164696611506\n",
      "ma F1:  0.9060804139382772\n",
      "mi F1:  0.9089403973509934\n",
      "we F1:  0.9086961862436456\n",
      "update!  Acc:  0.9089403973509934\n",
      "Eval Loss:  0.22679094970226288\n",
      "Eval Loss:  0.27160125970840454\n",
      "Eval Loss:  0.331210732460022\n",
      "Eval Loss:  0.2753230631351471\n",
      "Eval Loss:  0.23256516456604004\n",
      "Eval Loss:  0.27572160959243774\n",
      "Eval Loss:  0.31726157665252686\n",
      "Eval Loss:  0.26884520053863525\n",
      "Eval Loss:  0.3656909465789795\n",
      "Eval Loss:  0.21869808435440063\n",
      "Eval Loss:  0.21646186709403992\n",
      "Eval Loss:  0.2122112214565277\n",
      "Eval Loss:  0.2659749984741211\n",
      "Eval Loss:  0.23377476632595062\n",
      "Eval Loss:  0.24851106107234955\n",
      "Eval Loss:  0.232471764087677\n",
      "Eval Loss:  0.2812383770942688\n",
      "Eval Loss:  0.1646689772605896\n",
      "Eval Loss:  0.2326989471912384\n",
      "Eval Loss:  0.32337045669555664\n",
      "Eval Loss:  0.2788929045200348\n",
      "Eval Loss:  0.3504860997200012\n",
      "Eval Loss:  0.31916531920433044\n",
      "Eval Loss:  0.2859712839126587\n",
      "Eval Loss:  0.3274509310722351\n",
      "Eval Loss:  0.2251555323600769\n",
      "Eval Loss:  0.32554230093955994\n",
      "Eval Loss:  0.2833852469921112\n",
      "Eval Loss:  0.26217120885849\n",
      "[[16944  1469]\n",
      " [ 1940  9518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     18413\n",
      "           1       0.87      0.83      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.88      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8858759331793378\n",
      "pre:  0.8662965322654046\n",
      "rec:  0.83068598359225\n",
      "ma F1:  0.8783580838254899\n",
      "mi F1:  0.8858759331793378\n",
      "we F1:  0.8853991075604768\n",
      "29871 467\n",
      "Loss:  0.07045242190361023\n",
      "Loss:  0.050047483295202255\n",
      "Loss:  0.06193165481090546\n",
      "36 **********\n",
      "Epoch:  1940.5742988586426  fold:  10  kers:  32\n",
      "epoch:  37\n",
      "29871 467\n",
      "Loss:  0.07631753385066986\n",
      "Loss:  0.06439859420061111\n",
      "Loss:  0.08756079524755478\n",
      "37 **********\n",
      "Epoch:  1980.263179063797  fold:  10  kers:  32\n",
      "epoch:  38\n",
      "29871 467\n",
      "Loss:  0.0816965326666832\n",
      "Loss:  0.07119858264923096\n",
      "Loss:  0.054168086498975754\n",
      "38 **********\n",
      "Epoch:  2019.9241335391998  fold:  10  kers:  32\n",
      "epoch:  39\n",
      "Eval Loss:  0.3446182608604431\n",
      "Eval Loss:  0.14591434597969055\n",
      "Eval Loss:  0.08090677857398987\n",
      "[[1620  131]\n",
      " [ 159 1110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1751\n",
      "           1       0.89      0.87      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.90      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9039735099337748\n",
      "pre:  0.8944399677679291\n",
      "rec:  0.8747044917257684\n",
      "ma F1:  0.9011545884450864\n",
      "mi F1:  0.9039735099337748\n",
      "we F1:  0.9038187456167487\n",
      "Eval Loss:  0.22736331820487976\n",
      "Eval Loss:  0.24604108929634094\n",
      "Eval Loss:  0.30244752764701843\n",
      "Eval Loss:  0.27618682384490967\n",
      "Eval Loss:  0.2302442193031311\n",
      "Eval Loss:  0.2614000141620636\n",
      "Eval Loss:  0.3016873896121979\n",
      "Eval Loss:  0.28070443868637085\n",
      "Eval Loss:  0.3655773997306824\n",
      "Eval Loss:  0.21619854867458344\n",
      "Eval Loss:  0.20019853115081787\n",
      "Eval Loss:  0.2174389511346817\n",
      "Eval Loss:  0.2532435357570648\n",
      "Eval Loss:  0.2159404754638672\n",
      "Eval Loss:  0.2444189041852951\n",
      "Eval Loss:  0.23237742483615875\n",
      "Eval Loss:  0.26808565855026245\n",
      "Eval Loss:  0.1766539216041565\n",
      "Eval Loss:  0.21444585919380188\n",
      "Eval Loss:  0.3238602578639984\n",
      "Eval Loss:  0.2533990144729614\n",
      "Eval Loss:  0.3311415910720825\n",
      "Eval Loss:  0.3019214868545532\n",
      "Eval Loss:  0.2512439489364624\n",
      "Eval Loss:  0.30894067883491516\n",
      "Eval Loss:  0.22248120605945587\n",
      "Eval Loss:  0.3024989366531372\n",
      "Eval Loss:  0.2753369212150574\n",
      "Eval Loss:  0.24728669226169586\n",
      "[[17017  1396]\n",
      " [ 1852  9606]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     18413\n",
      "           1       0.87      0.84      0.86     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8912657761708681\n",
      "pre:  0.8731139792764951\n",
      "rec:  0.8383662070169314\n",
      "ma F1:  0.8841337827937278\n",
      "mi F1:  0.8912657761708681\n",
      "we F1:  0.8908269434924202\n",
      "29871 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.06050632521510124\n",
      "Loss:  0.06063065305352211\n",
      "Loss:  0.0719342976808548\n",
      "39 **********\n",
      "Epoch:  2097.921583890915  fold:  10  kers:  32\n",
      "epoch:  40\n",
      "29871 467\n",
      "Loss:  0.050677064806222916\n",
      "Loss:  0.07389943301677704\n",
      "Loss:  0.05570918694138527\n",
      "40 **********\n",
      "Epoch:  2137.554613351822  fold:  10  kers:  32\n",
      "epoch:  41\n",
      "29871 467\n",
      "Loss:  0.07718376815319061\n",
      "Loss:  0.0832846388220787\n",
      "Loss:  0.0576559416949749\n",
      "41 **********\n",
      "Epoch:  2177.108853340149  fold:  10  kers:  32\n",
      "epoch:  42\n",
      "Eval Loss:  0.4281952679157257\n",
      "Eval Loss:  0.11946528404951096\n",
      "Eval Loss:  0.06839382648468018\n",
      "[[1634  117]\n",
      " [ 179 1090]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      1751\n",
      "           1       0.90      0.86      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.90      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9019867549668874\n",
      "pre:  0.9030654515327258\n",
      "rec:  0.8589440504334122\n",
      "ma F1:  0.8986997963842337\n",
      "mi F1:  0.9019867549668874\n",
      "we F1:  0.9016121383637175\n",
      "Eval Loss:  0.23491381108760834\n",
      "Eval Loss:  0.2736510634422302\n",
      "Eval Loss:  0.344422310590744\n",
      "Eval Loss:  0.2588629126548767\n",
      "Eval Loss:  0.22514623403549194\n",
      "Eval Loss:  0.2881557047367096\n",
      "Eval Loss:  0.3103824555873871\n",
      "Eval Loss:  0.27169129252433777\n",
      "Eval Loss:  0.3476853668689728\n",
      "Eval Loss:  0.21900010108947754\n",
      "Eval Loss:  0.1903540939092636\n",
      "Eval Loss:  0.21083498001098633\n",
      "Eval Loss:  0.2564682960510254\n",
      "Eval Loss:  0.24398989975452423\n",
      "Eval Loss:  0.23527935147285461\n",
      "Eval Loss:  0.24883297085762024\n",
      "Eval Loss:  0.2823801636695862\n",
      "Eval Loss:  0.18055793642997742\n",
      "Eval Loss:  0.2314044088125229\n",
      "Eval Loss:  0.3332062363624573\n",
      "Eval Loss:  0.2880818843841553\n",
      "Eval Loss:  0.35074082016944885\n",
      "Eval Loss:  0.3206107020378113\n",
      "Eval Loss:  0.26834559440612793\n",
      "Eval Loss:  0.34227320551872253\n",
      "Eval Loss:  0.2296314835548401\n",
      "Eval Loss:  0.3304518163204193\n",
      "Eval Loss:  0.26776859164237976\n",
      "Eval Loss:  0.23030492663383484\n",
      "[[17041  1372]\n",
      " [ 1932  9526]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     18413\n",
      "           1       0.87      0.83      0.85     11458\n",
      "\n",
      "    accuracy                           0.89     29871\n",
      "   macro avg       0.89      0.88      0.88     29871\n",
      "weighted avg       0.89      0.89      0.89     29871\n",
      "\n",
      "acc:  0.8893910481738141\n",
      "pre:  0.8741053404294366\n",
      "rec:  0.8313841857217664\n",
      "ma F1:  0.8819171849787821\n",
      "mi F1:  0.8893910481738141\n",
      "we F1:  0.8888341135910839\n",
      "29871 467\n",
      "Loss:  0.053302422165870667\n",
      "Loss:  0.0954500362277031\n",
      "Loss:  0.06537850946187973\n",
      "42 **********\n",
      "Epoch:  2255.1771149635315  fold:  10  kers:  32\n",
      "epoch:  43\n",
      "29871 467\n",
      "Loss:  0.05294185131788254\n",
      "Loss:  0.07449176162481308\n",
      "Loss:  0.06435533612966537\n",
      "43 **********\n",
      "Epoch:  2294.7842135429382  fold:  10  kers:  32\n",
      "epoch:  44\n",
      "29871 467\n",
      "Loss:  0.04950372129678726\n",
      "Loss:  0.07349098473787308\n",
      "Loss:  0.06755779683589935\n",
      "44 **********\n",
      "Epoch:  2334.364384174347  fold:  10  kers:  32\n",
      "epoch:  45\n",
      "Eval Loss:  0.3464004397392273\n",
      "Eval Loss:  0.14160500466823578\n",
      "Eval Loss:  0.06357332319021225\n",
      "[[1621  130]\n",
      " [ 152 1117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1751\n",
      "           1       0.90      0.88      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.90      0.90      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9066225165562913\n",
      "pre:  0.8957497995188453\n",
      "rec:  0.880220646178093\n",
      "ma F1:  0.9039473138091019\n",
      "mi F1:  0.9066225165562913\n",
      "we F1:  0.9065057418331998\n",
      "Eval Loss:  0.21588344871997833\n",
      "Eval Loss:  0.25611934065818787\n",
      "Eval Loss:  0.3192251920700073\n",
      "Eval Loss:  0.2577124238014221\n",
      "Eval Loss:  0.21212482452392578\n",
      "Eval Loss:  0.2659316658973694\n",
      "Eval Loss:  0.2854693830013275\n",
      "Eval Loss:  0.26950275897979736\n",
      "Eval Loss:  0.3349147439002991\n",
      "Eval Loss:  0.21413683891296387\n",
      "Eval Loss:  0.1881314516067505\n",
      "Eval Loss:  0.2001858502626419\n",
      "Eval Loss:  0.24949398636817932\n",
      "Eval Loss:  0.2195187211036682\n",
      "Eval Loss:  0.23869873583316803\n",
      "Eval Loss:  0.23668372631072998\n",
      "Eval Loss:  0.2558812201023102\n",
      "Eval Loss:  0.1764943152666092\n",
      "Eval Loss:  0.21870926022529602\n",
      "Eval Loss:  0.3212207555770874\n",
      "Eval Loss:  0.26709693670272827\n",
      "Eval Loss:  0.3223491311073303\n",
      "Eval Loss:  0.29437974095344543\n",
      "Eval Loss:  0.2523563802242279\n",
      "Eval Loss:  0.29833707213401794\n",
      "Eval Loss:  0.2419513463973999\n",
      "Eval Loss:  0.3079547584056854\n",
      "Eval Loss:  0.2660585343837738\n",
      "Eval Loss:  0.227213054895401\n",
      "[[17001  1412]\n",
      " [ 1668  9790]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     18413\n",
      "           1       0.87      0.85      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.89      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.89688996016203\n",
      "pre:  0.8739510801642564\n",
      "rec:  0.8544248559958108\n",
      "ma F1:  0.8905092518653229\n",
      "mi F1:  0.89688996016203\n",
      "we F1:  0.8966634366113495\n",
      "29871 467\n",
      "Loss:  0.06872393190860748\n",
      "Loss:  0.1212008073925972\n",
      "Loss:  0.0680278092622757\n",
      "45 **********\n",
      "Epoch:  2412.542351961136  fold:  10  kers:  32\n",
      "epoch:  46\n",
      "29871 467\n",
      "Loss:  0.079190194606781\n",
      "Loss:  0.061368394643068314\n",
      "Loss:  0.11564754694700241\n",
      "46 **********\n",
      "Epoch:  2452.2182669639587  fold:  10  kers:  32\n",
      "epoch:  47\n",
      "29871 467\n",
      "Loss:  0.07071535289287567\n",
      "Loss:  0.07003547996282578\n",
      "Loss:  0.06680989265441895\n",
      "47 **********\n",
      "Epoch:  2492.0298187732697  fold:  10  kers:  32\n",
      "epoch:  48\n",
      "Eval Loss:  0.4476667046546936\n",
      "Eval Loss:  0.1213114932179451\n",
      "Eval Loss:  0.04558679834008217\n",
      "[[1638  113]\n",
      " [ 200 1069]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      1751\n",
      "           1       0.90      0.84      0.87      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.89      0.89      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8963576158940397\n",
      "pre:  0.9043993231810491\n",
      "rec:  0.8423955870764381\n",
      "ma F1:  0.8925430496806792\n",
      "mi F1:  0.8963576158940397\n",
      "we F1:  0.8957743693904151\n",
      "Eval Loss:  0.21493901312351227\n",
      "Eval Loss:  0.22464103996753693\n",
      "Eval Loss:  0.32717639207839966\n",
      "Eval Loss:  0.25019747018814087\n",
      "Eval Loss:  0.20977433025836945\n",
      "Eval Loss:  0.25669723749160767\n",
      "Eval Loss:  0.2627474069595337\n",
      "Eval Loss:  0.2857063412666321\n",
      "Eval Loss:  0.3278427720069885\n",
      "Eval Loss:  0.20297561585903168\n",
      "Eval Loss:  0.19939282536506653\n",
      "Eval Loss:  0.1987588107585907\n",
      "Eval Loss:  0.23118670284748077\n",
      "Eval Loss:  0.23024573922157288\n",
      "Eval Loss:  0.23959268629550934\n",
      "Eval Loss:  0.23334741592407227\n",
      "Eval Loss:  0.2614274322986603\n",
      "Eval Loss:  0.19008931517601013\n",
      "Eval Loss:  0.22690768539905548\n",
      "Eval Loss:  0.3094245195388794\n",
      "Eval Loss:  0.25660428404808044\n",
      "Eval Loss:  0.3216095566749573\n",
      "Eval Loss:  0.30295950174331665\n",
      "Eval Loss:  0.2503524124622345\n",
      "Eval Loss:  0.2834375202655792\n",
      "Eval Loss:  0.22490450739860535\n",
      "Eval Loss:  0.282914400100708\n",
      "Eval Loss:  0.2649756371974945\n",
      "Eval Loss:  0.22292090952396393\n",
      "[[17357  1056]\n",
      " [ 2013  9445]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     18413\n",
      "           1       0.90      0.82      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.88      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.8972582103043085\n",
      "pre:  0.8994381487477383\n",
      "rec:  0.824314889160412\n",
      "ma F1:  0.8895062652323076\n",
      "mi F1:  0.8972582103043085\n",
      "we F1:  0.8963205698298512\n",
      "29871 467\n",
      "Loss:  0.060050033032894135\n",
      "Loss:  0.06093377247452736\n",
      "Loss:  0.07855665683746338\n",
      "48 **********\n",
      "Epoch:  2569.970421552658  fold:  10  kers:  32\n",
      "epoch:  49\n",
      "29871 467\n",
      "Loss:  0.05785084888339043\n",
      "Loss:  0.08568903058767319\n",
      "Loss:  0.050667837262153625\n",
      "49 **********\n",
      "Epoch:  2609.6443412303925  fold:  10  kers:  32\n",
      "epoch:  50\n",
      "29871 467\n",
      "Loss:  0.08859290182590485\n",
      "Loss:  0.059778232127428055\n",
      "Loss:  0.06347811222076416\n",
      "50 **********\n",
      "Epoch:  2649.2454566955566  fold:  10  kers:  32\n",
      "epoch:  51\n",
      "Eval Loss:  0.34445586800575256\n",
      "Eval Loss:  0.1484532207250595\n",
      "Eval Loss:  0.05814965069293976\n",
      "[[1610  141]\n",
      " [ 151 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      1751\n",
      "           1       0.89      0.88      0.88      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.90      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.9033112582781457\n",
      "pre:  0.8880063542494043\n",
      "rec:  0.8810086682427108\n",
      "ma F1:  0.9006750814567055\n",
      "mi F1:  0.9033112582781457\n",
      "we F1:  0.9032576774484417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss:  0.2169077843427658\n",
      "Eval Loss:  0.27631062269210815\n",
      "Eval Loss:  0.35478919744491577\n",
      "Eval Loss:  0.2686784565448761\n",
      "Eval Loss:  0.21162205934524536\n",
      "Eval Loss:  0.25964000821113586\n",
      "Eval Loss:  0.2818957567214966\n",
      "Eval Loss:  0.23737046122550964\n",
      "Eval Loss:  0.3134908378124237\n",
      "Eval Loss:  0.22147566080093384\n",
      "Eval Loss:  0.17583875358104706\n",
      "Eval Loss:  0.1937117725610733\n",
      "Eval Loss:  0.2564413547515869\n",
      "Eval Loss:  0.203629732131958\n",
      "Eval Loss:  0.23305152356624603\n",
      "Eval Loss:  0.23574812710285187\n",
      "Eval Loss:  0.26763156056404114\n",
      "Eval Loss:  0.17134802043437958\n",
      "Eval Loss:  0.23370429873466492\n",
      "Eval Loss:  0.306948721408844\n",
      "Eval Loss:  0.26806819438934326\n",
      "Eval Loss:  0.3320852518081665\n",
      "Eval Loss:  0.32087501883506775\n",
      "Eval Loss:  0.2669469118118286\n",
      "Eval Loss:  0.3203216791152954\n",
      "Eval Loss:  0.22983410954475403\n",
      "Eval Loss:  0.29739314317703247\n",
      "Eval Loss:  0.24498701095581055\n",
      "Eval Loss:  0.22953130304813385\n",
      "[[16954  1459]\n",
      " [ 1615  9843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     18413\n",
      "           1       0.87      0.86      0.86     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.89      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.8970908238760001\n",
      "pre:  0.8709078039285082\n",
      "rec:  0.8590504451038575\n",
      "ma F1:  0.8909084849999225\n",
      "mi F1:  0.8970908238760001\n",
      "we F1:  0.8969551966977315\n",
      "29871 467\n",
      "Loss:  0.05671851709485054\n",
      "Loss:  0.07898171246051788\n",
      "Loss:  0.060200560837984085\n",
      "51 **********\n",
      "Epoch:  2727.4134509563446  fold:  10  kers:  32\n",
      "epoch:  52\n",
      "29871 467\n",
      "Loss:  0.06445442885160446\n",
      "Loss:  0.07794156670570374\n",
      "Loss:  0.057367920875549316\n",
      "52 **********\n",
      "Epoch:  2767.041493654251  fold:  10  kers:  32\n",
      "epoch:  53\n",
      "29871 467\n",
      "Loss:  0.04173244163393974\n",
      "Loss:  0.07569052278995514\n",
      "Loss:  0.07419976592063904\n",
      "53 **********\n",
      "Epoch:  2806.755306959152  fold:  10  kers:  32\n",
      "epoch:  54\n",
      "Eval Loss:  0.20591318607330322\n",
      "Eval Loss:  0.2549334168434143\n",
      "Eval Loss:  0.05959505960345268\n",
      "[[1589  162]\n",
      " [ 103 1166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92      1751\n",
      "           1       0.88      0.92      0.90      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9122516556291391\n",
      "pre:  0.8780120481927711\n",
      "rec:  0.9188337273443656\n",
      "ma F1:  0.9104957114998192\n",
      "mi F1:  0.9122516556291391\n",
      "we F1:  0.9124965745502499\n",
      "update!  Acc:  0.9122516556291391\n",
      "Eval Loss:  0.20938020944595337\n",
      "Eval Loss:  0.28424614667892456\n",
      "Eval Loss:  0.36178314685821533\n",
      "Eval Loss:  0.2939082086086273\n",
      "Eval Loss:  0.2135293036699295\n",
      "Eval Loss:  0.26735833287239075\n",
      "Eval Loss:  0.2837104797363281\n",
      "Eval Loss:  0.23802676796913147\n",
      "Eval Loss:  0.32011592388153076\n",
      "Eval Loss:  0.21974822878837585\n",
      "Eval Loss:  0.18537162244319916\n",
      "Eval Loss:  0.2013893872499466\n",
      "Eval Loss:  0.24933966994285583\n",
      "Eval Loss:  0.2262529581785202\n",
      "Eval Loss:  0.23722442984580994\n",
      "Eval Loss:  0.23705188930034637\n",
      "Eval Loss:  0.2543039917945862\n",
      "Eval Loss:  0.1704222857952118\n",
      "Eval Loss:  0.21555304527282715\n",
      "Eval Loss:  0.2955459654331207\n",
      "Eval Loss:  0.250662624835968\n",
      "Eval Loss:  0.31582245230674744\n",
      "Eval Loss:  0.31733280420303345\n",
      "Eval Loss:  0.29562345147132874\n",
      "Eval Loss:  0.3122154474258423\n",
      "Eval Loss:  0.2310800701379776\n",
      "Eval Loss:  0.29185572266578674\n",
      "Eval Loss:  0.2279445379972458\n",
      "Eval Loss:  0.24756108224391937\n",
      "[[16668  1745]\n",
      " [ 1371 10087]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91     18413\n",
      "           1       0.85      0.88      0.87     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.89      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.8956847778782097\n",
      "pre:  0.8525185936443543\n",
      "rec:  0.8803456100541107\n",
      "ma F1:  0.8903631975930092\n",
      "mi F1:  0.8956847778782097\n",
      "we F1:  0.8959872047170889\n",
      "29871 467\n",
      "Loss:  0.0566534660756588\n",
      "Loss:  0.03796898573637009\n",
      "Loss:  0.06872551143169403\n",
      "54 **********\n",
      "Epoch:  2885.0360000133514  fold:  10  kers:  32\n",
      "epoch:  55\n",
      "29871 467\n",
      "Loss:  0.06420137733221054\n",
      "Loss:  0.07928328216075897\n",
      "Loss:  0.09613832086324692\n",
      "55 **********\n",
      "Epoch:  2924.823616027832  fold:  10  kers:  32\n",
      "epoch:  56\n",
      "29871 467\n",
      "Loss:  0.048000842332839966\n",
      "Loss:  0.06877681612968445\n",
      "Loss:  0.05170322209596634\n",
      "56 **********\n",
      "Epoch:  2964.663093805313  fold:  10  kers:  32\n",
      "epoch:  57\n",
      "Eval Loss:  0.2720729112625122\n",
      "Eval Loss:  0.16944235563278198\n",
      "Eval Loss:  0.05387056618928909\n",
      "[[1620  131]\n",
      " [ 140 1129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      1751\n",
      "           1       0.90      0.89      0.89      1269\n",
      "\n",
      "    accuracy                           0.91      3020\n",
      "   macro avg       0.91      0.91      0.91      3020\n",
      "weighted avg       0.91      0.91      0.91      3020\n",
      "\n",
      "acc:  0.9102649006622516\n",
      "pre:  0.8960317460317461\n",
      "rec:  0.8896769109535066\n",
      "ma F1:  0.9078285170292901\n",
      "mi F1:  0.9102649006622516\n",
      "we F1:  0.9102202418991221\n",
      "Eval Loss:  0.20246614515781403\n",
      "Eval Loss:  0.23501835763454437\n",
      "Eval Loss:  0.329706609249115\n",
      "Eval Loss:  0.23990130424499512\n",
      "Eval Loss:  0.2035883665084839\n",
      "Eval Loss:  0.2538391649723053\n",
      "Eval Loss:  0.25944891571998596\n",
      "Eval Loss:  0.23436886072158813\n",
      "Eval Loss:  0.3301088213920593\n",
      "Eval Loss:  0.21348166465759277\n",
      "Eval Loss:  0.1781708002090454\n",
      "Eval Loss:  0.18128648400306702\n",
      "Eval Loss:  0.22230370342731476\n",
      "Eval Loss:  0.21317410469055176\n",
      "Eval Loss:  0.2359568029642105\n",
      "Eval Loss:  0.23320506513118744\n",
      "Eval Loss:  0.25348180532455444\n",
      "Eval Loss:  0.1721869707107544\n",
      "Eval Loss:  0.21590477228164673\n",
      "Eval Loss:  0.2998937964439392\n",
      "Eval Loss:  0.22995752096176147\n",
      "Eval Loss:  0.2975541353225708\n",
      "Eval Loss:  0.284704327583313\n",
      "Eval Loss:  0.24215485155582428\n",
      "Eval Loss:  0.28538763523101807\n",
      "Eval Loss:  0.22915706038475037\n",
      "Eval Loss:  0.2849615216255188\n",
      "Eval Loss:  0.22915081679821014\n",
      "Eval Loss:  0.2339773327112198\n",
      "[[17135  1278]\n",
      " [ 1672  9786]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     18413\n",
      "           1       0.88      0.85      0.87     11458\n",
      "\n",
      "    accuracy                           0.90     29871\n",
      "   macro avg       0.90      0.89      0.89     29871\n",
      "weighted avg       0.90      0.90      0.90     29871\n",
      "\n",
      "acc:  0.9012420072980483\n",
      "pre:  0.8844902386117137\n",
      "rec:  0.8540757549310526\n",
      "ma F1:  0.8948792490008337\n",
      "mi F1:  0.9012420072980483\n",
      "we F1:  0.9009008824145127\n",
      "29871 467\n",
      "Loss:  0.04499238356947899\n",
      "Loss:  0.059838876128196716\n",
      "Loss:  0.06990952044725418\n",
      "57 **********\n",
      "Epoch:  3042.5428595542908  fold:  10  kers:  32\n",
      "epoch:  58\n",
      "29871 467\n",
      "Loss:  0.06172339618206024\n",
      "Loss:  0.06351058185100555\n",
      "Loss:  0.062199387699365616\n",
      "58 **********\n",
      "Epoch:  3082.1250240802765  fold:  10  kers:  32\n",
      "epoch:  59\n",
      "29871 467\n",
      "Loss:  0.09099219739437103\n",
      "Loss:  0.06278443336486816\n",
      "Loss:  0.08216328173875809\n",
      "59 **********\n",
      "Epoch:  3123.8484642505646  fold:  10  kers:  32\n",
      "Eval Loss:  0.21697404980659485\n",
      "Eval Loss:  0.22249524295330048\n",
      "Eval Loss:  0.0656336322426796\n",
      "[[1551  200]\n",
      " [ 103 1166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      1751\n",
      "           1       0.85      0.92      0.89      1269\n",
      "\n",
      "    accuracy                           0.90      3020\n",
      "   macro avg       0.90      0.90      0.90      3020\n",
      "weighted avg       0.90      0.90      0.90      3020\n",
      "\n",
      "acc:  0.8996688741721854\n",
      "pre:  0.8535871156661786\n",
      "rec:  0.9188337273443656\n",
      "ma F1:  0.8980113517625324\n",
      "mi F1:  0.8996688741721854\n",
      "we F1:  0.9000864837143578\n",
      "update!  Acc:  0.9122516556291391\n",
      "Epoch:  3127.393984079361  fold:  10  kers:  32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from time import time\n",
    "for kers in [128,64,32]:\n",
    "    print(\"  \")\n",
    "    print(\"kernel:\",kers)\n",
    "    print(\"  \")\n",
    "    for fold in range(1,11):\n",
    "        begin=time()\n",
    "        #train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "        train_dtlist,test_dtlist=getTrainTestList(reclist,opt='kfold',fold = fold)#fold 1-10   \n",
    "        print('*********')\n",
    "\n",
    "        train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "        np.random.shuffle(train_dtlist)\n",
    "        test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "        print(len(train_dtlist),len(test_dtlist))\n",
    "        model = MyLSTM(2,kers).to(device)\n",
    "\n",
    "        #model.features[0]=nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if(m.in_channels!=m.out_channels or m.out_channels!=m.groups or m.bias is not None):\n",
    "                    # don't want to reinitialize downsample layers, code assuming normal conv layers will not have these characteristics\n",
    "                    #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                    print(m,'init')\n",
    "                else:\n",
    "                    print('Not initializing')\n",
    "        criterion=nn.CrossEntropyLoss().to(device)#weight=torch.FloatTensor([1,1.5])\n",
    "        #criterion = CircleLoss(m=0.25, gamma=256)\n",
    "        opt=torch.optim.Adam(model.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001)\n",
    "        loss_list=[]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        epoch_flag=0\n",
    "        best_acc=0\n",
    "        for epoch in range(60):\n",
    "            print('epoch: ', epoch)\n",
    "            if epoch_flag%3==0 and epoch_flag!=0:\n",
    "                model.eval()\n",
    "                prob_file,lab_file,tmp_acc,seg_file=eval(model,test_dtlist,criterion,device)\n",
    "                if tmp_acc>best_acc:\n",
    "                    best_acc=tmp_acc                   \n",
    "                    res_file_name=\"./weights/fold_%.0f_w_%.0f_fs_%.0f.csv\"%(fold,kers,28)\n",
    "                    res_file=pd.DataFrame({\"prob\":prob_file,'label':lab_file,'seg':seg_file})\n",
    "                    res_file.to_csv(res_file_name,index=False)\n",
    "                    torch.save(model.state_dict(), \"./weights/fold_%.0f_w_%.0f_fs_%.0f.pkl\"%(fold,kers,28))\n",
    "                    print(\"update! \",'Acc: ',best_acc)\n",
    "                #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "                _,_,_,_=eval(model,train_dtlist,criterion,device)\n",
    "                model.train()\n",
    "            train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "            #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "            train_loader=DataLoader(train_dataset, batch_size=64, shuffle=True, sampler=None, num_workers=0)\n",
    "\n",
    "            #test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "            print(len(train_dataset),len(train_loader)) #,len(test_dataset)\n",
    "            flag=0\n",
    "            accum_flag=0\n",
    "            for fe, label,seg_id in train_loader:\n",
    "                del seg_id\n",
    "                fe=fe.float().to(device)\n",
    "                #fe=(fe-fe_mean)/fe_std\n",
    "                #fe=torch.stft(fe,100,hop_length=50,onesided=True)\n",
    "\n",
    "                label=label.long().to(device)\n",
    "                pred_prob_no_softmax=model(fe)\n",
    "                loss=criterion(pred_prob_no_softmax,label)/4#/256\n",
    "                del label\n",
    "                del fe\n",
    "                #inp_sp, inp_sn = convert_label_to_similarity(pred_prob_no_softmax,label)\n",
    "                #loss = criterion(inp_sp, inp_sn)/256\n",
    "                \n",
    "                loss_list.append(loss.item())\n",
    "                loss.backward()\n",
    "                accum_flag+=1\n",
    "                if accum_flag%4==0:\n",
    "                    opt.step()\n",
    "                    accum_flag=0\n",
    "                    opt.zero_grad()\n",
    "                flag+=1\n",
    "                if flag%128==0:\n",
    "                    print(\"Loss: \", loss.item())\n",
    "                #print('step')\n",
    "            print(epoch_flag,'*'*10)\n",
    "            epoch_flag+=1\n",
    "            #scheduler.step()\n",
    "            print('Epoch: ', time()-begin,' fold: ',fold,' kers: ',kers)\n",
    "            \n",
    "        model.eval()\n",
    "\n",
    "        prob_file,lab_file,tmp_acc,seg_file=eval(model,test_dtlist,criterion,device)\n",
    "        if tmp_acc>best_acc:\n",
    "            best_acc=tmp_acc                   \n",
    "            res_file_name=\"./weights/fold_%.0f_w_%.0f_fs_%.0f.csv\"%(fold,kers,28)\n",
    "            res_file=pd.DataFrame({\"prob\":prob_file,'label':lab_file,'seg':seg_file})\n",
    "            res_file.to_csv(res_file_name,index=False)\n",
    "            torch.save(model.state_dict(), \"./weights/fold_%.0f_w_%.0f_fs_%.0f.pkl\"%(fold,kers,28))\n",
    "        print(\"update! \",'Acc: ',best_acc)\n",
    "        #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "\n",
    "        print('Epoch: ', time()-begin,' fold: ',fold,' kers: ',kers)\n",
    "        plt.plot(loss_list)\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "        print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blind val ^^^^^^^^^^^^^^^^^^^^\n",
      "  \n",
      "kernel: 128\n",
      "  \n",
      "70 0 []\n",
      "*********\n",
      "32891 0\n",
      "Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) init\n",
      "epoch:  0\n",
      "32891 129\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0c76cec02dde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#,len(test_dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mflag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m                 \u001b[0mfe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;31m#fe=(fe-fe_mean)/fe_std\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "print('blind val','^^^^^^^^^^^^^^^^^^^^')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from time import time\n",
    "for kers in [128,64,32]:\n",
    "    print(\"  \")\n",
    "    print(\"kernel:\",kers)\n",
    "    print(\"  \")\n",
    "    for fold in range(1,11):\n",
    "        begin=time()\n",
    "        #train_rec,test_rec=reclist[train_idx],reclist[test_idx]\n",
    "        train_dtlist,test_dtlist=getTrainTestList(reclist,opt='blind',fold = fold)#fold 1-10   \n",
    "        print('*********')\n",
    "\n",
    "        train_dtlist=[file for file in train_dtlist if dtclean(file)==0]\n",
    "        np.random.shuffle(train_dtlist)\n",
    "        test_dtlist=[file for file in test_dtlist if dtclean(file)==0]\n",
    "        print(len(train_dtlist),len(test_dtlist))\n",
    "        model = MyLSTM(2,kers).to(device)\n",
    "\n",
    "        #model.features[0]=nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if(m.in_channels!=m.out_channels or m.out_channels!=m.groups or m.bias is not None):\n",
    "                    # don't want to reinitialize downsample layers, code assuming normal conv layers will not have these characteristics\n",
    "                    #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                    print(m,'init')\n",
    "                else:\n",
    "                    print('Not initializing')\n",
    "        criterion=nn.CrossEntropyLoss().to(device)#weight=torch.FloatTensor([1,1.5])\n",
    "        #criterion = CircleLoss(m=0.25, gamma=256)\n",
    "        opt=torch.optim.Adam(model.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001)\n",
    "        loss_list=[]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        epoch_flag=0\n",
    "        for epoch in range(60):\n",
    "            print('epoch: ', epoch)\n",
    "            if epoch_flag%3==0 and epoch_flag!=0:\n",
    "                model.eval()\n",
    "                eval(model,test_dtlist,criterion,device)\n",
    "                #eval(model,train_dtlist[0:int(len(train_dtlist)*0.9)],criterion)\n",
    "                eval(model,train_dtlist,criterion,device)\n",
    "                model.train()\n",
    "            train_dataset = ApneaECGDataset(train_dtlist,istrain=False)\n",
    "            #test_dataset = ApneaECGDataset(test_dtlist,istrain=False)\n",
    "            train_loader=DataLoader(train_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "\n",
    "            #test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, sampler=None, num_workers=0)\n",
    "            print(len(train_dataset),len(train_loader)) #,len(test_dataset)\n",
    "            flag=0\n",
    "            for fe, label in train_loader:\n",
    "                fe=fe.float().to(device)\n",
    "                #fe=(fe-fe_mean)/fe_std\n",
    "                #fe=torch.stft(fe,100,hop_length=50,onesided=True)\n",
    "\n",
    "                label=label.long().to(device)\n",
    "                pred_prob_no_softmax=model(fe)\n",
    "                loss=criterion(pred_prob_no_softmax,label)#/256\n",
    "\n",
    "                #inp_sp, inp_sn = convert_label_to_similarity(pred_prob_no_softmax,label)\n",
    "                #loss = criterion(inp_sp, inp_sn)/256\n",
    "\n",
    "                loss_list.append(loss.item())\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "                flag+=1\n",
    "                if flag%4==0:\n",
    "                    print(\"Loss: \", loss.item())\n",
    "\n",
    "                #print('step')\n",
    "            print(epoch_flag,'*'*10)\n",
    "            epoch_flag+=1\n",
    "            #scheduler.step()\n",
    "            \n",
    "        model.eval()\n",
    "        eval(model,test_dtlist,criterion,device)\n",
    "        print('Epoch: ', time()-begin,' fold: ',fold,' kers: ',kers)\n",
    "        plt.plot(loss_list)\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "        print('------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
